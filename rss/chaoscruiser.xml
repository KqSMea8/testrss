<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>读《科技想要什么》，说AlphaGo Zero的大新闻</title>
<link>http://www.jintiankansha.me/t/Z1BaMSbLnO</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/Z1BaMSbLnO</guid>
<description>&lt;p&gt;一年前，和朋友闲聊，他说AlphaGo的下一代是BetaGo，结果人家从Master升级成了Zero，俩个神经网络也变成了一个。一年前，人们讨论AlphaGo是否理解了围棋，人们举例说，如果围棋的棋盘变成了20乘20，那柯洁闭着眼睛都能虐狗，由此来说明AlphaGo并不懂围棋。 但有了从零开始的zero，改变了棋盘的大小，给我3天的时间，照样能够虐人类。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;还有说狗狗不懂人类选手常用的围棋定式的。然而，从Zero的论文中看出来，恰好是那些学会定式慢的狗狗，棋下的好。不同版本的狗狗，最终都学到了围棋的定式，但若是过早的将选择定式的几率提高，那么会限制对未知模式的探索。从这个意义上来说，围棋的定式，何尝不是一种过拟合。然而只有等人类见识到了全新的风格，才能够意识到自己的不足。&lt;/p&gt;

&lt;p&gt;之前我们反驳狗狗不懂围棋的论据，都被AlphaGo Zero打破了，但人类最擅长的是改游戏规则。给定一个选手最多只能记住10万张棋谱，下十万盘棋，在这样的限制下，人类在当下的技术条件下，无论如何都是赢家。但这说明人类理解围棋，学习围棋比AI快吗？答案是否定的。加上这个限制，说明人类由于自身的限制，将围棋变成了一个有限游戏，人类围棋的规则其实是在只记住十万棋谱，下过不多于十万盘棋时下出最好的棋，而AI的出现，将围棋变成了一个无限的游戏。&lt;/p&gt;

&lt;p&gt;这里不是说围棋的可能性变成了无穷的，而是说计算机去掉了存储的限制，狗狗可以记住其下过的所有左右互搏的棋局，而蒙特卡罗树则将最后的输赢反馈到了最初的每一次落子上，解决了奖励时间的不确定性&lt;span&gt;，&lt;/span&gt;而CNN则负责从中推导出该怎么评估当前的局势，将你的落子和整个棋局的大背景结合起来。这样的框架，适合无限游戏的假设。而人类棋手一开始学习定式，则是人类在其自身的限制下最佳的学习方式。人不必盲目的崇拜计算机，说到底，狗狗和人玩的是不同的游戏，自然应该有不同的玩法。&lt;/p&gt;

&lt;p&gt;说完了狗狗，我们将视线拉远，猜猜狗狗下一步想做什么。人们对于未来的想象，常常是线性的。即使对于想象力丰富如著名的科幻作家凡尔纳，他设想的人类登月的方式也只是用大炮，然而真正改变世界的创新，最初都是不那么显著的，没有多少人会注意到。所以与其看狗狗下一步能做什么，不如看看狗狗做不了什么。与其看具体的行业，不如给出算命式的趋势预测。&lt;/p&gt;

&lt;p&gt;有了AlphaGo Zero的框架，所有的完美信息环境下的零和式，有限个选择的策略游戏，都已经成了AI的天下。再结合AI战胜人类的德州扑克选手，对于即使不是一个信息完全公开的游戏，只要可能出现的选项是已知而未知的只是出现的概率时，AI占据绝对优势，也是必然的了。留给人类的唯一机会，就是不要去玩零和游戏，不去玩有限的游戏了。&lt;/p&gt;

&lt;p&gt;有本书就叫《有限和无限的游戏》，书中写道，有限游戏以取胜为目的，而无限游戏以延续游戏为目的。有限博弈者在边界内游戏，无限博弈者以边界为游戏对象。有限游戏旨在以一位参与者的胜利终结比赛，每个有限游戏都是为了结束自身。矛盾恰恰就在于，所有有限游戏都是在对抗自身。在这本书中，作者提醒读者转化游戏观，认识到生活其实不应当被看成是有限的游戏。&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdXzh90N8e8w3xCAIpwsdUgG1YlshggBCmZO4lzsFk7U18nUx81SjnjsnSPU5byzFIWWML761cWUg/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.4455445544554455&quot; data-w=&quot;303&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;凯文凯利在《科技想要什么》中对《有限和无限的游戏》十分称赞。书中写道：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;进化、生命、思维和技术元素都是无限博弈。它们的博弈就是让博弈持续下去，让所有博弈者尽可能地长时间参与。为了达到这样的目的，它们像所有无限博弈一样戏弄游戏规则。进化之进化就是如此。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;生活中我们最爱的事物──包括生活本身──都属于无限博弈。当我们参与生活博弈或技术元素的博弈时，目标不是固定的，规则不明朗，并且一直在变动。我们如何进行下去？好的选择是增加选择。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;无限博弈的目标是保持游戏的进行：摸索游戏的所有玩法，增加各种博弈，召集所有可能的玩家，扩展游戏的意义，倾尽所有，无所保留，创建宇宙中不太可能发生的博弈。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;弄清楚了无限博弈的思路，就能够再一个大的框架下去看狗狗战胜人类的这件事，狗狗的出现，将围棋这种有限的游戏，转化成了一个无限的游戏。游戏的目地不再是为了获得世界第一，而是为了探索出围棋中的所有玩法。狗狗胜利的方式，是狗狗背后的Deep mind巧妙的改变了游戏规则，而不断改变游戏规则，正是无限游戏唯一的规则。&lt;em&gt;&lt;br /&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;说完了哲学性的话题，这篇小文就以AI取代职业这个话题来结束吧。很多人会问自己，你的工作中有百分之多少是可以被AI所替代的，然后据此评估AI是否会取代你的工作，但从有限和无限的游戏这个角度来看，你要问自己的问题的答案会是更主观的。你问自己在做的工作，究竟是该被当成有限的游戏，还是无限的游戏。&lt;/p&gt;

&lt;p&gt;一个餐厅的服务员的工作，是自动化程度很高的，但这并不意味着未来餐厅服务员这个职业会消失，米其林餐厅，国宴会，服务员的岗位总是在的。一个服务员若是将自己的工作时间看成是零和的游戏，那么她必然会担心自己的岗位丢掉，而她的担心会使得她忽略由于游戏边界的改变而带来的新机会。而如果她只是将餐厅的服务员工作看成是无限游戏中的一部分，那么在机器人取代一步步取代服务员的过程中，她会随之成长，找到新的坏境下新的角色。你的担忧反映的更多是你对自身角色的看法，而不是事实。&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;更多阅读&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382963&amp;amp;idx=1&amp;amp;sn=53c1f03208ca7a41285566b9bf8aa83d&amp;amp;chksm=84f3caf2b38443e40428d245046814ac4ca8883c4403a88f68980b86e57b4c754759edf6eece&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;铁哥谈AI： 浅析阿尔法元之元&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382959&amp;amp;idx=1&amp;amp;sn=4e3f03464db9bf33225d9293d69c5eb6&amp;amp;chksm=84f3caeeb38443f8aa9f050568b0368b512851c70c355d1690c07c3b1c92c82fe5d22f0b41ec&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;机器学习：增加更多就业岗位&lt;/a&gt;&lt;br /&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; &lt;/p&gt;



</description>
<pubDate>Tue, 24 Oct 2017 05:34:13 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/Z1BaMSbLnO</dc:identifier>
</item>
<item>
<title>从纯种狗的悲哀，最终说起人的理性和感性</title>
<link>http://www.jintiankansha.me/t/hhY7uwSJid</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/hhY7uwSJid</guid>
<description>&lt;p&gt;对于哺乳动物来说，体型越大，相对来说，寿命也越长。小老鼠的活不了几年，大象却能活的和人类相当，所谓朝菌不知晦朔，蟪蛄不知春秋。这条幂律法则决定的规律，在今年的新书《scale》中有过详细的描述。然而生物体内的第一铁律，就是除了这条规律之外，其他的规律都有反例。宠物狗作为一种被人工选择干预严重的生物，不同品种的狗狗虽然基因上差距不大，但体型上的差异却有一个数量级那么大。从最大的大丹犬到最小的茶杯贵宾犬。自然界中再也找不到一个体型差距这么大的物质了。&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdXzh90N8e8w3xCAIpwsdUgs4R9wslHwcozIe3lCxSJtVNkflX1kxdIZQsL4aJD1AvD02kqpgjajA/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.6499162479061976&quot; data-w=&quot;597&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于每一个养狗人来说，狗狗的寿命都是大家最关心的，狗狗的一岁约略等于人的7岁。而不同品种的狗狗，其寿命差距是很大的，体型越大，寿命越小。下面的图片来源于大样本量的长期调查，具有统计上的显著性，该结论已多次被不同的研究者重复出来，也符合养狗人士的常识。这里将狗狗按照体重分成了7 组，可以看到体重越轻的狗寿命越长的趋势是很明显的。这里的纵轴代表的是符合条件的这一组包含了几个品种，我们看到养的最多的还是20-40磅的小型狗。而将体重最小和最大的品种相比，其体重差了一个数量级，而寿命则差了接近一倍。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdXzh90N8e8w3xCAIpwsdUgianEdG351GL4WLrMPAEFuH2jj5VB1rwWcG6VPiaeWtMmBW8uaHRCrV7g/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.7856&quot; data-w=&quot;625&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;来源：http://users.pullman.com/lostriver/weight_and_lifespan.htm&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;下面的这幅图展示了不同标准体重的纯种狗的平均寿命，图中黑色的点代表母狗，白色代表公狗，每个点上标记的为狗狗的品种，和人类一样，雌性的寿命长一些。科学家将这么多种狗狗的体重和寿命画在一起，是为了通过拟合找出图中的黑线和虚线，也就是说，不同狗狗的寿命和他们的体重呈线性关系。&lt;/p&gt;



&lt;p&gt;&lt;img data-type=&quot;gif&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdXzh90N8e8w3xCAIpwsdUgN5PfhW7SEsbkkWd4KGxBd6beoyKSnUfS3oOwh18BpQR9zXWWndBuCA/0?wx_fmt=gif&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.6954545454545454&quot; data-w=&quot;440&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;图片来源：参考文献1&lt;/span&gt;&lt;/p&gt;

&lt;p&gt; 看来不止人超重了不好，狗狗太胖了也不好啊。但这和我们最初看到的普遍规律是相反的，这是为什么了？而这正是我感兴趣的。搞清楚这个问题，意义重大。因为狗狗的寿命和人的寿命的调控机制是一样的。你也许听说过，控制卡路里的摄入能够增加寿命，但这对吃货来说实在太痛苦了。也许通过对不同寿命的狗狗的研究，我们能够找到延长人类寿命的更有效的方法。而且科学史也告诉我们，弄清楚一个反常现象背后的原因，会带来意想不到的新研究方向。&lt;/p&gt;

&lt;p&gt;细心的读者也许会问，上图说的都是纯种狗，那对于混血狗，又是怎样的了？遗憾的是，由于纯种狗在人工培育的时候，都会经历一段瓶颈时期，也就是其种群数量很少，近交系数较高，从而积累很多的有害突变，所以导致相同体重的纯种狗，都不如杂种狗的寿命长。这是为什么狗狗的寿命和体型之间的关系异常的第一种猜想，即人工选择带来的初始种群过小。&lt;/p&gt;

&lt;p&gt;另一组科学家猜想是人们在培育体重大的狗狗的时候，保留了携带疾病的基因，参考文献3 4中列出的例如扩张型心肌病，胃扭转和肠扭转阻塞，人为的选择，使得那些本该被自然选择压淘汰的基因保存了下来。&lt;/p&gt;

&lt;p&gt;但疾病的因素还不能解释这么明显的差异，参考文献5从不同品种的狗狗的免疫系统的角度，解释了这个问题，研究发现个头小的狗狗胸腺功能的减弱来的晚的多，从而使得个头小的狗狗在年老后也能保持较高的免疫力。&lt;/p&gt;

&lt;p&gt;研究（文献6）表明个头小的狗狗&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382243&amp;amp;idx=1&amp;amp;sn=a6e7e40ecfcfe59045f2fd58f4b3066f&amp;amp;chksm=84f3cfa2b38446b4f92c3c5b55160c0935ac79f57bb987cadff1626b2455a1f54b8042e45983&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;端粒&lt;/a&gt;（点击链接，查看端粒究竟是什么）相对较长，这也可以部分解释为什么个头小的狗狗寿命长。但这并没有指出为何个头小的狗狗端粒相对长一些。&lt;/p&gt;

&lt;p&gt;科学家接着研究的问题是基因上的那些差异和狗狗的寿命有关，根据参考文献1，结果找到的变异位点竟然都落在和体重差异有关的基因上，例如IGF1基因，这究竟是不是仅仅是一种巧合了，还是有更深一步的生物学机理了？IGF1基因编码的蛋白是调控生长发育的，根据文献7，在大狗的血清中IGF1的浓度要相对高一些，高的时间也要相对长一些，没办法，狗狗要长那么大需要更多的时间，但IGF1蛋白的另一个影响是一旦细胞开始凋亡，它就会加速细胞的凋亡，而细胞凋亡又和衰老和癌症密切相关。这就是说，&lt;strong&gt;大狗壮硕的体型背后，意味着他们更早的开始衰老的过程。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;根据参考文献2，不同品种的狗狗为什么寿命差距这么大，在科学界依旧是一个开放的问题。对于这个问题的答案，我的想法是这个问题等价于两个问题，一是大狗为什么相对短命，二是为何小狗长寿。对于小型狗来说，它们的寿命长，我猜想是来自于它们吃不饱，也就是人类为了维持他们的体型，定向的选择了吃的少长的小的那些，而限制卡路里则会增加寿命，这已被科学界反复验证了的。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdXzh90N8e8w3xCAIpwsdUgn85aFoHWap9LT9cicUqGuOag5JKib7Y6XPh8ytufLlvzHNL1NZjE4Dag/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.6814814814814815&quot; data-w=&quot;1350&quot; /&gt;&lt;/p&gt;

&lt;p&gt;图片来源 Scale : the universal laws of growth, innovation, sustainability, and the pace of life in organisms, cities, economies, and companies / Geoffrey West.&lt;/p&gt;

&lt;p&gt;而对于为什么大狗短命，我倾向与人工选择带来的非预期后果，即无意中保留的治病突变。文献3和4的研究只看了单基因病，但更多被无意中保留下来的是癌症的易感性等复杂疾病的突变。只是这些要研究清楚，难度更大。&lt;/p&gt;

&lt;p&gt;最后，我想开一开脑洞，说说狗狗的驯化史和他们的寿命和那些不养狗的人有什么关系。我看过一部很伤感的纪录片《纯种狗的悲哀》，其中记录了纯种狗的悲剧。回到本文的第一幅图，寿命最小（5-7岁）的狗狗品种中，有4种不是大型犬，正是这些反例，使得我认为观察到的体型和寿命的关系只是相关性而不是因果性，是其他更基础成因带来的副产品。&lt;/p&gt;

&lt;p&gt; 而这更基本的成因，从自私的基因的角度来看，不管是大丹，还是那个平均寿命5-6岁的可怜品种，他们的基因都是异常成功的。但整个物种的角度来看，这些纯种狗的基因由于单一性状的选择，而使得其可进化性基本消失，它们不能再做任何改变了，也没有任何未来变化的可能性了。只要这种品种存在，那么他们就只能这样了。&lt;strong&gt;然而进化，如果说其有目的，在于扩大整个系统的可进化性，或者说是选择的空间。&lt;/strong&gt;但对于纯种狗来说，其基因组合是固定的。缺少可进化性，就注定会导致有害的突变富集。&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt;  再开一层脑洞，对于一个智慧生物来说，改造自然是必然的。这使得他迟早会走上以自己的偏好来决定身边生物的进化足迹的路途，被改变的生物，最终也会包括他自己。若不考虑人的感情和主观感受，就像人在培育纯种狗时，对狗狗缺少共情心，那么未来的人类，也会变得像狗狗这样。这么说看起来有些耸人听闻，但且听我演绎下这其中的逻辑。&lt;/p&gt;

&lt;p&gt;AI带来无用阶层，无用阶级不关心生产，只关注找到自我，但就像当下的以瘦为美，拼命节食所预示的，未来的无用阶级会以超过当下百倍的能力，为了单一的指标而改变自己，不论这个指标是智力，体力还是体型，反正未来即使有了问题，也有医学来保证。对单一指标的推崇，还反映在当前对某一营养元素的过度宣传上，例如Omega-3，花青素等。以及正在升温的全民健身，很多人真是为了健康还是一种盲目的对“公认西方肌肉美”的推崇？&lt;/p&gt;

&lt;p&gt;然而当人类开始了对单一形状的自我选择，那就会导致有坏突变的累积，就像我们在宠物狗中所看到的。而只有人类的主观感情以及人与人之间的共情心，才能打破这个魔咒。感情聚集了我们所有时间的全部体验，即包括能言说的，更包括了那些我们体会到却说不出的体验。感情的好坏，永远不会只关注避单一指标。纯种狗的培育者忽视了他们养育的狗狗的感情，才造成了当今纯种狗的悲哀。人类若是自我压抑，自我设限，那么正应了那句“后人哀之而不鉴之,亦使后人而复哀后人也”。&lt;/p&gt;

&lt;p&gt;为什么会有情感，会有意识，会有共情心，对于这样的问题，进化上一直没有一个好的解释。这篇小文也不打算回答这么巨大的问题。只是想因小及大，由对狗的人工选择反思当下和未来人类可能出现的对自己体型的选择，在表述担忧的同时提出解决的可能办法是人与人之间的共情心（理解、包容和接纳多样性）。共情让我们能推己及人，不以单一的评判标准去要求别人。而纯种狗的遭遇，对于这个过于推崇理性的年代，则是一种别样的提醒，没有共情心，只要理性，在长期上终究是不行的。&lt;/p&gt;

&lt;p&gt;扩展阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=402243130&amp;amp;idx=1&amp;amp;sn=cd7954ee7e0fc8dfe89634151a46365f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;理性是激情的奴隶&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;参考文献1：&lt;span&gt;Jones, P. et al. Single-nucleotide-polymorphism-based&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;association mapping of dog stereotypes. Genetics&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;179, 1033&lt;/span&gt;&lt;span&gt;–&lt;/span&gt;&lt;span&gt;1044 (2008).&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;参考文献2： Demographic history, selection and functional diversity of the canine genome. Nature Review &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;参考文献3 Ohta, T. Role of very slightly deleterious mutations in molecular evolution and polymorphism. Theor. Popul.Biol. 10, 254–275 (1976).&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;参考文献4 Eyre-Walker, A., Woolfit, M. &amp;amp; Phelps, T. The distribution of fitness effects of new deleterious amino acid mutations in humans. Genetics 173, 891–900 (2006).&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;参考文献5 Holder, A., Mella, S., Palmer, D. B., Aspinall, R. &amp;amp; Catchpole, B. An age-associated decline in thymic output differs in dog breeds according to their longevity. PLoS ONE 11, e0165968 (2016)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;参考文献6  Fick, L. J. et al. Telomere length correlates with life span of dog breeds. Cell Rep. 2, 1530–1536 (2012).&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;参考文献7 Bonnett, B. N., Egenvall, A., Hedhammar, A. &amp;amp; Olson, P. Mortality in over 350,000 insured Swedish dogs from 1995-2000: I. Breed-, gender-, age- and cause-specific rates. Acta Vet. Scand. 46, 105–120 (2005)&lt;/span&gt;&lt;/p&gt;



</description>
<pubDate>Sun, 22 Oct 2017 07:55:19 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/hhY7uwSJid</dc:identifier>
</item>
<item>
<title>铁哥谈AI： 浅析阿尔法元之元</title>
<link>http://www.jintiankansha.me/t/omFJ2C41aL</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/omFJ2C41aL</guid>
<description>&lt;p&gt;&lt;span data-offset-key=&quot;bi454-0-0&quot;&gt;今天早上被一条重大新闻刷屏：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;3jtcs-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;Nature- Mastering the game of go without human knowledge&lt;/span&gt;&lt;/span&gt;&lt;span data-offset-key=&quot;3jtcs-0-1&quot;&gt;， 阿尔法元超越自己的大哥-阿尔法狗。 这一代算法被deepmind命名为Alphago Zero， 中文阿尔法元，“元” 含有起点，创世之意。 总之，就是从零开始 ，其实这个元字用意很深， 一方面说， 这个算法是不需要人类数据指导，也不需要它哥哥（阿法狗）指导，就自己演化出来。 另一方面也可以理解为它可以开启新纪元。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dt5il-0-0&quot;&gt;当然， 同时谷歌也宣传了它的TPU， 只需要4台TPU运行几天的功夫就可以了。 那么， 这次的大新闻是不是一个谷歌精心策划的商业广告，还是真的隐藏天机。铁哥就来给大家解读一下阿法元和其背后的深度强化学习，看看这次的大新闻算不算得从零到一。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8ibcs-0-0&quot;&gt;如果大家了解计算机学下棋的事情，就会了解到几十年前，我们就已经用穷举法来解决棋类问题了，在国际象棋这类游戏里， 计算机会以比人脑快的多的速度推演两军对峙的未来，在运用零和游戏里固有的减少风险策略， 在1996年就可以让人类棋手甘拜下风。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;acaae-0-0&quot;&gt;穷举法不适用围棋，因为跟其灿若宇宙星辰的可能性搜索空间（每一步19*19可能，若干步骤后就是天文数字，这种由于可能性爆炸导致的悲剧也称为维度灾难），被称为人工智能界的mission impossible。 而在2015年， 梦幻被粉碎，原因在于深度卷积网络的幽灵终于潜入到了棋类游戏领域。 深度学习最擅长把高维度的问题自动的降维，从而解决了刚说过的维度灾难，如宇宙星辰般的搜索空间瞬间被压榨到很小，在此时的机器算法面前， 围棋无非是一个当年的国际象棋。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcps0Xjicz0kQJbhFWNb3Dev590WibnD2QZA8JbS69KEBdNIGTlzLDicZu2fQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;300&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;7ufh3-0-0&quot;&gt;然而当时立下首要功勋的深度卷积网络，却需要学习三千万组人类数据进行训练， 而整个训练过程需要的能量据说要耗费几吨煤炭。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;19ekg-0-0&quot;&gt;人们说，你秒杀人类智商的阿法狗无非是比人类看棋谱的速度快，难道还真的懂围棋吗？ 你所作的顶多是模仿，里面的强化学习到底有多少作用， 真的不知道。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;389o-0-0&quot;&gt;然而今天，阿法元却能够在不用那3000万数据的时候来个完胜阿法狗。从人工智能的技术角度看， 这是强化学习的胜利， 在不进行监督学习的情况下， 就可以达到一个高于人类的境地。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;cf1o3-0-0&quot;&gt;为什么强化学习如此重要？ 让我们先比较一下监督学习和强化学习的基本思想。 监督学习， 强化学习和无监督学习是机器学习的三大框架。 某一个意义说，监督学习是给定输入和输出，机器来学习输入和输出的关系，一个好的监督学习算法犹如一个预言家， 它能够根据自己之前见过的输入输出关系来预测未知的输入。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2psih-0-0&quot;&gt;强化学习呢？ 强化学习的三元素是状态，行为和环境奖励。 强化学习条件下， 学习者每一步看到的是它决策的行为结果， 然后导致下一步行动，为了最终游戏的胜利。 一句话说：强化学习强在决策。 监督学习是预言家，强化学习是决策家。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.48833333333333334&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsV4Mu5XbPHGfej0xjDpj72EibTct0ibav9n1Zzn4icv4IWzBMoaWTpialRA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;293&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;cj562-0-0&quot;&gt;我们一比就明白， 强化学习更像是一个日常决策中的人。我们看到一个老虎，监督学习帮你识别出来它是老虎，那么你可能刚说出来就被它吃了。 而强化学习告诉你赶紧跑，你可能活下来。 &lt;strong&gt;监督学习让你成为复读机，而强化学习让你称之为生物。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.29333333333333333&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsRxyf7PuFXI3NXVG0IB5N90pmc0QIdZBnEibf4yWCUwhichupUZgjtQkQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;176&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;bfpem-0-0&quot;&gt;再深一点想，其实学习是为了生存，是赢得game of life（想想那些不太读书就能过得很好生活的真是深谙强化学习的道理）。 强化学习赋予机器以灵魂。监督学习的那些任务反而是在这个宗旨之下产生的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;80nhn-0-0&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt;  回到围棋， 我们看看强化学习如何决策： 我们在好好理解一些一下“强化” 二字， 强化的意味是： 强化优势经历，反过来，就是弱化劣势经历。当你走了一部棋导致不好结果，之后被选入这一步棋的概率就降低， 而导致胜利的选择被不停的强化，直到你每次都延着最佳路径前进。这听起来很像进化， 而与进化的区别是，进化是严酷的客观环境对随机变化的生物的选择，而强化学习里的单元可以通过梯度下降主动调整策略。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a1bc6-0-0&quot;&gt;既然强化学习那么牛， 为什么阿法狗还用监督学习这个拐棍呢？一句话说，强化学习太难了！&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8s35-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;强化学习有两大难题：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ev461-0-0&quot;&gt;1， 奖励时间的不确定性： 今天的努力，可能明天回报， 可能十年后才有回报, 今天带来奖励的事情，明天可能就导致悲剧（比如吸毒很爽未来地狱） 对于游戏里的每一次决策，　你都无法获得立即的反馈，相比监督学习时时可以得到对和错的答案，这个信息实在太弱了， 用来指导学习，那是慢慢的（如何利用这个或有或无的信息，强化学习的一系列方法围绕而来，比如Q-learn）。 　&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2l540-0-0&quot;&gt;2， 探索与收益的平衡难以掌握： 有的人一辈子抱残守缺，７岁玩泥巴未来就永远玩泥巴。 有的人一辈子都在探索不同的方向，但是换来换去最终庸庸碌碌。而只有恰当把握探索收益平衡的，比如说27岁前读书去不同国家，27岁开始认准一个方向成为大佬，30岁前各种风流倜傥，30岁选个知书达理另一半从一而终。 强化学习始终面临是探索更多空间，还是开始用现在经验收益的矛盾。　&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;3cja1-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;这两点放到围棋这个搜索空间犹如宇宙星辰的游戏里，估计学习时间也要用生物进化的尺度算， 然而阿尔法元所用的强化学习算法，号称解决了这个问题。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ajql2-0-0&quot;&gt;仔细看它和它哥哥阿尔法狗的差别没那么大， 只不过这一次的神经网络完全由强化学习训练， 和蒙特卡罗树得融合可以算是完美。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6716o-0-0&quot;&gt;之前的阿尔法狗有策略和估值网络（都是深度卷积网络），策略负责把棋盘现在的状态转化为可能的行为概率， 这个东西被称为策略（policy，是由每个可能的行为概率构成的向量，简称策略向量） ，估值则是输入目前的棋盘状态得到最终结果的概率。 这两个网络在这一次被合成一个巨大的深度残差网络（卷积网络的一种）。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.9314079422382672&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsoH0hA9BP2pujxMyw7ZHia69xRjmMAibl7JhVWWsiaCaE9FebZrEpP0NKg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;554&quot; height=&quot;516&quot; width=&quot;554&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;7nudg-0-0&quot;&gt;Nature图： 深度卷积网络计算概率&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8uljh-0-0&quot;&gt;深度卷积网络擅长整体对图像信息进行编码， 我们可以把这个巨大的残差网络所作的事情看成白日梦者对未来的总体规划。 多层卷积本身的天性决定它擅长从这种19*19的格子图像总结出意思来，强化学习的信息一旦可以训练网络，就会产生意想不到的效果。而之后MCTS蒙特卡罗树则对这种初步的结论进行实践修正。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d3a31-0-0&quot;&gt;在这里回顾一下蒙特卡洛树是怎么工作的，说到蒙特卡洛， 这是大名鼎鼎的随机抽样方法。所谓树，大家一定可以想到决策树，树的节点是某一刻的状态，而枝杈代表一个决策（行为），而这里的蒙特卡洛树即生成整个决策树的过程，通过大量的实验（犹如蒙特卡洛抽样的过程）得到每个决策行为取胜的概率。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d3a31-0-0&quot;&gt;决策树从一个状态s出发，每个分支代表一个可能行为（a），而且有一个代表最终赢率的分数与之对应，我们选择分数最高的那个行为继续展开（下一次行动），得到新的状态，用相同的规则行动，直到游戏结束， 最终赢的走法加一分， 输的走法减一分，依次往复模拟无数次后，就会得到从s出发不同决策赢得比赛的概率。 这个过程酷似进化选择算法， 就是让那些有优势的选择有更高的繁殖子代概率， 最终胜出。虽说这仅仅是阿尔法元的一小步，却包含了著名的Q-learning和马尔科夫决策树的思想。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;qrgk-0-0&quot;&gt;我们来看每一步决策神经网络和蒙特卡洛树是怎么结合的： &lt;/span&gt;&lt;span data-offset-key=&quot;qrgk-0-1&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;决策分为搜索阶段和行为阶段&lt;/span&gt;&lt;/span&gt;&lt;span data-offset-key=&quot;qrgk-0-2&quot;&gt;。假定现在我处在状态s，在搜索阶段神经网络对我所能做的所有行为（a）进行根据对未来的猜测进行预判&lt;/span&gt;，生成赢棋的概率v和策略向量p（s，a）。 当然这个预判开始很不靠谱， 蒙特卡洛树在此基础通过无数次模拟实践展开来（注意均是在状态s上），来实践出靠谱的策略向量pi（s，a）。&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt;  有了神经网络的帮助，蒙特卡罗树展开不是瞎展开， 也不是从零开始，每一个树的新分支上，我们都通过神经网络给它一个是正确步骤的先验概率（P）和初始的赢率（V），代表走它通向胜利的概率。在神经网络助攻下，蒙特卡洛树可以更快的更新策略向量（每个行为选择的概率）。此时搜索阶段结束， 我们从这个策略向量里通过抽样得到我们最终进行的行为，是为行为阶段。 这下一步棋还真不容易啊！&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.26666666666666666&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsiajKyaOtibGwOv1hLBtLtjgNtSAAYibPBwNaiapFvJPyWb8FFcsTOWCkibg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;160&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;77j4h-0-0&quot;&gt;Nature图： 策略更新的方法&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a1pa3-0-0&quot;&gt;最终当游戏结束的时候，神经网络的权重开始更新，这个更新的过程里，我们把整个游戏的过程分成很多小段， 比较神经网络预测的概率和蒙特卡洛树算出来的（策略向量之间的差异），以及预测结果与最终结果的差距进行梯度下降（梯度由如下公式得到，此处混合之前的策略和估值网络）。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.14333333333333334&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsWbnhR49iaFicbgX6lQ8jibSQyN8WvXlZ5cYhTkh1u7EibTbDcbDMWal7Dg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;86&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;9jrnd-0-0&quot;&gt;这样周而复始，我们可以推断，最终神经网络的预测将越来越靠谱，和蒙特卡洛树给出的分析越来越一致。 而围棋的套路也会被一一发明出来，所谓无师自通。&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.8633333333333333&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsQTc3L6c3EdUyfKoVVa0CpgQciacvMYiaHYcdDGYFQaps8Q0NOrXqoJJQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;518&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;5ibte-0-0&quot;&gt;Nature图： 看看右下的图，是不是很像人类选手常用的招！  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9c2ea-0-0&quot;&gt;为什么说阿尔法元敢叫元？ 如果从技术角度看，这一次的阿尔法元没有那么多新的东西，而是在之前基础上让强化学习进行的更彻底了，然而它所展示的深度强化学习的应用未来，却是十分诱人的。&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.35&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsRGYzWDxqCfib19LOQ0gfBSD7qFIIaSQ3bAfbA6ibr02JT5uPI4Oic2wiaw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;210&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;fmjkn-0-0&quot;&gt;图： 强化学习的胜利（蓝）对比监督学习（紫）和监督+强化学习（虚线）&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;987es-0-0&quot;&gt;首先，我们看到， 并不是每一件机器学习的事情， 都需要和数据，尤其是需要大量人力的标注数据死磕， 而是可以通过恰当的设立模拟器（比如此处用到的蒙卡树） 来弥补。阿尔法元不是不需要数据，而是数据都是自己模拟产生的。 模拟+深度强化学习， &lt;strong&gt;在简单的游戏规则下，一些复杂的行为范式可以进化出来，而且可以比人类设计的还好&lt;/strong&gt;， 这， 你就可以大开脑洞了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ckimk-0-0&quot;&gt;这件事在很多设计性的工作里实在是太诱人了。 无论是设计新材料，建筑，还是衣服，&lt;strong&gt;这些可变维度很高的事物，你都可以想象设立一个模拟仿真环境，再设立一个相应的神经网络去做各种尝试，最终设计出的结果有一个奖惩函数反馈，来让这个网络来学习。&lt;/strong&gt;这就打破了深度学习创业只和手里有大量数据的垄断者相关的梦魇。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8k7da-0-0&quot;&gt;这里的深度强化技术， 也才只展示了冰山一角， 在一类被称为SLAM的技术上， 深度强化学习被证明了强大的控制能力， 它能够驱动机器人在非常复杂的空间里进行探索无需GPS，对于这一类深度学习任务， 有别于alphago的任务，因为围棋属于完全信息的博弈， 而真正的空间探索，是通过感知系统探测到的不完全信息， 通过记忆在时间尺度上的综合，这一点，只有搬出大名鼎鼎的LSTM来对付了。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.6333333333333333&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpskhySEVQXKxWy56LKHsAJ0XXnA0hdiaAua0iaZrdWHaTzGDjdAO0xMQibQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;380&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;4nqss-0-0&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt;  能够控制运动的深度强化学习，迟早会改变工业界，它不仅是无人车里的核心技术， 更是对话，推荐系统， 金融交易， 甚至是图像识别的利器，几乎各类需要监督学习的事情，说到底强化学习都有实力。 你如果制造一个聊天机器人， 你当然希望它能够揣测你的意图和你谈情说爱而不是背书。 你要一个推荐系统， 你当然不需要它天天给你推你刚看过的小黄片，而是带着你探索一段BBC-性的秘密。  所以， 强化学习， 是人工智能的大势所趋啊。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.66&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsjUU1ewb6V3XTQvWIy5IuR5tHXrIBWdnPzhAQcE4h8zY3CB0KJXVAOQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;396&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

图：强化学习下的装配空间

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5631970260223048&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcps8ic1kUm8dgUofdWt4AT4wib66t7NzYhTzVm1ribBxPmeFjgFB0jJhgjPA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;538&quot; height=&quot;303&quot; width=&quot;538&quot; /&gt;&lt;/p&gt;

图： 强化学习下的物流车间





&lt;p&gt;&lt;span data-offset-key=&quot;evrgp-0-0&quot;&gt;更有甚者，我们可以设立一个具有类似地球的物理环境的地方，让配备了深度强化学习系统的虚拟生物进行各种活动，看它们能否利用这个环境发现和利用其中的物理定律。&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;duudf-0-0&quot;&gt;欢迎关注巡洋舰的深度学习课程， 深度强化学习将是重点：&lt;/span&gt;&lt;span data-offset-key=&quot;duudf-0-0&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382937&amp;amp;idx=1&amp;amp;sn=d4510592a837c44fe75393c2578698d8&amp;amp;chksm=84f3cad8b38443ce6adcd155a2c45ee7707b4a9d8e48c05728aa7e93862475832bf89617025f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;巡洋舰新年深度学习训练营计划&lt;/a&gt;， 这么课程， 将真正带你手把手的领略深度强化学习的魅力， 看你能不能自己动手设计个阿尔法元&lt;/span&gt;&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdrg83hduKplaOkZeV6icFIST2rojIm4SLJSQU8CgNia1AYmETxrSibzh5P6vPiaOffICZibFcNKfichRhw/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.7935540069686411&quot; data-w=&quot;1148&quot; /&gt;&lt;/p&gt;










</description>
<pubDate>Fri, 20 Oct 2017 19:19:26 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/omFJ2C41aL</dc:identifier>
</item>
</channel>
</rss>