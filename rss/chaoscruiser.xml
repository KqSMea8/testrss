<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>小学生都看得懂之 白话数据降维</title>
<link>http://www.jintiankansha.me/t/tfYe8PS62H</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/tfYe8PS62H</guid>
<description>&lt;p&gt;数据降维是数据分析中最常用到的一种技术了，这篇小文将试图用大白话讲一讲数据降维到底是什么，有什么用，常用的方法分别是什么？希望写的让小学生也能听懂，下面先为各位奉上这篇小文的思维导图。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdELMqvjP6J8kM6RDh7vCSlGHsrvSxVJgAQM6CwLX3q7uj4icwWAzv0fZQmNT0mv6dUaL5jmzRq5lg/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.40923076923076923&quot; data-w=&quot;975&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这篇文章贯穿始终的一个故事场景是如何在一个小镇上将横纵的街道编号，例如科技三路和凤城五路的接口这样一个用俩个数字标注的位置信息，转化更一个只用一个数字标识的位置描述。在上述的例子中，原来的位置信息有俩个维度，我们就用笛卡尔坐标系中的X轴和Y轴来表示吧，而数据降维的目地就是要让数据的维度降低到一维。而在上述的小镇上，如果有一条铁路通过了小镇，而小镇上所有重要的建筑都在铁路边，那么就可以根据距离铁路的起点多远来定义每一个点的位置。当然，这样的定位不如用俩个维度来的准，有的地点离铁路远，但是远多少，在新的表示中就没有得到展示了。这说明数据降维不是无损的，会造成信息的部分丢失。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdELMqvjP6J8kM6RDh7vCSlDyqI9ibbzhUUlGZoCY02o6RGibj9I4dHlGsBuicQSNjb6sicpFhqxogVjg/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.24566473988439305&quot; data-w=&quot;692&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那数据降维在什么时候应该应用了？回到小镇的例子，数据降维的第一个用途是数据压缩，如果你只能在一张小便签向一位你新认识的朋友写下你家的地址，便签上写不下是××路××号，那你可写铁路第五。而数据降维还可以去做数据可视化或特征提取，比如你要在小镇上开一家点，你先看看那里人群更加密集，你可以通过数据降维，做出那些地方周围的点多，从而人流更密。数据降维的第三个用途是异常值检测和聚类，例如你通过数据降维，发现小镇上的大部分人家都住在两个火车站附近，但是有一俩个家却不在这里，这样你就发现了小镇里那些特立独行的人，接着你发现俩个火车站附件的人家，一家都姓张，一家都姓李，这样，你就将小镇的人家通过数据降维，分成了俩类。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdELMqvjP6J8kM6RDh7vCSlB1aqBDEF7Fic0r5cV16EaxNPoXr114ukwKsePabVriaX2W5meAGQtXVQ/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.47074468085106386&quot; data-w=&quot;376&quot; data-backw=&quot;376&quot; data-backh=&quot;177&quot; /&gt;&lt;/p&gt;

&lt;p&gt;接下来说说各种做数据降维的方法，最熟悉的方法是主成分分析法，即PCA，在上面的例子中，主成分就是我们找到的铁路线，我们将小镇上所有的人家按照铁路开来的顺序，依次排序，从而得到了只用一个数字表示的距离。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;然而PCA有一个问题，就是他画出的这条线，一定要是一条直线，如果这个小镇上的人家不是根据铁路线，而是根据一条弯弯区区的河流，在河两岸安家的，那么PCA就无法找出这条弯曲的线了。而我们遇到的大部分小镇，都是逐水而居的，正如我们通常遇到的需要降维数据，而这就需要所谓的非线性数据降维方法了。&lt;/p&gt;

&lt;p&gt;第一种非线性的降维方法叫做核PCA，即Kernel PCA。理解核PCA，可以想象我们在标识一家人的住址的时候，先通过一个核函数的方式估算出这家人住的地方海拔有多高，由于水是向低流的，通过先将数据的维度提升，再降低的方式，从而在非线性的约束下实现数据降维。&lt;/p&gt;

&lt;p&gt;而第二种非线性的降维方式叫做tsne，tsne是一种很强大，也很费计算时间的非线性降维方法。tsne的逻辑可以这样理解，你要将小镇上每户人家的住址降低成用一个数字表达的数，由于在之前小镇上人们之所以张家和李家住的近，是因为他们自己是亲家，而刘家和王家住的远，是因为他们之间打过架。在之前的住址中，包含了这样拓扑信息，而在降维之后，你在地图上画出一条弯弯曲曲的线，不管这条线你是怎么画的，你都希望在这条线上张家和李家还是很近，刘家和王家还是很远。这就是tsne要保留的高维数据中的拓扑结构。可以想象，小镇里要是住户越多，这条线也越难画，tsne是一种迭代的算法，也就是说人民最开始画的线不一定是最好的，一次次向着优化目标的修改，直到达到相对较好的点。&lt;/p&gt;

&lt;p&gt;而这里要介绍的最后一种降维方法，来自于机器学习的门派，叫做自编码器。还是拿小镇上的例子来说，现在你假设要对镇上每户人家的住址用一个数字来编码，但你不知道该怎么办。于是你叫来你的双胞胎儿子，叫弟弟想办法用一个数字来标记每户人家，而叫哥哥在不知情的情况下，根据他弟弟给出的数字去猜测每户人家在那里，最初哥哥猜出的地方和这户人家本来的地方差距很远的，而等到几个月之后，兄弟俩有了默契，他们猜到的地方就差不多了。这时你将弟弟称为编码器，将哥哥称为解码器。而你叫来兄弟俩，问清楚他们各自是怎么做的。通过这种方法，你完成了任务。为了保证兄弟俩没有相互串通，你还故意在告诉弟弟每户人的住址时，故意说错一点，也就是给数据增加了一些误差，通过这样的方式，你可以确保兄弟俩是学到了数据中真实的规律，而不只是鹦鹉学舌。&lt;/p&gt;

&lt;p&gt;总结一下，数据降维是拿到高纬度数据后，不可不做的一件事，其既可以用来探索数据的结构，比如做聚类，又可以用来去找出数据中质量不好的离群点，数据降维的方式很多，最常用的是PCA及其衍生改进方法，以及相比PCA慢的多但也强大的多的tsne，另外还有来自神经网络的自编码器。这些方法可以结合起来使用，比如将一个10维的数据先用PCA降成5维，再用tsne降低成2维，这样兼顾的计算耗时和准确度。&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdELMqvjP6J8kM6RDh7vCSl5ApQPrl6wTwJCAwmZiaOEibBpuwibc2V7xFm2VgpKdLvhk0w7Iu9UicZGg/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-backw=&quot;239&quot; data-backh=&quot;136&quot; data-croporisrc=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdELMqvjP6J8kM6RDh7vCSlxdZg5QsD5SbWSMyveUovrXJdyJa83UFiaoy7zKQ4tEr5quMvojMrckw/0?wx_fmt=png&quot; data-cropx1=&quot;0&quot; data-cropx2=&quot;239&quot; data-cropy1=&quot;38.687050359712224&quot; data-cropy2=&quot;135.8345323741007&quot; data-ratio=&quot;0.4100418410041841&quot; data-w=&quot;239&quot; /&gt;&lt;/p&gt;

&lt;p&gt;扩展阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383161&amp;amp;idx=1&amp;amp;sn=b27c2a0686d57b13daadcfd16cb35dac&amp;amp;chksm=84f3cb38b384422ecfca55da7b54978a8f3742605549566920507d5e032e16da1be50c1f5f97&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;你需要的深度学习数学基础： 从入门到进阶&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;


&lt;p&gt;以下的内容不适合小学生哦，一个是R语言中对应的包，而是一些测试题，测试你对这篇小文的理解。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdELMqvjP6J8kM6RDh7vCSlicMrpaVDKNMrYPHn8vxKubz4pO5ZhsS9k0cxxCiaIWkjgF6wLzEHfaog/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.5093240093240093&quot; data-w=&quot;858&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面是想深入了解的读者可以回答的一些问题，前四提单选，后两题多选。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdELMqvjP6J8kM6RDh7vCSllqCnCcA6uAjibdRho0DQQJibxdvicBib4fT3tUm3iahWichdUNOzxGyHj0iaw/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;1.0521042084168337&quot; data-w=&quot;499&quot; data-backw=&quot;499&quot; data-backh=&quot;525&quot; /&gt;&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;欢迎关注&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382937&amp;amp;idx=1&amp;amp;sn=d4510592a837c44fe75393c2578698d8&amp;amp;chksm=84f3cad8b38443ce6adcd155a2c45ee7707b4a9d8e48c05728aa7e93862475832bf89617025f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;巡洋舰的深度学习实战课程&lt;/a&gt;， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛， 感兴趣的小伙伴可以点击阅读原文。&lt;/strong&gt;&lt;/p&gt;


</description>
<pubDate>Mon, 27 Nov 2017 19:06:34 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/tfYe8PS62H</dc:identifier>
</item>
<item>
<title>【今日直播】《深度学习图像风格迁移》</title>
<link>http://www.jintiankansha.me/t/FbJC2j9Dum</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/FbJC2j9Dum</guid>
<description>&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.7786666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/EribroYqw9eBkHbybwibTB3slfmZcro69Y6UTMbFoa7jRoAo2ric1GSIicxNicUXdsiaz9FRTD3MCqJbrsm2XUebd0oQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;【上课方式】&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;手机端APP：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;万门大学&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/EribroYqw9eBkHbybwibTB3slfmZcro69YdtpZ7Fl4NOPP3ExqjAbicibicibpt86n3FJbGyWDfZ7SX3xB3zl2dqPF6g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;400&quot; width=&quot;129px&quot; /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;电脑网页版：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;www.wanmen.org&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;注册&amp;amp;登录万门账号&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;搜索课程名 &lt;/span&gt;&lt;span&gt;深度学习图像风格迁移&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;课程页面点击&lt;span&gt;我要报名&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;报名后，进入&lt;/span&gt;&lt;span&gt;个人中心&lt;span&gt;—&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;我的课程&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;检查是否有此课程，确认是否报名成功&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;【进群交流】&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;私信小万君&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;留言 &lt;span&gt;图像风格迁移&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;邀请您进入课程交流群&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;直播过程中可与老师互动～&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;【直播时间】&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;明日 （11月26日）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;16:20-17:00&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;《人工智能、大数据与复杂系统》概论课程，点击【&lt;span&gt;阅读原文&lt;/span&gt;】免费学习&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Sun, 26 Nov 2017 06:35:15 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/FbJC2j9Dum</dc:identifier>
</item>
<item>
<title>多余的话 借深度网络说说最近发生的几件事</title>
<link>http://www.jintiankansha.me/t/i6XlKO9l9h</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/i6XlKO9l9h</guid>
<description>&lt;p&gt;关于刘鑫的事情，我曾经写过一篇明知道不讨喜会找骂的小文-&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383146&amp;amp;idx=1&amp;amp;sn=052ca08472d6e71c1343266ef6dacfbc&amp;amp;chksm=84f3cb2bb384423d04dc390a568db078d4d5abd8ecd283cd30ac8bbd50179daa00a4542d2e82&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;Do not pity the dead. Pity the living&lt;/a&gt;，写的是关于这件事有关的一些我觉得有关系的格言。将这些格言组织成一篇有论据，更重要的是有观点，也注定会更讨喜的文， 对我来说一点不难。但我从来都不是为了讨读者的喜欢而写作的，有没有人来读，我根本不care，也别给我说什么媒体和个人写作的区别，都不过只是一个说人话的地方。我在乎的只是我在写作的时候是否有所提高，永远都是写给一俩个人的。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;记得曾经的孙志刚还是小悦悦的事件，当年我一个要好的朋友因为这件事很生气，很难受，哭着对我说这世界怎么这样，我不知怎么去安慰。就陪着一起读书，一起查资料，想象我们要为这件事做一期访谈类的节目，类似铿锵三人行吧，我们查了很多的书，比如路西法效应等社会心理学的研究，还有小说和影视作品中的话，以及哲学家关于正义的讨论，后来我们终于不那么生气了。&lt;/p&gt;

&lt;p&gt;如今又是一件令我们哭不出声音的事情出现。我觉得关于这件事，是该写点什么的，我喜欢写写新奇的角度，那就按照我熟悉的写起吧。最近看到一个微课，名字是阿尔法元100：0完爆阿尔法狗的给人类的三个启示，说的是人类可以从深度神经网络的架构中能学到些什么。那就照猫画虎，说说从深度学习的角度来看，三颜色这件事该怎么去看。我这里会少谈时事，多讲技术。&lt;/p&gt;

&lt;p&gt;所谓学龄前教育，就如同神经网络的参数初始化。任何一个有过实战经验的人，都知道参数初始化的重要性。不止会影响模型收敛的速率，也就是需要花更多的时间，才能够找到一个相对好的解，还会影响模型的泛化能力。举一个极端的例子，如果你对模型初始的参数都设置为一样的值，例如0，那么神经网络就变成了一个确定性的模型，也就是无法在之后的训练数据中，无法学到任何需要用到概率的判断。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;那么该怎么对神经网络的参数进行初始化了，常用的有俩种方法，一种是随机给每个权重一个符合均匀分布的数字，比如拿一个公平的骰子，从1到6的数字随机之中选一个。第二种方法是给这些权重随机选择一个符合正态分布，平均为0的数。我没有尝试过，如果给参数初始化时，随机给他们分配一个符合尾巴很肥的幂律分布的随机数会是怎样。可以推算下，对于那些被随机分配到初始权重接近负无穷的点，也许这些点的权重很难通过训练回到他们应有的样子了，这不是稀疏编码，让训练好的神经元随机的失联，而是从一开始就将这些信息丢掉。就假设我们是训练识别猫狗图像的神经网络吧，这意味着有些时候，我们的神经网络会怎么都认不出图中的动物的耳朵在那里，也许缺少了耳朵形状这一个特征，对网络整体的影响并不大。但正如在雪崩时，没有一片雪花是无辜的。但凡涌现的系统，每一个输入的信号，都可能成为那影响飓风的蝴蝶之翼。&lt;/p&gt;

&lt;p&gt;接着来说说深度学习的深。为什么深度学习的神经网络需要那么多层了？这个问题的答案，我最初的回答是因为局部感知，也就是先只看整体图景的一个局部，正因为你限制了自己的任务，从而使得你能够更准确的完成你的任务，正如经济学中讲的分工带来效率的突飞猛进，如果每一个辨别能力不那么强的神经元，可以通过较少的训练就能够很好的完成需要整合局部信息的任务，那么通过层次化的管理，例如深度学习中的KPI--交叉熵，那么就可以聚沙成塔，完成复杂的信息整合。&lt;/p&gt;

&lt;p&gt;但是后来的我回答这个问题，却会说为什么深度学习需要这么多层，是因为每层的神经元都需要做到权值共享。所谓weight sharing，就是让神经元们有一套普世的价值观，这不止对加快网络的收敛，提高训练的速度很重要，更可以增加模型的泛化能力。若没有了权值共享，那么你以为你身边的人和你有一样的价值观，等到不知什么时候却发现那么对那些你以为天经地义的事情，你们都有着不同的观点，这时你就会发现，网络的深度变得没有多少意义，因为你无法根据自己身处的环境，判定你处于网络中的那一层。&lt;/p&gt;

&lt;p&gt;所以我觉得权重共享是比dropout更应该向所有人普及的一个概念，dropout说的是在面对不确定的未来时，通过小的可控的失败来避免大错误，类似反脆弱的概念，而权重共享却关系到我们每一个人该怎么去交流，关于权重共享，我曾写过一篇文 &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382656&amp;amp;idx=1&amp;amp;sn=cf461c00d2af8b1cf1afeb2c5622aa47&amp;amp;chksm=84f3cdc1b38444d75ba2f93162acab88141e0887f9a04e6cef80cfd4591e7d56d963c2ebf131&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;从深度学习中的weight sharing说说共同价值观&lt;/a&gt;，可以参考。&lt;/p&gt;

&lt;p&gt;接着说一说深度学习中最大的魔鬼，也就是梯度消失和梯度爆炸。先说梯度消失，今天公众号李松蔚发了一篇文&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA4NTI3NTkyNQ==&amp;amp;mid=2654002999&amp;amp;idx=1&amp;amp;sn=1695e3987dc94252a429790c900aa7af&amp;amp;chksm=841e1b4db369925b83a2d0a997fad15b8ff9c2d9152fc754d8b465dc883b638c895cb5f7a9bb&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;不只是被虐的孩子，整个社会都应激障碍了&lt;/a&gt;，我觉得应激障碍这个词，很形象的说了梯度爆炸是什么。由错误驱动的学习是一层一层进行的，但学习的过程中使用的信号是上一层错误的偏导数，偏导数是只关注变化的，在一层层的信号传递链，变化被放大，也许只是一件小事，但就如同玩电话传消息的孩子，会将原本的信息扭曲，从而使得即使网络本来有很多层，但深度越深，得到的反馈越少。&lt;/p&gt;

&lt;p&gt;只关注变化，这很想《怪诞行为学》中描述的锚定效应，更概括的来说，是人的情绪，就是这样一个短时的偏导运算符，只关注相比别人，你得到了多少。当上海廉价的幼儿园和北京的高价幼儿园依次出事，社会作为一个整体由不得会反应过度。情绪的链式传递，导致了更为关键的信息被忽视，比如长期以来对基础教育尤其是幼儿教育的投入不和法律缺失。不要以为找到了幕后的黑手，就算是深度的思考了。面对每一个都可能会切身面对的社会问题，每一个人都需要拿出创业者的激情来。既然现在幼师的准入门槛还没有明确的规定，以剔除那些本身不喜欢小孩的人，那么能不能通过社交网络中留下的痕迹，通过APP中的行为测试，去识别你孩子的幼儿园老师是不是喜欢孩子。&lt;/p&gt;

&lt;p&gt;接着说说梯度消失对应的梯度消失。这里可以看六神磊磊今天发的文 &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA4NDEzNTMyMA==&amp;amp;mid=2650316540&amp;amp;idx=2&amp;amp;sn=5e0bb1af48ae7bd1aeafb294f3c587f5&amp;amp;chksm=87e7e20bb0906b1dee12267f6e7c2f876a82c7bd5df2b6f6eba7a48061f9a28c2b0b1593b5dc&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;没有中间层的结果，就是直面下层的火力&lt;/a&gt;。我们常说米国这二十年来中产阶级消失了，对应到深度学习中，这个问题就是梯度消失。消失的中层，使得哪怕预先优化好的网络结构变成了一张白纸，制度不管用了。&lt;/p&gt;

&lt;p&gt;吵闹但无序的底层无法和自以为国师的精英上层对话。你说你拆除违章建筑，是合法合规，就理应如此。而他们则说着要生存，说着自己的孩子已经受了多少不平等的对待。然而若是送快递的小哥和收快递的白领之间能够说几句贴心话，那么这些白领也许能够写出带着感情的文章，写成内参，让更上层的决策者知道自己的每一个决策究竟对于活生生的人意味着什么，那信息的传递就不算脱节。然而若是收快递的白领也人人自危，觉得自己不过是长的肥一些的韭菜，那么我们就说梯度消失了，模型中离输出层越远，能学到的东西越少。&lt;/p&gt;

&lt;p&gt;任何社会运都行在一个变化无穷的环境中，整个社会可以看成是一个需要不断优化的神经网络。而面对复杂的环境，本来深层的网络是能够相对更好的应对的。然而，正如做科普的童鞋常常觉得为什么科普这么难，不靠谱的养生神帖那么多。本质的原因不是科普文写的不好，而是由于要学习的网络太深了，而在向中间层的传递过程中，出现了梯度消失。&lt;/p&gt;

&lt;p&gt;而解决梯度消失或者梯度下降的一个常用方法，就是批量正则化（batch normalization），也就是在每一层的时候，都对要传递的信号进行一下平移和拉伸，使得他们呈现为平均值为0，符合高斯分布的一组变量。通过批量正则化，网络的每一层都会拿到分布的相似一组信号，这样做的好处是让网络学的更快，同时缓解了梯度消失/爆炸的问题，如果你得到的初始信号不包含上一层的偏见，那么你学习中也没有偏见可以放大或者忽视。&lt;/p&gt;

&lt;p&gt;而这需要在神经网络的每一层之间，加上一个专门正则化的处理层。而这正是媒体在一个成熟的社会里应做的事。好的媒体不是1984，那对应的是梯度消失，或者是美丽新世界，那对应的是梯度爆炸。好的媒体用每一层能够听懂的话，去克制的说出，更多的时候是一遍遍的复述普遍共享的价值观和事实。就如同精准饮食，针对每一层的文化背景，去说他们能听懂的话，去讲他们愿意听的故事。&lt;/p&gt;

&lt;p&gt;人人都能发声的时代，如果你只是表示情绪，那么你也许贡献的更多是噪音，若你只是想获得关注，那么你传递的更多是别人想要的而不是别人真的需要的，写任何文，我总觉得要做的既是不得不写，又清楚知道自己写的不过是篇多余的话，才算是为自己而写。古之学者为己 今之学者为人，不可不戒。&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383146&amp;amp;idx=1&amp;amp;sn=052ca08472d6e71c1343266ef6dacfbc&amp;amp;chksm=84f3cb2bb384423d04dc390a568db078d4d5abd8ecd283cd30ac8bbd50179daa00a4542d2e82&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;Do not pity the dead. Pity the living&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383124&amp;amp;idx=1&amp;amp;sn=80b21ed5c144027b12388abf85c7dccb&amp;amp;chksm=84f3cb15b38442034b620347e8530958e53546d377e990c5a4c8bd111a3238be44926496b57b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;人的价值在于提问-读《Human are underrated》&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

</description>
<pubDate>Sat, 25 Nov 2017 12:05:41 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/i6XlKO9l9h</dc:identifier>
</item>
<item>
<title>你需要的深度学习数学基础： 从入门到进阶</title>
<link>http://www.jintiankansha.me/t/j3MuNyjiAa</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/j3MuNyjiAa</guid>
<description>&lt;p&gt;&lt;span data-offset-key=&quot;mgnb-0-0&quot;&gt;&lt;strong&gt;本文为&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382937&amp;amp;idx=1&amp;amp;sn=d4510592a837c44fe75393c2578698d8&amp;amp;chksm=84f3cad8b38443ce6adcd155a2c45ee7707b4a9d8e48c05728aa7e93862475832bf89617025f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;巡洋舰的深度学习实战课程&lt;/a&gt;数学预科准备。 &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;mgnb-0-0&quot;&gt;打开深度学习， 对于大部分小白， 编程已然令人生畏， 而更加令人难以接受的，那么，深度学习里的数学到底难在哪里？ 寻常人等又有如何路径走通， 请听铁哥慢慢解析。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUOic3LicwjTEXpo0GY2dIJibqouwicgjibbIm6TMLf8AVoFKeYGSkRuASTHsg/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.48272552783109407&quot; data-w=&quot;1042&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;4tb26-0-0&quot;&gt;线性代数： &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4tb26-0-0&quot;&gt;想要学习深度学习， 你第一个需要理解透彻的学问是&lt;strong&gt;线性代数&lt;/strong&gt;。 为什么？ 因为深度学习的根本思想就是把任何事物转化成高维空间的向量， 强大无比的神经网络， 说来归齐就是无数的矩阵运算和简单的非线性变换的结合。 这样把图像啊， 声音啊这类的原始数据一层层转化为我们数学上说的向量。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;什么image to vector， word to vector 这些， 都在说的一件事情就是这类数学转化， 不同类型（我们通常称为非结构化数据）的数据最终成为数学上不可区分的高维空间的向量，所谓万类归宗。 线性代数，就是对于这一类高维空间运算做的默认操作模式，可谓上帝的魔术之手。 &lt;/p&gt;

&lt;p&gt;因此你要驾驶深度学习这个跑车， 线性代数关系你到是否理解发动机的原理。&lt;/p&gt;

&lt;p&gt;线性代数核心需要掌握的是线性空间的概念和矩阵的各项基本运算，对于线性组合， 线性空间的各类概念， &lt;strong&gt;矩阵&lt;/strong&gt;的各种基本运算， 矩阵的正定和&lt;strong&gt;特征值&lt;/strong&gt;等等都要有非常深厚的功力。 &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;概率论： &lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dr7ka-0-0&quot;&gt;下一个我们需要讲解的是什么呢？ &lt;strong&gt;概率论&lt;/strong&gt;基础 。 概率论事整个机器学习和深度学习的语言 ， 因为无论是深度学习还是机器学习所做的事情是均是预测未知。 预测未知你就一定要对付不确定性。 整个人类对不确定性的描述都包含在了概率论里面。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dr7ka-0-0&quot;&gt;概率论你首先要知道的是关于概率来自频率主义和贝叶斯主义的观点， 然后你要了解概率空间这一描述描述不确定事件的工具， 在此基础上， 熟练掌握各类分布函数描述不同的不确定性。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dr7ka-0-0&quot;&gt; 我们最常用的分布函数是高斯， 但是你会发现高斯是数学书里的理想， 而&lt;/span&gt;真实世界的数据， 指数分布和幂函数分布也很重要， 不同的分布对机器学习和深度学习的过程会有重要的影响，比如它们影响我们对目标函数和正则方法的设定。懂得了这些操作， 会对你解决一些竞赛或实战里很难搞定的corner case大有裨益。 &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5fo8r-0-0&quot;&gt;一个于概率论非常相关的领域&lt;strong&gt;-信息论&lt;/strong&gt;也是深度学习的必要模块，理解信息论里关于熵，条件熵， 交叉熵的理论， 有助于帮助我们了解机器学习和深度学习的目标函数的设计， 比如交叉熵为什么会是各类分类问题的基础。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;5fo8r-0-0&quot;&gt;微积分： &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bq2c-0-0&quot;&gt;微积分和相关的优化理论算是第三个重要的模块吧，线性代数和概率论可以称得上是深度学习的语言，那微积分和相关的优化理论就是工具了。  深度学习， 用层层迭代的深度网络对非结构数据进行抽象表征， 这不是平白过来的，这是优化出来的，用比较通俗的话说就是调参。 整个调参的基础，都在于优化理论， 而这又是以多元微积分理论为基础的。这就是学习微积分也很重要的根源。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;bq2c-0-0&quot;&gt;优化理论： &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bq2c-0-0&quot;&gt;机器学习里的优化问题，往往是有约束条件的优化，所谓带着镣铐的起舞 ， 因此拉格朗日乘子法就成了你逃不过的魔咒。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bq2c-0-0&quot;&gt;优化理论包含一阶和二阶优化，传统优化理论最核心的是牛顿法和拟牛顿法。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bq2c-0-0&quot;&gt;由于机器学习本身的一个重要内容是正则化，优化问题立刻转化为了一个受限优化问题。这一类的问题，在机器学习里通常要由拉格朗日乘子法解决。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;传统模型往往遵循奥卡姆剃刀的最简化原理，能不复杂就不复杂。 &lt;strong&gt;而深度学习与传统统计模型的设计理念区别一个本质区别在于，深度模型在初始阶段赋予模型足够大的复杂度&lt;/strong&gt;，让模型能够适应复杂的场合，而通过加入与问题本身密切相关的约束： 例如全职共享，和一些通用的正则化方法：例如dropout， 减少过拟合的风险。 &lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5h3b-0-0&quot;&gt; 而正因为这种复杂度， 使得优化变得更加困难，主要由于： &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5h3b-0-0&quot;&gt;1， &lt;strong&gt;维度灾难&lt;/strong&gt;， 深度学习动辄需要调整几百万的参数，是一个计算量超大的问题。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;2， &lt;strong&gt;目标函数非凸&lt;/strong&gt;， 具有众多的鞍点和极小值。 我们无法直接应用牛顿法等凸优化中的常见方法，而一般用到一阶优化（梯度下降），这看起来是比支持向量机里的二阶优化简单，然而正是因为缺乏很好的系统理论， 边角case变得特别多，反而最终更难。&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5h3b-0-0&quot;&gt;3， &lt;strong&gt;深度&lt;/strong&gt;， 由于深，造成反向传播的梯度往往越来越弱， 而造成梯度消失问题。 &lt;/span&gt;各类深度学习的领先算法往往是围绕解决梯度消失问题。 &lt;/p&gt;

&lt;p&gt;&lt;img data-type=&quot;gif&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUOHYPYO0IS40T4ianPe2txtibXsg3IXgLNMsx0KlIo3swCUvQJQYKiav0lw/0?wx_fmt=gif&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.622680412371134&quot; data-w=&quot;485&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;5h3b-0-0&quot;&gt;图： 臭名昭著的局部极小值问题。 &lt;br /&gt;&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;6d768-0-0&quot;&gt;我们用一些非常简单的实例说一下深度学习的几个主要应用方向与数学的结合：&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;1ldau-0-0&quot;&gt;阶段1&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;1ldau-0-0&quot;&gt;：  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1ldau-0-0&quot;&gt;多层神经网络（DNN）的前传与回传（BP）算法 。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dr1rf-0-0&quot;&gt;理解DNN的前向传递过程， 这个过程里包含了线性代数的空间变换思想和简单的高数。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;f8mha-0-0&quot;&gt;这算是第一难度梯级， 你需要掌握的是BP算法， 这里含有多元微积分一个最基本的法则： 链式求导和jacobian矩阵。  在此处你会对维度产生全新的认识。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUO5Yuyvgrvx25yyKTEPyuaYqS6ZUtcLpSR0QUYMQuUYUQrXdmgtkFiaQg/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.734020618556701&quot; data-w=&quot;485&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;609l5-0-0&quot;&gt;阶段2&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;609l5-0-0&quot;&gt;：  　&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;609l5-0-0&quot;&gt;深度学习的中流砥柱CNN卷积运算 ： 这里应用的数学是卷积本身， 你要通过高数掌握卷积的本质， 体会它与相关性， 傅立叶变换等运算之间的联系。 这部分也属于高数内容， 而卷积运算本身也需要强大的线性代数基础。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUO4kibA85lQR0Kewzj8PJic338A7E14QkmsIfuDsSQkSk1X7cBgsPJLbDg/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.771551724137931&quot; data-w=&quot;464&quot; /&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;b3epo-0-0&quot;&gt;阶段3：　&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;b3epo-0-0&quot;&gt;RNN网络与微分方程。RNN似乎包含比别家算法多很多的数学知识，因为RNN的运算和调参你需要理解一些非线性动力系统的基础知识。如定点，边缘稳定性和混沌。非线性动力学是物理的内容， 但是大部分讲的是数学， 这点物理系的学的会很有优势。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUOxW5MMMg9CnD4E6928FC6pKib1zbWVJLYIsPYalvMvdBicib2FCg7TJy7g/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.44642857142857145&quot; data-w=&quot;336&quot; data-backw=&quot;336&quot; data-backh=&quot;150&quot; /&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;cc74-0-0&quot;&gt;阶段４：&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;cc74-0-0&quot;&gt;　&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;cc74-0-0&quot;&gt;深度强化学习。 这时候你的数学工具要包含bellaman 方程，控制论的一些基础知识，更多关于马尔可夫过程和时间序列的知识。简单的控制论你看看会很好的助力你对整个机器学习用于机器人控制的理解，而马尔科夫决策树的基础知识学了你会觉得什么阿尔法狗阿尔法元都挺简单的。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUOoBgbTec5jCqdwTricnp1LSeBe4MYObJnLcTg3aCypj1JkV9Hy7QArHw/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.335625&quot; data-w=&quot;1600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;76lem-0-0&quot;&gt;阶段5：　&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;76lem-0-0&quot;&gt;生成式模型与GAN对抗网络。这部分的数学难度应该与深度强化学习在同一难度上。　需要对概率论有比较深的理解。 最基础的生成模型你要理解玻尔兹曼机这个与统计物理渊源很深的模型，需要较深的概率统计知识。 GAN生成对抗模型的目标函数含有了大名鼎鼎的博弈论思想。纳什均衡都进来了啊， 虽然这时候的优化理论已经飞一样的难， 你还是会有一种融汇贯通的感觉。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUO2seqfyC8Xy0R7aeY8OTfXjFuYciaaeB8MwqbvUmGbHHn4cNLvedHfmQ/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.48297213622291024&quot; data-w=&quot;323&quot; data-backw=&quot;323&quot; data-backh=&quot;156&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;76lem-0-0&quot;&gt;阶段6：&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;76lem-0-0&quot;&gt;   &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;76lem-0-0&quot;&gt;信息瓶颈理论？  计算神经科学前沿？ 铁哥恭喜你此处要告别尘缘了。  深度学习的尽头必然要与我们对认知和信息本质的基础认识相连。 此处针对希望做深度学习研究的人员。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUOO17N3ibUgy7JZa4xOvRuOtnoGGun7ic0OKsrJmxwhicJtickcDqTvw5iatg/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.5&quot; data-w=&quot;696&quot; /&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;8rdun-0-0&quot;&gt;基础教材推荐：  &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;陈希孺院士的&lt;strong&gt;《概率论与数理统计》&lt;/strong&gt;，这是一本数理统计的入门级教材。最好的统计中文教材。参考评论&lt;span class=&quot;Apple-converted-space&quot;&gt; &lt;/span&gt;https://d.cosx.org/d/14990-14990&lt;/p&gt;

&lt;p&gt;龚升的&lt;strong&gt;《简明微积分》&lt;/strong&gt;。这本教材是我见过的最与众不同的写作结构，不是按常规教材那样讲导数、微分、微分的应用然后是不定积分、定积分。如果觉得难， 入门从同济大学的微积分教材入手也不错。&lt;/p&gt;

&lt;p&gt;线性代数：&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;Introduction to Linear Algebra   &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Gilbert Strang） MIT的教授，网上还有视频。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;482sr-0-0&quot;&gt;&lt;strong&gt;如果你对上面的脑洞感兴趣，&lt;/strong&gt;&lt;strong&gt;欢迎关注&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382937&amp;amp;idx=1&amp;amp;sn=d4510592a837c44fe75393c2578698d8&amp;amp;chksm=84f3cad8b38443ce6adcd155a2c45ee7707b4a9d8e48c05728aa7e93862475832bf89617025f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;巡洋舰的深度学习实战课程&lt;/a&gt;， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛， 感兴趣的小伙伴可以点击阅读原文。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;










</description>
<pubDate>Tue, 21 Nov 2017 15:40:39 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/j3MuNyjiAa</dc:identifier>
</item>
</channel>
</rss>