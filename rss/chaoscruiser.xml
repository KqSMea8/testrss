<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>用R语言实现深度学习情感分析例子</title>
<link>http://www.jintiankansha.me/t/LMMxn2nEDp</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/LMMxn2nEDp</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者介绍：&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;黄升&lt;/strong&gt;，普兰金融数据分析师，从事数据分析相关工作，擅长R语言，热爱统计和挖掘建模。&lt;/p&gt;


&lt;p&gt;&lt;span&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;到了2018新的一年。18岁虽然没有成为TF-boys，但是2018新的一年可以成为TF（Tensorflow-boys）啊~~&lt;/p&gt;
&lt;h3&gt;word embeddings介绍&lt;/h3&gt;
&lt;p&gt;      之前建立的情感分类的模型都是Bag of words方法，&lt;span&gt;&lt;strong&gt;仅仅统计词出现的次数&lt;/strong&gt;&lt;/span&gt;这种方法破坏了句子的结构。这样的结构，我们也可以使用如下的向量（one hot 编码）表示句子「The cat sat on the mat」：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5011494252873563&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPaVqEwmr79eOyMfOUutFxLaXe5RKPLObjHpmbTiaXtwialQibicicMGOzgfA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;435&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      然而，在实际应用中，我们希望学习模型能够在词汇量很大（10,000 字以上）的情况下进行学习。从这里能看到&lt;span&gt;&lt;strong&gt;使用「独热码」表示单词的效率问题&lt;/strong&gt;&lt;/span&gt;——对这些词汇建模的任何神经网络的输入层至少都有 17000,000 个节点。因此，我们需要使用&lt;span&gt;&lt;strong&gt;更高效的方法&lt;/strong&gt;&lt;/span&gt;表示文本数据，而这种方法不仅可以保存单词的上下文的信息，而且可以在更低的维度上表示。这是 &lt;span&gt;&lt;strong&gt;word embeddings 方法&lt;/strong&gt;&lt;/span&gt;发明的初衷。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.0586510263929618&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPueCErIy2T4I5IfwoNsJmdlYD5cw0aTicrZYC1OnnY7tJTGx4u6I3lDQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;341&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      word embeddings就是&lt;span&gt;&lt;strong&gt;将一个个词映射到低维连续向量&lt;/strong&gt;&lt;/span&gt;(如下图所示) ：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.4393939393939394&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccP99flmtqZiaMWhHMPGfY6WmQh8dSUicuk1jZKO2Qm9s5S1mj1hRoyvbBQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;264&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      这种向量的思想就是将相似的词映射到相似方向，所以，语义相似性就可以被编码了。相似性一般可以通过&lt;span&gt;&lt;strong&gt;余弦相似度来衡量&lt;/strong&gt;&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9490616621983914&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPQqNJpOPcx1UF8Bu7rMiaPhljHp46jSJF5VokPRokiaWPvOHbMYY11TgQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;373&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;安装TensorFlow和Keras&lt;/h3&gt;
&lt;pre readability=&quot;4.5&quot;&gt;
&lt;code class=&quot;&quot; readability=&quot;3&quot;&gt;&lt;span class=&quot;&quot;&gt;# 安装并加载Keras包&lt;br /&gt;&lt;/span&gt;install.packages(&lt;span class=&quot;&quot;&gt;&quot;devtools&quot;&lt;/span&gt;)
devtools::install_github(&lt;span class=&quot;&quot;&gt;&quot;rstudio/keras&quot;&lt;/span&gt;)
install_keras()&lt;span class=&quot;&quot;&gt;library&lt;/span&gt;(keras)&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;
&lt;span class=&quot;&quot;&gt;# 安装并加载TensorFlow包&lt;br /&gt;&lt;/span&gt;devtools::install_github(&lt;span class=&quot;&quot;&gt;&quot;rstudio/tensorflow&quot;&lt;/span&gt;)&lt;span class=&quot;&quot;&gt;library&lt;/span&gt;(tensorflow)
install_tensorflow()&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;      &lt;span&gt;&lt;strong&gt;注&lt;/strong&gt;&lt;/span&gt;：安装TensorFlow和Keras前需要安装Anaconda，Anaconda尽量装最新版本的，Anaconda在Windows安装有一些坑，我是把Java环境删掉还有使用默认路径才成功安装了Anaconda。&lt;/p&gt;
&lt;h3&gt;检测是否安装成功&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;&quot;&gt;&lt;span class=&quot;&quot;&gt;# 输入下面代码&lt;br /&gt;&lt;/span&gt;sess = tf$Session()
hello 'Hello, TensorFlow!')
sess$run(hello)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;OK,如果没有问题的话，你的结果也将是如上图所示，则表明你已安装成功。&lt;/p&gt;
&lt;h3&gt;LSTM原理&lt;/h3&gt;
&lt;p&gt;      &lt;span&gt;&lt;strong&gt;长短期记忆网络&lt;/strong&gt;&lt;/span&gt;——通常简称“LSTMs”，是一种特殊的RNN，能够学习长期依赖关系，它可以桥接超过1000步的时间间隔的信息。LSTM由Hochreiter和Schmidhuber （1997）提出，在后期工作中又由许多人进行了调整和普及（除了原始作者之外，许多人为现代LSTM做出了贡献）。LSTM在各种各样的问题上工作非常好，现在被广泛使用。&lt;/p&gt;
&lt;p&gt;      LSTMs被设计出来是&lt;span&gt;&lt;strong&gt;为了避免长期的依赖性问题，记忆长时间的信息实际上是他们的固有行为&lt;/strong&gt;&lt;/span&gt;，而不是去学习，这点和传统的具有强大的表征学习能力的深度神经网络不同。&lt;/p&gt;
&lt;p&gt;      所有的RNNs（包括LSTM）都具有一连串重复神经网络模块的形式。在标准的RNNs中，这种重复模块有一种非常简单的结构，比如单个tanh层：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.448512585812357&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPAEg8bvV0OU0gKWZhloPBvPleuYTOB4sYLoGJIr60HIibRCqrCxxPVJA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;437&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      &lt;span&gt;&lt;strong&gt;什么是tanh？&lt;/strong&gt;&lt;/span&gt;中文叫双曲正切函数，属于神经网络隐藏层的activation function（激活函数）中的一种。别以为是什么好厉害的东西，其实就是一个简单的以原点对称的值域为[-1,1]的非线性函数。而神经网络中比较常见的另外一个激活函数 &lt;span&gt;&lt;strong&gt;sigmoid 函数&lt;/strong&gt;&lt;/span&gt;，则不过是把tanh函数往上平移到[0，1]的区间，这个函数在LSTM也会用到。&lt;/p&gt;
&lt;p&gt;      LSTM也有像RNN这样的链式结构，只不过重复模块有着与传统的RNN不同的结构，比传统的RNN复杂不少：不只是有一个神经网络层，而是有四个神经网络层，以一个非常特殊的方式进行交互。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.41935483870967744&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPVS0u2s7fxjJJC53FT0UhhF3CWcgJBIKPBFXxNHRVsL6l8YfTPZ16TA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;434&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      不用担心看不懂细节部分是什么意思，稍后我们将逐步浏览LSTM图。现在，让我们试着去熟悉我们将要使用的符号。&lt;/p&gt;
&lt;p&gt;      在上面所示的图中，我们对以上符号进行如下定义：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2361111111111111&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccP67x2JWmNtgedWsn2hXtt5SJM9QytuErf5CibhUnh6JyZYicUibTwRFnNg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;432&quot; /&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;黄块表示学习神经网络层（tanh层或sigmoid层）；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;粉色圆圈表示按位操作，如向量加法或者向量点乘；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;每条线代表着一整个向量（vector），用来表示从一个节点的输出到另一个节点的输入；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;合并的线代表连接或者说是拼接;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;分叉表示其内容被复制，复制内容将转到不同的位置&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;LSTMs背后的核心理念&lt;/h3&gt;
&lt;p&gt;      LSTMs的关键是细胞状态（cell state），是一条水平线，贯穿图的顶部。而Cell 的状态就像是传送带，它的状态会沿着整条链条传送，而只有少数地方有一些线性交互。&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.4585987261146497&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccP0QAlicLqwOQYOibpbOjc5OXbAPRoibDEhlr4graFY9rhVNTiblUmPiapaHw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;314&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      因此“门”就是LSTM控制信息通过的方式，这里的&lt;span&gt;&lt;strong&gt;” σ “&lt;/strong&gt;&lt;/span&gt; 指的是 sigmoid 函数。Sigmoid 层的输出值在 0 到 1 间，表示每个部分所通过的信息。&lt;span&gt;&lt;strong&gt;“0” 意味&lt;/strong&gt;&lt;/span&gt;着“让任何事情无法通过”或者说成”忘记所有的事“；&lt;span&gt;&lt;strong&gt;“ 1 ”意味&lt;/strong&gt;&lt;/span&gt;着”让一切都通过！“ 或者说”我要记住这一切! “&lt;/p&gt;
&lt;p&gt;      一个 LSTM 有三个这样的门，分别是“输入门”、遗忘门“和 ”输出门“，在单一模块里面控制 cell 的状态。&lt;/p&gt;
&lt;p&gt;      首先，LSTM 的第一步就是让信息通过”遗忘门“，&lt;span&gt;&lt;strong&gt;决定需要从 cell 中忘掉哪些信息&lt;/strong&gt;&lt;/span&gt;。它的输入是 ht-1 和 xt。另外，我们之所以使用sigmoid激活函数是因为我们所需要的数字介于0至1之间。Ct−1 就是每个在 cell 中所有在 0 和 1 之间的数值，就像我们刚刚所说的，0 代表全抛弃，1 代表全保留。&lt;/p&gt;
&lt;p&gt;      看到这里应该有朋友会&lt;span&gt;&lt;strong&gt;问什么是ht&lt;/strong&gt;&lt;/span&gt;，ht是LSTM层在t时刻的输出，但不是最终的输出，ht仅仅是LSTM层输出的向量，要想得到最终的结果&lt;span&gt;&lt;strong&gt;还要连接一个softmax层&lt;/strong&gt;&lt;/span&gt;（sigmoid函数的输出是”0“”1“，但是使用softmax函数能在三个类别以上的时候输出相应的概率以解决多分类问题），而x就是我们的输入，是一个又一个的词语。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.41766109785202865&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccP6IRWK69v1hcsHLSCJFmtMTug4bYy2oHR2UajXoFgOOLric2UPw0tpLQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;419&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      下一步，我们需要&lt;span&gt;&lt;strong&gt;决定什么样的信息应该被存储起来&lt;/strong&gt;&lt;/span&gt;。这个过程主要分两步。&lt;span&gt;&lt;strong&gt;首先是 sigmoid 层&lt;/strong&gt;&lt;/span&gt;（这就是“输入门”）决定我们需要更新哪些值；&lt;span&gt;&lt;strong&gt;随后，&lt;/strong&gt;&lt;strong&gt;tanh 层&lt;/strong&gt;&lt;/span&gt;生成了一个新的“候选添加记忆” C`t，&lt;span&gt;&lt;strong&gt;最后，我们将这两个值结合起来&lt;/strong&gt;&lt;/span&gt;。结合后能够加入cell的状态（长期记忆）中。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.3726851851851852&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPqKCU5AMBk1G5mLT2I5uiaIFX9Yts2wZlKpFUrVnAR3CfyibUugTS1jTg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;432&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      接下来我们可以更新 cell （长期记忆）的状态了。首先第一步将旧状态与通过遗忘门得到的 ft 相乘，忘记此前我们想要忘记的内容，然后加上通过输入门和tanh层得到的候选记忆 C`t。在忘记我们认为不再需要的记忆并保存输入信息的有用部分后，我们就会得到更新后的长期记忆。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.3696682464454976&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPaQpIoAjR9FhvBbYSQSXjqT3UVZ2qdwID0f7b3bicR1DOjtaYqtdGibtg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;422&quot; /&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;-0.5&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;strong&gt;输出门&lt;/strong&gt;&lt;br /&gt;      接下来我们来更新一下ht，即输出的内容，这部分由输出门来完成。首先，我们把 cell 状态通过 tanh 函数，将输出值保持在-1 到 1 间。随后，前一时刻的输出ht-1和xt会通过一个 sigmoid 层，决定 cell 状态输出哪一部分。之后，我们再乘以 sigmoid 门的输出值，就可以得到结果了。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.38686131386861317&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPe146uroN5rMcLib9C808xy6PP74MBhbW7EO8db9om9OTBNTrtlHPNlA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;411&quot; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;R上用LSTM做情感分类&lt;/h3&gt;
&lt;pre readability=&quot;4.5&quot;&gt;
&lt;code class=&quot;&quot; readability=&quot;3&quot;&gt;max_features 20000&lt;br /&gt;batch_size 32&lt;p&gt;&lt;span class=&quot;&quot;&gt;# Cut texts after this number of words (among top max_features most common words)&lt;br /&gt;&lt;/span&gt;maxlen 80  cat(&lt;span class=&quot;&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;

    
'Loading data...\n'&lt;/span&gt;)

imdb &lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.4159132007233273&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPx5ldWMJ88hUbrcHRuPo4uKG5gjrgxGh0kcnMEnDY7KST3iadRSKhxVw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;553&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;IMDB数据集包含有2.5万条电影评论&lt;/strong&gt;&lt;/span&gt;，被标记为积极和消极。影评会经过预处理，把每一条影评编码为一个词索引(数字)sequence(前面的一种word embeddings方法） 。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;&quot;&gt;cat(length(x_train), &lt;span class=&quot;&quot;&gt;'train sequences\n'&lt;/span&gt;)
cat(length(x_test), &lt;span class=&quot;&quot;&gt;'test sequences\n'&lt;/span&gt;)
cat(&lt;span class=&quot;&quot;&gt;'Pad sequences (samples x time)\n'&lt;/span&gt;)

x_train 'x_train shape:', dim(x_train), &lt;span class=&quot;&quot;&gt;'\n'&lt;/span&gt;)
cat(&lt;span class=&quot;&quot;&gt;'x_test shape:'&lt;/span&gt;, dim(x_test), &lt;span class=&quot;&quot;&gt;'\n'&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.1837837837837838&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPrIGxbicFAsJNrNfiaBnL5VhedBJSX4SYFzWEcMhVy9SbTKz2iatKEIPKw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;370&quot; /&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;&quot;&gt;cat(&lt;span class=&quot;&quot;&gt;'Build model...\n'&lt;/span&gt;)
model %
  layer_embedding(input_dim = max_features, output_dim = &lt;span class=&quot;&quot;&gt;128&lt;/span&gt;) %&amp;gt;% 
  layer_lstm(units = &lt;span class=&quot;&quot;&gt;64&lt;/span&gt;, dropout = &lt;span class=&quot;&quot;&gt;0.2&lt;/span&gt;, recurrent_dropout = &lt;span class=&quot;&quot;&gt;0.2&lt;/span&gt;) %&amp;gt;% 
  layer_dense(units = &lt;span class=&quot;&quot;&gt;1&lt;/span&gt;, activation = &lt;span class=&quot;&quot;&gt;'sigmoid'&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;      当然，可以尝试使用不同的优化器和不同的优化器配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;&quot;&gt;model %&amp;gt;% compile(
  loss = &lt;span class=&quot;&quot;&gt;'binary_crossentropy'&lt;/span&gt;,
  optimizer = &lt;span class=&quot;&quot;&gt;'adam'&lt;/span&gt;,
  metrics = c(&lt;span class=&quot;&quot;&gt;'accuracy'&lt;/span&gt;)
)

cat(&lt;span class=&quot;&quot;&gt;'Train...\n'&lt;/span&gt;)
model %&amp;gt;% fit(
  x_train, y_train,
  batch_size = batch_size,
  epochs = &lt;span class=&quot;&quot;&gt;15&lt;/span&gt;,
  validation_data = list(x_test, y_test)
)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面代码的训练过程如下图所示（我电脑大概用了20min）：&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.22603978300180833&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccP4mbzMYvic1m6WRFJujojBHtTvCCVe2gyjBlCiasPQicZDxWuxscGkB2Rw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;553&quot; /&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;&quot;&gt;&lt;span class=&quot;&quot;&gt;# 模型的准确度度量&lt;br /&gt;&lt;/span&gt;scores % evaluate(
  x_test, y_test,
  batch_size = batch_size
)

cat(&lt;span class=&quot;&quot;&gt;'Test score:'&lt;/span&gt;, scores[[&lt;span class=&quot;&quot;&gt;1&lt;/span&gt;]])
cat(&lt;span class=&quot;&quot;&gt;'Test accuracy'&lt;/span&gt;&lt;/code&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;

    
, scores[[&lt;span class=&quot;&quot;&gt;2&lt;/span&gt;]])
&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.08787878787878788&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPJaUia26365nfLJAbPtPAYChC5Kt8LoM0xCPpVRIv1jTiccVR42y1ibctg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;330&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      接下来，我们再对比其他模型，不妨以随机森林为例：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;&quot;&gt;&lt;span class=&quot;&quot;&gt;library&lt;/span&gt;(randomForest)

y_train 1000)
predict &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.14859437751004015&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPGOibNB2RBnbCDHFzz89sSEzOH3bACHSSpK6gj918wU27Tj6rxzsicriaQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; /&gt;      &lt;/p&gt;
&lt;p&gt;很显然，集成算法随机森林远远没有LSTM出来的效果好。今天关于基于R语言的深度学习就介绍到这里。最后，很高兴和大家一起学习R上的深度学习。&lt;/p&gt;
&lt;p&gt;参考资料&lt;/p&gt;
&lt;p&gt;https://tensorflow.rstudio.com/keras/articles/examples/imdb_lstm.html&lt;br /&gt;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&lt;/p&gt;
&lt;p&gt;扩展阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383226&amp;amp;idx=1&amp;amp;sn=959e2bfa3cdf523250b1d082548380a2&amp;amp;chksm=84f3cbfbb38442ede89aa9b8bd4e1db04c7d5faaa4111a73d9712f1055aeebcd8ec3f2b17b07&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;用深度学习玩图像的七重关卡&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

</description>
<pubDate>Tue, 02 Jan 2018 19:24:40 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/LMMxn2nEDp</dc:identifier>
</item>
<item>
<title>[原创]用深度学习玩图像的七重关卡</title>
<link>http://www.jintiankansha.me/t/FDI5UwW9rA</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/FDI5UwW9rA</guid>
<description>&lt;p&gt;&lt;span&gt;第一个重境界： 图像识别&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;如果你开始了解深度学习的图像处理， 你接触的第一个任务一定是图像识别 ：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;比如把你的爱猫输入到一个普通的CNN网络里， 看看它是喵咪还是狗狗。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5958333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pmVWxEbialvmZ1zRnIcvMycjzeNGH3RdEtSwpyRAjuoL5TtRMQ3LpzeA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1292&quot; /&gt;


&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.34419551934826886&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p8618aL9uvCzCqdfWsQVoYu6ibRiaDMkeV71jhF1B8hgCfY4Jq3W9WhvA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;491&quot; width=&quot;491&quot; /&gt;
&lt;p&gt;&lt;span&gt;一个最普通的CNN， 比如像这样几层的CNN鼻祖Lenet， 如果你有不错的数据集（比如kaggle猫狗大战）都可以给出一个还差强人意的分类结果(80%多准确率)， 虽然不是太高。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;当然，如果你再加上对特定问题的一些知识， 也可以顺便识别个人脸啥的，开个startup叫face 减减什么：&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.525&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8px9qZQu3008UB7uKa041NllHicdwJz031bQIlegIfzfia4f57M4ngR3yw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1200&quot; /&gt;
&lt;p&gt;&lt;span&gt;会玩的， 也可以顺别识别个猪脸什么哒（我觉得长得都一样哦）， 这样搞出来每个猪的身份， 对于高质量猪肉的销售， 真是大有裨益的。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;1.2181372549019607&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pwZbwmQdSZHGHSfufIuqSRGAANDLOs6uqFNiaEk7yXJFfPKFzfXw8Eww/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;408&quot; width=&quot;408&quot; /&gt;
&lt;p&gt;&lt;span&gt;或者看看植物都有个什么病害什么的，像这样不同的病斑， 人都懒得看的， 它可以给你看出来。 植物保护的人可以拿着手机下田了。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.8548812664907651&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pL7EMgc4RAtHuuwecULkGmzopwFEGOuozy9IhHFpbsnCH7wKKPfC99w/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;379&quot; width=&quot;379&quot; /&gt;&lt;span&gt;Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. &quot;U-net: Convolutional networks for biomedical image segmentation.&quot; International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2015.&lt;/span&gt;


&lt;p&gt;&lt;span&gt;虽然植物保护真的很好用，分类问做就了还真是挺无聊的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们进化的方向，也就是用更高级的网络结构取得更好的准确率，比如像下图这样的残差网络（已经可以在猫狗数据集上达到99.5%以上准确率）。分类做好了你会有一种成为深度学习大师，拿着一把斧子眼镜里都是钉子的幻觉。 分类问题之所以简单， 一要归功于大量标记的图像， 二是分类是一个边界非常分明的问题， 即使机器不知道什么是猫什么是狗， 看出点区别还是挺容易的， 如果你给机器几千几万类区分， 机器的能力通过就下降了（再复杂的网络，在imagenet那样分1000个类的问题里，都很难搞到超过80%的准确率）。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;2.236051502145923&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8ptnQicHcOPyIjI1iabQUicU5GrDB0oegPvX5mDDW0tUOL8fxP98frhDTVw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;233&quot; width=&quot;233&quot; /&gt;&lt;span&gt;He, Kaiming, et al. &quot;Identity mappings in deep residual networks.&quot; European Conference on Computer Vision. Springer International Publishing, 2016.&lt;/span&gt;


&lt;p&gt;&lt;span&gt;第二重境界 ： 物体检测&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;很快你发现，分类的技能在大部分的现实生活里并没有鸟用。因为现实中的任务啊， 往往是这样的：&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6097222222222223&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8peEg2SST3nibYmXDmusWibwg7lYXf25kwAaEXx4gUR7GwCibhktSAGcqUg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1833&quot; /&gt;
&lt;p&gt;&lt;span&gt;或者这样的：&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p1JiaNU4qkFaNAub1352C9zGfEJQDpv2TlcGqOicTtDJDH2pHnEFz7RtQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1280&quot; /&gt;
&lt;p&gt;&lt;span&gt;那么多东西在一起，你拿猫狗大头照训练的分类网络一下子就乱了阵脚。 即使是你一个图片里有一个猫还有一个狗，甚至给猫加点噪声，都可以使你的分类网络分寸大乱。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;现实中， 哪有那么多图片， 一个图里就是一个猫或者美女的大图，更多的时候， 一张图片里的东西， 那是多多的， 乱乱的，没有什么章法可言的， 你需要自己做一个框， 把你所需要看的目标给框出来， 然后， 看看这些东西是什么 。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;于是你来到机器视觉的下一层挑战 - 目标检测（从大图中框出目标物体并识别）， 随之而来的是一个新的网络架构， 又被称为R - CNN， 图片检测网络 ， 这个网络不仅可以告诉你分类，还可以告诉你目标物体的坐标， 即使图片里有很多目标物体， 也一一给你找出来。&lt;/span&gt;&lt;/p&gt;


&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.983739837398374&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p1Eib5JAt85jFrNdjZN1Ekhe6o5q0UMILTnhlmzc5A2KLZMVG2tBZ3dA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;369&quot; width=&quot;369&quot; /&gt;&lt;span&gt;Ren, Shaoqing, et al. &quot;Faster R-CNN: Towards real-time object detection with region proposal networks.&quot; Advances in neural information processing systems. 2015.&lt;/span&gt;


&lt;p&gt;&lt;span&gt;万军斩你首级那是杠杠的，在众多路人甲中识别嫌疑犯，也是轻而易举， 安防的人听着要按捺不住了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;今年出现的YOLO算法更是实现了快速实时的物体检测，你一路走过就告诉你视线里都有什么在哪里，要知道这在无人驾驶里是何等的利器。&lt;/span&gt;&lt;/p&gt;


&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.27361111111111114&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pv2ent4UhiaQCSVqqtuyEYvuWm8dreC119Pxicpwib5pr2FvLdv5RwHvvg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;932&quot; /&gt;&lt;span&gt;YOLO快速检测法Redmon, Joseph, et al. &quot;You only look once: Unified, real-time object detection.&quot; Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016.&lt;/span&gt;


&lt;p&gt;&lt;span&gt;当然， 到这里你依然最终会觉得无聊， 即使网络可以已经很复杂， 不过是一个CNN网络（推荐区域），在加上一层CNN网络做分类和回归。 能不能干点别的？&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;第三重境界 ： 图像切割&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;啊哈， 这就来到了第三个关卡， 你不仅需要把图片中边边角角的物体给检测出来， 你还要做这么一个猛料的工作， 就是把它从图片中扣出来。 要知道， 刚出生的婴儿分不清物体的边界， 比如桌上有苹果这种事， 什么是桌子，什么是苹果，为什么苹果不是占在桌子上的？ 所以， 网络能不能把物体从一个图里抠出来， 事关它是否真的像人一样把握了视觉的本质。 这也算是对它的某种“图灵测试” 。 而把这个问题简化，我们无非是在原先图片上生成出一个原图的“mask”， 面具，有点像phtoshop里的蒙版的东西。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.43333333333333335&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8plAMK9N6CCNlXBialKWGsFpEUYOg8DLopAW4Bm7OSGcxiaZwuEWbGibn9Q/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1960&quot; /&gt;&lt;span&gt;所谓抠图&lt;/span&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5601503759398496&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p72XAMqcibeaNphRQgFcuvqKhTL7gAHFl5zz2Jsgibicq9odzS5u59R9pQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;532&quot; width=&quot;532&quot; /&gt;&lt;span&gt;Drozdzal, Michal, et al. &quot;The importance of skip connections in biomedical image segmentation.&quot; International Workshop on Large-Scale Annotation of Biomedical Data and Expert Label Synthesis. Springer International Publishing, 2016.&lt;/span&gt;

&lt;p&gt;&lt;span&gt;注意，这个任务里，我们是要从一个图片里得到另一个图片哦！ 生成的面具是另一个图片， 这时候，所谓的U型网络粉墨登场，注意这是我们的第一个生成式的模型。 它的组成单元依然是卷积，但是却加入了maxpooling的反过程升维采样。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这个Segmentation任务， 作用不可小瞧哦， 尤其对于科研口的你， 比如现在私人卫星和无人机普及了，要不要去看看自己小区周围的地貌， 看是不是隐藏了个金库？ 清清输入， 卫星图片一栏无余。 哪里有树， 哪里有水，哪里有军事基地，不需要人，全都给你抠出来。&lt;/span&gt;&lt;/p&gt;


&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.425&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pMILia1oGtBVD1frgKQurjhb0JVt65xztrywKhbE5Qersq6ekJkMgrFg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;2824&quot; /&gt;

&lt;p&gt;&lt;span&gt;如果你要数个细胞啥的 ，都是挺容易的，给它变成这样的轮廓不就你得了。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6577777777777778&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pKSLTajVkpM8OQOY40o5elTc6YcS8bJwQ4nWTz5GvG7GicwatA5ksyMQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;450&quot; width=&quot;450&quot; /&gt;

&lt;p&gt;&lt;span&gt;第四重境界：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们开始fashion起来， 如果你是淘宝服装小店的老板 ，想让客户输入一张服装的图片，然后得到一组推荐的服装， 来个以图搜图的功能怎么搞呢？ 注意啊，我可以从网络上爬一大堆图出来，但是这些数据是没有标注的。怎么办？ 铁哥告你还是有的搞，这个搞法，就是聚类。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;铁哥教你最简单的一招聚类哦，那就是， 把图片统统放进卷积网络，但是我们不提取分类，而只是提取一些网络中间层的特征， 这些特征有点像每个图片的视觉二维码，然后我们对这些二维码做一个k-means聚类， 也会得到意想不到的效果。 为什么要深度？ 因为深度提取的特征，那是与众不同的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然后以图搜图呢？ 不过是找到同一聚类里的其它图片啊。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pydpxk94iaOS3TsAne9NqweE09T3YWtvic58vicmh3Xu3tGsRO642yg9mQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1506&quot; /&gt;
&lt;p&gt;&lt;span&gt;在聚类的基础上， 就可以做个搜索！&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5958333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pdPkKgSWcric4QIu78icfsMiaYPYwjBhNXfVt94w9dXlCicic0OOQdHo8hJw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;754&quot; /&gt;

&lt;p&gt;&lt;span&gt;第五层境界 ：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们开始晋升为仰望星空的人， 之前那些分类赚钱的应用太无聊了。 机器视觉搞科学怎么港？ 作为一群仰望星空后观察细胞的人，我们最常发现的是我们得到的天文或者细胞图片的噪声实在太大了， 这简直没法忍啊， 然后， 深度学习给了你一套降噪和恢复图像的方法。 一个叫auto-encoder的工具， 起到了很大的作用 ， 刷的一下，图像就清楚了。&lt;/span&gt;&lt;/p&gt;


&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.24027777777777778&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pJcbXOYHicuJB6QkiafzP6gp8GkcP0rTIhh1zcwXWYsVAuddMtecbZVDA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;797&quot; /&gt;
&lt;p&gt;&lt;span&gt;这还不是最酷炫的，那个应用了博弈理论的对抗学习， 也可以帮你谋杀噪点！ 如果你会对抗所谓GAN， 也是一种图像生成的工具， 让网络去掉噪声的图片，与没有噪声的自然图片， 连卷积网络都判别不出来，对， 就是这样！&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5606936416184971&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pmRuSYRGgC2Hz0fia9n1SKWpEW5vC0ReFpLibhWHHOkootXOWhI3IzJNQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;519&quot; width=&quot;519&quot; /&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.25&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pIicCIdGK2w2AaziaYHALia2cRRUgwibdU6J84xiaX5gfMibY81mbNMOtuiaPg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;806&quot; /&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;span&gt;Schawinski, Kevin, et al. &quot;Generative adversarial networks recover features in astrophysical images of galaxies beyond the deconvolution limit.&quot; Monthly Notices of the Royal Astronomical Society: Letters 467.1 (2017): L110-L114.&lt;/span&gt;



&lt;p&gt;&lt;span&gt;第六重境界 ：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在工业界赚够了钱，科学也太nerd了， 我们来玩艺术思考哲学 ，第一招， 图像风格迁移，请见&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383188&amp;amp;idx=1&amp;amp;sn=ec8d1090fe46741c14ccf7cc02b57c2c&amp;amp;chksm=84f3cbd5b38442c33ef70b698dd07f5b7aa954623fe3724e9f83b8e10a44b86a3777054395a4&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;怎么样用深度学习取悦你的女朋友（有代码）&lt;/span&gt;&lt;/a&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6904761904761905&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8paO6E4iaLY8ruEAE6G4PPCuicWXGSICQCZeXUzcdVMfiaRvbPibhK0PMdnw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;714&quot; width=&quot;714&quot; /&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.43333333333333335&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pDadLaRicMiajia9wJtp4DM49hWZ9WmwTc9Cia3fe6mvEvR3VnibLpl7AgwQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; width=&quot;600&quot; /&gt;


&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.2119487908961593&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8piaCt4IcpJNvDic7nnHMMh9YzL3onemYkfBGy8uy0gmiaJsIaNt6IKYSiaw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;703&quot; width=&quot;703&quot; /&gt;

&lt;p&gt;&lt;span&gt;然而真正能玩好这一事项的，还是那个刚刚提过的对抗学习GAN， 比如大名鼎鼎的CycleGAN， 几乎可以实现一种你自定义的“图像翻译” 功能，而且你不用做标注哦， 拿出冬天和夏天的两组图片， 它会自动的在两组图片中找出对应来。&lt;/span&gt;&lt;/p&gt;


&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.4791666666666667&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p2zXHUFQ3QBxgSVj7DKOaAibucGLrVJmcumwaDLhwpLic7Yy7NrO6o9icw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;963&quot; /&gt;&lt;span&gt;Zhu, Jun-Yan, et al. &quot;Unpaired image-to-image translation using cycle-consistent adversarial networks.&quot; arXiv preprint arXiv:1703.10593 (2017).&lt;/span&gt;


&lt;p&gt;&lt;span&gt;第七重境界：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;图像翻译也懒的玩了， 你神经网络不是号称能够理解图像，看你来个无中生有，在噪声里生成图片来？&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;对，依然是GAN，而且是最基础的卷积GAN (DCGAN)就可以给你干出来。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;看看GAN所幻想的宾馆情景， 你能想到是计算机做的图吗？ 哈哈哈！&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.23194444444444445&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pibZlT5DL1c0ibHtng9H2UdDVyStfea2SfZy6oVf3jbLdeQtvVicY4Xp5Q/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;912&quot; /&gt;&lt;span&gt;Goodfellow, Ian, et al. &quot;Generative adversarial nets.&quot; Advances in neural information processing systems. 2014.&lt;/span&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5347222222222222&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p6MVDPc4s5NsFmZnha7m8qUxGFIUicyGCYNMvBCllDoWohGrq8yBFMKQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;744&quot; /&gt;

&lt;p&gt;&lt;span&gt;写到这里， 我自己都觉得GAN是非常有前途的，有前途的，有前途的，以前我还以为只是好玩呢。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这里展示的七级浮屠，也不过深度学习被人类discover的冰山一角， 醉卧沙场君莫笑， 古来征战几人回。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;给你一个稍微清晰一些的大纲：&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.39444444444444443&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pZIxvp9LSmFuO5owzINicw9a9HlL9nNJ8W2WZEBCmeHO9JJL6Uib7GMvQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;914&quot; /&gt;
&lt;p&gt;&lt;span&gt;如果对基础理论部分有不熟悉，请返回文章&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383212&amp;amp;idx=1&amp;amp;sn=e6dbbda2acc5984c8d06e24ec9c84d09&amp;amp;chksm=84f3cbedb38442fb58f0aea635821fcf4ba3edaacef4685716c7eadb6191197ebfa70a6bf14b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;你不能不知道的CNN&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，当然它只是冰山一角， 了解更多并挨个实战请关注：巡洋舰的&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383029&amp;amp;idx=1&amp;amp;sn=a792653f736540e06d96e6f3970264e0&amp;amp;chksm=84f3cab4b38443a2754072d8b3d3fdade7ea503b15ecea46595bb149edcc139000b7f315e624&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;深度学习实战课程&lt;/span&gt;&lt;/a&gt;&lt;span&gt;， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛。刚刚讲的方法都将在课程里详细展开。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;目前课程线下版本已经基本报名完毕（特殊申请可加一到两个名额）， 为了缓解众多异地学员的需求， 我们提出一个线上加线下的课程简版， 课程包括全部课程视频， notebook作业， 和一个课程模块的来京线下实践机会， 名额限5名，预报从速，详情请联系陈欣&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfCFEFrIh4CD3HnwF5a6d9gqk3NhIsY8ThV50SQ5ut1tiaRVs5lSnvrYRqWuJNgxJTXTZ9fu54micsw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;1&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;


</description>
<pubDate>Sat, 23 Dec 2017 04:45:54 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/FDI5UwW9rA</dc:identifier>
</item>
<item>
<title>[原创]脑洞用深度学习来做三国杀的AI</title>
<link>http://www.jintiankansha.me/t/CzAiwMy52B</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/CzAiwMy52B</guid>
<description>&lt;p&gt;看着神经网络攻克了一个又一个的游戏，从围棋到星际争霸再到德州扑克，作为一名三国杀的玩家，忍不住就想能不能用深度学习来做一做三国杀这款游戏的AI，于是在这里脑洞一下，看看深度学习和三国杀能擦出怎样的火花。&lt;/p&gt;

&lt;p&gt;机器学习总体分来，有三大框架，如同一家人中大的三兄弟，大哥最稳重，也是这家人的顶梁柱，对应的是我们最熟悉，应用最广泛也最成熟的是有监督学习，只要和预测有关的，那就属于有监督学习的了。而与之对应的无监督学习则是潜力股，其做的事虽然多，但却比不上大哥和小弟出名。而机器学习中最年轻的则当属强化学习了，他最能出风头，最爱上头条，也最容易引起人们对于强机器智能，也就是机器统治人类的恐惧。&lt;/p&gt;

&lt;p&gt;究其原因，是应为不同于前两种模型，只会给出用户建议，强化学习的目标是去直接进行行动。就拿三国杀的游戏AI举个例子，若是用的模型是有监督学习，那么其做的是在你选将的时候帮你预测你选择哪一个武将胜率大，但不会自己做决定。而无监督学习是在游戏的进行中帮你分析哪一个是忠臣，哪一个是主公，而强化学习做的则是直接设计出一个AI，从头到尾战胜你。&lt;/p&gt;

&lt;p&gt;强化学习的英文是reinforce， re这个词根强调了重复，也就是说学习需要一次一次而不可以一蹴而就。force则是取推动的意思，也就是有推动或者指导着学习的方向。至于学习的内容什么，一言而概括是通过做出正确的决策来生存下来。强化学习不关心是否能够准确的预测未来，只关心自己当下的决策对未来的自己影响如何。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;不说这些空话，我们来看具体的三国杀中的例子，若是传统的设计一个AI来玩这个游戏，有一派的思路是针对游戏中的每一个决策，例如一开始选择哪个武将，之后攻击那个人，对谁使用技能，针对每一个决策，预先设定一些固定的规则，比如攻击主公的就是反贼，给主公桃子就是忠臣，然后再根据积累的游戏记录，去决定上面的哪些规则更加靠谱，并通过规则间的组合，得出更强大的AI。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;然而这样的预先设定好的规则，是受制于最初设定的限制的规则集合的，用机器学习的行话来说，就是数据集的特征提取是由人手工完成的。而若是通过深度学习的方式，其最大的特点是由机器来随机生成的特征提取规则，在经过训练数据的检验，留下适合的，再逐步改进那些看起来还可以的规则。这样做的好处是能够发明很多新的思路，对于三国杀这样相对简单的游戏，人类可以说穷尽了所有的小技巧，但对于围棋则不然，这也解释了为什么alpha zero最近能推出教柯结下棋的最新版工具，其表现出的创新不是来自于人类式的思考（类似于问as if 式的问题），而是自然选择的结果。&lt;/p&gt;

&lt;p&gt;下面来说说为什么深度学习要足够的神，若是只有一层的神经网络，那么神经网络能学到的规则就是，杀主公的就是反。然而对于更复杂的情况，就无法进行表示了。例如如果主公是专职卖血的武将，那么一开始攻击主公的就不一定是反而是忠。而一个多层的神经网络就能够处理这样的情况。用机器学习界的行话来说，也就是随着网络深度的增加，模型的容量也随之增加，从而能够处理更为复杂的特征。&lt;/p&gt;

&lt;p&gt;下一个问题是强化学习学的是什么，这里说的是强化学习中最常用的Q learning，强化学习中有状态(state)、动作(action)、奖赏(reward)这三个要素。AI需要根据当前状态来采取动作，获得相应的奖赏之后，再去改进这些动作，使得下次再到相同状态时，智能体能做出更优的动作。为了达到这一目标，AI要不断调整自己给自己的奖励，也就是Q value， 这里的Q为动作效用函数（action-utility function），用于评价在特定状态下采取某个动作的优劣。&lt;/p&gt;

&lt;p&gt;这么说好抽象的，还是用三国杀的例子。例如让程序相互之间玩游戏，游戏胜利的时候，给那些胜利的AI根据自己的身份，奖励相应的得分，从而使得下一轮这些AI能够更容易生存下去，然而对于当下的每一个选择来说，怎么给分了。想象一个AI在面临选将的时候该选刘备还是孙权的问题的时候，AI的做法是和同样的一群AI，在相同的情景下玩100次，然后发现使用孙权赢了5次，使用刘备一次没有赢，从而决定在今后较少的使用刘备。这种方法的背后，就是所谓的蒙特卡罗随机取样。&lt;/p&gt;

&lt;p&gt;接着上面的例子，若是AI决定了用孙权比刘备胜率高，但是随着其他AI的进化，AI之间变得更加会配合了，这时用刘备的胜率就高了，而若是AI坚持过去的结论，那么AI就无法探索新的战术了，所以在之前的例子中，AI所作的也不是完全不用刘备，而只是少用刘备，这就是为了平衡当前最优和未来的最优值，即要探索，也要利用好当前已知的规律。&lt;/p&gt;

&lt;p&gt;总结一下，这篇小文介绍了机器学习中的强化学习。先说了强化学习的目地是什么，即做出一个能在给定的坏境下通过做出恰当决策生存下来的智能体。再说了通过深度神经网络来做的优点，即能不受人为经验的限制，得出新的且足够复杂规则，用来简化数据，从而超越人类的偏见和定式，最后说了强化学习是怎么做的，即要学习的是如何判定当前决策的奖励，同时平衡探索新规律和利用旧规律。&lt;/p&gt;

&lt;p&gt;扩展阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383042&amp;amp;idx=1&amp;amp;sn=5992f31b4e9bb688a0c797d2c1517aca&amp;amp;chksm=84f3cb43b38442559adbb162a27698d91f4097aba2a546d83b591aeaf14c64912de527d197bf&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;用游戏中的情景来讲解常见的8种机器学习算法&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如果你对强化学习或深度学习感兴趣，&lt;/strong&gt;&lt;strong&gt;欢迎关注&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382937&amp;amp;idx=1&amp;amp;sn=d4510592a837c44fe75393c2578698d8&amp;amp;chksm=84f3cad8b38443ce6adcd155a2c45ee7707b4a9d8e48c05728aa7e93862475832bf89617025f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;巡洋舰的深度学习实战课程&lt;/a&gt;， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;目前课程线下版本已经基本报名完毕（特殊申请可加一到两个名额）， 为了缓解众多异地学员的需求， 我们提出一个线上加线下的课程简版， 课程包括全部课程视频， notebook作业， 和一个课程模块的来京线下实践机会， 名额限5名，预报从速，&lt;/span&gt; &lt;/strong&gt;&lt;strong&gt;有兴趣的可加 陈欣 微信 ： &lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfCFEFrIh4CD3HnwF5a6d9gqk3NhIsY8ThV50SQ5ut1tiaRVs5lSnvrYRqWuJNgxJTXTZ9fu54micsw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;800&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;




</description>
<pubDate>Thu, 21 Dec 2017 15:31:08 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/CzAiwMy52B</dc:identifier>
</item>
<item>
<title>你所不能不知道的CNN</title>
<link>http://www.jintiankansha.me/t/fJWHbpOdQ8</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/fJWHbpOdQ8</guid>
<description>&lt;p&gt;说起CNN，最初人们想到的都是某电视台，但等过几年，人们想起的多半是深度学习了。&lt;/p&gt;

&lt;p&gt;应该说， CNN是这两年深度学习风暴的罪魁祸首， 自2012年， 正是它让打入冷宫的神经网络重见天日并且建立起自己在人工智能王国的霸主地位。&lt;/p&gt;

&lt;p&gt;如过你认为深度学习是只能用来理解图像的，你就大错特错了， 因为它的用途太广了，上至文字，中有图像， 下至音频， 从手写数字识别到大名鼎鼎的GAN对抗学习， 都离不开它。&lt;/p&gt;

&lt;p&gt;不过要了解CNN，还是拿图像做例子比较恰当。一句话来说CNN图像处理的本质，就是信息抽取， 巨大的网络可以抽取一步步得到最关键的图像特征， 我们有时也叫自动的特征工程。&lt;/p&gt;

&lt;p&gt;CNN的建造灵感来自于人类对视觉信息的识别过程。 人脑对物体的识别的第一个问题是： 对应某一类对象的图像千千万， 比如一个苹果， 就有各种状态的成千上万状态， 我们识别物体的类别，事实上是给这成千上万不同的图片都打上同一个标签。&lt;/p&gt;
&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.6863468634686347&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJI259ewy6Db9CG9xFdiaf6yOwWXVVwibWTmWa5PqZBk001mkUP0NiapFIOw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;271&quot; width=&quot;271&quot; /&gt;CNN的灵感来自人大脑
&lt;p&gt;物理里管这种一个事物的结果与一些列的变化都没有关的特性，叫不变性， 比如如果你转动一个苹果任何一个角度它都是苹果， 这就是苹果有旋转不变性，但是数字6就不行， 如果你给它旋转特定角度它就变成9了， 它就没有旋转不变性。&lt;/p&gt;

&lt;p&gt;我们人通常可以无视这些变化认出事物来，也就是把和这种变化有关的信息忽略。如果我们对图像进行识别， 事实上我们的算法就要有人的这种本领， 首先让它学会什么东西与真实的物体信息是无关的。&lt;/p&gt;

&lt;p&gt;就拿数字识别举个例子吧， 一个数字是什么，虽然与旋转的角度有关系， 但与它在图片中的上下左右没关系， 我们管这种不变性叫平移不变性。&lt;/p&gt;

&lt;p&gt;解决这个问题，最粗暴的一个方法是制造很多的样本，比如把“1” 放在很多不同的位置，然后让机器在错误中学习。 然后穷尽所有的位置， 不过我相信没有人是这么完成对物体的识别的。&lt;/p&gt;

&lt;p&gt;那怎么办？CNN中的卷积正是这一问题的答案，因为卷积操作本身具有平移不变性（我知道听起来不明觉厉 ，请看下文）。&lt;/p&gt;

&lt;p&gt;卷积，顾名思义， “卷”有席卷的意思，“积“ 有乘积的意思。 卷积实质上是用一个叫kernel的矩阵，从图像的小块上一一贴过去，一次和图像块的每一个像素乘积得到一个output值， 扫过之后就得到了一个新的图像。我们用一个3*3的卷积卷过一个4*4的图像， 看看取得的效果。&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6847222222222222&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJIU7jaZqUeskJShdjW1xADTKJvormu9ia4F2ZPPLcpe1YAaVic2935Om3Q/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;800&quot; /&gt;卷积的数学过程
&lt;p&gt;一个卷积核就像一个小小的探测器， 它的DNA是被刻录在卷积核的数字里的， 告诉我们它要干什么， 而卷积核扫过图片，只要它的DNA是不变的，那么它在图片上下左右的哪个位置看到的结果都相同， 这变是卷积本身具有平移不变性的原理。 由于这种不变性， 一个能够识别1的卷积在图片的哪个位置都可以识别1，一次训练成本，即可以对任何图片进行操作。&lt;/p&gt;

&lt;p&gt;图像处理领域，卷积早已有另一个名字 ， 叫做滤镜，滤波器， 我们把图像放进去，它就出来一个新图像，可以是图像的边缘，可以是锐化过的图像，也可以是模糊过的图像。&lt;/p&gt;

&lt;p&gt;如果大家玩过photoshop， 大家都会发现里面有一些滤镜，比如说锐化，模糊， 高反差识别这一类，都是用着类似的技术，这样的技术所作的事情是图像的每个小片用一个矩阵进行处理，得到一个画面的转换 。 我们有时候会说低通和高通滤镜 ，低通滤镜通常可以用来降噪， 而高通则可以得到图像的细微纹理。 你玩photoshop，玩的就是卷积，卷积核里面的数字定了， 它的功能也就定了。&lt;/p&gt;

&lt;p&gt;为什么这样做有效果了？因为图像的特征往往存在于相邻像素之间， kernel就是通过计算小区域内像素的关系来提取局部特征，可以理解为一个局部信息的传感器， 或物理里的算子。&lt;/p&gt;

&lt;p&gt;比如提到的边缘提取滤镜， 它所做的物理操作又称为拉普拉斯， 只有像素在由明亮到变暗的过程里它才得1， 其他均得0，因此它所提取的图像特征就是边缘。 事实上我们知道图像中的信息往往包含在其边缘，你给以一个人画素描， 一定能够完全识别这个人 。 我们通过寻找到信息的关键载体-边缘， 而把其他多余的信息过滤掉，得到了比第一层更好处理的图像， 大大减少了需要搜索图像的可能性。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.7507836990595611&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJIKRaoRHBpH3zugrS3Fn9jIYaNRDrvHqsY0seaDXaxyrLEUqnSsmEJGw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;&quot; width=&quot;638&quot; /&gt;卷积的边缘抽取过程
&lt;p&gt;常用于卷积的Kernel本质是两个： 第一， kernel具有局域性， 即只对图像中的局部区域敏感， 第二， 权重共享。 也就是说我们是用一个kernel来扫描整个图像， 其中过程kernel的值是不变的。这点就可以保证刚刚说的平移不变形。 比如说你识别一个物体， 显然你的识别不应该依赖物体的位置。 和位置无关， 及平移不变。&lt;/p&gt;

&lt;p&gt;那卷积如何帮你从不同的图形中识别数字1了？数字的尖锐的线条会让卷积的值很高（响起警报）。无论你1出现在图像中的哪一个位置， 我的局部扫描+统一权重算法都给你搞出来， 你用同一个识别1的卷积核来扫过图片，voila，任何一个位置我都给你找出来。&lt;/p&gt;

&lt;p&gt;那卷积和神经网络有什么关系了？答案是卷积扫过图像，每一个卷积核与图像块相乘的过程，都可以看作是一个独立的神经元用它的神经突触去探测图像的一个小局部，然后再做一个决策，就是我看到了什么或没看到什么。整个卷积过程， 不就对应一层神经网络吗？啊哈， 整个卷积过程相当于一层神经网络！&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6708333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJIICwDf8icCuSiaSsicdKTJXGtAlA0FzVYW7M3OXraicLGlNNIwp6fibjPZzQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;878&quot; /&gt;一个个小探测器一般的神经元
&lt;p&gt;刚刚说了卷积是一个能够对图片中任何位置的同一类信息进行抽取的工具， 那么我们还讲到我们除了抽取， 还要做的一个工作是，取出重要信息，扔掉不重要的，实现这一个的操作，叫做pooling&lt;/p&gt;

&lt;p&gt;但是大家注意，这个时候如果原图像是28*28， 那么从kernel里出来的图形依然是28*28， 而事实上， 事实是上， 大部分时候一个图像的局部特征的变化都不会是像素级。我们可以把局部特征不变形看做一个假设， 把这个假设作为一个数学公式加入到卷积层里帮我们过滤冗余信息， 这就是pooling所做的事情 -也就是扔掉你周边得和你长得差不多得那些像素。&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5216666666666666&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJIScj5wqr3aLUCNmVqYd19HuZQo1Kxcv0efULV2kcEz9EGduLibXh3lQQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; width=&quot;600&quot; /&gt;Max Pooling的数学过程&lt;/p&gt;

&lt;p&gt;Pooling的本质即降采样，以提升统计效率，用一个比较冠冕的话说是利用局部特征不变性降维 ，pooling的方法很多，常见的叫做max pooling，就是找到相邻几个像素里值最大的那个作为代表其它扔掉。&lt;/p&gt;

&lt;p&gt;这样经过从卷积到pooling的过程， 在识别1的任务里，我们可以验明在每个小区域里有没有存在边缘， 从而找到可能存在1的区域。 在pooling的终结点， 我们得到的是一个降低维度了的图像，这个图像的含义是告诉你在原有的图像的每个区域里是含有1还是不含有1， 又叫做特征图。&lt;/p&gt;
&lt;p&gt;好了，我们可以从一堆图片中识别出1了， 那么我们怎么搞定2呢？ 我们把2写成一个Z型， 你有没有思路我们如何做到这点？ 我们不能只识别竖着的线条，还需要识别横向的线条，记住，一个卷积层只搞定一个特征，如果你既要找竖线也要找横线， 我们需要两个不同的卷积层，并且把他们并联在一起，&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;1.0194444444444444&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJINwr565frR5WvtFweXQLyV05un9UicfU8hZCv51TibnBYF8L5XE6BFgIw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1414&quot; /&gt;手写数字识别
&lt;p&gt;然后呢？ 横线对应一张特征图， 竖线对应另一个张特征图， 如果要识别2， 你无非需要比较这两张特征图，看是否有哪个位置两个特征图同时发生了警报（既有横线又有竖线）。&lt;/p&gt;
&lt;p&gt;这个比较的过程，我们还是可以用一个卷积搞定（理由依然是平移不变性）！&lt;/p&gt;
&lt;p&gt;这个时候， 新的卷积层对之前并连的两个卷积的结果做了一个综合， 或者说形成了一个特征之特征， 即横向和竖线交叉的特征。&lt;/p&gt;

&lt;p&gt;这里把我们的理论可以更上一层路。 深度意味着什么？ 我们想一下， 要正确的识别一个图像，你不可能只看变，也不可能只看边角， 你要对图像的整体有认识才知道张三李四。 也就是说我们要从局部关联进化到全局关联， 真实的图像一定是有一个全局的，比如手我的脸， 只有我的眼镜，鼻子耳朵都被一起观察时候才称得上我的脸，一个只要局部，就什么都不是了。如何提取全局特征？&lt;/p&gt;

&lt;p&gt;从一个层次到另一个层次的递进， 通常是对上一层次做横向以及纵向的整合（图层间的组合或图层之内的组合或两者），我们的特征组合是基于之前已经通过pooling降低维度的图层，因此事实上每一个神经元决策的信息相对上一层都更多，我们用一个学术名词 – 感受野来表述一个神经元决策所涵盖的像素多少， 上一层次看到更多的输入神经元， 因此感受野看更多了 。 越靠近顶层的神经元， 所要做的事情就越接近全局关联。&lt;/p&gt;
&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.459214501510574&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJITZicswJMbK60yq98JmMiab3YziaicmZAoib9PiaQxfAibX3xJrrpoqzaOcklg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;331&quot; width=&quot;331&quot; /&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5631229235880398&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJIvMPdtamMf7XC3G9EA0u14JtXWroPKsKHrQia4ibTJ9QELHPBfHEDRx7A/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;602&quot; width=&quot;602&quot; /&gt;越深，感受野越大， 表示越抽象
&lt;p&gt;这和物理学的一个基本方法--尺度变换有着异曲同工之妙（我们后面讲）， 也是提取全局信息的一个非常核心的办法，我管它叫级级递进法。 你一级一级的进行对画面进行降采样， 把图像里的四个小格子合成一个， 再把新的图像里四个小格子合成一个， 直到一个很大的图像被缩小成一个小样。每一层的卷积，都不是一个卷积，而是一组执行不同特征提取的卷积网络，比如我刚刚说的 不同方向的边缘沟成的一组卷积， 你可以想象后面有不同大小的角度组成的一组网络， 他体现了在一个空间尺度上我们所能够达到的特征工程。&lt;/p&gt;

&lt;p&gt;如此级级互联， 越靠上层感受野就越大。 整个CNN网络如同一封建等级社会，最上层的，就是君王，它是整个集团唯一具有全局视野的人，下一级别， 是各大领主，然后是领主上的风尘，骑士，知道农民（底层神经元）。&lt;/p&gt;

&lt;p&gt;我们把刚刚的全局换一个词叫抽象。深度卷积赋予了神经网络以抽象能力。 这样的一级级向上卷积做基变换的过程，有人说叫搞基（深度学习就是搞基），深一点想叫表征， 和人的思维做个比喻就是抽象。 抽象是我在很深的层次把不同的东西联系起来，CNN教会了我们事先抽象的一种物理方法。&lt;/p&gt;

&lt;p&gt;到目前为止， 我所描述的是都是一些人工的特征工程，即使网络在深，顶多说的上是深度网络，而与学习无关。我们说这样一个系统（mxnxpxz）， 我们要人工设计，几乎穷经皓首也可能做的都是错的。我们说， 这样的一个结构， 只能靠机器自己学，这就是深度学习的本质了， 我们通过几条basic假设（正则）和一个优化函数，让优化（进化）来寻找这样一个结构。 Basic假设无非图像的几个基本结构， 体现在几个不变形上，物理真是好伟大啊。&lt;/p&gt;

&lt;p&gt;深度学习的训练，就是计算机帮助人完成了机器学习最难的一步特征工程（特征工程本质就是基变换啊）。以前人类穷尽脑汁思考如何做图像识别， 是寻找人是如何识别图像的， 希望把人能用来识别物体的特征输入给计算机， 但是现在通过深度卷积，计算机自己完成了这个过程。&lt;/p&gt;

&lt;p&gt;卷积网络在2012 年的发展趋势， 大家可以关注几个方向：&lt;/p&gt;

&lt;p&gt;1， 更深的模型 ： 从AlexNet到VCG19 ，High way network 再到残差网络， 一个主要的发展趋势是更深的模型。 当你采用更深的模型，经常你会发现一些神奇的事情发生了。 当然网络的宽度（通道数量）也在增加。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.7507836990595611&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJI4MgHzMgW8BpgRIUIwjaZEib5mXYpPxWQ3O4h9lIagdzXlFTDrnuJ6sQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;&quot; width=&quot;638&quot; /&gt;这只是最初级的CNN&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5626959247648903&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJIfQsZBwppJXcjH5e8rWOViaefnsstpzajyFibZfshKjl6wZGibFrbl9Cicg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;&quot; width=&quot;638&quot; /&gt;这也只是小菜一碟
&lt;p&gt;2， 更通畅的信息交换 : 深，带来的第一个问题是训练困难， 反向传播难以传递。 从残差网络， 到目前开始流行的Dense Network， 一个主要的发展趋势是不同层级间的信息的交换越来越通畅。 我们逐步在不同层之间加入信息的直连通道。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6652777777777777&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJI1wS4QUHOtwmDrfIsmNdeYURdybYTjibibicK33KIiaxasE0kEJ6TVrFMEg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1504&quot; /&gt;Dense Network
&lt;p&gt;3， 与监督学习之外的学习方法的结合， 如迁移学习， 半监督学习， 对抗学习， 和强化学习。 后两者的有趣程度远超监督学习。&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; 
&lt;p&gt;4， 轻量化， CNN网络越来越深， 使得网络的文件动辄装不下， 这点使得CNN网络的轻量化部署成为重点， 我们希望在性能和能耗中取中。 一个很好的办法是对网络权重进行减枝，去掉不重要的权重， 另外一个是把每个权重的数据位数本身缩减，甚至是使用0和1表示， 虽然看上去我们丢失了很多信息， 但是由于巨大网络中的信息是统计表达的，我们到底损失多大还真不一定。&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5319148936170213&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJImjNnqhBaSKLHdmb6kBX4qSSvIZBSRlx6icey6W4xzuyhlTVZKBBNNDQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;658&quot; width=&quot;658&quot; /&gt;酷似生物过程的剪枝处理

&lt;p&gt;以上是CNN的小结， 不要以为图像处理与你无关，我刚刚说的其实一篇文章如果你把它转化为一个矩阵无非一个图像， 一段音频你给它转换成一个矩阵无非一个图像， 你看， 都可以和CNN挂钩。&lt;/p&gt;

&lt;p&gt;我想说，无论你是做什么的， 无论是苦逼的计算机工程师， 游戏设计师，还是外表高大上的金融分析师，甚至作为一个普通消费者， 你的生活以后都和CNN脱不开干系了 ， 预知更多情报还请关注：&lt;/p&gt;

&lt;p&gt;巡洋舰的深度学习实战课程， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛。刚刚讲的方法都将在课程里详细展开。&lt;/p&gt;

&lt;p&gt;目前课程线下版本已经基本报名完毕（特殊申请可加一到两个名额）， 为了缓解众多异地学员的需求， 我们提出一个线上加线下的课程简版， 课程包括全部课程视频， notebook作业， 和一个课程模块的来京线下实践机会， 名额限5名，预报从速，&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;有兴趣的可加 陈欣 微信 ： &lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfCFEFrIh4CD3HnwF5a6d9gqk3NhIsY8ThV50SQ5ut1tiaRVs5lSnvrYRqWuJNgxJTXTZ9fu54micsw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;800&quot; /&gt;&lt;/p&gt;

</description>
<pubDate>Fri, 15 Dec 2017 16:55:06 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/fJWHbpOdQ8</dc:identifier>
</item>
</channel>
</rss>