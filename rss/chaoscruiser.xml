<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>怎么样用深度学习取悦你的女朋友（有代码）</title>
<link>http://www.jintiankansha.me/t/PfqJe3yAlh</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/PfqJe3yAlh</guid>
<description>&lt;p&gt;&lt;span&gt;本文为巡洋舰的深度学习实战课程 预科准备。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;深度学习目前为止最有用的东西是图像处理，我们可以用它在极早期判断癌症， 也可以用它在茫茫人海里寻找犯人，但是要我说你能写一个小程序取悦女朋友， 你就不一定能信， 这一招叫艺术风格变换，就是你点击一下，就可以把你女朋友的大头照换成一个毕加索的后现代艺术作品（当然是取代还是找打要看你的艺术品位）。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.23965141612200436&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYic4o3ws1KeJDFhvTm58UIPuMhxlGQ2UiciaAyZWHk9R0Hh8dkh5Fh9jyg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;459&quot; width=&quot;459&quot; /&gt;入行需谨慎
&lt;p&gt;艺术风格迁移是一个古老而现代的主题 ， 多少艺术家为了描摹他人作品而竞折腰。 在出现了IT之后， 它也成为adobe之类的公司竞相追求的宠儿，却始终进展缓慢。&lt;/p&gt;
&lt;p&gt;而深度学习， 却可以轻轻点击自动完成这个任务， 铁哥在此给大家拆拆招 ， 看如何玩转神经风格迁移。&lt;/p&gt;
&lt;p&gt;我们说，神经风格迁移就是把一张图片的内容和另一个图片的风格合成的一个方法，比如说你给出一个猫的图片和一个梵高的自画像，就可以生成一只梵高的猫。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.43333333333333335&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYr42IhDQYJ9YHANqFzwPcFkX4vB66wcpZKVNgYD2JCYBHCP5uWD1CNw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; width=&quot;600&quot; /&gt;&lt;p&gt;在深度学习之前，机器视觉的工程师就尝试用各类神奇的滤镜提取图像的纹理信息，抽取取来的纹理图在经过某个变换放回到原图片里，就得到了一个新的风格的图片。　&lt;/p&gt;
&lt;p&gt;深度学习所作的事情，是把这个东西给自动化。我们利用卷积网络的深层结构提取的信息，来替代之前的各种滤镜。　&lt;/p&gt;
&lt;p&gt;首先，卷积网络不仅能够做猫狗识别这一类分类任务，在其中间层里，其实包含了丰富的有用信息，而这些信息，正是我们做风格迁移的基础。如果你可视化CNN的各层级结构，你会发现里面的每一层神经元的激活态都对应了一种特定的信息，越是底层的，就越接近画面的纹理信息，如同物品的材质。 越是上层的，就越接近实际内容（能说出来是个什么东西的那些信息），如同物品的种类。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.8819444444444444&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYtHhWia3sSnXwsXtRXPP3Sgq9ibDZRIF0guMlvE30JnFmJwxjTVxBBibYw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1164&quot; /&gt;研究人员提出的一套可视化CNN的方法，把深层的内容通过反卷积映射回图象，好比你关心什么，就给你投影出来(Visualizing CNN 2014 )。&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.41944444444444445&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYuMdgmuZUu2Z4uSK6gGbIib0Sic19HEibKIVjYXDb6mkHAEVicKlj1RthSg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;2068&quot; /&gt;底层神经元关心画面的材质&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.3472222222222222&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbY1KVNsUIqsIzTRcbzoqaySD0h1Eia9co1BVjGTgrCuSbVYBJqZg3icMAg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;2178&quot; /&gt;深层神经元关心物品的种类
&lt;p&gt;那么好了，风格迁移不就是这么简单吗，把一张图片的底层信息和另一张图片的上层信息合成一起不久可以了吗？ 用适当的数学方法，我们可以在卷积网络的中间层里左手提取图象内容有关的信息，右手提取图象风格有关的信息。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6888888888888889&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYQx9EibUZNRW5l5nEdDzhYfScqPmKRUCDEkvt7BV7T5c91IficozfQTFg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1764&quot; /&gt;用中间层的信息恢复的内容，可以看到不同层里里都可以找到风格和内容有关的信息， 但是层次越深， 具体的信息就越少， 而“实体” 的概念轮廓犹在

&lt;p&gt;看起来是的，我们可以通过一个已经训练好的CNN， 把一张风格图片和内容图片的信息都抽取出来， 然后拼在一起！&lt;/p&gt;
&lt;p&gt;为什么这里要用一个已经训练好的CNN呢？ 一个用分类任务训练好的CNN，通常已经具有了对世界大多数图像提取信息的能力， 因为图像传递信息的底层机制是想通的。 我们把这个网络连接的权衡直接共享过来， 图片一导进来， 网络就可以生成直接可用的特征！ 这正是迁移学习的原理。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.7507836990595611&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYs7AoRBGTAIVlBicbHGFwuNQ4OIr1WY8Kg0HWLR8ROxlp6S0iabDJMnuQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;638&quot; width=&quot;638&quot; /&gt;这里我们导入一个已经训练好的VGG19网络，一种非常流行的CNN图像分类框架
&lt;p&gt;所有深度学习和机器学习，都是预先设定好一个损失函数，然后在进行梯度回传，这里也不例外，我们可以通过设定合理的损失函数，来解决问题。这个损失函数，正是一种能够测量生成图片与风格图片，内容图片距离的函数。　&lt;/p&gt;
&lt;p&gt;来，兄弟们，看我们如何设定这样一个函数。既然我们的深度卷积网络可以做到测量与内容有关的特征，　那么我们只需要在这个层次上找一下特征向量的距离就好了。　&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6597222222222222&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbY4yZ09u9kBCIGxP4T5lWcaqkWVsRAjO4btfsIw7cwGA0tBCMY7XEiazQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1514&quot; /&gt;图像无非是高维空间的一个点，通过神经网络变换再经过特定降维方法处理后我们可以给它转化成二维曲面上的一个点， 我们会发现，在这个世界里， 狗在狗的国度 ， 猫在猫的国度。 而我们只需要度量不同图像的空间距离，就测量了内容的相似度。&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.26136363636363635&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbY2paPnepwZeWvZm9Yoz78JxwR5YsrbLFCEzgbNUNcS8bszXbic95NJyA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;528&quot; width=&quot;528&quot; /&gt;哇， 这不就是定义距离的公式吗！
&lt;p&gt;然后呢，如何搞定风格，风格通常是一个艺术家眼中主关的有点虚无缥缈的概念，也就是我们通常说的感觉， 比如梵高或者莫奈的画，你没有经过艺术熏陶也可以得来。&lt;/p&gt;
&lt;p&gt;而在深度学习的角度下， 这种感觉却发现与不同神经元活动的相关性有关！ 也就是说，风格是深度网络神经元活动的某种统计特性！ 悄悄的，我们把艺术和数学对接上了。 统计果然是上帝的语言啊有木有！&lt;/p&gt;
&lt;p&gt;这里我们借助一个叫gram矩阵的数学工具，它通过测量同一层卷积输出不同通道之间的相关性（计算不同通道间的相关性，组成一个矩阵）给出一个对风格的度量。然后，我们在测量一下风格之间的距离不就行了吗？&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.48333333333333334&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbY5sepmib4hJQbzL66Fnq348wTSibMmU5Z1flGNZR1yEcW18WoYEPBqpFA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1570&quot; /&gt;把CNN某一层对应不同特征的神经元像摊煎饼一样摊开， 然后计算之间的相关性&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.325&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYTyKWmy40p9TRlDgJGicrScDAtmWE3GficSxQw01aG6iaFC4x9033wE2kw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1790&quot; /&gt;得到一个矩阵，矩阵的每个元素对应不同特征间的相关性

&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.3803680981595092&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbY6ItuRzYmgHJZWPJR1kCFraIpFEnBEOXgQVSxCQ4QKkicF083zdkia6ug/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;326&quot; width=&quot;326&quot; /&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.49295774647887325&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYKrhVYKh7reuEI53qNHlrPxqHqV8bea2RxrX9Wj0msxcjXhpWoNzQZg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;568&quot; width=&quot;568&quot; /&gt;这个损失函数就是gram 矩阵之间的距离！
&lt;p&gt;注意，衡量风格之间的距离， 我们是把不同网络层级间的gram矩阵的距离都计算一下加在一起，这样可以把不同层次度量的东西综合起来 。&lt;/p&gt;
&lt;p&gt;好了，到这一步， 大功告成， 把两个损失函数叠加在一起就好了。&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.18055555555555555&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbY6NHs2k9libLbZmsD6fDURhyg7xwYTnMpz6YiaOdjIr1TkG2ccLCicjt1w/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1072&quot; /&gt;&lt;p&gt;目标函数的设计学问可大了，改变a和b的比例就能造成很多区别，大家注意风格图片的比例越高，图像就越纹理化。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.8736111111111111&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbY6H4zp6eorl2Soq5sL7ibMbGo6WIW2t6ltj6un6rroAHK7cicicpxInybw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1422&quot; /&gt;风格的权重变大的时候， 那图像就变成了意大利瓷砖！


&lt;p&gt;然后我们可以做什么呢？ 梯度下降！但注意，这里我们优化的目标不是网络权重而是图像本身，这样我们就大功告成了！&lt;/p&gt;

&lt;p&gt;当然这里说的只是风格迁移的一种， 这种方法的优点是通俗易懂， 而缺点是速度很慢。 还有一个方法，是借用生成网络，直接给搞出来， 这个方法更快速， 更加适合工业封装。 我来给大家展示一下这个方法的实质。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.2611111111111111&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYOZfamhMQlq3vu12hkUlXvcb3nqWQFZQmiaVCjicSicd7OLvJaEWX4IISA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1852&quot; /&gt;像不像GAN的结构！
&lt;p&gt;哈哈，这样我们就可以完成一幅艺术作品交给家里领导了，但是不要忘记哦， 这件事给我们的启示绝不止这一个呀。 它给我们启示的是，我们深层神经编码的机制里，深度学习的踪影， 你对风格的认知，其实是和内容的认知一样， 是可以量化的，而不像某些艺术家所言， 完全主观，与数学无关。 不仅可以量化，而且这个信息是可以独立被提取的， 这种信息不是存在于某个神经元之上， 而是分布式的存在于多级神经网络的不同尺度之间， 通过每一层神经元的统计规律表达。&lt;/p&gt;
&lt;p&gt;虽然我们尚不知道这些猜想是否正确， 他们我们人类深奥的视觉处理机制提供了一种聪明的理解方法。&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt;  附： 代码, 看看用pytorch做出来是多么简洁：&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.20416666666666666&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYkW3KqZibWm1Qnj2bLXnO94rj0clSaTHCbfElOBPu2YaAW30ZlNHJ2zg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1618&quot; /&gt;计算内容损失函数&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.8236111111111111&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYTTcNv6BZMQvH4Z3trGs1sXuNnGVxOUKZWgcN49vn8VraKK5NQL7pTQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1614&quot; /&gt;计算风格损失函数&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.7583333333333333&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYOGnSUIGv8TG89XLcNbmCknZgTZ6gks7LnyvMm9iahTno5U1VTmpW6lw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1616&quot; /&gt;设定模型主体！&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.4152777777777778&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYno7cPsax1X1Cbsw1oEiaibQVd8B3jnTpdYSrVBwicgVHb408AaXpKiaU1g/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1620&quot; /&gt;训练过程！
&lt;p&gt;&lt;span&gt;如果你对上面的脑洞感兴趣，欢迎关注巡洋舰的深度学习实战课程， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;许铁关于风格迁移的讲解视频查看，请点击链:http://pan.baidu.com/s/1c6Siaa  密码:2g61。&lt;/p&gt;


</description>
<pubDate>Tue, 28 Nov 2017 19:41:31 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/PfqJe3yAlh</dc:identifier>
</item>
<item>
<title>【今日直播】《深度学习图像风格迁移》</title>
<link>http://www.jintiankansha.me/t/FbJC2j9Dum</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/FbJC2j9Dum</guid>
<description>&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.7786666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/EribroYqw9eBkHbybwibTB3slfmZcro69Y6UTMbFoa7jRoAo2ric1GSIicxNicUXdsiaz9FRTD3MCqJbrsm2XUebd0oQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;【上课方式】&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;手机端APP：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;万门大学&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/EribroYqw9eBkHbybwibTB3slfmZcro69YdtpZ7Fl4NOPP3ExqjAbicibicibpt86n3FJbGyWDfZ7SX3xB3zl2dqPF6g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;400&quot; width=&quot;129px&quot; /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;电脑网页版：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;www.wanmen.org&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;注册&amp;amp;登录万门账号&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;搜索课程名 &lt;/span&gt;&lt;span&gt;深度学习图像风格迁移&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;课程页面点击&lt;span&gt;我要报名&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;报名后，进入&lt;/span&gt;&lt;span&gt;个人中心&lt;span&gt;—&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;我的课程&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;检查是否有此课程，确认是否报名成功&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;【进群交流】&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;私信小万君&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;留言 &lt;span&gt;图像风格迁移&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;邀请您进入课程交流群&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;直播过程中可与老师互动～&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;【直播时间】&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;明日 （11月26日）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;16:20-17:00&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;《人工智能、大数据与复杂系统》概论课程，点击【&lt;span&gt;阅读原文&lt;/span&gt;】免费学习&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Sun, 26 Nov 2017 06:35:15 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/FbJC2j9Dum</dc:identifier>
</item>
<item>
<title>多余的话 借深度网络说说最近发生的几件事</title>
<link>http://www.jintiankansha.me/t/i6XlKO9l9h</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/i6XlKO9l9h</guid>
<description>&lt;p&gt;关于刘鑫的事情，我曾经写过一篇明知道不讨喜会找骂的小文-&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383146&amp;amp;idx=1&amp;amp;sn=052ca08472d6e71c1343266ef6dacfbc&amp;amp;chksm=84f3cb2bb384423d04dc390a568db078d4d5abd8ecd283cd30ac8bbd50179daa00a4542d2e82&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;Do not pity the dead. Pity the living&lt;/a&gt;，写的是关于这件事有关的一些我觉得有关系的格言。将这些格言组织成一篇有论据，更重要的是有观点，也注定会更讨喜的文， 对我来说一点不难。但我从来都不是为了讨读者的喜欢而写作的，有没有人来读，我根本不care，也别给我说什么媒体和个人写作的区别，都不过只是一个说人话的地方。我在乎的只是我在写作的时候是否有所提高，永远都是写给一俩个人的。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;记得曾经的孙志刚还是小悦悦的事件，当年我一个要好的朋友因为这件事很生气，很难受，哭着对我说这世界怎么这样，我不知怎么去安慰。就陪着一起读书，一起查资料，想象我们要为这件事做一期访谈类的节目，类似铿锵三人行吧，我们查了很多的书，比如路西法效应等社会心理学的研究，还有小说和影视作品中的话，以及哲学家关于正义的讨论，后来我们终于不那么生气了。&lt;/p&gt;

&lt;p&gt;如今又是一件令我们哭不出声音的事情出现。我觉得关于这件事，是该写点什么的，我喜欢写写新奇的角度，那就按照我熟悉的写起吧。最近看到一个微课，名字是阿尔法元100：0完爆阿尔法狗的给人类的三个启示，说的是人类可以从深度神经网络的架构中能学到些什么。那就照猫画虎，说说从深度学习的角度来看，三颜色这件事该怎么去看。我这里会少谈时事，多讲技术。&lt;/p&gt;

&lt;p&gt;所谓学龄前教育，就如同神经网络的参数初始化。任何一个有过实战经验的人，都知道参数初始化的重要性。不止会影响模型收敛的速率，也就是需要花更多的时间，才能够找到一个相对好的解，还会影响模型的泛化能力。举一个极端的例子，如果你对模型初始的参数都设置为一样的值，例如0，那么神经网络就变成了一个确定性的模型，也就是无法在之后的训练数据中，无法学到任何需要用到概率的判断。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;那么该怎么对神经网络的参数进行初始化了，常用的有俩种方法，一种是随机给每个权重一个符合均匀分布的数字，比如拿一个公平的骰子，从1到6的数字随机之中选一个。第二种方法是给这些权重随机选择一个符合正态分布，平均为0的数。我没有尝试过，如果给参数初始化时，随机给他们分配一个符合尾巴很肥的幂律分布的随机数会是怎样。可以推算下，对于那些被随机分配到初始权重接近负无穷的点，也许这些点的权重很难通过训练回到他们应有的样子了，这不是稀疏编码，让训练好的神经元随机的失联，而是从一开始就将这些信息丢掉。就假设我们是训练识别猫狗图像的神经网络吧，这意味着有些时候，我们的神经网络会怎么都认不出图中的动物的耳朵在那里，也许缺少了耳朵形状这一个特征，对网络整体的影响并不大。但正如在雪崩时，没有一片雪花是无辜的。但凡涌现的系统，每一个输入的信号，都可能成为那影响飓风的蝴蝶之翼。&lt;/p&gt;

&lt;p&gt;接着来说说深度学习的深。为什么深度学习的神经网络需要那么多层了？这个问题的答案，我最初的回答是因为局部感知，也就是先只看整体图景的一个局部，正因为你限制了自己的任务，从而使得你能够更准确的完成你的任务，正如经济学中讲的分工带来效率的突飞猛进，如果每一个辨别能力不那么强的神经元，可以通过较少的训练就能够很好的完成需要整合局部信息的任务，那么通过层次化的管理，例如深度学习中的KPI--交叉熵，那么就可以聚沙成塔，完成复杂的信息整合。&lt;/p&gt;

&lt;p&gt;但是后来的我回答这个问题，却会说为什么深度学习需要这么多层，是因为每层的神经元都需要做到权值共享。所谓weight sharing，就是让神经元们有一套普世的价值观，这不止对加快网络的收敛，提高训练的速度很重要，更可以增加模型的泛化能力。若没有了权值共享，那么你以为你身边的人和你有一样的价值观，等到不知什么时候却发现那么对那些你以为天经地义的事情，你们都有着不同的观点，这时你就会发现，网络的深度变得没有多少意义，因为你无法根据自己身处的环境，判定你处于网络中的那一层。&lt;/p&gt;

&lt;p&gt;所以我觉得权重共享是比dropout更应该向所有人普及的一个概念，dropout说的是在面对不确定的未来时，通过小的可控的失败来避免大错误，类似反脆弱的概念，而权重共享却关系到我们每一个人该怎么去交流，关于权重共享，我曾写过一篇文 &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382656&amp;amp;idx=1&amp;amp;sn=cf461c00d2af8b1cf1afeb2c5622aa47&amp;amp;chksm=84f3cdc1b38444d75ba2f93162acab88141e0887f9a04e6cef80cfd4591e7d56d963c2ebf131&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;从深度学习中的weight sharing说说共同价值观&lt;/a&gt;，可以参考。&lt;/p&gt;

&lt;p&gt;接着说一说深度学习中最大的魔鬼，也就是梯度消失和梯度爆炸。先说梯度消失，今天公众号李松蔚发了一篇文&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA4NTI3NTkyNQ==&amp;amp;mid=2654002999&amp;amp;idx=1&amp;amp;sn=1695e3987dc94252a429790c900aa7af&amp;amp;chksm=841e1b4db369925b83a2d0a997fad15b8ff9c2d9152fc754d8b465dc883b638c895cb5f7a9bb&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;不只是被虐的孩子，整个社会都应激障碍了&lt;/a&gt;，我觉得应激障碍这个词，很形象的说了梯度爆炸是什么。由错误驱动的学习是一层一层进行的，但学习的过程中使用的信号是上一层错误的偏导数，偏导数是只关注变化的，在一层层的信号传递链，变化被放大，也许只是一件小事，但就如同玩电话传消息的孩子，会将原本的信息扭曲，从而使得即使网络本来有很多层，但深度越深，得到的反馈越少。&lt;/p&gt;

&lt;p&gt;只关注变化，这很想《怪诞行为学》中描述的锚定效应，更概括的来说，是人的情绪，就是这样一个短时的偏导运算符，只关注相比别人，你得到了多少。当上海廉价的幼儿园和北京的高价幼儿园依次出事，社会作为一个整体由不得会反应过度。情绪的链式传递，导致了更为关键的信息被忽视，比如长期以来对基础教育尤其是幼儿教育的投入不和法律缺失。不要以为找到了幕后的黑手，就算是深度的思考了。面对每一个都可能会切身面对的社会问题，每一个人都需要拿出创业者的激情来。既然现在幼师的准入门槛还没有明确的规定，以剔除那些本身不喜欢小孩的人，那么能不能通过社交网络中留下的痕迹，通过APP中的行为测试，去识别你孩子的幼儿园老师是不是喜欢孩子。&lt;/p&gt;

&lt;p&gt;接着说说梯度消失对应的梯度消失。这里可以看六神磊磊今天发的文 &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA4NDEzNTMyMA==&amp;amp;mid=2650316540&amp;amp;idx=2&amp;amp;sn=5e0bb1af48ae7bd1aeafb294f3c587f5&amp;amp;chksm=87e7e20bb0906b1dee12267f6e7c2f876a82c7bd5df2b6f6eba7a48061f9a28c2b0b1593b5dc&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;没有中间层的结果，就是直面下层的火力&lt;/a&gt;。我们常说米国这二十年来中产阶级消失了，对应到深度学习中，这个问题就是梯度消失。消失的中层，使得哪怕预先优化好的网络结构变成了一张白纸，制度不管用了。&lt;/p&gt;

&lt;p&gt;吵闹但无序的底层无法和自以为国师的精英上层对话。你说你拆除违章建筑，是合法合规，就理应如此。而他们则说着要生存，说着自己的孩子已经受了多少不平等的对待。然而若是送快递的小哥和收快递的白领之间能够说几句贴心话，那么这些白领也许能够写出带着感情的文章，写成内参，让更上层的决策者知道自己的每一个决策究竟对于活生生的人意味着什么，那信息的传递就不算脱节。然而若是收快递的白领也人人自危，觉得自己不过是长的肥一些的韭菜，那么我们就说梯度消失了，模型中离输出层越远，能学到的东西越少。&lt;/p&gt;

&lt;p&gt;任何社会运都行在一个变化无穷的环境中，整个社会可以看成是一个需要不断优化的神经网络。而面对复杂的环境，本来深层的网络是能够相对更好的应对的。然而，正如做科普的童鞋常常觉得为什么科普这么难，不靠谱的养生神帖那么多。本质的原因不是科普文写的不好，而是由于要学习的网络太深了，而在向中间层的传递过程中，出现了梯度消失。&lt;/p&gt;

&lt;p&gt;而解决梯度消失或者梯度下降的一个常用方法，就是批量正则化（batch normalization），也就是在每一层的时候，都对要传递的信号进行一下平移和拉伸，使得他们呈现为平均值为0，符合高斯分布的一组变量。通过批量正则化，网络的每一层都会拿到分布的相似一组信号，这样做的好处是让网络学的更快，同时缓解了梯度消失/爆炸的问题，如果你得到的初始信号不包含上一层的偏见，那么你学习中也没有偏见可以放大或者忽视。&lt;/p&gt;

&lt;p&gt;而这需要在神经网络的每一层之间，加上一个专门正则化的处理层。而这正是媒体在一个成熟的社会里应做的事。好的媒体不是1984，那对应的是梯度消失，或者是美丽新世界，那对应的是梯度爆炸。好的媒体用每一层能够听懂的话，去克制的说出，更多的时候是一遍遍的复述普遍共享的价值观和事实。就如同精准饮食，针对每一层的文化背景，去说他们能听懂的话，去讲他们愿意听的故事。&lt;/p&gt;

&lt;p&gt;人人都能发声的时代，如果你只是表示情绪，那么你也许贡献的更多是噪音，若你只是想获得关注，那么你传递的更多是别人想要的而不是别人真的需要的，写任何文，我总觉得要做的既是不得不写，又清楚知道自己写的不过是篇多余的话，才算是为自己而写。古之学者为己 今之学者为人，不可不戒。&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383146&amp;amp;idx=1&amp;amp;sn=052ca08472d6e71c1343266ef6dacfbc&amp;amp;chksm=84f3cb2bb384423d04dc390a568db078d4d5abd8ecd283cd30ac8bbd50179daa00a4542d2e82&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;Do not pity the dead. Pity the living&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383124&amp;amp;idx=1&amp;amp;sn=80b21ed5c144027b12388abf85c7dccb&amp;amp;chksm=84f3cb15b38442034b620347e8530958e53546d377e990c5a4c8bd111a3238be44926496b57b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;人的价值在于提问-读《Human are underrated》&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

</description>
<pubDate>Sat, 25 Nov 2017 12:05:41 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/i6XlKO9l9h</dc:identifier>
</item>
<item>
<title>你需要的深度学习数学基础： 从入门到进阶</title>
<link>http://www.jintiankansha.me/t/j3MuNyjiAa</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/j3MuNyjiAa</guid>
<description>&lt;p&gt;&lt;span data-offset-key=&quot;mgnb-0-0&quot;&gt;&lt;strong&gt;本文为&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382937&amp;amp;idx=1&amp;amp;sn=d4510592a837c44fe75393c2578698d8&amp;amp;chksm=84f3cad8b38443ce6adcd155a2c45ee7707b4a9d8e48c05728aa7e93862475832bf89617025f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;巡洋舰的深度学习实战课程&lt;/a&gt;数学预科准备。 &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;mgnb-0-0&quot;&gt;打开深度学习， 对于大部分小白， 编程已然令人生畏， 而更加令人难以接受的，那么，深度学习里的数学到底难在哪里？ 寻常人等又有如何路径走通， 请听铁哥慢慢解析。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUOic3LicwjTEXpo0GY2dIJibqouwicgjibbIm6TMLf8AVoFKeYGSkRuASTHsg/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.48272552783109407&quot; data-w=&quot;1042&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;4tb26-0-0&quot;&gt;线性代数： &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4tb26-0-0&quot;&gt;想要学习深度学习， 你第一个需要理解透彻的学问是&lt;strong&gt;线性代数&lt;/strong&gt;。 为什么？ 因为深度学习的根本思想就是把任何事物转化成高维空间的向量， 强大无比的神经网络， 说来归齐就是无数的矩阵运算和简单的非线性变换的结合。 这样把图像啊， 声音啊这类的原始数据一层层转化为我们数学上说的向量。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;什么image to vector， word to vector 这些， 都在说的一件事情就是这类数学转化， 不同类型（我们通常称为非结构化数据）的数据最终成为数学上不可区分的高维空间的向量，所谓万类归宗。 线性代数，就是对于这一类高维空间运算做的默认操作模式，可谓上帝的魔术之手。 &lt;/p&gt;

&lt;p&gt;因此你要驾驶深度学习这个跑车， 线性代数关系你到是否理解发动机的原理。&lt;/p&gt;

&lt;p&gt;线性代数核心需要掌握的是线性空间的概念和矩阵的各项基本运算，对于线性组合， 线性空间的各类概念， &lt;strong&gt;矩阵&lt;/strong&gt;的各种基本运算， 矩阵的正定和&lt;strong&gt;特征值&lt;/strong&gt;等等都要有非常深厚的功力。 &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;概率论： &lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dr7ka-0-0&quot;&gt;下一个我们需要讲解的是什么呢？ &lt;strong&gt;概率论&lt;/strong&gt;基础 。 概率论事整个机器学习和深度学习的语言 ， 因为无论是深度学习还是机器学习所做的事情是均是预测未知。 预测未知你就一定要对付不确定性。 整个人类对不确定性的描述都包含在了概率论里面。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dr7ka-0-0&quot;&gt;概率论你首先要知道的是关于概率来自频率主义和贝叶斯主义的观点， 然后你要了解概率空间这一描述描述不确定事件的工具， 在此基础上， 熟练掌握各类分布函数描述不同的不确定性。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dr7ka-0-0&quot;&gt; 我们最常用的分布函数是高斯， 但是你会发现高斯是数学书里的理想， 而&lt;/span&gt;真实世界的数据， 指数分布和幂函数分布也很重要， 不同的分布对机器学习和深度学习的过程会有重要的影响，比如它们影响我们对目标函数和正则方法的设定。懂得了这些操作， 会对你解决一些竞赛或实战里很难搞定的corner case大有裨益。 &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5fo8r-0-0&quot;&gt;一个于概率论非常相关的领域&lt;strong&gt;-信息论&lt;/strong&gt;也是深度学习的必要模块，理解信息论里关于熵，条件熵， 交叉熵的理论， 有助于帮助我们了解机器学习和深度学习的目标函数的设计， 比如交叉熵为什么会是各类分类问题的基础。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;5fo8r-0-0&quot;&gt;微积分： &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bq2c-0-0&quot;&gt;微积分和相关的优化理论算是第三个重要的模块吧，线性代数和概率论可以称得上是深度学习的语言，那微积分和相关的优化理论就是工具了。  深度学习， 用层层迭代的深度网络对非结构数据进行抽象表征， 这不是平白过来的，这是优化出来的，用比较通俗的话说就是调参。 整个调参的基础，都在于优化理论， 而这又是以多元微积分理论为基础的。这就是学习微积分也很重要的根源。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;bq2c-0-0&quot;&gt;优化理论： &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bq2c-0-0&quot;&gt;机器学习里的优化问题，往往是有约束条件的优化，所谓带着镣铐的起舞 ， 因此拉格朗日乘子法就成了你逃不过的魔咒。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bq2c-0-0&quot;&gt;优化理论包含一阶和二阶优化，传统优化理论最核心的是牛顿法和拟牛顿法。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bq2c-0-0&quot;&gt;由于机器学习本身的一个重要内容是正则化，优化问题立刻转化为了一个受限优化问题。这一类的问题，在机器学习里通常要由拉格朗日乘子法解决。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;传统模型往往遵循奥卡姆剃刀的最简化原理，能不复杂就不复杂。 &lt;strong&gt;而深度学习与传统统计模型的设计理念区别一个本质区别在于，深度模型在初始阶段赋予模型足够大的复杂度&lt;/strong&gt;，让模型能够适应复杂的场合，而通过加入与问题本身密切相关的约束： 例如全职共享，和一些通用的正则化方法：例如dropout， 减少过拟合的风险。 &lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5h3b-0-0&quot;&gt; 而正因为这种复杂度， 使得优化变得更加困难，主要由于： &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5h3b-0-0&quot;&gt;1， &lt;strong&gt;维度灾难&lt;/strong&gt;， 深度学习动辄需要调整几百万的参数，是一个计算量超大的问题。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;2， &lt;strong&gt;目标函数非凸&lt;/strong&gt;， 具有众多的鞍点和极小值。 我们无法直接应用牛顿法等凸优化中的常见方法，而一般用到一阶优化（梯度下降），这看起来是比支持向量机里的二阶优化简单，然而正是因为缺乏很好的系统理论， 边角case变得特别多，反而最终更难。&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;5h3b-0-0&quot;&gt;3， &lt;strong&gt;深度&lt;/strong&gt;， 由于深，造成反向传播的梯度往往越来越弱， 而造成梯度消失问题。 &lt;/span&gt;各类深度学习的领先算法往往是围绕解决梯度消失问题。 &lt;/p&gt;

&lt;p&gt;&lt;img data-type=&quot;gif&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUOHYPYO0IS40T4ianPe2txtibXsg3IXgLNMsx0KlIo3swCUvQJQYKiav0lw/0?wx_fmt=gif&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.622680412371134&quot; data-w=&quot;485&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;5h3b-0-0&quot;&gt;图： 臭名昭著的局部极小值问题。 &lt;br /&gt;&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;6d768-0-0&quot;&gt;我们用一些非常简单的实例说一下深度学习的几个主要应用方向与数学的结合：&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;1ldau-0-0&quot;&gt;阶段1&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;1ldau-0-0&quot;&gt;：  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1ldau-0-0&quot;&gt;多层神经网络（DNN）的前传与回传（BP）算法 。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dr1rf-0-0&quot;&gt;理解DNN的前向传递过程， 这个过程里包含了线性代数的空间变换思想和简单的高数。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;f8mha-0-0&quot;&gt;这算是第一难度梯级， 你需要掌握的是BP算法， 这里含有多元微积分一个最基本的法则： 链式求导和jacobian矩阵。  在此处你会对维度产生全新的认识。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUO5Yuyvgrvx25yyKTEPyuaYqS6ZUtcLpSR0QUYMQuUYUQrXdmgtkFiaQg/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.734020618556701&quot; data-w=&quot;485&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;609l5-0-0&quot;&gt;阶段2&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;609l5-0-0&quot;&gt;：  　&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;609l5-0-0&quot;&gt;深度学习的中流砥柱CNN卷积运算 ： 这里应用的数学是卷积本身， 你要通过高数掌握卷积的本质， 体会它与相关性， 傅立叶变换等运算之间的联系。 这部分也属于高数内容， 而卷积运算本身也需要强大的线性代数基础。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUO4kibA85lQR0Kewzj8PJic338A7E14QkmsIfuDsSQkSk1X7cBgsPJLbDg/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.771551724137931&quot; data-w=&quot;464&quot; /&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;b3epo-0-0&quot;&gt;阶段3：　&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;b3epo-0-0&quot;&gt;RNN网络与微分方程。RNN似乎包含比别家算法多很多的数学知识，因为RNN的运算和调参你需要理解一些非线性动力系统的基础知识。如定点，边缘稳定性和混沌。非线性动力学是物理的内容， 但是大部分讲的是数学， 这点物理系的学的会很有优势。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUOxW5MMMg9CnD4E6928FC6pKib1zbWVJLYIsPYalvMvdBicib2FCg7TJy7g/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.44642857142857145&quot; data-w=&quot;336&quot; data-backw=&quot;336&quot; data-backh=&quot;150&quot; /&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;cc74-0-0&quot;&gt;阶段４：&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;cc74-0-0&quot;&gt;　&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;cc74-0-0&quot;&gt;深度强化学习。 这时候你的数学工具要包含bellaman 方程，控制论的一些基础知识，更多关于马尔可夫过程和时间序列的知识。简单的控制论你看看会很好的助力你对整个机器学习用于机器人控制的理解，而马尔科夫决策树的基础知识学了你会觉得什么阿尔法狗阿尔法元都挺简单的。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUOoBgbTec5jCqdwTricnp1LSeBe4MYObJnLcTg3aCypj1JkV9Hy7QArHw/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.335625&quot; data-w=&quot;1600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;76lem-0-0&quot;&gt;阶段5：　&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;76lem-0-0&quot;&gt;生成式模型与GAN对抗网络。这部分的数学难度应该与深度强化学习在同一难度上。　需要对概率论有比较深的理解。 最基础的生成模型你要理解玻尔兹曼机这个与统计物理渊源很深的模型，需要较深的概率统计知识。 GAN生成对抗模型的目标函数含有了大名鼎鼎的博弈论思想。纳什均衡都进来了啊， 虽然这时候的优化理论已经飞一样的难， 你还是会有一种融汇贯通的感觉。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUO2seqfyC8Xy0R7aeY8OTfXjFuYciaaeB8MwqbvUmGbHHn4cNLvedHfmQ/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.48297213622291024&quot; data-w=&quot;323&quot; data-backw=&quot;323&quot; data-backh=&quot;156&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;76lem-0-0&quot;&gt;阶段6：&lt;/span&gt;&lt;/strong&gt;&lt;span data-offset-key=&quot;76lem-0-0&quot;&gt;   &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;76lem-0-0&quot;&gt;信息瓶颈理论？  计算神经科学前沿？ 铁哥恭喜你此处要告别尘缘了。  深度学习的尽头必然要与我们对认知和信息本质的基础认识相连。 此处针对希望做深度学习研究的人员。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccylNKJ1ic3uoyKHeFRx0LUOO17N3ibUgy7JZa4xOvRuOtnoGGun7ic0OKsrJmxwhicJtickcDqTvw5iatg/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.5&quot; data-w=&quot;696&quot; /&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;8rdun-0-0&quot;&gt;基础教材推荐：  &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;陈希孺院士的&lt;strong&gt;《概率论与数理统计》&lt;/strong&gt;，这是一本数理统计的入门级教材。最好的统计中文教材。参考评论&lt;span class=&quot;Apple-converted-space&quot;&gt; &lt;/span&gt;https://d.cosx.org/d/14990-14990&lt;/p&gt;

&lt;p&gt;龚升的&lt;strong&gt;《简明微积分》&lt;/strong&gt;。这本教材是我见过的最与众不同的写作结构，不是按常规教材那样讲导数、微分、微分的应用然后是不定积分、定积分。如果觉得难， 入门从同济大学的微积分教材入手也不错。&lt;/p&gt;

&lt;p&gt;线性代数：&lt;strong&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;Introduction to Linear Algebra   &lt;/span&gt;&lt;/strong&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;Gilbert Strang） MIT的教授，网上还有视频。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;482sr-0-0&quot;&gt;&lt;strong&gt;如果你对上面的脑洞感兴趣，&lt;/strong&gt;&lt;strong&gt;欢迎关注&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382937&amp;amp;idx=1&amp;amp;sn=d4510592a837c44fe75393c2578698d8&amp;amp;chksm=84f3cad8b38443ce6adcd155a2c45ee7707b4a9d8e48c05728aa7e93862475832bf89617025f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;巡洋舰的深度学习实战课程&lt;/a&gt;， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛， 感兴趣的小伙伴可以点击阅读原文。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;










</description>
<pubDate>Tue, 21 Nov 2017 15:40:39 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/j3MuNyjiAa</dc:identifier>
</item>
</channel>
</rss>