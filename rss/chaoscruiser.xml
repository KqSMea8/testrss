<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>读《科技想要什么》，说AlphaGo Zero的大新闻</title>
<link>http://www.jintiankansha.me/t/Z1BaMSbLnO</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/Z1BaMSbLnO</guid>
<description>&lt;p&gt;一年前，和朋友闲聊，他说AlphaGo的下一代是BetaGo，结果人家从Master升级成了Zero，俩个神经网络也变成了一个。一年前，人们讨论AlphaGo是否理解了围棋，人们举例说，如果围棋的棋盘变成了20乘20，那柯洁闭着眼睛都能虐狗，由此来说明AlphaGo并不懂围棋。 但有了从零开始的zero，改变了棋盘的大小，给我3天的时间，照样能够虐人类。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;还有说狗狗不懂人类选手常用的围棋定式的。然而，从Zero的论文中看出来，恰好是那些学会定式慢的狗狗，棋下的好。不同版本的狗狗，最终都学到了围棋的定式，但若是过早的将选择定式的几率提高，那么会限制对未知模式的探索。从这个意义上来说，围棋的定式，何尝不是一种过拟合。然而只有等人类见识到了全新的风格，才能够意识到自己的不足。&lt;/p&gt;

&lt;p&gt;之前我们反驳狗狗不懂围棋的论据，都被AlphaGo Zero打破了，但人类最擅长的是改游戏规则。给定一个选手最多只能记住10万张棋谱，下十万盘棋，在这样的限制下，人类在当下的技术条件下，无论如何都是赢家。但这说明人类理解围棋，学习围棋比AI快吗？答案是否定的。加上这个限制，说明人类由于自身的限制，将围棋变成了一个有限游戏，人类围棋的规则其实是在只记住十万棋谱，下过不多于十万盘棋时下出最好的棋，而AI的出现，将围棋变成了一个无限的游戏。&lt;/p&gt;

&lt;p&gt;这里不是说围棋的可能性变成了无穷的，而是说计算机去掉了存储的限制，狗狗可以记住其下过的所有左右互搏的棋局，而蒙特卡罗树则将最后的输赢反馈到了最初的每一次落子上，解决了奖励时间的不确定性&lt;span&gt;，&lt;/span&gt;而CNN则负责从中推导出该怎么评估当前的局势，将你的落子和整个棋局的大背景结合起来。这样的框架，适合无限游戏的假设。而人类棋手一开始学习定式，则是人类在其自身的限制下最佳的学习方式。人不必盲目的崇拜计算机，说到底，狗狗和人玩的是不同的游戏，自然应该有不同的玩法。&lt;/p&gt;

&lt;p&gt;说完了狗狗，我们将视线拉远，猜猜狗狗下一步想做什么。人们对于未来的想象，常常是线性的。即使对于想象力丰富如著名的科幻作家凡尔纳，他设想的人类登月的方式也只是用大炮，然而真正改变世界的创新，最初都是不那么显著的，没有多少人会注意到。所以与其看狗狗下一步能做什么，不如看看狗狗做不了什么。与其看具体的行业，不如给出算命式的趋势预测。&lt;/p&gt;

&lt;p&gt;有了AlphaGo Zero的框架，所有的完美信息环境下的零和式，有限个选择的策略游戏，都已经成了AI的天下。再结合AI战胜人类的德州扑克选手，对于即使不是一个信息完全公开的游戏，只要可能出现的选项是已知而未知的只是出现的概率时，AI占据绝对优势，也是必然的了。留给人类的唯一机会，就是不要去玩零和游戏，不去玩有限的游戏了。&lt;/p&gt;

&lt;p&gt;有本书就叫《有限和无限的游戏》，书中写道，有限游戏以取胜为目的，而无限游戏以延续游戏为目的。有限博弈者在边界内游戏，无限博弈者以边界为游戏对象。有限游戏旨在以一位参与者的胜利终结比赛，每个有限游戏都是为了结束自身。矛盾恰恰就在于，所有有限游戏都是在对抗自身。在这本书中，作者提醒读者转化游戏观，认识到生活其实不应当被看成是有限的游戏。&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdXzh90N8e8w3xCAIpwsdUgG1YlshggBCmZO4lzsFk7U18nUx81SjnjsnSPU5byzFIWWML761cWUg/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.4455445544554455&quot; data-w=&quot;303&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;凯文凯利在《科技想要什么》中对《有限和无限的游戏》十分称赞。书中写道：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;进化、生命、思维和技术元素都是无限博弈。它们的博弈就是让博弈持续下去，让所有博弈者尽可能地长时间参与。为了达到这样的目的，它们像所有无限博弈一样戏弄游戏规则。进化之进化就是如此。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;生活中我们最爱的事物──包括生活本身──都属于无限博弈。当我们参与生活博弈或技术元素的博弈时，目标不是固定的，规则不明朗，并且一直在变动。我们如何进行下去？好的选择是增加选择。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;无限博弈的目标是保持游戏的进行：摸索游戏的所有玩法，增加各种博弈，召集所有可能的玩家，扩展游戏的意义，倾尽所有，无所保留，创建宇宙中不太可能发生的博弈。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;弄清楚了无限博弈的思路，就能够再一个大的框架下去看狗狗战胜人类的这件事，狗狗的出现，将围棋这种有限的游戏，转化成了一个无限的游戏。游戏的目地不再是为了获得世界第一，而是为了探索出围棋中的所有玩法。狗狗胜利的方式，是狗狗背后的Deep mind巧妙的改变了游戏规则，而不断改变游戏规则，正是无限游戏唯一的规则。&lt;em&gt;&lt;br /&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;说完了哲学性的话题，这篇小文就以AI取代职业这个话题来结束吧。很多人会问自己，你的工作中有百分之多少是可以被AI所替代的，然后据此评估AI是否会取代你的工作，但从有限和无限的游戏这个角度来看，你要问自己的问题的答案会是更主观的。你问自己在做的工作，究竟是该被当成有限的游戏，还是无限的游戏。&lt;/p&gt;

&lt;p&gt;一个餐厅的服务员的工作，是自动化程度很高的，但这并不意味着未来餐厅服务员这个职业会消失，米其林餐厅，国宴会，服务员的岗位总是在的。一个服务员若是将自己的工作时间看成是零和的游戏，那么她必然会担心自己的岗位丢掉，而她的担心会使得她忽略由于游戏边界的改变而带来的新机会。而如果她只是将餐厅的服务员工作看成是无限游戏中的一部分，那么在机器人取代一步步取代服务员的过程中，她会随之成长，找到新的坏境下新的角色。你的担忧反映的更多是你对自身角色的看法，而不是事实。&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;更多阅读&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382963&amp;amp;idx=1&amp;amp;sn=53c1f03208ca7a41285566b9bf8aa83d&amp;amp;chksm=84f3caf2b38443e40428d245046814ac4ca8883c4403a88f68980b86e57b4c754759edf6eece&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;铁哥谈AI： 浅析阿尔法元之元&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382959&amp;amp;idx=1&amp;amp;sn=4e3f03464db9bf33225d9293d69c5eb6&amp;amp;chksm=84f3caeeb38443f8aa9f050568b0368b512851c70c355d1690c07c3b1c92c82fe5d22f0b41ec&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;机器学习：增加更多就业岗位&lt;/a&gt;&lt;br /&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; &lt;/p&gt;



</description>
<pubDate>Tue, 24 Oct 2017 05:34:13 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/Z1BaMSbLnO</dc:identifier>
</item>
<item>
<title>深度学习入门书单</title>
<link>http://www.jintiankansha.me/t/IO0qc1Nqz9</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/IO0qc1Nqz9</guid>
<description>&lt;p&gt;列书单之前，想再强调一遍学习方法（请参考&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382837&amp;amp;idx=1&amp;amp;sn=3fbfc8f640dae96efaadb3824f765300&amp;amp;chksm=84f3ca74b38443627ee4b0c38d2857fb40b3daa18ff0dbbc33c44146ffbfb9b3ea29567af1b0&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;教师节-说说学习方法-就拿AI举例子吧&lt;/a&gt;），只有先摆正了态度，才能够事半功倍。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;接着说说这个书单吧，书单里没有出现英文书和翻译书。英文书单已经有很多了，且能看英文书的朋友，最好就不要看书了，直接去看综述文章或者最新的论文和代码去。这里的书单是入门级别的，针对英语不怎么好的读者。书分成三类，一种是讲原理或综述，第二类是针对特定平台，第三类是结合具体的应用场景&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; width=&quot;auto&quot; /&gt;&lt;span&gt;    &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;阅读难度：一星&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceBgKNyXRzRUPmkuWo06djtqzXkzC0nZ9CGy8ssBsLYz7ZichRuUibTdicicicd51icRia1TLdDemsYiapVag/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.3653846153846154&quot; data-w=&quot;312&quot; data-type=&quot;jpeg&quot; data-backw=&quot;312&quot; data-backh=&quot;426&quot; /&gt;&lt;/p&gt;
&lt;h3 title=&quot;&amp;#x767D;&amp;#x8BDD;&amp;#x6DF1;&amp;#x5EA6;&amp;#x5B66;&amp;#x4E60;&amp;#x4E0E;TensorFlow&quot;&gt;白话深度学习与TensorFlow这本书覆盖了深度学习的诸多概念，内容全面，看完了这本书，你就懂了深度学习这个领域的行话了。书中有很多具体例子，作者有丰富的实践经验。另外这本书的姐妹版《白话大数据与机器学习》也不错，在APP 网易蜗牛阅读上可以免费阅读。&lt;/h3&gt;


&lt;p&gt;阅读难度：一星&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccQOduTGLky8BfGHuUzsqoNBeT60OLG1FrwmKTCBMTqt18bP8Uknib6iafqmUAvibfXuJOg91bvHSsJQ/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.309328968903437&quot; data-w=&quot;611&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;机器学习之路这本书从内容方面本书共包含两部分：机器学习篇和深度学习篇。这本书避过数学推导等复杂的理论推衍，介绍模型背后的一些简单直观的理解，以及如何上手使用。这本书适合有一些编程和自学能力，但数学等基础理论能力不足的人群。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; width=&quot;auto&quot; /&gt;    &lt;/p&gt;
&lt;p&gt;阅读难度：2 星&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccQOduTGLky8BfGHuUzsqoN6RJGEM6eoBrgzPOlevGf6IvDr8gGbMZPRQN1SvyFVUuUTbeljam6gQ/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.3428571428571427&quot; data-w=&quot;315&quot; data-backw=&quot;315&quot; data-backh=&quot;423&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这本书写的很基础，帮助读者快速了解keras在各个领域的应用，书中的例子打通了从工具准备、数据获取和处理到针对问题进行建模的整个过程和实践经验的全流程，以深度学习在推荐系统、图像识别、自然语言处理、文字生成和时间序列中的具体应用为案例，虽然每个案例都没有讲细，但是一本不错的入门书。&lt;/p&gt;

&lt;p&gt;阅读难度：2星 &lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccQOduTGLky8BfGHuUzsqoNd2QHic9g2FXjpQNXWsPVdUeOUjj56tjORMGvdwypfPtlatlibr9LP6eg/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;1&quot; data-w=&quot;363&quot; data-backw=&quot;363&quot; data-backh=&quot;363&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccQOduTGLky8BfGHuUzsqoNffdu7PMncV4ZdPdpKJdrHHAqGwVd74QwLf6AWD6FVVSbs9PfBXgrDQ/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.3333333333333333&quot; data-w=&quot;315&quot; data-type=&quot;jpeg&quot; data-backw=&quot;315&quot; data-backh=&quot;420&quot; /&gt;&lt;/p&gt;

&lt;p&gt;说起深度学习，不得不提tensorflow，关于这个最热的平台，推荐俩本入门书，关于这俩本书，CSDN上曾有人做过对比，综合起来，第一本书更加全面，第二本书更容易上手。&lt;br /&gt;&lt;/p&gt;



&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccQOduTGLky8BfGHuUzsqoNhcJM5IbLzbYVc1g0Bpwuepp0rReRJoAiblGrvTY3KEzFr8aYAQ7ouvg/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;1.3114754098360655&quot; data-w=&quot;610&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这本书目前正在预售中，因此不好评价。但作为一种与主流的深度学习框架都不同的动态的图构建框架，PyTorch值得了解。&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;阅读难度：   &lt;/span&gt;3 星&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccQOduTGLky8BfGHuUzsqoN7BgtWHhLnI7AicYqn1SdebXEEUEYIM7a2ToXa7t1VAuFmgCDGdaF5ZQ/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.4455445544554455&quot; data-w=&quot;303&quot; data-backw=&quot;303&quot; data-backh=&quot;438&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这本书是研究汉语自然语言处理方面的基础性、综合性书籍，从认知语言学的视角重新认识和分析了NLP的句法和语义相结合的数据结构。书中从自然语言处理的传统方法，结束到最新的基于深度学习的处理方法，可以使读者对自然语言处理整个行业有全面的了解。&lt;/p&gt;

&lt;p&gt;阅读难度 3星&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccQOduTGLky8BfGHuUzsqoNazFlcl9rFI7R8UH4NpYchp2XPib7nLNKNDI17EXxQSQRjQxIppQFeow/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.3113207547169812&quot; data-w=&quot;318&quot; data-type=&quot;jpeg&quot; data-backw=&quot;318&quot; data-backh=&quot;417&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这本书看似是轻松学，但读起来却并不轻松，&lt;span&gt;书中介绍了卷积神经网络中很多细节，&lt;span&gt;这些细节是决定了一个人对CNN的理解深度&lt;/span&gt;&lt;/span&gt;。书中介绍了深度学习在视觉领域的应用，从原理层面揭示其思路思想，帮助读者在此领域中夯实技术基础。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;duudf-0-0&quot;&gt;欢迎关注巡洋舰的深度学习课程， 深度强化学习将是重点：&lt;/span&gt;&lt;span data-offset-key=&quot;duudf-0-0&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382937&amp;amp;idx=1&amp;amp;sn=d4510592a837c44fe75393c2578698d8&amp;amp;chksm=84f3cad8b38443ce6adcd155a2c45ee7707b4a9d8e48c05728aa7e93862475832bf89617025f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;巡洋舰新年深度学习训练营计划&lt;/a&gt;， 这么课程， 将真正带你手把手的领略深度强化学习的魅力， 看你能不能读完后合作写一本深度学习的入门书，成为身边人眼中的大牛。下面是整个课程的思维导图，感兴趣的小伙伴可以点击阅读原文了解更多。&lt;/span&gt;&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7935540069686411&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdrg83hduKplaOkZeV6icFIST2rojIm4SLJSQU8CgNia1AYmETxrSibzh5P6vPiaOffICZibFcNKfichRhw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1148&quot; /&gt;&lt;/p&gt;

</description>
<pubDate>Mon, 23 Oct 2017 05:19:26 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/IO0qc1Nqz9</dc:identifier>
</item>
<item>
<title>铁哥谈AI： 浅析阿尔法元之元</title>
<link>http://www.jintiankansha.me/t/omFJ2C41aL</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/omFJ2C41aL</guid>
<description>&lt;p&gt;&lt;span data-offset-key=&quot;bi454-0-0&quot;&gt;今天早上被一条重大新闻刷屏：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;3jtcs-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;Nature- Mastering the game of go without human knowledge&lt;/span&gt;&lt;/span&gt;&lt;span data-offset-key=&quot;3jtcs-0-1&quot;&gt;， 阿尔法元超越自己的大哥-阿尔法狗。 这一代算法被deepmind命名为Alphago Zero， 中文阿尔法元，“元” 含有起点，创世之意。 总之，就是从零开始 ，其实这个元字用意很深， 一方面说， 这个算法是不需要人类数据指导，也不需要它哥哥（阿法狗）指导，就自己演化出来。 另一方面也可以理解为它可以开启新纪元。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dt5il-0-0&quot;&gt;当然， 同时谷歌也宣传了它的TPU， 只需要4台TPU运行几天的功夫就可以了。 那么， 这次的大新闻是不是一个谷歌精心策划的商业广告，还是真的隐藏天机。铁哥就来给大家解读一下阿法元和其背后的深度强化学习，看看这次的大新闻算不算得从零到一。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8ibcs-0-0&quot;&gt;如果大家了解计算机学下棋的事情，就会了解到几十年前，我们就已经用穷举法来解决棋类问题了，在国际象棋这类游戏里， 计算机会以比人脑快的多的速度推演两军对峙的未来，在运用零和游戏里固有的减少风险策略， 在1996年就可以让人类棋手甘拜下风。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;acaae-0-0&quot;&gt;穷举法不适用围棋，因为跟其灿若宇宙星辰的可能性搜索空间（每一步19*19可能，若干步骤后就是天文数字，这种由于可能性爆炸导致的悲剧也称为维度灾难），被称为人工智能界的mission impossible。 而在2015年， 梦幻被粉碎，原因在于深度卷积网络的幽灵终于潜入到了棋类游戏领域。 深度学习最擅长把高维度的问题自动的降维，从而解决了刚说过的维度灾难，如宇宙星辰般的搜索空间瞬间被压榨到很小，在此时的机器算法面前， 围棋无非是一个当年的国际象棋。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcps0Xjicz0kQJbhFWNb3Dev590WibnD2QZA8JbS69KEBdNIGTlzLDicZu2fQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;300&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;7ufh3-0-0&quot;&gt;然而当时立下首要功勋的深度卷积网络，却需要学习三千万组人类数据进行训练， 而整个训练过程需要的能量据说要耗费几吨煤炭。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;19ekg-0-0&quot;&gt;人们说，你秒杀人类智商的阿法狗无非是比人类看棋谱的速度快，难道还真的懂围棋吗？ 你所作的顶多是模仿，里面的强化学习到底有多少作用， 真的不知道。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;389o-0-0&quot;&gt;然而今天，阿法元却能够在不用那3000万数据的时候来个完胜阿法狗。从人工智能的技术角度看， 这是强化学习的胜利， 在不进行监督学习的情况下， 就可以达到一个高于人类的境地。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;cf1o3-0-0&quot;&gt;为什么强化学习如此重要？ 让我们先比较一下监督学习和强化学习的基本思想。 监督学习， 强化学习和无监督学习是机器学习的三大框架。 某一个意义说，监督学习是给定输入和输出，机器来学习输入和输出的关系，一个好的监督学习算法犹如一个预言家， 它能够根据自己之前见过的输入输出关系来预测未知的输入。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2psih-0-0&quot;&gt;强化学习呢？ 强化学习的三元素是状态，行为和环境奖励。 强化学习条件下， 学习者每一步看到的是它决策的行为结果， 然后导致下一步行动，为了最终游戏的胜利。 一句话说：强化学习强在决策。 监督学习是预言家，强化学习是决策家。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.48833333333333334&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsV4Mu5XbPHGfej0xjDpj72EibTct0ibav9n1Zzn4icv4IWzBMoaWTpialRA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;293&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;cj562-0-0&quot;&gt;我们一比就明白， 强化学习更像是一个日常决策中的人。我们看到一个老虎，监督学习帮你识别出来它是老虎，那么你可能刚说出来就被它吃了。 而强化学习告诉你赶紧跑，你可能活下来。 &lt;strong&gt;监督学习让你成为复读机，而强化学习让你称之为生物。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.29333333333333333&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsRxyf7PuFXI3NXVG0IB5N90pmc0QIdZBnEibf4yWCUwhichupUZgjtQkQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;176&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;bfpem-0-0&quot;&gt;再深一点想，其实学习是为了生存，是赢得game of life（想想那些不太读书就能过得很好生活的真是深谙强化学习的道理）。 强化学习赋予机器以灵魂。监督学习的那些任务反而是在这个宗旨之下产生的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;80nhn-0-0&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt;  回到围棋， 我们看看强化学习如何决策： 我们在好好理解一些一下“强化” 二字， 强化的意味是： 强化优势经历，反过来，就是弱化劣势经历。当你走了一部棋导致不好结果，之后被选入这一步棋的概率就降低， 而导致胜利的选择被不停的强化，直到你每次都延着最佳路径前进。这听起来很像进化， 而与进化的区别是，进化是严酷的客观环境对随机变化的生物的选择，而强化学习里的单元可以通过梯度下降主动调整策略。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a1bc6-0-0&quot;&gt;既然强化学习那么牛， 为什么阿法狗还用监督学习这个拐棍呢？一句话说，强化学习太难了！&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8s35-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;强化学习有两大难题：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ev461-0-0&quot;&gt;1， 奖励时间的不确定性： 今天的努力，可能明天回报， 可能十年后才有回报, 今天带来奖励的事情，明天可能就导致悲剧（比如吸毒很爽未来地狱） 对于游戏里的每一次决策，　你都无法获得立即的反馈，相比监督学习时时可以得到对和错的答案，这个信息实在太弱了， 用来指导学习，那是慢慢的（如何利用这个或有或无的信息，强化学习的一系列方法围绕而来，比如Q-learn）。 　&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2l540-0-0&quot;&gt;2， 探索与收益的平衡难以掌握： 有的人一辈子抱残守缺，７岁玩泥巴未来就永远玩泥巴。 有的人一辈子都在探索不同的方向，但是换来换去最终庸庸碌碌。而只有恰当把握探索收益平衡的，比如说27岁前读书去不同国家，27岁开始认准一个方向成为大佬，30岁前各种风流倜傥，30岁选个知书达理另一半从一而终。 强化学习始终面临是探索更多空间，还是开始用现在经验收益的矛盾。　&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;3cja1-0-0&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;这两点放到围棋这个搜索空间犹如宇宙星辰的游戏里，估计学习时间也要用生物进化的尺度算， 然而阿尔法元所用的强化学习算法，号称解决了这个问题。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ajql2-0-0&quot;&gt;仔细看它和它哥哥阿尔法狗的差别没那么大， 只不过这一次的神经网络完全由强化学习训练， 和蒙特卡罗树得融合可以算是完美。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6716o-0-0&quot;&gt;之前的阿尔法狗有策略和估值网络（都是深度卷积网络），策略负责把棋盘现在的状态转化为可能的行为概率， 这个东西被称为策略（policy，是由每个可能的行为概率构成的向量，简称策略向量） ，估值则是输入目前的棋盘状态得到最终结果的概率。 这两个网络在这一次被合成一个巨大的深度残差网络（卷积网络的一种）。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.9314079422382672&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsoH0hA9BP2pujxMyw7ZHia69xRjmMAibl7JhVWWsiaCaE9FebZrEpP0NKg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;554&quot; height=&quot;516&quot; width=&quot;554&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;7nudg-0-0&quot;&gt;Nature图： 深度卷积网络计算概率&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8uljh-0-0&quot;&gt;深度卷积网络擅长整体对图像信息进行编码， 我们可以把这个巨大的残差网络所作的事情看成白日梦者对未来的总体规划。 多层卷积本身的天性决定它擅长从这种19*19的格子图像总结出意思来，强化学习的信息一旦可以训练网络，就会产生意想不到的效果。而之后MCTS蒙特卡罗树则对这种初步的结论进行实践修正。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d3a31-0-0&quot;&gt;在这里回顾一下蒙特卡洛树是怎么工作的，说到蒙特卡洛， 这是大名鼎鼎的随机抽样方法。所谓树，大家一定可以想到决策树，树的节点是某一刻的状态，而枝杈代表一个决策（行为），而这里的蒙特卡洛树即生成整个决策树的过程，通过大量的实验（犹如蒙特卡洛抽样的过程）得到每个决策行为取胜的概率。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d3a31-0-0&quot;&gt;决策树从一个状态s出发，每个分支代表一个可能行为（a），而且有一个代表最终赢率的分数与之对应，我们选择分数最高的那个行为继续展开（下一次行动），得到新的状态，用相同的规则行动，直到游戏结束， 最终赢的走法加一分， 输的走法减一分，依次往复模拟无数次后，就会得到从s出发不同决策赢得比赛的概率。 这个过程酷似进化选择算法， 就是让那些有优势的选择有更高的繁殖子代概率， 最终胜出。虽说这仅仅是阿尔法元的一小步，却包含了著名的Q-learning和马尔科夫决策树的思想。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;qrgk-0-0&quot;&gt;我们来看每一步决策神经网络和蒙特卡洛树是怎么结合的： &lt;/span&gt;&lt;span data-offset-key=&quot;qrgk-0-1&quot;&gt;&lt;span data-text=&quot;true&quot;&gt;决策分为搜索阶段和行为阶段&lt;/span&gt;&lt;/span&gt;&lt;span data-offset-key=&quot;qrgk-0-2&quot;&gt;。假定现在我处在状态s，在搜索阶段神经网络对我所能做的所有行为（a）进行根据对未来的猜测进行预判&lt;/span&gt;，生成赢棋的概率v和策略向量p（s，a）。 当然这个预判开始很不靠谱， 蒙特卡洛树在此基础通过无数次模拟实践展开来（注意均是在状态s上），来实践出靠谱的策略向量pi（s，a）。&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt;  有了神经网络的帮助，蒙特卡罗树展开不是瞎展开， 也不是从零开始，每一个树的新分支上，我们都通过神经网络给它一个是正确步骤的先验概率（P）和初始的赢率（V），代表走它通向胜利的概率。在神经网络助攻下，蒙特卡洛树可以更快的更新策略向量（每个行为选择的概率）。此时搜索阶段结束， 我们从这个策略向量里通过抽样得到我们最终进行的行为，是为行为阶段。 这下一步棋还真不容易啊！&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.26666666666666666&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsiajKyaOtibGwOv1hLBtLtjgNtSAAYibPBwNaiapFvJPyWb8FFcsTOWCkibg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;160&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;77j4h-0-0&quot;&gt;Nature图： 策略更新的方法&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a1pa3-0-0&quot;&gt;最终当游戏结束的时候，神经网络的权重开始更新，这个更新的过程里，我们把整个游戏的过程分成很多小段， 比较神经网络预测的概率和蒙特卡洛树算出来的（策略向量之间的差异），以及预测结果与最终结果的差距进行梯度下降（梯度由如下公式得到，此处混合之前的策略和估值网络）。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.14333333333333334&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsWbnhR49iaFicbgX6lQ8jibSQyN8WvXlZ5cYhTkh1u7EibTbDcbDMWal7Dg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;86&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;9jrnd-0-0&quot;&gt;这样周而复始，我们可以推断，最终神经网络的预测将越来越靠谱，和蒙特卡洛树给出的分析越来越一致。 而围棋的套路也会被一一发明出来，所谓无师自通。&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.8633333333333333&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsQTc3L6c3EdUyfKoVVa0CpgQciacvMYiaHYcdDGYFQaps8Q0NOrXqoJJQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;518&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;5ibte-0-0&quot;&gt;Nature图： 看看右下的图，是不是很像人类选手常用的招！  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9c2ea-0-0&quot;&gt;为什么说阿尔法元敢叫元？ 如果从技术角度看，这一次的阿尔法元没有那么多新的东西，而是在之前基础上让强化学习进行的更彻底了，然而它所展示的深度强化学习的应用未来，却是十分诱人的。&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.35&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsRGYzWDxqCfib19LOQ0gfBSD7qFIIaSQ3bAfbA6ibr02JT5uPI4Oic2wiaw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;210&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;fmjkn-0-0&quot;&gt;图： 强化学习的胜利（蓝）对比监督学习（紫）和监督+强化学习（虚线）&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;987es-0-0&quot;&gt;首先，我们看到， 并不是每一件机器学习的事情， 都需要和数据，尤其是需要大量人力的标注数据死磕， 而是可以通过恰当的设立模拟器（比如此处用到的蒙卡树） 来弥补。阿尔法元不是不需要数据，而是数据都是自己模拟产生的。 模拟+深度强化学习， &lt;strong&gt;在简单的游戏规则下，一些复杂的行为范式可以进化出来，而且可以比人类设计的还好&lt;/strong&gt;， 这， 你就可以大开脑洞了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ckimk-0-0&quot;&gt;这件事在很多设计性的工作里实在是太诱人了。 无论是设计新材料，建筑，还是衣服，&lt;strong&gt;这些可变维度很高的事物，你都可以想象设立一个模拟仿真环境，再设立一个相应的神经网络去做各种尝试，最终设计出的结果有一个奖惩函数反馈，来让这个网络来学习。&lt;/strong&gt;这就打破了深度学习创业只和手里有大量数据的垄断者相关的梦魇。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8k7da-0-0&quot;&gt;这里的深度强化技术， 也才只展示了冰山一角， 在一类被称为SLAM的技术上， 深度强化学习被证明了强大的控制能力， 它能够驱动机器人在非常复杂的空间里进行探索无需GPS，对于这一类深度学习任务， 有别于alphago的任务，因为围棋属于完全信息的博弈， 而真正的空间探索，是通过感知系统探测到的不完全信息， 通过记忆在时间尺度上的综合，这一点，只有搬出大名鼎鼎的LSTM来对付了。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.6333333333333333&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpskhySEVQXKxWy56LKHsAJ0XXnA0hdiaAua0iaZrdWHaTzGDjdAO0xMQibQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;380&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;



&lt;p&gt;&lt;span data-offset-key=&quot;4nqss-0-0&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt;  能够控制运动的深度强化学习，迟早会改变工业界，它不仅是无人车里的核心技术， 更是对话，推荐系统， 金融交易， 甚至是图像识别的利器，几乎各类需要监督学习的事情，说到底强化学习都有实力。 你如果制造一个聊天机器人， 你当然希望它能够揣测你的意图和你谈情说爱而不是背书。 你要一个推荐系统， 你当然不需要它天天给你推你刚看过的小黄片，而是带着你探索一段BBC-性的秘密。  所以， 强化学习， 是人工智能的大势所趋啊。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.66&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcpsjUU1ewb6V3XTQvWIy5IuR5tHXrIBWdnPzhAQcE4h8zY3CB0KJXVAOQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; height=&quot;396&quot; width=&quot;600&quot; /&gt;&lt;/p&gt;

图：强化学习下的装配空间

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5631970260223048&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccPns0lxHhsOFyp82BuMcps8ic1kUm8dgUofdWt4AT4wib66t7NzYhTzVm1ribBxPmeFjgFB0jJhgjPA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;538&quot; height=&quot;303&quot; width=&quot;538&quot; /&gt;&lt;/p&gt;

图： 强化学习下的物流车间





&lt;p&gt;&lt;span data-offset-key=&quot;evrgp-0-0&quot;&gt;更有甚者，我们可以设立一个具有类似地球的物理环境的地方，让配备了深度强化学习系统的虚拟生物进行各种活动，看它们能否利用这个环境发现和利用其中的物理定律。&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;&lt;span data-offset-key=&quot;duudf-0-0&quot;&gt;欢迎关注巡洋舰的深度学习课程， 深度强化学习将是重点：&lt;/span&gt;&lt;span data-offset-key=&quot;duudf-0-0&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382937&amp;amp;idx=1&amp;amp;sn=d4510592a837c44fe75393c2578698d8&amp;amp;chksm=84f3cad8b38443ce6adcd155a2c45ee7707b4a9d8e48c05728aa7e93862475832bf89617025f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;巡洋舰新年深度学习训练营计划&lt;/a&gt;， 这么课程， 将真正带你手把手的领略深度强化学习的魅力， 看你能不能自己动手设计个阿尔法元&lt;/span&gt;&lt;/strong&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdrg83hduKplaOkZeV6icFIST2rojIm4SLJSQU8CgNia1AYmETxrSibzh5P6vPiaOffICZibFcNKfichRhw/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.7935540069686411&quot; data-w=&quot;1148&quot; /&gt;&lt;/p&gt;










</description>
<pubDate>Fri, 20 Oct 2017 19:19:26 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/omFJ2C41aL</dc:identifier>
</item>
<item>
<title>机器学习：增加更多就业岗位</title>
<link>http://www.jintiankansha.me/t/QmMHKirztV</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/QmMHKirztV</guid>
<description>&lt;p&gt;Nature一篇AlphaGo新版本完爆旧版本100:0的新闻刷爆炸了朋友圈。这条影响因子高达40的文章最本质有2点，第一，100:0是个结果，实际上，比赛10局，是10:0，比赛100局，是100:0，如果比赛1000局，那是1000:0。第二，击败世界冠军是旧版AlphaGo训练数据使用了好几个月，而新版的AlphaGo只用了三天。旧版的AlphaGo出现不知道用了多少时间，而我们可以清楚的看到，迭代到新版，只用了1年。&lt;/p&gt;
&lt;p&gt;这条新闻的意义是非凡的。如果理性而客观的看，最近这两年，专家，政策，纷纷聚焦清理低端人口，消灭贫困人口，借助于计算机领域最强大的进展，我觉这个计划可以更快速的实现了。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;机器学习，最本质的原理是，通过已有的经验处理相似的问题。算法并不能说过于复杂，但是计算机的运算能力在以往是难以提供的，得益于计算能力的快速发展，很多冗长的算法得以实施。AlphaGo取得现在的成就基于现在的计算机计算强度，再过10年，计算能力绝非今日可比。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;很多文科生对于AI的理解大多是计算机通晓人类情感，是错的，很多工科生对于AI现状的理解大多数所谓AI不过是高级穷举拟合，也是不充分的。技术的最终落脚点是能否支持生产力的发展，能否在市场中参与竞争，能否为行业带来利润。这当然是可能，而且是消灭低端人口的最佳方式。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;必须要承认的人，人类的社会结构就是金字塔状的，是分层次的，在计算机科学逐步发展的过程中，我们可以理解到，应该是一步步的逐步的慢慢取代的过程，而不是出现所谓一夜变天的过程，但是这种温水煮青蛙的过程，将会在未来，开始起步。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;能有简单经验构成的行业，必将慢慢降低门槛，并逐步消失。举个例子，古人云的好，久病成医，说的是普通人。而且，非常多的小疾病，可以在社区医院解决，那么，社区医院做的是什么工作呢？不过是问点话，开点药，“啊，张大点嘴。”不过如此。可是将来的某一天，你张开嘴，摄像头就能显示出是发炎，发炎到多少程度，要开什么药。如果你问题很大，直接转到上级医疗机构即可。而监督这些过程的工作人员，培训三个月就能上岗。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;这种设备的成本很高，取代这个行业的周期不会短，但是我们必须要意识到它的边际成本很低，接下来，只需要一个小的医疗室，有一个低成本的终端，有一根网线，借助于5G时代强大的数据传输能力，一切都变得方便，而这些，都可以在近期实现。回想你遇到的很多医生是不是态度非常恶劣？可是你为什么不知道无数医科生都找不到工作？这种行业被更新唯一的阻碍，就是既得利益集团。但是人类的发展终于是摧枯拉朽的，正如新版AlphaGo取代旧版的只需要1年，时间只需要3天。未来可期。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;没有人会失业的，只有好吃懒做的人才会失业。人工智能的发展会消灭低端的工作岗位是不可逆转的，但是机器学习也会催生无数相关行业的就业岗位，所以很多媒体所提及的对经济影响的忧虑，都不过是毫无经济学常识的小编瞎丁日扯。毫无历史经验，人类社会从森林古猿开始，科技就一直不断进步，何曾没有了工作机会？科技进步，从来不会减少就业岗位，谁想不明白，谁是傻逼。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;但是，还要更给力一点。否则这篇文章就写的没意义了。谷歌的工程师给了人们一个大大的惊喜，那就是机器学习实现了一个不需要人类现有经验而自我达成的任务。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;这个重大的意义在哪儿呢？我们知道，人类的经验都是不断试错得来，也许有些路，我们走了99步，都没有成功，于是人类就废弃了，然后写个标签告诉后来人，此路不通。哈哈哈哈其实，这条路没准走999步也不会成功。但是不依赖人类经验的机器学习，使得机器不在乎这个标签。机器只需要毫无表情的穷举，把所有的可能都给算一遍。结果那条走了999不通的路，机器发现走到1000的时候成功了，而且收益是10倍。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;人类的经验终究是限制了机器的想象力，而Nature这篇文章告诉我们，机器学习，不仅仅会使用已有经验，全面消灭低端行业，并且，还会给人类催生更多全新的经验。这些经验，人类可以从未涉足。人类能够从机器学习的成果中汲取知识，这是个反转。突破总是来的很慢，并一旦发生就爆发的更快。就像指数函数一样，也许它的时间变量非常小，以至于它的起始的值太小，小到连一个线性函数都要嘲笑它。可是指数终函数究是指数，在指数函数之上如果再有加成，那就是一个全新的世界。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;牛逼吹上天，还是要从小处落笔。这种科幻的未来已经不是我们这一代人要考虑的了，我们这一代人，能专注而努力，奋力且拼搏，不被当成低端人口消灭，就是最大的幸事。但是对于未来，终于是要保持敬畏的，想起欧成效在某一篇文章中描写降维打击时写到，&lt;br /&gt;&lt;/p&gt;

&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;em&gt;1840年，鸦片战争前夜&lt;/em&gt; &lt;br /&gt;&lt;em&gt;不列颠人和大清帝国指挥官&lt;/em&gt; &lt;br /&gt;&lt;em&gt;都在思考同一个问题&lt;/em&gt; &lt;br /&gt;&lt;em&gt;对方为什么就不害怕呢？&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Reference：&lt;/p&gt;
&lt;p&gt;所谓 “低端人口”的概念，是人日民报（海外版）在一篇题为《北上广常住人口增速放缓 专家：靠政策清理“低端人口”》的文章中首次提出的。&lt;/p&gt;

&lt;p&gt;本文来自 巡洋舰群友的知乎专栏，点击阅读原文，查看原文&lt;/p&gt;

</description>
<pubDate>Thu, 19 Oct 2017 18:56:11 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/QmMHKirztV</dc:identifier>
</item>
</channel>
</rss>