<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>[原创]读《人之彼岸》说说我心目中的AI与反乌托邦</title>
<link>http://www.jintiankansha.me/t/EHOS3SSh5L</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/EHOS3SSh5L</guid>
<description>&lt;p&gt;18年读的第一本书，是郝景芳的《人之彼岸》，全书的六个故事和两篇非科幻的思索，相映成趣，思考中提到的观点，都在小说中有所呈现。整本书的主题，用作者的话可以看成是&lt;span&gt;“人工智能在彼岸，我们在此岸。”也&lt;/span&gt;可以用书中提出的“逆图灵测试”来概括。图灵测试是通过人类无法分别和Ta交流的是人类还是电脑来判定智能水平的，而逆图灵测试则是通过呈现人类特有的性状，让人类能够和那些智能水平上已经不相上下的AI区分开来。全书写的六个故事，每一个都可以看成是逆图灵测试，故事中的英雄有的成功了，而有的则在故事的最后明白自己为什么没有通过测试。&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdV5esuvsoSc6k8dG6TcBrCk9Sabyh4Ss7Ip2lUDSPXubicA4MW9dXicB2Bkt7qBJzEStTAnJRDIe1A/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.4455445544554455&quot; data-w=&quot;303&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;在对这本书进行创造性的批判之前，想先说说对这本书整体的看法。文字简洁，论述到位，作者对认知心理学和人工智能的了解都深入本质。然而作者将AI进行的漫画式的夸张处理，我却不赞同。这本书中的AI，不管能力有多强，都缺少情感，永远表现的彬彬有礼，不会被愤怒等负面情绪冲昏了头脑，从艺术上来说，这样可以创造出戏剧冲突，凸显人与机器的不同，但是未来的AI真的会是这样吗？我觉得值得担心的不是机器背后的数字化逻辑侵蚀了那些使人类生活有意义的部分，而是机器用廉价的仿制品让人类不觉得使生活有意义的是爱与创造。&lt;/p&gt;

&lt;p&gt;关于未来AI的讨论，从更抽象的层次来看，可以看成是反乌托邦式的推演。人们更容易害怕的是通过脑机接口，全球化的AI知道了每个人一生中的所有想法，是机器通过概率的计算让人的自由意志变成了幻象，这些都不过是奥威尔式的1984的变种。但真正要担心的是赫胥黎式的未来，而从目前的趋势来看，这种未来是更有可能的。在前一种的未来预测中，恋爱的人不在有眼神的交流，是因为觉得指导约会的软件无法定量分析眼神中的信息，而在一种未来里，是因为人们戴上了假眼睛，可以通过改变眼睛的颜色来交流，并把这叫做眼神的交流。&lt;/p&gt;

&lt;p&gt;大前研一有两本书，一本叫《低欲望社会》，另一本叫《低智商社会》，这俩本书虽然说的是日本，但在全球化的大趋势下，书中所说的也多少适用于其他国家。书中所说的低欲望社会，主要指的是年轻人缺少好奇心和上进心，不管对消费还是恋爱，都缺少兴趣，只想宅在家里。这看起来和人工智能没有半毛钱关系，但是若不是有一个智能的网络来保证这些人基本的生存需求，那么想要维持这样的低欲望社会，是不可能的。&lt;/p&gt;

&lt;p&gt;然而按照常理推断，人类的需求金字塔是普世的，没有人会只安逸于最底层需求的满足，而不去追求自我实现。要想解释这个矛盾，我们就要看看满足自我实现的需求，有几种途径。身体力行的去做自然能让人有成就感，可人脑中的镜像神经元决定了人可以不需要自己去冒险，只需要通过冒险的故事，就能够差不多的体会到实现自我是怎样一种感觉。而这正是为什么会有低欲望社会的原因。虚构的游戏和影视剧让人们可以长久生活在幻想中。&lt;/p&gt;

&lt;p&gt;AI的进步会使的让人停留在幻想中变得更容易，就拿当下已有的技术来说。个性化的推荐会给你那些会让你反复点击的内容，而AR的进步会让内容的呈现变得难以分清真假。不需要脑机接口这样的黑科技，只要未来几十年，人类最聪明的大脑还是将精力放在获取更多的点击，而不是去探索太空，那么这种未来就会越来越变成现实。&lt;/p&gt;

&lt;p&gt;人类作为万物之灵，不止在于创造了，还在于其心智中的无用之大用，比如认为人生有比利益优化更重要的意义，能感受得到伟大艺术家给人传递的震撼。这是人类区别于机器的更基本的特征，不是常识，心智理论或者信息整合等具体的能力，而是一种一旦说出来就没意思的那点意思。正是因为不能说，所以真正需要提防的不是奥威尔式的禁止和无视，而是对这种精神的一种降级后表达。比如我中学时喜欢读李白的诗，但若是他诗中的句子出现在语文考试的阅读理解中，让我不得不写下干巴巴的中心思想，那这首诗，至少在那一刻就算毁了，就不会再让我感受到心灵的震动了。&lt;/p&gt;

&lt;p&gt;关于AI的讨论，最终都要回到该如何做好一个人的层面上。《人之彼岸》这本书在其最后一章，讨论了人工智能时代的教育，作为一个母亲，她谈论的是怎样去教育孩子。而这里想说说该怎么对自己进行教育。这里说三点，第一是回归到原始的材料上，在听他人的转述之前，先去看看第一手的信息来源是怎么说的，再看看他人根据文本进行的展开。要进行信息整合，就不能只根据关键词去做联想，去构建知识图谱，这机器也会。人的作用是将自己的亲身经验加入到文本的理解中，机器的理解是做减法，人的理解是做加法。&lt;/p&gt;

&lt;p&gt;第二是关注信息的网络结构，要去深挖那些处在网络中心的知识点，这也是人能够进行小样本学习的关键。人类识别狗狗，不是通过数万照片的持续训练，而是在头脑中构建了关于狗狗这个概念的一张网，第一次见到狗狗，学到了叫声，大小等核心的不变的特征，第二次注意到了狗狗的尾巴，耳朵毛色等次要特征，从而在第三次见到狗就能认出了。通过将概念按网络拆解，人可以在学会了狗狗这个概念之后，就可以将之前的经验用在识别狗狗的品种上。这正是机器所无法做到的，深度学习可以做到层次化，却无法体察出观念与观念之间的驱动关系网。&lt;/p&gt;

&lt;p&gt;第三点要提醒的是去学习一些看起来无用的知识，这是人之为人最不同的一点，机器现在已经有注意力，有创造性，未来也注定会有主动的行为。但机器不会去做超越胜败的尝试。对于机器来说，没有优化的目标或评价标准，就没有了存在的意义，但人类却可以自己通过在无用的尝试中找到的规律，不断为自己创造新的标杆，在通过艺术，文学等来向更多人展示自己认为的有意义的生活是怎样的。所以去了解那些没有直接用途的知识，是为我们找到船，而实用的知识不过是桨，没有了船，在陆地划的浆再大，也走不远。&lt;/p&gt;


&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;扩展阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383164&amp;amp;idx=1&amp;amp;sn=0cfac710d4d5783ed06bbdb694828409&amp;amp;chksm=84f3cb3db384422b11c90bf7826cc7b52a3f74176442fb28e6ebc27b5e44c9d1ef33f39d077e&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;多余的话 借深度网络说说最近发生的几件事&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;


</description>
<pubDate>Sat, 06 Jan 2018 04:11:12 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/EHOS3SSh5L</dc:identifier>
</item>
<item>
<title>你所不能不知道的CNN</title>
<link>http://www.jintiankansha.me/t/fJWHbpOdQ8</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/fJWHbpOdQ8</guid>
<description>&lt;p&gt;说起CNN，最初人们想到的都是某电视台，但等过几年，人们想起的多半是深度学习了。&lt;/p&gt;

&lt;p&gt;应该说， CNN是这两年深度学习风暴的罪魁祸首， 自2012年， 正是它让打入冷宫的神经网络重见天日并且建立起自己在人工智能王国的霸主地位。&lt;/p&gt;

&lt;p&gt;如过你认为深度学习是只能用来理解图像的，你就大错特错了， 因为它的用途太广了，上至文字，中有图像， 下至音频， 从手写数字识别到大名鼎鼎的GAN对抗学习， 都离不开它。&lt;/p&gt;

&lt;p&gt;不过要了解CNN，还是拿图像做例子比较恰当。一句话来说CNN图像处理的本质，就是信息抽取， 巨大的网络可以抽取一步步得到最关键的图像特征， 我们有时也叫自动的特征工程。&lt;/p&gt;

&lt;p&gt;CNN的建造灵感来自于人类对视觉信息的识别过程。 人脑对物体的识别的第一个问题是： 对应某一类对象的图像千千万， 比如一个苹果， 就有各种状态的成千上万状态， 我们识别物体的类别，事实上是给这成千上万不同的图片都打上同一个标签。&lt;/p&gt;
&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.6863468634686347&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJI259ewy6Db9CG9xFdiaf6yOwWXVVwibWTmWa5PqZBk001mkUP0NiapFIOw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;271&quot; width=&quot;271&quot; /&gt;CNN的灵感来自人大脑
&lt;p&gt;物理里管这种一个事物的结果与一些列的变化都没有关的特性，叫不变性， 比如如果你转动一个苹果任何一个角度它都是苹果， 这就是苹果有旋转不变性，但是数字6就不行， 如果你给它旋转特定角度它就变成9了， 它就没有旋转不变性。&lt;/p&gt;

&lt;p&gt;我们人通常可以无视这些变化认出事物来，也就是把和这种变化有关的信息忽略。如果我们对图像进行识别， 事实上我们的算法就要有人的这种本领， 首先让它学会什么东西与真实的物体信息是无关的。&lt;/p&gt;

&lt;p&gt;就拿数字识别举个例子吧， 一个数字是什么，虽然与旋转的角度有关系， 但与它在图片中的上下左右没关系， 我们管这种不变性叫平移不变性。&lt;/p&gt;

&lt;p&gt;解决这个问题，最粗暴的一个方法是制造很多的样本，比如把“1” 放在很多不同的位置，然后让机器在错误中学习。 然后穷尽所有的位置， 不过我相信没有人是这么完成对物体的识别的。&lt;/p&gt;

&lt;p&gt;那怎么办？CNN中的卷积正是这一问题的答案，因为卷积操作本身具有平移不变性（我知道听起来不明觉厉 ，请看下文）。&lt;/p&gt;

&lt;p&gt;卷积，顾名思义， “卷”有席卷的意思，“积“ 有乘积的意思。 卷积实质上是用一个叫kernel的矩阵，从图像的小块上一一贴过去，一次和图像块的每一个像素乘积得到一个output值， 扫过之后就得到了一个新的图像。我们用一个3*3的卷积卷过一个4*4的图像， 看看取得的效果。&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6847222222222222&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJIU7jaZqUeskJShdjW1xADTKJvormu9ia4F2ZPPLcpe1YAaVic2935Om3Q/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;800&quot; /&gt;卷积的数学过程
&lt;p&gt;一个卷积核就像一个小小的探测器， 它的DNA是被刻录在卷积核的数字里的， 告诉我们它要干什么， 而卷积核扫过图片，只要它的DNA是不变的，那么它在图片上下左右的哪个位置看到的结果都相同， 这变是卷积本身具有平移不变性的原理。 由于这种不变性， 一个能够识别1的卷积在图片的哪个位置都可以识别1，一次训练成本，即可以对任何图片进行操作。&lt;/p&gt;

&lt;p&gt;图像处理领域，卷积早已有另一个名字 ， 叫做滤镜，滤波器， 我们把图像放进去，它就出来一个新图像，可以是图像的边缘，可以是锐化过的图像，也可以是模糊过的图像。&lt;/p&gt;

&lt;p&gt;如果大家玩过photoshop， 大家都会发现里面有一些滤镜，比如说锐化，模糊， 高反差识别这一类，都是用着类似的技术，这样的技术所作的事情是图像的每个小片用一个矩阵进行处理，得到一个画面的转换 。 我们有时候会说低通和高通滤镜 ，低通滤镜通常可以用来降噪， 而高通则可以得到图像的细微纹理。 你玩photoshop，玩的就是卷积，卷积核里面的数字定了， 它的功能也就定了。&lt;/p&gt;

&lt;p&gt;为什么这样做有效果了？因为图像的特征往往存在于相邻像素之间， kernel就是通过计算小区域内像素的关系来提取局部特征，可以理解为一个局部信息的传感器， 或物理里的算子。&lt;/p&gt;

&lt;p&gt;比如提到的边缘提取滤镜， 它所做的物理操作又称为拉普拉斯， 只有像素在由明亮到变暗的过程里它才得1， 其他均得0，因此它所提取的图像特征就是边缘。 事实上我们知道图像中的信息往往包含在其边缘，你给以一个人画素描， 一定能够完全识别这个人 。 我们通过寻找到信息的关键载体-边缘， 而把其他多余的信息过滤掉，得到了比第一层更好处理的图像， 大大减少了需要搜索图像的可能性。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.7507836990595611&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJIKRaoRHBpH3zugrS3Fn9jIYaNRDrvHqsY0seaDXaxyrLEUqnSsmEJGw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;&quot; width=&quot;638&quot; /&gt;卷积的边缘抽取过程
&lt;p&gt;常用于卷积的Kernel本质是两个： 第一， kernel具有局域性， 即只对图像中的局部区域敏感， 第二， 权重共享。 也就是说我们是用一个kernel来扫描整个图像， 其中过程kernel的值是不变的。这点就可以保证刚刚说的平移不变形。 比如说你识别一个物体， 显然你的识别不应该依赖物体的位置。 和位置无关， 及平移不变。&lt;/p&gt;

&lt;p&gt;那卷积如何帮你从不同的图形中识别数字1了？数字的尖锐的线条会让卷积的值很高（响起警报）。无论你1出现在图像中的哪一个位置， 我的局部扫描+统一权重算法都给你搞出来， 你用同一个识别1的卷积核来扫过图片，voila，任何一个位置我都给你找出来。&lt;/p&gt;

&lt;p&gt;那卷积和神经网络有什么关系了？答案是卷积扫过图像，每一个卷积核与图像块相乘的过程，都可以看作是一个独立的神经元用它的神经突触去探测图像的一个小局部，然后再做一个决策，就是我看到了什么或没看到什么。整个卷积过程， 不就对应一层神经网络吗？啊哈， 整个卷积过程相当于一层神经网络！&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6708333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJIICwDf8icCuSiaSsicdKTJXGtAlA0FzVYW7M3OXraicLGlNNIwp6fibjPZzQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;878&quot; /&gt;一个个小探测器一般的神经元
&lt;p&gt;刚刚说了卷积是一个能够对图片中任何位置的同一类信息进行抽取的工具， 那么我们还讲到我们除了抽取， 还要做的一个工作是，取出重要信息，扔掉不重要的，实现这一个的操作，叫做pooling&lt;/p&gt;

&lt;p&gt;但是大家注意，这个时候如果原图像是28*28， 那么从kernel里出来的图形依然是28*28， 而事实上， 事实是上， 大部分时候一个图像的局部特征的变化都不会是像素级。我们可以把局部特征不变形看做一个假设， 把这个假设作为一个数学公式加入到卷积层里帮我们过滤冗余信息， 这就是pooling所做的事情 -也就是扔掉你周边得和你长得差不多得那些像素。&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5216666666666666&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJIScj5wqr3aLUCNmVqYd19HuZQo1Kxcv0efULV2kcEz9EGduLibXh3lQQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; width=&quot;600&quot; /&gt;Max Pooling的数学过程&lt;/p&gt;

&lt;p&gt;Pooling的本质即降采样，以提升统计效率，用一个比较冠冕的话说是利用局部特征不变性降维 ，pooling的方法很多，常见的叫做max pooling，就是找到相邻几个像素里值最大的那个作为代表其它扔掉。&lt;/p&gt;

&lt;p&gt;这样经过从卷积到pooling的过程， 在识别1的任务里，我们可以验明在每个小区域里有没有存在边缘， 从而找到可能存在1的区域。 在pooling的终结点， 我们得到的是一个降低维度了的图像，这个图像的含义是告诉你在原有的图像的每个区域里是含有1还是不含有1， 又叫做特征图。&lt;/p&gt;
&lt;p&gt;好了，我们可以从一堆图片中识别出1了， 那么我们怎么搞定2呢？ 我们把2写成一个Z型， 你有没有思路我们如何做到这点？ 我们不能只识别竖着的线条，还需要识别横向的线条，记住，一个卷积层只搞定一个特征，如果你既要找竖线也要找横线， 我们需要两个不同的卷积层，并且把他们并联在一起，&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;1.0194444444444444&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJINwr565frR5WvtFweXQLyV05un9UicfU8hZCv51TibnBYF8L5XE6BFgIw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1414&quot; /&gt;手写数字识别
&lt;p&gt;然后呢？ 横线对应一张特征图， 竖线对应另一个张特征图， 如果要识别2， 你无非需要比较这两张特征图，看是否有哪个位置两个特征图同时发生了警报（既有横线又有竖线）。&lt;/p&gt;
&lt;p&gt;这个比较的过程，我们还是可以用一个卷积搞定（理由依然是平移不变性）！&lt;/p&gt;
&lt;p&gt;这个时候， 新的卷积层对之前并连的两个卷积的结果做了一个综合， 或者说形成了一个特征之特征， 即横向和竖线交叉的特征。&lt;/p&gt;

&lt;p&gt;这里把我们的理论可以更上一层路。 深度意味着什么？ 我们想一下， 要正确的识别一个图像，你不可能只看变，也不可能只看边角， 你要对图像的整体有认识才知道张三李四。 也就是说我们要从局部关联进化到全局关联， 真实的图像一定是有一个全局的，比如手我的脸， 只有我的眼镜，鼻子耳朵都被一起观察时候才称得上我的脸，一个只要局部，就什么都不是了。如何提取全局特征？&lt;/p&gt;

&lt;p&gt;从一个层次到另一个层次的递进， 通常是对上一层次做横向以及纵向的整合（图层间的组合或图层之内的组合或两者），我们的特征组合是基于之前已经通过pooling降低维度的图层，因此事实上每一个神经元决策的信息相对上一层都更多，我们用一个学术名词 – 感受野来表述一个神经元决策所涵盖的像素多少， 上一层次看到更多的输入神经元， 因此感受野看更多了 。 越靠近顶层的神经元， 所要做的事情就越接近全局关联。&lt;/p&gt;
&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.459214501510574&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJITZicswJMbK60yq98JmMiab3YziaicmZAoib9PiaQxfAibX3xJrrpoqzaOcklg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;331&quot; width=&quot;331&quot; /&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5631229235880398&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJIvMPdtamMf7XC3G9EA0u14JtXWroPKsKHrQia4ibTJ9QELHPBfHEDRx7A/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;602&quot; width=&quot;602&quot; /&gt;越深，感受野越大， 表示越抽象
&lt;p&gt;这和物理学的一个基本方法--尺度变换有着异曲同工之妙（我们后面讲）， 也是提取全局信息的一个非常核心的办法，我管它叫级级递进法。 你一级一级的进行对画面进行降采样， 把图像里的四个小格子合成一个， 再把新的图像里四个小格子合成一个， 直到一个很大的图像被缩小成一个小样。每一层的卷积，都不是一个卷积，而是一组执行不同特征提取的卷积网络，比如我刚刚说的 不同方向的边缘沟成的一组卷积， 你可以想象后面有不同大小的角度组成的一组网络， 他体现了在一个空间尺度上我们所能够达到的特征工程。&lt;/p&gt;

&lt;p&gt;如此级级互联， 越靠上层感受野就越大。 整个CNN网络如同一封建等级社会，最上层的，就是君王，它是整个集团唯一具有全局视野的人，下一级别， 是各大领主，然后是领主上的风尘，骑士，知道农民（底层神经元）。&lt;/p&gt;

&lt;p&gt;我们把刚刚的全局换一个词叫抽象。深度卷积赋予了神经网络以抽象能力。 这样的一级级向上卷积做基变换的过程，有人说叫搞基（深度学习就是搞基），深一点想叫表征， 和人的思维做个比喻就是抽象。 抽象是我在很深的层次把不同的东西联系起来，CNN教会了我们事先抽象的一种物理方法。&lt;/p&gt;

&lt;p&gt;到目前为止， 我所描述的是都是一些人工的特征工程，即使网络在深，顶多说的上是深度网络，而与学习无关。我们说这样一个系统（mxnxpxz）， 我们要人工设计，几乎穷经皓首也可能做的都是错的。我们说， 这样的一个结构， 只能靠机器自己学，这就是深度学习的本质了， 我们通过几条basic假设（正则）和一个优化函数，让优化（进化）来寻找这样一个结构。 Basic假设无非图像的几个基本结构， 体现在几个不变形上，物理真是好伟大啊。&lt;/p&gt;

&lt;p&gt;深度学习的训练，就是计算机帮助人完成了机器学习最难的一步特征工程（特征工程本质就是基变换啊）。以前人类穷尽脑汁思考如何做图像识别， 是寻找人是如何识别图像的， 希望把人能用来识别物体的特征输入给计算机， 但是现在通过深度卷积，计算机自己完成了这个过程。&lt;/p&gt;

&lt;p&gt;卷积网络在2012 年的发展趋势， 大家可以关注几个方向：&lt;/p&gt;

&lt;p&gt;1， 更深的模型 ： 从AlexNet到VCG19 ，High way network 再到残差网络， 一个主要的发展趋势是更深的模型。 当你采用更深的模型，经常你会发现一些神奇的事情发生了。 当然网络的宽度（通道数量）也在增加。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.7507836990595611&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJI4MgHzMgW8BpgRIUIwjaZEib5mXYpPxWQ3O4h9lIagdzXlFTDrnuJ6sQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;&quot; width=&quot;638&quot; /&gt;这只是最初级的CNN&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5626959247648903&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJIfQsZBwppJXcjH5e8rWOViaefnsstpzajyFibZfshKjl6wZGibFrbl9Cicg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;&quot; width=&quot;638&quot; /&gt;这也只是小菜一碟
&lt;p&gt;2， 更通畅的信息交换 : 深，带来的第一个问题是训练困难， 反向传播难以传递。 从残差网络， 到目前开始流行的Dense Network， 一个主要的发展趋势是不同层级间的信息的交换越来越通畅。 我们逐步在不同层之间加入信息的直连通道。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6652777777777777&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJI1wS4QUHOtwmDrfIsmNdeYURdybYTjibibicK33KIiaxasE0kEJ6TVrFMEg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1504&quot; /&gt;Dense Network
&lt;p&gt;3， 与监督学习之外的学习方法的结合， 如迁移学习， 半监督学习， 对抗学习， 和强化学习。 后两者的有趣程度远超监督学习。&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; 
&lt;p&gt;4， 轻量化， CNN网络越来越深， 使得网络的文件动辄装不下， 这点使得CNN网络的轻量化部署成为重点， 我们希望在性能和能耗中取中。 一个很好的办法是对网络权重进行减枝，去掉不重要的权重， 另外一个是把每个权重的数据位数本身缩减，甚至是使用0和1表示， 虽然看上去我们丢失了很多信息， 但是由于巨大网络中的信息是统计表达的，我们到底损失多大还真不一定。&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5319148936170213&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceukHX94qAOhC6RWQ9zCzJImjNnqhBaSKLHdmb6kBX4qSSvIZBSRlx6icey6W4xzuyhlTVZKBBNNDQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;658&quot; width=&quot;658&quot; /&gt;酷似生物过程的剪枝处理

&lt;p&gt;以上是CNN的小结， 不要以为图像处理与你无关，我刚刚说的其实一篇文章如果你把它转化为一个矩阵无非一个图像， 一段音频你给它转换成一个矩阵无非一个图像， 你看， 都可以和CNN挂钩。&lt;/p&gt;

&lt;p&gt;我想说，无论你是做什么的， 无论是苦逼的计算机工程师， 游戏设计师，还是外表高大上的金融分析师，甚至作为一个普通消费者， 你的生活以后都和CNN脱不开干系了 ， 预知更多情报还请关注：&lt;/p&gt;

&lt;p&gt;巡洋舰的深度学习实战课程， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛。刚刚讲的方法都将在课程里详细展开。&lt;/p&gt;

&lt;p&gt;目前课程线下版本已经基本报名完毕（特殊申请可加一到两个名额）， 为了缓解众多异地学员的需求， 我们提出一个线上加线下的课程简版， 课程包括全部课程视频， notebook作业， 和一个课程模块的来京线下实践机会， 名额限5名，预报从速，&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;有兴趣的可加 陈欣 微信 ： &lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfCFEFrIh4CD3HnwF5a6d9gqk3NhIsY8ThV50SQ5ut1tiaRVs5lSnvrYRqWuJNgxJTXTZ9fu54micsw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;800&quot; /&gt;&lt;/p&gt;

</description>
<pubDate>Fri, 15 Dec 2017 16:55:06 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/fJWHbpOdQ8</dc:identifier>
</item>
</channel>
</rss>