<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>[原创]青春为何那么感人的三个理由</title>
<link>http://www.jintiankansha.me/t/DVbTYPc7i4</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/DVbTYPc7i4</guid>
<description>&lt;p&gt;最近看一部电视剧，叫“你好旧时光”，其中不止一次哭得不要不要的，记得上次看电影落泪，还是看“我的少女时代”，再之前是看“新闻编辑室”，再之前还是青春片，记不清是不是“那些年我们追过的女孩”。其中的新闻编辑室看起来是说职场的传媒剧情片，但由于这部片中的人物各个都充满了理想主义的色彩，片中成年人的恋爱模式也特别像高中生，所以当我三刷的时候，才发现这剧内核其实还是青春片。我接下来就想，为什么青春片能这么感人了？有什么共同的元素一直都会出现？这个原因和长大以后的生活有什么关系了？&lt;/p&gt;

&lt;p&gt;简单的说，青春片中都会出现“那怕与世界为敌，也要坚持”唐吉珂德式的场景，不管是为了爱情友情还是想要做成的事。但这不是深层次的区别。青春真正感人的是“知道这件事是对的就去做”的简单，不管有没有舞台，有多少观众，我就是要展示自己的本来面目。而成年人则不会这样，或者说那些过早成熟的人也不会这样。&lt;/p&gt;

&lt;p&gt;多少成年人说要减肥，他们是不知道该怎么做吗？是需要一个app去提醒，甚至一个基因检测来帮你确定减肥方案，再加上打卡分享去帮你完成吗？答案不是的，所有想减肥的人都知道该少吃多运动，只是他们没有了当初那份想做就做的简单和坚持，而是必要外界的动力来激励自己做一件自己内心认为是对的事。当你需要外界的激励才能去开始尝试自己想要完成的事情时，你的青春就烟消云散了，你也不具有怀念青春的资格了。&lt;/p&gt;

&lt;p&gt;我每每看到朋友圈晒自己的跑步记录，读书背单词的打卡或者请别人监督自己运动的状态就很不解。做这些事情本来就是自己想做所以才去做的，怎么变成了拿出来展示的，怎么都这么有表演欲，于是就屏蔽了所有晒这些人的朋友圈。我觉得人变得不单纯，就是从开始把那些为自己做的事情变成为别人做开始的。我只和单纯的人做朋友，只有这样才能让自己保持单纯。&lt;/p&gt;

&lt;p&gt;《新闻编辑室》中最后一集的标题是“We just decided to do it”，其中的插曲《How I got  to memphis》歌词写的道尽了青春就该有的无怨无悔。爱不是因为自己能够到，只是为了培养自己爱的能力，做这个决定不是因为会获得什么，而是为了不要下一秒的自己看不起这一秒的自己。当你爱的不够深沉的时候，你就会有贪嗔痴带来的苦恼，就会戴上虚伪的假面。&lt;/p&gt;


&lt;p&gt;青春片里的第二个感人之处是其亲密无间的关系，但这也只是表象，无话不谈的朋友的背后是不把人区分开的社会坏境。真正让我们感动的是能够不主动将人与人区分开的那一群人。年少时和好友共读福柯，当时不觉得惩戒和规训为什么能摧残人性。如今想来，正是由于有那么多的惩戒与规训，才导致人早早的由内在驱动转向了外在驱动。这个转换一旦完成，就很难回去，除非你又能像青春年少时那样爱的奋不顾身了。&lt;/p&gt;

&lt;p&gt;福柯主要的时间花在写精神病这个被创建出的概念，用来折射现代性的将人机械的分出了正常不正常的俩类。而如今，移动互联网上的广义的知识付费正在做着同样的事情，之所以是广义的知识付费，是因为其包括了所有通过告诉你你是谁来赚钱的行业。&lt;/p&gt;

&lt;p&gt;培训业的逻辑是在你简历上增加一项技能，而知识付费带来的成就感是在自己的内心自画像上将自己标为一个精英，一个读书破万卷的文化人。这俩者干的都是将特定人从人群中区分出来的生意，只有区分开来，才会让你有优越感从而愿意持续付费。不要扯什么学习带来的心流体验，在碎片时间，即使难度处在挑战区，也只是不觉得无聊而已。真正心流体验的前提是你只专注做一件困难事，而不是在地铁上，洗内衣时听别人来讲不那么无趣的事。&lt;/p&gt;

&lt;p&gt;通过将某个人从人群中区分出来，从而让特定的人获得信息优势，以此为基础的服务还包括最近发展迅速的基因检测。在绝大的数检测产品没有达到医学级的认可度时，基因检测做的是变种的知识付费和个性化推荐，告诉你自己有哪些不同之处。然而由于大多数人还不了解统计意义上的区别意味着什么，也不知道自己知道这些区别能做什么，或者知道了但是不想去做，所以受众的接受度不高，觉得无法和自己生活联系起来。&lt;/p&gt;

&lt;p&gt;但所有关于人的知识，都应该是教会你该如何和自身的不完美讲和，而不是将你和他人区分开。你告诉读者一个名人的事迹，一本书的梗概，不是要让他拿去作为谈资或者PPT的材料，而是要引导他自己思考从中获得关于自己该怎么做决定的启发。罗胖擅长的是第一类，的确第一类也适合这个充满了大人的世界，于是作为商人的他将自己的价值观强加到了所有得到讲师上，顺便也毁掉了我曾经很喜欢的万维刚和熊逸。&lt;/p&gt;

&lt;p&gt;就像我中学时拿到课本，第一时间要看看语文中的课文，我就怕老师的见解毁掉了好文章，本来好好的一篇文章，老师非要在旁边要你记笔记誊抄官方的所谓中心思想，就如同清蒸的海鲜边被放了一大坨咸菜，完全没有了食物本来的鲜味。这方面知乎的私家课和喜马拉雅做的就不错，就像脱口秀应该有的样子，不像得到的内容，听起来比阅读原书都更费神，你需要时刻警惕，看看Ta又在用什么套路，又在夹带怎样的私货。&lt;/p&gt;

&lt;p&gt;忍不住吐槽两句，回到青春片。青春片里那不非阶级，不非彼此的懵懵懂懂，正是由于现代性代表的将人区分开的知识还没有入侵的太深。福柯在《疯癫与文明》中写道：“知识变得越抽象复杂，产生疯癫的危险性就越大”。现代的知识付费，例如得到那种试图通过一个体系化的概念网络，其效果是使得知识变得抽象复杂，Ta看起来是在做简化，但只要是体系化的，就必须有隐含的逻辑线索，只是Ta没有展示而已。就像马克思主义本来很深刻的洞见，被斯大林为了宣传的目地体系化成了机械的教条的辩证法，反而成了马克思想要批判的费尔巴哈的理论。所以想通过一个系统化的知识来武装自己，只会增加自己成为他人眼中成为疯子的概率。&lt;/p&gt;

&lt;p&gt;真正能让自己和自己的不完美讲和，从而获得心安增加幸福感的知识一定不是由抽象的概念串起来的。而是取之于鲜血淋漓的生活本身的，Ta要做不是和世界去争辩，而是去告诉你另一个为何对着世界如此眷恋的理由。柴静的《看见》中写道她和她的调查记者伙伴在路上唱起郑智化的“蕾丝花边”，我想这首歌很适合在这里放放。&lt;/p&gt;


&lt;p&gt;青春片感人的第三个理由，是它带给你一种渺小的感觉，你看完了会觉得自己没那么太该死的重要。就像一个人第一次看见雪山时因为意识到自己的渺小而产生的敬畏感会让人忍不住落泪。青春片中的孩子在做着看似不可能的事，多半获得的只有值得牢记一辈子的epic fall，在这个过程中，你既感到了人性的伟大，又时刻提醒你个人的渺小以及群体的温暖。亚里士多德说城邦之外，非神既兽。人天生就是要社交的动物，人天生也是居于天使和野兽之间的生物。&lt;/p&gt;

&lt;p&gt;所以说有的社交，将人导向魔鬼，有的则会将你导向天使。导向魔鬼的社交机制让人觉得自己就是那么重要那么独一无二那么万众瞩目，比如大部分互联网产品想做的社交，都是要让你成为舞台的中心，满足你窥探他人隐私的愿望，通过比较来满足你的虚荣心，通过竞猜来装点自己的自鸣得意。而导向天使则让你时不时感到渺小和敬畏之感，让你时不时用事情本身内在内在的矛盾将你打磨一下，让你不那么舒服，不那么轻而易举不假思索遵从直觉，最关键的是，Ta会不躲避你终究要在泥水里滚滚，血水里的泡泡的事实。&lt;/p&gt;

&lt;p&gt;之前关注互联网带来的负面外部性，比如回音室效应（filter bubble）带来的观念极端化，就是由于互联网上有太多将人引入魔鬼的社交机制了。如果觉得一种文化不适合自己，那就应该创造一种新的文化。不管是外在驱动替代了内在驱动，还是将人区分开的知识取代了让你和自己讲和的知识，或者是让你感到渺小的社区逐渐稀少，最终决定这一切的都取决于我们自己。还是福柯的话，“当前的目标并不在于发现我们是谁，而是拒绝我们是谁。”我们要拒绝是将死亡的静穆消解到日常徒劳口角与蝇营狗苟的对疯癫的嘲弄，先承认我们自己的渺小，我们当下生活的荒诞，才能找回“&lt;span&gt;勇锐盖过怯弱，进取压倒苟安”的青春锐气。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383677&amp;amp;idx=1&amp;amp;sn=b1aa1ab4453286c02b7fedcc28a9b391&amp;amp;chksm=84f3c93cb384402ae4482f878a696616f168f13e9f1a6a74481f892b0265ef087de6f7d1901a&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;当你年近九十，是否还有心气，向人类史上最困难的百万美金发起挑战？&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=402051699&amp;amp;idx=1&amp;amp;sn=11cf55a50be75d5b64d08d8755b73447&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;要想体会人生，就要多爱几次&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383548&amp;amp;idx=1&amp;amp;sn=73af031076b2e015d9ffbc4480a9352f&amp;amp;chksm=84f3c8bdb38441ab2394fb5c48df0fc98b0793c16ba698bc7c5ee1f03906066a35c1f4e0d37b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;虽千万人吾往矣，便是你最光辉的时刻，赢了成史，输了成诗。&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;




</description>
<pubDate>Fri, 28 Sep 2018 20:59:42 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/DVbTYPc7i4</dc:identifier>
</item>
<item>
<title>[原创]学习如何学习 之 meta learning</title>
<link>http://www.jintiankansha.me/t/Zu8xwvhsNT</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/Zu8xwvhsNT</guid>
<description>&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;img data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.665625&quot; data-w=&quot;640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcd9g9aFjBooVn5U4PP1EDF3ugVJrLlia2ELtxHbXUJs7SUPtRaxmkUBHhx3jLciaHXpx1ABVYwYBu9w/640?wx_fmt=jpeg&quot; /&gt;&lt;/pre&gt;
&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;span&gt;作者许铁，微信号：ironcruiser &lt;/span&gt;&lt;br /&gt;&lt;span&gt;法国&lt;/span&gt;&lt;strong&gt;巴黎高师&lt;/strong&gt;&lt;span&gt;物理硕士 ，&lt;/span&gt;&lt;strong&gt;以色列理工大学&lt;/strong&gt;&lt;span&gt;（以色列85%科技创业人才的摇篮, 计算机科学享誉全球）计算神经科学博士，巡洋舰科技有限公司创始人,   《机器学习与复杂系统》纸质书作者。曾在香港浸会大学非线性科学中心工作一年 ，万门童校长好战友。&lt;br /&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.10966542750929369&quot; data-w=&quot;538&quot; class=&quot;&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibccdYT8ViaXic1q1ibC3U0Ub0WhaaX0dxl5oRO3YicRx7fSozVkP7Z5UfiaQdwyaxxEM5AZaMAGHjY4yS4Q/640?wx_fmt=jpeg&quot; /&gt;&lt;/pre&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;e9vou-0-0&quot;&gt;深度学习如火如荼的今天， 我们看到强大的视觉算法识别了复杂的疾病和所有人所观察不到的事物细节， 强大的阿法狗能够结束人类历史最精妙的发明围棋。一方面这些算法无时无刻不再鄙视着人类， 另一方面它们越来越透漏出它们的局限，比如惊人的数据消耗， 惊人的耗能，   “ 有限的范化能力”  ，  使得越来越多的人了解它们不过是一些头脑巨大的爬虫 而非真正的智能物种。    给你和人类学习一样的数据和一样的能量， 看你还能牛到哪去？  这是人们经常的质疑。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;7mu6m-0-0&quot;&gt;这些问题事实也是学界的焦点，  前两年一片叫做“元学习” 的文章， 就试图从学习的本质解决问题。 那就是 - 学习 如何 学习， 就像那个cousera 的爆款课程一样 learn how to learn. 机器能够用暴力的算力和数据来梯度下降，但是它们真的懂学习吗？&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8ko21-0-0&quot;&gt;我们知道， 所谓的机器学习还是深度学习， 无非给出一个问题， 你写出一个带着一堆参数（假设）的问题表达式和损失函数， 然后上一个损失函数， 然后梯度下降大法， 求出一个最优解。    &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;3np5r-0-0&quot;&gt;然而如果我说这是学习的唯一方法， 你一定会觉得我学傻了。 难道你要学习人任何一个任务，都要在那里等着你大脑里的神经突触一点点的改造（梯度下降）？    简直有一种欲练神功， 必先自宫的既视感。    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;3np5r-0-0&quot;&gt;  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;2f6vl-0-0&quot;&gt;我们的生活无时无刻不需要我们快速的学习和适应新的情况， 而神经突触的改变是一个慢过程， 这就决定了它必然不是学习的全部方法。  &lt;/span&gt;这个“快” 与 “ 慢” 的矛盾如何调和呢？  一个解决方法就是学习本身也是一个“快” 与“慢” 相加的过程。  &lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d03is-0-0&quot;&gt;事实上我们人类能够快速学习新情况， 是因为我们已经经过了大量的基础性学习， 我们后天的学习 ， 事实是因为我们的学习建立在更基础的模型之上。   这一点你的反应可能立即是迁移学习， 但是光看我们深度学习里那个迁移参数的深度学习是一个解决方法， 你可以把迁移学习看作今天这类方法的一个特例 ，而我们要看的是一种更广泛的方法。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;95efr-0-0&quot;&gt;这里提到的双层学习， 是另一种更基本的框架， 又称元学习 ， “meta learning”  ，  它的概念是学习一大类任务的先验信息 ， 然后利用学习到的先验学习， 加速这一大类里的每个具体任务的学习。 其实这样的一个工作正是深度视觉能够成功的关键， 我们常说的CNN结构本身就是抓住了图像理解这个任务里平移不变等关键先验信息， 然后把它们手写到网络里面去的。  这里元认知唯一的区别在于我们不再靠手写，   而是让神经网络自己学到这个先验。  就好比给你一个特别巨大的多层感知机网络， 然后让它自己学出类似深度卷积的结构来。  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;9ugf9-0-0&quot;&gt;今天讲的元学习的一个具体实例是指利用RNN网络加上深度强化学习的方法先学得一大类相关任务的先验信息，  然后利用这个先验信息，不用梯度下降学习， 纯凭网络动力学， 也可以适应每一个具体的任务得方法。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;44afo-0-0&quot;&gt;文章声称， 当您 有一个RNN，加上比较强大的深度强化学习算法， 你就可能拥有这种能力。 具体怎么做呢？ 首先， 我们知道一个强化学习任务里， 你需要根据当下的状态做决策，来最大化最后的奖励， 这个东西我们通常称之为策略 ，数学上看就是根据每个状态， 采取一定决策的条件概率函数。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d6ptk-0-0&quot;&gt;对于传统的强化学习算法， 我们通常需要动态优化等技巧来求解这个最优策略。 一个最典型的任务就是多臂赌博机。 这是一个由很多摇臂组成的赌博机，   每个臂都按照一定概率给你带来一个回报 ， 然后你要在有限的次数里最大化你的利益。  这个问题浓缩了强化学习的核心矛盾 -  探索与发现，假定你能够绝对准确的测量中奖概率， 那么你无非选择概率最高的那个臂就够了， 但是你要懂得绝对准确的测量概率需要无限长的时间， 而你的时间是有限的， 这时候， 你就需要在探索（测量）与发现之间做出权衡，摇臂赌博机涵盖了有限生命和未知世界的永恒矛盾， 因而也在生活或者广告电商应用里无处不见其踪影。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.6316666666666667&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcenH9WLvLsrBZukiafEJwhkE0YyoA4lE9rAY3XWGz7luAtTezXibqjDvDVmbqicdv1wOLRV5ibTnAIZOg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;af696-0-0&quot;&gt;对于这个问题的求解有很多经典算法， 一大类经典算法称为托马斯采样，  这个方法的本质就是求解最大后验概率， 你用一个β分布作为先验，然后根据每一次实验（摇臂）的结构来更新这个概率， 比如一次结果为空， 就会按照贝叶斯后验概率公式轻微下降这个选项的概率而上升其它，最终求得结果。 托马斯采样是一种保守的，将探索和利用混合在一起的策略，  也能够取得相当不错的成绩。    &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d12g2-0-0&quot;&gt;另外一个常用的方法称为upper confidence bound（UCB）,  可以翻译成最大信心策略吧。 这个策略与上面的托马斯采样相反，是一种激进乐观主义的策略，  它的信条是在那片黑暗的未知里隐藏着好事情。  具体的公式类似于当你在当下对某个摇臂积累了一定的经验， 比如N次尝试有m次奖励，此时的经验概率为m/N，  你知道这个测量由于数据不足有不准确性， 假定这个奖励符合高斯分布， 那么你就可以根据你的置信区间（自己定的）得到真实可能的概率的上界（乐观因此取上界）， 这样你就得到你的决策根据。 这个策略会偏向于探索未知， 因为你对某个摇臂尝试的次数越少，你的高斯分布就越宽（不确定）， 你的上确界距离你的&lt;/span&gt;实验概率就越远。  &lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6c1jj-0-0&quot;&gt;好了， 我们来看看现在的任务， 我们生成一些的二摇臂（两个摇臂）的任务， 每个任务里的摇臂的得奖概率都是随机制定的0到1间的数。 有多少个这样的任务呢？ 两万个， 相反的， 我们对于这些任务不适用那些量身定制的传统算法，  而是使用一个LSTM加上Actor Critic 方法训练， 这是一种当下流行的， 同时进行策略估值和生成的方法， 我们把这个游戏里每一步骤的奖励和决策作为输入给网络 ， 然后让网络去最优化总奖励数。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;c1snv-0-0&quot;&gt;这样训练完之后， 我们再来一组（300）个这样的任务， 没一个二摇臂任务由不同的概率组成， 不同的是，这组任务里我们固定网络参数， 不允许网络在梯度下降。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;beb0o-0-0&quot;&gt;如果按照传统方法的思维， 这时候的表现应该很差， 因为每个任务里概率都不一样， 需要重新通过刚刚讲过的方法学习得到， 你不允许网络学习， 它也就无所适从了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dgbl5-0-0&quot;&gt;然而这个时候我们发现，  LSTM仿佛自己得到了学习的真谛，它在任务的开始， 逐步探索积累经验， 然后通过学习得到的概率，很好的完成了任务， 就跟那些传统的学习算法结果一样好！    &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcenH9WLvLsrBZukiafEJwhkEjHKMicNK59QRF47CFCNhfibjcZVdgdyQl7vrTgFDejtNdQDPrtV10pZQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;8sua3-0-0&quot;&gt;不仅如此， 我们再进一步， 让这个游戏便的更复杂，我们刚刚假设摇臂是独立的， 真实世界的选项之间往往由相关性， 比如A的好往往暗示了B的坏， 宇宙能量守恒吗。  再摇臂之间的概率由相关性的时候又会怎样呢？      比如最简单的相关性 p1 +p2 = 1.  最后的结果就是相当的好！  再经过一段时间的训练后，网路无需学习， 就可以利用这种概率间的相关性规律， 来加速探索取得更好的成绩！  这也就是所谓的RNN可以自发学习掌握任务里的先验规律的意思。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;8sua3-0-0&quot;&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;9jpj4-0-0&quot;&gt;然后还有更有意思的 ， 我们可以设计一个更加奇妙古怪的相关性， 比如：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;b5sci-0-0&quot;&gt;我们又12个摇臂， 其中的某一个摇臂叫做信息摇臂，它可以指示其它的摇臂的奖励值，仿佛一个先知， 然而先知本身不给你奖励，只是告诉你哪一个摇臂的奖励值可能更高， 而且发现先知的过程要耗费时间的。  训练后的RNN网络仿佛理解了这个游戏的含义 - 通过寻找提示信息来学习。   在全新的任务里， RNN可以不再经过任何梯度下降， 主动的寻找信息摇臂， 并利用摇臂指示的信息寻找最高奖励。  这个问题里， RNN仿佛理解了探索与利用的矛盾， 并在全新的网络里， 利用自己的动力系统去实现这个过程。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dkk1t-0-0&quot;&gt;更上一层楼， 我们让这回连固定的概率都不要， 让每个摇臂的概率值随时间变化，唯一固定的是有的时候这个概率变化的速度快， 有的时候这个变化的概率小，  这个时候， RNN训练后的网络竟然仿佛能够在任何新来到的时候， 具有一种可调节学习速度的能力， 在那些概率经常变化的时间段让自己的学习速度也加快。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcenH9WLvLsrBZukiafEJwhkEEx9Y6LNrAAewzPhvaNfFt8wFjkhcicib51umtBLSSFcVOgpzaIxT7cfg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;除了K摇臂这个实验 ， 论文还尝试了经典的马尔科夫决策问题，  这个任务旨在通过一个简单的实验， 证实一个概念，   那就是刚刚的RNN 加上深度强化学习方法， 具备某种“构造世界模型” 的能力，  所谓构建世界模型，就是通过主动的了解和预测外界环境的变化来加强决策（对未知事物做出计划）。 而非光通过经验积累。  这也是区分人类高级学习和低级学习的关键所在，我们饱读诗书，都是在建立世界模型， 让我们对于毫无经历的事物也能够决策。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcenH9WLvLsrBZukiafEJwhkEIiaVibPU73DicUURCAE34s5pjvTd4j6DmVynLEeCXaCQbGmIEo8SItkNQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;dr5de-0-0&quot;&gt;但是这个能力以往需要通过工程方法加入到模型， 也就是人类自己先了解了模型， 然后通过程序嵌入进去。  &lt;/span&gt;而在刚刚的框架下， 这种通过构建世界模型的学习能力似乎也能够被学到。  上面的例子里，有一个状态S1 ， 状态S1 可以通过行为a1 或者a2  得到新的状态S2 或S3，  在此之上根据S2或S3得到一个奖励0或1， 这个奖励也是随时间变化的随机变量。 当然任何一种行为都可以得到后面的两个状态只是概率不同， 就像经典的马尔科夫决策问题一样， 这可以被一个转移概率矩阵描述， 而这个矩阵对于行为者是未知的。 由于这个转移概率包含了世界在我的行为下会如何变化， 它就是我们所说的世界模型。 如果学习者主动掌握这个模型来决策， 就好比它学会了有模型学习。&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;59tjr-0-0&quot;&gt;我们可以通过学习者的行为判断它是否试图建立这个模型， 如果行为者做出a1 ，并且最终达到S3得到奖励1，  那么它是应该更加鼓励行为a1还是行为a2 呢？  一朝中大彩， 十年买彩票， 不考虑任何模型的学习者所依靠的就是纯经验， 那么这个好经历无疑会让他更倾向于在S1下进行a1的决策，  而有模型的决策者就不然了，因为它知道这个结果是在一个小概率事件（从a2到S3是一个25%的小概率事件）  ，  同时通过“深思世界的本质” 他知道， 其实这真正说明的是S3是一个好状态， 更加容易达到S3的路径是a1而不是a2， 那么反过来我应该增大a2决策的权值而不是a1 ！   在这个事件下， 通过经验学习， 和模型结合经验学习就天壤之别了。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8igi7-0-0&quot;&gt;后面论文还举了一些比较复杂的任务，其中一个比较有趣的是导航。  这个导航的任务， 是让行为单元走迷宫，这个迷宫的某个角落藏着宝物， 然而隔一段事件宝物的位置就会被移动到另一个位置， 而更加残酷的是， 每次行为者发现宝物后就会被转移到另一个随机的地点。 这个任务里， 行为者的输入只有它眼前的迷宫景物和它本身的行动速度，以及是否得到了奖励， 这样的情景很像我们的3D射击游戏， 同样的RNN 框架下， 通过不停游戏的初始训练阶段，游戏者仿佛掌握了一种进行空间行走规划的能力。在测试阶段，无需重新训练调整， 行为者也可以去发现目标宝藏， 并且在一次发现之后，无论它被重新扔到哪个未知角落， 都已十分有效的方法返回回去。这里的世界模型， 事实上是这个环境的地图和宝藏的坐标， RNN在某种程度掌握了这个概念， 因此， 它会在全新的位置也能够做出类似于合理的行为， 这一点， 和人是类似的。    &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcenH9WLvLsrBZukiafEJwhkEmPhjuKavicy2XQ8nGvrn7Cyj8pmDYrqibj4vPRZV0o8CfwSq6d6VHkBA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.10966542750929369&quot; data-w=&quot;538&quot; class=&quot;&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibccdYT8ViaXic1q1ibC3U0Ub0WhaaX0dxl5oRO3YicRx7fSozVkP7Z5UfiaQdwyaxxEM5AZaMAGHjY4yS4Q/640?wx_fmt=jpeg&quot; /&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span data-offset-key=&quot;8h5th-0-0&quot;&gt;广告时间：&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383610&amp;amp;idx=1&amp;amp;sn=eae53f91ea3bdb1d99464d3824175707&amp;amp;chksm=84f3c97bb384406dd3942d73be8d1dbe5a16815743990686d9054e1a3e9fa8fc42c8519ba270&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;铁哥开设的一个为期两日（12小时）的强化学习特训班&lt;/a&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;

&lt;p helvetica=&quot;&quot; neue=&quot;&quot; sc=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; justify=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; border-box=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;为什么是强化学习？  请看下图的技术泡沫爆裂图。  机器学习和深度学习在2017处于关注热度的顶峰， 大家看处在上升期的人工智能技术， 第一当属深度强化学习， 据这张非常表格非常粗糙的估计， 深度强化学习的技术成熟期在未来5-10年， 此时此刻， 正类似于深度学习在2010的状况。  &lt;/span&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.67&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfqJgX6L51kcnJ07DHpdBzqmXKic2iaDgZOpUiacyYFWzBHst0BCZVTJINPzpfRibpMV6hWgUKSlj7ibBw/640?wx_fmt=jpeg&quot; /&gt;&lt;/p&gt;

&lt;br /&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.10966542750929369&quot; data-w=&quot;538&quot; class=&quot;&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibccdYT8ViaXic1q1ibC3U0Ub0WhaaX0dxl5oRO3YicRx7fSozVkP7Z5UfiaQdwyaxxEM5AZaMAGHjY4yS4Q/640?wx_fmt=jpeg&quot; /&gt;&lt;img data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;5.896&quot; data-w=&quot;750&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccvEGHcvx6vn7ibqucwWjTLJNQDiajMVL3arkx9IJnm10baZ1RjdLTN2KH6SKHZqnzyGO5K0G3dNOwg/640?wx_fmt=jpeg&quot; /&gt;
</description>
<pubDate>Sun, 23 Sep 2018 18:44:40 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/Zu8xwvhsNT</dc:identifier>
</item>
</channel>
</rss>