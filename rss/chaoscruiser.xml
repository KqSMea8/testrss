<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>深度学习常见面试题及回答</title>
<link>http://www.jintiankansha.me/t/ImKQUOj4DJ</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/ImKQUOj4DJ</guid>
<description>&lt;p&gt;1）什么是深度学习？&lt;/p&gt;
&lt;p&gt;回答：深度学习是机器学习的一个领域, 它专注于使用包含不止一个隐藏层的人工神经网络, 这部分由大脑中神经元的结构启发而生成。深度学习适用于计算机视觉、语音识别、自然语言处理等一系列领域。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;2）什么是损失函数&lt;/p&gt;
&lt;p&gt;损失函数告诉我们神经网络的执行效果如何。我们在训练神经网络的目标是找到使最小化成本函数的神经元权重组合。&lt;/p&gt;

&lt;p&gt;举一个成本函数的例子, 考虑平均平方误差函数:&lt;/p&gt;


&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccQOduTGLky8BfGHuUzsqoNmCAIv7sAl7jcDtY1fsXyDDMUh2z8rb3VVoVMn7AslgIich8VFsU2TWg/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.2777777777777778&quot; data-w=&quot;270&quot; /&gt;&lt;/p&gt;
&lt;p&gt;该函数表示我们预期的结果Y^和实际的结果Y之间的差距，而这正是我们力图减少的。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;3）什么是梯度下降&lt;/p&gt;

&lt;p&gt;梯度下降是一种深度学习的最常用优化算法, 通过迭代来修改参数值，以最小化成本函数。 在每个迭代中, 我们计算每个参数的成本函数的梯度, 并通过以下方法更新函数的参数。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccQOduTGLky8BfGHuUzsqoNPibNzWDPLC9YXIVlgZ3wibW2ibxO0nSXg3G2MGPqMmtlk5wE3hA2Htj3A/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.31797235023041476&quot; data-w=&quot;217&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccQOduTGLky8BfGHuUzsqoNRvQH8RicpD45RaicIySUksLXGvxngj1JnyNibqLnSOD6fsaYJw5551zVQ/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.9555555555555556&quot; data-w=&quot;45&quot; /&gt;是待优化的参数向量，&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccQOduTGLky8BfGHuUzsqoN5UnAHKL68Qe6v6yp4Kb0BMHqtWfgKvBqPsODBsgyenPDRz85XuP04w/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;1.4166666666666667&quot; data-w=&quot;24&quot; /&gt;是学习率，&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccQOduTGLky8BfGHuUzsqoNVYNdnDwZV0FR5SmgVgGASZaHK6qWLQs8esthDuHvAuhEo9TNKZ1vCg/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.723404255319149&quot; data-w=&quot;47&quot; /&gt;是损失函数。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;4）什么是反向传播算法&lt;/p&gt;
&lt;p&gt;反向传播算法是一种用在多层神经网络中的训练算法, 它允许对梯度的变化进行有效的计算。&lt;/p&gt;

&lt;p&gt;反向算法可分为以下几个步骤:&lt;/p&gt;

&lt;p&gt;1) 通过网络向前传播待训练数据, 以产生输出。&lt;/p&gt;
&lt;p&gt;2) 使用目标值和输出值来计算由损失函数定义的误差的导数。&lt;/p&gt;
&lt;p&gt;3) 向神经网络中的前一层的输出上一步计算的误差的导数, 并依次传递到每一个更前的隐藏层。&lt;/p&gt;
&lt;p&gt;4) 根据上一步传递的误差的导数，依据链式法则，计算上一步的误差相对于当前神经元的权重的导数&lt;/p&gt;
&lt;p&gt;5) 更新权重。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;5）解释以下三种梯度下降算法的变体: 批处理、随机下降和 Minibatch？&lt;/p&gt;


&lt;p&gt;随机梯度下降：仅使用单个训练示例来计算渐变和更新参数。&lt;/p&gt;
&lt;p&gt;批处理渐变下降：计算整个数据集的渐变, 并在每次迭代中只执行一个更新。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;Minibatch 梯度下降：将数据集拆分为小批, 并对每个 mini-batch 执行参数更新。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;6）什么是单个热编码（One Hot Encoding）？&lt;/p&gt;

&lt;p&gt;单个热编码用于对分类特征进行编码。我们为每个唯一的值创建一个单独的特性, 这样, 值就会彼此相同。&lt;/p&gt;
&lt;p&gt;例如, 让我们假设有一个称为颜色的功能, 它可以采用如下值: 红色、蓝色、绿色。&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccQOduTGLky8BfGHuUzsqoNmbKQHcibPQDkiaRSCd2ypXzBDyeEVsOdLJ6dj4Eribiaje2CGKGleX70aQ/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.4980392156862745&quot; data-w=&quot;255&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;7）激活函数的作用是什么？&lt;/p&gt;

&lt;p&gt;激活函数的目的是将非线性引入神经网络, 使其能够学习更复杂的函数。如果没有它, 神经网络将只能够学习线性函数, 它只能产生输入数据的线性组合。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;8）提供一些激活函数的例子？&lt;/p&gt;

&lt;p&gt;Sigmoid函数&lt;/p&gt;

&lt;p&gt;Sigmoid函数也称为logistic函数, 它是连续的, 也容易计算导数。它将所有的实数压缩到范围 0到1之间。&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; &lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccQOduTGLky8BfGHuUzsqoN9YkXsmoD1qNWmYIeicuB2rkic9AawXw9ENXxMzTlicOvdkuicJtfoBjNnQ/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.9087779690189329&quot; data-w=&quot;581&quot; /&gt;&lt;/p&gt;

&lt;p&gt;softmax&lt;/p&gt;

&lt;p&gt;Softmax 是一个泛化的Sigmoid函数，,当我们要处理多个类。所有输出值都在范围 (0, 1) ，其总和为 1, 因此可以将输出解释为概率。&lt;/p&gt;


&lt;p&gt;整流线性单元– ReLU&lt;/p&gt;

&lt;p&gt;ReLU 函数如果输入小于或等于 0,则输出0 否则输出输入的值, 我们可以把它们看成开关。 它可以免受梯度消失的问题, 它计算非常快。在卷积网络中的应用时比应用Sigmoid函数更有效。&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccQOduTGLky8BfGHuUzsqoNaGwTKvEnPoFkWNEoias88Aib7Kzfe9tEqxJ5ZMbpUZicY6hr3ME0kLKRA/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.8791018998272885&quot; data-w=&quot;579&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;9）什么是超参数, 提供一些例子？&lt;/p&gt;

&lt;p&gt;参数相对于模型参数不能从数据中学习, 它们是在训练阶段之前设置的。下面是常用的超参数。&lt;/p&gt;

&lt;p&gt;学习率（Learning Rate）&lt;/p&gt;

&lt;p&gt;它决定了我们要在优化过程中更新权重的速度, 如果学习率太小, 梯度下降可以缓慢地找到最小值, 如果它的太大梯度下降可能不会收敛。它被认为是最重要的 超参数。&lt;/p&gt;

&lt;p&gt;epoch&lt;/p&gt;

&lt;p&gt;&lt;span&gt;当一个完整的数据集通过了神经网络一次并且返回了一次，这个过程称为一个 epoch。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;批处理大小 Batch Size&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;在不能将数据一次性通过神经网络的时候，就需要将数据集分成几批分开处理。批处理大小指&lt;/span&gt;一个训练批次中的样本总数。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; width=&quot;auto&quot; /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;10）什么是模型容量？&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;模型容量用来评价系统的解释是否具有足够的扩展性。较高的模型容量是可以存储在网络中的信息量越大。如果模型容量过大，就像一个记忆力极为精准的植物学家，当她看到一颗新的树的时候，由于这棵树的叶子和她以前看到的树的叶子数目不一样，因此判断这不是树；但如果模型容量太小，就像一个懒惰的植物学家，只要看到绿色的东西都把它叫做树。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;11）什么是卷积神经网络？&lt;/p&gt;

&lt;p&gt;卷积神经网络, 也被称为 CNN, 是一种神经网络的架构,常用与图像识别，也可用在自然语言处理。其使用卷积在至少一个隐藏层。卷积层由一组过滤器 (内核) 组成。这个过滤器滑动切割整个输入图像, 计算点产品之间的权重，经过待训练的神经网络，即过滤器，将处理后的结果输出到下一层。 由于训练结果, 网络会学到能够检测特定功能的过滤器。例如识别三角形，直角。将多个卷积层堆叠起来，可以得到对整个图像的全局特征的提取。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccQOduTGLky8BfGHuUzsqoNtl7ibWvBdSicxiboVgAbf2VNwkc5sV82o1Wvoq788uHvU8n59IlHKqohw/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.6312292358803987&quot; data-w=&quot;602&quot; data-type=&quot;png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;12）什么是自编码器 （autoencoder）？&lt;/p&gt;

&lt;p&gt;自编码器是一种人工神经网络的结构, 它能够在没有任何标签的情况下学习数据集 (编码) 的表示。他们通过重现输入的特征进行学习, 通常其神经网络的内部表示比输入向量具有更小的维数, 这样他们就可以学习有效的表示数据的方法。自编码器由两部分组成, 编码器试图将输入与内部表示相适应, 解码器将内部状态转换为输出。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccQOduTGLky8BfGHuUzsqoNdmHupMQJsGwqEnEn4icVsL4qBCN7hrhbZFmvYMW54SdGjC3tZBUICqw/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.7888040712468194&quot; data-w=&quot;393&quot; data-type=&quot;png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;13）什么是dropout（辍学&lt;img data-src=&quot;https://res.wx.qq.com/mpres/htmledition/images/icon/common/emotion_panel/smiley/smiley_7.png&quot; data-ratio=&quot;1&quot; data-w=&quot;20&quot; /&gt;）？&lt;/p&gt;

&lt;p&gt;dropout是一种在神经网络中减少过拟合的正则化技术。在每个训练步骤中, 我们随机地关闭一些网络中的神经元, 这样我们为每个训练用例创建不同的模型, 所有这些模型都共享权重。这是对一组容量略低的模型求平均值的方法，类似随机森林。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccQOduTGLky8BfGHuUzsqoNrgG6yxZQNjo0D5SpE9zibZuhyrNb9I7ZFqyVYNJ9Fkxal1t7Ov4fuGQ/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.5342019543973942&quot; data-w=&quot;614&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;14）我们如何使用交叉熵来作为成本函数？&lt;/p&gt;

&lt;p&gt;交叉熵作为成本函数可用于分类,这是一个最自然的选择, 如果有一个Sigmoid或 softmax 的非线性在输出层。&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccQOduTGLky8BfGHuUzsqoNFpibmlmYjSN79xFXy8HOnib0sZicoe3hMogZ7C9dD9ScTKs3qAQYKibphg/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.16584158415841585&quot; data-w=&quot;404&quot; /&gt;&lt;/p&gt;
&lt;p&gt;其中C为交叉熵，a是神经网络的输出权重，y是目标函数，n是训练样本的个数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;欢迎关注&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382937&amp;amp;idx=1&amp;amp;sn=d4510592a837c44fe75393c2578698d8&amp;amp;chksm=84f3cad8b38443ce6adcd155a2c45ee7707b4a9d8e48c05728aa7e93862475832bf89617025f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;巡洋舰的深度学习实战课程&lt;/a&gt;， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛， 感兴趣的小伙伴可以点击阅读原文。 &lt;span data-offset-key=&quot;duudf-0-0&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; &lt;/span&gt;&lt;/strong&gt; &lt;span data-offset-key=&quot;duudf-0-0&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;duudf-0-0&quot;&gt;&lt;strong&gt;下图是这门课程的思维导图。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span data-offset-key=&quot;duudf-0-0&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7935540069686411&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdrg83hduKplaOkZeV6icFIST2rojIm4SLJSQU8CgNia1AYmETxrSibzh5P6vPiaOffICZibFcNKfichRhw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1148&quot; width=&quot;auto&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;duudf-0-0&quot;&gt;原创不易，随喜赞赏&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;duudf-0-0&quot;&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;duudf-0-0&quot;&gt;更多阅读&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;duudf-0-0&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382986&amp;amp;idx=1&amp;amp;sn=13707c68d198bfa947eb90606ac99f05&amp;amp;chksm=84f3ca8bb384439d5c3ceeab35dd97373b1b461d4745ba2ab782998a8a3ea8722acca491f434&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;深度学习入门书单&lt;/a&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;duudf-0-0&quot;&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382963&amp;amp;idx=1&amp;amp;sn=53c1f03208ca7a41285566b9bf8aa83d&amp;amp;chksm=84f3caf2b38443e40428d245046814ac4ca8883c4403a88f68980b86e57b4c754759edf6eece&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;铁哥谈AI： 浅析阿尔法元之元&lt;/a&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Wed, 25 Oct 2017 21:01:22 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/ImKQUOj4DJ</dc:identifier>
</item>
<item>
<title>读《科技想要什么》，说AlphaGo Zero的大新闻</title>
<link>http://www.jintiankansha.me/t/Z1BaMSbLnO</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/Z1BaMSbLnO</guid>
<description>&lt;p&gt;一年前，和朋友闲聊，他说AlphaGo的下一代是BetaGo，结果人家从Master升级成了Zero，俩个神经网络也变成了一个。一年前，人们讨论AlphaGo是否理解了围棋，人们举例说，如果围棋的棋盘变成了20乘20，那柯洁闭着眼睛都能虐狗，由此来说明AlphaGo并不懂围棋。 但有了从零开始的zero，改变了棋盘的大小，给我3天的时间，照样能够虐人类。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;还有说狗狗不懂人类选手常用的围棋定式的。然而，从Zero的论文中看出来，恰好是那些学会定式慢的狗狗，棋下的好。不同版本的狗狗，最终都学到了围棋的定式，但若是过早的将选择定式的几率提高，那么会限制对未知模式的探索。从这个意义上来说，围棋的定式，何尝不是一种过拟合。然而只有等人类见识到了全新的风格，才能够意识到自己的不足。&lt;/p&gt;

&lt;p&gt;之前我们反驳狗狗不懂围棋的论据，都被AlphaGo Zero打破了，但人类最擅长的是改游戏规则。给定一个选手最多只能记住10万张棋谱，下十万盘棋，在这样的限制下，人类在当下的技术条件下，无论如何都是赢家。但这说明人类理解围棋，学习围棋比AI快吗？答案是否定的。加上这个限制，说明人类由于自身的限制，将围棋变成了一个有限游戏，人类围棋的规则其实是在只记住十万棋谱，下过不多于十万盘棋时下出最好的棋，而AI的出现，将围棋变成了一个无限的游戏。&lt;/p&gt;

&lt;p&gt;这里不是说围棋的可能性变成了无穷的，而是说计算机去掉了存储的限制，狗狗可以记住其下过的所有左右互搏的棋局，而蒙特卡罗树则将最后的输赢反馈到了最初的每一次落子上，解决了奖励时间的不确定性&lt;span&gt;，&lt;/span&gt;而CNN则负责从中推导出该怎么评估当前的局势，将你的落子和整个棋局的大背景结合起来。这样的框架，适合无限游戏的假设。而人类棋手一开始学习定式，则是人类在其自身的限制下最佳的学习方式。人不必盲目的崇拜计算机，说到底，狗狗和人玩的是不同的游戏，自然应该有不同的玩法。&lt;/p&gt;

&lt;p&gt;说完了狗狗，我们将视线拉远，猜猜狗狗下一步想做什么。人们对于未来的想象，常常是线性的。即使对于想象力丰富如著名的科幻作家凡尔纳，他设想的人类登月的方式也只是用大炮，然而真正改变世界的创新，最初都是不那么显著的，没有多少人会注意到。所以与其看狗狗下一步能做什么，不如看看狗狗做不了什么。与其看具体的行业，不如给出算命式的趋势预测。&lt;/p&gt;

&lt;p&gt;有了AlphaGo Zero的框架，所有的完美信息环境下的零和式，有限个选择的策略游戏，都已经成了AI的天下。再结合AI战胜人类的德州扑克选手，对于即使不是一个信息完全公开的游戏，只要可能出现的选项是已知而未知的只是出现的概率时，AI占据绝对优势，也是必然的了。留给人类的唯一机会，就是不要去玩零和游戏，不去玩有限的游戏了。&lt;/p&gt;

&lt;p&gt;有本书就叫《有限和无限的游戏》，书中写道，有限游戏以取胜为目的，而无限游戏以延续游戏为目的。有限博弈者在边界内游戏，无限博弈者以边界为游戏对象。有限游戏旨在以一位参与者的胜利终结比赛，每个有限游戏都是为了结束自身。矛盾恰恰就在于，所有有限游戏都是在对抗自身。在这本书中，作者提醒读者转化游戏观，认识到生活其实不应当被看成是有限的游戏。&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdXzh90N8e8w3xCAIpwsdUgG1YlshggBCmZO4lzsFk7U18nUx81SjnjsnSPU5byzFIWWML761cWUg/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.4455445544554455&quot; data-w=&quot;303&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;凯文凯利在《科技想要什么》中对《有限和无限的游戏》十分称赞。书中写道：&lt;/p&gt;
&lt;p&gt;&lt;em&gt;进化、生命、思维和技术元素都是无限博弈。它们的博弈就是让博弈持续下去，让所有博弈者尽可能地长时间参与。为了达到这样的目的，它们像所有无限博弈一样戏弄游戏规则。进化之进化就是如此。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;生活中我们最爱的事物──包括生活本身──都属于无限博弈。当我们参与生活博弈或技术元素的博弈时，目标不是固定的，规则不明朗，并且一直在变动。我们如何进行下去？好的选择是增加选择。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;无限博弈的目标是保持游戏的进行：摸索游戏的所有玩法，增加各种博弈，召集所有可能的玩家，扩展游戏的意义，倾尽所有，无所保留，创建宇宙中不太可能发生的博弈。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;弄清楚了无限博弈的思路，就能够再一个大的框架下去看狗狗战胜人类的这件事，狗狗的出现，将围棋这种有限的游戏，转化成了一个无限的游戏。游戏的目地不再是为了获得世界第一，而是为了探索出围棋中的所有玩法。狗狗胜利的方式，是狗狗背后的Deep mind巧妙的改变了游戏规则，而不断改变游戏规则，正是无限游戏唯一的规则。&lt;em&gt;&lt;br /&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;说完了哲学性的话题，这篇小文就以AI取代职业这个话题来结束吧。很多人会问自己，你的工作中有百分之多少是可以被AI所替代的，然后据此评估AI是否会取代你的工作，但从有限和无限的游戏这个角度来看，你要问自己的问题的答案会是更主观的。你问自己在做的工作，究竟是该被当成有限的游戏，还是无限的游戏。&lt;/p&gt;

&lt;p&gt;一个餐厅的服务员的工作，是自动化程度很高的，但这并不意味着未来餐厅服务员这个职业会消失，米其林餐厅，国宴会，服务员的岗位总是在的。一个服务员若是将自己的工作时间看成是零和的游戏，那么她必然会担心自己的岗位丢掉，而她的担心会使得她忽略由于游戏边界的改变而带来的新机会。而如果她只是将餐厅的服务员工作看成是无限游戏中的一部分，那么在机器人取代一步步取代服务员的过程中，她会随之成长，找到新的坏境下新的角色。你的担忧反映的更多是你对自身角色的看法，而不是事实。&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;更多阅读&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382963&amp;amp;idx=1&amp;amp;sn=53c1f03208ca7a41285566b9bf8aa83d&amp;amp;chksm=84f3caf2b38443e40428d245046814ac4ca8883c4403a88f68980b86e57b4c754759edf6eece&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;铁哥谈AI： 浅析阿尔法元之元&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382959&amp;amp;idx=1&amp;amp;sn=4e3f03464db9bf33225d9293d69c5eb6&amp;amp;chksm=84f3caeeb38443f8aa9f050568b0368b512851c70c355d1690c07c3b1c92c82fe5d22f0b41ec&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;机器学习：增加更多就业岗位&lt;/a&gt;&lt;br /&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; &lt;/p&gt;



</description>
<pubDate>Tue, 24 Oct 2017 05:34:13 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/Z1BaMSbLnO</dc:identifier>
</item>
</channel>
</rss>