<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>[原创]《人机平台》 深度解读</title>
<link>http://www.jintiankansha.me/t/8LBv6gbwqV</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/8LBv6gbwqV</guid>
<description>&lt;p&gt;你好，Peter为你分享的书叫《Machine Platform Crowd》，中文名是《人机平台》，这本书 2017 年在美国出版畅销，而在亚马逊商城获得4.4分的佳绩。 &lt;/p&gt;

&lt;p&gt;为什么一本书会成为我的必读书，其中一个原因是这本书的作者曾写过一本经典之作。《人机平台：新商业世界的行动解决方案》就是这样，两位作者都是麻省理工斯隆管理学院的教授，他们在14年出版的《第二次机器时代》曾被很多人当成是对未来先知般的预言，而这本新书则可以看成是《第二次机器时代》的续集，将上本书中没有说透彻的话题一一道来。&lt;/p&gt;

&lt;p&gt;未来是数字化的，但具体来说，以移动通讯和人工智能为代表数字技术在那些层面深远的改变社会，我们目前所看到的还只是冰山浮起的那尖尖角，数字技术在未来将要产生比我们现在所感受到的还要巨大而深远的影响。这个观点你也许并不陌生，也认同其说的与我心有戚戚焉。毕竟关于这个话题，很多大牛都曾进行了论述，包括凯文凯利的《必然》，尤瓦尔.赫拉利的《未来简史》，那这本《人机平台》又有什么特别之处呢？&lt;/p&gt;

&lt;p&gt;不同背景的作者会带着不同的思维习惯，就如武林高手会有武功套路。比如凯文凯利是硅谷出生，他分析问题，会从技术本身来看。而尤瓦尔.赫拉利本行是历史学家，他的书就会有历史深度，擅长横向对比，见微知著。而《人机平台》的作者是经济学家，因此书中有不少经济学的理论，比如在分析例如Uber这些平台时，用到了消费者剩余的概念，在分析公司为什么还会存在时，引用了科斯的公司理论和不完整合同的概念。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;查理芒格一直推崇多学科的思维方式，认为只有从多个角度来看问题，才能深入的理解问题的本质。&lt;/strong&gt;而对于技术对未来社会的发展这样一个天问一般的大问题，我们更需要多学科的思维，只有通过整合多种来源的思考，才能帮助你更完整的建立起独属于你的自己的世界观。所以这本书可以看成是《未来简史》这本书的姐妹版。&lt;/p&gt;

&lt;p&gt;在这本书里，作者观察未来，是围绕着三对相互矛盾又相互依存的事物展开的，而今天我要分享给你的，也会围绕着这三个维度&lt;/p&gt;
&lt;p&gt;一是人脑的智能和机器的智能这两者之间的竞争和互补&lt;/p&gt;
&lt;p&gt;二是平台和产品的这两者之间的相互依存&lt;/p&gt;
&lt;p&gt;三是众包和集中式管理之间的权衡&lt;/p&gt;

&lt;p&gt;好，接下来我们首先就来看看今天要分享的第一个重点内容。为了方便你理解，这里请将你想象成一个新出生的孩子的父母，让我们看看我们的孩子未来究竟要面对那些挑战。&lt;/p&gt;

&lt;p&gt;假设你打算让你的孩子在大学阶段就打工挣学费，就像我们自己曾经做过的那样。然而，未来所有适合大学生勤工俭学的工作，都会被机器人替代。不管是送快递，KFC的服务员，还是翻译，文案校正。你再深想一层，这样下去，是不是弱势群体的子女，将再难以通过自己的双手来实现阶级跃升？&lt;/p&gt;

&lt;p&gt;在《人机平台》中，作者针对这些问题给出了自己的思考。我们理解的人工智能不止能取代上面所说的体力活，还能够完成诸多我们以为的需要创造力和整体思考的领域，在干货笔记中，你可以看到由计算机算法设计的赛车模型。而传统的观念上，这样的工作需要有多年工作经验的老手才能做的好。但只要存在一个可以清晰定义的评价指标，以及相对封闭的系统边界，没有那么多的意外，AI算法未来一定会做的不比人类差。&lt;/p&gt;

&lt;p&gt; 看来你指望在你的孩子的童年阶段培养他的创造力，从而为他的未来提供先人一步的起跑点也没用了。根据《人机平台》这本书中所说的，你要为你的孩子准备好以下的心态，首先是和机器协同工作，让机器保证思考的全面，然后在由人根据具体的场景对其进行调整和改进，你可以在家就从小给孩子做示范，通过言传身教让孩子知道如何结合人和机器的智能的优点。其次，你要展示出人类目前真正战胜机器的优势，即对他人的需求和想法的深刻而敏感的觉察，而要做到这一点，你首先要让自己成为一个敏感的人，即使你现在还不是这样的人，&lt;strong&gt;多阅读经典的人文著作，可以帮你提升对人的心理的洞察，从而提升自己在机器智能崛起的时代作为人的独特价值。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;好了，以上就是今天为你分享的第一个重点内容，咱们接下来说第二个。让我们还是假设自己是孩子的父母，在为他考大学提供哪个行业有前途的建议。每个亲戚对这个问题都有自己的看法，这时一个高人说道，还选什么行业啊，这年头要做平台，你看阿里做的是电商平台，云计算平台，哪里有什么具体的产品呢？所以说做平台比做具体的产品有前途多了。&lt;/p&gt;

&lt;p&gt;上面的争论说的就是平台的价值和具体产品之间的关系。为什么有的平台会成功？平台的价值又是从何而来的？从经济学的角度来看，所谓平台，就是一个集市，大家都到你的这里来交易，从中获得消费剩余，而你则提前买好了集市旁边的地，等到集市成为了繁华的商贸中心，再把地卖出去。所以作为好的平台，首先要开放，要吸引各种不同的人来到你这做交易。在《人机平台》这本书中，作者讲述了IOS的应用市场是如何差一点就被乔帮主那偏执狂的不开放态度给毁了的。这个故事有些长，很多细节就不在这里讲了。感兴趣的请移步《人机平台》这本书。&lt;/p&gt;

&lt;p&gt;开放不止意味着进入你这里没有门槛，还意味着你这里有很多能满足小众需求的东西。人无癖不可深交，所谓癖，就是癖好，就是别人不理解，但就是有那么一小群人喜欢的东西，当你的平台能提供的不止是大路货，还包含足够多的很容易被检索到的特色产品时，那么这个平台对消费者的吸引力就越大。&lt;/p&gt;

&lt;p&gt;然而正如任何集市都需要有管理员，平台的开放也不应该是绝对的。平台的构建者要在平台中构建起自己的价值观，要确保你的平台提供给所有接触到这个平台的人的东西都是积极的，正面的。这里说一个见仁见智的例子，我的一位朋友至今不用淘宝的平台，原因是他在留学的时候，亲眼看到一个同学在淘宝上购买作业的答案以及代写论文的服务，这让他对淘宝的印象很差。所以说平台的开放，绝对不意味着平台可以藏污纳垢。《人机平台》这本书中对这一点进行了特别强调，英文原版书中用的一个词特别高级，叫curator，中文是博物馆馆长或者大学的理事，这个词语背后的隐喻是&lt;strong&gt;做一个好平台，就如同做一所大学一样，需要有原则的开放。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;就像一个城市只有一俩个商业中心一样，平台也不会太多，一个平台的兴起，天生会对类似的平台产生排他性，所以做平台要趁早。任何一个领域，若是你打算成为平台型的玩家，虽然你不必是第一个，但你绝对不应该在已有的平台已站稳脚跟时再跟进，除非你做的平台和他们的有足够的区分度，能够做到满足一个还没有被发现的，又足够频繁的细分需求。如果做不到，那你正确的做法是利用好现有平台提供的便利，老老实实做产品。&lt;/p&gt;

&lt;p&gt;从这个角度来看，要是一个领域还在快速发展的时期，那么就会出现百花齐放的平台，比如深度学习领域，已经有大量平台出现，从最初的caffe，到Kerse，到现在最火的tensorflow，还有facebook的Pythorch，这些都是大公司准备的帮助你写代码的工具包，大公司这么做，是希望能在未来成为行业标准的制定者，甚至是垄断者。这个现象反过来说明深度学习这个领域还没有实现一家独大，这时候你就应该打好基本功，先学点机器学习的理论知识，等到这个行业只剩下一两家平台，再具体针对一家的平台深耕细作。&lt;/p&gt;

&lt;p&gt;好了，以上就是今天为你分享的第二个重点内容，下面，来为你说说最后一个重点，核心团队和众包的关系。还假设你是一个有着正在读大学的孩子的父母，当你发现你的孩子的生活费来自于一个个零散的任务奖金时，你可能会担心，你的孩子学的本来不是化工专业啊，怎么一会参加了一个化工方面的项目，一会又参加了一个生物相关问题的课题，这么东一榔头西一棒槌，孩子本来学的电子工程这个核心技能，不就要荒废了？&lt;/p&gt;

&lt;p&gt;而《人机平台》这本书想要告诉你众包的力量。和众包关系密切的是群体智慧。这个词说的是当一个企业遇到了自己解决不了的问题，将这个问题放到网络上，提供一笔奖金，吸引全世界的人一起来挑战。例如美国的著名影视公司网飞公司，也就是那个拍摄了纸牌屋的网飞，他们2012年搞了一个竞赛，看有谁能将他们的推荐算法的准确度提高10%。当时还没有专门的推荐算法专家，各种背景的人都组团去参加比赛。最后的结果是网飞公司只花了很少的钱，就尝试了很多改进推荐算法的方法。这要是由内部团队去开发，需要的时间那可就长的多了。&lt;/p&gt;

&lt;p&gt;另一个例子是一篇有数万作者的科研论文。一位科学家将一个前沿的生物学问题，蛋白质怎么折叠更稳定，做成了一个游戏放到网络上，结果有几万人通过玩游戏，竟然让科学研究有了进展，于是就有了在最权威的自然杂志上发表的这篇有几万作者的论文。&lt;/p&gt;

&lt;p&gt;众包之所以有效，按照《人机平台》中所讲述，还和经济学大牛哈耶克的思想有关，我们知道哈耶克提出了默会知识的概念，沉默的默，会议的会，也就是一个人所知的比他能表达出来的远远要多，你无法清晰实时说出你想要什么、能做什么、知道的知识能怎么被用到，只有通过行动，所有这些隐藏属性才能得以体现。在快速变革的时代，很多问题其实解决者没有相应的知识储备，而在众包平台上发布任务，可以解决这种错配。&lt;/p&gt;

&lt;p&gt;我们最熟悉的众包还有维基百科和百度百科，但同样是众包产生的，都是用户提供内容，为什么在很多人印象中，百度百科的用户体验就不如维基百科呢？这就说到了核心团队的价值。《人机平台》这本书中详细的介绍了维基百科是如何维持一个纪律严明的核心管理团队的，也就是说，和我们一般理解不同的是，&lt;strong&gt;众包不意味着没有核心，或者核心没有用。核心对维持项目的整体价值观和一致性至关重要。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;好了，说到这儿，今天的内容就聊差不多了。下面，来简单总结一下今天为你分享的内容。&lt;/p&gt;

&lt;p&gt;首先，我们说到了人机未来合作决策的方式，那就是机器做出决策，然后人类用常识去修正。比如，著名打车软件优步的算法，给出的建议是在大雪天涨价来激励司机多出来，但优步的员工却可以判断这时候涨价会激怒消费者，对公司的形象不利，从而选择维持原价。&lt;/p&gt;
&lt;p&gt;第二，我们说到了各式各样的平台降低了交易成本，从而让我们可以满足小众的需求。做平台要趁早，要保持开放。&lt;/p&gt;
&lt;p&gt;最后，我们说到了要利用好群体的智慧，去处理团队没有能力解决的问题，但也要保有一个管理核心。&lt;/p&gt;

&lt;p&gt;好了， 以上就是今天为你分享的全部内容， 下面说说我个人的对这本书的看法：&lt;/p&gt;

&lt;p&gt;每一个核心概念都需要有其对应的另一极。在这本书里，作者对机器学习给出的对应是人的心智；对于例如优步这样的平台，对应的概念是产品，而对于众包和集群智慧，给出的对应概念是核心团队。而连接这三组概念的是科技如何影响人与人合作的方式。机器学习改变了人类怎么做决策，交易平台改变了人们怎么获得生活所必须的吃喝拉撒，而众包则改变了人们怎么去解决一个困难问题的方式，或者怎么去度过闲暇的时间。&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt; 扩展阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383237&amp;amp;idx=1&amp;amp;sn=c9562cbdcfea785da928434973116aae&amp;amp;chksm=84f3cb84b3844292efc85670d09d9eb0405a7db370782fba722919ff40b7ed028a7825b12909&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;读《人之彼岸》说说我心目中的AI与反乌托邦&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383124&amp;amp;idx=1&amp;amp;sn=80b21ed5c144027b12388abf85c7dccb&amp;amp;chksm=84f3cb15b38442034b620347e8530958e53546d377e990c5a4c8bd111a3238be44926496b57b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;人的价值在于提问-读《Human are underrated》&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;



</description>
<pubDate>Sun, 14 Jan 2018 06:16:44 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/8LBv6gbwqV</dc:identifier>
</item>
<item>
<title>[原创]2017 我的学习之路</title>
<link>http://www.jintiankansha.me/t/Suu0gyNwLb</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/Suu0gyNwLb</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;span&gt;伟大的&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;毛主席这样说：&lt;/span&gt;“读书是学习，使用也是学习，而且是更重要的学习”。在&lt;span&gt;17&lt;/span&gt;&lt;span&gt;年底，借着万门大学征文的机会，在这里总结下我自以为的学习之道，分享给每一位也许迷茫也许焦虑的同学，培根（不是吃得那个，是腐国的一位大思想家）曾说过，我活着是为学习，而学习并不是为活着。这句话前半部分可以看成是终身学习的鸡汤，而后半句则是告诫你去学一些看起来和求生无关的东西，通过学习，活出自己的个性来。这句话应和我最喜欢引用的一句话古之学者为己&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;今之学者为人。在当下的社交媒体上，标注并分享自己学习了一个内容，要远远比学习某一个内容来的简单的多，人们都有去做简单的事情的冲动，但学习就应该选择那条难走的路。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;在今年夏天&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;的万门复杂系统和机器学习的特训班上，我十分荣幸的应许铁邀请，献丑做了一回授课讲师，授课的经历，给我留下了即深刻又美好的回忆，更令我受益良多。做为只是粗粗了解机器学习的一位外行，我本对接受邀约很犹豫，觉得自己讲不出什么干货，但耐不住基友的邀请最终答应了下来，课前很是花功夫做了准备，写课程的逐字稿，一次次的打磨&lt;/span&gt;PPT&lt;span&gt;，在这个过程中深化了自己对之前学过的课程和看过的书籍的理解，更锻炼了自己的表达能力和时间掌控的能力，在此要借着这个平台感谢万门大学和混沌巡洋舰给了我这个机会来实践自己通过输出来主动促进学习效率的学习之道。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;在我这个夏天做的分享中，我曾细致的讨论了如何在未来自学机器学习，还推荐了一些相关的视频课程和书籍。后来还曾经针对大数据，列过一个书单，（&lt;/span&gt;AI&lt;span&gt;，大数据，复杂系统 最精&lt;/span&gt; &lt;span&gt;40&lt;/span&gt;&lt;span&gt;本大书单），然而在我心中，学习的最佳方法绝不是仅仅去读书，而是要给身边的小伙伴讲出你读的这本书说了什么，最终的目标是要做到学以致用，尝试用书中所说的道理方法来改变你看问题做决策的习惯。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;若你觉得高质量的输出对于你来说太难了，你要明白写作或是讲课，本身就是很难的，需要你对自己所学的有深度的了解。为了给输出做好准备，可以通过问题来指导你的学习。一开始，问题可以是有趣的，例如在万门的免费课程&lt;/span&gt;-&lt;span&gt;《阿哲的疯狂实验室》中，童校就是通过一个个有趣的问题吸引人去进入看似深不可测的高等数学或大学物理中。然而这样有趣的问题，终究只能算是开胃菜。通过问题指引的学习，还应当去问些基本的问题，只有通过这些类似屈原的“天问”式的大问题，我们才能够系统性的学习一个学科。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;比如想学经济学，该问那些问题了，最初的问题可能会是生活中的房产现象，例如为什么在大萧条的时候，资本家宁可讲牛奶倒掉，也不愿意给穷人喝，这个问题由之同学给出了很好的回答，然而若是想全面的学习经济学，心中必须要弄清楚经济学想解决的是那些大问题，这些问题注定是超越时代和文化背景的，也一定不会是非黑即白而会是两难的选择，例如该如何权衡公平和效率，该如何分配稀缺的资源。带着这样的大问题，再去看经济学各个子学科中的假设与简化，就不会陷于细节而忘记了学习这门学科的初心。我的好友由之今年也曾经在万门的经济特训班讲课，为此他写下了数万字的讲稿，我想他也因此而加深了对经济学的理解了吧。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;不替万门做广告了，总结一下我想分享的学习之法。学习是困难的，能激励你坚持学习的不应仅仅是意志力，更应该是情感。这情感有由内而生的，即我们的好奇心，对于那些我们未知的有趣的问题，我们每个人都天生想知道问题的答案，只是该如何做才能避免让这份好奇心因为长大了就慢慢消散？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;激励我们持续学习的第二种情感由外而内，来自于和他人分享知识带来的快乐。为了更高效的和他人分享，你需要将自己学到的观点和案例按照那些永恒不变的大问题归档，将你读过的书和文章中的每个知识点按照其可以回答的问题打上标签，进行分类归档，只有这样才能高效的讲给身边的伙伴。而更多的伙伴得到了知识光芒的照耀，也会激励你持续去追求新知的，只有这样的正向循环转动了起来，才可以督促自己去看更多的书，去问更多的问题，然后再将这些问题归类成大问题的子问题或变种，从而即加深了自己对知识的理解，也保证了在自己学到的内容是规整有序的。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382825&amp;amp;idx=1&amp;amp;sn=85d1aa1ef152c25d05fc576ceb3a310d&amp;amp;chksm=84f3ca68b384437e5f45ee169f6f0cbd991a7230fe54d0d2da0449fe44a2fd241ba3f9c729d8&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;如何评价人工智能与复杂系统特训课-看看铁哥怎么说&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 09 Jan 2018 17:58:18 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/Suu0gyNwLb</dc:identifier>
</item>
<item>
<title>[原创]深度学习入门最少需要知道什么？</title>
<link>http://www.jintiankansha.me/t/yjIfMX7Tjm</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/yjIfMX7Tjm</guid>
<description>&lt;p&gt;本文是巡洋舰深度课程讲师龚鹤扬根据文章 What you need to do deep learning __by Rachel Thomas 给出一个最简单的回答。&lt;/p&gt;
&lt;p&gt;经常有人会问：&lt;/p&gt;
&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;深度学习需要什么样的电脑？&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;怎样入门深度学习？&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;对于深度学习初学者，有什么建议？&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;怎用应用深度学习技术到某个具体的问题？&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;这些问题其实就是&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;深度学习需要什么样的硬件，软件，背景和数据？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;br /&gt;&lt;/h2&gt;
&lt;h2&gt;硬件&lt;/h2&gt;
&lt;p&gt;深度学习硬件很大的受益于游戏产业的高性能GPUs， 众多不同种类的显卡，我们推荐 Nvidia:&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccS7wUjwvEibuOBpJRAOMp1wAT8rBkyCuibpvfa9K4rOibibgnMIYdCDFjWUtGpTcMLxLIoRdQzL4BceA/0?wx_fmt=jpeg&quot; width=&quot;500&quot; class=&quot;&quot; data-ratio=&quot;0.8017578125&quot; data-w=&quot;1024&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;如果你的电脑没有 GPU 或者不是英伟达的 GPU，那么你有以下几个选择使用 fast.ai 的 Crestle 云服务，亚马逊云， 阿里云等。使用起来有些麻烦，使用方法参考原文：http://www.fast.ai/2017/11/16/what-you-need/ 。&lt;/p&gt;
&lt;h2&gt;&lt;br /&gt;&lt;/h2&gt;
&lt;h2&gt;软件&lt;/h2&gt;
&lt;p&gt;深度学习是一个新兴领域，软件库和工具包每天都在快速地提升。我们建议使用 Pytorch。为什么不推荐 Tensorflow 呢？ 主要原因是 Tensorflow 的动态计算图机制不成熟，其会话管理机制也有学习成本。Pytorch 适用于&lt;span&gt;探索科研和快速开发模型原型&lt;/span&gt;， 它相对来说更容易理解和使用。原文总结了如下几个理由:&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccS7wUjwvEibuOBpJRAOMp1weFiaa7Iwn9mCNXCKYaHJvBmOs5qhZPzVWQtY3cOga4DBVaVZ2rYzz8A/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.521484375&quot; data-w=&quot;512&quot; data-type=&quot;png&quot; /&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li&gt;
&lt;p&gt;易于调试&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;动态计算图更适用于自然语言处理&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;支持传统的面向对象编程风格&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;TensorFlow 的 上下文管理器和会话等机制需要我们花费额外的精力学习&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;&lt;br /&gt;&lt;/h2&gt;
&lt;h2&gt;背景&lt;/h2&gt;
&lt;p&gt;深度学习需要的基础主要包括两个部分：&lt;/p&gt;
&lt;p&gt;虽然数学对学好深度学习极其重要，但是我们不建议在前期花太多时间在数学基础上。个人建议是直接看看西瓜书的数学附录， 花书中的数学基础部分。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccS7wUjwvEibuOBpJRAOMp1wBhUpsawDPo59ly9LnNBajDvKLJZukz3GpKOic3icBeExgDsWt01LBu1g/0?wx_fmt=jpeg&quot; width=&quot;500&quot; class=&quot;&quot; data-ratio=&quot;1&quot; data-w=&quot;300&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;br /&gt;&lt;/h2&gt;
&lt;h2&gt;数据&lt;/h2&gt;
&lt;p&gt;在大众的印象中，训练一个深度学习模型动辄需要几百万的样本，然而这并不总是成立。很多时候我们利用 &lt;span&gt;迁移学习(结合数据增强技术)&lt;/span&gt;，我们用几百上千个数据就可以训练一个很好的深度网路了。 例如， 在 medical start-up Enlitic， Jeremy Howard 领导的一个团队用 1000 个肺部CT扫描 图像， 训练出一个网络诊断肺癌，准确率比专家还要高！&lt;/p&gt;
&lt;p&gt;C++ 库 Dlib 中的一个人脸检测例子，甚至只有4个训练样本！&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccS7wUjwvEibuOBpJRAOMp1wUXJQLP3T8MybVJthjCRJLUBDkhRwN0JwLtvicbaovjzpnsVPiboH3U6Q/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.6578125&quot; data-w=&quot;640&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;迁移学习和数据增强技术减少了深度学习模型对数据量的需求。当然还有其他方法， 例如生成对抗，深度强化学习等很多时候不需要大量的人工标注样本。而深度学习初学者需要用到的数据甚至直接集成在框架中（例如 Pytorch），直接调用就行。&lt;/p&gt;

&lt;p&gt;巡洋舰深度课程系列文章&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383161&amp;amp;idx=1&amp;amp;sn=b27c2a0686d57b13daadcfd16cb35dac&amp;amp;chksm=84f3cb38b384422ecfca55da7b54978a8f3742605549566920507d5e032e16da1be50c1f5f97&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;你需要的深度学习数学基础： 从入门到进阶&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383212&amp;amp;idx=1&amp;amp;sn=e6dbbda2acc5984c8d06e24ec9c84d09&amp;amp;chksm=84f3cbedb38442fb58f0aea635821fcf4ba3edaacef4685716c7eadb6191197ebfa70a6bf14b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;你所不能不知道的CNN&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383226&amp;amp;idx=1&amp;amp;sn=959e2bfa3cdf523250b1d082548380a2&amp;amp;chksm=84f3cbfbb38442ede89aa9b8bd4e1db04c7d5faaa4111a73d9712f1055aeebcd8ec3f2b17b07&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;用深度学习玩图像的七重关卡&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 08 Jan 2018 17:36:45 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/yjIfMX7Tjm</dc:identifier>
</item>
<item>
<title>[原创]读《人之彼岸》说说我心目中的AI与反乌托邦</title>
<link>http://www.jintiankansha.me/t/EHOS3SSh5L</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/EHOS3SSh5L</guid>
<description>&lt;p&gt;18年读的第一本书，是郝景芳的《人之彼岸》，全书的六个故事和两篇非科幻的思索，相映成趣，思考中提到的观点，都在小说中有所呈现。整本书的主题，用作者的话可以看成是&lt;span&gt;“人工智能在彼岸，我们在此岸。”也&lt;/span&gt;可以用书中提出的“逆图灵测试”来概括。图灵测试是通过人类无法分别和Ta交流的是人类还是电脑来判定智能水平的，而逆图灵测试则是通过呈现人类特有的性状，让人类能够和那些智能水平上已经不相上下的AI区分开来。全书写的六个故事，每一个都可以看成是逆图灵测试，故事中的英雄有的成功了，而有的则在故事的最后明白自己为什么没有通过测试。&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdV5esuvsoSc6k8dG6TcBrCk9Sabyh4Ss7Ip2lUDSPXubicA4MW9dXicB2Bkt7qBJzEStTAnJRDIe1A/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.4455445544554455&quot; data-w=&quot;303&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;在对这本书进行创造性的批判之前，想先说说对这本书整体的看法。文字简洁，论述到位，作者对认知心理学和人工智能的了解都深入本质。然而作者将AI进行的漫画式的夸张处理，我却不赞同。这本书中的AI，不管能力有多强，都缺少情感，永远表现的彬彬有礼，不会被愤怒等负面情绪冲昏了头脑，从艺术上来说，这样可以创造出戏剧冲突，凸显人与机器的不同，但是未来的AI真的会是这样吗？我觉得值得担心的不是机器背后的数字化逻辑侵蚀了那些使人类生活有意义的部分，而是机器用廉价的仿制品让人类不觉得使生活有意义的是爱与创造。&lt;/p&gt;

&lt;p&gt;关于未来AI的讨论，从更抽象的层次来看，可以看成是反乌托邦式的推演。人们更容易害怕的是通过脑机接口，全球化的AI知道了每个人一生中的所有想法，是机器通过概率的计算让人的自由意志变成了幻象，这些都不过是奥威尔式的1984的变种。但真正要担心的是赫胥黎式的未来，而从目前的趋势来看，这种未来是更有可能的。在前一种的未来预测中，恋爱的人不在有眼神的交流，是因为觉得指导约会的软件无法定量分析眼神中的信息，而在一种未来里，是因为人们戴上了假眼睛，可以通过改变眼睛的颜色来交流，并把这叫做眼神的交流。&lt;/p&gt;

&lt;p&gt;大前研一有两本书，一本叫《低欲望社会》，另一本叫《低智商社会》，这俩本书虽然说的是日本，但在全球化的大趋势下，书中所说的也多少适用于其他国家。书中所说的低欲望社会，主要指的是年轻人缺少好奇心和上进心，不管对消费还是恋爱，都缺少兴趣，只想宅在家里。这看起来和人工智能没有半毛钱关系，但是若不是有一个智能的网络来保证这些人基本的生存需求，那么想要维持这样的低欲望社会，是不可能的。&lt;/p&gt;

&lt;p&gt;然而按照常理推断，人类的需求金字塔是普世的，没有人会只安逸于最底层需求的满足，而不去追求自我实现。要想解释这个矛盾，我们就要看看满足自我实现的需求，有几种途径。身体力行的去做自然能让人有成就感，可人脑中的镜像神经元决定了人可以不需要自己去冒险，只需要通过冒险的故事，就能够差不多的体会到实现自我是怎样一种感觉。而这正是为什么会有低欲望社会的原因。虚构的游戏和影视剧让人们可以长久生活在幻想中。&lt;/p&gt;

&lt;p&gt;AI的进步会使的让人停留在幻想中变得更容易，就拿当下已有的技术来说。个性化的推荐会给你那些会让你反复点击的内容，而AR的进步会让内容的呈现变得难以分清真假。不需要脑机接口这样的黑科技，只要未来几十年，人类最聪明的大脑还是将精力放在获取更多的点击，而不是去探索太空，那么这种未来就会越来越变成现实。&lt;/p&gt;

&lt;p&gt;人类作为万物之灵，不止在于创造了，还在于其心智中的无用之大用，比如认为人生有比利益优化更重要的意义，能感受得到伟大艺术家给人传递的震撼。这是人类区别于机器的更基本的特征，不是常识，心智理论或者信息整合等具体的能力，而是一种一旦说出来就没意思的那点意思。正是因为不能说，所以真正需要提防的不是奥威尔式的禁止和无视，而是对这种精神的一种降级后表达。比如我中学时喜欢读李白的诗，但若是他诗中的句子出现在语文考试的阅读理解中，让我不得不写下干巴巴的中心思想，那这首诗，至少在那一刻就算毁了，就不会再让我感受到心灵的震动了。&lt;/p&gt;

&lt;p&gt;关于AI的讨论，最终都要回到该如何做好一个人的层面上。《人之彼岸》这本书在其最后一章，讨论了人工智能时代的教育，作为一个母亲，她谈论的是怎样去教育孩子。而这里想说说该怎么对自己进行教育。这里说三点，第一是回归到原始的材料上，在听他人的转述之前，先去看看第一手的信息来源是怎么说的，再看看他人根据文本进行的展开。要进行信息整合，就不能只根据关键词去做联想，去构建知识图谱，这机器也会。人的作用是将自己的亲身经验加入到文本的理解中，机器的理解是做减法，人的理解是做加法。&lt;/p&gt;

&lt;p&gt;第二是关注信息的网络结构，要去深挖那些处在网络中心的知识点，这也是人能够进行小样本学习的关键。人类识别狗狗，不是通过数万照片的持续训练，而是在头脑中构建了关于狗狗这个概念的一张网，第一次见到狗狗，学到了叫声，大小等核心的不变的特征，第二次注意到了狗狗的尾巴，耳朵毛色等次要特征，从而在第三次见到狗就能认出了。通过将概念按网络拆解，人可以在学会了狗狗这个概念之后，就可以将之前的经验用在识别狗狗的品种上。这正是机器所无法做到的，深度学习可以做到层次化，却无法体察出观念与观念之间的驱动关系网。&lt;/p&gt;

&lt;p&gt;第三点要提醒的是去学习一些看起来无用的知识，这是人之为人最不同的一点，机器现在已经有注意力，有创造性，未来也注定会有主动的行为。但机器不会去做超越胜败的尝试。对于机器来说，没有优化的目标或评价标准，就没有了存在的意义，但人类却可以自己通过在无用的尝试中找到的规律，不断为自己创造新的标杆，在通过艺术，文学等来向更多人展示自己认为的有意义的生活是怎样的。所以去了解那些没有直接用途的知识，是为我们找到船，而实用的知识不过是桨，没有了船，在陆地划的浆再大，也走不远。&lt;/p&gt;


&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;扩展阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383164&amp;amp;idx=1&amp;amp;sn=0cfac710d4d5783ed06bbdb694828409&amp;amp;chksm=84f3cb3db384422b11c90bf7826cc7b52a3f74176442fb28e6ebc27b5e44c9d1ef33f39d077e&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;多余的话 借深度网络说说最近发生的几件事&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;


</description>
<pubDate>Sat, 06 Jan 2018 04:11:12 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/EHOS3SSh5L</dc:identifier>
</item>
<item>
<title>用R语言实现深度学习情感分析例子</title>
<link>http://www.jintiankansha.me/t/LMMxn2nEDp</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/LMMxn2nEDp</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;作者介绍：&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;黄升&lt;/strong&gt;，普兰金融数据分析师，从事数据分析相关工作，擅长R语言，热爱统计和挖掘建模。&lt;/p&gt;


&lt;p&gt;&lt;span&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;到了2018新的一年。18岁虽然没有成为TF-boys，但是2018新的一年可以成为TF（Tensorflow-boys）啊~~&lt;/p&gt;
&lt;h3&gt;word embeddings介绍&lt;/h3&gt;
&lt;p&gt;      之前建立的情感分类的模型都是Bag of words方法，&lt;span&gt;&lt;strong&gt;仅仅统计词出现的次数&lt;/strong&gt;&lt;/span&gt;这种方法破坏了句子的结构。这样的结构，我们也可以使用如下的向量（one hot 编码）表示句子「The cat sat on the mat」：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5011494252873563&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPaVqEwmr79eOyMfOUutFxLaXe5RKPLObjHpmbTiaXtwialQibicicMGOzgfA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;435&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      然而，在实际应用中，我们希望学习模型能够在词汇量很大（10,000 字以上）的情况下进行学习。从这里能看到&lt;span&gt;&lt;strong&gt;使用「独热码」表示单词的效率问题&lt;/strong&gt;&lt;/span&gt;——对这些词汇建模的任何神经网络的输入层至少都有 17000,000 个节点。因此，我们需要使用&lt;span&gt;&lt;strong&gt;更高效的方法&lt;/strong&gt;&lt;/span&gt;表示文本数据，而这种方法不仅可以保存单词的上下文的信息，而且可以在更低的维度上表示。这是 &lt;span&gt;&lt;strong&gt;word embeddings 方法&lt;/strong&gt;&lt;/span&gt;发明的初衷。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.0586510263929618&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPueCErIy2T4I5IfwoNsJmdlYD5cw0aTicrZYC1OnnY7tJTGx4u6I3lDQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;341&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      word embeddings就是&lt;span&gt;&lt;strong&gt;将一个个词映射到低维连续向量&lt;/strong&gt;&lt;/span&gt;(如下图所示) ：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.4393939393939394&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccP99flmtqZiaMWhHMPGfY6WmQh8dSUicuk1jZKO2Qm9s5S1mj1hRoyvbBQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;264&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      这种向量的思想就是将相似的词映射到相似方向，所以，语义相似性就可以被编码了。相似性一般可以通过&lt;span&gt;&lt;strong&gt;余弦相似度来衡量&lt;/strong&gt;&lt;/span&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9490616621983914&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPQqNJpOPcx1UF8Bu7rMiaPhljHp46jSJF5VokPRokiaWPvOHbMYY11TgQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;373&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;安装TensorFlow和Keras&lt;/h3&gt;
&lt;pre readability=&quot;4.5&quot;&gt;
&lt;code class=&quot;&quot; readability=&quot;3&quot;&gt;&lt;span class=&quot;&quot;&gt;# 安装并加载Keras包&lt;br /&gt;&lt;/span&gt;install.packages(&lt;span class=&quot;&quot;&gt;&quot;devtools&quot;&lt;/span&gt;)
devtools::install_github(&lt;span class=&quot;&quot;&gt;&quot;rstudio/keras&quot;&lt;/span&gt;)
install_keras()&lt;span class=&quot;&quot;&gt;library&lt;/span&gt;(keras)&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;
&lt;span class=&quot;&quot;&gt;# 安装并加载TensorFlow包&lt;br /&gt;&lt;/span&gt;devtools::install_github(&lt;span class=&quot;&quot;&gt;&quot;rstudio/tensorflow&quot;&lt;/span&gt;)&lt;span class=&quot;&quot;&gt;library&lt;/span&gt;(tensorflow)
install_tensorflow()&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;      &lt;span&gt;&lt;strong&gt;注&lt;/strong&gt;&lt;/span&gt;：安装TensorFlow和Keras前需要安装Anaconda，Anaconda尽量装最新版本的，Anaconda在Windows安装有一些坑，我是把Java环境删掉还有使用默认路径才成功安装了Anaconda。&lt;/p&gt;
&lt;h3&gt;检测是否安装成功&lt;/h3&gt;
&lt;pre&gt;
&lt;code class=&quot;&quot;&gt;&lt;span class=&quot;&quot;&gt;# 输入下面代码&lt;br /&gt;&lt;/span&gt;sess = tf$Session()
hello 'Hello, TensorFlow!')
sess$run(hello)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;OK,如果没有问题的话，你的结果也将是如上图所示，则表明你已安装成功。&lt;/p&gt;
&lt;h3&gt;LSTM原理&lt;/h3&gt;
&lt;p&gt;      &lt;span&gt;&lt;strong&gt;长短期记忆网络&lt;/strong&gt;&lt;/span&gt;——通常简称“LSTMs”，是一种特殊的RNN，能够学习长期依赖关系，它可以桥接超过1000步的时间间隔的信息。LSTM由Hochreiter和Schmidhuber （1997）提出，在后期工作中又由许多人进行了调整和普及（除了原始作者之外，许多人为现代LSTM做出了贡献）。LSTM在各种各样的问题上工作非常好，现在被广泛使用。&lt;/p&gt;
&lt;p&gt;      LSTMs被设计出来是&lt;span&gt;&lt;strong&gt;为了避免长期的依赖性问题，记忆长时间的信息实际上是他们的固有行为&lt;/strong&gt;&lt;/span&gt;，而不是去学习，这点和传统的具有强大的表征学习能力的深度神经网络不同。&lt;/p&gt;
&lt;p&gt;      所有的RNNs（包括LSTM）都具有一连串重复神经网络模块的形式。在标准的RNNs中，这种重复模块有一种非常简单的结构，比如单个tanh层：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.448512585812357&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPAEg8bvV0OU0gKWZhloPBvPleuYTOB4sYLoGJIr60HIibRCqrCxxPVJA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;437&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      &lt;span&gt;&lt;strong&gt;什么是tanh？&lt;/strong&gt;&lt;/span&gt;中文叫双曲正切函数，属于神经网络隐藏层的activation function（激活函数）中的一种。别以为是什么好厉害的东西，其实就是一个简单的以原点对称的值域为[-1,1]的非线性函数。而神经网络中比较常见的另外一个激活函数 &lt;span&gt;&lt;strong&gt;sigmoid 函数&lt;/strong&gt;&lt;/span&gt;，则不过是把tanh函数往上平移到[0，1]的区间，这个函数在LSTM也会用到。&lt;/p&gt;
&lt;p&gt;      LSTM也有像RNN这样的链式结构，只不过重复模块有着与传统的RNN不同的结构，比传统的RNN复杂不少：不只是有一个神经网络层，而是有四个神经网络层，以一个非常特殊的方式进行交互。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.41935483870967744&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPVS0u2s7fxjJJC53FT0UhhF3CWcgJBIKPBFXxNHRVsL6l8YfTPZ16TA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;434&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      不用担心看不懂细节部分是什么意思，稍后我们将逐步浏览LSTM图。现在，让我们试着去熟悉我们将要使用的符号。&lt;/p&gt;
&lt;p&gt;      在上面所示的图中，我们对以上符号进行如下定义：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2361111111111111&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccP67x2JWmNtgedWsn2hXtt5SJM9QytuErf5CibhUnh6JyZYicUibTwRFnNg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;432&quot; /&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;黄块表示学习神经网络层（tanh层或sigmoid层）；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;粉色圆圈表示按位操作，如向量加法或者向量点乘；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;每条线代表着一整个向量（vector），用来表示从一个节点的输出到另一个节点的输入；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;合并的线代表连接或者说是拼接;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;分叉表示其内容被复制，复制内容将转到不同的位置&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;LSTMs背后的核心理念&lt;/h3&gt;
&lt;p&gt;      LSTMs的关键是细胞状态（cell state），是一条水平线，贯穿图的顶部。而Cell 的状态就像是传送带，它的状态会沿着整条链条传送，而只有少数地方有一些线性交互。&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.4585987261146497&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccP0QAlicLqwOQYOibpbOjc5OXbAPRoibDEhlr4graFY9rhVNTiblUmPiapaHw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;314&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      因此“门”就是LSTM控制信息通过的方式，这里的&lt;span&gt;&lt;strong&gt;” σ “&lt;/strong&gt;&lt;/span&gt; 指的是 sigmoid 函数。Sigmoid 层的输出值在 0 到 1 间，表示每个部分所通过的信息。&lt;span&gt;&lt;strong&gt;“0” 意味&lt;/strong&gt;&lt;/span&gt;着“让任何事情无法通过”或者说成”忘记所有的事“；&lt;span&gt;&lt;strong&gt;“ 1 ”意味&lt;/strong&gt;&lt;/span&gt;着”让一切都通过！“ 或者说”我要记住这一切! “&lt;/p&gt;
&lt;p&gt;      一个 LSTM 有三个这样的门，分别是“输入门”、遗忘门“和 ”输出门“，在单一模块里面控制 cell 的状态。&lt;/p&gt;
&lt;p&gt;      首先，LSTM 的第一步就是让信息通过”遗忘门“，&lt;span&gt;&lt;strong&gt;决定需要从 cell 中忘掉哪些信息&lt;/strong&gt;&lt;/span&gt;。它的输入是 ht-1 和 xt。另外，我们之所以使用sigmoid激活函数是因为我们所需要的数字介于0至1之间。Ct−1 就是每个在 cell 中所有在 0 和 1 之间的数值，就像我们刚刚所说的，0 代表全抛弃，1 代表全保留。&lt;/p&gt;
&lt;p&gt;      看到这里应该有朋友会&lt;span&gt;&lt;strong&gt;问什么是ht&lt;/strong&gt;&lt;/span&gt;，ht是LSTM层在t时刻的输出，但不是最终的输出，ht仅仅是LSTM层输出的向量，要想得到最终的结果&lt;span&gt;&lt;strong&gt;还要连接一个softmax层&lt;/strong&gt;&lt;/span&gt;（sigmoid函数的输出是”0“”1“，但是使用softmax函数能在三个类别以上的时候输出相应的概率以解决多分类问题），而x就是我们的输入，是一个又一个的词语。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.41766109785202865&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccP6IRWK69v1hcsHLSCJFmtMTug4bYy2oHR2UajXoFgOOLric2UPw0tpLQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;419&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      下一步，我们需要&lt;span&gt;&lt;strong&gt;决定什么样的信息应该被存储起来&lt;/strong&gt;&lt;/span&gt;。这个过程主要分两步。&lt;span&gt;&lt;strong&gt;首先是 sigmoid 层&lt;/strong&gt;&lt;/span&gt;（这就是“输入门”）决定我们需要更新哪些值；&lt;span&gt;&lt;strong&gt;随后，&lt;/strong&gt;&lt;strong&gt;tanh 层&lt;/strong&gt;&lt;/span&gt;生成了一个新的“候选添加记忆” C`t，&lt;span&gt;&lt;strong&gt;最后，我们将这两个值结合起来&lt;/strong&gt;&lt;/span&gt;。结合后能够加入cell的状态（长期记忆）中。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.3726851851851852&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPqKCU5AMBk1G5mLT2I5uiaIFX9Yts2wZlKpFUrVnAR3CfyibUugTS1jTg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;432&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      接下来我们可以更新 cell （长期记忆）的状态了。首先第一步将旧状态与通过遗忘门得到的 ft 相乘，忘记此前我们想要忘记的内容，然后加上通过输入门和tanh层得到的候选记忆 C`t。在忘记我们认为不再需要的记忆并保存输入信息的有用部分后，我们就会得到更新后的长期记忆。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.3696682464454976&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPaQpIoAjR9FhvBbYSQSXjqT3UVZ2qdwID0f7b3bicR1DOjtaYqtdGibtg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;422&quot; /&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;-0.5&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;strong&gt;输出门&lt;/strong&gt;&lt;br /&gt;      接下来我们来更新一下ht，即输出的内容，这部分由输出门来完成。首先，我们把 cell 状态通过 tanh 函数，将输出值保持在-1 到 1 间。随后，前一时刻的输出ht-1和xt会通过一个 sigmoid 层，决定 cell 状态输出哪一部分。之后，我们再乘以 sigmoid 门的输出值，就可以得到结果了。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.38686131386861317&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPe146uroN5rMcLib9C808xy6PP74MBhbW7EO8db9om9OTBNTrtlHPNlA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;411&quot; /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;R上用LSTM做情感分类&lt;/h3&gt;
&lt;pre readability=&quot;4.5&quot;&gt;
&lt;code class=&quot;&quot; readability=&quot;3&quot;&gt;max_features 20000&lt;br /&gt;batch_size 32&lt;p&gt;&lt;span class=&quot;&quot;&gt;# Cut texts after this number of words (among top max_features most common words)&lt;br /&gt;&lt;/span&gt;maxlen 80  cat(&lt;span class=&quot;&quot;&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;

    
'Loading data...\n'&lt;/span&gt;)

imdb &lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.4159132007233273&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPx5ldWMJ88hUbrcHRuPo4uKG5gjrgxGh0kcnMEnDY7KST3iadRSKhxVw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;553&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;IMDB数据集包含有2.5万条电影评论&lt;/strong&gt;&lt;/span&gt;，被标记为积极和消极。影评会经过预处理，把每一条影评编码为一个词索引(数字)sequence(前面的一种word embeddings方法） 。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;&quot;&gt;cat(length(x_train), &lt;span class=&quot;&quot;&gt;'train sequences\n'&lt;/span&gt;)
cat(length(x_test), &lt;span class=&quot;&quot;&gt;'test sequences\n'&lt;/span&gt;)
cat(&lt;span class=&quot;&quot;&gt;'Pad sequences (samples x time)\n'&lt;/span&gt;)

x_train 'x_train shape:', dim(x_train), &lt;span class=&quot;&quot;&gt;'\n'&lt;/span&gt;)
cat(&lt;span class=&quot;&quot;&gt;'x_test shape:'&lt;/span&gt;, dim(x_test), &lt;span class=&quot;&quot;&gt;'\n'&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.1837837837837838&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPrIGxbicFAsJNrNfiaBnL5VhedBJSX4SYFzWEcMhVy9SbTKz2iatKEIPKw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;370&quot; /&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;&quot;&gt;cat(&lt;span class=&quot;&quot;&gt;'Build model...\n'&lt;/span&gt;)
model %
  layer_embedding(input_dim = max_features, output_dim = &lt;span class=&quot;&quot;&gt;128&lt;/span&gt;) %&amp;gt;% 
  layer_lstm(units = &lt;span class=&quot;&quot;&gt;64&lt;/span&gt;, dropout = &lt;span class=&quot;&quot;&gt;0.2&lt;/span&gt;, recurrent_dropout = &lt;span class=&quot;&quot;&gt;0.2&lt;/span&gt;) %&amp;gt;% 
  layer_dense(units = &lt;span class=&quot;&quot;&gt;1&lt;/span&gt;, activation = &lt;span class=&quot;&quot;&gt;'sigmoid'&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;      当然，可以尝试使用不同的优化器和不同的优化器配置：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;&quot;&gt;model %&amp;gt;% compile(
  loss = &lt;span class=&quot;&quot;&gt;'binary_crossentropy'&lt;/span&gt;,
  optimizer = &lt;span class=&quot;&quot;&gt;'adam'&lt;/span&gt;,
  metrics = c(&lt;span class=&quot;&quot;&gt;'accuracy'&lt;/span&gt;)
)

cat(&lt;span class=&quot;&quot;&gt;'Train...\n'&lt;/span&gt;)
model %&amp;gt;% fit(
  x_train, y_train,
  batch_size = batch_size,
  epochs = &lt;span class=&quot;&quot;&gt;15&lt;/span&gt;,
  validation_data = list(x_test, y_test)
)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面代码的训练过程如下图所示（我电脑大概用了20min）：&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.22603978300180833&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccP4mbzMYvic1m6WRFJujojBHtTvCCVe2gyjBlCiasPQicZDxWuxscGkB2Rw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;553&quot; /&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;&quot;&gt;&lt;span class=&quot;&quot;&gt;# 模型的准确度度量&lt;br /&gt;&lt;/span&gt;scores % evaluate(
  x_test, y_test,
  batch_size = batch_size
)

cat(&lt;span class=&quot;&quot;&gt;'Test score:'&lt;/span&gt;, scores[[&lt;span class=&quot;&quot;&gt;1&lt;/span&gt;]])
cat(&lt;span class=&quot;&quot;&gt;'Test accuracy'&lt;/span&gt;&lt;/code&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;

    
, scores[[&lt;span class=&quot;&quot;&gt;2&lt;/span&gt;]])
&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.08787878787878788&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPJaUia26365nfLJAbPtPAYChC5Kt8LoM0xCPpVRIv1jTiccVR42y1ibctg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;330&quot; /&gt;&lt;/p&gt;
&lt;p&gt;      接下来，我们再对比其他模型，不妨以随机森林为例：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;&quot;&gt;&lt;span class=&quot;&quot;&gt;library&lt;/span&gt;(randomForest)

y_train 1000)
predict &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.14859437751004015&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/yjFUicxiaClgVujRjsTzGOCIicdBPnhmccPGOibNB2RBnbCDHFzz89sSEzOH3bACHSSpK6gj918wU27Tj6rxzsicriaQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; /&gt;      &lt;/p&gt;
&lt;p&gt;很显然，集成算法随机森林远远没有LSTM出来的效果好。今天关于基于R语言的深度学习就介绍到这里。最后，很高兴和大家一起学习R上的深度学习。&lt;/p&gt;
&lt;p&gt;参考资料&lt;/p&gt;
&lt;p&gt;https://tensorflow.rstudio.com/keras/articles/examples/imdb_lstm.html&lt;br /&gt;http://colah.github.io/posts/2015-08-Understanding-LSTMs/&lt;/p&gt;
&lt;p&gt;扩展阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383226&amp;amp;idx=1&amp;amp;sn=959e2bfa3cdf523250b1d082548380a2&amp;amp;chksm=84f3cbfbb38442ede89aa9b8bd4e1db04c7d5faaa4111a73d9712f1055aeebcd8ec3f2b17b07&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;用深度学习玩图像的七重关卡&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

</description>
<pubDate>Tue, 02 Jan 2018 19:24:40 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/LMMxn2nEDp</dc:identifier>
</item>
</channel>
</rss>