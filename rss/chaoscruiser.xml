<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>[原创]节律的跨学科研究-读《同步：秩序如何从混沌中涌现》</title>
<link>http://www.jintiankansha.me/t/SpZuqXZgWn</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/SpZuqXZgWn</guid>
<description>&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.2592592592592593&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdg1gTK9kUXHNsC3zbVQMtOjNdEJ0DKYMzs5qbm4IXnd6mLbYDmkmTAicicOhv9Rq8q8E4Vb98Ny4cg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;这是一本老书了，英文版的书在2003年就有出版，但直到15年后，才由湛卢文化翻译成中文版。但是我觉得这本书的书名没有翻译好，在当代的语境中，同步的含义更接近英语中的update，有一种跟上主流的意义，但书中描述的却是去中心化的系统如何产生步调一致，因此题目翻译成”节律“更加恰当。至少这样在搜索这本书的书名的时候，不会被太多无关的项目干扰了。&lt;/p&gt;

&lt;p&gt;虽然是老书，但整本书想要读者的话到如今却没有过时。用一句话来概述这本书想说的，就是在不断增加的无序（增熵）下，各个尺度下的不同系统都具有产生节律的可能性，同步能力不依赖于智力，生命或自然选择。即使无意识的、没有生命的事物也会自发地同步。&lt;/p&gt;

&lt;p&gt;书中举的一个最出人意料的同步的例子-伦敦千禧桥，这座吊桥在第一次使用时就，在扭转振荡中崩塌。造成悲剧的是走动时的微弱横向力，平常这些微弱的横向力会相互抵消，但若是每个人都同步前进，所有横向力就会累加，变得集中。而在事实中，随着大桥的摇晃，行人不自觉地调整了步伐，而这一动作加剧了振动，使得更多人失去了平衡，使得桥摆动更加剧烈。&lt;/p&gt;

&lt;p&gt;什么是节律，书中提到的例子是数千只萤火虫在同一时间共同闪烁，数万条鱼在同一方向成群的游动，上万亿个电子在超导体中步调一致地前进，甚至女性室友之间的月经周期随着时间的推移开始相互匹配。但生活中节律远不止这些，例如手机厂商发布新机的时间，就会集中在那么几个月；例如团队游戏中有些英雄技能适合在同一时间上放出来，有些就不行；例如在电视剧中，有的角色放在一起就合拍，有些角色就显得突兀。这背后的道理，都可以在这本书中找到答案。&lt;/p&gt;

&lt;p&gt;为了研究清楚这样看起来形式不同的现象，科学家要做的是忽略其所有的生化差异，而关注本质的规律。于是不管是月经周期，脉动的起搏神经元，合唱的蟋蟀还是萤火虫的闪光节律，都被当成了“振子”。而所有这些现象中共同的特征则是其中每个个体都具有发送和接收信号的能力，而这两个能力的变化贯穿于振子的整个运动周期，从而带来的节律。&lt;/p&gt;

&lt;p&gt;下一步是将上述的概念用数学的形式描述出来，于是发送信号的能力被”影响力函数“来记录，而“灵敏度函数”将振子如何响应接收的信号进行了编码。于是描述一个振子所需要的只是这两个函数，一旦它们被选定，振子的行为就可以被确定，无论是作为信号的发送者还是接收者。&lt;/p&gt;

&lt;p&gt;抽象之后要做的是举出具体的例子，最好是跨界的例子。书中在描述时举的例子是一名在围绕着一个圆形跑道跑步的跑者。而同步如何产生的问题就变成了两名慢跑者如何通过在跑步时彼此不间断地喊口令让他们步调一致。而影响力函数则可以看出一串规则，比如何时叫同伴快一些，何时叫同伴慢一些，而灵敏度函数则记录他的同伴在什么时候言听计从，什么时候不理不睬，什么时候反其道而行之。&lt;/p&gt;

&lt;p&gt;将这个模型扩展到更多的个体时，就需要考虑到个体之间的差异了，在跑步的例子中就是每个人舒适的速度是多少。有了上述的三个变量，当我们需要利用当前位置来确定速度规律的时候，就会建立微分方程，从而能够在理论上根据当前来预测振子群未来的状态，从而研究是那些因素导致了振子群自发同步。&lt;/p&gt;

&lt;p&gt;科学中一个常用的思考范式是思考极限情况，如果所有振子的灵敏度函数都太低，那系统肯定不会产生同步，若是所有人接到指令加速，就以百米冲刺的速度跑起来，那系统也无法同步，而若是没有一个人来发号施令或者所有人都想指导别人，那自然也不会出现同步。&lt;/p&gt;

&lt;p&gt;思考极端情况的另一种方式是从个人的角度去提问，比如问当系统自发同步的时候，没有任何振子是不可缺少的。答案是同步的群体中没有领袖，任何一个振子都可以被移除而也会不影响系统的运行。&lt;/p&gt;

&lt;p&gt;下一个问题是同步后的速度（频率）会是怎样的？答案是群体可以按照其成员的平均速度运行，也可以比任何成员的速度更快或更慢。这个回答之所以反直觉，是读者将个体舒服的跑速和他可能达到的跑速搞混了，可能达到的跑速在我们的模型中取决于在相对舒适跑速的差异的灵敏度函数，个体可以受到集体的影响，跑得比自己舒适的快那么一点，而若是自己加速时超过了群体时最快的初始速度，那系统就可能同步在一个比初始的最快速度还快的速度上。&lt;/p&gt;

&lt;p&gt;下一个问题是群体中成员间的不同会怎样影响同步现象。若是个体之间的差异太大，即便他们的“影响度函数”和“敏感度函数”倾向于使他们聚在一起，也是无法出现同步现象的。只有当能力间的差异小于多样性的阈值时，同步才有可能出现。从这里可以看到生物学和物理学之间的联系，同步类似于相变，就像水凝固成冰。而区别在于同步关注的是时间层面，而相变是空间上分子运动方向的一致。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.6921887084300077&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdg1gTK9kUXHNsC3zbVQMtORgPIq9kwXZiamicFgq78npvIpHfnV62oyeRSX6yrxfdPDCxBicx2gpnog/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;1293&quot; /&gt;&lt;/p&gt;

&lt;p&gt;回到前文提到的吊桥的例子上来，为什么这件事会是新闻，是由于这样的事情不常发生，那是什么不同因素导致了千禧桥的悲剧。答案是只有在桥梁非常长、易弯曲、非常拥挤的时候才可能发生。这说明在类似的弱耦合的系统中，群体的大小也会成为决定相变是否发生的临界点，如果人数小于阈值时，桥一点也不摇晃，要是超过了阈值后毫无征兆地剧烈摇晃。&lt;/p&gt;

&lt;p&gt;第五个会影响群体同步的因素是不同个体之间的连接网络的结构。网络的结构总会影响其功能。假设现在跑步的说着不同语言的一群人，有的人会两种语言，有的人只会一种语言，这时要在群体上保持同步，就需要去考虑我说的跑慢点要经过几次翻译才能让身边的人听懂。假设每个人会说俩种语言，如果说不同语言的人都均匀的分布，那这群人的每条指令都要经过数百次的翻译才能传遍整个群体，但如果说同一种语言的人都聚在一起，那跑步的群体则会由于无法交流而分成很多个子群。上述的情况都无助与同步，而小世界网络则可以让全世界的人却都被非常短的关系连接，同时保有高度集群性。&lt;/p&gt;

&lt;p&gt;研究同步可以解释为什么会产生，而这知识则可以用来指导干预来帮助人们恢复或促成同步的诞生。比如睡眠的节律研究清楚，可以帮助治疗失眠。比如什么东西会流行，也可以看成是同步现象，《引爆点》这本书讲的就是社会层面上的同步。而生物体的衰老也和基因间的同步减缓有关，如果能够研究清楚基因间的同步，就能找到预警疾病的临界点。&lt;/p&gt;

&lt;p&gt;在讲述跑步的例子中，如果人群间的速度差异过大，那整个群体也会同步，只是会分成三群，一小群长跑健将，一小群懒散的散步，剩下的一大群人在中间。而这正是这些年来热议的阶级固化，阶级固化的影响之远，甚至可以从一部全是抄袭段子的电视剧”爱情公寓“中看出。&lt;/p&gt;

&lt;p&gt;09年的爱情公寓一让我记住了林宛瑜这个人物，但这个角色到了第三部短暂出场后就悲剧的离场。年轻时不明白其背后的道理，长大了才看出其背后阶级差异过大，带来的不是”天然呆“，而是对剧中的小市民情趣的嘲讽。在第一部出现的09年，阶级固化还不明显，但到了第三部，富有主见热爱自由的宛瑜只会让片中的其他女性显得像提前衰老的鱼眼睛，典型的场景是片中另外两位女性穿上婚纱后极为夸张的欣喜若狂在宛瑜的淡定下显得讨人厌。为了讨好爱情公寓的主要受众，宛瑜只能离开而不能与集体形成同步。&lt;/p&gt;

&lt;p&gt;既然说到了阶级固化这样沉重的话题，就说说另一件看似和同步没有关系的事情。最近网上流传着一个名为”这届年轻人要做好过苦日子的准备“，文中列举了所谓的消费降级的例子，还引用了人民日报的话，说物质充沛的时代要结束了。在我看来，物质的充沛其实来源于同步的产生。若非不同地区的人一同种植，运输，加工，自助餐的丰盛也不会出现。&lt;/p&gt;

&lt;p&gt;要准备过苦日子，究竟是由于阶级固化加深，从而社会间同步消失导致的生产力降低种下的果。而若是能通过苦日子让各阶层再一次步调接近，那也是接下来一轮繁荣的根。保持同步也不时刻都是好事，中风是神经元间不经意的同步造成的，而对于那些习惯了赚快钱的人，同步的正反馈则同样会让人在未来失去行动的能力。像自助餐这样同时吃下很多的暴饮暴食，也不利于身体的健康。&lt;/p&gt;

&lt;p&gt;总结一下，《同步：秩序如何从混乱中诞生》这本书从同步现象的如何产生介绍了混沌理论与复杂性科学，本文中描述的模型仅仅是书中精华的一小部分，书中讲述了如何用更简洁的模型来描述系统间同步的产生，讲述了作者个人的故事，讲述了不同学科间是如何连接起来的。&lt;/p&gt;


&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382190&amp;amp;idx=1&amp;amp;sn=eb3eba0905e52f12d3e63be6ae15333f&amp;amp;chksm=84f3cfefb38446f900903983ed3fd98365346b4c9bcf29d422a64b3c5fd224fe5bc6551a4ee3&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;未名湖的鱼-frazer｜演化和复杂系统（上）&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382194&amp;amp;idx=1&amp;amp;sn=37c14a31dcb773348f41209edc36b6f1&amp;amp;chksm=84f3cff3b38446e51cf019fe9004c430a749da4be73067cca191c626673d23a0fd608f50d878&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;复杂系统（下）：自组织和演化-&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;





</description>
<pubDate>Sun, 19 Aug 2018 18:23:19 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/SpZuqXZgWn</dc:identifier>
</item>
<item>
<title>[原创]铁哥的强化学习特训课</title>
<link>http://www.jintiankansha.me/t/pwsIsf7b1P</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/pwsIsf7b1P</guid>
<description>&lt;p&gt;&lt;span data-offset-key=&quot;8h5th-0-0&quot;&gt;报告大家一个好消息， 铁哥拟开设一个为期两日（12小时）的强化学习特训班。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;2i3so-0-0&quot;&gt;首先， 我们已经有了机器学习， 深度学习的课程， 为什么要开设一个强化学习特训课？  因为深度学习已经火了至少5年了吧， 你的小伙伴们已经早已使用pytorch，  tensorflow在cifar数据上玩的溜了飞起。 而你要想再度的装逼， 不， 说准确了是拥抱未来， 就要有一点新的东西啦。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;e6tvm-0-0&quot;&gt;那为什么是强化学习？  请看下图的技术泡沫爆裂图。  机器学习和深度学习在2017处于关注热度的顶峰， 大家看处在上升期的人工智能技术， 第一当属深度强化学习， 据这张非常表格非常粗糙的估计， 深度强化学习的技术成熟期在未来5-10年， 此时此刻， 正类似于深度学习在2010的状况。  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.67&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfqJgX6L51kcnJ07DHpdBzqmXKic2iaDgZOpUiacyYFWzBHst0BCZVTJINPzpfRibpMV6hWgUKSlj7ibBw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;e3oap-0-0&quot;&gt;作为80，90就已经开始起飞的强化学习技术， 事实上在一开始就被认为是在给机器赋予大脑，作为强人工智能的希望所在， 但无奈在2，30年里碰到了先天的技术瓶颈。  也仅在这三年， 强化学习遇到了2012崛起的深度学习， 碰撞出的这个深度强化学习，才开始了强化学习真正的异军突起， 这里面的标志事件也就是两阿的崛起， 所谓阿尔法狗先战胜人类， 然后弟弟阿尔法元又战胜了它， 这无疑是深度强化学习进军其他领域的序章。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;7e8q2-0-0&quot;&gt;深度强化学习给机器以灵魂， 将会影响机器人， 工业4.0， 智能交通， 智能电网，自然语言处理的所有领域， 而这些， 其实比目前深度学习革命所带来的工业影响力要深远广泛的多。  一些公司比如滴滴的智能调动和阿里的推荐系统，已经在它们的生产线上悄悄布置了深度强化学习的系统。 因此我们率先了解是赢在起跑线上， 而这一点， 也是我此次的课程意义之所以， 通过一步步的循循善诱和铺垫， 一窥深度强化学习的殿堂。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;up89-0-0&quot;&gt;为什么是叫一窥， 因为我们的两日显然只能看一眼， 而登堂入室更多的事实上是靠大家自己。 我们希望给只有浅显机器学习基础的同学， 能够对强化学习建立起一个思维导图。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfqJgX6L51kcnJ07DHpdBzqCgYN1dD3XAMuRjXZuW8LY5OKAgKPmsVSQzPpDldvFT9aVgpMWrl06g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;kt94-0-0&quot;&gt;那么我们这个课程会涵盖什么内容呢？&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ajlfr-0-0&quot;&gt;1，  强化学习基础， 从马尔科夫决策理解强化学习的目标和实现手段&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ddvg5-0-0&quot;&gt;2，  基于动态规划的优化算法让小鼠走迷宫&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;6apmg-0-0&quot;&gt;3，  探索与收益的平衡，  多臂赌博机问题&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;7b5jj-0-0&quot;&gt;4，  机器学习思想的渗入 - Q函数学习&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;18c7b-0-0&quot;&gt;5，  策略梯度算法求解非全局信息问题&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;3kaev-0-0&quot;&gt;6，  Actor - Crtic 强化学习两大流派的汇集点&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8n7ec-0-0&quot;&gt;7， 从Atari 到阿法元， 基于CNN的深度强化学习&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;dr129-0-0&quot;&gt;8， 从doom到空间导航问题， 基于RNN的深度强化学习&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;fgo10-0-0&quot;&gt;9，  有模型强化学习（关联深度强化学习）&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4a9jq-0-0&quot;&gt;10   更仿生的探索算法 -  引入好奇心  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ddomo-0-0&quot;&gt;11，提高泛化能力 ： 元强化学习。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;d5mfu-0-0&quot;&gt;12， 结束语： 再看强化学习与其它学习的联系，  强化学习产业化之机遇与挑战。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;8ngq0-0-0&quot;&gt;这12个小主题， 事实上是把强化学习的主线结晶出来， 然后按照逻辑顺序穿成的一个最小框架图。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;6anfe-0-0&quot;&gt;通过这个12个小主题， 我们给大家铺垫出一个理解深度强化学习的最小通路 。 让大家了解强化学习和深度学习的联姻究竟带来了什么机会和挑战。 我们也会给大家点名重要的书籍，网课资源和本领域的核心论文， 这样有助于大家自己在后续根据自己的需求跟进。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;463c5-0-0&quot;&gt;继续强调， 这门课程的目的不是让大家具有自己动手编程的能力， 而是拓宽大家的视野，以及制定进一步学习的计划。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4csh-0-0&quot;&gt;铁哥本人的研究目前涉及深度强化学习与RNN的结合， 因此参与课程也是与铁哥结盟， 共同进军未来的深度强化学习世界的机会。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;10.284953395472703&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfqJgX6L51kcnJ07DHpdBzq4CdJ7Pj2yE9q9ZGjIpLAQSMrWe8ricgP18icaBWjc39YTLsPLCvWsJNQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;751&quot; /&gt;&lt;/p&gt;

</description>
<pubDate>Sat, 18 Aug 2018 05:13:44 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/pwsIsf7b1P</dc:identifier>
</item>
<item>
<title>[原创]当RNN碰上强化学习-为空间建立通用模型</title>
<link>http://www.jintiankansha.me/t/sAxMjmtY0C</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/sAxMjmtY0C</guid>
<description>&lt;p&gt;你可能了解强化学习，你也可能了解RNN， 这两个在机器学习的世界里都不算简单的东西在一起能碰出什么火花，我给大家随便聊几句。  &lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7KfrfdKcbEB2Kic4M8MfGAJ0EAuiatSW2r64cCwnyl4uLZjsLM0ujNAkjhw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;4hh4f-0-0&quot;&gt;在讲RNN前我们先来侃侃强化学习, 强化学习越来越受重视，它为什么很重要，用一张图就够了。想像一下我们是人工智能体，我们有强化学习和监督学习可以选择，但干的事情是不一样的。面对一只老虎的时候，如果只有监督学习就会反映出老虎两个字，但如果有强化学习就可以决定逃跑还是战斗，哪一个重要是非常明显的，因为在老虎面前你知道这是老虎是没有意义的，需要决定是不是要逃跑，所以要靠强化学习来决定了你的行为。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bfaa2-0-0&quot;&gt;从算法上看，  强化学习是一个对未来的优化问题， 其算法的总纲可以归结到下面这张图里面，强化学习有两大门派：一种是动态规划（Dynamic Programming），另一种是策略梯度（Policy Optimization），还用老虎的例子说， 见到老虎估计一个打和不打在20年里的收益函数（比如打死老虎，县衙领赏， 抱得美人得10分vs被打死负10分） 然后推出现在的决定就是动态规划。 凭直觉和既往经验直觉决定跑还是打就是策略梯度法。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;bfaa2-0-0&quot;&gt;动态规划需要通过迭代来学习比较繁琐但是更精确，直接学习法更简单但是容易陷入局部最优，为了优势互补，两种方法相结合就得到Actor-Critic法，一方面直接学习行为，另一方面通过评估函数来最终评价那个行为对整个未来的影响，在反作用于对行为的学习，现在主流的模型都是基于这种方式。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7KfkpsUHQEQAbBImrY3mrC9veN1qG1EW95GicYdicndG2Hr7KoolQX1OFaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;bu154-0-0&quot;&gt;强化学习优化算法的成功是在Markov决策框架里开始的，只要问题符合这个框架（把过程分解为无数离散的时刻，然后此刻的信息足以决策后面的结果， 而无需历史信息，无论问题多复杂， 都可以分解为状态（state）- 行为（action）- 奖励（reward）- 策略（policy）四要素。状态是每个时刻你拥有的和决策相关的信息总和，行为是你的决定， 奖励是你的此刻收益。而策略就是从状态到行为的对应关系。就拿方格矩阵走迷宫（下图a）的例子说，你的状态就是你的位置，你的行为就是上下左右走，你的奖励是中间的加号。行走的过程每一步都只与上一步相关，此刻拥有绝对信息（位置），因此可以简化为下图b的马尔科夫决策图框架。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;fo343-0-0&quot;&gt;这里面只有策略是优化的目标。策略最简单的表格方法就是一个纵轴是状态，横轴是行为的表格，每个格子里是某状态下做出某个行为的概率（下图c）。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;如果你用刚提到的动态规划法来做优化，你还需要另一个表格，叫做Q表格， 这个纵轴同样是状态，横轴同样是行为，但是每个对应的格子里的内容是value， 数学上说就是某个状态和行为下未来收益的期望（d）, 我们通过学习不停迭代这个表格（e）。 有了Q表格， 你可以通过对随机性偏好的假设很自然的得到刚刚说的策略表格。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.7899159663865546&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7Kf0JXXcicKyT1ZG6E23CBtMyN7gSIYlIObR2t8xWKooicujPYjkNqCQ5mg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;238&quot; /&gt;&lt;/p&gt;

a


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7KfCoicfghk7hfW0Go2dorPMkH6HEmnuvWGYUvGibdBtJUdgEnHXKkRpBuQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

b

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.225130890052356&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7KfQggzMLEIj83umLs9kNiaH4qjBQMx4V29ECGbH3vvJ1Tib6pU3J8uYuRA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;573&quot; /&gt;&lt;/p&gt;

c


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.225130890052356&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7KfXj1V9qyvdqcF0Vzia9SfiaEplbqLXmhqGt7O2eRu3gfGtPMWT0JHjvug/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;573&quot; /&gt;&lt;/p&gt;

d

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.7069444444444445&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7KfyJEYpPQ3EC2GzEyApRbIDF77FWTpGpflxiaI39LEibeWHtWYRFEXMDVA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;

Q表格逐步迭代的过程， 先更新最靠近结尾的状态收益，在往起始状态推演， 最终得到每个状态行为下的未来收益。 图中的gamma是贴现率， 贴现率越低，状态间的收益变化越平滑

&lt;p&gt;&lt;span data-offset-key=&quot;9g54b-0-0&quot;&gt;然后深度强化学习从何而来?  现实生活中的状态太多，如围棋有3的361次方个状态，你的表格几乎可以布满银河系。所以你不能用表格法，这就自然的引入了机器学习。 因为机器学习，尤其是神经网络，本质就是函数逼近， 或者某种插值方法。 当表格大到填不完，我们就用一个函数来替代它，然后用神经网络来学习这个函数，这就自然的引入了深度强化学习。通过数据可以模拟函数，有了函数就可以把值函数的问题解决。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;7584b-0-0&quot;&gt;DQN深度值函数算法最基本的深度强化学习算法，2015年发表的关于Alpha-Go的文章就是值函数法，策略梯度，蒙卡树，结合了CNN得到的算法。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7Kf5srE5mpkXicBCPPe62EInLwW2df4NUe2LfCkHNLXXGUJGDFJTgmOvNw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7KfNeHtwFhQPmlW8CGHVarOdZLC28ibhicrsGAQCVGPpREY880th5CpT4Pg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;
&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.10966542750929369&quot; data-w=&quot;538&quot; class=&quot;&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibccdYT8ViaXic1q1ibC3U0Ub0WhaaX0dxl5oRO3YicRx7fSozVkP7Z5UfiaQdwyaxxEM5AZaMAGHjY4yS4Q/640?wx_fmt=jpeg&quot; /&gt;&lt;/pre&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4peqn-0-0&quot;&gt;然而Alpha-Go再强大也不能解决所有问题，比如星际争霸，因为当下游戏画面当中的信息是不足以进行决策的，针对决策的信息并没有全部在一个画面当中呈现出来，所有就需要使用其它的方法。这也是我们的另一个主角RNN登场的机会。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;egipd-0-0&quot;&gt;我们用要一个最微小的例子来说明，还是那个走方格的问题，骷髅就是有危险的意思，我们希望走到有奖励的地方。 我只做一个小的改动将使得之前问题面目全非，之前的马尔科夫决策附加的条件就是当下的状态含有用来决策的所有信息，方格问题里， 这个信息就是位置坐标。而如果我没有位置这个信息， 取之以感知信息， 比如我只能感知我所在方格的周围两个方格有什么（下图中的骷髅或金币）。  &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;p5te-0-0&quot;&gt;注意如果我们处在下图灰色方格的区域（左右各一个），此时相邻的两个方格的情况是完全一致的（白色），也就是说我无法确定我是处于左边还是右边的灰色方格， 这导致无法决策正确的行为（左边和右边的正确决策是相反的！ 一个向左一个向右， 但是我无法确定是哪一个！）。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7KfGqJpRTS8zD1tJUJv64Mww8RPn8BnrLA19hLx0hCoHRbhqA3xWYZpjg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-offset-key=&quot;bedq2-0-0&quot;&gt;真实的生物天天生活在非完全信息环境下， 到处都是刚刚图中的灰色方格。 它们还得学到正确的行为， 那么它们是如何解决这个问题呢？&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;4eu1v-0-0&quot;&gt;主要有三种方法：一种就是策略梯度的方法，虽然所知状态和信息是不全面的，我们可以利用概率的方法来学习。当不知道该往左走还是该往右走时，随便走出一步，这样有百分之五十的概率得到最后要的奖励（一个驴子在沙漠里， 怎么都要选择一个方向走，不走一定渴死），利用直接学习的策略函数也就是Policy Gradient解决掉这个问题。这个方法大家可以看到效率是比较低的， 如果时间有限那就死了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;ablgj-0-0&quot;&gt;另外一种方法就是引入记忆，你有了记忆， 事实上你就可以把一些不同时间点的信息凑成一个整体，你的信息当然比之前多。在上图走方格的例子里如果你知道你上一步是从左边边界来还是从右边边界来问题迎刃而解。 而最后一种就是加入精确的世界模型， 你的信息不全面， 但是我可以用我的大脑给世界建模， 这样一个不完全信息的世界在我脑补下就变成了完整的世界。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1kqh8-0-0&quot;&gt;引入记忆的方法，就很自然的引入了是RNN，它是类似模仿生物工作记忆的原理，信息放在记忆里面，将其作为决策的依据。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;a8guj-0-0&quot;&gt;RNN的网络结构和前向神经网络差距并不大，只是多了一个时间转移矩阵，即当下隐藏的状态再到下一步隐藏状态的连接。这个连接实际上是传递当下的信息到下一刻的过程，这个传递过程中包含了记忆，我们可以把过去的信息往将来不停的迭代，于是神经网络细胞当中就含有过去很多时刻的记忆，其实就是生物的Working Memory。LSTM只是在RNN的基础上多了一记忆细胞层，可以把过去的信息和当下的信息隔离开来，过去的信息直接在Cell运行，当下的决策在Hidden State里面运行。加入RNN以后就把DQN变成了DRQN，然后就可以走一些非常复杂的环境。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7Kfk56k6bIcM1zT9IOewKLJcSlaQicOfuoXic0ddW5UfomCU2pHfO1bkgpg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

RNN， U是隐层连接




&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7Kficj2E96qrs1L6E5oZdIWTaJehwregGsOGTwSFojNIAtfcPSy2icTVPZQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

LSTM： 加入Cell


&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7Kfhq3BYoVU1JL4Ss9LY1ApnLmJpAFsJ8TLI8lNWQze6bM7uOQiaZBkA8w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

DRQN框架 ， RNN网络是大脑，做出的决策影响世界， 世界又给这个大脑以反馈。

&lt;p&gt;&lt;span data-offset-key=&quot;bldb6-0-0&quot;&gt;下图是一个二维的迷宫，只能看到周围格的情况，就是刚刚描述那个问题的拓展版（相当于在沙漠里寻找水源， 你只能看到自己周围有什么，没有其他信息）。 需要我们做的是在很复杂的情况下搜索到目标在哪里，这就是一个导航的问题。左下角的红点就是起始位置，中心的红点是目标，最终学习得到的行为是： agent会直接走到墙上得到自己位置有关的信息， 然后从这里奔向目标，这就模拟了空间搜索的过程，RNN在这个过程里把不同时间点的信息拼接成一个整体。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.36944444444444446&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7Kf6ENuOB66bNK4fEicoK2p5jlXHffycrxUg2h6TouXtHEpLggNrHTOT9Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;

二维游戏， 输入信息只有相邻格子的状态


&lt;p&gt;&lt;span data-offset-key=&quot;58pir-0-0&quot;&gt;RNN虽然有这种能力,  但是一旦空间复杂了它还是会蒙蔽， 因为空间是很复杂的，比如一个有很多屋子的宾馆， 这个时候就需要更强大的空间表示能力。这个东西还是可以通过学习诱导， 通常的做法是加入监督学习的成分，比如学习预测你在空间里的什么位置， 这个过程里， 模拟空间的能力会在RNN的动力结构里自动浮现出现。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;c4n3b-0-0&quot;&gt;监督学习信号比较多而且目标明确，它可以预测走到哪里了，距离奖励还有多远，可以说给之前的强化学习添上了翅膀。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7KfkAwV0tlKQALyibDntKgGXZIx2ic3Epia7SNkBAuotaGwkpFRhoVvZCUiaw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

在2017年， 人们使用类似的方法让agent很好的打赢了doom   Lample, Guillaume, and Devendra Singh Chaplot. &quot;Playing FPS Games with Deep Reinforcement Learning.&quot; AAAI. 2017.


&lt;p&gt;&lt;span data-offset-key=&quot;bnbsa-0-0&quot;&gt;一旦加入监督学习，事实上我们就达到了刚刚说的第三种策略，引入世界模型， 只不过这个过程是一步步的而非一蹴而就。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;9nka2-0-0&quot;&gt;一篇发表在《Nature》上的论文就把这个东西更加推进了一部。同样是监督学习，但是它在基础学习基础上诱导RNN（lstm）在原基础上形成新的结构，这个东西竟然惊人的和小鼠脑中的栅格细胞相近。这个栅格细胞实际是把空间当作一个很多六边形组成的蜂巢网络来表达，每个细胞对六边形网络的端点位置是敏感的，而不同的细胞对不同空间周期（网格边长）的网格敏感。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;1n3eu-0-0&quot;&gt;这个方法的本质是建立空间的通用模型。 显然你的大脑不会给北京，上海，或者天津建立完全不同和分离的神经表达，必然的有一种空间语言来支撑所有的空间概念，而从一个地方到另一个地方，最底层的这个表达是不变的。这个东西可以看作模型之上之模型，这个东西正是这个栅格细胞。栅格细胞的每个细胞相当于一个不同空间周期的六边形网，通过组合这些六边形网，我们可以很容易的得到对空间相对位置的表达（很像傅里叶变化，每个栅格细胞是傅里叶变换的成分，被下游的位置细胞组合读取）。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span data-offset-key=&quot;fjiht-0-0&quot;&gt;有了这个细胞的网络会有更强的在空间当中运行的能力，一个标志性的表现在于可以在复杂的空间当中抄近路。如果路径发生变化（比如一个门堵死了），就会找次优的目标，也就是说有一种动态规划的能力，即具有空间行走的智能。在RNN的基础上加入适当的监督学习，从而产生与生物细胞类似的结构，具有了空间表达能力。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.6062407132243685&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7KfDdAJGCsbTCDURlia6Q0PEwjbTbtg7kUKH48ByHCSxbtdGZkNNCIGwtg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;673&quot; /&gt;&lt;/p&gt;

事实上，我们不满足于上述的结果， 有没有一个方法， 让agent学习得到一个通用的空间表示？ 这样生物才能真正学到对一般空间特征的泛华能力。



&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.4775641025641026&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7Kf6gVXmgZ6ypo63MbxVNXYU9TibpiaXPDAWd6fMAJ6uKRLbg1NsB43q6yw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;624&quot; /&gt;&lt;/p&gt;

生物对空间的表示， 是通过一个叫grid cell- place cell组合实现的， 这个组合的特点是上游的grid cell 提供一组特定空间频率的细胞， 然后通过一个线性组合（place cell)， 我们就可以得到对空间位置的描述。  这类似于一种对空间进行的傅里叶变换。

&lt;p&gt;&lt;img class=&quot;Image FocusPlugin--unfocused Image--isBlock&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcfh8M2ib5ZtShLeSLsVicG7KfmRsudSrliapsM7RwqTKqqlFQF2vGgnAX4bgq2vAXpIlYfpDGWpdYvJA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

在使用了这种grid的空间表示后，最大的特点是增加了agent的灵活性， agent真正更够进行某种空间规划了

&lt;p&gt;&lt;span&gt;最终我们可以这样总结RNN在强化学习的潜力：  RNN，作为一个动力学系统， 本身表达了过去，现在和将来的联系， 这可以看作是部分的， 或者全部的世界模型。 而强化学习， 作为一个对未来收益的优化， 可以看作一个序列决策问题， 你对系统的过去现在和将来了解的越透彻，这个决策能力就越强， 因此RNN天生和强化学习有某种契合。 &lt;strong&gt;RNN的这个动力系统， 可以说部分的，或者全部的表达了世界模型，因此， 它非但是解决局部马尔科夫问题的利器，更在免模型和有模型的强化学习当中构建了一个桥梁。  &lt;/strong&gt;&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;相关阅读&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383552&amp;amp;idx=1&amp;amp;sn=d10cf1e80137c23827a8a57f1605f3b5&amp;amp;chksm=84f3c941b38440577a067cd312d6683f193000781fe1da2310769b88b850e6eabf21a5a0626a&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;铁哥长文：神经导航简介 - 论deepmind最新文章&lt;/a&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383480&amp;amp;idx=1&amp;amp;sn=c4ca5c392e66df49f61bd0efb0997f9c&amp;amp;chksm=84f3c8f9b38441efe87e238ba063fe6e308e13a9d8460835429aa5093ab899136c9351a5ac52&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;从Q-learning的小游戏看阿尔法元技术&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;更深入了解，请阅读的文章如下：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Bakker B. Reinforcement learning with long short-term memory[C]//Advances in neural information processing systems. 2002&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;最早在强化学习里引入RNN的尝试，  主要是强调RNN可以解POMDP&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span data-offset-key=&quot;1788i-0-0&quot;&gt;Hausknecht, Matthew, and Peter Stone. &quot;Deep recurrent q-learning for partially observable mdps.&quot; &lt;/span&gt;&lt;span data-offset-key=&quot;1788i-0-1&quot;&gt;CoRR&lt;/span&gt;&lt;span data-offset-key=&quot;1788i-0-2&quot;&gt;, abs/1507.06527 7.1 (2015).&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这一篇接着2002的文章， 主要是承接了2015 deepmind 在DQN的突破，强调那些信息并不全面的Atari Game， 可以通过RNN（LSTM）得到性能突破&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span data-offset-key=&quot;2ksd8-0-0&quot;&gt;Mirowski, Piotr, et al. &quot;Learning to navigate in complex environments.&quot; &lt;/span&gt;&lt;span data-offset-key=&quot;2ksd8-0-1&quot;&gt;arXiv preprint arXiv:1611.03673&lt;/span&gt;&lt;span data-offset-key=&quot;2ksd8-0-2&quot;&gt; (2016)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;导航领域的牛文， 介绍了在RNN（LSTM）下的深度强化学习里如何进一步加入监督学习， 获得性能突破&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Wang J X, Kurth-Nelson Z, Tirumala D, et al. Learning to reinforcement learn[J]. arXiv preprint arXiv:1611.05763, 2016.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;小众的神文， wang xiao jing 大神介绍了一种基于RNN的强化元学习能力， 一种举一反三的能力。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span data-offset-key=&quot;3pvui-0-0&quot;&gt;Banino, Andrea, et al. &quot;Vector-based navigation using grid-like representations in artificial agents.&quot; &lt;/span&gt;&lt;span data-offset-key=&quot;3pvui-0-1&quot;&gt;Nature&lt;/span&gt;&lt;span data-offset-key=&quot;3pvui-0-2&quot;&gt; 557.7705 (2018): 429.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;最新的Nature文章，  介绍了通过监督学习引导RNN（LSTM）产生空间栅格细胞的能力&lt;/span&gt;&lt;/p&gt;

&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-ratio=&quot;0.10966542750929369&quot; data-w=&quot;538&quot; class=&quot;&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibccdYT8ViaXic1q1ibC3U0Ub0WhaaX0dxl5oRO3YicRx7fSozVkP7Z5UfiaQdwyaxxEM5AZaMAGHjY4yS4Q/640?wx_fmt=jpeg&quot; /&gt;&lt;br /&gt;&lt;/pre&gt;
&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcd9g9aFjBooVn5U4PP1EDF3ugVJrLlia2ELtxHbXUJs7SUPtRaxmkUBHhx3jLciaHXpx1ABVYwYBu9w/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.665625&quot; data-w=&quot;640&quot; /&gt;&lt;/pre&gt;
&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;span&gt;作者许铁，微信：ironcruiser &lt;/span&gt;&lt;br /&gt;&lt;span&gt;法国&lt;/span&gt;&lt;strong&gt;巴黎高师&lt;/strong&gt;&lt;span&gt;物理硕士 ，&lt;/span&gt;&lt;strong&gt;以色列理工大学&lt;/strong&gt;&lt;span&gt;（以色列85%科技创业人才的摇篮, 计算机科学享誉全球）计算神经科学博士，巡洋舰科技有限公司创始人,   曾在香港浸会大学非线性科学中心工作一年 ，万门童校长好战友。&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;5.896&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccvEGHcvx6vn7ibqucwWjTLJNQDiajMVL3arkx9IJnm10baZ1RjdLTN2KH6SKHZqnzyGO5K0G3dNOwg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;750&quot; /&gt;&lt;/p&gt;
&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;br /&gt;&lt;/pre&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;/pre&gt;
&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;span&gt;许铁的《机器学习和复杂系统》这本书用物理学视角来看机器学习，目前已经正式上架。同时，许铁已在万门大学已开设机器学习原理和深度学习原理两门在线课程，即将于9月开设强化学习的在线直播课程。感兴趣的可以点击下图的二维码咨询。&lt;/span&gt;&lt;br /&gt;&lt;/pre&gt;
&lt;pre contenteditable-directive=&quot;&quot; mm-paste=&quot;&quot; ng-blur=&quot;editAreaBlur($event)&quot; ng-model=&quot;editAreaCtn&quot; ng-click=&quot;editAreaClick($event)&quot; ng-keyup=&quot;editAreaKeyup($event)&quot; ng-keydown=&quot;editAreaKeydown($event)&quot;&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdtdhcvoVrIAictVtkxkfXSiambAf4zOLtDxdYq09GEcgnRltUzicyJbr7EcCX7bYVV3GKuKXdlFdQqw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;4.717741935483871&quot; data-w=&quot;620&quot; /&gt;&lt;/p&gt;







</description>
<pubDate>Sun, 12 Aug 2018 19:28:35 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/sAxMjmtY0C</dc:identifier>
</item>
<item>
<title>[原创]恐慌与困惑-读《今日简史》看当下的四重困惑</title>
<link>http://www.jintiankansha.me/t/ZNVahb4qfa</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/ZNVahb4qfa</guid>
<description>&lt;p&gt;面对《今日简史》这个书名，不必吐槽，作者在书中写道，在他之前为他的前俩本书写的简介中，编辑会指出有的词不能用，要换成别的词。这不是为了迎合某位编辑的个人喜好，而是编辑认为这个书名能够在搜索引擎上获得更多的点击。我想这本书的书名没有被直译为英文原版的21堂关于21世纪的课，也是为了迎合中文的搜索引擎。你既可以挂国人祖传的“十景病”，也可以怪中文分词的算法。而这个标题中的细节正折射出书中的主旨，我们生活在一个令人困惑的后真相时代，以及我们该如何在其中重构出一个故事来。&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.4240282685512367&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdwaZ6W5S4zIOYyabz4v7aHhVPqf2aiaFExiasRO4QXcoxSc28uLtq25HJeKZfR4ShrEnt10e2fhBLA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;283&quot; /&gt;&lt;/p&gt;
&lt;p&gt;本来人类自从诞生以来，就生活在无真相的时代，无论是巫术还是神话，无论是被用作聚财还是统御，一个个的故事哄骗着我们的祖先度过了远离真相的一生，也创造了辉煌的文明。这是《人类简史》告诉我们的故事改变历史，而到了《未来简史》，智人分化为超人和无用之人。相比于前俩本书的明确主题，《今日简史》缺少一个明确的关键词，而像是对前俩本书的自我抄袭。但若是这么看，则说明看书时还只是抱着猎奇的心态，没有进入到惊奇之境。殊不知，猎奇是人性的弱点，是让你泯然众人的捷径，是会让你不知不觉就虚度光阴的。而惊奇是哲学的开始，会为新的探索指引方向。&lt;/p&gt;

&lt;p&gt;猎奇的读者，总想着读一本书就刷新三观，而要进入惊奇，就要始终带着一个大问题去阅读。作者为什么要写这本书了，在书前言，作者这样写道：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在一个信息爆炸却多半无用的世界，清晰的见解就成了一种力量。从理论上讲，人人都能参与这场以“人类未来”为主题的辩论并发表高见，但想要保持清晰的认识并不容易。而通常的情形是，我们根本没注意到有这场辩论，或者根本不清楚关键问题何在。很多人并没有太多的时间好好研究这件事，因为手边总有更紧急的事：上班、照顾孩子或者侍奉年迈的双亲。可是，历史不会因此就对你更宽容。就算你因为忙着让孩子吃饱穿暖而缺席这场有关人类未来的辩论，你还是躲不过日后的结果。这实在太不公平了。但是，谁又能说历史是公平的呢？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这段话的关键词是清晰的见解，那什么才算是清晰的见解了？作者接着写道&lt;em&gt;&lt;br /&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我只是个历史学家，并没办法供人衣服、给人食物，但希望能提出一些清晰的见解，尽量让人们能够公平地参与这场辩论。只要有人，哪怕是极少数人，因此而加入关于人类未来的辩论，我也就对得起这份工作了。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;能够让拥有它的人公平的参与有关人类未来的辩论，这是作者心中清晰的见解的作用。那怎么获得了，其中重要的一环是理清看似相近但本质不同的概念。比如恐慌和困惑，面对不确定的未来，你可能无暇思考对其恐慌或者困惑有什么区别，但是书中写道：&lt;strong&gt;恐慌暗含着一种傲慢，以为自己都看明白了，未来一定会变坏，而困惑是谦虚者才有的表现，承认不确定性，但会努力从模棱俩可中梳理出世事的脉络。&lt;/strong&gt;又比如我在本文试图想区分惊奇和猎奇，并给出这俩者的四个区别。&lt;em&gt;&lt;br /&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccXGqI1vC7ZRtFxawSEUMEJHibUvh5daPgAU8S4JqxE7ZoAibtibiaK6hunMMsCVp515qujnknm8nfduw/640?wx_fmt=jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;为什么困惑了？第一层的回答是变化太快了，新知的进展压得我们快喘不过气了。朋友圈中那么多标题党的帖子，吸引你点击，诱惑你下单，靠得就是这紧迫感，但正应了“无恒产者无恒心”，紧迫感对有一技旁身的人，起不了太多效果。另一类相似的回答是当下值得恐惧的事情太多了，但正如书中关于恐怖主义的一章写道的，恐怖主义带来的问题更多是由于反应过度造成的。媒体的普及让更多的黑暗被暴露了出来，但以前这些却是不为人知的常态。当下的恐惧只是过渡反应后的集体无意识。&lt;/p&gt;

&lt;p&gt;可当前的情况却不止是一般人困惑，而是越有本事的人越困惑。尤瓦尔·赫拉利的三本书应运而生，对这普遍的困惑提供了更深入的解释。&lt;/p&gt;

&lt;p&gt;精英的困惑，首先是因为人不再是变化中站在聚光灯下主角了。改变世界的不再是某个英雄的自我牺牲，而是算法，基因这些说不清的东西。数据成了最宝贵的资源，可是该如何守护并运用数据带来的权益，却对精英来说也是摸着石头过河。&lt;/p&gt;

&lt;p&gt;本来每个人都以为历史总会有聚光灯，灯下的人就算再平凡，也能改变世界。可未来的历史学家在讲述#MeToo之风的时候，不会对第一个发言的她大书特书，而会将推特平台当成是真正的英雄。如今这指引历史发展最坚固的聚光灯也要烟消云散了，这才是为什么精英更加困惑的根源，他们本比普通人更有机会站在聚光灯下的。在一个习惯了当帝王师的文化里长大的中国人，理所当然要比他国人更多一份牵挂去思考该如何为天地立心，这也难怪全球第一个出版《今日简史》的是汉语版。&lt;/p&gt;

&lt;p&gt;能想到这一层，那就不能靠走马观花的猎奇，只看新鲜事，不晓昨日非。而有深厚的积淀，则是进入惊奇之境的第二把钥匙，只有带着自己独特的背景知识去观察，才可以获得清晰的见解。历史能让读者去情绪化，去认清事件的全貌。而在才是能公平的参与关于人类未来辩论所需要的。&lt;/p&gt;

&lt;p&gt;正如作者在前言中所说的，这本书对自由的明珠的政治制度多有批评，但强调这是人类迄今为止最成功也最灵活的政治模式，作者明知任何对其的批评都有可能被其反对者断章取义的滥用，但如果不批评自由主义，就无法修复其缺点并有所超越。而这正是惊奇和猎奇的第三个区别所在，惊奇者会在新知让久识得以完整时感到震撼，而猎奇者则会被人云亦云带入无聊和不满的循环。&lt;/p&gt;

&lt;p&gt;就算人不在是主角了，那人的思想和选择也还是在塑造着历史的。但在《今日简史》中，指出了当下令人困惑的第三层原因，至少对于自由主义者来说，决定当下历史的思想是如同魔戒中重新聚集的魔王索伦，是从被封印的诅咒之地走出来的。极端的民族主义，宗教原教旨主义，威权统治，寡头经济，这不都是20世纪经过俩次热战一次冷战才打倒的吗？怎么没过几年自由的灯塔，就变成了变节的Saruman了？&lt;/p&gt;

&lt;p&gt;若只是纠结于主义，而不谈具体的问题，就又流于了猎奇。现实中的困难会打断猎奇者在不同主义间的漫游，而惊奇者则会思考世界变化趋势会怎么影响自己的思考方式。而思考的源头是把自己看得不那么特立独行，承认近朱者赤也适合自己。而这也引出了当下困惑的最深一层的根源，我们是否在逆向选择着我们的下一代，不是选那些最聪明的，而是选那些最听话的，不是选那些最勇敢的，而是选那些最能产生数据的。&lt;/p&gt;

&lt;p&gt;当我们认不出还不成熟的人工智能其实只是人工智障，那就会让自己变得愚蠢。书中讲述了一个在GPS指引下将车开进太平洋的司机的故事，讲了人类再还不了解自己心智的秘密时就将探索的责任交给了算法。退化的人类使用着进化的计算机，不知不觉的互相伤害，并伤害着地球，这才是当下在千年的视角上最让人困惑的事。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccXGqI1vC7ZRtFxawSEUMEJHibUvh5daPgAU8S4JqxE7ZoAibtibiaK6hunMMsCVp515qujnknm8nfduw/640?wx_fmt=jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;厘清是什么让当下的人困惑，也就实现了这本书的初心，让多一些的人能参与关于未来的辩论。作者没有给出解决的方案，但是指出了那些方案是不可行的。比如让变化慢下来就不行，书中写到，&lt;strong&gt;哲学家很有耐心，工程师的耐心要小的多，而投资者是最没有耐心的，就算你没有想清楚该怎么用这股设计生命的力量，市场也不会允许你花一千年想清楚再做。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;提供全民基本保障金，也是不行的。什么叫基本需求？什么是全民？这写问题是没法用科学说清楚的。即使提供了无条件的物质保障，就能够保证有意义的生活吗？如果智能的目的是扩大宇宙间中意识的数量，那不应该更关注精神的需求吗？广泛的社群和有意义的目标，也许会让被机器抢走工作显得塞翁失马。&lt;/p&gt;

&lt;p&gt;而回到个人各扫门前雪的民族国家，则无法解决全球变暖，核战争，科技进步带来的全球性问题，也不行。至于传统宗教，则是用增字解经的方式将现代的科学包装成古老的教义。而基于文化认同来区分那些敌我，也会让个人的独特性被基于统计的，过于笼统的群体的属性所裹挟，从而无法让更多人参与到全球性问题的讨论中。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-type=&quot;jpeg&quot; data-w=&quot;490&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccXGqI1vC7ZRtFxawSEUMEJHibUvh5daPgAU8S4JqxE7ZoAibtibiaK6hunMMsCVp515qujnknm8nfduw/640?wx_fmt=jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;那这本书究竟有没有给出一些建设性的意见了，似乎并不多。作者写道真正重要的信息绝不会是免费的，是需要从一手的科学文献中直接去获取的，作者提到科幻小说在塑造人们对未来的思考时比科研论文更有影响力。但很快又写到了自由意志这个幻觉的破灭可以从好莱坞《头脑特工队》的成功看出。又借着《美丽新世界》指出你的&lt;strong&gt;大脑和自我都是母体的一部分，想逃离母体，就必须逃离自我。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在书的第19章“教育，改变是唯一不变的事”，书中终于给出了作者对种种困惑的最终解药-扩大自我的边界。书中写道：&lt;/span&gt;&lt;strong&gt;在21世纪，摆脱对自我的狭隘定义可能成为必须的生存技能。&lt;/strong&gt;&lt;strong&gt;“&lt;/strong&gt;&lt;strong&gt;想适应未来的世界，现在我们该教给孩子的是“4C”，即批判性思考（critical thinking）、沟通（communication）、合作（collaboration）和创意（creativity）。或者说，学校不应该太看重特定的工作技能，而要强调通用的生活技能。最重要的是能够随机应变，学习新事物，在不熟悉的环境里仍然保持心智平衡。”&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对个人来讲，第一个的建议则是认识你自己，再去构建一个自己能参与并延伸到超出自己视界的故事。故事不必是真实的，但却能让你为自己的生命赋予意义。但作者接着指出，没有人应该仅仅是一个故事中的人物，也不应该忽视真实和虚构的区分。尤其是当面对“牺牲，永恒，纯净，恢复“时，更要注意将关注点拉回现实的痛苦上。书中写道：“&lt;strong&gt;如果想知道宇宙的真相，人生的意义，自己的身份，最好的出发点就是开始观察痛苦，探索痛苦的本质。答案永远不会是一个故事”。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;除了这些积极的建议，书中最有价值的一段话我忍不住摘出，作为这篇小文的结尾。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如果真要做出某些人士最重要的决定，就我个人而言，我更愿意相信那些承认自己无知的人，而不是那些声称自己全知全能的人。如果你希望自己的宗教，意识形态或世界观能够领导世界，那我要问的第一个问题就是，你的宗教，意识形态或价值观过去犯过那些错误，当时它做错了什么事？如果你无法找到一个认真的回答，至少我是不会相信你的。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;总结一下，《今日简史》一直围绕着一开篇提出的问题，方法大多是从反面去思考，告诉你什么不是清晰的见解，至于去除了那些阻碍清晰思考的成见，剩下的东西就算是晦暗的，也是能让我们籍之向死而生的意义。另外这篇小文还想借着《今日简史》说说猎奇和惊奇的区别，这个时代把好奇心捧得太高了。而但凡被捧杀的，都是在困难的小路上架设了断头的高架桥，将俩者区分清楚，实在是少数能在成年后改变思考质量的方式。重复一下，惊奇者会带着大问题而不是漫无目的的去接触新知，会用自己的积淀而不是一无所有的去解读新知，会使用新知去完善而不是推翻旧有的观念，会主动用新知改变自身而不是等着新知将自己改变。&lt;/p&gt;








</description>
<pubDate>Sat, 11 Aug 2018 18:44:03 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/ZNVahb4qfa</dc:identifier>
</item>
</channel>
</rss>