<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>白话迁移学习</title>
<link>http://www.jintiankansha.me/t/KQI4gcI1tj</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/KQI4gcI1tj</guid>
<description>&lt;p&gt;深度神经网络，相比于之前的传统机器学习方法，可以看成是一个全新的物种，这背后的原因，最明显的还是深度学习对机器算力的巨大需求，在&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383250&amp;amp;idx=1&amp;amp;sn=59c8b29f52dcc4db8ddf286840bca434&amp;amp;chksm=84f3cb93b3844285742e9034aef6f23a1a88dfb17ea85b81cd364032fed123200a7cc80f3b14&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;深度学习入门最少需要知道什么？&lt;/a&gt;中介绍了深度学习所需的显卡资源，而当前大内存的机器不贵，而高性能，大显存的显卡就没那么便宜了。这使得使用深度学习去处理实际生活中遇到的问题，例如图像和语音的识别时，需要消耗大量的资源。而迁移可以改变这一切，显著的降低深度学习所需的硬件资源。&lt;/p&gt;

&lt;p&gt;本文会先介绍迁移学习的定义，接着说说预先训练好的网络是什么，为什么有用？使用预训练的网络又有那两种方法？之后会通过MINST数字识别的例子，来展示该如何应用迁移学习。&lt;/p&gt;

&lt;p&gt;让我们通过一个直观的例子来说明什么是迁移学习。假设你穿越到了古代，成为了太子，为了治理好国家，你需要知道的实在太多了。若是从头学起，肯定是来不及的。你要做的是找你的皇帝老爸，问问他正在做了什么，而他也希望能将他脑子的知识一股脑的转移到你脑中。这正是迁移学习。即将一个领域的已经成熟的知识应用到其他的场景中。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK1MBlkszgaZsnbgj2kgIzTh1pUyZSPO5Tvedk6pcVNrWTpcGOSukfIeA/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.749034749034749&quot; data-w=&quot;259&quot; data-type=&quot;jpeg&quot; data-backw=&quot;259&quot; data-backh=&quot;194&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;p&quot;&gt;用神经网络的词语来表述，就是一层层网络中每个节点的权重从一个训练好的网络迁移到一个全新的网络里，而不是从头开始，为每特定的个任务训练一个神经网络。这样做的好处，可以从下面的例子中体现，假设你已经有了一个可以高精确度分辨猫和狗的深度神经网络，你之后想训练一个能够分别不同品种的狗的图片模型，你需要做的不是从头训练那些用来分辨直线，锐角的神经网络的前几层，而是利用训练好的网络，提取初级特征，之后只训练最后几层神经元，让其可以分辨狗的品种。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK1iaJF6OAYQCmftEmC2lx1GuteKib50Iw5Pr1Ol3pRYL3dEXB51BcaXaRw/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.6013888888888889&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;p&quot;&gt;从上述的例子引申出来，迁移学习的理念，其实有广泛的应用。人类的语言使得代际之间的迁移学习变得可能，在语言出现之前，每一代能够教给下一代的东西极其有限，而有了语言，人类的知识得以爆炸性的增长。而随着现代科学的进步，每门学科都产生了很多术语，这些术语相当于抽象层次更高的表述，所需的学习时间也会变长，这使得童年这个文化概念得以产生。迁移学习的道理应用到现实生活中，还意味着教育和娱乐的区别。教育要有阐释，有背景，有对情境复杂性的分析，追求的是宽度，而当前娱乐式的知识传授，则只追求深度，从一个有趣的案例，一路衍生出看似深刻的道理，或者停留在事实本身，将知识变成一个个孤岛而不是网络。&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK1pvRr1fkPx7A1jmghaDHHRjb4M1G65k3LEJPmqO9zSfR4mQ67szLG8w/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.44344262295081965&quot; data-w=&quot;1220&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK1nHIxqzgLHx3oiaknGVvjpr7AqwQ8xEKW7YZ2ibUt3H3bT1bsXiaAe2J7g/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;1.1176024279210925&quot; data-w=&quot;1318&quot; /&gt;&lt;/p&gt;


&lt;p&gt;回到技术问题。迁移学习相当于让神经网络有了语言，新一代的神经网络可以站在前人的基础上更进一步，而不必重新发明轮子。使用一个由他人预先训练好，应用在其他领域的网络，可以作为我们训练模型的起点。不论是有监督学习，无监督学习还是强化学习，迁移学习的概念都有广泛的应用。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK11EERsE2DL3ZCSrj8SUicAHyEzDlYicE08ZCF5nEVWhhh4RvaxkkicZmDQ/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.7263888888888889&quot; data-w=&quot;720&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;举图像识别中最常见的例子，训练一个神经网络。来识别不同的品种的猫，你若是从头开始训练，你需要百万级的带标注数据，海量的显卡资源。而若是使用迁移学习，你可以使用Google发布的Inception或VGG16这样成熟的物品分类的网络，只训练最后的softmax层，你只需要几千张图片，使用普通的CPU就能完成，而且模型的准确性不差。&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK1GhQvoG75aCXBY66nF31SWgAj99iaJcpIOC7Sbu3OtpdGOiaicP7cx3Dog/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.6866485013623979&quot; data-w=&quot;734&quot; /&gt;&lt;/p&gt;

&lt;p&gt;使用迁徙学习时要注意，本来预训练的神经网络，要和当前的任务差距不大，不然迁徙学习的效果会很差。例如如果你要训练一个神经网络来识别肺部X光片中是否包含肿瘤，那么使用VGG16的网络就不如使用一个已训练好的判断脑部是否包含肿瘤的神经网络。后者与当前的任务有相似的场景，很多底层的神经员可以做相同的事，而用来识别日常生活中照片的网络，则难以从X光片中提取有效的特征。&lt;/p&gt;

&lt;p&gt;另一种迁移学习的方法是对整个网络进行微调，假设你已训练好了识别猫品种的神经网络，你的网络能对50种猫按品种进行分类。接下来你想对网络进行升级，让其能够识别100种猫，这时你不应该只训练网络的最后一层，而应该逐层对网络中每个节点的权重进行微调。显然，只训练最后几层，是迁移学习最简单的1.0版，而对节点权重进行微调（fine turing），就是更难的2.0版，通过将其他层的权重固定，只训练一层这样的逐层训练，可以更好的完成上述任务。&lt;/p&gt;


&lt;p&gt;另一种迁移学习的方式是借用网络的结构，即不是使用已训练好的网络的权重，而是使用相同的网络结构，例如多少层，每层多少节点这样的信息，然后使用随机生成的权重作为训练的起点。例如你要训练世界上第一个识别fMRI图像的神经网络，你就可以借鉴识别X光图片的神经网络。&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK1UMtuDP614TlUwZibNUPKRyP0kmPa2f3PYxZ7SRQSrQLk0lnaOa2DDbQ/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.5534883720930233&quot; data-w=&quot;645&quot; data-type=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;和传统的方法相比，迁移学习的另一个好处其可以做多任务目标的学习，传统的模型面对不同类型的任务，需要训练多个不同的模型。而有了迁移学习，可以先去实现简单的任务，将简单任务中的得到的知识应用到更难的问题上，从而解决标注数据缺少，标注不准确等问题。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK1bicRk7k5WlNxflPB4iaMOWdEKYT1EYbszD9OKMMAMzr6XbXYxE9KMKgA/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.9&quot; data-w=&quot;300&quot; data-type=&quot;jpeg&quot; data-backw=&quot;300&quot; data-backh=&quot;270&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这幅图说明了该用哪种迁移学习，让我们逐个来看。&lt;/p&gt;

&lt;p&gt;1）右下角场景，待训练的数据集较小，已训练的模型和当前任务相似。此时可以只是重新训练已有模型的靠近输出的几层，例如将ImageNet中输出层原来可以判别一万种输出的网络改的只能判别猫的品种，从而利用已有网络来做低层次的特征提取。&lt;/p&gt;

&lt;p&gt;2）左下角场景，待训练的数据集较小，已训练的模型和当前任务场景差距较大。例如你有的已训练网络能识别出白天高速路上的违章车辆，你需要训练一个能识别出夜间违章车辆的模型，由于不管白天夜晚，交通规则是没有变化的，所以你需要将网络靠近输入的那几层重新训练，等到新的网络能够提取出夜间车辆的基本信息后，就可以借用已有的，在大数据集下训练好的神经网络来识别违章车辆，而不用等夜间违章的车辆的照片积累的足够多之后再重新训练。&lt;/p&gt;

&lt;p&gt;3）左上角场景，待训练的数据集较大，已有的模型和新模型的数据差异度很高。此时应该做的是从头开始，重新训练。&lt;/p&gt;

&lt;p&gt;4）右上角场景，待训练的数据集较大，已有模型的训练数据和现有的训练数据类似。此时应该使用原网络的结构，并保留每一层的节点权重，再逐层微调。&lt;/p&gt;

&lt;p&gt;接下来看一个实际的例子，大家都熟悉的MINST手写数字识别，也可以用迁移学习来做，已有的训练数据是六万张图片，已有的模型是通用的图像识别模型VGG16，看起来，我们即可以将网络的最高层重新训练，也可以训练网络的最初几层，毕竟手写数字的图片，和我们日常见到的图片即相似也有明显不同。点击阅读原文，可以查看具体的python代码。&lt;/p&gt;

&lt;p&gt;总结一下，迁移学习应用广泛，尤其是在工程界，不管是语音识别中应对不同地区的口音，还是通过电子游戏的模拟画面前期训练自动驾驶汽车，迁移学习已深度学习在工业界之所以成功的最坚实支柱，而学术界对迁移学习的研究则关注以下几点，一是通过半监督学习减少对标注数据的依赖，应对标注数据的不对称性，二是用迁移学习来提高模型的稳定性和可泛化性，不至于因为一个像素的变化而改变分类结果，三是使用迁移学习来做到持续学习，让神经网络得以保留在旧任务中所学到的技能。&lt;/p&gt;

&lt;p&gt;最后引申来看，集成学习，例如AdaBoost其背后的机制，也可以看成是另一种形式的迁移学习，通过多次使用训练样本，并给不同的样本赋予不同的权重，集成学习也可以做到站在巨人的肩上。而Dropout机制，也是让网络训练中随机的丢失节点，从而使得网络不得不依据之前的模型进行迁移学习，从而提高泛化能力。迁移学习本质上利用的是不同任务间的相关性，用冗余对抗复杂。&lt;/p&gt;

&lt;p&gt;参考资料&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;http://sebastianruder.com/transfer-learning/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;https://www.analyticsvidhya.com/blog/2017/06/transfer-learning-the-art-of-fine-tuning-a-pre-trained-model/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;扩展文章&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383280&amp;amp;idx=1&amp;amp;sn=a6fd903f2c47339c52dcea9eedf65851&amp;amp;chksm=84f3cbb1b38442a7f4aac491852e06c34794154946a3656bc4ac4805b1ef1b41cb4469ae8419&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;对抗神经网络初探&lt;/a&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383212&amp;amp;idx=1&amp;amp;sn=e6dbbda2acc5984c8d06e24ec9c84d09&amp;amp;chksm=84f3cbedb38442fb58f0aea635821fcf4ba3edaacef4685716c7eadb6191197ebfa70a6bf14b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;你所不能不知道的CNN&lt;/a&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 21 Jan 2018 08:28:40 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/KQI4gcI1tj</dc:identifier>
</item>
<item>
<title>从英语翻译到人工智能：我如何用两年时间跨界转行</title>
<link>http://www.jintiankansha.me/t/9NzvujlNB7</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/9NzvujlNB7</guid>
<description>&lt;p&gt;&lt;strong&gt;&lt;span&gt;本文来自铁哥好友 唐思楠 的个人公众号 影子练习SinanTalk&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;版权说明&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;无特别说明情况下，图文均原创（题图: 美剧《硅谷》） &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;欢迎转发 转载请微信联系 @LynnTang_&lt;/span&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;&lt;span&gt;刚刚发了一条微博，纪念自己从决定转行到现在刚刚好两周年：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.5625&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/ETsNbcnZdRzicic4bIy3ktuByhwZJCfibIugUiccyCZUezkSKR2E375cIq7Kl232mn1lF5zY6aeXOVmNG5850hbHBw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在这两年里，我经历了以下大大小小的里程碑：&lt;/span&gt;&lt;/p&gt;

&lt;blockquote readability=&quot;27&quot;&gt;
&lt;p&gt;&lt;span&gt;2016 年初：&lt;/span&gt;&lt;span&gt;在德国刚开始读英语语言学硕士没多久，萌生了转方向到计算机语言学（Computational Linguistics，后来我才知道那与自然语言处理 Natual Language Processing 领域基本重合）的想法。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;2016 年春夏：&lt;/span&gt;&lt;span&gt;开始在 Coursera 上从零自学编程，主要是 Python。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;2016 年夏末：&lt;/span&gt;&lt;span&gt;找到第一份计算机语言学领域的实习，在德国一研究院做 Research Assistant。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;2016 年冬：&lt;/span&gt;&lt;span&gt;利用第一份实习找到第二份德国 IBM 人工智能小组（Watson Analytics）的实习机会。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;2017 年春夏：&lt;/span&gt;&lt;span&gt;IBM 全职实习 5 个月，那时才知道计算机语言学与人工智能息息相关。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;span&gt;2017 年秋：&lt;/span&gt;&lt;span&gt;密集地在家自学了几个月计算机科学的科目，包括算法入门、数据分析、概率论、程序设计，同时继续提高编程能力；开始投简历练面试找工作。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;2017 年冬：&lt;/span&gt;&lt;span&gt;找到人生第一份正式工作，全球 500 强科技企业，人工智能行业，薪资超过德国 CS 硕士平均起薪。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;2018 年初：&lt;/span&gt;&lt;span&gt;开始工作，来到硅谷参加入职培训。&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;


&lt;p&gt;&lt;span&gt;这样列出来看起来似乎既光鲜又井井有条，但大概只有我才知道自己经历过多少不安、焦虑、抓狂和混乱。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这也是我从去年起就一直积极写文科生转行学编程找实习系列文章的初心：我懂得这条路的艰辛不易，也摸索出了一点微薄的经验与方法，更知道达成每个小目标的欣喜，因此希望能以自己的真实经历启发、帮助到更多处境类似的读者。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;让我尤有成就感的是，我已经收到过几位读者的私下赞赏和留言，说 TA 在我经历的鼓舞下也勇敢地踏出了转专业 / 转行的第一步。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;如果你也怀有转行到 IT 行业技术工程岗的想法，或想多了解在德国（欧洲）找工作的技巧，或只单纯想参考我的转行与自学编程经历，都能从这篇文章中找到你需要的内容！你也可以关注我的公众号，我会常常分享原创的工作与技术文章。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;预告：&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;本文会写到以下话题：&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot;&gt;&lt;li&gt;
&lt;p&gt;为什么转行？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;转到哪儿去？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何转行？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;怎么跨行找工作？&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;span&gt;为什么转行？转到哪儿去？&lt;/span&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我认为在做任何重要决定之前，比起搞清楚该怎么做（HOW），追问自己&lt;strong&gt;&lt;span&gt;为什么&lt;/span&gt;&lt;/strong&gt;要做出这个选择要重要得多（WHY）。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;方向大于努力。&lt;/span&gt;&lt;/p&gt;

&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;p&gt;&lt;span&gt;大多数人终究也不懂这个道理，于是终日一边忙碌一边迷茫。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;当面对职业规划的重要决策时，你做决定的依据是什么？&lt;/span&gt;&lt;/p&gt;

&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;钱&lt;/span&gt;&lt;/strong&gt;更多？更&lt;strong&gt;&lt;span&gt;喜欢&lt;/span&gt;&lt;/strong&gt;？更&lt;strong&gt;&lt;span&gt;擅长&lt;/span&gt;&lt;/strong&gt;？&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;任何一条理由都没问题，但为了增加你转行的成功率和优化新工作的发展前景，应该尽量寻找这三条职场优势的&lt;/span&gt;&lt;strong&gt;&lt;span&gt;公共交集&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;一开始，谁也不能一击命中&lt;strong&gt;&lt;span&gt;既钱多又喜欢还擅长&lt;/span&gt;&lt;/strong&gt;的工作，但这并不妨碍你先从已经&lt;/span&gt;&lt;strong&gt;&lt;span&gt;同时具备了两个职场优势的选项&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;出发，并&lt;/span&gt;&lt;strong&gt;&lt;span&gt;把三大优势的交集作为自己职业规划的终极目标&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;除此之外，每个人或许还有些个人限制条件，比如地理位置和语言水平。再比如，对于留学生或有移民需求的人来说，如果想留在国外工作，那就应该把&lt;strong&gt;解决签证&lt;/strong&gt;作为最重要的职业先决目标。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;如何利用以上理论来分析自己适不适合转行、该转到哪儿去呢？我就拿自己来举例分析分析——&lt;/span&gt;&lt;/p&gt;

&lt;blockquote readability=&quot;27&quot;&gt;
&lt;p&gt;&lt;span&gt;首先，我决定暂时留在德国或其他欧洲国家工作，这就存在语言问题。两年前刚到德国时我完全不会德语，一两年时间业余学德语也达不到可以用来流利工作的程度，因此我最好能找到可以英语工作的公司。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;另一方面，钱对于我也很重要。由于过去两三年都是自己负担生活费，常常连买学期火车票都要心疼一下，所以很迫切地需要 financial stability。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;能赚一点钱、可以讲英语还机会多的职业选择，在德国基本仅限于 IT 技术行业了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;作为文科生，对于 IT 肯定不具备“擅长”这个职业优势。但我有别的长处，我不讨厌理科和代码，有点喜欢和数据打交道；后来自学编程渐入佳境后，也喜欢上了用程序解决问题的思维方式。&lt;/span&gt;&lt;/p&gt;

&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;p&gt;&lt;span&gt;综上，对我来说，转行到 IT 行业就是我目前的职业规划最优解，接下来只要方向明确地补齐技能树就应该能够转轨到理想行业了。我找到 CS 与语言学的交叉学科“&lt;strong&gt;计算机语言学&lt;/strong&gt;（Computational Linguistics）”，在翻了很多维基百科、Quora 和知乎帖子后，决定先从自学 Python 开始。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;当然，这过程绝非顺风顺水。后来在对自然语言处理（NLP）有了更实际的认知后，我才意识到在这个领域，计算机科学素养比语言学知识储备更重要。但从本质上来说，这只是&lt;strong&gt;难度与积累时长&lt;/strong&gt;的问题，&lt;strong&gt;而&lt;/strong&gt;&lt;strong&gt;非选错了努力方向&lt;/strong&gt;。因此现在回望，我两年前的决策依然是有效、明智的。&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 class=&quot;&quot;&gt;&lt;br /&gt;&lt;/h4&gt;

&lt;h4 class=&quot;&quot;&gt;&lt;span&gt;如何转行？&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;&lt;span&gt;培训学校铺天盖地的“三个月从零到精通 Python，成为大数据工程师”速成广告，朋友圈和知乎最流行刷的也是“三个月转行数据分析”、“五个月成为前端工程师”。此时我写下这样一行“我用两年时间跨界转行”确显得非常不合群不鸡汤了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;但我真心认为，&lt;strong&gt;&lt;span&gt;用两年时间跨度真正从零掌握一门能够赚钱养家的专业技能，绝不算漫长&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;

&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;&lt;span&gt;注意这里的重要定语：&lt;strong&gt;&lt;span&gt;能够赚钱养家&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;技能分很多种，并非所有都能在两年学习积累后成功变现。那些非常依赖天赋，跟年龄关系很大，特别需要运气或社会资源的行业，外行人进入的困难更大。&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;span&gt;这里的两年指的是保留原本工作或学生身份的两年，比如我在自学编程做实习找工作的两年间也同时在正常地上课考试写论文。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;我并不鼓励脱产全职学习某项技能长达两年，因为大部分人并不能承受那种心理压力。而大跨度转行（比如纯文科转纯理工）积累阶段的最大障碍其实来自&lt;strong&gt;心魔&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;“我会不会一开始就选错了？”、“别人看起来比我更有天赋，有更多资源优势，我真的能行吗？”……长期被恐惧和焦虑驱动的滋味可不好受；这不仅让人难过，还会&lt;span&gt;&lt;strong&gt;让大脑处于“资源稀缺”的思维状态&lt;/strong&gt;&lt;/span&gt;（参考《稀缺》&amp;amp;《贫穷的本质》），容易做出只顾及眼前好处却牺牲长远利益的短视决定。比如年轻时为了赚小钱省小钱而花费宝贵时间与注意力，这类短视决定大多数人都做过，包括我。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;所以对于一开始还没在新行业建立起自信的人来说，保留主业所带来的安全感（safety net）是保证我们大脑尽可能作出符合人生长远利益决策的前提。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;span&gt;但是，长达两年的下班后转行积累方案始终存在一个致命问题：大多数人都走不到能看见光明的节点，在中途的某个困难上就跌倒在舒适区（comfort zone）的蜜糖罐儿里起不来了——任何需要长期执行的方案都存在这个问题。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;那该如何解决呢？唯有&lt;strong&gt;&lt;span&gt;有效计划&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;先入门再积极寻找实践机会。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;想进入一个新领域，在互联网资源极度丰富的今天，&lt;/span&gt;&lt;span&gt;入门其实不难&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;很多人想要转行当程序员工程师，而现在网上自学编程的课程非常多，找个权威口碑好的课程（比如 MIT600）配一本权威经典的入门书（比如我推荐多次的《Think Python 2》），认认真真在半年之内学完读完做完习题这就算入门了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;理论知识上入门之后，就需要寻找可以练手实践的机会，比如实习和个人项目，这些实践机会最好&lt;strong&gt;&lt;span&gt;既能让你获得成长又可以留下方便展示的作品&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;初学者对新领域的理解不论是广度还是深度上都必然存在误区与盲区，这些误区盲区很可能不能仅靠小白独自一人摸索来破除。与我以前在《文科女进德国 IBM 实习做程序媛，我是怎么办到的》写到的道理一致，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;你必须在与现实世界的交流反馈中才能快速成长通关&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;，想太多做太少的要么成了哲学家要么得了焦虑症。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在实践过程中反思并调整计划，有意为自己寻找职业发展路上的 mentor（同行业的前辈、校友、教授等），在学习和实践中一点点增长技能点。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;按这样的路径，两年时间足以让一个普通年轻人转换职场赛道。并且，在产业发展还未完全成熟的国家地区，比如国内，这个转行过程肯定会更快。&lt;/span&gt;&lt;/p&gt;



&lt;h4 class=&quot;&quot;&gt;&lt;span&gt;怎么跨行找工作？&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;&lt;span&gt;不论是否跨行，找实习找工作的过程中，最重要的决胜点在于&lt;strong&gt;&lt;span&gt;心态&lt;/span&gt;&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;

&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;p&gt;&lt;span&gt;尤其对于正在找人生第一份正式工作的学生来说，校园到职场的转变对于任何人来说都是不小的挑战。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;我也经历过很久这个“知道该怎么做却毫无动力去执行 - 不行动带来的焦虑越积越多 - 焦虑状态下要么动弹不得要么做啥错啥 - 最终崩溃大哭”的消极循环，所以我很理解排斥走出象牙塔，拖延开始找工作的学生心态。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;我收到工作 offer 后的第一反应是“终于不用找工作了”，因为那实在是不令人愉快的体验。我到现在也不喜欢找工作这类需要等待别人审判贴再标签的事，你也没必要喜欢啊，但这不影响我们参与 Job Hunting 游戏。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;可以把这看作培养职业素养的第一步：&lt;strong&gt;把个人感情与工作任务分开&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;没多少人喜欢找工作这件事，你又怎知面对你的 HR 和面试官不讨厌他们自己的工作，但这不妨碍每个人扮演好自己的职场角色，做好成人世界的游戏。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;毕竟，&lt;/span&gt;&lt;span&gt;&lt;strong&gt;对立心态在职场对自己毫无好处&lt;/strong&gt;&lt;/span&gt;。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;解决了心态问题，接下来为找到工作行动起来就是自然而然的事了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;这里限于篇幅就不赘述找工作细节了，具体求职攻略我会以后单独更新。但有一点关键&lt;/span&gt;&lt;strong&gt;&lt;span&gt;「元」方法&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;我一定要写一写。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;找工作是一件比找对象还讲究&lt;strong&gt;&lt;span&gt;「合适」&lt;/span&gt;&lt;/strong&gt;的事。每当看到一份招聘启事（JD）时，脑子里应该立刻放大并高频闪烁&lt;strong&gt;&lt;span&gt;「match（匹配）」&lt;/span&gt;&lt;/strong&gt;一词。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;HR 并不关心你的人生经历或你的履历是否高大上，TA 只关心你是不是这个职位的「match」，&lt;/span&gt;&lt;span&gt;你是否在简历和面试中清楚有力地表达了自己具备这个职位所需的技能或拥有学习这项技能的潜能，并给出了具体经历来证明你说的论点&lt;/span&gt;&lt;span&gt;。这一点无比重要，不论什么水准的求职者都可能犯这个错误，即把求职的焦点从「match」上移开。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;对于跨界转行的求职者来说，这一点只会更重要。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;  关于简历和面试，我想说的还有很多很多，&lt;strong&gt;接下来会专门针对这个话题写篇求职攻略文&lt;/strong&gt;，欢迎关注 :)&lt;/span&gt;&lt;/p&gt;



&lt;h4 class=&quot;&quot;&gt;&lt;span&gt;尾声&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;&lt;span&gt;通过自己的力量转行成功这件事对我来说有什么意义呢？我认真想过这个问题。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;除了更好的职业出路外，最大的意义或许是看到这个世界对我的认可进而更加了解自己了吧。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;从两年前决定转行的那一刻起，我便患上了&lt;strong&gt;「冒充者综合症 (Imposter Syndrome)」&lt;/strong&gt;。不论参加实习还是在网上写技术文，我总觉得自己在假装一个更有天赋、更有能力、更优游自如的人，而别人随时都会戳穿这层面具。实际上，直到长途飞机落地美国我走过了美国海关那一刻的前一秒，我都在怀疑这一切的真实性，还认真担心过自己签证出意外最终被海关检查员以奇怪的理由遣送的场景。所以当我终于在硅谷住下，在入职的第一天拿到属于自己的 badge 时，我突然如梦方醒，“哇，这一切竟然都是真的！！”&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;用两年时间自我积累转行成功，让我觉察到我真的拥有改变自己人生轨迹的力量，也让我有依据地相信一个人拥有只要愿意学习就能获得成长的巨大潜能。而这一切都让我进一步笃信继续写文章的意义，&lt;strong&gt;也许其中有一篇就改变了宇宙中另外一个人的人生轨迹了呢。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;


</description>
<pubDate>Fri, 19 Jan 2018 13:08:28 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/9NzvujlNB7</dc:identifier>
</item>
<item>
<title>[原创]绕不开的比特币</title>
<link>http://www.jintiankansha.me/t/2cbR6ytp4H</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/2cbR6ytp4H</guid>
<description>&lt;p&gt;针对区块链的话题，最近看来是绕不开了。先是有好友因为投资ICO赔了不少，今天铁哥又叫我来就这个话题策划一篇文。本来对于这样太热的话题，我是一向不喜欢写的，原因是这样的文多半只是表述自己的观点，对写作者个人没有提升，二来这样的话题，半衰期太短，等到时间过去之后，再回味着阅读，便没有一丝一毫的价值。&lt;/p&gt;

&lt;p&gt;然而既然决定了要写这个话题，就先要定出这篇文想要完成的目标。这里列3条，一是清晰的呈现自己对这个话题的观点，二是展现自己思考的过程，试图通过这个案例让读者能够清楚该如何面对类似比特币这样的新事物，三是说说从比特币的话题延伸出去能得出什么样的道理。&lt;/p&gt;

&lt;p&gt;写这个话题，首先要引用很多聪明人关于比特币的观点，这里就列出几个&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceyqo5GoQQMqyy8cVN7RFBFgbgiceNib5VMY9VXyXese3D9qtIfice6kKwPHbC3cDGCIykwveAxM7dSw/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.17279174725983237&quot; data-w=&quot;1551&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceyqo5GoQQMqyy8cVN7RFBFXpBODWncdBRdF2PwEHvT79FabQK7NhvcdIfAKNUF8StvJRtCTCWaqw/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.1714123006833713&quot; data-w=&quot;1756&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceyqo5GoQQMqyy8cVN7RFBF347b58ticdr6s9N2Ihey80GwtqibcTfRvqGqicle6MYeDZNqxHp4DfbvQ/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.7363128491620111&quot; data-w=&quot;895&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceyqo5GoQQMqyy8cVN7RFBFsDe72v3vyD7j5kRgyAgl2jc1CBicQPHTzLsKmDqWbbf4aUiboTA7CdOA/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.623860811930406&quot; data-w=&quot;1207&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceyqo5GoQQMqyy8cVN7RFBFnwqM9IeKXiakWg9joJqY2OHL5CibawNhRpU1y4TbAfQcvMbvEMUv9now/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.6326732673267327&quot; data-w=&quot;1010&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceyqo5GoQQMqyy8cVN7RFBFdAUBaca8g6TuAJHopn4o4YBRDjJVHf1UKyb9ybe4lNH7YzqHHfdSPQ/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;1.0345744680851063&quot; data-w=&quot;752&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceyqo5GoQQMqyy8cVN7RFBFWWbbicITFuft8cDFYp4jpU0oFxhfnoMuKInXmnCQLkQ4iaoqf43gjQpg/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.9864130434782609&quot; data-w=&quot;736&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceyqo5GoQQMqyy8cVN7RFBFLYRO4c2tINkHN36wxO4IoV68176j9yfjdrj0V9wD4ibFl7Q9uJicBoZQ/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-croporisrc=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceyqo5GoQQMqyy8cVN7RFBFw8YWhaJiav9vwsmIxbsFtiaNUmEL3owcqCGmy3HELUFG4jZDYy1tlWFA/0?wx_fmt=png&quot; data-cropx1=&quot;0&quot; data-cropx2=&quot;729&quot; data-cropy1=&quot;0&quot; data-cropy2=&quot;299.9463327370304&quot; data-ratio=&quot;0.4101508916323731&quot; data-w=&quot;729&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceyqo5GoQQMqyy8cVN7RFBFZ805GXyUAErQtZFazhCVSN4qvYicOibMibqnWJEiaQgHVqw0kDibhbkatibQ/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;1.073699421965318&quot; data-w=&quot;692&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceyqo5GoQQMqyy8cVN7RFBFGFiaraJYJ1IUh5ziaoXk8C3ibbBuVKSQ21uEHO3OfIicZH9Ud0zQclOH0w/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.7220602526724975&quot; data-w=&quot;1029&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceyqo5GoQQMqyy8cVN7RFBFtMSGlxacpp8IOyaj3GqFChP1TjjDSozH7DlFcBbCpNIicTXEKqkbBvw/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.6895306859205776&quot; data-w=&quot;1108&quot; /&gt;&lt;/p&gt;


&lt;p&gt;摘录了这么多大佬的意见，除了反脆弱的作者说期货做空比特币不可行，都是坚决不支持比特币的。下面说说我自己的看法了。&lt;strong&gt;首先我认为应该分清楚区块链和比特币以及衍生出的ICO等的区别&lt;/strong&gt;，区块链是一种革命性的，具有广泛应用场景的技术。作为一项技术，它是中立的，既可以为善，也可以为恶。而比特币仅仅区块链技术在金融上的具体应用，不能因为我反对比特币就认为我觉得区块链技术没有前途。区块链改变了互联网上的匿名复制的机制，使得每一次对数据的修改和读取都变得全网可见，未来一定会有广泛的应用。&lt;/p&gt;

&lt;p&gt;其次，我想说一说货币的价值来源，&lt;strong&gt;货币的价值在于其具有稀缺性&lt;/strong&gt;，不然谁愿意相信今天的货币在明天能买来相同的东西。最初是贵金属，后来是国家的信用，前者受制于物理定律的限制，最靠谱，后者受制于集体文化的限制，随着组织规模的扩大，也能相对的保证政府不滥用自己的权力。而比特币的算法，虽然理论上保证了其稀缺性，但只要这种算法是公开的，任何人都可以制造类似的比特币的山寨品，个人的贪欲无穷，因此根本无法保证货币本身的稀缺性。由此我认为比特币不应该被当成一种货币。未来等到量子计算发展了，做出了基于量子纠缠的新版电子货币，只怕才能成为真正靠谱的“电子货币”，因为这样的量子货币，它的稀缺性同样是基于物理规律的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;既然比特币不能作为一种货币或者金融工具，那么比特币的交易就更应该看成是一种投机而不是投资行为。&lt;/strong&gt;关于这个话题的论证，我认为可以采取机器学习的方式。也就是找到比特币的交易数据，包括价格变动表，成交量等，然后选择一批已知的投机市场，例如郁金香泡沫，英国南海股票泡沫等的数据，再选取一些成熟的市场，例如美国股市的数据。有了数据，可以构造一个2分类的分类器，看一看当前的比特币市场更像投机主宰的还是投资主宰的。之所以要采取算法来判定比特币究竟是一种投机还是投资行为，是因为算法是没有情感偏见的，也是能够整合很多人看不到的特征的。对于上述的思想实验，我没有实际来做，但是只要算一算比特币市场的日均价格方差，就可以想出来分类器会做出什么样的判断了。&lt;/p&gt;

&lt;p&gt;用一句话来概括比特币的投资，比特币以及ICO的投资的确有可能让你获得超出常人的回报，但你首先要确保自己能够承受100%的本金损失。我不能说当前比特币已进入博傻的环节，庞氏骗局的泡沫破灭虽然从长期上是不可避免，但其具体时间却是难以预测的。而从道德上来说，你明知道可能是骗局，却希望自己不是最后一个接盘的，这样的心态下即使赚到钱，你能花的心安理得吗？如果你自己的德行配不少自己得到的财富，那么财富不过是伪装的厄运，会让你过得还不如自己没有得到财富时幸福。&lt;/p&gt;

&lt;p&gt;说完了自己对于比特币的看法。下面说说该怎么从观察比特币这件事中能学到什么。首先是兼听则明，这句话知易行难，人们总以为自己是聪明的，却不愿意相信数据，而如今，你需要的是收集数据。你可以在准备投资比特币相关的领域之前，看一看大牛的意见，哪怕你弄不懂比特币的算法原理，你可以列出历年诺贝尔奖经济学得主，去列出国内外名校的经济学金融学教授的名单，一个个的去搜他们对比特币的看法，然后根据他们的观点来进行打分。你要是相信自己真的比这些大牛都聪明，那你至少要想好该用什么来对冲比特币的风险，也就是想想比特币跌的时候，什么东西的价格从机理上会涨。这么一想，你也许就发现比特币是无法找到对冲机制的，而一种无法进行风险控制的投资方式，注定不能称之为一种投资方式.&lt;/p&gt;

&lt;p&gt;最后的最后，忍不住唐僧一句，对于个人来说，财富的价值其实更多的来自创造它的过程，而不是享用财富本身，如果你在获得财富的过程中没有铸造起生命的意义，那么财富本身的消耗不会让你本来就荒谬的人生有光彩。比特币只能让你富裕，却无法让你富足。&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;

</description>
<pubDate>Tue, 16 Jan 2018 07:57:45 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/2cbR6ytp4H</dc:identifier>
</item>
<item>
<title>[原创]对抗神经网络初探</title>
<link>http://www.jintiankansha.me/t/580btc2hBL</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/580btc2hBL</guid>
<description>&lt;p&gt;GAN，也就是对抗神经网络背后的道理，具有普适的应用场景，毕竟，在金庸小说中就有左右互搏，而GAN说到底不过是一个生成器一个判别器，让俩者“自我对弈”，从而互相进步。然而，神经网络在复杂搜索空间上能够找出其他的机器学习方法所不能的路径，就如同如果你只会一俩种拳法，那么即使教会你双手互搏的心法，你也无法武功大进，而若是你本身就会顶级武功，那这时左右互搏就能让你取长补短。&lt;/p&gt;

&lt;p&gt;回到GAN，该领域的进步使得对抗神经网络的思路可以完成很多传统的深度学习方法所不能完成的任务，例如训练一个能够写新闻稿的机器人，能够模仿知名画家风格的艺术家（参考 &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383188&amp;amp;idx=1&amp;amp;sn=ec8d1090fe46741c14ccf7cc02b57c2c&amp;amp;chksm=84f3cbd5b38442c33ef70b698dd07f5b7aa954623fe3724e9f83b8e10a44b86a3777054395a4&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;怎么样用深度学习取悦你的女朋友（有代码）&lt;/a&gt;）。大神Yann LeCun在他的Quora回答中说到，&lt;strong&gt;&lt;em&gt;“(GANs), and the variations that are now being proposed is the most interesting idea in the last 10 years in ML, in my opinion.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sZePaKib83hoSePYOh4CHzUejxib4gbuBSGGyibcEfc1M1taK3BaZMn3Gg/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;1&quot; data-w=&quot;400&quot; /&gt;&lt;/p&gt;
&lt;p&gt;不必担心GAN太难，在这篇文章中, 我将向您介绍GAN的基础概念, 并解释它们是如何与挑工作的。我也会让你知道人们已经做了使用GAN做的一些很酷的事, 并给你一些可以深入了解这些技术细节的链接。我们先从GAN的名字说的Generative指的是生成式的，&lt;span&gt;Adversarial是对手的意思，而N则是Network。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;让我们先通过一个类比来解释GAN:&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;如果你想在国际象棋中表现的更好;你会怎么做？你多半会分析你做错了什么, 他做对了什么, 并考虑你可以做什么来击败他在下一场比赛。你持续的重复这样的思考, 直到你击败对手。这个例子可以用来指导该如何建立更好的模型。简单地说, 为了获得一个强大的生成器 , 我们需要一个更强大的对手 ，即鉴别器。&lt;/p&gt;

&lt;p&gt;另一个来自生活中的例子是名画的伪造者和文物专家之间的关系。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcejQNVxSmiaFURGv147aIL2swicbppC77fe8gxqAESNn9L9SFWPcHuUwzBvia7S19NGqByDHJCJC1E3w/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.6657608695652174&quot; data-w=&quot;736&quot; /&gt;&lt;/p&gt;

&lt;p&gt;伪造者的任务是创造足以以假乱真的著名艺术家的杰作的模仿品。如果这个模仿的画作被判定为原作, 伪造者就会得到许多金钱上的报酬。另一方面, 一个文物专家的任务是抓住这些伪造者的模仿品。他是怎么做到的？他知道什么真品的特有属性, 他用头脑中积累的这些知识, 来检查画作是否真实。这样的猫鼠游戏使得艺术鉴定家和仿照者都提升了姿势水平。对应到神经网络中，就是训练一个神经网络来生成数据，另一个判定网络来判定生成器生成的数据是真的（来自于现实世界的训练数据）还是假的。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcejQNVxSmiaFURGv147aIL2skicXUeGwDRZyNJIcq8HJYSZaCiaQsQs3k42ex8bKqicicJoyxHxDup9fuw/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.43260188087774293&quot; data-w=&quot;638&quot; /&gt;&lt;/p&gt;
&lt;p&gt;此图中的生成器使用随机数以及先验的知识（编程者告诉神经网络数据预期会是怎样，非必需）来生成一些伪造的数据，而图中的手写数字则是真实的图片，之后这俩部分数据被放进了判别器中，判别器要做的判定哪一个是生成器生成的，输出是0到1之间的一个数，代表每个数据点是真实数据的概率。&lt;/p&gt;

&lt;p&gt;我们来做一些数学上的严谨定义：&lt;/p&gt;
&lt;p&gt;&lt;span&gt;P(x) -&amp;gt;真实数据的分布函数&lt;/span&gt;&lt;br /&gt;&lt;span&gt;X -&amp;gt;真实数据p(x)的取样&lt;/span&gt;&lt;br /&gt;&lt;span&gt;P(z) -&amp;gt; 生成函数的概率分布&lt;/span&gt;&lt;br /&gt;&lt;span&gt;Z -&amp;gt;  生成数据p(z)的取样&lt;/span&gt;&lt;br /&gt;&lt;span&gt;G(z) -&amp;gt; 生成网络&lt;/span&gt;&lt;br /&gt;&lt;span&gt;D(x) -&amp;gt; 判别网络&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;而训练的过程可以看成是如下的优化任务：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sRCuYnumZLX9bEuMbat6A3xRiawfzazmoQ2kujzLibhfickeibabkPzw8zw/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.18032786885245902&quot; data-w=&quot;610&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;这里的V（D,G）的第一项是真实数据通过判别网络鉴定为真的期望，第二项为生成的数据&lt;strong&gt;不&lt;/strong&gt;通过判别网络的鉴定的期望，我们希望通过训练的判别器能使第一项为1，第二项为0，总的来说，训练的目标是使V（D,G）最大。而对于生成器，网络的训练目标在于使V（D,G）最小，也就是让判别网络犯迷糊。在实际的训练中，可以先训练生成网络，让判别网络冬眠，之后在训练判别网络，同时保持生成网络的参数不变，通过这样的方式，来实现上述目标。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sXq6bBg8FMYaibHUTZ2BAwrFIPnE5cwbWicWgIQ5ja0gxHicYXkd5kJ11w/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.7459618208516887&quot; data-w=&quot;681&quot; /&gt;&lt;/p&gt;

&lt;p&gt;训练GAN的7个步骤&lt;/p&gt;
&lt;p&gt;步骤 1: 定义问题。你想生成图像或文本。在这里, 您应该完全定义问题并为其收集足够的真实的训练数据。&lt;/p&gt;
&lt;p&gt;步骤 2: 定义 GAN 的体系结构。定义你的 GAN 应该是什么样子。你的生成器和鉴别器应该是多层感知机, 还是卷积神经网络？这一步将取决于您试图解决的问题。&lt;/p&gt;
&lt;p&gt;步骤 3: 先用真实数据训练鉴别器。获取已有的（或随机生成的）伪造的数据，目标是训练鉴别器使其可以正确地预测数据那些是真的。&lt;/p&gt;
&lt;p&gt;步骤4：生成器生成假数据, 并对假数据进行鉴别。获取生成的数据, 目标是让让鉴别器正确地预测它们是假的。&lt;/p&gt;
&lt;p&gt;步骤 5: 用鉴别器输出的训练生成器。现在, 鉴别器已经训练好了, 你可以得到它的判定, 并把它作为一个训练生成器的目标。目标是训练生成器来愚弄鉴别器。&lt;/p&gt;
&lt;p&gt;步骤 6: 迭代式的重复步骤3到步骤5&lt;/p&gt;
&lt;p&gt;7步: 如果假数据看似没问题 请手动检查。如果它看起来合适, 停止训练, 否则去步骤3。这是一个有点不够自动的任务, 手工评估数据是用来检测GAN训练成果的最好方式。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sz92Dxu1StWPlibsiay5X32kOJHWj8Ptib7OwgoReB7J3BVM97YUfkhRmg/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.7402031930333817&quot; data-w=&quot;689&quot; /&gt;&lt;/p&gt;
&lt;p&gt;理论上，GAN可以看成是强化学习的变种，是最容易实现强人工智能的一种方式，你可以用GAN训练可以完成任意任务的目标，不管是写作权力的游戏的续集，驾驶汽车，或者是整理法律文书。只要你能够说清楚你想要模仿的任务是什么就可以了。但是，在现实中，GAN面临着诸多的挑战。&lt;/p&gt;

&lt;p&gt;关于这个话题，可以参考下面的论文 &lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sibp9ibID91ozoAryB2oEQKzuwq5vyIBp0pFTWVmnY26HhVhic3PJaIN6A/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.719626168224299&quot; data-w=&quot;856&quot; /&gt;&lt;/p&gt;
&lt;p&gt;https://arxiv.org/pdf/1606.03498.pdf&lt;/p&gt;

&lt;p&gt;首要的问题是GAN的稳定性，即生成器和判别器是相克相生的，如果一个表现的不好，另一个也无法表现好。如果训练中判别器比生成器好的太多了，那生成器会需要特别长的时间才能稍微进步一点点，而若是你将判别器调整的过于“是非不分”，那么生成器也没什么可以学习的，同样无法进步。这对于生活在“别人家的孩子”阴影下的孩子应该很熟悉，你的父母就是那个判别器，如果你和别人家的孩子差的太远，那么你会难以进步，若是你的父母对你过度溺爱，你也无法成长。&lt;/p&gt;

&lt;p&gt;下面说说具体的问题，下面的这些图片是GAN生成的&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sSIFDWI8pibRJSqPPib8YqaWyel1OYiaeJgGakoe2OxQU0GbfR2m0ELzEw/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.7550200803212851&quot; data-w=&quot;747&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们看到，神经网络无法计数，因此会生成这样荒谬的照片，虽然图中的眼睛看起来确实是对应动物的，但神经网络却不知道该将其放在那里，放几个。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sRZMsTVd0AgKCmpN31DvQtf7pEWia2BXcdOliaopTbdlFWo2M0O7Pqy6g/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.7520107238605898&quot; data-w=&quot;746&quot; /&gt;&lt;/p&gt;
&lt;p&gt;上面的图片指出，生成器难以正确的的将三维的物体投影到2维上，也无法区分向前看和向后看的区别。&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sdnqJZb6JPsLC2Ube5RQ53amUHcgfXvGxibShjO0nGficzHXT1OY7dMqQ/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.748&quot; data-w=&quot;750&quot; /&gt;&lt;/p&gt;
&lt;p&gt;生成器不能生成理解局部和整体之间的关系，因此会生成看起来荒谬的图片。&lt;/p&gt;

&lt;p&gt;下面让我们看一个具体的案例，我们训练一个网络，来判定一幅28×28的图片是否是数字，用到的训练数据集可以从这里下载https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/&lt;/p&gt;

&lt;p&gt;下面看一看训练GAN的伪代码：&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2saQiaJKTukPiaNKBFibV3G6v7coh4X9x1niaZUCPwIyvRht526CSibgQyUVg/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.5099846390168971&quot; data-w=&quot;651&quot; /&gt;&lt;/p&gt;

&lt;p&gt;来源：http://papers.nips.cc/paper/5423-generative-adversarial&lt;/p&gt;

&lt;p&gt;接着看看用到的python 包&lt;/p&gt;
&lt;pre&gt;
import os
import numpy as np
import pandas as pd
from scipy.misc import imread

import keras
from keras.models import Sequential
from keras.layers import Dense, Flatten, Reshape, InputLayer
from keras.regularizers import L1L2
&lt;/pre&gt;
&lt;p&gt;接着给生成器设定一个随机数种子&lt;/p&gt;
&lt;pre&gt;
# to stop potential randomness
seed = 128
rng = np.random.RandomState(seed)
&lt;/pre&gt;
&lt;p&gt;导入数据&lt;/p&gt;
&lt;pre&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt;

    
# set path
root_dir = os.path.abspath('.')
data_dir = os.path.join(root_dir, 'Data')
&lt;/pre&gt;
&lt;pre&gt;
# load data
train = pd.read_csv(os.path.join(data_dir, 'Train', 'train.csv'))
test = pd.read_csv(os.path.join(data_dir, 'test.csv'))

temp = []
for img_name in train.filename:
    image_path = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)
    img = imread(image_path, flatten=True)
    img = img.astype('float32')
    temp.append(img)
    
train_x = np.stack(temp)

train_x = train_x / 255.
&lt;/pre&gt;
&lt;p&gt;看一看导入的数据的具体状况&lt;br /&gt;&lt;/p&gt;
&lt;pre&gt;
img_name = rng.choice(train.filename)
filepath = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)

img = imread(filepath, flatten=True)

pylab.imshow(img, cmap='gray')
pylab.axis('off')
pylab.show()
&lt;/pre&gt;
&lt;p&gt;&lt;span&gt;下面的图片来自于训练数据集，也是这段代码会展示的：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sWz2wUdicF4Jlicb9koGeicdhuVaEduAadCJJO5pLdbzY4SvykVKXbswiaw/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.9882352941176471&quot; data-w=&quot;255&quot; /&gt;&lt;/p&gt;

&lt;p&gt;接着我们定义生成器，这是一个三层的神经网络，前俩层是500个神经员，激活函数是常用的Relu，同时每一层进行了L2正则化，最后一层是28×28个神经元，使用Sigmoid函数来确定输出的图像中每一个点是黑，白还是灰色。&lt;/p&gt;
&lt;pre&gt;
# generator
model_1 = Sequential([
    Dense(units=hidden_1_num_units, input_dim=g_input_shape, activation='relu', kernel_regularizer=L1L2(1e-5, 1e-5)),

    Dense(units=hidden_2_num_units, activation='relu', kernel_regularizer=L1L2(1e-5, 1e-5)),
        
    Dense(units=g_output_num_units, activation='sigmoid', kernel_regularizer=L1L2(1e-5, 1e-5)),
    
    Reshape(d_input_shape),
])
&lt;/pre&gt;
&lt;p&gt;&lt;span&gt;判别网络有着类似的构成&lt;/span&gt;&lt;/p&gt;
&lt;pre&gt;
# discriminator
model_2 = Sequential([
    InputLayer(input_shape=d_input_shape),
    
    Flatten(),
        
    Dense(units=hidden_1_num_units, activation='relu', kernel_regularizer=L1L2(1e-5, 1e-5)),

    Dense(units=hidden_2_num_units, activation='relu', kernel_regularizer=L1L2(1e-5, 1e-5)),
        
    Dense(units=d_output_num_units, activation='sigmoid', kernel_regularizer=L1L2(1e-5, 1e-5)),
])
&lt;/pre&gt;
&lt;p&gt;接着可以看一看网络的整体情况&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sCBTHJ60JVWM6kZ5TLTs7uXDA9PeDvCPYxoeGdzy8kDJnTv1QO3DDSQ/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.27923387096774194&quot; data-w=&quot;992&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sff1DGpu4WrRply4Ty1NIqC3RZs7UaaSjPB1YG2f9DicgX41ic2ialGFiag/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.3119266055045872&quot; data-w=&quot;981&quot; /&gt;&lt;/p&gt;
&lt;p&gt;接着倒入Keras中和GAN相关的包：&lt;/p&gt;
&lt;pre&gt;
from keras_adversarial import AdversarialModel, simple_gan, gan_targets
from keras_adversarial import AdversarialOptimizerSimultaneous, normal_latent_sampling
&lt;/pre&gt;
&lt;p&gt;最后我们开始GAN的训练&lt;/p&gt;
&lt;pre&gt;
gan = simple_gan(model_1, model_2, normal_latent_sampling((100,)))
model = AdversarialModel(base_model=gan,player_params=[model_1.trainable_weights, model_2.trainable_weights])
model.adversarial_compile(adversarial_optimizer=AdversarialOptimizerSimultaneous(), player_optimizers=['adam', 'adam'], loss='binary_crossentropy')

history = model.fit(x=train_x, y=gan_targets(train_x.shape[0]), epochs=10, batch_size=batch_size)
&lt;/pre&gt;
&lt;p&gt;让看看训练10轮后的结果&lt;/p&gt;
&lt;pre&gt;
plt.plot(history.history['player_0_loss'])
plt.plot(history.history['player_1_loss'])
plt.plot(history.history['loss'])
&lt;/pre&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2s5uWzahiapia0XqH3aLudOQkhibzb4v6UsDH1S5Su7yiapr0vyTpnwb7zXA/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.6774193548387096&quot; data-w=&quot;372&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这里我们看到生成器一开始表现是很差的，判别器表现也不好，但是不要急，经过100轮的训练，得到了下面的图片，看起来就挺像数字的了。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2s5aCweiaJiaRTuRb7WxP1qtIwCiaJP4Y5jSJTKBMsMxs98IQMA2qxYr0Qg/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.9882352941176471&quot; data-w=&quot;255&quot; data-type=&quot;png&quot; /&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sWgManM7xnELgqLDia22pPQmqUKxDx6M2gmzkBHdatIjQ6RkezNBoVcQ/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.9882352941176471&quot; data-w=&quot;255&quot; data-type=&quot;png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2s1piayAk41c3cIMjW7Gdh19OJkoaG0Aib7pQWMxmZ9powf8icOCWwabPOQ/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.9882352941176471&quot; data-w=&quot;255&quot; data-type=&quot;png&quot; /&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2suee0F74j2aDl1nMicKmuql7pw8ibFVM2IqYc1MaUrweBNYibRTo3lwHgw/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.9882352941176471&quot; data-w=&quot;255&quot; data-type=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面介绍一下GAN的应用场景：&lt;/p&gt;
&lt;p&gt;预测视频中下一帧会发生什么？ &lt;span&gt;: https://arxiv.org/pdf/1511.06380.pdf&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sCqTWaRfaCyK2icpW7gbvHfHbdURtTugy2mibYhNLOJiayFvibwZMDMy2AA/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.902542372881356&quot; data-w=&quot;236&quot; data-type=&quot;png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2suLN3UX8hpF5vfya2icFuaQ32ibEm56icicLpKtT2dqURdzKtU2C5F7mXkQ/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.42350332594235035&quot; data-w=&quot;451&quot; data-type=&quot;png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;用较低像素的图片中生成较高像素的图片：&lt;span&gt;https://arxiv.org/pdf/1609.04802.pdf&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sJxjDSSmGRnlcmribREWia0MiaxiannlRicCY9A8TRUA33TdCQvazpSZNygg/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.5172031076581576&quot; data-w=&quot;901&quot; /&gt;&lt;/p&gt;
&lt;p&gt;创意图片的动态生成，艺术家只需要画出草稿，由GAN来填充细节&lt;/p&gt;
&lt;p&gt;&lt;span&gt;https://github.com/junyanz/iGAN&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sZN60aDgQEfzicu8QByIM9p31DF2ypWXZxicyoBZ08nbiasTaicgoB6fiboA/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.7170626349892009&quot; data-w=&quot;463&quot; /&gt;&lt;/p&gt;
&lt;p&gt;利用原始图片生成新图片：&lt;span&gt;https://arxiv.org/pdf/1611.07004.pdf&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2s36R42Z7r2FFbQZ8yj7iaOibvX8iamtiadibTGwkOqBqcWHHAfzxNXvYkDUg/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;1.0152439024390243&quot; data-w=&quot;328&quot; /&gt;&lt;/p&gt;
&lt;p&gt;根据图片生成描述的文字&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcejQNVxSmiaFURGv147aIL2sicNvhaEia7QVNicS7Cu0fQnrRJu86TtS8oMbr67u0dagAGWqJx83TO6qA/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.4123989218328841&quot; data-w=&quot;1113&quot; data-type=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总结：GAN是神经网络研究中很热门的一个子领域，也有很多变种，进展很快，工业界的应用也很广。GAN的思路会让人想起无监督学习中的自编码器，其思路虽然说起来很简单，但要想训练好相应的GAN，却需要很多和问题相关的技巧。&lt;/p&gt;

&lt;p&gt;最后列出对GAN学习有关的链接：&lt;/p&gt;
&lt;p&gt;https://github.com/zhangqianhui/AdversarialNetsPapers&lt;/p&gt;
&lt;p&gt;http://www.deeplearningbook.org/contents/generative_models.html&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;本文参考：https://www.analyticsvidhya.com/blog/2017/06/introductory-generative-adversarial-networks-gans/&lt;/p&gt;
&lt;p&gt;http://www.iangoodfellow.com/slides/2016-12-04-NIPS.pdf&lt;/p&gt;

&lt;p&gt;扩展阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383233&amp;amp;idx=1&amp;amp;sn=3a9cb6619a9340a01eb4a46f56a53312&amp;amp;chksm=84f3cb80b3844296f5824666bc97cd6211456d49bc1d68c0648189026e2814d138e4e06ee553&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;用R语言实现深度学习情感分析例子&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383226&amp;amp;idx=1&amp;amp;sn=959e2bfa3cdf523250b1d082548380a2&amp;amp;chksm=84f3cbfbb38442ede89aa9b8bd4e1db04c7d5faaa4111a73d9712f1055aeebcd8ec3f2b17b07&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;用深度学习玩图像的七重关卡&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 15 Jan 2018 07:13:02 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/580btc2hBL</dc:identifier>
</item>
</channel>
</rss>