<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>我也许不配我的同情心</title>
<link>http://www.jintiankansha.me/t/ubWaudqv0Y</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/ubWaudqv0Y</guid>
<description>&lt;p&gt;10年之前，美国各地都展开了影响深远的强拆行为，寒冬之际，不少家庭在短短几天之内，从自家的住的公寓被赶出去，而只得住在坏境更加差的汽车旅馆中，甚至不得不举家露宿街头。我描述的这件事，叫做次贷危机。那些在次贷危机中被赶出家的人，有多少是真正了解或者想去了解那些未来高到离谱的还款条件的。人可以有梦想，但若是完全超越了现实，那就是妄想，就是贪欲，不值得被鼓励。&lt;/p&gt;

&lt;p&gt;十年之后，面对朋友圈爆棚的同情心，实在忍不住想写点什么。很多人都熟悉《了不起的盖茨比》的作者说过那句话，同时保有全然相反的两种观念,还能正常行事,是第一流智慧的标志。而另一位常常出现在所谓的中产嘴里的智慧导师查理芒格也说过，&lt;em&gt;如果我要拥有一种观点，如果我不能够比全世界最聪明、最有能力、最有资格反驳这个观点的人更能够证否自己，我就不配拥有这个观点。&lt;/em&gt;先让我们记住这俩句话，如果你觉得他们说的有道理。接着我们来看看最近最容易被404的话题，折叠的首都。&lt;/p&gt;

&lt;p&gt;在一片404的海洋中，我们其实只是看到了一方的观点，而没有看到另一方的观点。这些写文章的作者们似乎都没有想过另一方的逻辑，不过这并不怪他们，有句话说得好，不在其位，不谋其政。那些转发404的伙伴，有多少实地去看过群租房，去体验过低端行业里的生活究竟是怎样的，又有多少看过哪怕是一个小镇的经济数据，或者管理过一个村庄。在没有获得完整的信息的时候，你是不配去批评权威的。世界本来就是这么残酷，话语权要依靠自己的思考来争取，没有人可以永远生活在童话里。&lt;/p&gt;

&lt;p&gt;你若是想要写出一篇不被404的文，你要做的是先真正想清楚自己的论点有什么问题，什么地方可以怎样被证伪，被反驳。你要能看到站在楚河汉界的两方各自的难处和不得已，看出他们各自的逻辑都说的通，然后还能给出自己的解决方案。若是做不到这一点，那你的观点多半是噪音的概率大一些。看到这里，作为读者的你可以用《了不起的盖茨比》的话来反驳我，“&lt;em&gt;每逢你想要批评任何人的时候，你就记住，这个世界上所有的人，并不是个个都有过你拥有的那些优越条件。”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;的确，并不是每一个人都能做到时刻保持理智的头脑，时刻不被感情所挟持。但这不应该成为每一个有独立意识的公民所毕生追求的目标吗？如同内省能力，独立思考的能力并不是天生的，唯有艰辛的训练才能获得。可为什么等到了修炼的关键时刻，你们就只是从众的转发，难道就不能发出些不同的声音吗？&lt;/p&gt;

&lt;p&gt;这篇文章背后的读者又忍不住的冒了出来，难倒忘了昆德拉说过的刻奇了吗？反媚俗本身往往还是一种媚俗。昆德拉借书中人物的口说道，&lt;em&gt;你是站在媚俗的对立面的。但是他们不能摆脱媚俗，媚俗是人类的博爱，媚俗是枷锁，但是媚俗是让人能够将双脚放在地面上的力量。&lt;/em&gt;读者会说我最讨厌这样的理中客了，我就要展示我的同情心，因为我是一个活生生的人。&lt;/p&gt;

&lt;p&gt;好，那我们先谈同情心，之后再来谈媚俗。同情心不是点亮蜡烛，也不是转发404，而是要看看实际的行动。而想到转发的伙伴多半自己也是上个月刚刚自嘲过的困难群众，也就不应该要求他们去捐钱，那每个人至少有几件旧衣服，家里有几本不需要的书吧。那这些衣服，你们总可以洗干净，捐出去了吧。但是你们有这么做吗？有发动你的朋友一起捐旧衣和旧书吗？同情心永远不应该只是谈谈而已。当你羡慕英国火灾后的人情味，但是这背后的基础是基督教文化传统。要传递同情心，去行动比去只是发言更有效果。&lt;/p&gt;

&lt;p&gt;回到媚俗的话题。媚俗的根源就是对生命的绝对认同。昆德拉如是说。这话也说到了点子上。很多人都熟悉的三体中有澳洲移民的那一段，有这么一句话，生存本来就需要争取,什么时候成了理所当然?”而在三体结束的段落，歌者唱完“我看到了我的爱恋”，片刻后，向太阳系随手丢出了二向箔。在歌者的话里，我看到了相似的媚俗。《遥远的救世主》中写道&lt;em&gt;生存法则很简单，就是忍人所不忍，能人所不能，忍是一条线，能又是一条线，这个两者之间就是生存空间。&lt;/em&gt;这个规则从生命诞生后就没变过，未来也不会变。&lt;/p&gt;

&lt;p&gt;引用知乎用户殷泉夜的话：&lt;em&gt;用爱解决悬殊问题是多么可笑的想法。退一万步讲，任何个体都只会爱与自己差不多平等的个体，就像人可能爱上另一个人或者一个猩猩一条鱼，却不会爱上一个细菌或者草履虫。&lt;/em&gt;而对于工作在写字楼，没有住过带着隔间的群租房的人来说，你们的发言，和歌者的歌曲，又有什么区别，同样是让人细思极恐。一方面对未来充满焦虑，想通过终身学习提升自己，而这实际上是在限制那些你们同情的人群的发展上限，而另一方面，你们又想通过发言，来表示自己的社会责任心和道德情操。&lt;/p&gt;

&lt;p&gt;还是《生命不可承受之轻》中的话，&lt;em&gt;“令她反感的，远不是世界的丑陋，而是这个世界所戴的漂亮面具。”&lt;/em&gt; 都是成年人了，应该活在现实中，都应该试着去追求主人的道德观，而不是弱者的，依赖强者的道德期望而意外获得的渴望救世主的道德观。所以我不是为了反媚俗而反对，而是为了让更多人看到这个社会残酷却每时每刻都在上演的每个人对每个人的战争真相。&lt;/p&gt;

&lt;p&gt;有文章拿大公司裁员时只给半小时收拾个人物品，来类比最近发生的事。而我这里则是拿美国的次贷危机来类比。最近的争论，从本质上看，其实可以看成是一个很古老的问题，也就是用一个不恰当的手段去做一件长期上有价值也必须要做的事，是不是有错。从一方面来讲，产业升级的重要性这里不需要多讲，违规的群租房如果程序正义上没有问题，就应当做到有法必依。而从另一方面来讲，其中的手段的确有值得诟病值得改进的地方。至于能不能，该不该用大局这样抽象的词语掩盖过去，则是个人的道德问题，而不该是法律问题。舆论应该通过指出问题来影响未来的立法，而不应该通过情绪的宣泄来干扰当前的执法。&lt;/p&gt;

&lt;p&gt;让舆论干扰法制的后果，已经在西欧接受中东难民的事上显现了出来。当年默克尔在难民上受到了民意的影响，没有坚持自己本来的政策，从而使得当前的德国多少受了本来不该有的冲击。我这篇很早就写好的文，拖到现在才想发，就是觉得虽然知道观点肯定会受到抨击，然而毕竟是向往过千万人吾往矣的人。这件事情上看得透的人不会忧心，他们知道事情已经发生，要关注的是未来如何在乡村造血，使得这些人能够融入社会的合作网络中。&lt;/p&gt;

&lt;p&gt;这篇文章刻意不去谈论法律的对错，我知道我的背景不配说这个，对于自己不了解的，就该保持沉默。但我知道，当众人都在指责一个人或者一个抽象的机构时，这是很危险的很恐怖的。好的文化应该是具有内省而不是仅仅会向外去指责的，这会限制个人去解读不该被忽略的细节，会使得他容易被有心人或者媒体煽动，去做出一些他们长大后会后悔的事情来。&lt;/p&gt;

&lt;p&gt;萧伯纳有句话：人人有权争胜负,无人有权论是非。我不喜欢一心只争论是非，但不解决实际问题，也不能帮助读者成长的文字。然而我似乎不应该去苛责过多，论语中有这样的话，&lt;em&gt;孟氏使阳肤为士师,问于&lt;/em&gt;&lt;em&gt;曾子&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;em&gt;曾子&lt;/em&gt;&lt;em&gt;曰：“上失其道,民散久矣.如得其情,则哀矜而勿喜.”&lt;/em&gt; 士师就是典狱官，这里的曾子说的是在上位的人失去了和百姓交流的通道,百姓早就离心离德了.你如果能弄清他们的情况,就应当怜悯他们,而不要自鸣得意，也不要以执政者无道为理由而藐视对法律的尊严。真正的怜悯是把自己置身在他人那里，我住过的最类似群租房是实习那三个月的八人一间的小宿舍，然而那毕竟是合法的，有管理登记的。在苦水里泡的不够久，我也许还配不上拥有同情心。&lt;/p&gt;

&lt;p&gt;那就在最后说说怎么样的发言，才能算是有信息量的。你可以叙述发生了什么，但你要格外的克制，不在记叙中夹杂自己的评论和情绪，要记录一个事件各方面的参与者，要在记叙中只用那些你亲眼所见的，或者是有据可查的信息。你也可以去做分析，但分析是比记录更难的事情，你需要全面的系统性的去看，要保持前瞻性，需要对人性的多样有深刻的了解。当然最简单的还是去传播，但传播的时候你自己要去选择，选择那些不是那么情绪化的。现代社会是一个非常复杂的整体，情绪这种系统一给出的快速的反馈多半是不适合的，我们需要在面对复杂的问题时，以复杂对抗复杂。&lt;/p&gt;

&lt;p&gt;对于一件事情，除了法律的观点之外，还会有道德，文化，经济，宗教的观点，在任何一种观点的偏废，都是不好的。因此传播的时候，也要注意多样化。当然，应对复杂最好的方法还是去行动。你可以去用行动在实际上帮助那些你觉得值得同情的人，你可以做的不止是捐捐捐，你也许会觉得明年那些被赶走的人又会回到新的群租房里，那时也许一些企业会给他们也许会有更高一些的工资，更好的工作坏境，然后他们的产品也会涨价，到时你们应该还会记得怎么用脚投票吧。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;


&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383164&amp;amp;idx=1&amp;amp;sn=0cfac710d4d5783ed06bbdb694828409&amp;amp;chksm=84f3cb3db384422b11c90bf7826cc7b52a3f74176442fb28e6ebc27b5e44c9d1ef33f39d077e&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;多余的话 借深度网络说说最近发生的几件事&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;









</description>
<pubDate>Sat, 02 Dec 2017 15:36:56 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/ubWaudqv0Y</dc:identifier>
</item>
<item>
<title>R 语言中的深度学习 Minst数据集下的聚类分析</title>
<link>http://www.jintiankansha.me/t/grFZrWsqEf</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/grFZrWsqEf</guid>
<description>&lt;p&gt;&lt;span&gt;本文为巡洋舰的深度学习实战课程 预科准备。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;说到深度学习，想到的都是python中的框架，例如tensorflow。然而R语言作为另一种数据科学家常用的工具，也不会缺席深度学习的盛宴的。今天为大家介绍一个来自R语言的包（package），名叫h2o，相比tensorflow，他的功能虽然不够强大，可能无法实现CNN，RNN这种特殊的结构，但却可以满足日常数据分析和建模的应用。&lt;/p&gt;

&lt;p&gt;这个包的安装简单，只需一行命令就可以搞定，不管是在notebook中，还是R的自带的运行坏境，只要输入install.package(&quot;h2o&quot;), 然后选择相应的镜像服务器，就可以安装完成了。h2o这个包功能强大，不止包含深度学习的模型，还包括工程界流行树模型，例如xgBoost，随机森林等，还包括自然语言处理中的word2vec，由于这个包是由由java实现底层代码的，其运算速度相对较快。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;而h2o这个包中和深度学习有关的函数是deeplearning这个函数，这个函数既可以用来训练常见的分类模型，用来做有监督学习；也可以用来做无监督学习，对数据进行聚类。而对于用深度学习的模型来进行聚类，则是这里要介绍的要点，也就是自编码器。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;无监督学习的目的是为了展示出那些没有带标签的数据之间的关系。一种常见的应用场景是数据降维，也就是将原来的高纬度数据投影到2维，从而使人们可以清楚的看到其间的关系。而用来评价数据降维的效果好坏，有一套常用的数据集，也就是分类中常用的MINST，手写数字的照片集，如下图。&lt;/p&gt;


&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceCicV64SRTQnx3BRq4k511ZtNQx32nw4EmRFvgoXnq4b9SEVKFCMXOMcELC0VWOV5pkg6d81BdcVA/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.7423423423423423&quot; data-w=&quot;555&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而分类的任务是给定一个数据，由算法模型来预测这个数字究竟是几，而聚类的任务，则是去看看能不能相同的数字放到一起，常用的聚类方法有PCA和tsne， 其中tsne是效果较好的一种方法。下图分别是用PCA 和tsne'做聚类得到的结果，不同的颜色代表不同的数字，我们看到各个类之间还是分得比较开的。而之所以tsne效果要好于pca，那是因为tsne能更好的处理非线性的变换，从而造成较少的信息丢失。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceCicV64SRTQnx3BRq4k511ZSJETWx8QNbWf8wGiae19HVib8FHxHNg3HiczzmquQ7zbmj5jjUg6HoQZg/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.8079561042524005&quot; data-w=&quot;729&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceCicV64SRTQnx3BRq4k511ZvUWlHSMEyNhrNJGcxhSdyicl0UKOHIseECczRGS5LP5PuPpB9VWL6Rw/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;1.1&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;


&lt;p&gt;而深度学习，则天生适合处理非线性的情况，所以从理论上来说，使用深度学习，也可以做到较好的聚类。自编码器是一种神经网络的结构，其左右互博的思路，有些类似GAN。一个神经网络用来降低维度，另一个网络用来从降维的信息中恢复出尽可能多的信息，整个神经网络的目标是使得恢复出的数据尽可能的和原始的数据相类似。&lt;/p&gt;

&lt;p&gt;&lt;img data-backh=&quot;301&quot; data-backw=&quot;556&quot; data-w=&quot;820&quot; data-ratio=&quot;0.5414634146341464&quot; class=&quot;&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceCicV64SRTQnx3BRq4k511ZSsT4Ehrz0jSZU1G6LrK659ZGMdic3rFFIqXt1exz8ZWDHv0pAzYIfWA/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以上的神经网络中，输入的信息有4维，经过一层名叫编码器的神经网络的降维，变成了2维的，也就是中间那俩个隐藏层的输出，之后进过4个解码器中人工神经元的处理，由恢复成了4维，这就是一个最基本的自编码器。&lt;/p&gt;

&lt;p&gt;而将许多个单层的编码器和解码器按照顺序堆叠起来，就构成了更强大的深度自编码器，如下图所示。先是将5维变成4维3维再变成2维，之后再按顺序升维。而要获得降维后的表示，只要看看中间那俩个神经元的输出就好。&lt;/p&gt;

&lt;p&gt;好，我们来看看在R 语言的h2o包中如何实现深度自编码器。首先是导入包，&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;library(h2o) 这一句就行了，之后是导入训练数据&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;mfile =&lt;/code&gt; &lt;code class=&quot;r string&quot;&gt;&quot;D:\R_Projects\MNIST\MNIST_DIGITStrain.csv&quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;MDIG =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;h2o.importFile&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(path = mfile,sep=&lt;/code&gt;&lt;code class=&quot;r string&quot;&gt;&quot;,&quot;&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;之后要做的就是去规定模型了，这里的函数有很多参数，每一个读者都可以在了解后观察其对模型效果的影响，这里大多数采取了默认值。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;NN_model =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;h2o.deeplearning&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;x = 2:785,&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;training_frame = MDIG,&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;hidden =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;c&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(400, 200, 2, 200, 400 ),&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;epochs = 600,&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;activation =&lt;/code&gt; &lt;code class=&quot;r string&quot;&gt;&quot;Tanh&quot;&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;,&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;autoencoder =&lt;/code&gt;  &lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; &lt;code class=&quot;r keyword&quot;&gt;TRUE&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这里x 指出了使用数据中的第2列到第785 列，第一列是该行突袭对应的数字标签，这里不用，第二行是告诉模型使用的训练数据是之前导入的MINST，第三个参数指定了有多少可隐藏神经元，最初是400个，之后是200个，最后是2个，再进行升维，第四个参数是说模型最多训练400轮，第五个函数是每个神经元的激励函数是什么，这里是双曲正切Tanh函数，最后一个参数是指定这里是一个自编码器而不是分类器。&lt;/p&gt;

&lt;p&gt;接着我们来看看模型的效果，第一幅图是用自编码器画出的，第二副则是由h2o这个包中的线性聚类方法SVD画出的，明显看起来第一幅要比第二副好的的，当然自编码器要慢一些，需要350秒来完成训练，而SVD只需要6.5 秒。有兴趣的小伙伴可以自己试试不同的网络结构，看看会不会得出更好的效果。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;train_supervised_features2 =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;h2o.deepfeatures&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(NN_model, MDIG, layer=3)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;plotdata2 =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;as.data.frame&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(train_supervised_features2)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;plotdata2$label =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;as.character&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(&lt;/code&gt;&lt;code class=&quot;r functions&quot;&gt;as.vector&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(MDIG[,1]))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;r functions&quot;&gt;qplot&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(DF.L3.C1, DF.L3.C2, data = plotdata2, color = label, main =&lt;/code&gt; &lt;code class=&quot;r string&quot;&gt;&quot;Neural network: 400 - 200 - 2 - 200 - 4000 &quot;&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceCicV64SRTQnx3BRq4k511ZMfRMrSCIUnicFBDJalm7f8VmE2lzQ7gzySGuwGib2ChZjvI684DmiaiaBA/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.9076376554174067&quot; data-w=&quot;563&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceCicV64SRTQnx3BRq4k511Z1iaLXNDyDakIGGlfuwVrkQw9hjxpHomnlu2vWXRnSSc9ASklzhgGfTA/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.6305506216696269&quot; data-w=&quot;563&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总结一下，在R平台下，也可以进行深度学习，而且可以进行聚类和数据降维。自编码器作为一种常见的非监督学习框架，在未来也会有广泛的应用。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;欢迎关注巡洋舰的深度学习实战课程&lt;/span&gt;&lt;span&gt;， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;

</description>
<pubDate>Thu, 30 Nov 2017 20:32:57 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/grFZrWsqEf</dc:identifier>
</item>
</channel>
</rss>