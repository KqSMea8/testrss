<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>R 语言中的深度学习 Minst数据集下的聚类分析</title>
<link>http://www.jintiankansha.me/t/grFZrWsqEf</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/grFZrWsqEf</guid>
<description>&lt;p&gt;&lt;span&gt;本文为巡洋舰的深度学习实战课程 预科准备。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;说到深度学习，想到的都是python中的框架，例如tensorflow。然而R语言作为另一种数据科学家常用的工具，也不会缺席深度学习的盛宴的。今天为大家介绍一个来自R语言的包（package），名叫h2o，相比tensorflow，他的功能虽然不够强大，可能无法实现CNN，RNN这种特殊的结构，但却可以满足日常数据分析和建模的应用。&lt;/p&gt;

&lt;p&gt;这个包的安装简单，只需一行命令就可以搞定，不管是在notebook中，还是R的自带的运行坏境，只要输入install.package(&quot;h2o&quot;), 然后选择相应的镜像服务器，就可以安装完成了。h2o这个包功能强大，不止包含深度学习的模型，还包括工程界流行树模型，例如xgBoost，随机森林等，还包括自然语言处理中的word2vec，由于这个包是由由java实现底层代码的，其运算速度相对较快。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;而h2o这个包中和深度学习有关的函数是deeplearning这个函数，这个函数既可以用来训练常见的分类模型，用来做有监督学习；也可以用来做无监督学习，对数据进行聚类。而对于用深度学习的模型来进行聚类，则是这里要介绍的要点，也就是自编码器。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;无监督学习的目的是为了展示出那些没有带标签的数据之间的关系。一种常见的应用场景是数据降维，也就是将原来的高纬度数据投影到2维，从而使人们可以清楚的看到其间的关系。而用来评价数据降维的效果好坏，有一套常用的数据集，也就是分类中常用的MINST，手写数字的照片集，如下图。&lt;/p&gt;


&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceCicV64SRTQnx3BRq4k511ZtNQx32nw4EmRFvgoXnq4b9SEVKFCMXOMcELC0VWOV5pkg6d81BdcVA/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.7423423423423423&quot; data-w=&quot;555&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而分类的任务是给定一个数据，由算法模型来预测这个数字究竟是几，而聚类的任务，则是去看看能不能相同的数字放到一起，常用的聚类方法有PCA和tsne， 其中tsne是效果较好的一种方法。下图分别是用PCA 和tsne'做聚类得到的结果，不同的颜色代表不同的数字，我们看到各个类之间还是分得比较开的。而之所以tsne效果要好于pca，那是因为tsne能更好的处理非线性的变换，从而造成较少的信息丢失。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceCicV64SRTQnx3BRq4k511ZSJETWx8QNbWf8wGiae19HVib8FHxHNg3HiczzmquQ7zbmj5jjUg6HoQZg/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.8079561042524005&quot; data-w=&quot;729&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceCicV64SRTQnx3BRq4k511ZvUWlHSMEyNhrNJGcxhSdyicl0UKOHIseECczRGS5LP5PuPpB9VWL6Rw/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;1.1&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;


&lt;p&gt;而深度学习，则天生适合处理非线性的情况，所以从理论上来说，使用深度学习，也可以做到较好的聚类。自编码器是一种神经网络的结构，其左右互博的思路，有些类似GAN。一个神经网络用来降低维度，另一个网络用来从降维的信息中恢复出尽可能多的信息，整个神经网络的目标是使得恢复出的数据尽可能的和原始的数据相类似。&lt;/p&gt;

&lt;p&gt;&lt;img data-backh=&quot;301&quot; data-backw=&quot;556&quot; data-w=&quot;820&quot; data-ratio=&quot;0.5414634146341464&quot; class=&quot;&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceCicV64SRTQnx3BRq4k511ZSsT4Ehrz0jSZU1G6LrK659ZGMdic3rFFIqXt1exz8ZWDHv0pAzYIfWA/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以上的神经网络中，输入的信息有4维，经过一层名叫编码器的神经网络的降维，变成了2维的，也就是中间那俩个隐藏层的输出，之后进过4个解码器中人工神经元的处理，由恢复成了4维，这就是一个最基本的自编码器。&lt;/p&gt;

&lt;p&gt;而将许多个单层的编码器和解码器按照顺序堆叠起来，就构成了更强大的深度自编码器，如下图所示。先是将5维变成4维3维再变成2维，之后再按顺序升维。而要获得降维后的表示，只要看看中间那俩个神经元的输出就好。&lt;/p&gt;

&lt;p&gt;好，我们来看看在R 语言的h2o包中如何实现深度自编码器。首先是导入包，&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;library(h2o) 这一句就行了，之后是导入训练数据&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;mfile =&lt;/code&gt; &lt;code class=&quot;r string&quot;&gt;&quot;D:\R_Projects\MNIST\MNIST_DIGITStrain.csv&quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;MDIG =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;h2o.importFile&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(path = mfile,sep=&lt;/code&gt;&lt;code class=&quot;r string&quot;&gt;&quot;,&quot;&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;之后要做的就是去规定模型了，这里的函数有很多参数，每一个读者都可以在了解后观察其对模型效果的影响，这里大多数采取了默认值。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;NN_model =&lt;/code&gt;  &lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; &lt;code class=&quot;r functions&quot;&gt;h2o.deeplearning&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;x = 2:785,&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;training_frame = MDIG,&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;hidden =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;c&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(400, 200, 2, 200, 400 ),&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;epochs = 600,&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;activation =&lt;/code&gt; &lt;code class=&quot;r string&quot;&gt;&quot;Tanh&quot;&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;,&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; &lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;autoencoder =&lt;/code&gt; &lt;code class=&quot;r keyword&quot;&gt;TRUE&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这里x 指出了使用数据中的第2列到第785 列，第一列是该行突袭对应的数字标签，这里不用，第二行是告诉模型使用的训练数据是之前导入的MINST，第三个参数指定了有多少可隐藏神经元，最初是400个，之后是200个，最后是2个，再进行升维，第四个参数是说模型最多训练400轮，第五个函数是每个神经元的激励函数是什么，这里是双曲正切Tanh函数，最后一个参数是指定这里是一个自编码器而不是分类器。&lt;/p&gt;

&lt;p&gt;接着我们来看看模型的效果，第一幅图是用自编码器画出的，第二副则是由h2o这个包中的线性聚类方法SVD画出的，明显看起来第一幅要比第二副好的的，当然自编码器要慢一些，需要350秒来完成训练，而SVD只需要6.5 秒。有兴趣的小伙伴可以自己试试不同的网络结构，看看会不会得出更好的效果。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;train_supervised_features2 =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;h2o.deepfeatures&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(NN_model, MDIG, layer=3)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;plotdata2 =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;as.data.frame&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(train_supervised_features2)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;plotdata2$label =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;as.character&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(&lt;/code&gt;&lt;code class=&quot;r functions&quot;&gt;as.vector&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(MDIG[,1]))&lt;/code&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; 
&lt;p&gt;&lt;code class=&quot;r functions&quot;&gt;qplot&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(DF.L3.C1, DF.L3.C2, data = plotdata2, color = label, main =&lt;/code&gt; &lt;code class=&quot;r string&quot;&gt;&quot;Neural network: 400 - 200 - 2 - 200 - 4000 &quot;&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceCicV64SRTQnx3BRq4k511ZMfRMrSCIUnicFBDJalm7f8VmE2lzQ7gzySGuwGib2ChZjvI684DmiaiaBA/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.9076376554174067&quot; data-w=&quot;563&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceCicV64SRTQnx3BRq4k511Z1iaLXNDyDakIGGlfuwVrkQw9hjxpHomnlu2vWXRnSSc9ASklzhgGfTA/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.6305506216696269&quot; data-w=&quot;563&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总结一下，在R平台下，也可以进行深度学习，而且可以进行聚类和数据降维。自编码器作为一种常见的非监督学习框架，在未来也会有广泛的应用。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;欢迎关注巡洋舰的深度学习实战课程&lt;/span&gt;&lt;span&gt;， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;

</description>
<pubDate>Thu, 30 Nov 2017 20:32:57 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/grFZrWsqEf</dc:identifier>
</item>
<item>
<title>怎么样用深度学习取悦你的女朋友（有代码）</title>
<link>http://www.jintiankansha.me/t/PfqJe3yAlh</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/PfqJe3yAlh</guid>
<description>&lt;p&gt;&lt;span&gt;本文为巡洋舰的深度学习实战课程 预科准备。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;深度学习目前为止最有用的东西是图像处理，我们可以用它在极早期判断癌症， 也可以用它在茫茫人海里寻找犯人，但是要我说你能写一个小程序取悦女朋友， 你就不一定能信， 这一招叫艺术风格变换，就是你点击一下，就可以把你女朋友的大头照换成一个毕加索的后现代艺术作品（当然是取代还是找打要看你的艺术品位）。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.23965141612200436&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYic4o3ws1KeJDFhvTm58UIPuMhxlGQ2UiciaAyZWHk9R0Hh8dkh5Fh9jyg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;459&quot; width=&quot;459&quot; /&gt;入行需谨慎
&lt;p&gt;艺术风格迁移是一个古老而现代的主题 ， 多少艺术家为了描摹他人作品而竞折腰。 在出现了IT之后， 它也成为adobe之类的公司竞相追求的宠儿，却始终进展缓慢。&lt;/p&gt;
&lt;p&gt;而深度学习， 却可以轻轻点击自动完成这个任务， 铁哥在此给大家拆拆招 ， 看如何玩转神经风格迁移。&lt;/p&gt;
&lt;p&gt;我们说，神经风格迁移就是把一张图片的内容和另一个图片的风格合成的一个方法，比如说你给出一个猫的图片和一个梵高的自画像，就可以生成一只梵高的猫。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.43333333333333335&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYr42IhDQYJ9YHANqFzwPcFkX4vB66wcpZKVNgYD2JCYBHCP5uWD1CNw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; width=&quot;600&quot; /&gt;&lt;p&gt;在深度学习之前，机器视觉的工程师就尝试用各类神奇的滤镜提取图像的纹理信息，抽取取来的纹理图在经过某个变换放回到原图片里，就得到了一个新的风格的图片。　&lt;/p&gt;
&lt;p&gt;深度学习所作的事情，是把这个东西给自动化。我们利用卷积网络的深层结构提取的信息，来替代之前的各种滤镜。　&lt;/p&gt;
&lt;p&gt;首先，卷积网络不仅能够做猫狗识别这一类分类任务，在其中间层里，其实包含了丰富的有用信息，而这些信息，正是我们做风格迁移的基础。如果你可视化CNN的各层级结构，你会发现里面的每一层神经元的激活态都对应了一种特定的信息，越是底层的，就越接近画面的纹理信息，如同物品的材质。 越是上层的，就越接近实际内容（能说出来是个什么东西的那些信息），如同物品的种类。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.8819444444444444&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYtHhWia3sSnXwsXtRXPP3Sgq9ibDZRIF0guMlvE30JnFmJwxjTVxBBibYw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1164&quot; /&gt;研究人员提出的一套可视化CNN的方法，把深层的内容通过反卷积映射回图象，好比你关心什么，就给你投影出来(Visualizing CNN 2014 )。&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.41944444444444445&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYuMdgmuZUu2Z4uSK6gGbIib0Sic19HEibKIVjYXDb6mkHAEVicKlj1RthSg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;2068&quot; /&gt;底层神经元关心画面的材质&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.3472222222222222&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbY1KVNsUIqsIzTRcbzoqaySD0h1Eia9co1BVjGTgrCuSbVYBJqZg3icMAg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;2178&quot; /&gt;深层神经元关心物品的种类
&lt;p&gt;那么好了，风格迁移不就是这么简单吗，把一张图片的底层信息和另一张图片的上层信息合成一起不久可以了吗？ 用适当的数学方法，我们可以在卷积网络的中间层里左手提取图象内容有关的信息，右手提取图象风格有关的信息。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6888888888888889&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYQx9EibUZNRW5l5nEdDzhYfScqPmKRUCDEkvt7BV7T5c91IficozfQTFg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1764&quot; /&gt;用中间层的信息恢复的内容，可以看到不同层里里都可以找到风格和内容有关的信息， 但是层次越深， 具体的信息就越少， 而“实体” 的概念轮廓犹在

&lt;p&gt;看起来是的，我们可以通过一个已经训练好的CNN， 把一张风格图片和内容图片的信息都抽取出来， 然后拼在一起！&lt;/p&gt;
&lt;p&gt;为什么这里要用一个已经训练好的CNN呢？ 一个用分类任务训练好的CNN，通常已经具有了对世界大多数图像提取信息的能力， 因为图像传递信息的底层机制是想通的。 我们把这个网络连接的权衡直接共享过来， 图片一导进来， 网络就可以生成直接可用的特征！ 这正是迁移学习的原理。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.7507836990595611&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYs7AoRBGTAIVlBicbHGFwuNQ4OIr1WY8Kg0HWLR8ROxlp6S0iabDJMnuQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;638&quot; width=&quot;638&quot; /&gt;这里我们导入一个已经训练好的VGG19网络，一种非常流行的CNN图像分类框架
&lt;p&gt;所有深度学习和机器学习，都是预先设定好一个损失函数，然后在进行梯度回传，这里也不例外，我们可以通过设定合理的损失函数，来解决问题。这个损失函数，正是一种能够测量生成图片与风格图片，内容图片距离的函数。　&lt;/p&gt;
&lt;p&gt;来，兄弟们，看我们如何设定这样一个函数。既然我们的深度卷积网络可以做到测量与内容有关的特征，　那么我们只需要在这个层次上找一下特征向量的距离就好了。　&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6597222222222222&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbY4yZ09u9kBCIGxP4T5lWcaqkWVsRAjO4btfsIw7cwGA0tBCMY7XEiazQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1514&quot; /&gt;图像无非是高维空间的一个点，通过神经网络变换再经过特定降维方法处理后我们可以给它转化成二维曲面上的一个点， 我们会发现，在这个世界里， 狗在狗的国度 ， 猫在猫的国度。 而我们只需要度量不同图像的空间距离，就测量了内容的相似度。&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.26136363636363635&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbY2paPnepwZeWvZm9Yoz78JxwR5YsrbLFCEzgbNUNcS8bszXbic95NJyA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;528&quot; width=&quot;528&quot; /&gt;哇， 这不就是定义距离的公式吗！
&lt;p&gt;然后呢，如何搞定风格，风格通常是一个艺术家眼中主关的有点虚无缥缈的概念，也就是我们通常说的感觉， 比如梵高或者莫奈的画，你没有经过艺术熏陶也可以得来。&lt;/p&gt;
&lt;p&gt;而在深度学习的角度下， 这种感觉却发现与不同神经元活动的相关性有关！ 也就是说，风格是深度网络神经元活动的某种统计特性！ 悄悄的，我们把艺术和数学对接上了。 统计果然是上帝的语言啊有木有！&lt;/p&gt;
&lt;p&gt;这里我们借助一个叫gram矩阵的数学工具，它通过测量同一层卷积输出不同通道之间的相关性（计算不同通道间的相关性，组成一个矩阵）给出一个对风格的度量。然后，我们在测量一下风格之间的距离不就行了吗？&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.48333333333333334&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbY5sepmib4hJQbzL66Fnq348wTSibMmU5Z1flGNZR1yEcW18WoYEPBqpFA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1570&quot; /&gt;把CNN某一层对应不同特征的神经元像摊煎饼一样摊开， 然后计算之间的相关性&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.325&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYTyKWmy40p9TRlDgJGicrScDAtmWE3GficSxQw01aG6iaFC4x9033wE2kw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1790&quot; /&gt;得到一个矩阵，矩阵的每个元素对应不同特征间的相关性

&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.3803680981595092&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbY6ItuRzYmgHJZWPJR1kCFraIpFEnBEOXgQVSxCQ4QKkicF083zdkia6ug/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;326&quot; width=&quot;326&quot; /&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.49295774647887325&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYKrhVYKh7reuEI53qNHlrPxqHqV8bea2RxrX9Wj0msxcjXhpWoNzQZg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;568&quot; width=&quot;568&quot; /&gt;这个损失函数就是gram 矩阵之间的距离！
&lt;p&gt;注意，衡量风格之间的距离， 我们是把不同网络层级间的gram矩阵的距离都计算一下加在一起，这样可以把不同层次度量的东西综合起来 。&lt;/p&gt;
&lt;p&gt;好了，到这一步， 大功告成， 把两个损失函数叠加在一起就好了。&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.18055555555555555&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbY6NHs2k9libLbZmsD6fDURhyg7xwYTnMpz6YiaOdjIr1TkG2ccLCicjt1w/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1072&quot; /&gt;&lt;p&gt;目标函数的设计学问可大了，改变a和b的比例就能造成很多区别，大家注意风格图片的比例越高，图像就越纹理化。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.8736111111111111&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbY6H4zp6eorl2Soq5sL7ibMbGo6WIW2t6ltj6un6rroAHK7cicicpxInybw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1422&quot; /&gt;风格的权重变大的时候， 那图像就变成了意大利瓷砖！


&lt;p&gt;然后我们可以做什么呢？ 梯度下降！但注意，这里我们优化的目标不是网络权重而是图像本身，这样我们就大功告成了！&lt;/p&gt;

&lt;p&gt;当然这里说的只是风格迁移的一种， 这种方法的优点是通俗易懂， 而缺点是速度很慢。 还有一个方法，是借用生成网络，直接给搞出来， 这个方法更快速， 更加适合工业封装。 我来给大家展示一下这个方法的实质。&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.2611111111111111&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYOZfamhMQlq3vu12hkUlXvcb3nqWQFZQmiaVCjicSicd7OLvJaEWX4IISA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1852&quot; /&gt;像不像GAN的结构！
&lt;p&gt;哈哈，这样我们就可以完成一幅艺术作品交给家里领导了，但是不要忘记哦， 这件事给我们的启示绝不止这一个呀。 它给我们启示的是，我们深层神经编码的机制里，深度学习的踪影， 你对风格的认知，其实是和内容的认知一样， 是可以量化的，而不像某些艺术家所言， 完全主观，与数学无关。 不仅可以量化，而且这个信息是可以独立被提取的， 这种信息不是存在于某个神经元之上， 而是分布式的存在于多级神经网络的不同尺度之间， 通过每一层神经元的统计规律表达。&lt;/p&gt;
&lt;p&gt;虽然我们尚不知道这些猜想是否正确， 他们我们人类深奥的视觉处理机制提供了一种聪明的理解方法。&lt;/p&gt;

&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt;  附： 代码, 看看用pytorch做出来是多么简洁：&lt;/p&gt;
&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.20416666666666666&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYkW3KqZibWm1Qnj2bLXnO94rj0clSaTHCbfElOBPu2YaAW30ZlNHJ2zg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1618&quot; /&gt;计算内容损失函数&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.8236111111111111&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYTTcNv6BZMQvH4Z3trGs1sXuNnGVxOUKZWgcN49vn8VraKK5NQL7pTQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1614&quot; /&gt;计算风格损失函数&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.7583333333333333&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYOGnSUIGv8TG89XLcNbmCknZgTZ6gks7LnyvMm9iahTno5U1VTmpW6lw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1616&quot; /&gt;设定模型主体！&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.4152777777777778&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibce26jm4VbZHNZy8LN13ejbYno7cPsax1X1Cbsw1oEiaibQVd8B3jnTpdYSrVBwicgVHb408AaXpKiaU1g/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1620&quot; /&gt;训练过程！
&lt;p&gt;&lt;span&gt;如果你对上面的脑洞感兴趣，欢迎关注巡洋舰的深度学习实战课程， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;许铁关于风格迁移的讲解视频查看，请点击链:http://pan.baidu.com/s/1c6Siaa  密码:2g61。&lt;/p&gt;


</description>
<pubDate>Tue, 28 Nov 2017 19:41:31 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/PfqJe3yAlh</dc:identifier>
</item>
<item>
<title>【今日直播】《深度学习图像风格迁移》</title>
<link>http://www.jintiankansha.me/t/FbJC2j9Dum</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/FbJC2j9Dum</guid>
<description>&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.7786666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/EribroYqw9eBkHbybwibTB3slfmZcro69Y6UTMbFoa7jRoAo2ric1GSIicxNicUXdsiaz9FRTD3MCqJbrsm2XUebd0oQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;750&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;【上课方式】&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;手机端APP：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;万门大学&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/EribroYqw9eBkHbybwibTB3slfmZcro69YdtpZ7Fl4NOPP3ExqjAbicibicibpt86n3FJbGyWDfZ7SX3xB3zl2dqPF6g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;400&quot; width=&quot;129px&quot; /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;电脑网页版：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;www.wanmen.org&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;注册&amp;amp;登录万门账号&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;搜索课程名 &lt;/span&gt;&lt;span&gt;深度学习图像风格迁移&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;课程页面点击&lt;span&gt;我要报名&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;span&gt;报名后，进入&lt;/span&gt;&lt;span&gt;个人中心&lt;span&gt;—&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;我的课程&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;检查是否有此课程，确认是否报名成功&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;【进群交流】&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;私信小万君&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;留言 &lt;span&gt;图像风格迁移&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;邀请您进入课程交流群&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;直播过程中可与老师互动～&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;【直播时间】&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;明日 （11月26日）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;16:20-17:00&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;《人工智能、大数据与复杂系统》概论课程，点击【&lt;span&gt;阅读原文&lt;/span&gt;】免费学习&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Sun, 26 Nov 2017 06:35:15 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/FbJC2j9Dum</dc:identifier>
</item>
</channel>
</rss>