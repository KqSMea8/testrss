<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>贝叶斯大脑</title>
<link>http://www.jintiankansha.me/t/eNQhobGY97</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/eNQhobGY97</guid>
<description>&lt;p&gt;本文来自巡洋舰读者投稿，作者为复旦物理博士，现从事机器学习算法研究。 首发于作者的的个人公众号“Kane的世界线”，欢迎各位关注。这里发布的这篇文章，和原文有些不同，进行了进一步的修改，以便于读者理解。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;
&lt;p&gt;如果要从1到100里面猜一个和16最像的数，你会猜什么？&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;可能你会觉得无从下手，因为相像有无数可能性，可以是15或者17，因为数值相近；可以是96或者4，因为是16的倍数或者都是偶数；还可以是2,4,16,32，因为都是2的幂次。那接着告诉你，除了16之外，还有8,2,64也在同一组，那么你觉得下一个可能的数是什么？我想很多人会由此推断出要找的数是2的幂次；而如果说23,19,20和16是同一组呢，那么可能会推断是想找数值相近的数。&lt;/p&gt;

&lt;p&gt;咋一看，这很显然。但细想，却很玄妙。在很多情况下，只给一个或少数几个例子，而且仅仅是正面例子，我们便可以从中学习、推断和做分类，这是一项神奇的能力，至少目前的机器学习算法还没有人类做得好。我们的大脑是怎么做到这一点的呢，这还要从Bayes，哦，不，Sheldon说起。&lt;/p&gt;
&lt;h3&gt;从Sheldon到Bayes定理&lt;/h3&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.5193621867881549&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/AF0iapL8bN1PZ4qH1iatN3fwuLmtPoMoibt9yWfab9aBepbcvictwiaiayw9C1V40T6WCws2VUQUFMN9LUxxo2NSJJaA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;878&quot; /&gt;&lt;/p&gt;
&lt;p&gt;很多人都喜欢看《生活大爆炸》，欣赏里面Sheldon的绝顶聪明，上面的图片就出自《生活大爆炸》第四季第二集。里面的Sheldon非常担心，害怕自己活不到技术“奇点”的出现，也就无法通过意识上传获得永生。他根据家族成员的寿命和疾病史等，预期自己还有六十年可以活。他是怎么做到的呢？用的就是黑板上的贝叶斯定理，也是今天要讲的主题。&lt;/p&gt;

&lt;p&gt;贝叶斯是18世纪英国的一位统计学家，他的生平事迹这里就不赘述，只需要知道他发现了这一定理的一种特别情况，后人因此用他名字给这一定理命名。这一定理看起来是如此的显然和稀松平常，以致于初次遇见可能会忽视它。而细究之下，又会发现，它的内涵是如此丰富，不仅仅改变了我们对概率论的看法，并且很多情况下，我们的思维和决策本身也是基于其基础之上的，就像前面所讲的例子。&lt;/p&gt;

&lt;p&gt;在概率论中，设两个事件发生的概率分别是P(A)和P(B)，那么他们同时发生的概率P(A,B)可以用两种方式计算，既可以表述为事件A发生的概率P(A)乘以事件A发生时事件B也发生的概率（条件概率）P(B|A)，也可以表述为事件B发生的概率P(B)乘以事件B发生时事件A也发生的概率P(A|B)，公式表达如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.12859884836852206&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/AF0iapL8bN1PZ4qH1iatN3fwuLmtPoMoibtT1S3Qb5F7xNiaPxkcicRQV8x40YhyibnhDO5neMrTOBr0ic3ukQ38uEs5A/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;521&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这就是贝叶斯定理的全部。很简单而且显然，对不对。只不过为了更好的理解其中的含义，我们把上述公式变换到它的标准形式：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.1895551257253385&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/AF0iapL8bN1PZ4qH1iatN3fwuLmtPoMoibt1QbEI04Qiaib1AaAe2t3HVdzgT392YMUa8Ur8Ej5ATFXGHEibLN0ibj65g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;517&quot; /&gt;&lt;/p&gt;
&lt;p&gt;通常情况下，B表示某一论断，例如“太阳每天从东方升起”，P(B)表示最初我们对这一论断的信念，称为先验概率prior。A表示对这一论断我们收集的证据，例如，今天太阳从东方升起。P(A|B)表示假如论断成立，出现这一证据的可能性，称为似然概率likelihood。那么我们便可以根据上述公式对信念进行更新，从先验概率P(B)变到后验概率posterior P(B|A)。&lt;/p&gt;

&lt;p&gt;这里很重要的一点是，和我们平常所使用的概率方式不同，这里，一开始我们并没有假定“太阳每天从东方升起”一定正确，而是万事看证据，根据证据来修正我们对一件事物的看法。这一范式的改变发展出了概率论的贝叶斯学派，和传统的频率学派对概率论的解释形成对立，争论至今。&lt;/p&gt;

&lt;p&gt;由此说开去，我们发现，不管是科学理论的建立还是发明创造，很多时候都是一条漫长曲折的寻找证据，并从证据中逐步抽象，建立起理论的道路。但在理论建立完备后，常常讲解的方式却是另外一种，高屋建瓴式的、抽象的、预设的前提假设出发，一步步小心求证，最后得到结论，这一方式发挥到极致的学科便是数学。后一种方法我们称之为演绎推理deduction，而前一种更多的是归纳推理induction。对归纳推理炉火纯青的应用，正是人类学习的一个很大优势。&lt;/p&gt;

&lt;h3&gt;&lt;strong&gt;认知的贝叶斯模型&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;回到开头提到的猜数字的游戏，有了贝叶斯定理的武装，我们便能更好的理解在这一任务中，大脑究竟发生了什么。这一例子出自Tenenbaum的博士论文，并被Murphy在《机器学习》[1]一书中采用，为了便于解释，我们截取Murphy书中的两张图：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.0553191489361702&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/AF0iapL8bN1PZ4qH1iatN3fwuLmtPoMoibt8EmbWYAiaOjvicaPWE86IHXA5QoBwGhAnrH1G5gMbHfwjXt2tkvf9ibvA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;705&quot; /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;上图给出了知道数字16之后，我们所做的各种模型假设，以及相应的先验概率、似然概率和后验概率分布。纵坐标为各个模型假设，横坐标标记为&quot;prior&quot;的左侧图是每个模型对应的先验概率P(h_i)，它表示我们对每种假设的信念大小，例如把数字分成奇数偶数比较常见，于是我们把相应模型的先验概率设得比较大，而对于“都是2的幂次但排除32”这样的规则，我们会觉得很不“自然”，相应的会给予很小的概率。对模型的偏好来自于我们的先验知识，在两个一样解释力的模型中，我们会偏好更简单的模型，这就是经典的Occam剃刀原则。&lt;/p&gt;

&lt;p&gt;同样的，我们还需要知道对每种既定假设，出现数字16的概率大小P(O|h_i)，这表示在上图横坐标为&quot;lik&quot;的中部。具体计算逻辑为，设假设h_i允许出现的结果有|h_i|种，那么每种结果出现的可能性便是：&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.45982142857142855&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/AF0iapL8bN1PZ4qH1iatN3fwuLmtPoMoibtXXxOHOWwDK8lFzxUF1n3MicIpGVQrHbIVnDO3IRibm9PpXRoaicS0sCKg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;224&quot; /&gt;&lt;/p&gt;
&lt;p&gt;所以我们可以看到，因为满足“都是4的幂次”假设的结果只有4,16,64三种，所以16对应的似然概率为1/3。&lt;/p&gt;

&lt;p&gt;根据贝叶斯定理，最终对每种假设的信念便是两者的乘积，既要考虑到先验假设，也要考虑到似然概率，相乘的结果显示在图中横坐标为“post&quot;的右侧。对于”都是偶数“这样的假设，尽管先验概率比较大，但因为1到100间的偶数太多，出现16的概率仅1/50，如果恰恰出现了，我们会觉得是“惊人的巧合”，而不太会相信它是真的。这对应着贝叶斯版的Occam剃刀，在机器学习中，它化身为正则化项以防止模型过拟合。&lt;/p&gt;

&lt;p&gt;这样，我们就有了知道数字16后各模型的后验概率P(h_i|O),从中我们就可以选择概率最大的一个作为最大似然估计，图中，我们可以看到选出的模型是“都是4的幂次”。如果有更多的证据，模型便会快速收敛至真实情况。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/AF0iapL8bN1PZ4qH1iatN3fwuLmtPoMoibtCwIgn2nqcGXOWqnztmbDG66CdW2oKlSACzCN2K8HNRX1Lvf4zv7FAg/640?wx_fmt=png&quot; data-type=&quot;png&quot; class=&quot;&quot; data-ratio=&quot;0.6851851851851852&quot; data-w=&quot;1080&quot; /&gt;&lt;/p&gt;
&lt;p&gt;那么我们又是如何猜测下一个数字x的呢？我们已经有了每个模型的后验概率，下一个数字是x的概率就可以表示为每个模型的后验概率和相应模型出现x的概率的乘积的求和，俗称贝叶斯模型平均。表示为：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.24937027707808565&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/AF0iapL8bN1PZ4qH1iatN3fwuLmtPoMoibtnEyASleib8xAkkasB0Tdz8HHS5X7ic33MXcbKibzR9arQ7gYS9TJaXPbg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;397&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这一计算过程漂亮的反映在上图中。中间那一大块图纵轴表示各种可能假设，而每条横线表示1到100的数值区间，那么每条线上的点便表示各模型假设允许出现的数值。可以看到假设“all&quot;的横线布满了点，因为从1到100，它每个数都可以取到。我们再看图的右边那条曲线，它表示的便是给定数值16后各模型的后验概率分布，可以看到，假设”都是4的幂次“的后验概率最大。将两者结合并叠加起来，就会得到图中上部所示的x的概率分布。可以看到，数字16,64,4的概率最大，与我们料想的非常一致。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们再看大脑推断中用到贝叶斯的两个例子。第一个例子同样来自Tenenbaum[2]的论文，说的不仅仅是我们如何学习单个概念，还说明了我们是如何将概念对应到事物的不同范畴的。所谓范畴，就是对事物的分类，并且这种分类通常是有不同层次的。例如你的写字桌，它既属于写字桌这一类，也属于桌子这一类，还属于家具这一类，在范畴论中，它分别可以对应着下位范畴、基本范畴和上位范畴。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7096330275229358&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceJvQ7HtlOv1xOicdicJDrQS21t67oyBNBXMgXdicclSx7lSoGNsn36YWGLaJ29nl8QQmwxJX1FItJMw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;2180&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在Tenenbaum论文的例子中，当指着一张标记为fep的斑点狗图片，来猜测fep的含义时，我们既可以认为fep表示上位范畴的动物，表示基本范畴的狗，也可以是表示下位范畴的斑点狗。而我们会倾向于推断fep的意思是狗。这是由基本范畴偏差（prior)造成的，因为我们日常处理事物大多都在基本范畴，这也是为什么基本范畴的中英文单词大多非常简单且长度很短。但当给了三张斑点狗的图片，而且每张都标记为fep的时候，我们却更可能推断fep意思是斑点狗而不是所有的狗。因为直观上来讲，如果fep表示的是所有的狗，但随机抽取的三个样本都是斑点狗，那将是“惊人的巧合”。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第二个例子来自刘未鹏的《暗时间》，里面提到了一个自然语言的二义性例子。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;the girl saw the boy with a telescope.&lt;/p&gt;

&lt;/blockquote&gt;
&lt;p&gt;对于上面这句话，我们既可以理解为那个女孩拿着望远镜看那个男孩，也可以理解为那个女孩看到那个拿着望远镜的男孩。那么为什么通常情况下，我们会想当然的理解为第一个意思而消除歧义？从语法结构上讲，两种结构都是成立的，在这里体现为先验概率P(h)大致一样，但是P(O|h)却很不一样。如果是第二种情况，那么为何偏偏那个男孩拿的是一个望远镜，而不是一本书或一只苹果呢？有很多不同的可能性，恰巧是望远镜的可能性是非常小的。但是如果用第一种语义理解就不一样了，女孩通过某种东西看男孩，那么，拿的是望远镜就很显然。&lt;/p&gt;

&lt;p&gt;在很多情况下，贝叶斯原理很好用，我们大脑也用它做很多事。但另一方面，它也是认知偏差的孵化池。&lt;/p&gt;

&lt;h3&gt;&lt;strong&gt;认知偏差&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;在《机器人叛乱》一书中，斯坦诺维奇讲到了认知心理学文献中的琳达问题：&lt;/p&gt;
&lt;blockquote readability=&quot;23&quot;&gt;
&lt;p&gt;琳达今年31岁，单身、率真、非常聪明。她的专业是哲学。作为一个学生，她格外关心歧视和社会公正问题，也曾参加过反核示威游行。请根据可能性对下面的陈述进行评价，1代表可能性最高，8代表可能性最低。&lt;/p&gt;
&lt;p&gt;a. 琳达是一名小学老师。&lt;/p&gt;
&lt;p&gt;b. 琳达在书店工作，上瑜伽课。&lt;/p&gt;
&lt;p&gt;c. 琳达积极参加女权运动。&lt;/p&gt;
&lt;p&gt;d. 琳达是一名精神病学的社工。&lt;/p&gt;
&lt;p&gt;e. 琳达是妇女选民联盟的一员。&lt;/p&gt;
&lt;p&gt;f. 琳达是一名银行出纳。&lt;/p&gt;
&lt;p&gt;g. 琳达是一名保险销售员。&lt;/p&gt;
&lt;p&gt;h. 琳达是一名银行出纳，积极参加女权运动。&lt;/p&gt;

&lt;/blockquote&gt;
&lt;p&gt;因为选项h是选项c和f的组合，所以从概率来看，肯定比两者来得小，但是研究表明，有85%的参与者出现了“组合偏差”，他们认为选项h比f的可能性更高。&lt;/p&gt;
&lt;p&gt;这可以看成是混淆了似然概率与后验概率的区别。本来需要计算后验概率P(h|O)，却计算了似然函数P(O|h)，或者说本来需要用induction的地方却错误的使用了deduction。&lt;/p&gt;

&lt;p&gt;因为按照似然函数的思路，相比于“琳达是一名银行出纳”的论断，“琳达是一名银行出纳，并且积极参加女权运动”的论断，更可能得到琳达关心歧视和社会公正问题等具体描述。而没有注意到，对于后验概率，还需要关注先验概率prior，而f选项的prior明显比h大得多。&lt;/p&gt;

&lt;p&gt;类似的认知谬误比比皆是，我们可以再看赌徒谬误的例子，里面混淆了前提假设和后验概率。&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.1671875&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz/dcEP2tDMibcfyNibceeGvVKo0qCGicGJ9lQ9J5zzOIxmTUAE4OYfwx25QZ2J2KLUic1lWYkMwelC8Ld30RF0FsibAPQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;640&quot; /&gt;&lt;/p&gt;

&lt;p&gt;赌徒谬误[3]说的是：&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;抛一枚公平的硬币，连续出现越多次正面朝上，下次抛出正面的机率就越小，抛出反面的机率就越大。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;把这个谬误和热手谬误[4]及选择性记忆相结合，就不难理解为何赌徒永远赢不了。理性的分析容易看到，每次抛硬币都是相互独立事件，前面的结果不会对之后的结果产生影响。而我们又有了前提假设：硬币是无偏的。所以不管哪次抛掷硬币，出现正反的可能性都是1/2。&lt;/p&gt;

&lt;p&gt;更精确的，我们可以用数学语言描述。假设硬币出现正面朝上的概率为h,已抛掷4次，每次都是正面朝上，这一事实表述为O. 硬币无偏，满足P(h=0.5)=1,则下一次出现正面朝上的概率为P(u,O|h=0.5)=0.5，出现反面朝上的概率也是P(d,O|h=0.5)=0.5.&lt;/p&gt;

&lt;p&gt;但是，赌徒错误的使用了硬币无偏的结论，没有把它看成是前提假设，而看成是证据之后的推断，也就是后验概率。因为之前四次的正面朝上已经让硬币正面朝上的概率偏向于E(h)&amp;gt;0.5,为了维持硬币无偏的信念，那么我们期望的是下次的抛掷能使E(h)偏回来一点。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceJvQ7HtlOv1xOicdicJDrQS2dyvxXNJQYPfxibfzduOHc8sU1QIVYTC5Ahdqj7fZUEz8CFNlIDWAh1A/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;800&quot; /&gt;&lt;/p&gt;
&lt;p&gt;具体的，我们假设h的先验分布是均匀的（当然这里只是为了方便，用其他的分布不影响结论），那么抛掷四次正面朝上，使我们对h的概率预期变为：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.18579234972677597&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/AF0iapL8bN1PZ4qH1iatN3fwuLmtPoMoibtOHynyPeJPsCjFh8aWbGsYjIGpeGNicMU0kWibCbvKXVhySoE2zk4zASg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;366&quot; /&gt;&lt;/p&gt;
&lt;p&gt;可以得到期望E(h|O)=5/6。和设想的一样，经过四次正面朝上后，我们的证据偏向于硬币是h&amp;gt;0.5的。然后我们计算，下一次抛掷结果分别为正面朝上u和反面朝上d，h后验概率的期望。具体的：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.18857901726427623&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/AF0iapL8bN1PZ4qH1iatN3fwuLmtPoMoibtYf55SllvS3WatZPdHnhLzvhr131ib1h4iaTAAWy80O57biabwicLwPdggQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;753&quot; /&gt;&lt;/p&gt;
&lt;p&gt;由此，计算可得E(h|u,O)=6/7,而E(h|d,O)=5/7.可以看到，确实下一次抛掷如果反面朝上便可以增强我们对硬币无偏的信念。不仅如此，我们还可以发现E(h|O)介于两者之间。&lt;/p&gt;

&lt;h3&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;我歌月徘徊，我舞影零乱。我们的贝叶斯大脑根据已有知识对外界进行响应。这一方面让我们可以在稀疏的、少量的、只有正例的情境下快速学习、构建各种概念。但同时，也得警惕这种启发式的学习可能导致的各种认知谬误。&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651381623&amp;amp;idx=1&amp;amp;sn=079563ccdd30186de04e4826b5b37d18&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;玩转贝叶斯分析&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382073&amp;amp;idx=1&amp;amp;sn=50ba7a0867dbce73e967215ca9ef2d1d&amp;amp;chksm=84f3cf78b384466e971c57f3bf1db19a55280afe68a68c80b217f2501438a3b1c4029de7f73d&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;贝叶斯分析解码谁是卧底的游戏&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;参考文献：&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[1]: Murphy, K. P. (2012). Machine Learning: A Probabilistic Perspective (1 edition). Cambridge, MA: The MIT Press.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[2]: Xu, F., &amp;amp; Tenenbaum, J. B. (2007). Word learning as Bayesian inference. Psychological Review, 114(2), 245.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[3]: [维基百科：赌徒谬误](https://zh.wikipedia.org/wiki/%E8%B3%AD%E5%BE%92%E8%AC%AC%E8%AA%A4)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[4]: 热手谬误认为某事多次发生则未来发生的机率会较大，见维基百科。&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Tue, 06 Feb 2018 21:34:07 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/eNQhobGY97</dc:identifier>
</item>
<item>
<title>胶囊网络结构Capsule初探</title>
<link>http://www.jintiankansha.me/t/DFL1G8ddhQ</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/DFL1G8ddhQ</guid>
<description>&lt;p&gt;作为神经网络的大牛Geoffrey Hinton在17年十月提出了一种新的网络结构，他称之为Capsule，这个词的中文意思是胶囊。在本周，Capsule的代码在github上开源，瞬间成为爆款。 Capsule式的网络结构，和卷积神经网络一样，最初是用来处理视觉问题的，但是也可以应用到其他领域。这篇小文不涉及Capsule神经网络的数学细节，而是关注Capsule网络是如何克服CNN存在的问题的。阅读之前，对于卷积神经网络不熟悉的可以先看看&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383212&amp;amp;idx=1&amp;amp;sn=e6dbbda2acc5984c8d06e24ec9c84d09&amp;amp;chksm=84f3cbedb38442fb58f0aea635821fcf4ba3edaacef4685716c7eadb6191197ebfa70a6bf14b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;你所不能不知道的CNN&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.3333333333333333&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2cVakZ7GRGnXvdSYNcLe0nYcfIwkZJKEXuCPIuGv0RTYWDFf6vWuwDIw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;225&quot; /&gt;&lt;/p&gt;
&lt;p&gt;谷歌公司的Geoffrey Hinton大神&lt;/p&gt;

&lt;p&gt;用Hinton大神的话来说，计算机图形学做的是渲染，而计算视觉想做的就是渲染的逆过程。渲染是将三维的图像投影到二维，在数学上意味着给原图乘以一个固定的矩阵。而计算机视觉做的，则是Inverse Graphics，也就是从二维的图像推测出本身的三维结构。为了比较胶囊网络和CNN之间的区别，让我们先看看CNN想做什么，有什么不足。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1) CNN那里做的不够好&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;有一些事情，对小孩子来说很容易，但若是卷积神经网络，则很难，例如认清楚下面两章图上的猫是同一只。然而若是神经网络无法做到这一点，机器视觉的模型，不管处理怎样的任务，都注定会不够稳键（robust）。解决图像迁移后的一致识别，是Capsule神经网络出现的第一个目的。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.46530612244897956&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcesX0Jso3CcjQl3jZyyVQ2RmWaSadwAKZ6rUhjnbDFCIiazxkyzoVLbzHEm7oqyC8EPrubRkp45Izg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;735&quot; /&gt;&lt;/p&gt;

&lt;p&gt;不止是左右的平移，CNN对于旋转，加上边框也会难以觉察出其一致性，CNN会认为下图的三个R是两个不同的字母，而这是由网络结构所带来的，这也造成了CNN所需的训练集要很大，而数据增强技术虽然有用，但提升有限。&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.47793190416141235&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcesX0Jso3CcjQl3jZyyVQ2Ry60uqy6EUl4QsIbf9W9Xhttb9YibT6kGD1MJYbe6pCt96WlHoUotiaDA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;793&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9135338345864662&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcesX0Jso3CcjQl3jZyyVQ2RT5uCI0gYIibENKuQQUIKQgdd8yNvCQs1QibibJoCReIAygTQQicIHBQdhQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;532&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一张脸上不应该只是由两只眼睛一张嘴巴一对鼻子构成的，组成整体的部分之间的相互关系对于识别图形，也很重要。下面的这张图会被CNN看成是一张脸，这是因为CNN识别脸的时候，是识别脸的几个组成部分，下图中的确有两个眼睛，有鼻子，有嘴，虽然其位置不对，这对于CNN来说就够了，CNN是不会注意子结构之间关系的。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.8577777777777778&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2cH8rtUb5xpYGmmic09jCMQbGaLPFcZ1ppZ073Z2GgT7d447vj1icVNI1Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;225&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-backh=&quot;160&quot; data-backw=&quot;558&quot; data-croporisrc=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2cK4vlUic0z2MJ5ZWc2vBDwia5ficTKbX1gzpQPuVa21NTKelhgPsQ2zWqw/0?wx_fmt=png&quot; data-cropx1=&quot;0&quot; data-cropx2=&quot;590&quot; data-cropy1=&quot;5.286738351254481&quot; data-cropy2=&quot;174.46236559139786&quot; data-ratio=&quot;0.2864406779661017&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2c6A6Z5P1Urzr7uVamKwqeL2tq0icpB48zgN2cFRicdSkkMf1IomvKUIXQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;590&quot; /&gt;&lt;/p&gt;



&lt;p&gt;同样的道理，CNN的网络难以区分左图和右图，他们是由相同的形状（椭圆形）组成的，其信息都储存在子结构之间的关系中。卷积核之间的独立即使的训练简单，又丢失了全局的关联信息。&lt;/p&gt;
&lt;p&gt;              &lt;img class=&quot;&quot; data-ratio=&quot;0.9884393063583815&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2cBO7cFcRicet6sru6oTRkPlwYHfpXkn54YQeYBHkoCs3Q1eWngnVFONg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;173&quot; /&gt;      &lt;img class=&quot;&quot; data-ratio=&quot;0.7896995708154506&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2copuVfdwH3NlenyoYOQfSEj5seGibQAEtKn8XGwLrs2JDgSCQWMVwMfg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;233&quot; /&gt;&lt;/p&gt;
&lt;p&gt;人类在识别图像的时候，是遵照树形的方式，由上而下展开式的，而CNN则是通过一层层的过滤，将信息一步步由下而上的进行抽象。这是Hinton认为的人与CNN神经网络的最大区别。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.46210526315789474&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcesX0Jso3CcjQl3jZyyVQ2RMTVDGSnxcduFItCqrU0PDvAXgnQxUFGKKMRqibogsglohWA7BfZsACQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;950&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总结下这一小节，卷积神经网络的问题是其神经员之间都是平等的，没有内部的组织结构，这导致无法保证在不同位置，不同角度下对同一个物品做出相同的识别，也无法提取不同卷积核得出的子结构之间的相互关系。CNN中采用的分块和共享权重，其目标都是希望能够使神经网络学到的特征提取之术能够在图形出现微小变化时能够应对，而不是针对图形的变化，对应神经网络进行相应的改变，而这正是capsule神经网络所要做的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2）脆弱与反脆弱&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;用英文来说，为了提升模型的可扩展性，CNN追求的是Invariance，而胶囊网络追求的是Equivariance。熟悉塔勒布的童鞋会想起他的命运，脆弱的反义词不是稳健，而是反脆弱。这正是胶囊神经网络强大的地方，追求的是在不同视角下对同一个物品的相同感知（标签），而通过对各个视角下都有标记的数据死记硬背做到对相似物品图像的识别。&lt;/p&gt;

&lt;p&gt;回到上文提到的字母R的例子，下图的两个字母左边的那个不是R，但人类大脑在做出这一判断的时候，不需要一个老师指出这一事实，人会在自己的大脑中对左边的图像进行翻转，使得半圆处于图形的上方，之后再识别出图形，如果能够让神经网络也能做类似的事，那就不需要太多的标注数据了。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.4941329856584094&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2c4lkW5qicZ1fCV0gjDYynFJ8Ypicwdq7CMwsaWkdP07YRCyWSIzeecbqg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;767&quot; /&gt;&lt;/p&gt;

&lt;p&gt;正是由于胶囊网络可以对图形进行翻转，这使得其不需要那么多的标注数据，下图对比了CNN和胶囊神经网络在识别人脸上的区别。CNN中需要有一层去应对不同翻转角度的脸，而胶囊网络则可以用一个胶囊去完成这个任务&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.2700106723585913&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2c6HGafvh4Pibuvfw7rXUSINcIpDfPPQhhE63ANnZDBiaRNtUHBAkp6TnQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;937&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.24180327868852458&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2cNXWPvUhQuyib17UMM473hUL4DWScDcommbp5ibGwM1gTv7cIuicPXKw8Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;732&quot; /&gt;&lt;/p&gt;

&lt;p&gt;具体看看胶囊神经网络想做什么，假设我们训练一个识别数字2的网络，我们首先做的是在每一层训练一些胶囊（即一组相对独立的神经元），每一个胶囊只负责图形中的一个子结构，例如图中的三个胶囊，分别识别横线，竖线和锐角，每个胶囊给出图形中每个位置出现自己负责识别的特征的概率（intensity），之后再通过一个编码器，综合每一个胶囊给出的在各个位置的强度信息，最终得到经过重构后的图像。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7443820224719101&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2c1hJamiaArMdZFxib7rERlIyUL7AQlVK5x4ya5q9QLeT1ve59SlUaAaGg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;712&quot; /&gt;&lt;/p&gt;

&lt;p&gt;例如我们关注的是识别数字7，那么下图中的第一行是传统的神经元，会给出对应图形是不是7的概率，但这个神经网络却无法识别第三行的数字。一个包含两个神经元的胶囊可以一个识别图形的翻转情况，一个识别具体的形状。不管图形是第二行那样竖直站立的，还是像第三行那样歪倒的，胶囊网络都可以正确的识别。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.614853195164076&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2cr3icgBmyqib6qnVkaAkA18K5aLy9uDVTFjEsYslHR2RicBS0sGTUHM6SA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;579&quot; /&gt;&lt;/p&gt;

&lt;p&gt;由于每个胶囊给出的是输出是一组向量，不是如同传统的人工神经元是一个单独的数值（权重），为了解决这组向量向那一个更高层的神经元传输的问题，就需要Dynamic Routing的机制，而这是胶囊神经网络的一大创新点，也是理解中的难点。Dynamic routing使得胶囊神经网络可以识别图形中的多个图形，这一点也是CNN所不能的。由于讲解Dynamic routing需要很多数学细节，这里就不再细说。可以理解成一种实时的投票，决定不同胶囊网络之间提取的特征哪一个更显著，更有益于上一层网络的重构。&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;3）冗余对抗复杂&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下面的图展示了胶囊神经网络在MINST数据集下的表现，这里可以看出胶囊神经网络的另一个好处，即可解释性强，你可以看出每个胶囊想做什么。不过即使你知道了每个胶囊识别的是那些子结构，你也很难想象出是怎样通过这些结构的组合识别出数字的。我猜那是你理解的数字识别的规则，根本不需要这么多的子结构，但这只不过是你对当前情况的解释，真实的大脑，如同胶囊神经网络，所做的都是利用冗余来对抗复杂，让模型模仿人类大脑用冗余带动生产的能力， 来对抗复杂的问题。引申来说，说深度学习缺少解释性，部分的原因是我们对解释性的理解太浅了，人们天生不习惯复杂的解释，但要应对复杂，就必须有冗余。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.8304552590266876&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2cBMt0lUd0SQm3981NhGLMhcCIz0uyzrxN5rRoNDGrmQMEyOPECqn50Q/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;637&quot; /&gt;&lt;/p&gt;
&lt;p&gt;此图来自Hinton关于Capsule的论文，图中的第一列是网络的输入数据，第二列是网络根据原图重构的图形，网络的目标是让这两幅图的差距尽可能小，第三列给出了这两幅图之间的差别，之后的列是网络中每一个胶囊所识别的子结构，可以看到，这些子结构之间很多是相似的，也就是网络有冗余。&lt;/p&gt;

&lt;p&gt;冗余带来的好处，从下图可以看出，这里展示了如果对于每一个胶囊给出的intensity值加上或减去两个标准差后，网络重构出来的图像会是怎样，可以看出，图形基本还是能识别成原始的2的，这说明网络具有鲁棒性，不会像CNN一样，仅仅因为一两个像素点的改变，就将图形识别错误。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.43537414965986393&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2cOG9eKJc2bkNLsT9BtbcXoR1lFDxWibvbLxylsIGibroDCta517sDzhOg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;441&quot; /&gt;&lt;/p&gt;
&lt;p&gt;类似CNN的深层网络，胶囊网络也可以有层次结构，如下图所示，红色的是底层的胶囊结构，绿色的是高层的胶囊结构，绿色的胶囊无法知道图形中具体的形状是什么在哪里，这使得绿色的胶囊结构通过训练所学到的只是图形中子结构之间的相互关系，这就实现了CNN所不能的，也就是将图像在其头脑中进行翻转伸张平移等视角变换，但同时保持其特征的一致性。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7510373443983402&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2cPib3JFuWBAcgOxp32O9NibqSDfHjGub4n0bnY72ApEv1uAoAcJwzyibKA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;723&quot; /&gt;&lt;/p&gt;
&lt;p&gt;下面展示了胶囊神经网络在3D图像中的表现，这里的目标是看看胶囊神经网络能否正确的的从下图中左边的一列，将图形做选择，得出右图的图形。我们看到，胶囊网络翻转生成的图像效果不错。这说明神经网络学到了每个图形中子结构之间应该怎样连接。而在第二幅图中，展示了说学到的连接也可以应用在没有出现在训练集的测试数据上，哪怕训练数据是汽车，测试数据是飞机，这展示了胶囊网络优良的可扩展性。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.798219584569733&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2cibRjSbibSUhwcMMuvjakTqhFV3tiaA63bOAA90r58rHhkdAftHJibvO7Jw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;674&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7635829662261381&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2cKrqPJSs3ommkvXAsm9zicYLOexffTkwap3sUKibAk3ZgwnricsWsnBOUA/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;681&quot; /&gt;&lt;/p&gt;

&lt;p&gt;任何结构的神经网络需要提高其模型的可扩展性，都需要做正则化。CNN的标准做法是随机的扔掉一些神经元，即dropout，而胶囊神经网络则是通过重构的方式，在识别某一个图形的标签时，将网络中与这个图形无关的部分都关闭，而使剩下的网络试图尽可能准确的重构这个图形，从而提高模型的泛化能力，这里借鉴了自编码器的思路，结合胶囊网络子结构之间的独立性，这使得模型的泛化能力很强。而这也可以看成是通过冗余来应对复杂，明明识别6和9的网络可以很类似，但因为有了分工，弄混的概率也少了。&lt;/p&gt;

&lt;p&gt;4）小结&lt;/p&gt;
&lt;p&gt;胶囊网络可以算是一种革命性的网络架构，神经元的输出从一个标量变成了一组向量，这如同让网络流动起来了。每一个识别子结构的胶囊，使原始图形中隐藏的信息在bits数变小的情况下实现了高度的保真，而这个保真，又是从复杂结构里直接进化得到的。通过重构原图，模型做到了在视角变换后，通过网络结构的改变，给出相同的认知（重构），这使的胶囊网络具有了反脆弱的性质。另外需要指出的是，CNN和胶囊神经网络并不是互斥的，网络的底层也可以是卷积式的，毕竟胶囊网络善于的是在已抽象信息中用更少的比特做到高保真的重述。&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;&quot; data-ratio=&quot;0.7255216693418941&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdRef6B9WjltyUVqWvhQX2cAJ3EysYYBwhTaGqIO9n7q4VOg3KwH847JNbaXd9AOjz5PfUOuP69Jg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;623&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这里给出了用来识别MInst数字集的CapsNet网络结构图，底层是卷积层，而用来最终做预测的也是熟悉的Sigmoid全连接层，改变是只是中间那些层，由卷积网络变成了胶囊网络。&lt;/p&gt;

&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383309&amp;amp;idx=1&amp;amp;sn=f0ee86dc43994673f2b818cb2c2efe4b&amp;amp;chksm=84f3c84cb384415a67b8469578df8268a490f12355d4213c126d767227a0da52a77297b47be4&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;白话迁移学习&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383280&amp;amp;idx=1&amp;amp;sn=a6fd903f2c47339c52dcea9eedf65851&amp;amp;chksm=84f3cbb1b38442a7f4aac491852e06c34794154946a3656bc4ac4805b1ef1b41cb4469ae8419&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;对抗神经网络初探&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;参考资料&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;http://www.cs.toronto.edu/~fritz/absps/transauto6.pdf&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;http://cseweb.ucsd.edu/~gary/cs200/s12/Hinton.pdf&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;https://www.arxiv-vanity.com/papers/1712.03480/&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;https://jhui.github.io/2017/11/03/Dynamic-Routing-Between-Capsules/&lt;/span&gt;&lt;/p&gt;


</description>
<pubDate>Sat, 03 Feb 2018 06:25:33 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/DFL1G8ddhQ</dc:identifier>
</item>
<item>
<title>白话迁移学习</title>
<link>http://www.jintiankansha.me/t/KQI4gcI1tj</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/KQI4gcI1tj</guid>
<description>&lt;p&gt;深度神经网络，相比于之前的传统机器学习方法，可以看成是一个全新的物种，这背后的原因，最明显的还是深度学习对机器算力的巨大需求，在&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383250&amp;amp;idx=1&amp;amp;sn=59c8b29f52dcc4db8ddf286840bca434&amp;amp;chksm=84f3cb93b3844285742e9034aef6f23a1a88dfb17ea85b81cd364032fed123200a7cc80f3b14&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;深度学习入门最少需要知道什么？&lt;/a&gt;中介绍了深度学习所需的显卡资源，而当前大内存的机器不贵，而高性能，大显存的显卡就没那么便宜了。这使得使用深度学习去处理实际生活中遇到的问题，例如图像和语音的识别时，需要消耗大量的资源。而迁移可以改变这一切，显著的降低深度学习所需的硬件资源。&lt;/p&gt;

&lt;p&gt;本文会先介绍迁移学习的定义，接着说说预先训练好的网络是什么，为什么有用？使用预训练的网络又有那两种方法？之后会通过MINST数字识别的例子，来展示该如何应用迁移学习。&lt;/p&gt;

&lt;p&gt;让我们通过一个直观的例子来说明什么是迁移学习。假设你穿越到了古代，成为了太子，为了治理好国家，你需要知道的实在太多了。若是从头学起，肯定是来不及的。你要做的是找你的皇帝老爸，问问他正在做了什么，而他也希望能将他脑子的知识一股脑的转移到你脑中。这正是迁移学习。即将一个领域的已经成熟的知识应用到其他的场景中。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK1MBlkszgaZsnbgj2kgIzTh1pUyZSPO5Tvedk6pcVNrWTpcGOSukfIeA/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.749034749034749&quot; data-w=&quot;259&quot; data-type=&quot;jpeg&quot; data-backw=&quot;259&quot; data-backh=&quot;194&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;p&quot;&gt;用神经网络的词语来表述，就是一层层网络中每个节点的权重从一个训练好的网络迁移到一个全新的网络里，而不是从头开始，为每特定的个任务训练一个神经网络。这样做的好处，可以从下面的例子中体现，假设你已经有了一个可以高精确度分辨猫和狗的深度神经网络，你之后想训练一个能够分别不同品种的狗的图片模型，你需要做的不是从头训练那些用来分辨直线，锐角的神经网络的前几层，而是利用训练好的网络，提取初级特征，之后只训练最后几层神经元，让其可以分辨狗的品种。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK1iaJF6OAYQCmftEmC2lx1GuteKib50Iw5Pr1Ol3pRYL3dEXB51BcaXaRw/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.6013888888888889&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;p&quot;&gt;从上述的例子引申出来，迁移学习的理念，其实有广泛的应用。人类的语言使得代际之间的迁移学习变得可能，在语言出现之前，每一代能够教给下一代的东西极其有限，而有了语言，人类的知识得以爆炸性的增长。而随着现代科学的进步，每门学科都产生了很多术语，这些术语相当于抽象层次更高的表述，所需的学习时间也会变长，这使得童年这个文化概念得以产生。迁移学习的道理应用到现实生活中，还意味着教育和娱乐的区别。教育要有阐释，有背景，有对情境复杂性的分析，追求的是宽度，而当前娱乐式的知识传授，则只追求深度，从一个有趣的案例，一路衍生出看似深刻的道理，或者停留在事实本身，将知识变成一个个孤岛而不是网络。&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK1pvRr1fkPx7A1jmghaDHHRjb4M1G65k3LEJPmqO9zSfR4mQ67szLG8w/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.44344262295081965&quot; data-w=&quot;1220&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK1nHIxqzgLHx3oiaknGVvjpr7AqwQ8xEKW7YZ2ibUt3H3bT1bsXiaAe2J7g/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;1.1176024279210925&quot; data-w=&quot;1318&quot; /&gt;&lt;/p&gt;


&lt;p&gt;回到技术问题。迁移学习相当于让神经网络有了语言，新一代的神经网络可以站在前人的基础上更进一步，而不必重新发明轮子。使用一个由他人预先训练好，应用在其他领域的网络，可以作为我们训练模型的起点。不论是有监督学习，无监督学习还是强化学习，迁移学习的概念都有广泛的应用。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK11EERsE2DL3ZCSrj8SUicAHyEzDlYicE08ZCF5nEVWhhh4RvaxkkicZmDQ/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.7263888888888889&quot; data-w=&quot;720&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;举图像识别中最常见的例子，训练一个神经网络。来识别不同的品种的猫，你若是从头开始训练，你需要百万级的带标注数据，海量的显卡资源。而若是使用迁移学习，你可以使用Google发布的Inception或VGG16这样成熟的物品分类的网络，只训练最后的softmax层，你只需要几千张图片，使用普通的CPU就能完成，而且模型的准确性不差。&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK1GhQvoG75aCXBY66nF31SWgAj99iaJcpIOC7Sbu3OtpdGOiaicP7cx3Dog/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.6866485013623979&quot; data-w=&quot;734&quot; /&gt;&lt;/p&gt;

&lt;p&gt;使用迁徙学习时要注意，本来预训练的神经网络，要和当前的任务差距不大，不然迁徙学习的效果会很差。例如如果你要训练一个神经网络来识别肺部X光片中是否包含肿瘤，那么使用VGG16的网络就不如使用一个已训练好的判断脑部是否包含肿瘤的神经网络。后者与当前的任务有相似的场景，很多底层的神经员可以做相同的事，而用来识别日常生活中照片的网络，则难以从X光片中提取有效的特征。&lt;/p&gt;

&lt;p&gt;另一种迁移学习的方法是对整个网络进行微调，假设你已训练好了识别猫品种的神经网络，你的网络能对50种猫按品种进行分类。接下来你想对网络进行升级，让其能够识别100种猫，这时你不应该只训练网络的最后一层，而应该逐层对网络中每个节点的权重进行微调。显然，只训练最后几层，是迁移学习最简单的1.0版，而对节点权重进行微调（fine turing），就是更难的2.0版，通过将其他层的权重固定，只训练一层这样的逐层训练，可以更好的完成上述任务。&lt;/p&gt;


&lt;p&gt;另一种迁移学习的方式是借用网络的结构，即不是使用已训练好的网络的权重，而是使用相同的网络结构，例如多少层，每层多少节点这样的信息，然后使用随机生成的权重作为训练的起点。例如你要训练世界上第一个识别fMRI图像的神经网络，你就可以借鉴识别X光图片的神经网络。&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK1UMtuDP614TlUwZibNUPKRyP0kmPa2f3PYxZ7SRQSrQLk0lnaOa2DDbQ/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.5534883720930233&quot; data-w=&quot;645&quot; data-type=&quot;png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;和传统的方法相比，迁移学习的另一个好处其可以做多任务目标的学习，传统的模型面对不同类型的任务，需要训练多个不同的模型。而有了迁移学习，可以先去实现简单的任务，将简单任务中的得到的知识应用到更难的问题上，从而解决标注数据缺少，标注不准确等问题。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdhpRT4FMbr2F3M76szlnK1bicRk7k5WlNxflPB4iaMOWdEKYT1EYbszD9OKMMAMzr6XbXYxE9KMKgA/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.9&quot; data-w=&quot;300&quot; data-type=&quot;jpeg&quot; data-backw=&quot;300&quot; data-backh=&quot;270&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这幅图说明了该用哪种迁移学习，让我们逐个来看。&lt;/p&gt;

&lt;p&gt;1）右下角场景，待训练的数据集较小，已训练的模型和当前任务相似。此时可以只是重新训练已有模型的靠近输出的几层，例如将ImageNet中输出层原来可以判别一万种输出的网络改的只能判别猫的品种，从而利用已有网络来做低层次的特征提取。&lt;/p&gt;

&lt;p&gt;2）左下角场景，待训练的数据集较小，已训练的模型和当前任务场景差距较大。例如你有的已训练网络能识别出白天高速路上的违章车辆，你需要训练一个能识别出夜间违章车辆的模型，由于不管白天夜晚，交通规则是没有变化的，所以你需要将网络靠近输入的那几层重新训练，等到新的网络能够提取出夜间车辆的基本信息后，就可以借用已有的，在大数据集下训练好的神经网络来识别违章车辆，而不用等夜间违章的车辆的照片积累的足够多之后再重新训练。&lt;/p&gt;

&lt;p&gt;3）左上角场景，待训练的数据集较大，已有的模型和新模型的数据差异度很高。此时应该做的是从头开始，重新训练。&lt;/p&gt;

&lt;p&gt;4）右上角场景，待训练的数据集较大，已有模型的训练数据和现有的训练数据类似。此时应该使用原网络的结构，并保留每一层的节点权重，再逐层微调。&lt;/p&gt;

&lt;p&gt;接下来看一个实际的例子，大家都熟悉的MINST手写数字识别，也可以用迁移学习来做，已有的训练数据是六万张图片，已有的模型是通用的图像识别模型VGG16，看起来，我们即可以将网络的最高层重新训练，也可以训练网络的最初几层，毕竟手写数字的图片，和我们日常见到的图片即相似也有明显不同。点击阅读原文，可以查看具体的python代码。&lt;/p&gt;

&lt;p&gt;总结一下，迁移学习应用广泛，尤其是在工程界，不管是语音识别中应对不同地区的口音，还是通过电子游戏的模拟画面前期训练自动驾驶汽车，迁移学习已深度学习在工业界之所以成功的最坚实支柱，而学术界对迁移学习的研究则关注以下几点，一是通过半监督学习减少对标注数据的依赖，应对标注数据的不对称性，二是用迁移学习来提高模型的稳定性和可泛化性，不至于因为一个像素的变化而改变分类结果，三是使用迁移学习来做到持续学习，让神经网络得以保留在旧任务中所学到的技能。&lt;/p&gt;

&lt;p&gt;最后引申来看，集成学习，例如AdaBoost其背后的机制，也可以看成是另一种形式的迁移学习，通过多次使用训练样本，并给不同的样本赋予不同的权重，集成学习也可以做到站在巨人的肩上。而Dropout机制，也是让网络训练中随机的丢失节点，从而使得网络不得不依据之前的模型进行迁移学习，从而提高泛化能力。迁移学习本质上利用的是不同任务间的相关性，用冗余对抗复杂。&lt;/p&gt;

&lt;p&gt;参考资料&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;http://sebastianruder.com/transfer-learning/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;https://www.analyticsvidhya.com/blog/2017/06/transfer-learning-the-art-of-fine-tuning-a-pre-trained-model/&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;扩展文章&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383280&amp;amp;idx=1&amp;amp;sn=a6fd903f2c47339c52dcea9eedf65851&amp;amp;chksm=84f3cbb1b38442a7f4aac491852e06c34794154946a3656bc4ac4805b1ef1b41cb4469ae8419&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;对抗神经网络初探&lt;/a&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383212&amp;amp;idx=1&amp;amp;sn=e6dbbda2acc5984c8d06e24ec9c84d09&amp;amp;chksm=84f3cbedb38442fb58f0aea635821fcf4ba3edaacef4685716c7eadb6191197ebfa70a6bf14b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;你所不能不知道的CNN&lt;/a&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 21 Jan 2018 08:28:40 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/KQI4gcI1tj</dc:identifier>
</item>
</channel>
</rss>