<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>[原创]2017 我的学习之路</title>
<link>http://www.jintiankansha.me/t/Suu0gyNwLb</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/Suu0gyNwLb</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;span&gt;伟大的&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;毛主席这样说：&lt;/span&gt;“读书是学习，使用也是学习，而且是更重要的学习”。在&lt;span&gt;17&lt;/span&gt;&lt;span&gt;年底，借着万门大学征文的机会，在这里总结下我自以为的学习之道，分享给每一位也许迷茫也许焦虑的同学，培根（不是吃得那个，是腐国的一位大思想家）曾说过，我活着是为学习，而学习并不是为活着。这句话前半部分可以看成是终身学习的鸡汤，而后半句则是告诫你去学一些看起来和求生无关的东西，通过学习，活出自己的个性来。这句话应和我最喜欢引用的一句话古之学者为己&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;今之学者为人。在当下的社交媒体上，标注并分享自己学习了一个内容，要远远比学习某一个内容来的简单的多，人们都有去做简单的事情的冲动，但学习就应该选择那条难走的路。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;在今年夏天&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;的万门复杂系统和机器学习的特训班上，我十分荣幸的应许铁邀请，献丑做了一回授课讲师，授课的经历，给我留下了即深刻又美好的回忆，更令我受益良多。做为只是粗粗了解机器学习的一位外行，我本对接受邀约很犹豫，觉得自己讲不出什么干货，但耐不住基友的邀请最终答应了下来，课前很是花功夫做了准备，写课程的逐字稿，一次次的打磨&lt;/span&gt;PPT&lt;span&gt;，在这个过程中深化了自己对之前学过的课程和看过的书籍的理解，更锻炼了自己的表达能力和时间掌控的能力，在此要借着这个平台感谢万门大学和混沌巡洋舰给了我这个机会来实践自己通过输出来主动促进学习效率的学习之道。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;在我这个夏天做的分享中，我曾细致的讨论了如何在未来自学机器学习，还推荐了一些相关的视频课程和书籍。后来还曾经针对大数据，列过一个书单，（&lt;/span&gt;AI&lt;span&gt;，大数据，复杂系统 最精&lt;/span&gt; &lt;span&gt;40&lt;/span&gt;&lt;span&gt;本大书单），然而在我心中，学习的最佳方法绝不是仅仅去读书，而是要给身边的小伙伴讲出你读的这本书说了什么，最终的目标是要做到学以致用，尝试用书中所说的道理方法来改变你看问题做决策的习惯。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;若你觉得高质量的输出对于你来说太难了，你要明白写作或是讲课，本身就是很难的，需要你对自己所学的有深度的了解。为了给输出做好准备，可以通过问题来指导你的学习。一开始，问题可以是有趣的，例如在万门的免费课程&lt;/span&gt;-&lt;span&gt;《阿哲的疯狂实验室》中，童校就是通过一个个有趣的问题吸引人去进入看似深不可测的高等数学或大学物理中。然而这样有趣的问题，终究只能算是开胃菜。通过问题指引的学习，还应当去问些基本的问题，只有通过这些类似屈原的“天问”式的大问题，我们才能够系统性的学习一个学科。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;比如想学经济学，该问那些问题了，最初的问题可能会是生活中的房产现象，例如为什么在大萧条的时候，资本家宁可讲牛奶倒掉，也不愿意给穷人喝，这个问题由之同学给出了很好的回答，然而若是想全面的学习经济学，心中必须要弄清楚经济学想解决的是那些大问题，这些问题注定是超越时代和文化背景的，也一定不会是非黑即白而会是两难的选择，例如该如何权衡公平和效率，该如何分配稀缺的资源。带着这样的大问题，再去看经济学各个子学科中的假设与简化，就不会陷于细节而忘记了学习这门学科的初心。我的好友由之今年也曾经在万门的经济特训班讲课，为此他写下了数万字的讲稿，我想他也因此而加深了对经济学的理解了吧。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;不替万门做广告了，总结一下我想分享的学习之法。学习是困难的，能激励你坚持学习的不应仅仅是意志力，更应该是情感。这情感有由内而生的，即我们的好奇心，对于那些我们未知的有趣的问题，我们每个人都天生想知道问题的答案，只是该如何做才能避免让这份好奇心因为长大了就慢慢消散？&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;激励我们持续学习的第二种情感由外而内，来自于和他人分享知识带来的快乐。为了更高效的和他人分享，你需要将自己学到的观点和案例按照那些永恒不变的大问题归档，将你读过的书和文章中的每个知识点按照其可以回答的问题打上标签，进行分类归档，只有这样才能高效的讲给身边的伙伴。而更多的伙伴得到了知识光芒的照耀，也会激励你持续去追求新知的，只有这样的正向循环转动了起来，才可以督促自己去看更多的书，去问更多的问题，然后再将这些问题归类成大问题的子问题或变种，从而即加深了自己对知识的理解，也保证了在自己学到的内容是规整有序的。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382825&amp;amp;idx=1&amp;amp;sn=85d1aa1ef152c25d05fc576ceb3a310d&amp;amp;chksm=84f3ca68b384437e5f45ee169f6f0cbd991a7230fe54d0d2da0449fe44a2fd241ba3f9c729d8&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;如何评价人工智能与复杂系统特训课-看看铁哥怎么说&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 09 Jan 2018 17:58:18 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/Suu0gyNwLb</dc:identifier>
</item>
<item>
<title>[原创]深度学习入门最少需要知道什么？</title>
<link>http://www.jintiankansha.me/t/yjIfMX7Tjm</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/yjIfMX7Tjm</guid>
<description>&lt;p&gt;本文是巡洋舰深度课程讲师龚鹤扬根据文章 What you need to do deep learning __by Rachel Thomas 给出一个最简单的回答。&lt;/p&gt;
&lt;p&gt;经常有人会问：&lt;/p&gt;
&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;深度学习需要什么样的电脑？&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;怎样入门深度学习？&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;对于深度学习初学者，有什么建议？&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;怎用应用深度学习技术到某个具体的问题？&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;这些问题其实就是&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;深度学习需要什么样的硬件，软件，背景和数据？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;br /&gt;&lt;/h2&gt;
&lt;h2&gt;硬件&lt;/h2&gt;
&lt;p&gt;深度学习硬件很大的受益于游戏产业的高性能GPUs， 众多不同种类的显卡，我们推荐 Nvidia:&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccS7wUjwvEibuOBpJRAOMp1wAT8rBkyCuibpvfa9K4rOibibgnMIYdCDFjWUtGpTcMLxLIoRdQzL4BceA/0?wx_fmt=jpeg&quot; width=&quot;500&quot; class=&quot;&quot; data-ratio=&quot;0.8017578125&quot; data-w=&quot;1024&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;如果你的电脑没有 GPU 或者不是英伟达的 GPU，那么你有以下几个选择使用 fast.ai 的 Crestle 云服务，亚马逊云， 阿里云等。使用起来有些麻烦，使用方法参考原文：http://www.fast.ai/2017/11/16/what-you-need/ 。&lt;/p&gt;
&lt;h2&gt;&lt;br /&gt;&lt;/h2&gt;
&lt;h2&gt;软件&lt;/h2&gt;
&lt;p&gt;深度学习是一个新兴领域，软件库和工具包每天都在快速地提升。我们建议使用 Pytorch。为什么不推荐 Tensorflow 呢？ 主要原因是 Tensorflow 的动态计算图机制不成熟，其会话管理机制也有学习成本。Pytorch 适用于&lt;span&gt;探索科研和快速开发模型原型&lt;/span&gt;， 它相对来说更容易理解和使用。原文总结了如下几个理由:&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibccS7wUjwvEibuOBpJRAOMp1weFiaa7Iwn9mCNXCKYaHJvBmOs5qhZPzVWQtY3cOga4DBVaVZ2rYzz8A/0?wx_fmt=png&quot; class=&quot;&quot; data-ratio=&quot;0.521484375&quot; data-w=&quot;512&quot; data-type=&quot;png&quot; /&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li&gt;
&lt;p&gt;易于调试&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;动态计算图更适用于自然语言处理&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;支持传统的面向对象编程风格&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;TensorFlow 的 上下文管理器和会话等机制需要我们花费额外的精力学习&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;&lt;br /&gt;&lt;/h2&gt;
&lt;h2&gt;背景&lt;/h2&gt;
&lt;p&gt;深度学习需要的基础主要包括两个部分：&lt;/p&gt;
&lt;p&gt;虽然数学对学好深度学习极其重要，但是我们不建议在前期花太多时间在数学基础上。个人建议是直接看看西瓜书的数学附录， 花书中的数学基础部分。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccS7wUjwvEibuOBpJRAOMp1wBhUpsawDPo59ly9LnNBajDvKLJZukz3GpKOic3icBeExgDsWt01LBu1g/0?wx_fmt=jpeg&quot; width=&quot;500&quot; class=&quot;&quot; data-ratio=&quot;1&quot; data-w=&quot;300&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;br /&gt;&lt;/h2&gt;
&lt;h2&gt;数据&lt;/h2&gt;
&lt;p&gt;在大众的印象中，训练一个深度学习模型动辄需要几百万的样本，然而这并不总是成立。很多时候我们利用 &lt;span&gt;迁移学习(结合数据增强技术)&lt;/span&gt;，我们用几百上千个数据就可以训练一个很好的深度网路了。 例如， 在 medical start-up Enlitic， Jeremy Howard 领导的一个团队用 1000 个肺部CT扫描 图像， 训练出一个网络诊断肺癌，准确率比专家还要高！&lt;/p&gt;
&lt;p&gt;C++ 库 Dlib 中的一个人脸检测例子，甚至只有4个训练样本！&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibccS7wUjwvEibuOBpJRAOMp1wUXJQLP3T8MybVJthjCRJLUBDkhRwN0JwLtvicbaovjzpnsVPiboH3U6Q/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;0.6578125&quot; data-w=&quot;640&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;迁移学习和数据增强技术减少了深度学习模型对数据量的需求。当然还有其他方法， 例如生成对抗，深度强化学习等很多时候不需要大量的人工标注样本。而深度学习初学者需要用到的数据甚至直接集成在框架中（例如 Pytorch），直接调用就行。&lt;/p&gt;

&lt;p&gt;巡洋舰深度课程系列文章&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383161&amp;amp;idx=1&amp;amp;sn=b27c2a0686d57b13daadcfd16cb35dac&amp;amp;chksm=84f3cb38b384422ecfca55da7b54978a8f3742605549566920507d5e032e16da1be50c1f5f97&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;你需要的深度学习数学基础： 从入门到进阶&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383212&amp;amp;idx=1&amp;amp;sn=e6dbbda2acc5984c8d06e24ec9c84d09&amp;amp;chksm=84f3cbedb38442fb58f0aea635821fcf4ba3edaacef4685716c7eadb6191197ebfa70a6bf14b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;你所不能不知道的CNN&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383226&amp;amp;idx=1&amp;amp;sn=959e2bfa3cdf523250b1d082548380a2&amp;amp;chksm=84f3cbfbb38442ede89aa9b8bd4e1db04c7d5faaa4111a73d9712f1055aeebcd8ec3f2b17b07&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;用深度学习玩图像的七重关卡&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 08 Jan 2018 17:36:45 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/yjIfMX7Tjm</dc:identifier>
</item>
<item>
<title>[原创]读《人之彼岸》说说我心目中的AI与反乌托邦</title>
<link>http://www.jintiankansha.me/t/EHOS3SSh5L</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/EHOS3SSh5L</guid>
<description>&lt;p&gt;18年读的第一本书，是郝景芳的《人之彼岸》，全书的六个故事和两篇非科幻的思索，相映成趣，思考中提到的观点，都在小说中有所呈现。整本书的主题，用作者的话可以看成是&lt;span&gt;“人工智能在彼岸，我们在此岸。”也&lt;/span&gt;可以用书中提出的“逆图灵测试”来概括。图灵测试是通过人类无法分别和Ta交流的是人类还是电脑来判定智能水平的，而逆图灵测试则是通过呈现人类特有的性状，让人类能够和那些智能水平上已经不相上下的AI区分开来。全书写的六个故事，每一个都可以看成是逆图灵测试，故事中的英雄有的成功了，而有的则在故事的最后明白自己为什么没有通过测试。&lt;/p&gt;

&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcdV5esuvsoSc6k8dG6TcBrCk9Sabyh4Ss7Ip2lUDSPXubicA4MW9dXicB2Bkt7qBJzEStTAnJRDIe1A/0?wx_fmt=jpeg&quot; class=&quot;&quot; data-ratio=&quot;1.4455445544554455&quot; data-w=&quot;303&quot; data-type=&quot;jpeg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;在对这本书进行创造性的批判之前，想先说说对这本书整体的看法。文字简洁，论述到位，作者对认知心理学和人工智能的了解都深入本质。然而作者将AI进行的漫画式的夸张处理，我却不赞同。这本书中的AI，不管能力有多强，都缺少情感，永远表现的彬彬有礼，不会被愤怒等负面情绪冲昏了头脑，从艺术上来说，这样可以创造出戏剧冲突，凸显人与机器的不同，但是未来的AI真的会是这样吗？我觉得值得担心的不是机器背后的数字化逻辑侵蚀了那些使人类生活有意义的部分，而是机器用廉价的仿制品让人类不觉得使生活有意义的是爱与创造。&lt;/p&gt;

&lt;p&gt;关于未来AI的讨论，从更抽象的层次来看，可以看成是反乌托邦式的推演。人们更容易害怕的是通过脑机接口，全球化的AI知道了每个人一生中的所有想法，是机器通过概率的计算让人的自由意志变成了幻象，这些都不过是奥威尔式的1984的变种。但真正要担心的是赫胥黎式的未来，而从目前的趋势来看，这种未来是更有可能的。在前一种的未来预测中，恋爱的人不在有眼神的交流，是因为觉得指导约会的软件无法定量分析眼神中的信息，而在一种未来里，是因为人们戴上了假眼睛，可以通过改变眼睛的颜色来交流，并把这叫做眼神的交流。&lt;/p&gt;

&lt;p&gt;大前研一有两本书，一本叫《低欲望社会》，另一本叫《低智商社会》，这俩本书虽然说的是日本，但在全球化的大趋势下，书中所说的也多少适用于其他国家。书中所说的低欲望社会，主要指的是年轻人缺少好奇心和上进心，不管对消费还是恋爱，都缺少兴趣，只想宅在家里。这看起来和人工智能没有半毛钱关系，但是若不是有一个智能的网络来保证这些人基本的生存需求，那么想要维持这样的低欲望社会，是不可能的。&lt;/p&gt;

&lt;p&gt;然而按照常理推断，人类的需求金字塔是普世的，没有人会只安逸于最底层需求的满足，而不去追求自我实现。要想解释这个矛盾，我们就要看看满足自我实现的需求，有几种途径。身体力行的去做自然能让人有成就感，可人脑中的镜像神经元决定了人可以不需要自己去冒险，只需要通过冒险的故事，就能够差不多的体会到实现自我是怎样一种感觉。而这正是为什么会有低欲望社会的原因。虚构的游戏和影视剧让人们可以长久生活在幻想中。&lt;/p&gt;

&lt;p&gt;AI的进步会使的让人停留在幻想中变得更容易，就拿当下已有的技术来说。个性化的推荐会给你那些会让你反复点击的内容，而AR的进步会让内容的呈现变得难以分清真假。不需要脑机接口这样的黑科技，只要未来几十年，人类最聪明的大脑还是将精力放在获取更多的点击，而不是去探索太空，那么这种未来就会越来越变成现实。&lt;/p&gt;

&lt;p&gt;人类作为万物之灵，不止在于创造了，还在于其心智中的无用之大用，比如认为人生有比利益优化更重要的意义，能感受得到伟大艺术家给人传递的震撼。这是人类区别于机器的更基本的特征，不是常识，心智理论或者信息整合等具体的能力，而是一种一旦说出来就没意思的那点意思。正是因为不能说，所以真正需要提防的不是奥威尔式的禁止和无视，而是对这种精神的一种降级后表达。比如我中学时喜欢读李白的诗，但若是他诗中的句子出现在语文考试的阅读理解中，让我不得不写下干巴巴的中心思想，那这首诗，至少在那一刻就算毁了，就不会再让我感受到心灵的震动了。&lt;/p&gt;

&lt;p&gt;关于AI的讨论，最终都要回到该如何做好一个人的层面上。《人之彼岸》这本书在其最后一章，讨论了人工智能时代的教育，作为一个母亲，她谈论的是怎样去教育孩子。而这里想说说该怎么对自己进行教育。这里说三点，第一是回归到原始的材料上，在听他人的转述之前，先去看看第一手的信息来源是怎么说的，再看看他人根据文本进行的展开。要进行信息整合，就不能只根据关键词去做联想，去构建知识图谱，这机器也会。人的作用是将自己的亲身经验加入到文本的理解中，机器的理解是做减法，人的理解是做加法。&lt;/p&gt;

&lt;p&gt;第二是关注信息的网络结构，要去深挖那些处在网络中心的知识点，这也是人能够进行小样本学习的关键。人类识别狗狗，不是通过数万照片的持续训练，而是在头脑中构建了关于狗狗这个概念的一张网，第一次见到狗狗，学到了叫声，大小等核心的不变的特征，第二次注意到了狗狗的尾巴，耳朵毛色等次要特征，从而在第三次见到狗就能认出了。通过将概念按网络拆解，人可以在学会了狗狗这个概念之后，就可以将之前的经验用在识别狗狗的品种上。这正是机器所无法做到的，深度学习可以做到层次化，却无法体察出观念与观念之间的驱动关系网。&lt;/p&gt;

&lt;p&gt;第三点要提醒的是去学习一些看起来无用的知识，这是人之为人最不同的一点，机器现在已经有注意力，有创造性，未来也注定会有主动的行为。但机器不会去做超越胜败的尝试。对于机器来说，没有优化的目标或评价标准，就没有了存在的意义，但人类却可以自己通过在无用的尝试中找到的规律，不断为自己创造新的标杆，在通过艺术，文学等来向更多人展示自己认为的有意义的生活是怎样的。所以去了解那些没有直接用途的知识，是为我们找到船，而实用的知识不过是桨，没有了船，在陆地划的浆再大，也走不远。&lt;/p&gt;


&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;
&lt;p&gt;扩展阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383164&amp;amp;idx=1&amp;amp;sn=0cfac710d4d5783ed06bbdb694828409&amp;amp;chksm=84f3cb3db384422b11c90bf7826cc7b52a3f74176442fb28e6ebc27b5e44c9d1ef33f39d077e&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;多余的话 借深度网络说说最近发生的几件事&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;


</description>
<pubDate>Sat, 06 Jan 2018 04:11:12 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/EHOS3SSh5L</dc:identifier>
</item>
<item>
<title>[原创]用深度学习玩图像的七重关卡</title>
<link>http://www.jintiankansha.me/t/FDI5UwW9rA</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/FDI5UwW9rA</guid>
<description>&lt;p&gt;&lt;span&gt;第一个重境界： 图像识别&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;如果你开始了解深度学习的图像处理， 你接触的第一个任务一定是图像识别 ：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;比如把你的爱猫输入到一个普通的CNN网络里， 看看它是喵咪还是狗狗。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5958333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pmVWxEbialvmZ1zRnIcvMycjzeNGH3RdEtSwpyRAjuoL5TtRMQ3LpzeA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1292&quot; /&gt;


&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.34419551934826886&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p8618aL9uvCzCqdfWsQVoYu6ibRiaDMkeV71jhF1B8hgCfY4Jq3W9WhvA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;491&quot; width=&quot;491&quot; /&gt;
&lt;p&gt;&lt;span&gt;一个最普通的CNN， 比如像这样几层的CNN鼻祖Lenet， 如果你有不错的数据集（比如kaggle猫狗大战）都可以给出一个还差强人意的分类结果(80%多准确率)， 虽然不是太高。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;当然，如果你再加上对特定问题的一些知识， 也可以顺便识别个人脸啥的，开个startup叫face 减减什么：&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.525&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8px9qZQu3008UB7uKa041NllHicdwJz031bQIlegIfzfia4f57M4ngR3yw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1200&quot; /&gt;
&lt;p&gt;&lt;span&gt;会玩的， 也可以顺别识别个猪脸什么哒（我觉得长得都一样哦）， 这样搞出来每个猪的身份， 对于高质量猪肉的销售， 真是大有裨益的。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;1.2181372549019607&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pwZbwmQdSZHGHSfufIuqSRGAANDLOs6uqFNiaEk7yXJFfPKFzfXw8Eww/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;408&quot; width=&quot;408&quot; /&gt;
&lt;p&gt;&lt;span&gt;或者看看植物都有个什么病害什么的，像这样不同的病斑， 人都懒得看的， 它可以给你看出来。 植物保护的人可以拿着手机下田了。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.8548812664907651&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pL7EMgc4RAtHuuwecULkGmzopwFEGOuozy9IhHFpbsnCH7wKKPfC99w/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;379&quot; width=&quot;379&quot; /&gt;&lt;span&gt;Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. &quot;U-net: Convolutional networks for biomedical image segmentation.&quot; International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2015.&lt;/span&gt;


&lt;p&gt;&lt;span&gt;虽然植物保护真的很好用，分类问做就了还真是挺无聊的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们进化的方向，也就是用更高级的网络结构取得更好的准确率，比如像下图这样的残差网络（已经可以在猫狗数据集上达到99.5%以上准确率）。分类做好了你会有一种成为深度学习大师，拿着一把斧子眼镜里都是钉子的幻觉。 分类问题之所以简单， 一要归功于大量标记的图像， 二是分类是一个边界非常分明的问题， 即使机器不知道什么是猫什么是狗， 看出点区别还是挺容易的， 如果你给机器几千几万类区分， 机器的能力通过就下降了（再复杂的网络，在imagenet那样分1000个类的问题里，都很难搞到超过80%的准确率）。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;2.236051502145923&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8ptnQicHcOPyIjI1iabQUicU5GrDB0oegPvX5mDDW0tUOL8fxP98frhDTVw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;233&quot; width=&quot;233&quot; /&gt;&lt;span&gt;He, Kaiming, et al. &quot;Identity mappings in deep residual networks.&quot; European Conference on Computer Vision. Springer International Publishing, 2016.&lt;/span&gt;


&lt;p&gt;&lt;span&gt;第二重境界 ： 物体检测&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;很快你发现，分类的技能在大部分的现实生活里并没有鸟用。因为现实中的任务啊， 往往是这样的：&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6097222222222223&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8peEg2SST3nibYmXDmusWibwg7lYXf25kwAaEXx4gUR7GwCibhktSAGcqUg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1833&quot; /&gt;
&lt;p&gt;&lt;span&gt;或者这样的：&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p1JiaNU4qkFaNAub1352C9zGfEJQDpv2TlcGqOicTtDJDH2pHnEFz7RtQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1280&quot; /&gt;
&lt;p&gt;&lt;span&gt;那么多东西在一起，你拿猫狗大头照训练的分类网络一下子就乱了阵脚。 即使是你一个图片里有一个猫还有一个狗，甚至给猫加点噪声，都可以使你的分类网络分寸大乱。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;现实中， 哪有那么多图片， 一个图里就是一个猫或者美女的大图，更多的时候， 一张图片里的东西， 那是多多的， 乱乱的，没有什么章法可言的， 你需要自己做一个框， 把你所需要看的目标给框出来， 然后， 看看这些东西是什么 。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;于是你来到机器视觉的下一层挑战 - 目标检测（从大图中框出目标物体并识别）， 随之而来的是一个新的网络架构， 又被称为R - CNN， 图片检测网络 ， 这个网络不仅可以告诉你分类，还可以告诉你目标物体的坐标， 即使图片里有很多目标物体， 也一一给你找出来。&lt;/span&gt;&lt;/p&gt;


&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.983739837398374&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p1Eib5JAt85jFrNdjZN1Ekhe6o5q0UMILTnhlmzc5A2KLZMVG2tBZ3dA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;369&quot; width=&quot;369&quot; /&gt;&lt;span&gt;Ren, Shaoqing, et al. &quot;Faster R-CNN: Towards real-time object detection with region proposal networks.&quot; Advances in neural information processing systems. 2015.&lt;/span&gt;


&lt;p&gt;&lt;span&gt;万军斩你首级那是杠杠的，在众多路人甲中识别嫌疑犯，也是轻而易举， 安防的人听着要按捺不住了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;今年出现的YOLO算法更是实现了快速实时的物体检测，你一路走过就告诉你视线里都有什么在哪里，要知道这在无人驾驶里是何等的利器。&lt;/span&gt;&lt;/p&gt;


&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.27361111111111114&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pv2ent4UhiaQCSVqqtuyEYvuWm8dreC119Pxicpwib5pr2FvLdv5RwHvvg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;932&quot; /&gt;&lt;span&gt;YOLO快速检测法Redmon, Joseph, et al. &quot;You only look once: Unified, real-time object detection.&quot; Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016.&lt;/span&gt;


&lt;p&gt;&lt;span&gt;当然， 到这里你依然最终会觉得无聊， 即使网络可以已经很复杂， 不过是一个CNN网络（推荐区域），在加上一层CNN网络做分类和回归。 能不能干点别的？&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;第三重境界 ： 图像切割&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;啊哈， 这就来到了第三个关卡， 你不仅需要把图片中边边角角的物体给检测出来， 你还要做这么一个猛料的工作， 就是把它从图片中扣出来。 要知道， 刚出生的婴儿分不清物体的边界， 比如桌上有苹果这种事， 什么是桌子，什么是苹果，为什么苹果不是占在桌子上的？ 所以， 网络能不能把物体从一个图里抠出来， 事关它是否真的像人一样把握了视觉的本质。 这也算是对它的某种“图灵测试” 。 而把这个问题简化，我们无非是在原先图片上生成出一个原图的“mask”， 面具，有点像phtoshop里的蒙版的东西。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.43333333333333335&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8plAMK9N6CCNlXBialKWGsFpEUYOg8DLopAW4Bm7OSGcxiaZwuEWbGibn9Q/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1960&quot; /&gt;&lt;span&gt;所谓抠图&lt;/span&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5601503759398496&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p72XAMqcibeaNphRQgFcuvqKhTL7gAHFl5zz2Jsgibicq9odzS5u59R9pQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;532&quot; width=&quot;532&quot; /&gt;&lt;span&gt;Drozdzal, Michal, et al. &quot;The importance of skip connections in biomedical image segmentation.&quot; International Workshop on Large-Scale Annotation of Biomedical Data and Expert Label Synthesis. Springer International Publishing, 2016.&lt;/span&gt;

&lt;p&gt;&lt;span&gt;注意，这个任务里，我们是要从一个图片里得到另一个图片哦！ 生成的面具是另一个图片， 这时候，所谓的U型网络粉墨登场，注意这是我们的第一个生成式的模型。 它的组成单元依然是卷积，但是却加入了maxpooling的反过程升维采样。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这个Segmentation任务， 作用不可小瞧哦， 尤其对于科研口的你， 比如现在私人卫星和无人机普及了，要不要去看看自己小区周围的地貌， 看是不是隐藏了个金库？ 清清输入， 卫星图片一栏无余。 哪里有树， 哪里有水，哪里有军事基地，不需要人，全都给你抠出来。&lt;/span&gt;&lt;/p&gt;


&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.425&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pMILia1oGtBVD1frgKQurjhb0JVt65xztrywKhbE5Qersq6ekJkMgrFg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;2824&quot; /&gt;

&lt;p&gt;&lt;span&gt;如果你要数个细胞啥的 ，都是挺容易的，给它变成这样的轮廓不就你得了。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6577777777777778&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pKSLTajVkpM8OQOY40o5elTc6YcS8bJwQ4nWTz5GvG7GicwatA5ksyMQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;450&quot; width=&quot;450&quot; /&gt;

&lt;p&gt;&lt;span&gt;第四重境界：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们开始fashion起来， 如果你是淘宝服装小店的老板 ，想让客户输入一张服装的图片，然后得到一组推荐的服装， 来个以图搜图的功能怎么搞呢？ 注意啊，我可以从网络上爬一大堆图出来，但是这些数据是没有标注的。怎么办？ 铁哥告你还是有的搞，这个搞法，就是聚类。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;铁哥教你最简单的一招聚类哦，那就是， 把图片统统放进卷积网络，但是我们不提取分类，而只是提取一些网络中间层的特征， 这些特征有点像每个图片的视觉二维码，然后我们对这些二维码做一个k-means聚类， 也会得到意想不到的效果。 为什么要深度？ 因为深度提取的特征，那是与众不同的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然后以图搜图呢？ 不过是找到同一聚类里的其它图片啊。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pydpxk94iaOS3TsAne9NqweE09T3YWtvic58vicmh3Xu3tGsRO642yg9mQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1506&quot; /&gt;
&lt;p&gt;&lt;span&gt;在聚类的基础上， 就可以做个搜索！&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5958333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pdPkKgSWcric4QIu78icfsMiaYPYwjBhNXfVt94w9dXlCicic0OOQdHo8hJw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;754&quot; /&gt;

&lt;p&gt;&lt;span&gt;第五层境界 ：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们开始晋升为仰望星空的人， 之前那些分类赚钱的应用太无聊了。 机器视觉搞科学怎么港？ 作为一群仰望星空后观察细胞的人，我们最常发现的是我们得到的天文或者细胞图片的噪声实在太大了， 这简直没法忍啊， 然后， 深度学习给了你一套降噪和恢复图像的方法。 一个叫auto-encoder的工具， 起到了很大的作用 ， 刷的一下，图像就清楚了。&lt;/span&gt;&lt;/p&gt;


&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.24027777777777778&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pJcbXOYHicuJB6QkiafzP6gp8GkcP0rTIhh1zcwXWYsVAuddMtecbZVDA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;797&quot; /&gt;
&lt;p&gt;&lt;span&gt;这还不是最酷炫的，那个应用了博弈理论的对抗学习， 也可以帮你谋杀噪点！ 如果你会对抗所谓GAN， 也是一种图像生成的工具， 让网络去掉噪声的图片，与没有噪声的自然图片， 连卷积网络都判别不出来，对， 就是这样！&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5606936416184971&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pmRuSYRGgC2Hz0fia9n1SKWpEW5vC0ReFpLibhWHHOkootXOWhI3IzJNQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;519&quot; width=&quot;519&quot; /&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.25&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pIicCIdGK2w2AaziaYHALia2cRRUgwibdU6J84xiaX5gfMibY81mbNMOtuiaPg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;806&quot; /&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;span&gt;Schawinski, Kevin, et al. &quot;Generative adversarial networks recover features in astrophysical images of galaxies beyond the deconvolution limit.&quot; Monthly Notices of the Royal Astronomical Society: Letters 467.1 (2017): L110-L114.&lt;/span&gt;



&lt;p&gt;&lt;span&gt;第六重境界 ：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在工业界赚够了钱，科学也太nerd了， 我们来玩艺术思考哲学 ，第一招， 图像风格迁移，请见&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383188&amp;amp;idx=1&amp;amp;sn=ec8d1090fe46741c14ccf7cc02b57c2c&amp;amp;chksm=84f3cbd5b38442c33ef70b698dd07f5b7aa954623fe3724e9f83b8e10a44b86a3777054395a4&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;怎么样用深度学习取悦你的女朋友（有代码）&lt;/span&gt;&lt;/a&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6904761904761905&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8paO6E4iaLY8ruEAE6G4PPCuicWXGSICQCZeXUzcdVMfiaRvbPibhK0PMdnw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;714&quot; width=&quot;714&quot; /&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.43333333333333335&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pDadLaRicMiajia9wJtp4DM49hWZ9WmwTc9Cia3fe6mvEvR3VnibLpl7AgwQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; width=&quot;600&quot; /&gt;


&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.2119487908961593&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8piaCt4IcpJNvDic7nnHMMh9YzL3onemYkfBGy8uy0gmiaJsIaNt6IKYSiaw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;703&quot; width=&quot;703&quot; /&gt;

&lt;p&gt;&lt;span&gt;然而真正能玩好这一事项的，还是那个刚刚提过的对抗学习GAN， 比如大名鼎鼎的CycleGAN， 几乎可以实现一种你自定义的“图像翻译” 功能，而且你不用做标注哦， 拿出冬天和夏天的两组图片， 它会自动的在两组图片中找出对应来。&lt;/span&gt;&lt;/p&gt;


&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.4791666666666667&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p2zXHUFQ3QBxgSVj7DKOaAibucGLrVJmcumwaDLhwpLic7Yy7NrO6o9icw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;963&quot; /&gt;&lt;span&gt;Zhu, Jun-Yan, et al. &quot;Unpaired image-to-image translation using cycle-consistent adversarial networks.&quot; arXiv preprint arXiv:1703.10593 (2017).&lt;/span&gt;


&lt;p&gt;&lt;span&gt;第七重境界：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;图像翻译也懒的玩了， 你神经网络不是号称能够理解图像，看你来个无中生有，在噪声里生成图片来？&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;对，依然是GAN，而且是最基础的卷积GAN (DCGAN)就可以给你干出来。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;看看GAN所幻想的宾馆情景， 你能想到是计算机做的图吗？ 哈哈哈！&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.23194444444444445&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pibZlT5DL1c0ibHtng9H2UdDVyStfea2SfZy6oVf3jbLdeQtvVicY4Xp5Q/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;912&quot; /&gt;&lt;span&gt;Goodfellow, Ian, et al. &quot;Generative adversarial nets.&quot; Advances in neural information processing systems. 2014.&lt;/span&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5347222222222222&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p6MVDPc4s5NsFmZnha7m8qUxGFIUicyGCYNMvBCllDoWohGrq8yBFMKQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;744&quot; /&gt;

&lt;p&gt;&lt;span&gt;写到这里， 我自己都觉得GAN是非常有前途的，有前途的，有前途的，以前我还以为只是好玩呢。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这里展示的七级浮屠，也不过深度学习被人类discover的冰山一角， 醉卧沙场君莫笑， 古来征战几人回。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;给你一个稍微清晰一些的大纲：&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.39444444444444443&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pZIxvp9LSmFuO5owzINicw9a9HlL9nNJ8W2WZEBCmeHO9JJL6Uib7GMvQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;914&quot; /&gt;
&lt;p&gt;&lt;span&gt;如果对基础理论部分有不熟悉，请返回文章&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383212&amp;amp;idx=1&amp;amp;sn=e6dbbda2acc5984c8d06e24ec9c84d09&amp;amp;chksm=84f3cbedb38442fb58f0aea635821fcf4ba3edaacef4685716c7eadb6191197ebfa70a6bf14b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;你不能不知道的CNN&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，当然它只是冰山一角， 了解更多并挨个实战请关注：巡洋舰的&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383029&amp;amp;idx=1&amp;amp;sn=a792653f736540e06d96e6f3970264e0&amp;amp;chksm=84f3cab4b38443a2754072d8b3d3fdade7ea503b15ecea46595bb149edcc139000b7f315e624&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;深度学习实战课程&lt;/span&gt;&lt;/a&gt;&lt;span&gt;， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛。刚刚讲的方法都将在课程里详细展开。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;目前课程线下版本已经基本报名完毕（特殊申请可加一到两个名额）， 为了缓解众多异地学员的需求， 我们提出一个线上加线下的课程简版， 课程包括全部课程视频， notebook作业， 和一个课程模块的来京线下实践机会， 名额限5名，预报从速，详情请联系陈欣&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfCFEFrIh4CD3HnwF5a6d9gqk3NhIsY8ThV50SQ5ut1tiaRVs5lSnvrYRqWuJNgxJTXTZ9fu54micsw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;1&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;


</description>
<pubDate>Sat, 23 Dec 2017 04:45:54 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/FDI5UwW9rA</dc:identifier>
</item>
</channel>
</rss>