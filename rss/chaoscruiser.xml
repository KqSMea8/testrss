<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>[原创]用深度学习玩图像的七重关卡</title>
<link>http://www.jintiankansha.me/t/FDI5UwW9rA</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/FDI5UwW9rA</guid>
<description>&lt;p&gt;&lt;span&gt;第一个重境界： 图像识别&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;如果你开始了解深度学习的图像处理， 你接触的第一个任务一定是图像识别 ：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;比如把你的爱猫输入到一个普通的CNN网络里， 看看它是喵咪还是狗狗。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5958333333333333&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pmVWxEbialvmZ1zRnIcvMycjzeNGH3RdEtSwpyRAjuoL5TtRMQ3LpzeA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1292&quot; /&gt;


&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.34419551934826886&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p8618aL9uvCzCqdfWsQVoYu6ibRiaDMkeV71jhF1B8hgCfY4Jq3W9WhvA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;491&quot; width=&quot;491&quot; /&gt;
&lt;p&gt;&lt;span&gt;一个最普通的CNN， 比如像这样几层的CNN鼻祖Lenet， 如果你有不错的数据集（比如kaggle猫狗大战）都可以给出一个还差强人意的分类结果(80%多准确率)， 虽然不是太高。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;当然，如果你再加上对特定问题的一些知识， 也可以顺便识别个人脸啥的，开个startup叫face 减减什么：&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.525&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8px9qZQu3008UB7uKa041NllHicdwJz031bQIlegIfzfia4f57M4ngR3yw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1200&quot; /&gt;
&lt;p&gt;&lt;span&gt;会玩的， 也可以顺别识别个猪脸什么哒（我觉得长得都一样哦）， 这样搞出来每个猪的身份， 对于高质量猪肉的销售， 真是大有裨益的。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;1.2181372549019607&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pwZbwmQdSZHGHSfufIuqSRGAANDLOs6uqFNiaEk7yXJFfPKFzfXw8Eww/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;408&quot; width=&quot;408&quot; /&gt;
&lt;p&gt;&lt;span&gt;或者看看植物都有个什么病害什么的，像这样不同的病斑， 人都懒得看的， 它可以给你看出来。 植物保护的人可以拿着手机下田了。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.8548812664907651&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pL7EMgc4RAtHuuwecULkGmzopwFEGOuozy9IhHFpbsnCH7wKKPfC99w/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;379&quot; width=&quot;379&quot; /&gt;&lt;span&gt;Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. &quot;U-net: Convolutional networks for biomedical image segmentation.&quot; International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2015.&lt;/span&gt;


&lt;p&gt;&lt;span&gt;虽然植物保护真的很好用，分类问做就了还真是挺无聊的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们进化的方向，也就是用更高级的网络结构取得更好的准确率，比如像下图这样的残差网络（已经可以在猫狗数据集上达到99.5%以上准确率）。分类做好了你会有一种成为深度学习大师，拿着一把斧子眼镜里都是钉子的幻觉。 分类问题之所以简单， 一要归功于大量标记的图像， 二是分类是一个边界非常分明的问题， 即使机器不知道什么是猫什么是狗， 看出点区别还是挺容易的， 如果你给机器几千几万类区分， 机器的能力通过就下降了（再复杂的网络，在imagenet那样分1000个类的问题里，都很难搞到超过80%的准确率）。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;2.236051502145923&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8ptnQicHcOPyIjI1iabQUicU5GrDB0oegPvX5mDDW0tUOL8fxP98frhDTVw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;233&quot; width=&quot;233&quot; /&gt;&lt;span&gt;He, Kaiming, et al. &quot;Identity mappings in deep residual networks.&quot; European Conference on Computer Vision. Springer International Publishing, 2016.&lt;/span&gt;


&lt;p&gt;&lt;span&gt;第二重境界 ： 物体检测&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;很快你发现，分类的技能在大部分的现实生活里并没有鸟用。因为现实中的任务啊， 往往是这样的：&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6097222222222223&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8peEg2SST3nibYmXDmusWibwg7lYXf25kwAaEXx4gUR7GwCibhktSAGcqUg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1833&quot; /&gt;
&lt;p&gt;&lt;span&gt;或者这样的：&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5625&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p1JiaNU4qkFaNAub1352C9zGfEJQDpv2TlcGqOicTtDJDH2pHnEFz7RtQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1280&quot; /&gt;
&lt;p&gt;&lt;span&gt;那么多东西在一起，你拿猫狗大头照训练的分类网络一下子就乱了阵脚。 即使是你一个图片里有一个猫还有一个狗，甚至给猫加点噪声，都可以使你的分类网络分寸大乱。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;现实中， 哪有那么多图片， 一个图里就是一个猫或者美女的大图，更多的时候， 一张图片里的东西， 那是多多的， 乱乱的，没有什么章法可言的， 你需要自己做一个框， 把你所需要看的目标给框出来， 然后， 看看这些东西是什么 。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;于是你来到机器视觉的下一层挑战 - 目标检测（从大图中框出目标物体并识别）， 随之而来的是一个新的网络架构， 又被称为R - CNN， 图片检测网络 ， 这个网络不仅可以告诉你分类，还可以告诉你目标物体的坐标， 即使图片里有很多目标物体， 也一一给你找出来。&lt;/span&gt;&lt;/p&gt;


&lt;img class=&quot;content_image lazy&quot; data-ratio=&quot;0.983739837398374&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p1Eib5JAt85jFrNdjZN1Ekhe6o5q0UMILTnhlmzc5A2KLZMVG2tBZ3dA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;369&quot; width=&quot;369&quot; /&gt;&lt;span&gt;Ren, Shaoqing, et al. &quot;Faster R-CNN: Towards real-time object detection with region proposal networks.&quot; Advances in neural information processing systems. 2015.&lt;/span&gt;


&lt;p&gt;&lt;span&gt;万军斩你首级那是杠杠的，在众多路人甲中识别嫌疑犯，也是轻而易举， 安防的人听着要按捺不住了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;今年出现的YOLO算法更是实现了快速实时的物体检测，你一路走过就告诉你视线里都有什么在哪里，要知道这在无人驾驶里是何等的利器。&lt;/span&gt;&lt;/p&gt;


&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.27361111111111114&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pv2ent4UhiaQCSVqqtuyEYvuWm8dreC119Pxicpwib5pr2FvLdv5RwHvvg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;932&quot; /&gt;&lt;span&gt;YOLO快速检测法Redmon, Joseph, et al. &quot;You only look once: Unified, real-time object detection.&quot; Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016.&lt;/span&gt;


&lt;p&gt;&lt;span&gt;当然， 到这里你依然最终会觉得无聊， 即使网络可以已经很复杂， 不过是一个CNN网络（推荐区域），在加上一层CNN网络做分类和回归。 能不能干点别的？&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;第三重境界 ： 图像切割&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;啊哈， 这就来到了第三个关卡， 你不仅需要把图片中边边角角的物体给检测出来， 你还要做这么一个猛料的工作， 就是把它从图片中扣出来。 要知道， 刚出生的婴儿分不清物体的边界， 比如桌上有苹果这种事， 什么是桌子，什么是苹果，为什么苹果不是占在桌子上的？ 所以， 网络能不能把物体从一个图里抠出来， 事关它是否真的像人一样把握了视觉的本质。 这也算是对它的某种“图灵测试” 。 而把这个问题简化，我们无非是在原先图片上生成出一个原图的“mask”， 面具，有点像phtoshop里的蒙版的东西。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.43333333333333335&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8plAMK9N6CCNlXBialKWGsFpEUYOg8DLopAW4Bm7OSGcxiaZwuEWbGibn9Q/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1960&quot; /&gt;&lt;span&gt;所谓抠图&lt;/span&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5601503759398496&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p72XAMqcibeaNphRQgFcuvqKhTL7gAHFl5zz2Jsgibicq9odzS5u59R9pQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;532&quot; width=&quot;532&quot; /&gt;&lt;span&gt;Drozdzal, Michal, et al. &quot;The importance of skip connections in biomedical image segmentation.&quot; International Workshop on Large-Scale Annotation of Biomedical Data and Expert Label Synthesis. Springer International Publishing, 2016.&lt;/span&gt;

&lt;p&gt;&lt;span&gt;注意，这个任务里，我们是要从一个图片里得到另一个图片哦！ 生成的面具是另一个图片， 这时候，所谓的U型网络粉墨登场，注意这是我们的第一个生成式的模型。 它的组成单元依然是卷积，但是却加入了maxpooling的反过程升维采样。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这个Segmentation任务， 作用不可小瞧哦， 尤其对于科研口的你， 比如现在私人卫星和无人机普及了，要不要去看看自己小区周围的地貌， 看是不是隐藏了个金库？ 清清输入， 卫星图片一栏无余。 哪里有树， 哪里有水，哪里有军事基地，不需要人，全都给你抠出来。&lt;/span&gt;&lt;/p&gt;


&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.425&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pMILia1oGtBVD1frgKQurjhb0JVt65xztrywKhbE5Qersq6ekJkMgrFg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;2824&quot; /&gt;

&lt;p&gt;&lt;span&gt;如果你要数个细胞啥的 ，都是挺容易的，给它变成这样的轮廓不就你得了。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6577777777777778&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pKSLTajVkpM8OQOY40o5elTc6YcS8bJwQ4nWTz5GvG7GicwatA5ksyMQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;450&quot; width=&quot;450&quot; /&gt;

&lt;p&gt;&lt;span&gt;第四重境界：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们开始fashion起来， 如果你是淘宝服装小店的老板 ，想让客户输入一张服装的图片，然后得到一组推荐的服装， 来个以图搜图的功能怎么搞呢？ 注意啊，我可以从网络上爬一大堆图出来，但是这些数据是没有标注的。怎么办？ 铁哥告你还是有的搞，这个搞法，就是聚类。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;铁哥教你最简单的一招聚类哦，那就是， 把图片统统放进卷积网络，但是我们不提取分类，而只是提取一些网络中间层的特征， 这些特征有点像每个图片的视觉二维码，然后我们对这些二维码做一个k-means聚类， 也会得到意想不到的效果。 为什么要深度？ 因为深度提取的特征，那是与众不同的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然后以图搜图呢？ 不过是找到同一聚类里的其它图片啊。&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.625&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pydpxk94iaOS3TsAne9NqweE09T3YWtvic58vicmh3Xu3tGsRO642yg9mQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;1506&quot; /&gt;
&lt;p&gt;&lt;span&gt;在聚类的基础上， 就可以做个搜索！&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5958333333333333&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pdPkKgSWcric4QIu78icfsMiaYPYwjBhNXfVt94w9dXlCicic0OOQdHo8hJw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;754&quot; /&gt;

&lt;p&gt;&lt;span&gt;第五层境界 ：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们开始晋升为仰望星空的人， 之前那些分类赚钱的应用太无聊了。 机器视觉搞科学怎么港？ 作为一群仰望星空后观察细胞的人，我们最常发现的是我们得到的天文或者细胞图片的噪声实在太大了， 这简直没法忍啊， 然后， 深度学习给了你一套降噪和恢复图像的方法。 一个叫auto-encoder的工具， 起到了很大的作用 ， 刷的一下，图像就清楚了。&lt;/span&gt;&lt;/p&gt;


&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.24027777777777778&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pJcbXOYHicuJB6QkiafzP6gp8GkcP0rTIhh1zcwXWYsVAuddMtecbZVDA/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;797&quot; /&gt;
&lt;p&gt;&lt;span&gt;这还不是最酷炫的，那个应用了博弈理论的对抗学习， 也可以帮你谋杀噪点！ 如果你会对抗所谓GAN， 也是一种图像生成的工具， 让网络去掉噪声的图片，与没有噪声的自然图片， 连卷积网络都判别不出来，对， 就是这样！&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5606936416184971&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pmRuSYRGgC2Hz0fia9n1SKWpEW5vC0ReFpLibhWHHOkootXOWhI3IzJNQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;519&quot; width=&quot;519&quot; /&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.25&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pIicCIdGK2w2AaziaYHALia2cRRUgwibdU6J84xiaX5gfMibY81mbNMOtuiaPg/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;806&quot; /&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;&gt;&lt;/ins&gt; &lt;span&gt;Schawinski, Kevin, et al. &quot;Generative adversarial networks recover features in astrophysical images of galaxies beyond the deconvolution limit.&quot; Monthly Notices of the Royal Astronomical Society: Letters 467.1 (2017): L110-L114.&lt;/span&gt;



&lt;p&gt;&lt;span&gt;第六重境界 ：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在工业界赚够了钱，科学也太nerd了， 我们来玩艺术思考哲学 ，第一招， 图像风格迁移，请见&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383188&amp;amp;idx=1&amp;amp;sn=ec8d1090fe46741c14ccf7cc02b57c2c&amp;amp;chksm=84f3cbd5b38442c33ef70b698dd07f5b7aa954623fe3724e9f83b8e10a44b86a3777054395a4&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;怎么样用深度学习取悦你的女朋友（有代码）&lt;/span&gt;&lt;/a&gt;&lt;span&gt;：&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.6904761904761905&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8paO6E4iaLY8ruEAE6G4PPCuicWXGSICQCZeXUzcdVMfiaRvbPibhK0PMdnw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;714&quot; width=&quot;714&quot; /&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.43333333333333335&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pDadLaRicMiajia9wJtp4DM49hWZ9WmwTc9Cia3fe6mvEvR3VnibLpl7AgwQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot; width=&quot;600&quot; /&gt;


&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.2119487908961593&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8piaCt4IcpJNvDic7nnHMMh9YzL3onemYkfBGy8uy0gmiaJsIaNt6IKYSiaw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;703&quot; width=&quot;703&quot; /&gt;

&lt;p&gt;&lt;span&gt;然而真正能玩好这一事项的，还是那个刚刚提过的对抗学习GAN， 比如大名鼎鼎的CycleGAN， 几乎可以实现一种你自定义的“图像翻译” 功能，而且你不用做标注哦， 拿出冬天和夏天的两组图片， 它会自动的在两组图片中找出对应来。&lt;/span&gt;&lt;/p&gt;


&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.4791666666666667&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p2zXHUFQ3QBxgSVj7DKOaAibucGLrVJmcumwaDLhwpLic7Yy7NrO6o9icw/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;963&quot; /&gt;&lt;span&gt;Zhu, Jun-Yan, et al. &quot;Unpaired image-to-image translation using cycle-consistent adversarial networks.&quot; arXiv preprint arXiv:1703.10593 (2017).&lt;/span&gt;


&lt;p&gt;&lt;span&gt;第七重境界：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;图像翻译也懒的玩了， 你神经网络不是号称能够理解图像，看你来个无中生有，在噪声里生成图片来？&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;对，依然是GAN，而且是最基础的卷积GAN (DCGAN)就可以给你干出来。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;看看GAN所幻想的宾馆情景， 你能想到是计算机做的图吗？ 哈哈哈！&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.23194444444444445&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pibZlT5DL1c0ibHtng9H2UdDVyStfea2SfZy6oVf3jbLdeQtvVicY4Xp5Q/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;912&quot; /&gt;&lt;span&gt;Goodfellow, Ian, et al. &quot;Generative adversarial nets.&quot; Advances in neural information processing systems. 2014.&lt;/span&gt;&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.5347222222222222&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8p6MVDPc4s5NsFmZnha7m8qUxGFIUicyGCYNMvBCllDoWohGrq8yBFMKQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;744&quot; /&gt;

&lt;p&gt;&lt;span&gt;写到这里， 我自己都觉得GAN是非常有前途的，有前途的，有前途的，以前我还以为只是好玩呢。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这里展示的七级浮屠，也不过深度学习被人类discover的冰山一角， 醉卧沙场君莫笑， 古来征战几人回。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;给你一个稍微清晰一些的大纲：&lt;/span&gt;&lt;/p&gt;

&lt;img class=&quot;origin_image zh-lightbox-thumb lazy&quot; data-ratio=&quot;0.39444444444444443&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcegduosx5P7Kdx0tNF22S8pZIxvp9LSmFuO5owzINicw9a9HlL9nNJ8W2WZEBCmeHO9JJL6Uib7GMvQ/0?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;720&quot; width=&quot;914&quot; /&gt;
&lt;p&gt;&lt;span&gt;如果对基础理论部分有不熟悉，请返回文章&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383212&amp;amp;idx=1&amp;amp;sn=e6dbbda2acc5984c8d06e24ec9c84d09&amp;amp;chksm=84f3cbedb38442fb58f0aea635821fcf4ba3edaacef4685716c7eadb6191197ebfa70a6bf14b&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;你不能不知道的CNN&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，当然它只是冰山一角， 了解更多并挨个实战请关注：巡洋舰的&lt;/span&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383029&amp;amp;idx=1&amp;amp;sn=a792653f736540e06d96e6f3970264e0&amp;amp;chksm=84f3cab4b38443a2754072d8b3d3fdade7ea503b15ecea46595bb149edcc139000b7f315e624&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;深度学习实战课程&lt;/span&gt;&lt;/a&gt;&lt;span&gt;， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛。刚刚讲的方法都将在课程里详细展开。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;目前课程线下版本已经基本报名完毕（特殊申请可加一到两个名额）， 为了缓解众多异地学员的需求， 我们提出一个线上加线下的课程简版， 课程包括全部课程视频， notebook作业， 和一个课程模块的来京线下实践机会， 名额限5名，预报从速，详情请联系陈欣&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfCFEFrIh4CD3HnwF5a6d9gqk3NhIsY8ThV50SQ5ut1tiaRVs5lSnvrYRqWuJNgxJTXTZ9fu54micsw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; class=&quot;&quot; data-ratio=&quot;1&quot; data-w=&quot;720&quot; /&gt;&lt;/p&gt;


</description>
<pubDate>Sat, 23 Dec 2017 04:45:54 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/FDI5UwW9rA</dc:identifier>
</item>
<item>
<title>再谈江歌案——情绪正义，还是程序正义？</title>
<link>http://www.jintiankansha.me/t/Zzyt0kLNZc</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/Zzyt0kLNZc</guid>
<description>&lt;p&gt;&lt;span&gt;今天，江歌被害案在日本东京开始审理。这是一场万众瞩目的悲剧，我和你们一样，都在期待真相，期待正义女神的天平终于静止，利剑得以挥下。&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcccoM20SegGqedLD4G6kcv3q4acibACxvVVzYAP1yaU9MnTrBNvgOSYItzdRJWSZrJuDwv6smia656w/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;1.43875&quot; data-w=&quot;800&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;（古罗马正义女神Justitia，由justice一词转变而来）&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;可是不要忘了，正义女神最大的特征是蒙眼，因为司法纯靠理性，不靠感官印象。耶鲁法学院教授Cover曾写过：“蒙眼不是失明，是自我约束”，接着另起一行：&lt;strong&gt;“程序是正义的蒙眼布”&lt;/strong&gt;。这句话已作为格言收入法学词典，每每被人引证。&lt;/p&gt;

&lt;p&gt;所以谈生死，写法律，必须抱有最大限度的客观与克制，才能执笔。我不是法官，没有生杀予夺的权力，也不是卫道士，无意口诛笔伐，随手钉耻辱柱。&lt;/p&gt;

&lt;p&gt;我们首先要达成一个共识：&lt;strong&gt;带有偏见和信息不全的报导，和动辄喊打喊杀的舆论，绝无助于正义的到来。&lt;/strong&gt;公正只取决于两个东西：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;真相，程序。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-w=&quot;490&quot; /&gt;&lt;/p&gt;

&lt;p&gt;关于前者，我不敢做任何叙述和推断——抛开当事人和目击者，不谈警察取证、司法鉴定和法院卷宗，没有任何人、机构和媒体，有资格在庭审结束以前，把自以为是结论，编给公众听。&lt;/p&gt;

&lt;p&gt;我不是针对谁，说的就是某些个媒体，请有一点法律常识，或者药店碧莲。请报导既有的事实，不要肆意煽动情绪，更不要妄下结论，盗图打码前请看下日期。&lt;/p&gt;

&lt;p&gt;一个月前，江歌案在朋友圈流传不下十个版本，一篇篇写的身临其境，好像作者们就在现场组团围观一样。麻烦你们，这辈子去过日本吗？去过现场吗？看过笔录吗？知道证人和律师叫啥吗？&lt;/p&gt;

&lt;p&gt;今天被告律师主张过失杀人和正当防卫，曾在你们栩栩如生的版本里出现过吗？&lt;/p&gt;

&lt;p&gt;舆论干预司法为何如此敏感？&lt;strong&gt;因为三人成虎、众口熏天，在信息不全、报导不实的情况下，极有可能以讹传讹，草菅人命。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-w=&quot;490&quot; /&gt;&lt;/p&gt;

&lt;p&gt;再说后者，程序正义，是刑事审判的保险锁，是法律具备公信力的保障。这四个字写起来简单，其含义和理论却极复杂，所以经常成为自媒体写作的雷区与盲区。&lt;/p&gt;

&lt;p&gt;Justice must not only be done, but must be seen to be done. 用中文说，就是事儿不仅要做的好，还要做得好。&lt;/p&gt;

&lt;p&gt;即：&lt;strong&gt;公正的结果（实体正义），与获得结果的方式（程序正义）是否公正，同等重要。&lt;/strong&gt;只有判决过程符合公正的要求，裁判结论才能得到人们的普遍认可。由此，法制的威信力才会高于法西斯束棒。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcccoM20SegGqedLD4G6kcv3ADK5NSlRbY4hXHZia2JqOxWNGQBGeWk40w0NYJ8CibmsUsqTWfAfiaCXg/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.9982758620689656&quot; data-w=&quot;580&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;束棒代表权力和威信的意义一直延续到今天&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;拿江歌案来说，今天是开庭第一天，整个庭审和宣判将用时七日，一切才刚开始。陈世峰律师提出“刘鑫递刀，正当防卫，过失杀人”，只是单方面的陈述。&lt;strong&gt;单一言词证据，没有经过庭审质证，没有经过控辩双方交锋，没有得到主审法官的采信，是没有任何法律效力的。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;接下来，检方还要举证，证人还要出庭，证物、证词还要交叉验证、双方还要法庭辩论，在法槌落地之前，还有严格冗长的程序要走。此时我们能做的，是冷静和耐心等待，而非见风是雨、人云亦云。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-w=&quot;490&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在来说本案的核心：&lt;strong&gt;陈世峰是否构成正当防卫，能否逃脱死刑？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实在抱歉，我是数学系的，只能从逻辑上分析。从今早庭审的供述来看，有两个核心，直接决定陈的行为是蓄意谋杀，还是激情过失杀人：&lt;/p&gt;

&lt;p&gt;（1）刀是谁的？&lt;/p&gt;
&lt;p&gt;（2）刀是谁先拿出来的？&lt;/p&gt;

&lt;p&gt;现在的证据证词十分矛盾：警方在陈的研究室发现同款刀壳，但“不能确定是否就是凶器的外壳”；陈世峰则称“刀是刘鑫从屋里递给江歌的”，在争夺过程中刺伤江歌致死。&lt;/p&gt;

&lt;p&gt;孰真孰假，还需等刘鑫出庭作证，综合警方调查结果和法医鉴定，才能逐渐让这块信息拼图得以完满，我们才有可能更接近真相。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcccoM20SegGqedLD4G6kcv3CG5zLo1hhm1QfkBf4ia9e5UqWSE8u2XibJNAb8Q5t3b46icFyicaY5xB3Q/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;1.4283333333333332&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;图/澎湃新闻&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;平心而论，江歌颈部11到12处刀伤，还能辩解为正当防卫，此为初刻拍案惊奇。别说人了，你能连续捅一只鸡5刀试试？一般人连第二刀都握不稳。我也奇怪，杀人犯为逃脱死刑的证词，网民们都能照单全收，可谓二刻拍案惊奇。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-w=&quot;490&quot; /&gt;&lt;/p&gt;

&lt;p&gt;之后的几天，我们都会持续关注本案的进展。写到这里，我只想说，无论如何，一个生命就这样逝去了，每天还有数不清的悲剧上演。有的我们听得到，更多的我们听不到，想到这里，悲从中来，不可断绝。&lt;/p&gt;

&lt;p&gt;听报导说江歌妈妈想要寻死，无奈这么多人的关注与希冀压身。我想这真是世间最悲痛的感觉：哀莫大于心死，寻死不能，却又生不如死。&lt;/p&gt;

&lt;p&gt;惟愿公道在人间，上穷碧落下黄泉。&lt;/p&gt;





&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfWnH5bhxesLmmviahTl8tWKugO5svyoeZw2RJdKe7n8VmibgPpdAoEibec4qD28qoQ4J7PwRW9CyTXA/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;

</description>
<pubDate>Tue, 12 Dec 2017 02:55:38 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/Zzyt0kLNZc</dc:identifier>
</item>
<item>
<title>我也许不配我的同情心</title>
<link>http://www.jintiankansha.me/t/ubWaudqv0Y</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/ubWaudqv0Y</guid>
<description>&lt;p&gt;10年之前，美国各地都展开了影响深远的强拆行为，寒冬之际，不少家庭在短短几天之内，从自家的住的公寓被赶出去，而只得住在坏境更加差的汽车旅馆中，甚至不得不举家露宿街头。我描述的这件事，叫做次贷危机。那些在次贷危机中被赶出家的人，有多少是真正了解或者想去了解那些未来高到离谱的还款条件的。人可以有梦想，但若是完全超越了现实，那就是妄想，就是贪欲，不值得被鼓励。&lt;/p&gt;

&lt;p&gt;十年之后，面对朋友圈爆棚的同情心，实在忍不住想写点什么。很多人都熟悉《了不起的盖茨比》的作者说过那句话，同时保有全然相反的两种观念,还能正常行事,是第一流智慧的标志。而另一位常常出现在所谓的中产嘴里的智慧导师查理芒格也说过，&lt;em&gt;如果我要拥有一种观点，如果我不能够比全世界最聪明、最有能力、最有资格反驳这个观点的人更能够证否自己，我就不配拥有这个观点。&lt;/em&gt;先让我们记住这俩句话，如果你觉得他们说的有道理。接着我们来看看最近最容易被404的话题，折叠的首都。&lt;/p&gt;

&lt;p&gt;在一片404的海洋中，我们其实只是看到了一方的观点，而没有看到另一方的观点。这些写文章的作者们似乎都没有想过另一方的逻辑，不过这并不怪他们，有句话说得好，不在其位，不谋其政。那些转发404的伙伴，有多少实地去看过群租房，去体验过低端行业里的生活究竟是怎样的，又有多少看过哪怕是一个小镇的经济数据，或者管理过一个村庄。在没有获得完整的信息的时候，你是不配去批评权威的。世界本来就是这么残酷，话语权要依靠自己的思考来争取，没有人可以永远生活在童话里。&lt;/p&gt;

&lt;p&gt;你若是想要写出一篇不被404的文，你要做的是先真正想清楚自己的论点有什么问题，什么地方可以怎样被证伪，被反驳。你要能看到站在楚河汉界的两方各自的难处和不得已，看出他们各自的逻辑都说的通，然后还能给出自己的解决方案。若是做不到这一点，那你的观点多半是噪音的概率大一些。看到这里，作为读者的你可以用《了不起的盖茨比》的话来反驳我，“&lt;em&gt;每逢你想要批评任何人的时候，你就记住，这个世界上所有的人，并不是个个都有过你拥有的那些优越条件。”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;的确，并不是每一个人都能做到时刻保持理智的头脑，时刻不被感情所挟持。但这不应该成为每一个有独立意识的公民所毕生追求的目标吗？如同内省能力，独立思考的能力并不是天生的，唯有艰辛的训练才能获得。可为什么等到了修炼的关键时刻，你们就只是从众的转发，难道就不能发出些不同的声音吗？&lt;/p&gt;

&lt;p&gt;这篇文章背后的读者又忍不住的冒了出来，难倒忘了昆德拉说过的刻奇了吗？反媚俗本身往往还是一种媚俗。昆德拉借书中人物的口说道，&lt;em&gt;你是站在媚俗的对立面的。但是他们不能摆脱媚俗，媚俗是人类的博爱，媚俗是枷锁，但是媚俗是让人能够将双脚放在地面上的力量。&lt;/em&gt;读者会说我最讨厌这样的理中客了，我就要展示我的同情心，因为我是一个活生生的人。&lt;/p&gt;

&lt;p&gt;好，那我们先谈同情心，之后再来谈媚俗。同情心不是点亮蜡烛，也不是转发404，而是要看看实际的行动。而想到转发的伙伴多半自己也是上个月刚刚自嘲过的困难群众，也就不应该要求他们去捐钱，那每个人至少有几件旧衣服，家里有几本不需要的书吧。那这些衣服，你们总可以洗干净，捐出去了吧。但是你们有这么做吗？有发动你的朋友一起捐旧衣和旧书吗？同情心永远不应该只是谈谈而已。当你羡慕英国火灾后的人情味，但是这背后的基础是基督教文化传统。要传递同情心，去行动比去只是发言更有效果。&lt;/p&gt;

&lt;p&gt;回到媚俗的话题。媚俗的根源就是对生命的绝对认同。昆德拉如是说。这话也说到了点子上。很多人都熟悉的三体中有澳洲移民的那一段，有这么一句话，生存本来就需要争取,什么时候成了理所当然?”而在三体结束的段落，歌者唱完“我看到了我的爱恋”，片刻后，向太阳系随手丢出了二向箔。在歌者的话里，我看到了相似的媚俗。《遥远的救世主》中写道&lt;em&gt;生存法则很简单，就是忍人所不忍，能人所不能，忍是一条线，能又是一条线，这个两者之间就是生存空间。&lt;/em&gt;这个规则从生命诞生后就没变过，未来也不会变。&lt;/p&gt;

&lt;p&gt;引用知乎用户殷泉夜的话：&lt;em&gt;用爱解决悬殊问题是多么可笑的想法。退一万步讲，任何个体都只会爱与自己差不多平等的个体，就像人可能爱上另一个人或者一个猩猩一条鱼，却不会爱上一个细菌或者草履虫。&lt;/em&gt;而对于工作在写字楼，没有住过带着隔间的群租房的人来说，你们的发言，和歌者的歌曲，又有什么区别，同样是让人细思极恐。一方面对未来充满焦虑，想通过终身学习提升自己，而这实际上是在限制那些你们同情的人群的发展上限，而另一方面，你们又想通过发言，来表示自己的社会责任心和道德情操。&lt;/p&gt;

&lt;p&gt;还是《生命不可承受之轻》中的话，&lt;em&gt;“令她反感的，远不是世界的丑陋，而是这个世界所戴的漂亮面具。”&lt;/em&gt; 都是成年人了，应该活在现实中，都应该试着去追求主人的道德观，而不是弱者的，依赖强者的道德期望而意外获得的渴望救世主的道德观。所以我不是为了反媚俗而反对，而是为了让更多人看到这个社会残酷却每时每刻都在上演的每个人对每个人的战争真相。&lt;/p&gt;

&lt;p&gt;有文章拿大公司裁员时只给半小时收拾个人物品，来类比最近发生的事。而我这里则是拿美国的次贷危机来类比。最近的争论，从本质上看，其实可以看成是一个很古老的问题，也就是用一个不恰当的手段去做一件长期上有价值也必须要做的事，是不是有错。从一方面来讲，产业升级的重要性这里不需要多讲，违规的群租房如果程序正义上没有问题，就应当做到有法必依。而从另一方面来讲，其中的手段的确有值得诟病值得改进的地方。至于能不能，该不该用大局这样抽象的词语掩盖过去，则是个人的道德问题，而不该是法律问题。舆论应该通过指出问题来影响未来的立法，而不应该通过情绪的宣泄来干扰当前的执法。&lt;/p&gt;

&lt;p&gt;让舆论干扰法制的后果，已经在西欧接受中东难民的事上显现了出来。当年默克尔在难民上受到了民意的影响，没有坚持自己本来的政策，从而使得当前的德国多少受了本来不该有的冲击。我这篇很早就写好的文，拖到现在才想发，就是觉得虽然知道观点肯定会受到抨击，然而毕竟是向往过千万人吾往矣的人。这件事情上看得透的人不会忧心，他们知道事情已经发生，要关注的是未来如何在乡村造血，使得这些人能够融入社会的合作网络中。&lt;/p&gt;

&lt;p&gt;这篇文章刻意不去谈论法律的对错，我知道我的背景不配说这个，对于自己不了解的，就该保持沉默。但我知道，当众人都在指责一个人或者一个抽象的机构时，这是很危险的很恐怖的。好的文化应该是具有内省而不是仅仅会向外去指责的，这会限制个人去解读不该被忽略的细节，会使得他容易被有心人或者媒体煽动，去做出一些他们长大后会后悔的事情来。&lt;/p&gt;

&lt;p&gt;萧伯纳有句话：人人有权争胜负,无人有权论是非。我不喜欢一心只争论是非，但不解决实际问题，也不能帮助读者成长的文字。然而我似乎不应该去苛责过多，论语中有这样的话，&lt;em&gt;孟氏使阳肤为士师,问于&lt;/em&gt;&lt;em&gt;曾子&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;em&gt;曾子&lt;/em&gt;&lt;em&gt;曰：“上失其道,民散久矣.如得其情,则哀矜而勿喜.”&lt;/em&gt; 士师就是典狱官，这里的曾子说的是在上位的人失去了和百姓交流的通道,百姓早就离心离德了.你如果能弄清他们的情况,就应当怜悯他们,而不要自鸣得意，也不要以执政者无道为理由而藐视对法律的尊严。真正的怜悯是把自己置身在他人那里，我住过的最类似群租房是实习那三个月的八人一间的小宿舍，然而那毕竟是合法的，有管理登记的。在苦水里泡的不够久，我也许还配不上拥有同情心。&lt;/p&gt;

&lt;p&gt;那就在最后说说怎么样的发言，才能算是有信息量的。你可以叙述发生了什么，但你要格外的克制，不在记叙中夹杂自己的评论和情绪，要记录一个事件各方面的参与者，要在记叙中只用那些你亲眼所见的，或者是有据可查的信息。你也可以去做分析，但分析是比记录更难的事情，你需要全面的系统性的去看，要保持前瞻性，需要对人性的多样有深刻的了解。当然最简单的还是去传播，但传播的时候你自己要去选择，选择那些不是那么情绪化的。现代社会是一个非常复杂的整体，情绪这种系统一给出的快速的反馈多半是不适合的，我们需要在面对复杂的问题时，以复杂对抗复杂。&lt;/p&gt;

&lt;p&gt;对于一件事情，除了法律的观点之外，还会有道德，文化，经济，宗教的观点，在任何一种观点的偏废，都是不好的。因此传播的时候，也要注意多样化。当然，应对复杂最好的方法还是去行动。你可以去用行动在实际上帮助那些你觉得值得同情的人，你可以做的不止是捐捐捐，你也许会觉得明年那些被赶走的人又会回到新的群租房里，那时也许一些企业会给他们也许会有更高一些的工资，更好的工作坏境，然后他们的产品也会涨价，到时你们应该还会记得怎么用脚投票吧。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;


&lt;p&gt;更多阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383164&amp;amp;idx=1&amp;amp;sn=0cfac710d4d5783ed06bbdb694828409&amp;amp;chksm=84f3cb3db384422b11c90bf7826cc7b52a3f74176442fb28e6ebc27b5e44c9d1ef33f39d077e&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;多余的话 借深度网络说说最近发生的几件事&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;









</description>
<pubDate>Sat, 02 Dec 2017 15:36:56 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/ubWaudqv0Y</dc:identifier>
</item>
</channel>
</rss>