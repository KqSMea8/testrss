<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fchaoscruiser-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/chaoscruiser-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fchaoscruiser-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>混沌巡洋舰</title>
<link>http://www.jintiankansha.me/column/ultiWL8Axg</link>
<description>混沌巡洋舰 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>[原创]脑洞用深度学习来做三国杀的AI</title>
<link>http://www.jintiankansha.me/t/CzAiwMy52B</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/CzAiwMy52B</guid>
<description>&lt;p&gt;看着神经网络攻克了一个又一个的游戏，从围棋到星际争霸再到德州扑克，作为一名三国杀的玩家，忍不住就想能不能用深度学习来做一做三国杀这款游戏的AI，于是在这里脑洞一下，看看深度学习和三国杀能擦出怎样的火花。&lt;/p&gt;

&lt;p&gt;机器学习总体分来，有三大框架，如同一家人中大的三兄弟，大哥最稳重，也是这家人的顶梁柱，对应的是我们最熟悉，应用最广泛也最成熟的是有监督学习，只要和预测有关的，那就属于有监督学习的了。而与之对应的无监督学习则是潜力股，其做的事虽然多，但却比不上大哥和小弟出名。而机器学习中最年轻的则当属强化学习了，他最能出风头，最爱上头条，也最容易引起人们对于强机器智能，也就是机器统治人类的恐惧。&lt;/p&gt;

&lt;p&gt;究其原因，是应为不同于前两种模型，只会给出用户建议，强化学习的目标是去直接进行行动。就拿三国杀的游戏AI举个例子，若是用的模型是有监督学习，那么其做的是在你选将的时候帮你预测你选择哪一个武将胜率大，但不会自己做决定。而无监督学习是在游戏的进行中帮你分析哪一个是忠臣，哪一个是主公，而强化学习做的则是直接设计出一个AI，从头到尾战胜你。&lt;/p&gt;

&lt;p&gt;强化学习的英文是reinforce， re这个词根强调了重复，也就是说学习需要一次一次而不可以一蹴而就。force则是取推动的意思，也就是有推动或者指导着学习的方向。至于学习的内容什么，一言而概括是通过做出正确的决策来生存下来。强化学习不关心是否能够准确的预测未来，只关心自己当下的决策对未来的自己影响如何。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;不说这些空话，我们来看具体的三国杀中的例子，若是传统的设计一个AI来玩这个游戏，有一派的思路是针对游戏中的每一个决策，例如一开始选择哪个武将，之后攻击那个人，对谁使用技能，针对每一个决策，预先设定一些固定的规则，比如攻击主公的就是反贼，给主公桃子就是忠臣，然后再根据积累的游戏记录，去决定上面的哪些规则更加靠谱，并通过规则间的组合，得出更强大的AI。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;然而这样的预先设定好的规则，是受制于最初设定的限制的规则集合的，用机器学习的行话来说，就是数据集的特征提取是由人手工完成的。而若是通过深度学习的方式，其最大的特点是由机器来随机生成的特征提取规则，在经过训练数据的检验，留下适合的，再逐步改进那些看起来还可以的规则。这样做的好处是能够发明很多新的思路，对于三国杀这样相对简单的游戏，人类可以说穷尽了所有的小技巧，但对于围棋则不然，这也解释了为什么alpha zero最近能推出教柯结下棋的最新版工具，其表现出的创新不是来自于人类式的思考（类似于问as if 式的问题），而是自然选择的结果。&lt;/p&gt;

&lt;p&gt;下面来说说为什么深度学习要足够的神，若是只有一层的神经网络，那么神经网络能学到的规则就是，杀主公的就是反。然而对于更复杂的情况，就无法进行表示了。例如如果主公是专职卖血的武将，那么一开始攻击主公的就不一定是反而是忠。而一个多层的神经网络就能够处理这样的情况。用机器学习界的行话来说，也就是随着网络深度的增加，模型的容量也随之增加，从而能够处理更为复杂的特征。&lt;/p&gt;

&lt;p&gt;下一个问题是强化学习学的是什么，这里说的是强化学习中最常用的Q learning，强化学习中有状态(state)、动作(action)、奖赏(reward)这三个要素。AI需要根据当前状态来采取动作，获得相应的奖赏之后，再去改进这些动作，使得下次再到相同状态时，智能体能做出更优的动作。为了达到这一目标，AI要不断调整自己给自己的奖励，也就是Q value， 这里的Q为动作效用函数（action-utility function），用于评价在特定状态下采取某个动作的优劣。&lt;/p&gt;

&lt;p&gt;这么说好抽象的，还是用三国杀的例子。例如让程序相互之间玩游戏，游戏胜利的时候，给那些胜利的AI根据自己的身份，奖励相应的得分，从而使得下一轮这些AI能够更容易生存下去，然而对于当下的每一个选择来说，怎么给分了。想象一个AI在面临选将的时候该选刘备还是孙权的问题的时候，AI的做法是和同样的一群AI，在相同的情景下玩100次，然后发现使用孙权赢了5次，使用刘备一次没有赢，从而决定在今后较少的使用刘备。这种方法的背后，就是所谓的蒙特卡罗随机取样。&lt;/p&gt;

&lt;p&gt;接着上面的例子，若是AI决定了用孙权比刘备胜率高，但是随着其他AI的进化，AI之间变得更加会配合了，这时用刘备的胜率就高了，而若是AI坚持过去的结论，那么AI就无法探索新的战术了，所以在之前的例子中，AI所作的也不是完全不用刘备，而只是少用刘备，这就是为了平衡当前最优和未来的最优值，即要探索，也要利用好当前已知的规律。&lt;/p&gt;

&lt;p&gt;总结一下，这篇小文介绍了机器学习中的强化学习。先说了强化学习的目地是什么，即做出一个能在给定的坏境下通过做出恰当决策生存下来的智能体。再说了通过深度神经网络来做的优点，即能不受人为经验的限制，得出新的且足够复杂规则，用来简化数据，从而超越人类的偏见和定式，最后说了强化学习是怎么做的，即要学习的是如何判定当前决策的奖励，同时平衡探索新规律和利用旧规律。&lt;/p&gt;

&lt;p&gt;扩展阅读&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651383042&amp;amp;idx=1&amp;amp;sn=5992f31b4e9bb688a0c797d2c1517aca&amp;amp;chksm=84f3cb43b38442559adbb162a27698d91f4097aba2a546d83b591aeaf14c64912de527d197bf&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;用游戏中的情景来讲解常见的8种机器学习算法&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如果你对强化学习或深度学习感兴趣，&lt;/strong&gt;&lt;strong&gt;欢迎关注&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzA3MzQwNzI3OA==&amp;amp;mid=2651382937&amp;amp;idx=1&amp;amp;sn=d4510592a837c44fe75393c2578698d8&amp;amp;chksm=84f3cad8b38443ce6adcd155a2c45ee7707b4a9d8e48c05728aa7e93862475832bf89617025f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;巡洋舰的深度学习实战课程&lt;/a&gt;， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;目前课程线下版本已经基本报名完毕（特殊申请可加一到两个名额）， 为了缓解众多异地学员的需求， 我们提出一个线上加线下的课程简版， 课程包括全部课程视频， notebook作业， 和一个课程模块的来京线下实践机会， 名额限5名，预报从速，&lt;/span&gt; &lt;/strong&gt;&lt;strong&gt;有兴趣的可加 陈欣 微信 ： &lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfCFEFrIh4CD3HnwF5a6d9gqk3NhIsY8ThV50SQ5ut1tiaRVs5lSnvrYRqWuJNgxJTXTZ9fu54micsw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;800&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;




</description>
<pubDate>Thu, 21 Dec 2017 15:31:08 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/CzAiwMy52B</dc:identifier>
</item>
<item>
<title>再谈江歌案——情绪正义，还是程序正义？</title>
<link>http://www.jintiankansha.me/t/Zzyt0kLNZc</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/Zzyt0kLNZc</guid>
<description>&lt;p&gt;&lt;span&gt;今天，江歌被害案在日本东京开始审理。这是一场万众瞩目的悲剧，我和你们一样，都在期待真相，期待正义女神的天平终于静止，利剑得以挥下。&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcccoM20SegGqedLD4G6kcv3q4acibACxvVVzYAP1yaU9MnTrBNvgOSYItzdRJWSZrJuDwv6smia656w/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;1.43875&quot; data-w=&quot;800&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;（古罗马正义女神Justitia，由justice一词转变而来）&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;可是不要忘了，正义女神最大的特征是蒙眼，因为司法纯靠理性，不靠感官印象。耶鲁法学院教授Cover曾写过：“蒙眼不是失明，是自我约束”，接着另起一行：&lt;strong&gt;“程序是正义的蒙眼布”&lt;/strong&gt;。这句话已作为格言收入法学词典，每每被人引证。&lt;/p&gt;

&lt;p&gt;所以谈生死，写法律，必须抱有最大限度的客观与克制，才能执笔。我不是法官，没有生杀予夺的权力，也不是卫道士，无意口诛笔伐，随手钉耻辱柱。&lt;/p&gt;

&lt;p&gt;我们首先要达成一个共识：&lt;strong&gt;带有偏见和信息不全的报导，和动辄喊打喊杀的舆论，绝无助于正义的到来。&lt;/strong&gt;公正只取决于两个东西：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;真相，程序。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-w=&quot;490&quot; /&gt;&lt;/p&gt;

&lt;p&gt;关于前者，我不敢做任何叙述和推断——抛开当事人和目击者，不谈警察取证、司法鉴定和法院卷宗，没有任何人、机构和媒体，有资格在庭审结束以前，把自以为是结论，编给公众听。&lt;/p&gt;

&lt;p&gt;我不是针对谁，说的就是某些个媒体，请有一点法律常识，或者药店碧莲。请报导既有的事实，不要肆意煽动情绪，更不要妄下结论，盗图打码前请看下日期。&lt;/p&gt;

&lt;p&gt;一个月前，江歌案在朋友圈流传不下十个版本，一篇篇写的身临其境，好像作者们就在现场组团围观一样。麻烦你们，这辈子去过日本吗？去过现场吗？看过笔录吗？知道证人和律师叫啥吗？&lt;/p&gt;

&lt;p&gt;今天被告律师主张过失杀人和正当防卫，曾在你们栩栩如生的版本里出现过吗？&lt;/p&gt;

&lt;p&gt;舆论干预司法为何如此敏感？&lt;strong&gt;因为三人成虎、众口熏天，在信息不全、报导不实的情况下，极有可能以讹传讹，草菅人命。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-w=&quot;490&quot; /&gt;&lt;/p&gt;

&lt;p&gt;再说后者，程序正义，是刑事审判的保险锁，是法律具备公信力的保障。这四个字写起来简单，其含义和理论却极复杂，所以经常成为自媒体写作的雷区与盲区。&lt;/p&gt;

&lt;p&gt;Justice must not only be done, but must be seen to be done. 用中文说，就是事儿不仅要做的好，还要做得好。&lt;/p&gt;

&lt;p&gt;即：&lt;strong&gt;公正的结果（实体正义），与获得结果的方式（程序正义）是否公正，同等重要。&lt;/strong&gt;只有判决过程符合公正的要求，裁判结论才能得到人们的普遍认可。由此，法制的威信力才会高于法西斯束棒。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcccoM20SegGqedLD4G6kcv3ADK5NSlRbY4hXHZia2JqOxWNGQBGeWk40w0NYJ8CibmsUsqTWfAfiaCXg/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.9982758620689656&quot; data-w=&quot;580&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;束棒代表权力和威信的意义一直延续到今天&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;拿江歌案来说，今天是开庭第一天，整个庭审和宣判将用时七日，一切才刚开始。陈世峰律师提出“刘鑫递刀，正当防卫，过失杀人”，只是单方面的陈述。&lt;strong&gt;单一言词证据，没有经过庭审质证，没有经过控辩双方交锋，没有得到主审法官的采信，是没有任何法律效力的。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;接下来，检方还要举证，证人还要出庭，证物、证词还要交叉验证、双方还要法庭辩论，在法槌落地之前，还有严格冗长的程序要走。此时我们能做的，是冷静和耐心等待，而非见风是雨、人云亦云。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-w=&quot;490&quot; /&gt;&lt;/p&gt;

&lt;p&gt;现在来说本案的核心：&lt;strong&gt;陈世峰是否构成正当防卫，能否逃脱死刑？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实在抱歉，我是数学系的，只能从逻辑上分析。从今早庭审的供述来看，有两个核心，直接决定陈的行为是蓄意谋杀，还是激情过失杀人：&lt;/p&gt;

&lt;p&gt;（1）刀是谁的？&lt;/p&gt;
&lt;p&gt;（2）刀是谁先拿出来的？&lt;/p&gt;

&lt;p&gt;现在的证据证词十分矛盾：警方在陈的研究室发现同款刀壳，但“不能确定是否就是凶器的外壳”；陈世峰则称“刀是刘鑫从屋里递给江歌的”，在争夺过程中刺伤江歌致死。&lt;/p&gt;

&lt;p&gt;孰真孰假，还需等刘鑫出庭作证，综合警方调查结果和法医鉴定，才能逐渐让这块信息拼图得以完满，我们才有可能更接近真相。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcccoM20SegGqedLD4G6kcv3CG5zLo1hhm1QfkBf4ia9e5UqWSE8u2XibJNAb8Q5t3b46icFyicaY5xB3Q/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;1.4283333333333332&quot; data-w=&quot;600&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;图/澎湃新闻&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;平心而论，江歌颈部11到12处刀伤，还能辩解为正当防卫，此为初刻拍案惊奇。别说人了，你能连续捅一只鸡5刀试试？一般人连第二刀都握不稳。我也奇怪，杀人犯为逃脱死刑的证词，网民们都能照单全收，可谓二刻拍案惊奇。&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcczHDIiaWOR2dPFBtH8RttCZLu0icHb4T1zLe45Lb7ib7pYYZTkwsbibdV5ia5bTIeqOtP3u1AoPpnFGAg/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.12857142857142856&quot; data-w=&quot;490&quot; /&gt;&lt;/p&gt;

&lt;p&gt;之后的几天，我们都会持续关注本案的进展。写到这里，我只想说，无论如何，一个生命就这样逝去了，每天还有数不清的悲剧上演。有的我们听得到，更多的我们听不到，想到这里，悲从中来，不可断绝。&lt;/p&gt;

&lt;p&gt;听报导说江歌妈妈想要寻死，无奈这么多人的关注与希冀压身。我想这真是世间最悲痛的感觉：哀莫大于心死，寻死不能，却又生不如死。&lt;/p&gt;

&lt;p&gt;惟愿公道在人间，上穷碧落下黄泉。&lt;/p&gt;





&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibcfWnH5bhxesLmmviahTl8tWKugO5svyoeZw2RJdKe7n8VmibgPpdAoEibec4qD28qoQ4J7PwRW9CyTXA/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.5625&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;

</description>
<pubDate>Tue, 12 Dec 2017 02:55:38 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/Zzyt0kLNZc</dc:identifier>
</item>
<item>
<title>R 语言中的深度学习 Minst数据集下的聚类分析</title>
<link>http://www.jintiankansha.me/t/grFZrWsqEf</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/grFZrWsqEf</guid>
<description>&lt;p&gt;&lt;span&gt;本文为巡洋舰的深度学习实战课程 预科准备。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;说到深度学习，想到的都是python中的框架，例如tensorflow。然而R语言作为另一种数据科学家常用的工具，也不会缺席深度学习的盛宴的。今天为大家介绍一个来自R语言的包（package），名叫h2o，相比tensorflow，他的功能虽然不够强大，可能无法实现CNN，RNN这种特殊的结构，但却可以满足日常数据分析和建模的应用。&lt;/p&gt;

&lt;p&gt;这个包的安装简单，只需一行命令就可以搞定，不管是在notebook中，还是R的自带的运行坏境，只要输入install.package(&quot;h2o&quot;), 然后选择相应的镜像服务器，就可以安装完成了。h2o这个包功能强大，不止包含深度学习的模型，还包括工程界流行树模型，例如xgBoost，随机森林等，还包括自然语言处理中的word2vec，由于这个包是由由java实现底层代码的，其运算速度相对较快。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;而h2o这个包中和深度学习有关的函数是deeplearning这个函数，这个函数既可以用来训练常见的分类模型，用来做有监督学习；也可以用来做无监督学习，对数据进行聚类。而对于用深度学习的模型来进行聚类，则是这里要介绍的要点，也就是自编码器。&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;无监督学习的目的是为了展示出那些没有带标签的数据之间的关系。一种常见的应用场景是数据降维，也就是将原来的高纬度数据投影到2维，从而使人们可以清楚的看到其间的关系。而用来评价数据降维的效果好坏，有一套常用的数据集，也就是分类中常用的MINST，手写数字的照片集，如下图。&lt;/p&gt;


&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceCicV64SRTQnx3BRq4k511ZtNQx32nw4EmRFvgoXnq4b9SEVKFCMXOMcELC0VWOV5pkg6d81BdcVA/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.7423423423423423&quot; data-w=&quot;555&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而分类的任务是给定一个数据，由算法模型来预测这个数字究竟是几，而聚类的任务，则是去看看能不能相同的数字放到一起，常用的聚类方法有PCA和tsne， 其中tsne是效果较好的一种方法。下图分别是用PCA 和tsne'做聚类得到的结果，不同的颜色代表不同的数字，我们看到各个类之间还是分得比较开的。而之所以tsne效果要好于pca，那是因为tsne能更好的处理非线性的变换，从而造成较少的信息丢失。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceCicV64SRTQnx3BRq4k511ZSJETWx8QNbWf8wGiae19HVib8FHxHNg3HiczzmquQ7zbmj5jjUg6HoQZg/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.8079561042524005&quot; data-w=&quot;729&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceCicV64SRTQnx3BRq4k511ZvUWlHSMEyNhrNJGcxhSdyicl0UKOHIseECczRGS5LP5PuPpB9VWL6Rw/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;1.1&quot; data-w=&quot;1280&quot; /&gt;&lt;/p&gt;


&lt;p&gt;而深度学习，则天生适合处理非线性的情况，所以从理论上来说，使用深度学习，也可以做到较好的聚类。自编码器是一种神经网络的结构，其左右互博的思路，有些类似GAN。一个神经网络用来降低维度，另一个网络用来从降维的信息中恢复出尽可能多的信息，整个神经网络的目标是使得恢复出的数据尽可能的和原始的数据相类似。&lt;/p&gt;

&lt;p&gt;&lt;img data-backh=&quot;301&quot; data-backw=&quot;556&quot; data-w=&quot;820&quot; data-ratio=&quot;0.5414634146341464&quot; class=&quot;&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibceCicV64SRTQnx3BRq4k511ZSsT4Ehrz0jSZU1G6LrK659ZGMdic3rFFIqXt1exz8ZWDHv0pAzYIfWA/0?wx_fmt=png&quot; data-copyright=&quot;0&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以上的神经网络中，输入的信息有4维，经过一层名叫编码器的神经网络的降维，变成了2维的，也就是中间那俩个隐藏层的输出，之后进过4个解码器中人工神经元的处理，由恢复成了4维，这就是一个最基本的自编码器。&lt;/p&gt;

&lt;p&gt;而将许多个单层的编码器和解码器按照顺序堆叠起来，就构成了更强大的深度自编码器，如下图所示。先是将5维变成4维3维再变成2维，之后再按顺序升维。而要获得降维后的表示，只要看看中间那俩个神经元的输出就好。&lt;/p&gt;

&lt;p&gt;好，我们来看看在R 语言的h2o包中如何实现深度自编码器。首先是导入包，&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;library(h2o) 这一句就行了，之后是导入训练数据&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;mfile =&lt;/code&gt; &lt;code class=&quot;r string&quot;&gt;&quot;D:\R_Projects\MNIST\MNIST_DIGITStrain.csv&quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;MDIG =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;h2o.importFile&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(path = mfile,sep=&lt;/code&gt;&lt;code class=&quot;r string&quot;&gt;&quot;,&quot;&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;之后要做的就是去规定模型了，这里的函数有很多参数，每一个读者都可以在了解后观察其对模型效果的影响，这里大多数采取了默认值。&lt;br /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;NN_model =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;h2o.deeplearning&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;x = 2:785,&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;training_frame = MDIG,&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;hidden =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;c&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(400, 200, 2, 200, 400 ),&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;epochs = 600,&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;activation =&lt;/code&gt; &lt;code class=&quot;r string&quot;&gt;&quot;Tanh&quot;&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;,&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r spaces&quot;&gt;  &lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;autoencoder =&lt;/code&gt;  &lt;ins class=&quot;adsbygoogle&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;6787195013&quot; data-ad-format=&quot;auto&quot;&gt;&lt;/ins&gt; &lt;code class=&quot;r keyword&quot;&gt;TRUE&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这里x 指出了使用数据中的第2列到第785 列，第一列是该行突袭对应的数字标签，这里不用，第二行是告诉模型使用的训练数据是之前导入的MINST，第三个参数指定了有多少可隐藏神经元，最初是400个，之后是200个，最后是2个，再进行升维，第四个参数是说模型最多训练400轮，第五个函数是每个神经元的激励函数是什么，这里是双曲正切Tanh函数，最后一个参数是指定这里是一个自编码器而不是分类器。&lt;/p&gt;

&lt;p&gt;接着我们来看看模型的效果，第一幅图是用自编码器画出的，第二副则是由h2o这个包中的线性聚类方法SVD画出的，明显看起来第一幅要比第二副好的的，当然自编码器要慢一些，需要350秒来完成训练，而SVD只需要6.5 秒。有兴趣的小伙伴可以自己试试不同的网络结构，看看会不会得出更好的效果。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;train_supervised_features2 =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;h2o.deepfeatures&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(NN_model, MDIG, layer=3)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;plotdata2 =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;as.data.frame&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(train_supervised_features2)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;r plain&quot;&gt;plotdata2$label =&lt;/code&gt; &lt;code class=&quot;r functions&quot;&gt;as.character&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(&lt;/code&gt;&lt;code class=&quot;r functions&quot;&gt;as.vector&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(MDIG[,1]))&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;r functions&quot;&gt;qplot&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;(DF.L3.C1, DF.L3.C2, data = plotdata2, color = label, main =&lt;/code&gt; &lt;code class=&quot;r string&quot;&gt;&quot;Neural network: 400 - 200 - 2 - 200 - 4000 &quot;&lt;/code&gt;&lt;code class=&quot;r plain&quot;&gt;)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceCicV64SRTQnx3BRq4k511ZMfRMrSCIUnicFBDJalm7f8VmE2lzQ7gzySGuwGib2ChZjvI684DmiaiaBA/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.9076376554174067&quot; data-w=&quot;563&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-s=&quot;300,640&quot; data-type=&quot;jpeg&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/dcEP2tDMibceCicV64SRTQnx3BRq4k511Z1iaLXNDyDakIGGlfuwVrkQw9hjxpHomnlu2vWXRnSSc9ASklzhgGfTA/0?wx_fmt=jpeg&quot; data-copyright=&quot;0&quot; class=&quot;&quot; data-ratio=&quot;0.6305506216696269&quot; data-w=&quot;563&quot; /&gt;&lt;/p&gt;

&lt;p&gt;总结一下，在R平台下，也可以进行深度学习，而且可以进行聚类和数据降维。自编码器作为一种常见的非监督学习框架，在未来也会有广泛的应用。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;欢迎关注巡洋舰的深度学习实战课程&lt;/span&gt;&lt;span&gt;， 手把手带你进行深度学习实战， 课程涵盖机器学习，深度学习， 深度视觉， 深度自然语言处理， 以及极具特色的深度强化学习，看你能不能学完在你的领域跨学科的应用深度学习惊艳你的小伙伴，成为身边人眼中的大牛。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;原创不易，随喜赞赏&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9397590361445783&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.100weidu.com/get?src=http://mmbiz.qpic.cn/mmbiz_png/dcEP2tDMibcd4icdSNQnx98Zicw7nnP3icPycqI1uRMvRxCezhYm4xQKdbiamvHVmC19a0o7YS03eqTrIL9QJS4wS4w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;249&quot; width=&quot;auto&quot; /&gt;&lt;/p&gt;

</description>
<pubDate>Thu, 30 Nov 2017 20:32:57 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/grFZrWsqEf</dc:identifier>
</item>
</channel>
</rss>