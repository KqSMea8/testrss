<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fmathalg-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/mathalg-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fmathalg-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fmathalg-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>算法与数学之美</title>
<link>http://www.jintiankansha.me/column/c9dZ5TM2aS</link>
<description>算法与数学之美 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>图像风格迁移(Neural Style)简史</title>
<link>http://www.jintiankansha.me/t/0FSDKj3uVS</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/0FSDKj3uVS</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.6583333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/BkqApBic36NPgZbq8EGVpMutQIrNbsMtwGbE5dbibfHo6j7ibR9V3x1ic4WGSoOPrlR2XicdpX1jXfMyfPQ44XL3c5g/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot;/&gt;&lt;span&gt; 图像风格迁移科技树&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;


&lt;section class=&quot;&quot; data-mpa-template-id=&quot;410350&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1&quot;&gt;&lt;section data-mpa-template-id=&quot;234998&quot; class=&quot;&quot; data-mpa-color=&quot;null&quot; readability=&quot;2&quot;&gt;&lt;h2/&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;什么是图像风格迁移？&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;先上一组图。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;以下每一张图都是一种不同的艺术风格。作为非艺术专业的人，我就不扯艺术风格是什么了，每个人都有每个人的见解，有些东西大概艺术界也没明确的定义。如何要把一个图像的风格变成另一种风格更是难以定义的问题。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;对于程序员，特别是对于机器学习方面的程序员来说，这种模糊的定义简直就是噩梦。到底怎么把一个说都说不清的东西变成一个可执行的程序，是困扰了很多图像风格迁移方面的研究者的问题。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.7833333333333333&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMUQKibXqPvhH0brXibDc00tw0z52nNniaMB7QOT5CtL6cNfAuGQ22zmlzw/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在神经网络之前，图像风格迁移的程序有一个共同的思路：分析某一种风格的图像，给那一种风格建立一个数学或者统计模型，再改变要做迁移的图像让它能更好的符合建立的模型。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这样做出来效果还是不错的，比如下面的三张图中所示，但一个很大的缺点：一个程序基本只能做某一种风格或者某一个场景。因此基于传统风格迁移研究的实际应用非常有限。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.285&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMt2mIEYLImTaU5nJKHKK0V6J19lIYicnHibsibv6cnyFibgfC7ysrmIiaP3w/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;
&lt;h6&gt;&lt;span&gt;景色照片时间迁移&lt;/span&gt;&lt;/h6&gt;
&lt;p&gt;&lt;span&gt;改变了这种现状的是两篇Gatys的论文，在这之前让程序模仿任意一张图片画画是没法想象的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.1383333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMsH3ibyAVJDicdhico8PJiaG3VWKPC9znYV5ZsP1YtEibHT49pc7ysCqTe2g/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;span&gt;第一个基于神经网络的图像风格迁移算法，生成时间：5-20分钟&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我想试着从头开始讲起，从Gatys et al., 2015a和Gatys et al., 2015b中用到的一些技术的历史开始讲起，用最简单的方法说清楚基于神经网络的图像风格迁移的思路是什么，以及Gatys为什么能够想到使用神经网络来实现图像风格迁移。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如果大家对这个感兴趣的话，我将来可以继续写一些关于Neural Style最新的一些研究的进展，或者其他相关的一些图像生成类的研究，对抗网络之类的。写的有错误的不到位的地方请随意指正。&lt;/span&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;410350&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1&quot;&gt;&lt;section data-mpa-template-id=&quot;234998&quot; class=&quot;&quot; data-mpa-color=&quot;null&quot; readability=&quot;2&quot;&gt;&lt;h2/&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;Neural Style元年前20年-前3年&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;要理解对于计算机来说图片的风格是什么，只能追根溯源到2000年以及之前的图片纹理生成的研究上。明明是图像风格迁移的文章，为什么要说到图片纹理？在这儿我先卖个关子吧。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;据我所知，在2015年前所有的关于图像纹理的论文都是手动建模的，其中用到的最重要的一个思想是：纹理可以用图像局部特征的统计模型来描述。没有这个前提一切模型无从谈起。什么是统计特征呢，简单的举个例子——&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.3666666666666667&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMOfvuSWEsTT3TetGc1epoIu21o1kqNCSWevibr9lCJ65GBxWibUILNuPg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot;/&gt;&lt;span&gt;早期纹理生成结果&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;与此同时，图像风格迁移也并无建树，甚至比纹理生成还惨。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;因为纹理生成至少不管生成什么样子的纹理都叫纹理生成，然而图像风格迁移这个领域当时连个合适的名字都没有，因为每个风格的算法都是各管各的，互相之间并没有太多的共同之处。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;比如油画风格迁移，里面用到了7种不同的步骤来描述和迁移油画的特征。又比如头像风格迁移里用到了三个步骤来把一种头像摄影风格迁移到另一种上。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;以上十个步骤里没一个重样的，可以看出图像风格处理的研究在2015年之前基本都是各自为战，捣鼓出来的算法也没引起什么注意。相比之下Photoshop虽然要手动修图，但比大部分算法好用多了。&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.44666666666666666&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbM8yw9SNGb6t6icgV1bbMluhpkSBicULwKdJLGxiatvmYyVJdibXgh46BvKQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;span&gt; 头像风格迁移&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.32&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMdlNCxLeQ2koN0BWRksibAI9JosOE6e5ysUnEOBCYf4Qpge9qkichMAHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/span&gt;&lt;span&gt;油画风格迁移&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;同一个时期，计算机领域进展最大的研究之一可以说是计算机图形学了。简单的来说计算机图形学就是现在几乎所有游戏的基础，不论是男友1(战地1)里穿越回一战的战斗场景，还是FGO之类的手游，背后都少不了一代又一代的图形学研究者的工作。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在他们整日整夜忙着研究如何能让程序里的妹纸变成有血有肉的样子的时候，点科技树点出了一个重要的分支：显卡（GPU）。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;游戏机从刚诞生开始就伴随着显卡。显卡最大的功能当然是处理和显示图像。不同于CPU的是，CPU早期是单线程的，也就是一次只能处理一个任务，GPU可以一次同时处理很多任务，虽然单个任务的处理能力和速度比CPU差很多。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;比如一个128x128的超级马里奥游戏， 用CPU处理的话，每一帧都需要运行128x128=16384歩，而GPU因为可以同时计算所有像素点，时间上只需要1步，速度比CPU快很多。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;为了让游戏越来越逼近现实，显卡在过去20年内也变得越来越好。巧合的是，显卡计算能力的爆炸性增长直接导致了被放置play十几年的神经网络的复活和深度学习的崛起，因为神经网络和游戏图形计算的相似处是两者都需要对大量数据进行重复单一的计算。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;可以说如果没有游戏界就没有深度学习，也就没有Neural Style。所以想学机器学习先得去steam买东西，支持显卡研究。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5733333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMncUtg9Jnvj6yLAdmQmIz2nqsIECibEaMUoVKKgFZTnTU4uuj9g8y2mQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot;/&gt;&lt;/span&gt;&lt;span&gt; ImageNet物体识别比赛中使用GPU的队伍数量逐年上升，错误率逐年下降&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;提到神经网络我想稍微讲一下神经网络（特别是卷积神经网络）和传统做法的区别，已经有了解的可以跳过本段。卷积神经网络分为很多层，每一层都是由很多单个的人工神经元组成的。可以把每个神经元看作一个识别器，用刚刚的栗子来说的话，每一个或者几个神经元的组合都可以被用来识别某个特征，比如栗子的开口。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在训练前它们都是随机的，所以啥都不能做，训练的过程中它们会自动的被变成一个个不同的识别器并且相互组合起来，大量的识别器组合起来之后就可以识别物体了。整个过程除了一开始的神经网络的设计和参数的调整之外其他全是自动的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.4517857142857143&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbM2pNXBZ4ibVK3C78WmaA0CmHHYK3UxJrKyK0UwozJqS9lt5aeQcpyZbg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;560&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h6&gt;&lt;span&gt;卷积神经网络图例&lt;/span&gt;&lt;/h6&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;410350&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot; readability=&quot;1&quot;&gt;&lt;section data-mpa-template-id=&quot;234998&quot; class=&quot;&quot; data-mpa-color=&quot;null&quot; readability=&quot;2&quot;&gt;&lt;h2/&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;Neural Style元年前3年-前1年&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;2012-2014年的时候深度学习刚开始火，火的一个主要原因是因为人们发现深度学习可以用来训练物体识别的模型。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;之前的物体识别模型有些是用几何形状和物体的不同部分比较来识别，有些按颜色，有些按3d建模，还有一些按照局部特征。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;传统物体识别算法中值得一提的是按照比较局部特征来识别物体，其原理如下。比如我们的目标是在图片之中找到这个人：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.2380952380952381&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMmDpXYLeN4DJDTGY0wdYdfmFBc6UibyWDcibnZlrqVpMwuZEIicM65ATJg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;147&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;目标物体&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;对于程序而言这个人就是一堆像素嘛，让它直接找的话它只能一个个像素的去比较然后返回最接近的了（近邻算法）。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;但是现实中物体的形状颜色会发生变化，如果手头又只有这一张照片，直接去找的速度和正确率实在太低。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;有研究者想到，可以把这个人的照片拆成许多小块，然后一块一块的比较(方法叫Bag of Features)。最后哪一块区域相似的块数最多就把那片区域标出来。这种做法的好处在于即使识别一个小块出了问题，还有其他的小块能作为识别的依据，发生错误的风险比之前大大降低了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.2965116279069768&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMsbxQyfVjqdKqXLyJ2pKeNMl3ibUWx7mibfabrmZvGbHqgiaDsibt33caTg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;344&quot; width=&quot;298.672px&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; Bag of Features&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这种做法最大的缺点就是它还是把一个小块看成一坨像素然后按照像素的数值去比较，之前提到的改变光照改变形状导致物体无法被识别的问题根本上并没有得到解决。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;用卷积神经网络做的物体识别器其实原理和bag of features差不了太多，只是把有用的特征(feature)都装到了神经网络里了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt;  刚提到了神经网络经过训练会自动提取最有用的特征，所以特征也不再只是单纯的把原来的物体一小块一小块的切开产生的，而是由神经网络选择最优的方式提取。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9964285714285714&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMTYTD1uCBgIcfe3nlDO3MiapUplS92ic0gIPFa6yGYSm5Y0QG8nFnAzwg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;560&quot;/&gt;&lt;/p&gt;
&lt;h6&gt;&lt;span&gt;卷积神经网络提取的特征示意图，每一格代表一个神经元最会被哪种图片激活&lt;/span&gt;&lt;/h6&gt;
&lt;h6&gt;&lt;span&gt;卷积神经网络当时最出名的一个物体识别网络之一叫做VGG19，结构如下：&lt;/span&gt;&lt;/h6&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.75&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMDroxj5k4495d94UowNOVyvHU07x98pb0AAWowG3zkjenTSZRzhKmUQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot;/&gt;&lt;/span&gt;&lt;span&gt;VGG19网络结构&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;每一层神经网络都会利用上一层的输出来进一步提取更加复杂的特征，直到复杂到能被用来识别物体为止，所以每一层都可以被看做很多个局部特征的提取器。VGG19在物体识别方面的精度甩了之前的算法一大截，之后的物体识别系统也基本都改用深度学习了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;因为VGG19的优秀表现，引起了很多兴趣和讨论，但是VGG19具体内部在做什么其实很难理解，因为每一个神经元内部参数只是一堆数字而已。每个神经元有几百个输入和几百个输出，一个一个去梳理清楚神经元和神经元之间的关系太难。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;于是有人想出来一种办法：虽然我们不知道神经元是怎么工作的，但是如果我们知道了它的激活条件，会不会能对理解神经网络更有帮助呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;于是他们编了一个程序，（用的方法叫back propagation，和训练神经网络的方法一样，只是倒过来生成图片。）把每个神经元所对应的能激活它的图片找了出来，之前的那幅特征提取示意图就是这么生成的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;有人在这之上又进一步，觉得既然我们能找到一个神经元的激活条件，那能不能把所有关于“狗’的神经元找出来，让他们全部被激活，然后看看对于神经网络来说”狗“长什么样子的？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;长得其实是这样的：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.625&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMuuh9yMLDfhtHQjUo4MqTtxmdVKG4rKEAJTbUia1hxE1K1k7h7JdyCBw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot;/&gt;&lt;/span&gt;&lt;span&gt;神经网络想象中的狗&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这是神经网络想象中最完美的狗的样子，非常迷幻，都可以自成一派搞个艺术风格出来了。而能把任何图片稍作修改让神经网络产生那就是狗的幻觉的程序被称作deep dream。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5633333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMvU22E3XozoBC09nIxQt0ZoOg7p9pxdh15Xd7RvUHB7UHfia8NuHuysg/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot;/&gt;&lt;/span&gt;&lt;span&gt;Deep Dream&lt;/span&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;410350&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section data-mpa-template-id=&quot;234998&quot; class=&quot;&quot; data-mpa-color=&quot;null&quot;&gt;&lt;h2/&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;Neural Style元年&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;有了这么多铺垫，一切的要素已经凑齐，前置科技树也都已经被点亮了，现在进入正题了。基于神经网络的图像风格迁移在2015年由Gatys et al. 在两篇论文中提出：Gatys et al., 2015a和Gatys et al., 2015b。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Gatys et al., 2015a论文地址：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;http://t.cn/R9cnTeQ&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Gatys et al., 2015b论文地址：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;https://arxiv.org/abs/1508.06576&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们先说第一篇。第一篇比起之前的纹理生成算法，创新点只有一个：它给了一种用深度学习来给纹理建模的方法。之前说到纹理生成的一个重要的假设是纹理能够通过局部统计模型来描述，而手动建模方法太麻烦。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;于是Gatys看了一眼隔壁的物体识别论文，发现VGG19说白了不就是一堆局部特征识别器嘛。他把事先训练好的网络拿过来一看，发现这些识别器还挺好用的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;于是Gatys套了个Gramian matrix上去算了一下那些不同局部特征的相关性，把它变成了一个统计模型，于是就有了一个不用手工建模就能生成纹理的方法。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.75&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMAGicNwTvFicRFdEkEv2W7s9vw4Dt4QvrHPgdBWRw2G8b3PK7ib8vVTAHQ/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/span&gt;&lt;span&gt;基于神经网络的纹理生成算法&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;从纹理到图片风格其实只差两步。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;第一步也是比较神奇的，是Gatys发现纹理能够描述一个图像的风格。严格来说文理只是图片风格的一部分，但是不仔细研究纹理和风格之间的区别的话，乍一看给人感觉还真差不多。第二步是如何只提取图片内容而不包括图片风格。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;span&gt;这两点就是他的第二篇论文做的事情：Gatys又偷了个懒，把物体识别模型再拿出来用了一遍，这次不拿Gramian算统计模型了，直接把局部特征看做近似的图片内容，这样就得到了一个把图片内容和图片风格（说白了就是纹理）分开的系统，剩下的就是把一个图片的内容和另一个图片的风格合起来。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;合起来的方法用的正是之前提到的让神经网络“梦到”狗的方法，也就是研究员们玩出来的Deep Dream，找到能让合适的特征提取神经元被激活的图片即可。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.805&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMoT2eqlFyqqKn3sJ91vvYWoLHJlvoqibdQDBq7F2WLJQ5rETU34yAOHg/640?wx_fmt=png&quot; data-type=&quot;png&quot; data-w=&quot;600&quot;/&gt;&lt;/span&gt;&lt;span&gt;基于神经网络的图像风格迁移&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;至此，我们就把关于基于神经网络的图像风格迁移(Neural Style)的重点解释清楚了。背后的每一步都是前人研究的结果，不用因为名字里带深度啊神经网络啊而感觉加了什么特技，特别的高级。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Gatys所做的改进是把两个不同领域的研究成果有机的结合了起来，做出了令人惊艳的结果。其实最让我惊讶的是纹理竟然能够和人们心目中认识到的图片的风格在很大程度上相吻合。（和真正的艺术风格有很大区别，但是看上去挺好看的。）从那之后对neural style的改进也层出不穷，在这里就先放一些图，技术细节暂且不表。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.9114391143911439&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMw4DZxxOgOXV8sKRMe3Jibr74DllNG3e7YRPxibkW7NBfpuaDyzG1BLGw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;542&quot;/&gt;改进后的图像风格迁移算法&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;左：输入图像，中：改进前，右：改进后。生成时间：5-20分钟&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.715&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMgOdjZNOXpXCb36R21T51VXFees9FBs5jpPpEt9o3KvTvTHueaFiaEzQ/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot;/&gt;&lt;span&gt;多个预设风格的融合，生成时间：少于1秒，训练时间：每个风格1-10小时&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;1.2933333333333332&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMaIo5Q09icfliaWa3ibwN9pKX1DgZHb3rV6VBfEIL6YVnrmZicANGs7JAXw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot;/&gt;&lt;/span&gt;&lt;span&gt;最新的实时任意风格迁移算法之一，生成时间：少于10秒（少于一秒的算法也有，但个人认为看上去没这个好看），训练时间：10小时&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.8483333333333334&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/BkqApBic36NOcsWfbjV5VHQ6hBNsylcbMJXmO25uhlKsxyhh22BQSiacqRfbBiajMBvJjjW5l0GnibxOIHANT9zxLA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot;/&gt;&lt;span&gt;图片类比，生成时间：5-20分钟&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;最后安利一篇与本文无关的文章，Research Debt 是我写本文的动机，希望对相关阅读有所帮助。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Research Debt 地址（英文）：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;https://distill.pub/2017/research-debt/&lt;/span&gt;&lt;/p&gt;

&lt;h5&gt;&lt;span&gt;作者：李嘉铭&lt;/span&gt;&lt;/h5&gt;
&lt;h5&gt;&lt;span&gt;Northwestern University | CS&lt;/span&gt;&lt;/h5&gt;
&lt;p&gt;&lt;span&gt;知乎专栏：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;https://zhuanlan.zhihu.com/p/26746283&lt;/span&gt;&lt;/p&gt;

&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot;&gt;&lt;p&gt;&lt;span&gt;∑编辑&lt;span&gt; | &lt;/span&gt;Gemini&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;来源 | 乌镇智库&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;__bg_gif&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.9366666666666666&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/951TjTgiabkwJ4BpvBcQhGAbtWZZvV69s7GickZGibsKgYkTQkiaZfLYOmGS9iaaoibadibGJhT18OVZkfeJmCSUSD0zw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;600&quot; width=&quot;auto&quot;/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/section&gt;
&lt;p&gt;&lt;span&gt;算法数学之美微信公众号欢迎赐稿&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;稿件涉及数学、物理、算法、计算机、编程等相关领域&lt;br/&gt;稿件一经采用，我们将奉上稿酬。&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;&lt;span&gt;投稿邮箱：math_alg@163.com&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Sun, 04 Feb 2018 19:28:15 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/0FSDKj3uVS</dc:identifier>
</item>
<item>
<title>36小时，造一个亚马逊无人商店</title>
<link>http://www.jintiankansha.me/t/kU50zcHkx3</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/kU50zcHkx3</guid>
<description>&lt;p data-mpa-powered-by=&quot;yiban.io&quot;&gt;&lt;span&gt;无人超市，未来趋势。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;上面这段视频，展示了逛亚马逊的Amazon Go无人超市是种怎样的体验。毫无疑问，一个完善的无人超市需要复杂的技术支撑。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;现在，挑战来了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;你能不能在一天半的时间里，从零着手搭建出一个基本的Amazon Go无人超市系统？让客户可以体验无缝衔接的购物体验？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;当然可以。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;有个四人小组就在最新的一次黑客马拉松中，完成了这样一次挑战。他们只用了不到36个小时，就搞定了一切，而且还把整个教程公布了出来。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先，得有一套文档，列出全部需要做/可以做的事情；然后就是根据文档，去分模块实现。他们给自己的“山寨”Amazon Go起名叫EZShop，由这六大模块构成：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.7399660825325043&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBWo96VpyBL8DtFhGdzA1HSibbfQYRCyN9DgFAEItP0VXrC0YbdZlOzQywgT41LgjRz39QjnQ0Llww/640?&quot; data-type=&quot;png&quot; data-w=&quot;1769&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;EZShop的六大组件&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;下面分别介绍一下他们用到的些模块：&lt;/span&gt;&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;410350&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section data-mpa-template-id=&quot;234998&quot; class=&quot;&quot; data-mpa-color=&quot;null&quot;&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;Kairos人脸识别API&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/h2&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;这是EZShop的一个基本组件，能够识别、存储特定的人脸信息。EZShop用了它两个API：/enroll和/verify。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;/enroll的意思是“拍张照，找到里边的脸，然后把这张脸存到你创建的相册里。”&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这个小组就为顾客们创建了一个相册，也叫EZShop。顾客注册时，脸就会存到这个相册里，系统的实时数据库也会向这个顾客的注册信息返回并存储一个face_id。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;当要验证顾客的照片时，就需要把它送到/verify终端那里，终端返回一个匹配可能性最高的face_id。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在实际应用中，自己用TensorFlow搭一个人脸识别应用可能比用这种API更好，但是36小时hackathon嘛，API挺好用的。&lt;/span&gt;&lt;/p&gt;
&lt;section class=&quot;&quot; data-mpa-template-id=&quot;410350&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section data-mpa-template-id=&quot;234998&quot; class=&quot;&quot; data-mpa-color=&quot;null&quot;&gt;&lt;h2&gt;&lt;span&gt;实时Firebase数据库&lt;br/&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;这也是一个非常基本的组件，整套EZShop里，所有其他的组件都得和它实时交互。Firebase支持在数据库里的任何数据上创建定制化的变化监听器，这样一个特性再加上简单的设置流程，用起来简直毫不费力。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;整个计划很简单，数据库存储一组商品、一组顾客，如下面的JSON文件架构所示：&lt;/span&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;br/&gt;&lt;span&gt;{
  &quot;items&quot;: [
    {
      &quot;item_id&quot;: 1,
      &quot;item_name&quot;: &quot;Soylent&quot;,
      &quot;item_stock&quot;: 1,
      &quot;price&quot;: 10
    }
  ],
  &quot;users&quot;: [
    {
      &quot;face_id&quot;: 1,
      &quot;name&quot;: &quot;Subhan Nadeem&quot;,
      &quot;in_store&quot;: false,
      &quot;cart&quot;: [
        1
      ]
    }
  ]
}&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;span&gt;新顾客通过Kairos API注册之后，就会被添加到users那一组。当顾客出入时，他的in_store布尔值会更新，在商店经理和个人App界面上都有所体现。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;顾客拿起商品时，items那组数据会有更新。系统能够识别出哪个顾客拿了哪件商品，商品的ID会被添加到顾客的cart栏。&lt;/span&gt;&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;410350&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section data-mpa-template-id=&quot;234998&quot; class=&quot;&quot; data-mpa-color=&quot;null&quot;&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;经理App和顾客App&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/h2&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;团队里的iOS开发者John只用了12小时，就写完了这两个App。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.75&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBWo96VpyBL8DtFhGdzA1HS0iaxDHK3uxV2pbxXSo4XTJRs8I45vtibDIYdRrVr1TNNwc1VpNhWicAQw/640?&quot; data-type=&quot;png&quot; data-w=&quot;1600&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;经理App&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;经理App是iPad版的，能将新用户添加到Kairos API和Firebase数据库中，也能显示店里顾客的列表和货物的库存清单。商店经理能用这个App操作Firebase数据库、查看数据库发生的变化。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这个App还能追踪店内当前的所有用户，并获取他们的姓名和照片。当用户离开时，这个系统也能实时更新店内当前用户列表。&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; 
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.7786666666666666&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBWo96VpyBL8DtFhGdzA1HSbDQocOxB1N7ibibWohtXNjeGxZS5mc9Bg5yiaYBXWaytNDriaKjI2piaeicQ/640?&quot; data-type=&quot;png&quot; data-w=&quot;1125&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;顾客App&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;另一个App是供商店顾客用的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;顾客要进店，需要先上传自己的照片，注册成为可以在无人店内购物的用户。图片通过API上传到Imgur（一家国外图片分享网站），并与用户名相关联。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;EZShop会根据这个照片来识别顾客。顾客进入商店之后，它们购物车的更新会立刻显示在这个App上。顾客离开商店时，手机上还会收到一条推送通知，显示着他们花了多少钱。&lt;/span&gt;&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;410350&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section data-mpa-template-id=&quot;234998&quot; class=&quot;&quot; data-mpa-color=&quot;null&quot;&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;货架、传感器和摄像头&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/h2&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;这些东西由Soheil和Ruslan负责，他们设计了货架，写了相关的Pi Python脚本。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;货架大致长这样：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.1603585657370519&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBWo96VpyBL8DtFhGdzA1HS9DNgzR1ibqMzZY6cR96g0dK0DVQhOACrtibCpTE4icbMCBiaTRWdGk3DlA/640?&quot; data-type=&quot;png&quot; data-w=&quot;1004&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;货架&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在货架上，三件商品并排放着，中间的塔上安装监控摄像头（就是图上那个手机），两排商品后边还装有超声波传感器。超声波传感器和树莓派相连接，树莓派运行的Python脚本处理传感器与货架上物体之间的距离读数。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;商品被拿起来的时候，传感器的读数就会变化，触发数据库中商品库存的更新。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;塔顶上绑着的手机（摄像头）也会探测到场景的变化，还会识别拿商品的顾客。然后，这件商品会被放到顾客的虚拟购物车里。&lt;/span&gt;&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;410350&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section data-mpa-template-id=&quot;234998&quot; class=&quot;&quot; data-mpa-color=&quot;null&quot;&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;出入口的摄像头&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/h2&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;在商店的出口和入口，这个小组使用了Android手机作为面部识别摄像头。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;两部手机被安装在一个三脚架上，分别冲着相反的方向，一个方向用来识别入店的顾客，另一个方向用来识别出店的顾客。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;至于人脸检测技术，Google有一套非常棒的API，能够很好地检测出人脸。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;API地址：https://developers.google.com/vision/&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;特别的是，这个API还能提供从相机到人脸之间的大致距离，一旦顾客的距离足够近，摄像头就会拍照并使用Kairos API进行验证，然后与Firebase数据库同步，更新顾客在店内的状态。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在客户识别之外，系统还增加了个性化的语音问候，这进一步提升了用户体验。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;效果是这样的：&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;一旦顾客离开商店，Android应用程序将会检测顾客购买了什么商品，并计算消费总额，并通过Firebase云消息向顾客的个人App推送账单明细。&lt;/span&gt;&lt;/p&gt;

&lt;section class=&quot;&quot; data-mpa-template-id=&quot;410350&quot; data-mpa-color=&quot;null&quot; data-mpa-category=&quot;fav&quot;&gt;&lt;section data-mpa-template-id=&quot;234998&quot; class=&quot;&quot; data-mpa-color=&quot;null&quot;&gt;&lt;h2&gt;&lt;span&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/h2&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;在36个小时的黑客马拉松中，这个项目的团队大概只睡了6个小时，期间克服了许许多多的障碍，也有一些还未解决的问题。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;他们的努力也没有白费，这个项目最后夺得了第一名。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;有上百人进入了这个快速搭建的无人超市，拿起商品，然后离店，随即完成结算并获得账单。整个过程中不需要收银员、不需要排队……&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;&lt;span&gt;这个项目是开源的，想自己动手玩一下的话……GitHub地址在此：&lt;br/&gt;https://github.com/subhan-nadeem/EZShop&lt;/span&gt;&lt;/p&gt;
&lt;section data-style=&quot;white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);&quot; readability=&quot;2&quot;&gt;&lt;p&gt;&lt;span&gt;∑编辑&lt;span&gt; | &lt;/span&gt;Gemini&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;本文转载自「量子位」&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;__bg_gif&quot; data-copyright=&quot;0&quot; data-ratio=&quot;0.9366666666666666&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_gif/951TjTgiabkwJ4BpvBcQhGAbtWZZvV69s7GickZGibsKgYkTQkiaZfLYOmGS9iaaoibadibGJhT18OVZkfeJmCSUSD0zw/640?wx_fmt=gif&quot; data-type=&quot;gif&quot; data-w=&quot;600&quot; width=&quot;auto&quot;/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/section&gt;
&lt;p&gt;&lt;span&gt;算法数学之美微信公众号欢迎赐稿&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;稿件涉及数学、物理、算法、计算机、编程等相关领域&lt;br/&gt;稿件一经采用，我们将奉上稿酬。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;投稿邮箱：math_alg@163.com&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Sun, 04 Feb 2018 19:28:14 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/kU50zcHkx3</dc:identifier>
</item>
</channel>
</rss>