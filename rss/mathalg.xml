<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fmathalg-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/mathalg-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fmathalg-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fmathalg-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>算法与数学之美</title>
<link>http://www.jintiankansha.me/column/c9dZ5TM2aS</link>
<description>算法与数学之美 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>李开复：AI能在15年内取代40%~50％岗位</title>
<link>http://www.jintiankansha.me/t/p6FXLdFJEI</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/p6FXLdFJEI</guid>
<description>&lt;div id=&quot;&quot;&gt;
&lt;p&gt;&lt;span&gt;“概念火了会被玩儿坏。”这是9月2日，创新工场董事长兼CEO、人工智能科学家李开复博士在《AI·未来》新书发布会上的感叹。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;李开复表示，AI催生了一批公司进行AI概念包装，使得一些公司处于估值偏高的情况，但目前AI处于一个估值调整期，今年上半年已经有些项目估值下降了20%~30%，未来将会向合理趋势发展。待估值合理后，AI项目的投融资机会会更多。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;李开复还提到，在15年内，人工智能和自动化将具备取代40%~50％岗位的技术能力。不过，由于企业决策、工会影响和政府政策，实际过程中实现取代可能需要更长时间。&lt;/span&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;h3&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;15年内人工智能有能力取代5类工作&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;span&gt;2017年5月，人类围棋冠军先后输给人工智能算法“AlphaGo”后，掀起的人工智能话题热潮一浪高过一浪，李开复称这一事件为中国的“斯普特尼克”时间。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;2018年9月，李开复新书《AI·未来》在全球同步发售。《每日经济新闻》记者在现场获悉，在新书中，人工智能的发展被大致分为四波浪潮：互联网智能化（Internet AI）、商业智能化（Business AI）、实体世界智能化（Perception AI）、自主智能化（Autonomous AI）。每一波浪潮都运用了人工智能的不同能力，颠覆了不同的产业，让人工智能在日常生活中更加深入。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;李开复提到，中国人工智能技术快速发展，成为全球人工智能领域的重要拼图之一。过去3年，中国各地掀起了一波人工智能热潮，从科技界、商界、各级政府机关开始，一直蔓延到各行各业，甚至中小学和幼儿园的小朋友都在学习人工智能知识。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在李开复看来，基于当前技术的发展程度与合理推测，在15年内，人工智能和自动化将具备取代40%~50％岗位的技术能力。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这些岗位主要集中在以下工作和任务场景：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;重复性劳动——特别是在相同或非常相似的地方完成的工作，如洗碗、装配线检查、缝纫；&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;有固定台本和对白内容的各种互动，如客户服务、电话营销；&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;相对简单的数据分类，或思考不到1分钟就可以完成识别的工作，如文件归档、作业打分、名片筛选；&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在某公司一个非常狭小的领域工作，如银行理财产品的电话推销员、某部门的会计；&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;不需与人进行大量面对面交流的工作，如分拣、装配、数据输入。&lt;/span&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;h3&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;机器人进展比AI软件慢：它们仍然非常笨拙&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;span&gt;尽管AI大幅度提升生产效率，节省人力资本，但为了确保人类的职业生涯不会因人工智能替代而中断，需要了解“在可见的未来里，人工智能做不到什么”。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;李开复提到，虽然有媒体报道，称巨额投资将用于开发人工智能和机器人，但自动驾驶汽车、人工智能放射科医师等人工智能应用可能需要很长时间才能普及。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;“实际上在机器人和机械学方面取得进展比人工智能软件慢。机器人仍然非常笨拙，看看机器人拿铅笔的样子，你就会懂我的意思。”李开复表示，由于人工智能不擅长提出新概念、没有人类的情商，人类也不愿“信任”机器，让机器来处理人性化任务。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;因而有几类工作难以取代：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;创意性工作都，例如医学研究员、人工智能科学家、获奖剧本作家、公关专家、企业家；&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;复杂性/战略性工作，例如首席执行官、谈判专家、并购专家；&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;灵敏性工作，例如口腔外科医生、飞机机械师、脊椎按摩师。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;“我们应该具有战略性思维，并以人工智能无法取代的工作为目标。我们应该致力于终身学习，更新我们的技能，了解新趋势，并寻找新机遇。”李开复表示，应该积极使用人工智能工具，特别是专业人士，更多的数据和使用量能够使人工智能不断优化。同时应该使用上述工具来工作，保持开放态度，明确人工智能可以完成更多的日常任务，使人们能够关注更适合人类发展的领域。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;此外，李开复提到，应该鼓励批判性思维和各种创造力，不仅仅是科学和工程，还有艺术、建筑、音乐、诗歌、表演、讲故事等。应该接受传统工作岗位正在流失的现实。对于老年人，当需要提前退休时，请考虑接受，通过打零工和志愿服务赚取一些收入并过上喜欢的生活。&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;&lt;p helvetica=&quot;&quot; neue=&quot;&quot; pingfang=&quot;&quot; sc=&quot;&quot; hiragino=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; microsoft=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; px=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; caret-color:=&quot;&quot; text-align:=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; important=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;稿件涉及数学、物理、算法、计算机、编程等相关领域，经采用我们将奉上稿酬。&lt;/span&gt;&lt;/p&gt;</description>
<pubDate>Fri, 07 Sep 2018 20:55:05 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/p6FXLdFJEI</dc:identifier>
</item>
<item>
<title>数据从业者必读：抓取了一千亿个网页后我才明白，爬虫一点都不简单</title>
<link>http://www.jintiankansha.me/t/PL3lUE6OyC</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/PL3lUE6OyC</guid>
<description>&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkxgAnRBqqmCRx0BO9lJwAp4j6kP2K7BIbRIOcgmCxiax43Ud1RKjFCCuJARq6guEJYbKpYp73hbDcw/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;1000&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;现在爬虫技术似乎是很容易的事情，但这种看法是很有迷惑性的。开源的库/框架、可视化的爬虫工具以及数据析取工具有很多，从网站抓取数据似乎易如反掌。然而，当你成规模地在网站上抓东西时，事情很快就会变得非常棘手。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;自2010年以来抓取超过1000亿个产品页面，我们将会通过系列文章来分享从中学到的经验教训，让你深入了解从电子商务商店中规模析取数据时所面临的挑战，并且跟你分享应对这些挑战的某些最佳实践。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;本文是该系列文章的第一篇，在这里我们将提供规模抓取产品数据所面临主要挑战的概览，以及Scrapinghub从抓取1000亿产品页面中学到的经验教训。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;成立于2010年的Scrapinghub是领先的数据析取公司之一，也是当今最健壮和流行的web爬虫框架Scrapy的作者。目前Scrapinghub每月抓取许多全球最大型电子商务公司的页面数超过80亿（其中30亿是产品页面）。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;对于那些对规模爬取网页技术感兴趣但对要不要建立专门的web爬取团队或者外包给专门的web爬取公司的人来说，最好看看这个免费指南，企业web爬虫：规模化web爬取技术指南&lt;/span&gt;&lt;/p&gt;

&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section class=&quot;_135editor&quot; data-tools=&quot;135&amp;#x7F16;&amp;#x8F91;&amp;#x5668;&quot; data-id=&quot;90636&quot;&gt;&lt;section&gt;&lt;section data-width=&quot;100%&quot;/&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section class=&quot;135brush&quot; data-brushtype=&quot;text&quot;&gt;&lt;em&gt;规模爬取技术为什么重要？&lt;/em&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;&lt;span&gt;跟标准的web爬取应用不一样的是，规模爬取电子商务产品数据有一项独特挑战使得web抓取要困难许多。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;本质上这些挑战可归结为两件事情：&lt;strong&gt;速度和数据质量。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;由于时间通常是限制因素，规模抓取要求你的爬虫要以很高的速度抓取网页但又不能拖累数据质量。对速度的这张要求使得爬取大规模产品数据变得极具挑战性。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;&quot; data-ratio=&quot;0.5&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkxgAnRBqqmCRx0BO9lJwAp47tx7tibRQfQ8dguNhibAiciasD5Fv3jYp0icyRnzKKuaqP3lg3N19DVm6DA/640?wx_fmt=jpeg&quot; data-type=&quot;jpeg&quot; data-w=&quot;600&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt; 挑战#1——草率而且总是在变的网站格式 &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这一点很明显但也许不是最性感的挑战，但是草率而一直在变的网站格式是目前为止你在规模析取数据时将会面临的最大挑战。这未必是因为任务的复杂性，而是由于你要投入的时间和资源。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;如果你花过时间开发过电子商务商店的爬虫的话，你就会知道电子商务网站代码之草率是一种流行病。这可不仅仅是HTML完构性或者偶尔的字符编码问题。这些年来我们遇到过形形色色的问题——HTTP响应代码的误用，损坏的JavaScript代码，或者&lt;/span&gt;&lt;span&gt;&lt;strong&gt;Ajax的误用：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;&lt;span&gt;    停掉产品时移除页面的商店在网站升级后突然间会在404错误处理程序返回200响应码。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;    不恰当的JSON转义破坏了部分页面的JavaScript代码（比如‘b0rk’d’），导致你需要用正则表达式来抓取那部分数据。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;    滥用Ajax调用的商店以至于你只能靠渲染该页面（这会导致爬取慢很多）或者模仿API调用（导致要付出更多的开发努力）来获得数据。&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;span&gt;像这样草率的代码会导致编写爬虫非常痛苦，但也会使得可视化爬取工具或者自动析取不再可行。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在规模爬取的时候，你不仅要浏览成百上千个有着草率代码的网站，还将被迫应对不断演变的网站。一条好的经验法则是要预计你的目标网站每隔2到3个月就会发生让你的爬虫工作不了的变化。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这也许看起来不像是多大的事，但是当你规模抓取时，那些事件就会累积。比方说，Scrapinghub有一个规模比较大的电子商务项目大概有4000个爬虫抽取约1000个电子商务网站，意味着每天可能会经历20到30次爬虫失败。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;而且网站在不同地区、语言的变化，A/B测试以及包装/定价的派生也会制造出各种问题导致爬虫失败。&lt;/span&gt;&lt;/p&gt;

&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section class=&quot;_135editor&quot; data-tools=&quot;135&amp;#x7F16;&amp;#x8F91;&amp;#x5668;&quot; data-id=&quot;90636&quot;&gt;&lt;section&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;section data-width=&quot;100%&quot;/&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section class=&quot;135brush&quot; data-brushtype=&quot;text&quot;&gt;&lt;strong&gt;&lt;em&gt;没有容易的解决方案&lt;/em&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot; class=&quot;_135editor&quot;&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;不幸的是，不存在银弹可以彻底解决这些问题。很多时候这只是随着规模而扩大投入更多资源到你的项目上才能解决的事情。再拿上一个例子来说吧，那个项目有18名全职的爬虫工程师以及3名专职的QA工程师来确保客户总能得到可靠的数据流。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;不过，你的团队有经验以后就会学会如何开发出更加健壮的爬虫，从而检测并处置目标网站格式中的异常。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;如何处理目标网站有各种布局可能的情况呢？用多个爬虫也许不是最好的做法，我们的最佳实践是只用一个产品爬虫来处理不同页面布局个各种可能规则和模式。你的爬虫可配置性越强越好。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;尽管这些实践会让你的爬虫更加复杂（我们有些爬虫有好几千行），但它会确保你的爬虫更容易维护。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;由于大多数公司日常都需要析取产品数据，等待几天让你的工程团队修复任何坏掉的爬虫不是可选项。当出现这些情况时，Scrapinghub会利用自己开发的基于机器学习的数据析取工具来作为后备，直到爬虫修复好。这个基于ML的析取工具会自动识别目标网站的目标字段（产品名称、价格、货币单位、图像、SKU等）并且返回想要的结果。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;我们会在未来几周之内发布这项工具以及相关的指导文章，告诉大家如何将机器学习用到你的数据析取过程当中。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt; 挑战 2：可伸缩的架构 &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;你将面临的第二个挑战是建设一个可随每日请求数增长而扩充且性能不会下降的爬虫基础设施。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在规模析取产品数据时，一个串行爬取的简单web爬虫是不堪此任的。通常一个串行的web爬虫会循环发出请求，每一项请求都要2到3秒钟完成。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;如果你的爬虫每天发出的请求数不到40000的话这种做法是没有问题的。然而，超过这个点你就得过渡到一种让你每天可以完成数百万请求而不会性能下降的爬虫架构。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这个话题得用一篇文章才能说得清楚，未来几周我们将发布一篇专门的文章来讨论如何设计和开发高吞吐量的爬取架构。然而，本节的剩余部分我们将讨论一些高级原则和最佳实践。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;正如我们讨论过那样，在规模爬取产品数据时速度是关键。你需要确保在时间阈值范围内（通常是1天）可以找到并且爬取所有要求的产品页面。为此你需要做以下一些事情：&lt;/span&gt;&lt;/p&gt;

&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section class=&quot;_135editor&quot; data-tools=&quot;135&amp;#x7F16;&amp;#x8F91;&amp;#x5668;&quot; data-id=&quot;90636&quot;&gt;&lt;section&gt;&lt;section data-width=&quot;100%&quot;/&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section class=&quot;135brush&quot; data-brushtype=&quot;text&quot;&gt;&lt;strong&gt;&lt;em&gt;将产品发现与产品析取分开&lt;/em&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;&lt;span&gt;为了规模爬取产品数据你需要将你的产品发现爬虫与产品析取爬虫分开。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;产品发现爬虫的目标应该是让它浏览目前产品目录（或者“货架”）然后存储该目录下的产品URL供产品析取爬虫使用。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这个可以靠Scrapinghub 开发的开源工具Frontera之类的爬虫前端辅助完成。尽管Frontera原先的目的是配合Scrapy使用的，但它其实完全是不可知论者，可用于任何爬虫框架或者独立项目。在这篇文章中，我们分享了如何利用Frontera来规模抓取HackerNews的东西。&lt;/span&gt;&lt;/p&gt;

&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section class=&quot;_135editor&quot; data-tools=&quot;135&amp;#x7F16;&amp;#x8F91;&amp;#x5668;&quot; data-id=&quot;90636&quot;&gt;&lt;section&gt;&lt;section data-width=&quot;100%&quot;/&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section class=&quot;135brush&quot; data-brushtype=&quot;text&quot;&gt;&lt;strong&gt;&lt;em&gt;分配更多资源给产品析取&lt;/em&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot; class=&quot;_135editor&quot;&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;由于每一个产品目录“货架”可包含10到100种产品，而且析取产品数据需要的资源要比析取产品URL更多，发现爬虫通常运行要比产品析取爬虫更快。这种情况下，你需要有多个析取爬虫来对应每一个发现爬虫。一条好的经验法则是每10万个页面分配一个析取爬虫。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; 挑战 3：维护吞吐量性能 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;一级方程式的目标是将车上一切不必要的载荷都剔除掉，并且以速度之名将引擎最后一丝马力都榨干，从这个意义上来说规模抓取可以跟一级方程式相比较。规模web抓取也是一样的道理。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在析取大量数据时，在现有硬件资源条件下，你总是会想方设法要寻找请求周期最小化爬虫性能最大化的手段。这一切都是希望你能给每个请求节省下来那么几微秒的时间。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;为此你的团队需要对web爬取框架、代理管理以及所使用的硬件具备深刻理解，这样才能对它们进行调整以优化性能。你还需要关注：&lt;/span&gt;&lt;/p&gt;

&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section class=&quot;_135editor&quot; data-tools=&quot;135&amp;#x7F16;&amp;#x8F91;&amp;#x5668;&quot; data-id=&quot;90636&quot;&gt;&lt;section&gt;&lt;section data-width=&quot;100%&quot;/&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;strong&gt;&lt;span&gt;&lt;em&gt;  爬取效能  &lt;/em&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot; class=&quot;_135editor&quot;&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;规模爬取时你应该始终把焦点放在以尽量少的请求析取所需数据上。任何额外请求或者数据析取都会放缓你爬取网站的节奏。在设计你的爬虫时请记住这些提示：&lt;/span&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;&lt;span&gt;    作为最后一招，仅使用无界面浏览器，比如Splash或者Puppeteer来渲染JavaScript。用无界面浏览器渲染JavaScript同时爬取是非常耗资源的，会严重影响爬取的速度。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;    如果你可以从货架页面（比如产品名称、价格、评分等）获得所需的数据而不需要向独立的产品页面提出请求的话，那就不要向产品页面发出请求。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;span&gt;    不要请求或者析取图像，除非迫不得已。&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; 挑战 4：反机器人的对策 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如果你批量抓取电子商务网站的话一定会遇到采用反机器人对策的网站。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;规模小一点的网站其反机器人对策就是些基本手段（屏蔽发送请求过量的IP）。然而，较大的电子商务网站，比如Amazon等，会采用复杂的反机器人对策，比如Distil Networks、Incapsula或者Akamai等来使得析取数据困难许多。&lt;/span&gt;&lt;/p&gt;

&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section class=&quot;_135editor&quot; data-tools=&quot;135&amp;#x7F16;&amp;#x8F91;&amp;#x5668;&quot; data-id=&quot;90636&quot;&gt;&lt;section&gt;&lt;section data-width=&quot;100%&quot;/&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section class=&quot;135brush&quot; data-brushtype=&quot;text&quot;&gt;&lt;strong&gt;&lt;em&gt;代理&lt;/em&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot; class=&quot;_135editor&quot;&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;了解到这一点之后，任何项目想要规模抓取才数据，首要的基本需求就是得用代理。规模抓取数据时你需要可观的代理清单，而且需要实现必要的IP轮转、请求限制、会话管理以及黑名单逻辑来预防代理被屏蔽。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;或者除非你有或者愿意用一支规模可观的团队管理你的代理，否则的话你应该把抓取流程中的这一部分外包出去。提供各种水平服务的代理服务有很多。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;然而，我们的建议是找一家能够提供单个代理配置端点并且将所有的代理管理复杂性隐藏起来的代理提供商。在没有重新发明轮子、开发和维护自己的内部代理管理基础设施的情况下规模抓取就已经很耗资源了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;大多数大型电子商务公司都采用这种做法。一些全球最大型的电子商务网站采用Scrapinghub 开发的智能下载器Crawlera，这个东西的代理管理完全是外包的。当你的爬虫每天要发出2000万条请求时，把注意力放在分析数据而不是管理代理上会有意义得多。&lt;/span&gt;&lt;/p&gt;

&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section class=&quot;_135editor&quot; data-tools=&quot;135&amp;#x7F16;&amp;#x8F91;&amp;#x5668;&quot; data-id=&quot;90636&quot;&gt;&lt;section&gt;&lt;section data-width=&quot;100%&quot;/&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section class=&quot;135brush&quot; data-brushtype=&quot;text&quot;&gt;&lt;strong&gt;&lt;em&gt;代理以外&lt;/em&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot; class=&quot;_135editor&quot;&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;不幸的是，光靠使用代理服务并不足以确保你能规避大型电子商务网站的反机器人对策。越来越多的网站正在利用复杂的反机器人对策来监控你的爬虫行为，检测其是否真人访客。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这些范机器人对策不仅使得爬取电子商务网站越来越困难，而且克服这些手段如果做得不对的话也会严重拖累爬虫性能。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这些机器人对策有很大一部分使用到了JavaScript来确定请求是否来自于爬虫还是人（Javascript引擎检查、字体枚举、WebGL与Canvas等）。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;不过正如前面所述，规模爬取时你希望限制可编写脚本的无界面浏览器（Splash 或者Puppeteer等）的使用，因为渲染页面的任何JavaScript都非常耗资源并且放慢爬取网站的速度。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这意味着为了确保你能取得必要的吞吐量让爬虫提交每天的产品数据，你往往需要痛苦地对目标网站采用的反机器人对策进行逆向工程，并且在不使用无界面浏览器的情况下设计你的爬虫抵消那些对策。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt; 挑战 5：数据质量 &lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;从数据科学家的角度来说，任何网站爬取项目最重要的考虑是析取数据的质量。规模爬取只会令这一关注变得更加重要。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;当每天都要析取数百万数据点时，想靠人工来验证数据是否干净和完整是不可能的。变脏或者不完整的数据很容易就会流入到你的数据流里面，进而破坏了数据分析的效果。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;尤其是在抓取同一个的不同版本（不同的语言、地区等）或者不同商店上的产品时更是如此。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在爬虫开发的设计阶段，需要进行仔细的QA流程，爬虫代码要经过同行评审和测试以确保用最可靠的方式析取到想要的数据。确保最高数据质量的最好的办法是部署一套自动化QA监控系统。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;作为任何数据析取项目的一部分，你需要计划和开发一套监控系统，这套系统将提醒你任何不一致的数据以及发生的爬虫错误。Scrapinghub开发了一个机器学习算法来检测：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;数据验证错误&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;——每一个数据项都有定义好的遵循一致模式的数据类型和值。我们的数据验证算法会提醒项目的QA团队任何与预期数据类型不一致的数据项，然后再进行人工检查、提醒已验证或者标记为错误。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;产品差异化错误&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;——从同一网站的多个版本（不同语言、地区）爬取相同产品数据时，有可能变量或者像产品重量或者尺寸这样本该是固定值的数据项也会不一样。这可能是网站反机器人对策向你的一到多个爬虫提供篡改信息的结果。再次地，你需要算法来识别和标记类似这样的情况。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;基于数量的不一致性&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;——另一个关键的监控脚本是检测返回记录的任何异常变化。这可能预示网站已经做出改变或者你的爬虫被提供了篡改的信息。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;网站变化&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;——目标网站发生的结构性改变是爬虫失效的主要原因。我们的专用监控系统会监控到这一点。该工具会对目标网站进行频繁的检查，确保自从上次抓取之后没有发生任何变化。如果改变被发现，它也会发出通知。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;我们会在稍后的文章中专门讨论自动质量保证的细节。&lt;/span&gt;&lt;/p&gt;

&lt;section data-role=&quot;outer&quot; label=&quot;Powered by 135editor.com&quot;&gt;&lt;section class=&quot;_135editor&quot; data-tools=&quot;135&amp;#x7F16;&amp;#x8F91;&amp;#x5668;&quot; data-id=&quot;90636&quot;&gt;&lt;section&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;section data-width=&quot;100%&quot;/&gt;&lt;section data-width=&quot;100%&quot;&gt;&lt;section class=&quot;135brush&quot; data-brushtype=&quot;text&quot;&gt;&lt;strong&gt;&lt;em&gt;总结&lt;/em&gt;&lt;/strong&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section data-role=&quot;paragraph&quot; class=&quot;_135editor&quot;&gt;
&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;正如你所看到那样，规模抓取产品数据会面临一系列的独特挑战。希望这篇文章能够让你更加意识到相关挑战，并且就如何解决这些问题获得启发。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;然而，这只是本系列文章的第一部分，所以如果你感兴趣的话可以注册我们的电子邮件列表，一旦下一篇文章发表了我们会第一时间通知你。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;∑编辑 | Gemini&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;来源 | 技能get&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; pingfang=&quot;&quot; sc=&quot;&quot; hiragino=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; microsoft=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; px=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; caret-color:=&quot;&quot; text-align:=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; important=&quot;&quot; break-word=&quot;&quot;&gt;&lt;img class=&quot;&quot; data-copyright=&quot;0&quot; data-ratio=&quot;1.0437601296596435&quot; data-s=&quot;300,640&quot; data-type=&quot;png&quot; data-w=&quot;617&quot; width=&quot;auto&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabky7x6u1VxMVMia4MLibNzC2nrumY3zDflTsCeoM04M1BrkvPny8tsw6hYkIicUr42iarLmadL2x6JwV6A/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; pingfang=&quot;&quot; sc=&quot;&quot; hiragino=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; microsoft=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; px=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; caret-color:=&quot;&quot; text-align:=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; important=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;算法数学之美微信公众号欢迎赐稿&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; pingfang=&quot;&quot; sc=&quot;&quot; hiragino=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; microsoft=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; px=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; caret-color:=&quot;&quot; text-align:=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; important=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;稿件涉及数学、物理、算法、计算机、编程等相关领域，经采用我们将奉上稿酬。&lt;/span&gt;&lt;/p&gt;
&lt;p helvetica=&quot;&quot; neue=&quot;&quot; pingfang=&quot;&quot; sc=&quot;&quot; hiragino=&quot;&quot; sans=&quot;&quot; gb=&quot;&quot; microsoft=&quot;&quot; yahei=&quot;&quot; ui=&quot;&quot; arial=&quot;&quot; sans-serif=&quot;&quot; px=&quot;&quot; normal=&quot;&quot; rgb=&quot;&quot; caret-color:=&quot;&quot; text-align:=&quot;&quot; center=&quot;&quot; border-box=&quot;&quot; important=&quot;&quot; break-word=&quot;&quot;&gt;&lt;span&gt;投稿邮箱：math_alg@163.com&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 07 Sep 2018 20:55:04 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/PL3lUE6OyC</dc:identifier>
</item>
</channel>
</rss>