<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed43.com%2Fmathalg-jtks.xml&amp;max=5&amp;links=preserve&amp;exc=1" />
<atom:link rel="alternate" title="Source URL" href="http://feed43.com/mathalg-jtks.xml" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fmathalg-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed43.com%252Fmathalg-jtks.xml%26max%3D5%26links%3Dpreserve%26exc%3D1" />
<title>算法与数学之美</title>
<link>http://www.jintiankansha.me/column/c9dZ5TM2aS</link>
<description>算法与数学之美 - 今天看啥</description>
<ttl>360</ttl>
<item>
<title>机器学习萌新必学的Top10算法</title>
<link>http://www.jintiankansha.me/t/5Wyl5sQMiu</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/5Wyl5sQMiu</guid>
<description>&lt;p&gt;&lt;span&gt; 在机器学习领域里，不存在一种万能的算法可以完美解决所有问题，尤其是像预测建模的监督学习里。&lt;/span&gt;&lt;/p&gt;
&lt;section data-id=&quot;89091&quot; data-tools=&quot;135&amp;#x7F16;&amp;#x8F91;&amp;#x5668;&quot;&gt;&lt;section&gt;&lt;section&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;比方说，神经网络不见得比决策树好，同样反过来也不成立。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;最后的结果是有很多因素在起作用的，比方说数据集的大小以及组成。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;所以，针对你要解决的问题，最好是尝试多种不同的算法。并借一个测试集来评估不同算法之间的表现，最后选出一个结果最好的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;当然，你要选适合解决你问题的算法来尝试。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;比方说，要打扫房子，你会用真空吸尘器，扫把，拖把；你绝对不会翻出一把铲子来开始挖坑，对吧。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;不过呢，对于所有预测建模的监督学习算法来说，还是有一些通用的底层原则的。&lt;/span&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;span&gt;机器学习算法，指的是要学习一个目标函数，能够尽可能地还原输入和输出之间的关系。&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span&gt;然后根据新的输入值X，来预测出输出值Y。精准地预测结果是机器学习建模的任务。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;So，Top10机器学习算法，了解一下。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;统计学与机器学习领域里研究最多的算法。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;做预测建模，最重要的是准确性（尽可能减小预测值和实际值的误差）。哪怕牺牲可解释性，也要尽可能提高准确性。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;为了达到这个目的，我们会从不同领域（包括统计学）参考或照搬算法。&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;&lt;span&gt;线性回归可用一条线表示输入值X和输出值Y之间的关系，这条线的斜率的值，也叫系数。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.5277078085642317&quot; data-type=&quot;png&quot; data-w=&quot;794&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkxAlHEYKL3uacmerV9IUIZficzqGbphfYHNUX31gqJaEJLKDibia9yBgRfianBfoh2GOhPo5o56Ibwiadw/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;比方说，y = B0 + B1*x&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们就可以根据X值来预测Y值。机器学习的任务就是找出系数B0和B1。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;从数据中建立线性回归的模型有不同的方法，比方说线性代数的最小二乘法、梯度下降优化。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;线性回归已经存在了200多年，相关研究已经很多了。用这个算法关键在于要尽可能地移除相似的变量以及清洗数据。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;对算法萌新来说，是最简单的算法了。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这方法来自统计学领域，是一种可以用在二元分类问题上的方法。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;逻辑回归，和线性回归相似，都是要找出输入值的系数权重。不同的地方在于，对输出值的预测改成了逻辑函数。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;逻辑函数看起来像字母S，输出值的范围是0到1。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;把逻辑函数的输出值加一个处理规则，就能得到分类结果，非0即1。&lt;br/&gt;比方说，可以规定输入值小于0.5，那么输出值就是1。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.8237410071942446&quot; data-type=&quot;png&quot; data-w=&quot;556&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkxAlHEYKL3uacmerV9IUIZf5FVj703vyLhmJNmJ9MdKicXrjumScZGIGV6P5vlVdVlOmVJP4bg4VuA/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;
&lt;h6&gt;&lt;strong&gt;△&lt;/strong&gt; 逻辑回归&lt;/h6&gt;
&lt;p&gt;&lt;span&gt;这个算法还可以用来预测数据分布的概率，适用于需要更多数据论证支撑的预测。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;和线性回归相似，如果把和输出不相干的因子或者相近的因子剔除掉的话，逻辑回归算法的表现会更好。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;对于二元分类问题，逻辑回归是个可快速上手又有效的算法。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;逻辑回归算法，只能用于二分问题。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;当输出的结果类别超过两类的时候，就要用线性判别分析算法了。&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;&lt;span&gt;这种算法的可视化结果还比较一目了然，能看出数据在统计学上的特征。这上面的结果都是分别计算得到的，单一的输入值可以是每一类的中位数，也可以是每一类值的跨度。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.7776096822995462&quot; data-type=&quot;png&quot; data-w=&quot;661&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkxAlHEYKL3uacmerV9IUIZfQw9Vib1ia8o84WXh4kZq1KVaY5wotN8u4QANNmXOq3dRhO7vj8OMyhKw/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;
&lt;h6&gt;&lt;strong&gt;△&lt;/strong&gt; 线性判别分析&lt;/h6&gt;
&lt;p&gt;&lt;span&gt;基于对每种类别计算之后所得到的判别值，取最大值做出预测。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这种方法是假定数据符合高斯分布。所以，最好在预测之前把异常值先踢掉。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;对于分类预测问题来说，这种算法既简单又给力。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;预测模型里，决策树也是非常重要的一种算法。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;可以用分两叉的树来表示决策树的模型。每一个节点代表一个输入，每个分支代表一个变量（默认变量是数字类型）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.5464824120603015&quot; data-type=&quot;png&quot; data-w=&quot;796&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkxAlHEYKL3uacmerV9IUIZfZ5Ae99z6yQJFjmWZHiaPcBPNVsicGaQZxOm1n68Wibtnn9kMfM6gVNFyA/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;
&lt;h6&gt;&lt;strong&gt;△&lt;/strong&gt; 决策树&lt;/h6&gt;
&lt;p&gt;&lt;span&gt;决策树的叶节点指的是输出变量。预测的过程会经过决策树的分岔口，直到最后停在了一个叶节点上，对应的就是输出值的分类结果。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;决策树很好学，也能很快地得到预测结果。对于大部分问题来说，得到的结果还挺准确，也不要求对数据进行预处理。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这种预测建模的算法强大到超乎想象。&lt;br/&gt;这种模型，可以直接从你的训练集中计算出来两种输出类别的概率。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;一个是每种输出种类的概率；另外一个，是根据给定的x值，得到的是有条件的种类概率。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;一旦计算之后，概率的模型可以用贝叶斯定理预测新的数据。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;当你的数据是实数值，那么按理说应该是符合高斯分布的，也就很容易估算出这个概率。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img width=&quot;776&quot; height=&quot;476&quot; data-ratio=&quot;0.61375&quot; data-type=&quot;png&quot; data-w=&quot;800&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtBu1KvjWeMvfdAobXEDFqGnOGng7fDJCAIToR6jficAexhYo13IBAwBGKeAGvoxCWOqib9Wpx8xRqibw/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;h6&gt;&lt;strong&gt;△&lt;/strong&gt; 贝叶斯定理&lt;/h6&gt;
&lt;p&gt;&lt;span&gt;朴素贝叶斯定理之所以名字里有个“朴素”，是因为这种算法假定每个输入的变量都是独立的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;不过，真实的数据不可能满足这个隐藏前提。尽管如此，这个方法对很多复杂的问题还是很管用的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;最近K近邻的模型表示，就是整个训练集。很直截了当，对吧？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;对新数据的预测，是搜索整个训练集的值，找到K个最近的例子（literally的邻居）。然后总结K个输出的变量。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这种算法难就难在，怎么定义两个数据的相似度（相距多近算相似）。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如果你的特征(attributes)属于同一个尺度的话，那最简单的方法是用欧几里得距离。这个数值，你可以基于每个输入变量之间的距离来计算得出。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.7503649635036497&quot; data-type=&quot;png&quot; data-w=&quot;685&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkxAlHEYKL3uacmerV9IUIZftQMMLQCsficrIZFlIIOJuBXAndvRrlaJnz7HMRyZruNIQRt65LsNPsg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;
&lt;h6&gt;&lt;strong&gt;△&lt;/strong&gt; 最近邻法&lt;/h6&gt;
&lt;p&gt;&lt;span&gt;最近邻法，需要占用大量的内存空间来放数据，这样在需要预测的时候就可以进行即时运算（或学习）。也可以不断更新训练集，使得预测更加准确。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;距离或亲密度这个思路遇到更高维度（大量的输入变量）就行不通了，会影响算法的表现。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这叫做维度的诅咒。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;当（数学）空间维度增加时，分析和组织高维空间（通常有成百上千维），因体积指数增加而遇到各种问题场景。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;所以最好只保留那些和输出值有关的输入变量。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;最近邻法的缺点是，你需要整个训练集。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;而学习矢量量化（后简称LVQ）这个神经网络算法，是自行选择训练样例。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.4434673366834171&quot; data-type=&quot;png&quot; data-w=&quot;796&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkxAlHEYKL3uacmerV9IUIZfBnE12n14UdQ3hygdUXYR4XiaFXWWwUkwCzVTHYVJ92wqJN519aQg9Rw/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;LVQ，是一组矢量，也叫码本。一开始，矢量是随机选的，经过几次学习算法迭代之后，慢慢选出最能代表训练集的矢量。&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;&lt;span&gt;学习完成后，码本就可以用来预测了，就像最近邻法那样。计算新输入样例和码本的距离，可以找出最相近的邻居，也就是最匹配的码本。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如果你重新调整数据尺度，把数据归到同一个范围里，比如说0到1之间，那就可以获得最好的结果。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如果用最近邻法就获得了不错的结果，那么可以再用LVQ优化一下，减轻训练集储存压力。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这可能是机器学习里最受欢迎的算法了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;超平面是一条可以分割输入变量的空间的“线”。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;支持向量机的超平面，是能把输入变量空间尽可能理想地按种类切割，要么是0，要么是1。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在二维空间里，你可以把超平面可以分割变量空间的那条“线”。这条线能把所有的输入值完美一分为二。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;SVM的学习目标就是要找出这个超平面。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.5784313725490197&quot; data-type=&quot;png&quot; data-w=&quot;612&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkxAlHEYKL3uacmerV9IUIZfJFR8Vibpuia1wvtVH2L8Ihh9ro8oW05eCU6eInbjHugoiclWxf1IQjGsw/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;
&lt;h6&gt;&lt;strong&gt;△&lt;/strong&gt; 支持矢量机&lt;/h6&gt;
&lt;p&gt;&lt;span&gt;超平面和挨得最近的数据点之间的距离，叫做边缘。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;最理想的超平面，是可以无误差地划分训练数据。 也就是说，每一类数据里距离超平面最近的向量与超平面之间的距离达到最大值。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这些点就叫做支持向量，他们定义了超平面。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;从实际操作上，最理想的算法是能找到这些把最近矢量与超平面值距离最大化的点。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;支持向量可能是最强的拿来就用的分类器了。值得用数据集试试。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;随机森林，属于一种重复抽样算法，是最受欢迎也最强大的算法之一。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在统计学里，bootstrap是个估算值大小很有效的方法。比方说估算平均值。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;span&gt;从数据库中取一些样本，计算平均值，重复几次这样的操作，获得多个平均值。然后平均这几个平均值，希望能得到最接近真实的平均值。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;而bagging算法，是每次取多个样本，然后基于这些样本建模。当要预测新数据的时候，之前建的这些模型都做次预测，最后取这些预测值的平均数，尽力接近真实的输出值。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.6073446327683616&quot; data-type=&quot;png&quot; data-w=&quot;708&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkxAlHEYKL3uacmerV9IUIZfvNb5cu9WrsC2GPOaSU9LYAnsZABYXXvs7XoS1wHGibYCm1xHyOAP1Xg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;随机森林在这个基础上稍微有点变化。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;它包含多个决策树的分类器， 并且其输出的类别是由个别树输出的类别的众数而定。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如果你的高方差算法取得了不错的结果（比方说决策树），那么用随机森林的话会进一步拿到更好的结果。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;Boosting的核心是，对同一个训练集训练不同的分类器（弱分类器），然后把这些弱分类器集合起来，构成一个更强的最终分类器（强分类器）。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;所得到的第二个弱分类器会纠正第一个弱分类器的误差。弱分类器的不断叠加，直到预测结果完美为止。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Adaboost算法是首个成功用于二元分类问题的提升算法。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;现在有很多提升方法都是基于Adaboost。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.564945226917058&quot; data-type=&quot;png&quot; data-w=&quot;639&quot; data-s=&quot;300,640&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkxAlHEYKL3uacmerV9IUIZfbAx0rl0st61PVkGofO4yTQiaB1Jb7Ot4pE0sicOWV3xU8ZPJztZbqvKg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;AdaBoost适用于短的决策树。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在第一个树建立出来之后，不同的样本训练之后的表现可以作参考，用不同的样本训练弱分类器，然后根据错误率给样本一个权重。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;很难预测的训练数据应该给更多的权重，反过来，好预测的就少一点权重。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;模型按顺序一个一个建，每个训练数据的权重都会受到上一个决策树表现的影响。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;当所有的决策树都建好之后，看新数据的预测表现，结果准不准。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;因为训练数据对于矫正算法非常重要，所以要确保数据清洗干净了，不要有奇奇怪怪的偏离值。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;面对海量的机器学习算法，萌新最爱问的是，“我该选什么算法？”&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;p&gt;&lt;span&gt;在回答这个问题之前，要先想清楚：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;1）数据的数量、质量、本质；&lt;br/&gt;2）可供计算的时间；&lt;br/&gt;3）这个任务的紧急程度；&lt;br/&gt;4）你用这个数据想做什么。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;要知道，即使是老司机，也无法闭着眼睛说哪个算法能拿到最好的结果。还是得动手试。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;其实机器学习的算法很多的，以上只是介绍用得比较多的类型，比较适合萌新试试手找找感觉。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;最后，附编译来源，&lt;br/&gt;https://www.kdnuggets.com/2018/02/tour-top-10-algorithms-machine-learning-newbies.html&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;∑编辑 | Gemini&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;来源 | 量子位&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img width=&quot;auto&quot; data-ratio=&quot;0.7509529860228716&quot; data-type=&quot;jpeg&quot; data-w=&quot;787&quot; data-s=&quot;300,640&quot; data-copyright=&quot;0&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkz1SRWmm2kJgtV2NTQtdSgtyl7nJbJm8xS78Td2LBbJQKKqyE54oaOO9upMribZagMKYJVBaEDyKtA/640?wx_fmt=jpeg&quot;/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;算法数学之美微信公众号欢迎赐稿&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;稿件涉及数学、物理、算法、计算机、编程等相关领域&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;经采用我们将奉上稿酬。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;投稿邮箱：math_alg@163.com&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 10 Apr 2018 19:37:23 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/5Wyl5sQMiu</dc:identifier>
</item>
<item>
<title>读书新方式，给生活找点乐子</title>
<link>http://www.jintiankansha.me/t/tezaksJbLg</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/tezaksJbLg</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;-01-&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;小时候看蜡笔小新，觉得活成他爸爸那样，真可伶。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;三十二年的房贷、挨不完的暴揍、加不完的晚班……日子过得苦兮兮。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;然而，这位大叔成天就知傻笑，坦然得很。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;工作不顺，他就想想身边老婆儿子，想想今晚看场球赛。心情不爽，只要手边有杯冰啤酒，烦恼就咕咚咕咚灌下去。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;4dd84a9b446fe6ebea2639d141d12f9a.jpg&quot; data-ratio=&quot;0.546875&quot; data-type=&quot;jpeg&quot; data-w=&quot;512&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkwsgIiatzYRNQMa6xic921phrNFQDahPdbKG614sbtAzt1AVu72iahfUp3clS1o78fvZiaLcN931Fq1cA/640?wx_fmt=jpeg&quot; data-backw=&quot;512&quot; data-backh=&quot;280&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;现在回想，小新爸爸很厉害呀。那种 “生命要浪费在美好事物上”的人生哲学，他玩儿得很&lt;/span&gt;&lt;span&gt;溜。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;社会日益浮躁，功利主义渗透到每个角落，很多人过得不好，并不是因为没钱，而是因为他们没有精气神，没有恰当的审美，不讲究生活情趣，越来越追求实用化的背后，就是越来越平庸，越来越枯萎。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;梁文道说：“&lt;strong&gt;读一些无用的书，做一些无用的事，花一些无用的时间&lt;/strong&gt;，都是为了在一切已知之外，保留一个超越自己的机会，人生中一些很了不起的变化，就是来自这种时刻。”&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;-02-&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;看《花少》的时候，特别喜欢许晴，感觉她整个人都是鲜活的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;这档节目主打穷游，所有人都在为钱困扰，每天都在那“钱钱钱”、“省省省”，过得很是粗糙。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在离开的前一天，许晴没有跟团队活动，在街上走了3个多小时去当地最有名的菜场买了食材。一路上又买了蜡烛，她还想买桌布，可是找了很多地方都没有买到，最后到一个头饰店买了各种颜色的丝巾。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;晚上，当花少团回来时，就看见天台上摆放着一桌美食，烛光在四周摇曳，餐座和椅背上铺就了各色丝巾。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;风尘仆仆的一群人，这一刻在五颜六色如梦一般的气氛中，就着异国他乡的夜景，摇晃起了红酒杯。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;那一晚，凯丽回忆，是她那段旅行中最惬意的时光。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;懂得生活的人就是这样，一碗稀粥也能喝出玫瑰的气息。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; 

&lt;p&gt;&lt;strong&gt;&lt;span&gt;-03-&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;美好的东西能抵抗生活中的沮丧和困顿，一个人专注于审美、讲究生活趣味的过程，就是纳悦自己、滋养身心、重获希望的过程。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;被自己的老师沈从文夸“可爱”的小老头汪曾祺，有段时间，被扔到了马铃薯研究站，远在沽源。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;一个文学大师画土豆，像个什么样子？但他倒好，埋头画花和薯块，画完了，就丢在牛粪火里烤熟吃掉。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;还一度很骄傲：&lt;strong&gt;“我敢说，像我一样吃过这么多品种马铃薯的，全国盖无第二人！”&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-ratio=&quot;0.685&quot; data-type=&quot;jpeg&quot; data-w=&quot;400&quot; data-s=&quot;300,640&quot; data-copyright=&quot;0&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkwsgIiatzYRNQMa6xic921phrIcoVVH5F7EjCFS3nnOIWvq2qmJgs9FPrh2icYFANsMIVyAYQ8E0Ddpw/640?wx_fmt=jpeg&quot; data-backw=&quot;400&quot; data-backh=&quot;274&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;《随遇而安》中，他更是写道， “烤土豆的这段经历，真是三生有幸。要不然我这一生就更加平淡了。”&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;林语堂曾言：“我们最重要的不是去计较真与伪，得与失，名与利，贵与贱，富与贫，而是如何好好地快乐度日，并从中发现生活的诗意。”&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;一个人，光活着是不够的，他还应该拥有诗意的世界。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span&gt;-04-&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;讲究生活情趣，将生活过得入木三分、活色生香是一种能力。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;在《欢乐颂》里，赵医生告诉曲筱绡他喜欢交往有趣的人，曲筱绡一直不明白他所说的有趣是什么意思。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;赵医生是医学博士，能欣赏王小波的爱情小说，也能看日本的原版黄暴漫画。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;曲筱绡要带他去吃法式大餐，他说宁愿在家看东野圭吾，沉浸在小说中未曾体验过的生活中。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img title=&quot;8a6a55796acb538367c7fc4bbf6c9db9.jpg&quot; data-ratio=&quot;0.6592592592592592&quot; data-type=&quot;jpeg&quot; data-w=&quot;540&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkwsgIiatzYRNQMa6xic921phrEEKtcrkVIZcGvQiaLiaorLooZ6CZFxtq0uT5tIk3wPssaCaxpIiavMeicg/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;说白了，精致、诗意的生活背后，其实就是一股子热爱，就像&lt;span&gt;汪曾祺说的：人活着，一定要爱点什么。&lt;span&gt;这种能力能&lt;/span&gt;&lt;/span&gt;&lt;strong&gt;把普通的日子折腾地会发光&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;经历过人世复杂的汪曾祺，却一直天真得像个孩子。平日里，他酒一喝多，就吹大发：喂喂，你们对我客气点，我将来是要进文学史的。汪家人一个白眼扫过去。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;鹦鹉史航说：这世间可爱的老头儿很多，但可爱成汪曾祺这样的，却不常见。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;他写家乡的咸鸭蛋，“高邮咸蛋质细而油多，蛋白柔嫩，不似别处的发干、发粉，入口如嚼石灰。油多尤为别处所不及。筷子头一扎下去，吱——红油就冒出来了。”&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;他写自创的塞馅回锅油条，“猪肉馅要肥瘦各半，馅中加盐、葱花、姜末，如加少量榨菜末或酱瓜末、川冬菜末，亦可。&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; 
&lt;p&gt;&lt;span&gt;拌好的肉馅塞入油条中，逐段下油锅炸至油条挺硬，此菜嚼之酥脆，油条中有矾，略有涩味，比炸春卷味道好。”&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-ratio=&quot;0.5626666666666666&quot; data-type=&quot;jpeg&quot; data-w=&quot;750&quot; data-s=&quot;300,640&quot; data-copyright=&quot;0&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkwsgIiatzYRNQMa6xic921phrdv0CMx7iaic63ic0wE4FDVibhoM3ygdiciaOguZRRlIePlqdRc65aNm3xrHQ/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;最常见的栀子花在他笔下，都变得“张牙舞爪”：“栀子花粗粗大大，又香得掸都掸不开，于是为文雅人不取，以为品格不高。栀子花说：&lt;strong&gt;‘去你妈的，我就是要这样香，香得痛痛快快，你们他妈的管得着吗！’&lt;/strong&gt;”&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;什么是有趣？有趣就是在最普通寻常的日子里活出甜味、活出雅致、活出清欢。有趣才是一个人最高级的性感。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;对于懂得生活的人，生活中的这种小事才是最接近生活的本真。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;就像汪涵读书、研究方言，活成了“烟火神仙”；陈道明为女儿捏起糖人、面人，给爱人做手工包，总做“无用”之事；讲书人关熙潮繁忙生活之余拿起相机，捕捉生活的美好瞬间。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;img title=&quot;1808016702.jpg&quot; data-ratio=&quot;0.6555555555555556&quot; data-type=&quot;jpeg&quot; data-w=&quot;1080&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkwsgIiatzYRNQMa6xic921phrDOCKS68tIYLDKkM0oLIWoxTgIneoamXBxQFgaXuxHbWMlFGo6IibibHg/640?wx_fmt=jpeg&quot; data-backw=&quot;526&quot; data-backh=&quot;345&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;关熙潮/摄&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;很多人总是豪气冲天、幻想着策马扬鞭奔去远方，可是只有认真踏实地过好了眼前的小日子，才能像汪老头这样“活进文学史”里，活进自己的生活里。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;慢点走，品品茶，喝喝酒，听听曲，写写字。&lt;/span&gt;&lt;span&gt;——汪曾祺&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;hr/&gt;
&lt;p&gt;&lt;img title=&quot;&quot; data-ratio=&quot;1.744343891402715&quot; data-type=&quot;png&quot; data-w=&quot;442&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkwsgIiatzYRNQMa6xic921phrcvQREccP6vKOWRurfGYlPFTjMrPQLlSey2cuEeMcDvQc5l0rzadRiaw/640?wx_fmt=png&quot;/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img title=&quot;&quot; data-ratio=&quot;0.48654708520179374&quot; data-type=&quot;png&quot; data-w=&quot;446&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkwsgIiatzYRNQMa6xic921phrHRrTMSyxkPS9KA3YtqTDNOror6LgwllHia1YYbjMNb5vLpHZHLnQQnQ/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img title=&quot;&quot; data-ratio=&quot;0.9040178571428571&quot; data-type=&quot;png&quot; data-w=&quot;448&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkwsgIiatzYRNQMa6xic921phrlUOySfAqico3ic9gC3k72FFts4J5WnGtNjZsrrnlprJtIKBTiblMHpTXg/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;读书新方式&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;影视片段+小动画&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;讲书类型覆盖14个大类&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;每天8分钟，&lt;/span&gt;&lt;span&gt;看大咖讲书&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;限时特惠 &lt;span&gt;39.9&lt;/span&gt;元/月&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;原价&lt;/span&gt;&lt;span&gt;69&lt;/span&gt;&lt;span&gt;元&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;一杯下午茶的消费，180本书畅享&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;读更多书，让自己的生活更有品质&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;长按下方二维码立即了解课程详情&lt;/span&gt;&lt;/p&gt;
&lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;section class=&quot;RankEditor&quot; sans=&quot;sans&quot; pingfang=&quot;pingfang&quot; center=&quot;center&quot; rgb=&quot;rgb&quot; normal=&quot;normal&quot; px=&quot;px&quot; sans-serif=&quot;sans-serif&quot; e=&quot;e&quot; stheiti=&quot;stheiti&quot; fae=&quot;fae&quot; yahei=&quot;yahei&quot; microsoft=&quot;microsoft&quot; gb=&quot;gb&quot; hiragino=&quot;hiragino&quot; arial=&quot;arial&quot; helvetica=&quot;helvetica&quot; neue=&quot;neue&quot; sc=&quot;sc&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;p&gt;&lt;img data-ratio=&quot;1&quot; data-type=&quot;png&quot; data-w=&quot;272&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkwsgIiatzYRNQMa6xic921phrqC7rbv2aRnp8MpnzZgCrLTBn0yb9wGWDvTH2voZT9ps6HFWic3Ficwnw/640?wx_fmt=png&quot;/&gt;&lt;/p&gt;

&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;↓点击“阅读原文”，给生活找点乐子。&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 10 Apr 2018 19:37:22 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/tezaksJbLg</dc:identifier>
</item>
<item>
<title>免费福利 | 送你一份免费音频，让你躺着也能学习葡萄酒知识！</title>
<link>http://www.jintiankansha.me/t/nTPe6NS7ZH</link>
<guid isPermaLink="true" >http://www.jintiankansha.me/t/nTPe6NS7ZH</guid>
<description>
&lt;section class=&quot;RankEditor&quot;&gt;&lt;section&gt;&lt;section&gt;
&lt;section&gt;&lt;span&gt;如果你对红酒感兴趣，不妨继续看下去，因为我会在文中推送免费福利；如果你不感兴趣，也不妨多看几句，因为多了解一些红酒知识，是修养也是谈资，反正你也不亏，不是吗？&lt;/span&gt;&lt;/section&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;RankEditor&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section/&gt;&lt;section top=&quot;top&quot; rgb=&quot;rgb&quot; quot=&quot;&quot; no-repeat=&quot;no-repeat&quot; margin-top=&quot;&quot; inline-block=&quot;inline-block&quot; http=&quot;&quot; gif=&quot;&quot; em=&quot;em&quot; cover=&quot;cover&quot;/&gt;&lt;section/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;
&lt;p&gt;前几天到武汉拜访了一家非常用心做红酒的团队，基本上一整天都是在那边度过的，跟那边的负责人学习到了很多红酒知识，并深深的为之折服。最难能可贵的是，这是国内少有的能够独立打造自己供应链和内容体系的一个团队，并且他们在红酒音频和视频上有着很高的建树。当然，我也没忘了为大家争取一波&lt;span&gt;&lt;strong&gt;福利&lt;/strong&gt;&lt;/span&gt;！&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.75&quot; data-type=&quot;jpeg&quot; data-w=&quot;4032&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkxQPGkn7MWLwX7ocblzAfpZ7Vbk17FXicaNXVSkcorib3clCnngvlU4FXuics9yZia11s3qH5oic7XrWIQ/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;（这些红酒全部是他们团队提供的）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这个团队是卖红酒的，但是他们和国内其他酒商不一样。按照他们的说法就是：利用自身的专业性为大家普及红酒知识，利用团队的专业性为大家提供国外原产精品好酒，通过分享传播的方法让每一个关注他们的人都能学有所获。这也是我今天一定要写一篇公众号来像大家介绍他们的原因。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;他们的内容体系很全，从公众号，微博，付费音频，视频等都有。但是最值得欣赏的还是他们为他们的客户解决问题的能力：比如说，如果你喝过红酒，你也一定会对下面这些问题感到疑惑：&lt;/span&gt;&lt;/p&gt;
&lt;section class=&quot;editor&quot;&gt;&lt;section class=&quot;96wx-bdc&quot;&gt;&lt;section class=&quot;96wx-bdc&quot;&gt;&lt;section class=&quot;96wx-bdc&quot; readability=&quot;2.5&quot;&gt;&lt;section class=&quot;96wx-bgc&quot; readability=&quot;5&quot;&gt;&lt;p class=&quot;96wx-bdc&quot;&gt;&lt;strong class=&quot;96wx-bdc&quot;&gt;&lt;span class=&quot;96wx-bdc&quot;&gt;1.红酒酒款太多，不知道选哪一款 ；&lt;br/&gt;2.想入门，但是又一知半解 ；&lt;br/&gt;3.想品酒，但是不知道该如何入手 ；&lt;br/&gt;4.想喝“甜”一点的红酒，不知道哪一款适合 ；&lt;br/&gt;5.想知道如何鉴别葡萄酒，增加自己的品味 ；&lt;br/&gt;6.想知道如何判断红酒的好坏；&lt;br/&gt;7.想学会品鉴，顺便喝一点好的葡萄酒 ；&lt;br/&gt;8.以及，想从入门到精通，读懂葡萄酒的内涵 ；&lt;br/&gt;......&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;editor&quot; readability=&quot;2&quot;&gt;&lt;p&gt;他们给出的解决方案非常全面：&lt;/p&gt;
&lt;/section&gt;&lt;p&gt;&lt;strong&gt;一.推出红酒知识公众号，除了分享最专业的红酒知识，还会告诉你如何鉴别假酒，如何避免买到差酒。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.8888888888888888&quot; data-type=&quot;jpeg&quot; data-w=&quot;2484&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkxQPGkn7MWLwX7ocblzAfpZc43rS3bJBaBPTjZFyVPTAIIX1mPR6zEXP2yeSicUx5dpOMezJPuLDPA/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二.根据自己团队的经验编写了一本纸质版《葡萄酒入门手册》&lt;/strong&gt;，里面有着千金不换的品酒绝学，包括：&lt;span&gt;单宁是什么， 葡萄酒的年份有什么区别，酒体怎么理解，如何评价葡萄酒的好坏，如何正确的品鉴、评价一款葡萄酒， 如何提高葡萄酒水平，可以说，这是一本从入门到精通的手册，你想知道的，里面都有。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;0.6784922394678492&quot; data-type=&quot;jpeg&quot; data-w=&quot;4961&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkxQPGkn7MWLwX7ocblzAfpZM6OkAjpD7ZMJc2637XYMrU7meuWIGHBkUgvSU2FL8U46KUIyMdQxcA/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三.录制了56篇红酒知识音频，目前为付费，不过我这边有&lt;span&gt;免费&lt;/span&gt;&lt;/strong&gt;&lt;strong&gt;名额，添加他们品酒师微信，即可免费领取！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;img data-ratio=&quot;0.9954853273137697&quot; data-type=&quot;jpeg&quot; data-w=&quot;443&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkxQPGkn7MWLwX7ocblzAfpZ5ZBqLIe0WjvPNCXKQUtoibgIQ3YHLoKuibRuhWGCc7HXKN9EIbdTecOg/640?wx_fmt=jpeg&quot;/&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;长按图片识别图中二维码，添加微信&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-ratio=&quot;0.9986666666666667&quot; data-type=&quot;jpeg&quot; data-w=&quot;1500&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkxQPGkn7MWLwX7ocblzAfpZia6lvWHzP7CNGzZj80uiaicvtn7BpvmLc4O13UdKl0fWOKveNyEQ0GO8Q/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;四.制作了一系列的红酒视频，从入门到进阶，你想知道的，这里都有。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img data-ratio=&quot;0.5039808917197452&quot; data-type=&quot;jpeg&quot; data-w=&quot;1256&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkxQPGkn7MWLwX7ocblzAfpZf6qghVuicTcyMojbSnoxbLHfD6e2J3b5MwTvuBaCiciakq8HKXTDc7cEA/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;

&lt;p&gt;如果你解有关葡萄酒的一切，想节省买酒钱，不妨去关注一下他们的公众号。别急，后面我会把联系方式公布出来。&lt;/p&gt;
&lt;p&gt;&lt;img data-ratio=&quot;1.0249433106575964&quot; data-type=&quot;jpeg&quot; data-w=&quot;441&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkxQPGkn7MWLwX7ocblzAfpZQoXxV3zhvj3icL4Gqcltlwf1U1BX3GMAW9MX66B3Dr51pD8Ribd5qv7g/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;长按图片识别二维码，添加微信&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;古语云，授人以鱼不如授人以渔。所以我今天为大家带来的福利是他们的付费音频，一共有100个免费名额。在获取音频之前，你不妨看下他们的音频介绍：&lt;/p&gt;
&lt;section class=&quot;editor&quot;&gt;&lt;section&gt;&lt;section class=&quot;96wx-bdtc&quot;/&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;span&gt;谈谈音频制作的初衷，音频是专门为我们的会员准备了，因为我们发现国内不懂酒的人实在太多了，甚至有在我们这边花了几万块钱还是不懂酒的朋友。&lt;/span&gt;&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;0&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;所以我们在给大家分享葡萄酒的时候，也一直在给大家普及葡萄酒知识。这也是我们创作音频的初衷。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;这是比《入门手册》还要强大的知识体系，里面是我们精心给大家准备的进阶音频，品酒，鉴酒，评酒，酒圈知识，红酒交际，这里都有。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;section class=&quot;editor&quot;&gt;&lt;p&gt;&lt;img data-ratio=&quot;0.27906976744186046&quot; data-type=&quot;png&quot; data-w=&quot;387&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_png/951TjTgiabkxQPGkn7MWLwX7ocblzAfpZibXu9CPmYMLHqquSYB84FQWoFQ3NcibMkicWtygxF2cFHtYT7AuzOIeGA/640?wx_fmt=png&quot; data-width=&quot;100%&quot;/&gt;&lt;/p&gt;
&lt;/section&gt;&lt;p&gt;&lt;span&gt;音频会告诉你什么：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这套音频是根据大家对葡萄酒知识的掌握程度来进行划分的，一共分为6季，每一季都对应不同的主题，我希望喜欢音频的朋友一定要认真听完，因为我最终要达到的目的就是要让这些葡萄酒知识在大家的脑海中串联起来，让你深入浅出地了解与葡萄酒有关的一切。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;你将会收获到这些：&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;5.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;教你&lt;/span&gt;&lt;span&gt;识别假酒&lt;/span&gt;&lt;span&gt;，让你以后买酒的时候尽量避免买到假酒，不上当，少受骗。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;教你&lt;/span&gt;&lt;span&gt;鉴别酒的好坏&lt;/span&gt;&lt;span&gt;，让你知道好酒为什么贵，同时为你节省80%花在劣质酒上的冤枉钱。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;教你&lt;/span&gt;&lt;span&gt;品鉴好酒&lt;/span&gt;&lt;span&gt;，读懂葡萄酒的酸与涩，让酒不再生涩难咽，品出葡萄酒的魅力所在。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;会给每位购买了音频的会员安排一位&lt;/span&gt;&lt;span&gt;品酒师助手&lt;/span&gt; &lt;ins class=&quot;adsbygoogle&quot; data-ad-layout=&quot;in-article&quot; data-ad-format=&quot;fluid&quot; data-ad-client=&quot;ca-pub-1837452791782084&quot; data-ad-slot=&quot;7041996284&quot;/&gt; &lt;span&gt;，后续助手会安排你进入葡萄酒爱好者社群，认识更多志同道合的朋友。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;后续品酒师助手会有一系列&lt;/span&gt;&lt;span&gt;直播计划&lt;/span&gt;&lt;span&gt;，主要讲解与葡萄酒有关的知识，不懂的可以现场咨询提问。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;年后我们会推出我们的&lt;/span&gt;&lt;span&gt;社群&lt;/span&gt;&lt;span&gt;，以省为单位划分，目前暂定只对购买过我们葡萄酒的会员开放，让你遇到更多志同道合的朋友，以酒会友。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;section class=&quot;editor&quot;&gt;&lt;section class=&quot;RankEditor&quot;&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section/&gt;&lt;section/&gt;&lt;section/&gt;&lt;section/&gt;&lt;/section&gt;&lt;section&gt;&lt;section/&gt;&lt;section/&gt;&lt;section/&gt;&lt;section/&gt;&lt;/section&gt;&lt;section&gt;&lt;section/&gt;&lt;section/&gt;&lt;section/&gt;&lt;section/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section/&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;span&gt;&lt;strong&gt;免费获取全部音频的方式：添加品酒师微信，备注“音频福利”，即可获取全部音频，千万要备注，不然你获取的是免费版，免费版只有10期，但是付费版有56期。&lt;/strong&gt;&lt;/span&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section&gt;&lt;section&gt;&lt;section&gt;&lt;br/&gt;&lt;/section&gt;&lt;section/&gt;&lt;section/&gt;&lt;/section&gt;&lt;section&gt;&lt;section/&gt;&lt;section/&gt;&lt;section/&gt;&lt;section/&gt;&lt;/section&gt;&lt;section&gt;&lt;section/&gt;&lt;section/&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;p&gt;&lt;strong&gt;添加品酒师微信，免费获取葡萄酒入门音频&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img width=&quot;153&quot; height=&quot;150&quot; data-ratio=&quot;0.9977064220183486&quot; data-type=&quot;jpeg&quot; data-w=&quot;436&quot; data-src=&quot;http://img2.jintiankansha.me/get?src=http://mmbiz.qpic.cn/mmbiz_jpg/951TjTgiabkxQPGkn7MWLwX7ocblzAfpZtMoq1zg36QnEkDq0wZ7qNxs3utU4qWzo0XBeb8iap9DXC5z40PoENdg/640?wx_fmt=jpeg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;长按图片识别二维码&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 09 Apr 2018 16:02:22 +0000</pubDate>
<dc:language>zh-CN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.jintiankansha.me/t/nTPe6NS7ZH</dc:identifier>
</item>
</channel>
</rss>