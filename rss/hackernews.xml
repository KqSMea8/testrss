<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>How We Bootstrapped Our SaaS Startup to Ramen Profitability</title>
<link>https://blog.canny.io/saas-startup-ramen-profitability/</link>
<guid isPermaLink="true" >https://blog.canny.io/saas-startup-ramen-profitability/</guid>
<description>&lt;div id=&quot;wtr-content&quot; data-bg=&quot;#FFFFFF&quot; data-fg=&quot;#525df9&quot; data-width=&quot;4&quot; data-mute=&quot;1&quot; data-fgopacity=&quot;0.80&quot; data-mutedopacity=&quot;0.5&quot; data-placement=&quot;top&quot; data-placement-offset=&quot;0&quot; data-placement-touch=&quot;top&quot; data-placement-offset-touch=&quot;0&quot; data-transparent=&quot;&quot; data-touch=&quot;&quot; data-comments=&quot;&quot; data-commentsbg=&quot;#ffcece&quot; data-location=&quot;page&quot; data-mutedfg=&quot;#525df9&quot;&gt;
&lt;p&gt;It’s been seven months since we launched our SaaS startup and we’re &lt;a href=&quot;http://www.paulgraham.com/ramenprofitable.html&quot;&gt;ramen profitable&lt;/a&gt;. Canny makes enough to pay for its own expenses and our personal living expenses.&lt;/p&gt;
&lt;p&gt;This is far less money than we made working at Facebook, but a huge milestone for our bootstrapped startup. We’ve eliminated one of the biggest risks of failure: running out of money.&lt;/p&gt;
&lt;p&gt;In this post I’ll cover how we got here, and what we’ve learned.&lt;/p&gt;
&lt;h2&gt;How we found our burning problem&lt;/h2&gt;
&lt;p&gt;I won’t bore you with generic advice. You’ve heard it a thousand times. Solve a burning problem! Make something people want! Great advice, but not super actionable.&lt;/p&gt;
&lt;p&gt;Instead, I’ll share how we found our burning problem.&lt;/p&gt;
&lt;p&gt;We actually started with a problem of our own, then pivoted to a more valuable one.&lt;/p&gt;
&lt;h2&gt;Our original problem&lt;/h2&gt;
&lt;p&gt;We followed Paul Graham’s &lt;a href=&quot;http://www.paulgraham.com/startupideas.html&quot;&gt;advice&lt;/a&gt; and started with a problem we had ourselves:&lt;/p&gt;
&lt;p&gt;As users, it doesn’t feel like companies listen to our feedback. They’ll say “thanks, we’ll pass it on to the team”, but nothing ever happens. This is demoralizing. Apps are buggy and missing useful features. Fixing them would mean making all software experiences better.&lt;/p&gt;
&lt;img class=&quot;wp-image-247 size-full&quot; src=&quot;https://i0.wp.com/blog.canny.io/wp-content/uploads/2017/10/appy-email.png?resize=1068%2C684&amp;amp;ssl=1&quot; alt=&quot;generic-email-reply&quot; srcset=&quot;https://i0.wp.com/blog.canny.io/wp-content/uploads/2017/10/appy-email.png?w=1068&amp;amp;ssl=1 1068w, https://i0.wp.com/blog.canny.io/wp-content/uploads/2017/10/appy-email.png?resize=300%2C192&amp;amp;ssl=1 300w, https://i0.wp.com/blog.canny.io/wp-content/uploads/2017/10/appy-email.png?resize=768%2C492&amp;amp;ssl=1 768w, https://i0.wp.com/blog.canny.io/wp-content/uploads/2017/10/appy-email.png?resize=1024%2C656&amp;amp;ssl=1 1024w&quot; sizes=&quot;(max-width: 1068px) 100vw, 1068px&quot; data-recalc-dims=&quot;1&quot;/&gt;Sad, generic reply
&lt;p&gt;We built a community where people could post and vote on feedback for any product, publicly.&lt;/p&gt;
&lt;img class=&quot;alignnone size-full wp-image-244&quot; src=&quot;https://i0.wp.com/blog.canny.io/wp-content/uploads/2017/10/productpains.png?resize=1200%2C736&amp;amp;ssl=1&quot; alt=&quot;product-pains&quot; srcset=&quot;https://i0.wp.com/blog.canny.io/wp-content/uploads/2017/10/productpains.png?w=2338&amp;amp;ssl=1 2338w, https://i0.wp.com/blog.canny.io/wp-content/uploads/2017/10/productpains.png?resize=300%2C184&amp;amp;ssl=1 300w, https://i0.wp.com/blog.canny.io/wp-content/uploads/2017/10/productpains.png?resize=768%2C471&amp;amp;ssl=1 768w, https://i0.wp.com/blog.canny.io/wp-content/uploads/2017/10/productpains.png?resize=1024%2C628&amp;amp;ssl=1 1024w&quot; sizes=&quot;(max-width: 1200px) 100vw, 1200px&quot; data-recalc-dims=&quot;1&quot;/&gt;&lt;p&gt;Around 5,000 people posted and voted on ideas for several hundred products. It was a neat beta, but retention was weak. It was difficult to get teams to subscribe to feedback about their product.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Learning Lesson&lt;/strong&gt;: We kind of just assumed our problem was valid and started building the product. We should have talked to more people first. It would have saved us months. We would have realized it wasn’t something people really needed or would pay for.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MRR&lt;/strong&gt;: $0 (Oct, 2016)&lt;/p&gt;
&lt;h2&gt;The bigger problem&lt;/h2&gt;
&lt;p&gt;We starting talking to a ton of teams about user feedback.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;How do you collect feedback from your users?&lt;/li&gt;
&lt;li&gt;How do you keep track of user feedback?&lt;/li&gt;
&lt;li&gt;How do you decide what to build?&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;It turns out there’s a reason it doesn’t feel like companies are listening to our feedback. It’s because they aren’t.&lt;/p&gt;
&lt;p&gt;It’s not that they don’t care. They care deeply. It’s just that feedback is a mess. Product managers don’t have time to read every chat message, email, and support ticket. And even if they did, they wouldn’t remember it all.&lt;/p&gt;
&lt;p&gt;This is when we realized there was a business problem causing our consumer problem.&lt;/p&gt;
&lt;p&gt;To validate our new findings, we built a widget to help teams collect and keep track of user feedback.&lt;/p&gt;
&lt;img class=&quot;alignnone wp-image-305 size-full&quot; src=&quot;https://i1.wp.com/blog.canny.io/wp-content/uploads/2017/10/canny-widget.png?resize=1200%2C775&amp;amp;ssl=1&quot; alt=&quot;canny-widget&quot; srcset=&quot;https://i1.wp.com/blog.canny.io/wp-content/uploads/2017/10/canny-widget.png?w=2345&amp;amp;ssl=1 2345w, https://i1.wp.com/blog.canny.io/wp-content/uploads/2017/10/canny-widget.png?resize=300%2C194&amp;amp;ssl=1 300w, https://i1.wp.com/blog.canny.io/wp-content/uploads/2017/10/canny-widget.png?resize=768%2C496&amp;amp;ssl=1 768w, https://i1.wp.com/blog.canny.io/wp-content/uploads/2017/10/canny-widget.png?resize=1024%2C662&amp;amp;ssl=1 1024w&quot; sizes=&quot;(max-width: 1200px) 100vw, 1200px&quot; data-recalc-dims=&quot;1&quot;/&gt;&lt;p&gt;I still remember the first time someone paid us $19/mo for it. We were ecstatic. It was the first time we’d ever sold something we built. The best part: they’re still using us today, a year later.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Learning Lesson&lt;/strong&gt;: Talking to people is a great way to discover and validate problems. Writing code isn’t. Charging money is the ultimate form of validation. If a total stranger pays for your product, they must think you’re solving some problem for them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MRR&lt;/strong&gt;: $100 (Dec, 2016)&lt;/p&gt;
&lt;h2&gt;Understanding our value proposition&lt;/h2&gt;
&lt;p&gt;At this point, we knew what we had to do: fork the repo and re-market our community as a SaaS tool.&lt;/p&gt;
&lt;p&gt;Sarah’s a product designer and I’m a software engineer. Building the MVP was the easy part.&lt;/p&gt;
&lt;p&gt;But how do you make a landing page? What words go on it? How do you price it?&lt;/p&gt;
&lt;p&gt;These are sales and marketing problems that we had never faced before. The way to solve these problems, we learned, is to understand your value proposition:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;What problem do you solve?&lt;/li&gt;
&lt;li&gt;Who has that problem?&lt;/li&gt;
&lt;li&gt;How do they describe the problem?&lt;/li&gt;
&lt;li&gt;How big of a problem is it?&lt;/li&gt;
&lt;li&gt;How much would they pay for a solution?&lt;/li&gt;
&lt;li&gt;What other solutions are out there?&lt;/li&gt;
&lt;li&gt;How are you better / different?&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Without answers to these questions, you’re just guessing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Learning Lesson&lt;/strong&gt;: Sales and marketing is about understanding the problem you solve, and clearly communicating that. If you’re struggling with them, you may not understand your value proposition. We spent a lot of time reading blog posts about sales and marketing. We should have spent that time talking to our target customer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MRR&lt;/strong&gt;: $100 (Mar, 2017)&lt;/p&gt;
&lt;h2&gt;Launching our MVP&lt;/h2&gt;
&lt;p&gt;We started with a soft launch to the teams already using us.&lt;/p&gt;
&lt;p&gt;When we shipped our pivot, we were able to migrate everyone over from the old site. The core product was similar enough.&lt;/p&gt;
&lt;p&gt;This was a great way to get a bunch of people trying our “paid” product from day one. We let it run for a week or two, worked out the kinks, then launched on Product Hunt.&lt;/p&gt;
&lt;img class=&quot;alignnone size-full wp-image-283&quot; src=&quot;https://i1.wp.com/blog.canny.io/wp-content/uploads/2017/10/product-hunt-launch-1.jpg?resize=1200%2C701&amp;amp;ssl=1&quot; alt=&quot;product-hunt-launch&quot; srcset=&quot;https://i1.wp.com/blog.canny.io/wp-content/uploads/2017/10/product-hunt-launch-1.jpg?w=2428&amp;amp;ssl=1 2428w, https://i1.wp.com/blog.canny.io/wp-content/uploads/2017/10/product-hunt-launch-1.jpg?resize=300%2C175&amp;amp;ssl=1 300w, https://i1.wp.com/blog.canny.io/wp-content/uploads/2017/10/product-hunt-launch-1.jpg?resize=768%2C449&amp;amp;ssl=1 768w, https://i1.wp.com/blog.canny.io/wp-content/uploads/2017/10/product-hunt-launch-1.jpg?resize=1024%2C598&amp;amp;ssl=1 1024w&quot; sizes=&quot;(max-width: 1200px) 100vw, 1200px&quot; data-recalc-dims=&quot;1&quot;/&gt;&lt;p&gt;Our launch went amazing. Over 350 companies tried Canny that week. Dozens ended up paying after our 30-day trial.&lt;/p&gt;
&lt;p&gt;Several factors played into our successful launch:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;We solve a problem for software companies. Product Hunt’s community is mainly people working in tech. This audience was highly relevant for us.&lt;/li&gt;
&lt;li&gt;We emailed the 5,000 people who had left feedback in our community. We let them know about our pivot, and that we were launching on Product Hunt.&lt;/li&gt;
&lt;li&gt;We already had a few paying customers. This meant we knew we had something other people would pay for too.&lt;/li&gt;
&lt;li&gt;Chris Messina hunted us. Thanks Chris! (he has &lt;a href=&quot;https://chrismessina.typeform.com/to/t5FMAz&quot;&gt;a form&lt;/a&gt; where you can ask him to hunt you too)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Learning Lesson&lt;/strong&gt;: If you sell to tech companies, Product Hunt is a great place to launch. It’s a one-time trigger, not your marketing strategy. If you do it sooner, you’ll get valuable feedback. If you do it later, you’ll get paying customers. I’m glad we did it later.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MRR&lt;/strong&gt;: $1,000 (May, 2017)&lt;/p&gt;
&lt;h2&gt;Building an Inbound Engine&lt;/h2&gt;
&lt;p&gt;We’re coming up on 100 paying customers, and we’ve never done any outbound sales. Our strongest channel is organic, via “Powered by Canny”.&lt;/p&gt;
&lt;p&gt;This is one of the huge benefits of building a user-facing SaaS product. By user-facing, I mean our product is used by our customers’ customers.&lt;/p&gt;
&lt;img class=&quot;alignnone size-full wp-image-243&quot; src=&quot;https://i2.wp.com/blog.canny.io/wp-content/uploads/2017/10/poweredbycanny.png?resize=1200%2C716&amp;amp;ssl=1&quot; alt=&quot;powered-by-canny&quot; srcset=&quot;https://i2.wp.com/blog.canny.io/wp-content/uploads/2017/10/poweredbycanny.png?w=2598&amp;amp;ssl=1 2598w, https://i2.wp.com/blog.canny.io/wp-content/uploads/2017/10/poweredbycanny.png?resize=300%2C179&amp;amp;ssl=1 300w, https://i2.wp.com/blog.canny.io/wp-content/uploads/2017/10/poweredbycanny.png?resize=768%2C458&amp;amp;ssl=1 768w, https://i2.wp.com/blog.canny.io/wp-content/uploads/2017/10/poweredbycanny.png?resize=1024%2C611&amp;amp;ssl=1 1024w, https://i2.wp.com/blog.canny.io/wp-content/uploads/2017/10/poweredbycanny.png?w=2400&amp;amp;ssl=1 2400w&quot; sizes=&quot;(max-width: 1200px) 100vw, 1200px&quot; data-recalc-dims=&quot;1&quot;/&gt;&lt;p&gt;Thousands of people use our product every day. Some percentage of those people are PMs or founders, and have the problem we solve. They then sign up for Canny, wanting to use it for their own product.&lt;/p&gt;
&lt;p&gt;This channel is boosted by the fact that my co-founder Sarah is a super talented designer. Several of our customers have switched from competitors specifically for our design.&lt;/p&gt;
&lt;p&gt;Since we already had a bunch of inbound traffic, we’ve spent most of our time iterating on our funnel:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Landing Page → Pricing Page&lt;/strong&gt;: Iterated on and simplified our landing page. Experimented with the headline. Included key features.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pricing Page → Register Page&lt;/strong&gt;: Changed and simplified our pricing. Added a slider to remove anxiety around scaling pricing.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Register Page → Free Trial&lt;/strong&gt;: Simplified our registration forms.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Free Trial → Using Trial&lt;/strong&gt;: Added user onboarding to encourage key actions. Made it easier to integrate.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Using Trial → Paying&lt;/strong&gt;: Created a drip campaign in Intercom to encourage key actions. Added billing reminders.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Paying → Retained&lt;/strong&gt;: Offering friendly, prompt customer service. Nurturing to make sure people are getting value. Promptly fixing bugs + building features where it makes sense. Adding sticky integrations like Slack + Zapier.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;As a result, our funnel has gotten pretty darn good, and most months our churn is zero. We’ve been able to more than triple in just a few months, from our organic channel.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Learning Lesson&lt;/strong&gt;: Start marketing earlier. Write less code. Since we’re an engineer + designer, we constantly fall back into a “product mindset”. Features are great, but they usually aren’t the most optimal way to drive your business.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MRR&lt;/strong&gt;: $3,500 (Oct, 2017)&lt;/p&gt;
&lt;img class=&quot;size-full wp-image-307&quot; src=&quot;https://i0.wp.com/blog.canny.io/wp-content/uploads/2017/10/graph.jpg?resize=1200%2C672&amp;amp;ssl=1&quot; alt=&quot;saas-profits&quot; srcset=&quot;https://i0.wp.com/blog.canny.io/wp-content/uploads/2017/10/graph.jpg?w=1624&amp;amp;ssl=1 1624w, https://i0.wp.com/blog.canny.io/wp-content/uploads/2017/10/graph.jpg?resize=300%2C168&amp;amp;ssl=1 300w, https://i0.wp.com/blog.canny.io/wp-content/uploads/2017/10/graph.jpg?resize=768%2C430&amp;amp;ssl=1 768w, https://i0.wp.com/blog.canny.io/wp-content/uploads/2017/10/graph.jpg?resize=1024%2C574&amp;amp;ssl=1 1024w&quot; sizes=&quot;(max-width: 1200px) 100vw, 1200px&quot; data-recalc-dims=&quot;1&quot;/&gt;MRR: Up and to the right!
&lt;h2&gt;Umm, how do you live on $3,500?&lt;/h2&gt;
&lt;p&gt;If you live in San Francisco, you’re probably wondering how $3,500/mo is ramen profitable.&lt;/p&gt;
&lt;p&gt;Four months ago we moved out of our cozy apartment in San Francisco to be digital nomads. Right now we’re in Valencia, Spain. We’re also a couple.&lt;/p&gt;
&lt;p&gt;We’ll split an Airbnb for $1,000 a month, work from cafes, and eat cheaply. Canny spends hundreds a month, mostly on hosting and other SaaS.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Learning Lesson&lt;/strong&gt;: If you can get away with it, you can save a lot of money working nomad. As long as you have Wi-Fi, you can work anywhere. We’re actually more productive working remotely because we don’t know as many people. All we do is eat, sleep, work, and explore.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Intrigued?&lt;/strong&gt; Check out our &lt;a href=&quot;https://instagram.com/carryoncode&quot;&gt;travel Instagram&lt;/a&gt; or read Sarah’s post, &lt;a href=&quot;https://blog.canny.io/building-startup-digital-nomads/&quot;&gt;Building our Startup as Digital Nomads&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Next Up&lt;/h2&gt;
&lt;p&gt;We’ve built a solid engine that converts visitors into paying customers. It’s time to switch gears and focus on traffic.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Blogging&lt;/strong&gt;: Seems to work well for SaaS companies like ours. We love what Eoghan says about content: the less you try to make it convert, the better it does. We’re focusing on posts that benefit our target customer, rather than trying to sell Canny.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Advertising&lt;/strong&gt;: We’ve begun experimenting with FB + Google ads. Turning $X into $Y seems like a no brainer if Y &amp;gt; X.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Side Projects&lt;/strong&gt;: There’s this idea that you can build a useful product, and give it away for free. For example, Front built &lt;a href=&quot;http://reallygoodemails.com&quot;&gt;reallygoodemails.com&lt;/a&gt;. If done right, these projects can be huge business drivers. We’re product people, so this lets us do what we do best.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;We’ll let you know how it goes in our next post! Thanks for reading.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;wp-about-author-containter-none&quot;&gt;
&lt;div class=&quot;wp-about-author-pic wp-about-author-circle&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://secure.gravatar.com/avatar/61add4e4bf7ae918d780d7d30a99629f?s=90&amp;amp;d=mm&amp;amp;r=g&quot; srcset=&quot;https://secure.gravatar.com/avatar/61add4e4bf7ae918d780d7d30a99629f?s=180&amp;amp;d=mm&amp;amp;r=g 2x&quot; class=&quot;avatar avatar-90 photo&quot; height=&quot;90&quot; width=&quot;90&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;wp-about-author-text&quot;&gt;
&lt;h3&gt;&lt;a href=&quot;https://blog.canny.io/author/a13n/&quot; title=&quot;Andrew Rasmussen&quot;&gt;Andrew Rasmussen&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Hi, I'm a co-founder of Canny. Before that, I was a software engineer at Facebook. I love JavaScript, rock climbing, trading tech stocks, and SaaS.&lt;/p&gt;
&lt;p class=&quot;wpa-nomargin&quot;&gt;&lt;a href=&quot;https://blog.canny.io/author/a13n/&quot; title=&quot;More posts by Andrew Rasmussen&quot;&gt;More Posts&lt;/a&gt; - &lt;a href=&quot;http://www.twitter.com/a13n&quot;&gt;Twitter&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;post-subscribe-form&quot;&gt;
&lt;div class=&quot;header&quot;&gt;Like what you read?&lt;/div&gt;
&lt;div class=&quot;subtitle&quot;&gt;Get an email when we post new content&lt;/div&gt;

&lt;/div&gt;
</description>
<pubDate>Tue, 24 Oct 2017 19:15:14 +0000</pubDate>
<dc:creator>a13n</dc:creator>
<og:type>article</og:type>
<og:title>How we Bootstrapped our SaaS Startup to Ramen Profitability – Canny Blog</og:title>
<og:description>It’s been seven months since we launched our SaaS startup and we’re ramen profitable. Read about how we got here and what we've learned.</og:description>
<og:url>https://blog.canny.io/saas-startup-ramen-profitability/</og:url>
<og:image>https://blog.canny.io/wp-content/uploads/2017/10/ramen-profitable.jpg</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.canny.io/saas-startup-ramen-profitability/</dc:identifier>
</item>
<item>
<title>If you care about diversity, don&amp;#039;t just hire from the same five schools</title>
<link>http://blog.interviewing.io/if-you-care-about-diversity-you-should-stop-hiring-from-the-same-five-schools/</link>
<guid isPermaLink="true" >http://blog.interviewing.io/if-you-care-about-diversity-you-should-stop-hiring-from-the-same-five-schools/</guid>
<description>&lt;p&gt;If you’re a software engineer, you probably believe that, despite some glitches here and there, folks who have the technical chops can get hired as software engineers. We regularly hear stories about college dropouts, who, through hard work and sheer determination, bootstrapped themselves into millionaires. These stories appeal to our sense of wonder and our desire for fairness in the world, but the reality is very different. For many students looking for their first job, the odds of breaking into a top company are slim because they will likely never even have the chance to show their skills in an interview. For these students (typically ones without a top school on their resume), their first job is often a watershed moment where success or failure can determine which opportunities will be open to them from that point forward and ultimately define the course of their entire career. In other words, having the right skills as a student is nowhere near enough to get you a job at a top-tier tech company.&lt;/p&gt;&lt;p&gt;To make this point concrete, &lt;strong&gt;consider three&lt;/strong&gt; (fictitious, yet indicative) &lt;strong&gt;student personas, similar in smarts and skills but attending vastly different colleges. All are seeking jobs as software engineers at top companies upon graduation&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Mason goes to Harvard. He has a mediocre GPA but knows that doesn’t matter to tech companies, where some of his friends already work. Come September, recent graduates and alums fly back to campus on their company’s dime in order to recruit him. While enjoying a nice free meal in Harvard Square, he has the opportunity to ask these successful engineers questions about their current work. If he likes the company, all he has to do is accept the company’s standing invitation to interview on campus the next morning.&lt;/p&gt;
&lt;p&gt;Emily is a computer science student at a mid-sized school ranked in the top 30 for computer science. She has solid coursework in algorithms under her belt, a good GPA, and experience as an engineering intern at a local bank. On the day of her campus’s career fair, she works up the courage to approach companies – this will be her only chance to interact with companies where she dreams of working. Despite the tech industry being casual, the attire of this career fair is business formal with a tinge of sweaty. So after awkwardly putting together an outfit she would never wear again&lt;sup&gt;&lt;a id=&quot;university-ref1&quot; href=&quot;http://blog.interviewing.io/if-you-care-about-diversity-you-should-stop-hiring-from-the-same-five-schools/#university-fn1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, she locates an ancient printer on the far side of campus and prints 50 copies of her resume. After pushing through the lines in order to line up at the booths of tech companies, she gives her resume to every single tech company at the fair over the course of several hours. She won’t find out for two more weeks if she got any interviews.&lt;/p&gt;
&lt;p&gt;Anthony goes to a state school near the town where he grew up. He is top in his class, as well as a self-taught programmer, having gone above and beyond his coursework to hack together some apps. His school’s career fair has a bunch of local, non-tech employers. He has no means of connecting with tech companies face-to-face and doesn’t know anyone who works in tech. So, he applies to nearly a hundred tech companies indiscriminately through their website online, uploading his resume and carefully crafted cover letter. He will probably never hear from them.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;heading&quot;&gt;Career fair mania&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The status quo in university recruiting revolves around career fairs and in-person campus recruiting, which have serious limitations. For one, they are extremely expensive, especially at elite schools. Prime real estate at the MIT career fair will run you a steep $18,000, for entry alone. That’s not counting the price of swag (which gets more exorbitant each year), travel, and, most importantly, the opportunity cost of attending engineers’ time. &lt;strong&gt;While college students command the lowest salaries, it’s not uncommon for tech companies to spend 50% more on recruiting a student than a senior engineer.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At elite schools, the lengths to which companies go to differentiate themselves is becoming more exorbitant with each passing year. This year, Adam D’Angelo, the CEO of Quora and former CTO of Facebook, &lt;a href=&quot;https://www.facebook.com/events/121304685246334/&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;personally flew out to Harvard to give a talk&lt;/a&gt; and put in face time with students. In fact, students at elite colleges suffer from company overload because every major tech company, big and small, is trying to recruit them. All of this, while students at non-elite colleges are scrambling to get their foot in the door without any recruiters, let alone a CEO worth half a billion dollars, visiting their campus.&lt;/p&gt;
&lt;p&gt;Of course, due to this cost, companies are limited in their ability to visit colleges in person, and even large companies can visit around 15 or 20 colleges at most. This strategy overlooks top students at solid CS programs that are out of physical reach.&lt;/p&gt;
&lt;p&gt;In an effort to overcome this, companies are attending conferences and hackathons out of desperation to reach students at other colleges. The sponsorship tier for the Grace Hopper Conference, the premier gathering for women in tech, tops out at $100,000, with the sponsorship tier to get a single interview booth starting at $30,000. Additionally, larger companies send representatives (usually engineers) to large hackathons in an effort to recruit students in the midst of a 48-hour all-nighter. However, the nature of in-person career fairs and events are that not all students will be present. Grace Hopper is famously expensive to attend as a student, especially when factoring in airfare and hotel.&lt;/p&gt;
&lt;p&gt;This cost is inefficient at best, and prohibitive at worst, especially for small startups with low budget and brand. Career fairs serve a tiny portion of companies and a tiny portion of students, and the rest are caught in the pecuniary crossfire. &lt;strong&gt;Demand for talented engineers out of college who bring a different lived experience to tech has never been higher, yet companies are passing on precisely these students via traditional methods.&lt;/strong&gt; Confounding the issue even further is the fundamental question of &lt;a href=&quot;http://blog.interviewing.io/lessons-from-3000-technical-interviews/&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;whether having attended a top school has much bearing on candidate quality&lt;/a&gt; in the first place (more on that in the section on technical screening below).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://blog.interviewing.io/wp-content/uploads/2017/10/threshold-4-1024x606.png&quot; alt=&quot;&quot; width=&quot;1024&quot; height=&quot;606&quot; class=&quot;aligncenter size-large wp-image-1194&quot; srcset=&quot;http://blog.interviewing.io/wp-content/uploads/2017/10/threshold-4-1024x606.png 1024w, http://blog.interviewing.io/wp-content/uploads/2017/10/threshold-4-200x118.png 200w, http://blog.interviewing.io/wp-content/uploads/2017/10/threshold-4-300x178.png 300w, http://blog.interviewing.io/wp-content/uploads/2017/10/threshold-4-768x455.png 768w, http://blog.interviewing.io/wp-content/uploads/2017/10/threshold-4-860x509.png 860w, http://blog.interviewing.io/wp-content/uploads/2017/10/threshold-4-680x403.png 680w, http://blog.interviewing.io/wp-content/uploads/2017/10/threshold-4-400x237.png 400w, http://blog.interviewing.io/wp-content/uploads/2017/10/threshold-4-50x30.png 50w, http://blog.interviewing.io/wp-content/uploads/2017/10/threshold-4.png 1088w&quot; sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;heading&quot;&gt;Homogeneity of hires&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The focus of companies on elite schools has notable, negative implications for the diversity of their applicants. In particular, many schools that companies traditionally visit are notably lacking in diversity, especially when it comes to race and socioeconomic status. According to a &lt;a href=&quot;https://medium.com/@jcueto/race-and-gender-among-computer-science-majors-at-stanford-3824c4062e3a&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;survey of computer science students at Stanford&lt;/a&gt;, there were just fifteen Hispanic female and fifteen black female computer science majors in the 2015 graduating class &lt;em&gt;total&lt;/em&gt;. In this analysis, the Stanford 2015 CS major was 9% Hispanic and 6% black. According to a &lt;a href=&quot;https://medium.com/@winniewu/race-and-gender-among-computer-science-concentrators-at-harvard-1c1943a20457&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;2015 analysis&lt;/a&gt;, the Harvard CS major was just 3% black and 5 percent Hispanic. Companies that are diversity-forward and constrained to recruiting at the same few schools end up competing over this small pool of diverse students. Meanwhile, there is an entire ocean of qualified, racially diverse students from less traditional backgrounds whom companies are overlooking.&lt;/p&gt;
&lt;p&gt;The focus on elite schools also has meaningful implications on socioeconomic diversity. According to a detailed &lt;a href=&quot;https://www.nytimes.com/interactive/2017/01/18/upshot/some-colleges-have-more-students-from-the-top-1-percent-than-the-bottom-60.html?mcubz=0&amp;amp;_r=0&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;New York Times infographic&lt;/a&gt;, “four in 10 students from the top 0.1 percent attend an Ivy League or elite university, roughly equivalent to the share of students from poor families who attend any two- or four-year college.” The infographic highlights the rigid segmentation of students by class background in college matriculation.&lt;/p&gt;
&lt;div id=&quot;attachment_1153&quot; class=&quot;wp-caption aligncenter&quot;&gt;&lt;img src=&quot;http://blog.interviewing.io/wp-content/uploads/2017/10/Screenshot-2017-10-19-10.10.36-1024x538.png&quot; alt=&quot;&quot; width=&quot;1024&quot; height=&quot;538&quot; class=&quot;size-large wp-image-1153&quot; srcset=&quot;http://blog.interviewing.io/wp-content/uploads/2017/10/Screenshot-2017-10-19-10.10.36-1024x538.png 1024w, http://blog.interviewing.io/wp-content/uploads/2017/10/Screenshot-2017-10-19-10.10.36-200x105.png 200w, http://blog.interviewing.io/wp-content/uploads/2017/10/Screenshot-2017-10-19-10.10.36-300x158.png 300w, http://blog.interviewing.io/wp-content/uploads/2017/10/Screenshot-2017-10-19-10.10.36-768x403.png 768w, http://blog.interviewing.io/wp-content/uploads/2017/10/Screenshot-2017-10-19-10.10.36-860x452.png 860w, http://blog.interviewing.io/wp-content/uploads/2017/10/Screenshot-2017-10-19-10.10.36-680x357.png 680w, http://blog.interviewing.io/wp-content/uploads/2017/10/Screenshot-2017-10-19-10.10.36-400x210.png 400w, http://blog.interviewing.io/wp-content/uploads/2017/10/Screenshot-2017-10-19-10.10.36-50x26.png 50w, http://blog.interviewing.io/wp-content/uploads/2017/10/Screenshot-2017-10-19-10.10.36.png 1129w&quot; sizes=&quot;(max-width: 1024px) 100vw, 1024px&quot;/&gt;&lt;p class=&quot;wp-caption-text&quot;&gt;Source: &lt;a href=&quot;https://www.nytimes.com/interactive/2017/01/18/upshot/some-colleges-have-more-students-from-the-top-1-percent-than-the-bottom-60.html?mcubz=0&amp;amp;_r=0&quot;&gt;New York Times&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The article finds that the few lower-income students who end up at elite colleges do about as well as their more affluent classmates but that attending an elite versus non-elite college makes a huge difference in future income.&lt;/p&gt;
&lt;p&gt;The focus of tech companies on elite schools lends credence to this statistic, codifying the rigidity with which students at elite college are catapulted into the 1 percent, while others are left behind. Career-wise, it’s that first job or internship you get while you’re still in school that can determine what opportunities you have access to in the future. And yet, students at non-elite colleges have trouble accessing these very internships and jobs, or even getting a meager first round interview, contributing to the lack of social mobility in our society not for lack of skills but for lack of connections. This sucks. A lot.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;heading&quot;&gt;The technical screen&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let’s return to our three students. Let’s say that Emily, the student who attended her college’s career fair, gets called back by one or two companies for a first round interview if her resume meets the criteria that companies are looking for. Not having an internship at a top tech company already — quite the catch-22 — puts her at a disadvantage. Anthony has little to no chance of hearing back from employers via his applications online, but let’s say that by some miracle lands a phone screen with one of the tech giants (his best shot, as there are more recruiters to look through the resume dump on the other end).&lt;/p&gt;
&lt;p&gt;What are their experiences when it comes to prepping for upcoming technical interviews?&lt;/p&gt;
&lt;p&gt;Mason, the Harvard student, &lt;a href=&quot;https://www.facebook.com/events/138642833412845/&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;attends an event&lt;/a&gt; on campus with Facebook engineers teaching him how to pass the technical interview. He also accepts a few interviews at companies he’s less excited with for practice, and just in case. While he of course needs be sharp and prepare in order to get good at these sorts of algorithmic problems, he has all of the resources he could ask for and more at his disposal. Unsurprisingly, his Facebook interview goes well.&lt;/p&gt;
&lt;p&gt;Emily’s school has an informal, undergraduate computer science club in which they are collectively reading technical interviewing guides and trying to figure out what tech companies want from them. She has a couple interviews lined up, but all of which are for jobs she’s desperate to get. They trade tips after interviews but ultimately have a shaky understanding of they did right and wrong in the absence of post-interview feedback from companies. Only a couple of alumni from their school have made it to top tech companies in the past, and so they lack the kinds of information that Mason has on what companies are looking for. (E.g. Don’t be afraid to take hints, make sure to explain your thought process, what the heck is this CoderPad thing anyway…)&lt;/p&gt;
&lt;p&gt;Anthony doesn’t know anyone who has a tech job like the one he’s interviewing for, and only one of his friends is also interviewing. He doesn’t know where to start when it comes to getting ready for his upcoming interview at GoogFaceSoft. He only has one shot at it with no practice interviews lined up. He prepares by googling “tech interview questions” and stumbles upon a bunch of unrealistic interview questions, many of them behavioral or outdated. He might be offered the interview and be fit for the job, but he sure doesn’t know how to pass the interview.&lt;/p&gt;
&lt;p&gt;For students who may be unfamiliar with the art of the technical interview, algorithmic interviews can be mystifying, &lt;a href=&quot;http://blog.interviewing.io/you-cant-fix-diversity-in-tech-without-fixing-the-technical-interview/&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;leading to an imbalance of information on how to succeed&lt;/a&gt;. Given that &lt;a href=&quot;http://blog.interviewing.io/after-a-lot-more-data-technical-interview-performance-really-is-kind-of-arbitrary/&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;technical interviewing is a game&lt;/a&gt;, it is important that everyone knows the rules, spoken and unspoken. There are many practice resources available, but no amount of reading and re-reading &lt;em&gt;Cracking the Coding Interview&lt;/em&gt; can prepare you for that moment when you are suddenly in a live, technical phone screen with another human.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;heading&quot;&gt;We built a better way to hire&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Ultimately, as long as university hiring relies on a campus-by-campus approach, the status quo will continue to be fundamentally inefficient and unmeritocratic. No company, not even the tech giants, can cover every school or every resume submitted online. And, in the absence of any meaningful information on a student’s resume, companies default to their university as the only proxy. This approach is inefficient at best and, at worst, it’s the first in a series of watershed moments that derail the promise of social mobility for the non-elite, taking with them any hope of promoting diversity among computer science students.&lt;/p&gt;
&lt;p&gt;Because this level of inequity, placed for maximum damage right at the start of people’s careers, really pissed us off, we decided to do something about it. interviewing.io’s answer to the unfortunate status quo is a university-specific hiring platform. If you’re already familiar with how core interviewing.io works, you’ll see that the premise is exactly the same. &lt;strong&gt;We give out free practice to students, and use their performance in practice to identify top performers, completely independently of their pedigree. Those top performers then get to interview with companies like Lyft and Quora on our platform. In other words, we’re excited to provide students with pathways into tech that don’t involve going to an elite school or knowing someone on the inside.&lt;/strong&gt; So far, we’ve been very pleased with the results. You can see our student demographics and where they’re coming from below. Students from all walks of life, whether they’re from MIT or a school you’d never visit, are flocking to the platform, and we couldn’t be prouder.&lt;/p&gt;
&lt;div class=&quot;plotly-container&quot;&gt;&lt;a href=&quot;https://plot.ly/~aline_interviewingio/1045/?share_key=x6Eif4bgOZIc153mbJcmGr?link=false&quot; target=&quot;_blank&quot; title=&quot;school tier distribution&quot;&gt;&lt;img src=&quot;https://plot.ly/~aline_interviewingio/1045.png?share_key=x6Eif4bgOZIc153mbJcmGr?link=false&quot; alt=&quot;school tier distribution&quot; width=&quot;600&quot; onerror=&quot;this.onerror=null;this.src='https://plot.ly/404.png';&quot;/&gt;&lt;/a&gt;&lt;br/&gt;&lt;/div&gt;
&lt;p&gt;interviewing.io evaluates students based on their coding skills, not their resume. We are open to students regardless of their university affiliation, college major, and pretty much anything else (we ask for your class year to make sure you’re available when companies want you and that’s about it). Unlike traditional campus recruiting, we attract students organically (getting free practice with engineers from top companies is a pretty big draw) from schools big and small from across the country.&lt;/p&gt;
&lt;div class=&quot;plotly-container&quot;&gt;&lt;a href=&quot;https://plot.ly/~aline_interviewingio/1040/?share_key=a7nsQAtV72pih0OKIUr1Rp?link=false&quot; target=&quot;_blank&quot; title=&quot;student heatmap&quot;&gt;&lt;img src=&quot;https://plot.ly/~aline_interviewingio/1040.png?share_key=a7nsQAtV72pih0OKIUr1Rp?link=false&quot; alt=&quot;student heatmap&quot; width=&quot;600&quot; onerror=&quot;this.onerror=null;this.src='https://plot.ly/404.png';&quot;/&gt;&lt;/a&gt;&lt;br/&gt;&lt;/div&gt;
&lt;p&gt;We’re also proud that &lt;strong&gt;almost 40 percent of our university candidates come from backgrounds that are underrepresented in tech&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&quot;plotly-container&quot;&gt;&lt;a href=&quot;https://plot.ly/~aline_interviewingio/1048/?share_key=sT0cNXIzAEhiDENPsIqEuL?link=false&quot; target=&quot;_blank&quot; title=&quot;student heatmap&quot;&gt;&lt;img src=&quot;https://plot.ly/~aline_interviewingio/1048.png?share_key=sT0cNXIzAEhiDENPsIqEuL?link=false&quot; alt=&quot;student heatmap&quot; width=&quot;600&quot; onerror=&quot;this.onerror=null;this.src='https://plot.ly/404.png';&quot;/&gt;&lt;/a&gt;&lt;br/&gt;&lt;/div&gt;
&lt;p&gt;Because of our completely blind, skills-first approach, we’ve seen an interesting phenomenon happen time and time again: when a student unmasks at the end of a successful interview, the company in question realizes that the student who just aced their technical phone screen was one whose resume was sitting at the bottom of the pile all along.&lt;/p&gt;
&lt;p&gt;In addition to identifying top students who bring a different lived experience to tech, we’re excited about the economics of our model. &lt;strong&gt;With interviewing.io, a mid-sized startup can staff their entire intern class for the same cost as attending 1-2 career fairs at top schools… with a good chunk of those interns coming from underrepresented backgrounds.&lt;/strong&gt; Want to hire interns and new grads in the most efficient, fair way possible? &lt;a href=&quot;https://interviewing.io/university/signup&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Sign up to be an employer on our university platform!&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Meena runs interviewing.io’s &lt;a href=&quot;https://interviewing.io/university/&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;university hiring platform&lt;/a&gt;. We help companies hire college students from all over the US, with a focus on diversity. Prior to joining interviewing.io, Meena was a software engineer at Clever, and before that, Meena was in college on the other side of the engineer interviewing equation.&lt;/em&gt;&lt;/p&gt;

&lt;div class=&quot;sharedaddy sd-sharing-enabled&quot;&gt;
&lt;div class=&quot;robots-nocontent sd-block sd-social sd-social-official sd-sharing&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Share this:&lt;/h3&gt;

&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Tue, 24 Oct 2017 17:30:55 +0000</pubDate>
<dc:creator>leeny</dc:creator>
<og:url>http://blog.interviewing.io/if-you-care-about-diversity-you-should-stop-hiring-from-the-same-five-schools/</og:url>
<og:title>If you care about diversity, don’t just hire from the same five schools</og:title>
<og:description></og:description>
<og:type>article</og:type>
<og:image></og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://blog.interviewing.io/if-you-care-about-diversity-you-should-stop-hiring-from-the-same-five-schools/</dc:identifier>
</item>
<item>
<title>Gmail Launches Add-ons</title>
<link>https://www.blog.google/products/g-suite/do-more-your-inbox-gmail-add-ons/</link>
<guid isPermaLink="true" >https://www.blog.google/products/g-suite/do-more-your-inbox-gmail-add-ons/</guid>
<description>&lt;p&gt;For many of us, email is mission control—the prompt to generate an invoice, prepare a presentation or follow up on a sales opportunity. With so many to-dos, imagine if you could complete these tasks directly from your inbox without interrupting your workflow.&lt;/p&gt;
&lt;p&gt;We believe email can do more, which is why we’re launching Gmail Add-ons, a new way to work with your favorite business apps directly in Gmail.&lt;/p&gt;
</description>
<pubDate>Tue, 24 Oct 2017 17:03:20 +0000</pubDate>
<dc:creator>alooPotato</dc:creator>
<og:type>article</og:type>
<og:title>Do more from your inbox with Gmail Add-ons</og:title>
<og:description>New Gmail Add-ons to help you speed up your workflows at work.</og:description>
<og:image>https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gmailadons_3.2e16d0ba.fill-1000x555.png</og:image>
<og:url>https://www.blog.google/products/g-suite/do-more-your-inbox-gmail-add-ons/</og:url>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.blog.google/products/g-suite/do-more-your-inbox-gmail-add-ons/</dc:identifier>
</item>
<item>
<title>Speech Recognition Is Not Solved</title>
<link>https://awni.github.io/speech-recognition/</link>
<guid isPermaLink="true" >https://awni.github.io/speech-recognition/</guid>
<description>&lt;p&gt;Ever since Deep Learning hit the scene in speech recognition, word error rates have fallen dramatically. But despite articles you may have read, we still don’t have human-level speech recognition. Speech recognizers have many failure modes. Acknowledging these and taking steps towards solving them is critical to progress. It’s the only way to go from &lt;abbr title=&quot;automatic speech recognition&quot;&gt;ASR&lt;/abbr&gt; which works for &lt;em&gt;some people, most of the time&lt;/em&gt; to ASR which works for &lt;em&gt;all people, all of the time&lt;/em&gt;.&lt;/p&gt;
&lt;div class=&quot;figure&quot; readability=&quot;9&quot;&gt;&lt;img src=&quot;https://awni.github.io/images/speech-recognition/wer.svg&quot;/&gt;&lt;p&gt;Improvements in word error rate over time on the Switchboard conversational speech recognition benchmark. The test set was collected in 2000. It consists of 40 phone conversations between two random native English speakers.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Saying we’ve achieved human-level in conversational speech recognition based just on Switchboard results is like saying an autonomous car drives as well as a human after testing it in one town on a sunny day without traffic. The recent improvements on conversational speech are astounding. But, the claims about human-level performance are too broad. Below are a few of the areas that still need improvement.&lt;/p&gt;
&lt;h2 id=&quot;accents-and-noise&quot;&gt;Accents and Noise&lt;/h2&gt;
&lt;p&gt;One of the most visible deficiencies in speech recognition is dealing with accents&lt;sup id=&quot;fnref:scottish_accent&quot;/&gt; and background noise. The straightforward reason is that most of the training data consists of American accented English with high signal-to-noise ratios. For example, the Switchboard conversational training and test sets only have native English speakers (mostly American) with little background noise.&lt;/p&gt;
&lt;p&gt;But, more training data likely won’t solve this problem on its own. There are a lot of languages many of which have a lot of dialects and accents. It’s not feasible to collect enough annotated data for all cases. Building a high quality speech recognizer just for American accented English needs upwards of 5 thousand hours of transcribed audio.&lt;/p&gt;
&lt;div class=&quot;figure&quot; readability=&quot;8&quot;&gt;&lt;img src=&quot;https://awni.github.io/images/speech-recognition/human_model.svg&quot;/&gt;&lt;div class=&quot;caption&quot; readability=&quot;11&quot;&gt;Comparison of human transcribers to Baidu’s Deep Speech 2 model on various types of speech.&lt;sup id=&quot;fnref:data_details&quot;/&gt; Notice the humans are worse at transcribing the non-American accents. This is probably due to an American bias in the transcriber pool. I would expect transcribers native to a given region to have much lower error rates for that region’s accents.&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;With background noise, it’s not uncommon for the SNR in a moving car to be as low as -5dB. People don’t have much trouble understanding one another in these environments. Speech recognizers, on the other hand, degrade more rapidly with noise. In the figure above we see the gap between the human and the model error rates increase dramatically from the low SNR to the high SNR audio.&lt;/p&gt;
&lt;h2 id=&quot;semantic-errors&quot;&gt;Semantic Errors&lt;/h2&gt;
&lt;p&gt;Often the word error rate is not the actual objective in a speech recognition system. What we care about is the &lt;em&gt;semantic error rate&lt;/em&gt;. That’s the fraction of utterances in which we misinterpret the meaning.&lt;/p&gt;
&lt;p&gt;An example of a semantic error is if someone said “let’s meet up Tuesday” but the speech recognizer predicted “let’s meet up today”. We can also have word errors without semantic errors. If the speech recognizer dropped the “up” and predicted “let’s meet Tuesday” the semantics of the utterance are unchanged.&lt;/p&gt;
&lt;p&gt;We have to be careful when using the word error rate as a proxy. Let me give a worst-case example to show why. A WER of 5% roughly corresponds to 1 missed word for every 20. If each sentence has 20 words (about average for English), the sentence error rate could be as high as 100%. Hopefully the mistaken words don’t change the semantic meaning of the sentences. Otherwise the recognizer could misinterpret every sentence even with a 5% WER.&lt;/p&gt;
&lt;p&gt;When comparing models to humans, it’s important to check the nature of the mistakes and not just look at the WER as a conclusive number. In my own experience, human transcribers tend to make fewer and less drastic semantic errors than speech recognizers.&lt;/p&gt;
&lt;p&gt;Researchers at Microsoft recently compared mistakes made by humans and their human-level speech recognizer.&lt;sup id=&quot;fnref:human_comparison&quot;/&gt; One discrepancy they found was that the model confuses “uh” with “uh huh” much more frequently than humans. The two terms have very different semantics: “uh” is just filler whereas “uh huh” is a &lt;em&gt;backchannel&lt;/em&gt; acknowledgement. The model and humans also made a lot of the same types of mistakes.&lt;/p&gt;
&lt;h2 id=&quot;single-channel-multi-speaker&quot;&gt;Single-channel, Multi-speaker&lt;/h2&gt;
&lt;p&gt;The Switchboard conversational task is also easier because each speaker is recorded with a separate microphone. There’s no overlap of multiple speakers in the same audio stream. Humans on the other hand can understand multiple speakers sometimes talking at the same time.&lt;/p&gt;
&lt;p&gt;A good conversational speech recognizer must be able to segment the audio based on who is speaking (&lt;em&gt;diarisation&lt;/em&gt;). It should also be able to make sense of audio with overlapping speakers (&lt;em&gt;source separation&lt;/em&gt;). This should be doable without needing a microphone close to the mouth of each speaker, so that conversational speech can work well in arbitrary locations.&lt;/p&gt;
&lt;h2 id=&quot;domain-variation&quot;&gt;Domain Variation&lt;/h2&gt;
&lt;p&gt;Accents and background noise are just two factors a speech recognizer needs to be robust to. Here are a few more:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Reverberation from varying the acoustic environment.&lt;/li&gt;
&lt;li&gt;Artefacts from the hardware.&lt;/li&gt;
&lt;li&gt;The codec used for the audio and compression artefacts.&lt;/li&gt;
&lt;li&gt;The sample rate.&lt;/li&gt;
&lt;li&gt;The age of the speaker.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Most people wouldn’t even notice the difference between an &lt;code class=&quot;highlighter-rouge&quot;&gt;mp3&lt;/code&gt; and a plain &lt;code class=&quot;highlighter-rouge&quot;&gt;wav&lt;/code&gt; file. Before we claim human-level performance, speech recognizers need to be robust to these sources of variability as well.&lt;/p&gt;
&lt;h2 id=&quot;context&quot;&gt;Context&lt;/h2&gt;
&lt;p&gt;You’ll notice the human-level error rate on benchmarks like Switchboard is actually quite high. If you were conversing with a friend and they misinterpreted 1 of every 20 words, you’d have a tough time communicating.&lt;/p&gt;
&lt;p&gt;One reason for this is that the evaluation is done &lt;em&gt;context-free&lt;/em&gt;. In real life we use many other cues to help us understand what someone is saying. Some examples of context that people use but speech recognizers don’t include:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;The history of the conversation and the topic being discussed.&lt;/li&gt;
&lt;li&gt;Visual cues of the person speaking including facial expressions and lip movement.&lt;/li&gt;
&lt;li&gt;Prior knowledge about the person we are speaking with.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Currently, Android’s speech recognizer has knowledge of your contact list so it can recognize your friends’ names.&lt;sup id=&quot;fnref:contacts&quot;/&gt; The voice search in maps products uses geolocation to narrow down the possible points-of-interest you might be asking to navigate to.&lt;sup id=&quot;fnref:geo_location&quot;/&gt;&lt;/p&gt;
&lt;p&gt;The accuracy of ASR systems definitely improves when incorporating this type of signal. But, we’ve just begun to scratch the surface on the type of context we can include and how it’s used.&lt;/p&gt;
&lt;h2 id=&quot;deployment&quot;&gt;Deployment&lt;/h2&gt;
&lt;p&gt;The recent improvements in conversational speech are not deployable. When thinking about what makes a new speech algorithm deployable, it’s helpful to think in terms of latency and compute. The two are related, as algorithms which increase compute tend to increase latency. But for simplicity I’ll discuss each separately.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Latency&lt;/strong&gt;: With latency, I mean the time from when the user is done speaking to when the transcription is complete. Low latency is a common product constraint in ASR. It can significantly impact the user experience. Latency requirements in the tens of milliseconds aren’t uncommon for ASR systems. While this may sound extreme, remember that producing the transcript is usually the first step in a series of expensive computations. For example in voice search the actual web-scale search has to be done after the speech recognition.&lt;/p&gt;
&lt;p&gt;Bidirectional recurrent layers are a good example of a latency killing improvement. All the recent state-of-the-art results in conversational speech use them. The problem is we can’t compute anything after the first bidirectional layer until the user is done speaking. So the latency scales with the length of the utterance.&lt;/p&gt;
&lt;div class=&quot;figure&quot; readability=&quot;9&quot;&gt;&lt;img src=&quot;https://awni.github.io/images/speech-recognition/forward_only.svg&quot;/&gt;&lt;img src=&quot;https://awni.github.io/images/speech-recognition/bidirectional.svg&quot;/&gt;&lt;p&gt;&lt;strong&gt;Left:&lt;/strong&gt; With a forward only recurrence we can start computing the transcription immediately. &lt;strong&gt;Right:&lt;/strong&gt; With a bidirectional recurrence we have to wait until all the speech arrives before beginning to compute the transcription.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;A good way to efficiently incorporate future information in speech recognition is still an open problem.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Compute&lt;/strong&gt;: The amount of computational power needed to transcribe an utterance is an economic constraint. We have to consider the &lt;em&gt;bang-for-buck&lt;/em&gt; of every accuracy improvement to a speech recognizer. If an improvement doesn’t meet an economical threshold, then it can’t be deployed.&lt;/p&gt;
&lt;p&gt;A classic example of a consistent improvement that never gets deployed is an ensemble. The 1% or 2% error reduction is rarely worth the 2-8x increase in compute. Modern RNN language models are also usually in this category since they are very expensive to use in a beam search; though I expect this will change in the future.&lt;/p&gt;
&lt;p&gt;As a caveat, I’m not suggesting research which improves accuracy at great computational cost isn’t useful. We’ve seen the pattern of “first slow but accurate, then fast” work well before. The point is just that until an improvement is sufficiently fast, it’s not usable.&lt;/p&gt;
&lt;h2 id=&quot;the-next-five-years&quot;&gt;The Next Five Years&lt;/h2&gt;
&lt;p&gt;There are still many open and challenging problems in speech recognition. These include:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Broadening the capabilities to new domains, accents and far-field, low SNR speech.&lt;/li&gt;
&lt;li&gt;Incorporating more context into the recognition process.&lt;/li&gt;
&lt;li&gt;Diarisation and source-separation.&lt;/li&gt;
&lt;li&gt;Semantic error rates and innovative methods for evaluating recognizers.&lt;/li&gt;
&lt;li&gt;Super low-latency and efficient inference.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;I look forward to the next five years of progress on these and other fronts.&lt;/p&gt;
&lt;h3 id=&quot;acknowledgements&quot;&gt;Acknowledgements&lt;/h3&gt;
&lt;p&gt;Thanks to &lt;a href=&quot;https://twitter.com/mrhannun&quot;&gt;@mrhannun&lt;/a&gt; for useful feedback and edits.&lt;/p&gt;


</description>
<pubDate>Tue, 24 Oct 2017 16:08:40 +0000</pubDate>
<dc:creator>allenleein</dc:creator>
<og:description>Ever since Deep Learning hit the scene in speech recognition, word error rates have fallen dramatically. But despite articles you may have read, we still don’t have human-level speech recognition. Speech recognizers have many failure modes. Acknowledging these and taking steps towards solving them is critical to progress. It’s the only way to go from ASR which works for some people, most of the time to ASR which works for all people, all of the time.</og:description>
<og:title>Speech Recognition Is Not Solved</og:title>
<dc:format>text/html</dc:format>
<dc:identifier>https://awni.github.io/speech-recognition/</dc:identifier>
</item>
<item>
<title>Saying Goodbye to Firebug</title>
<link>https://hacks.mozilla.org/2017/10/saying-goodbye-to-firebug/</link>
<guid isPermaLink="true" >https://hacks.mozilla.org/2017/10/saying-goodbye-to-firebug/</guid>
<description>&lt;p&gt;The most popular and powerful web development tool.&lt;/p&gt;&lt;p&gt;Firebug has been a phenomenal success. Over its 12-year lifespan, the open source tool developed a near cult following among web developers. When it came out in 2005, Firebug was the first tool to let programmers inspect, edit, and debug code right in the Firefox browser. It also let you monitor CSS, HTML, and JavaScript live in any web page, which was a huge step forward.&lt;/p&gt;
&lt;p&gt;Firebug caught people’s attention — and more than a million loyal fans still use it today.&lt;/p&gt;
&lt;p&gt;So it’s sad that Firebug is now reaching end-of-life in the Firefox browser, with the release of Firefox Quantum (version 57) next month. The good news is that all the capabilities of Firebug are now present in current Firefox Developer Tools.&lt;/p&gt;
&lt;p&gt;The story of Firefox and Firebug is synonymous with the rise of the web. We fought the good fight and changed how developers inspect HTML and debug JS in the browser. Firebug ushered in the Web 2.0 era. Today, the work pioneered by the Firebug community over the last 12 years lives on in &lt;a href=&quot;https://www.mozilla.org/en-US/firefox/developer/?utm_source=blog&amp;amp;utm_medium=hacks&amp;amp;utm_campaign=switch&quot;&gt;Firefox Developer Tools&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/firebug-large.png&quot;&gt;&lt;img class=&quot;aligncenter wp-image-31488 size-full&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/firebug-large.png&quot; alt=&quot;&quot; width=&quot;264&quot; height=&quot;211&quot; srcset=&quot;https://hacks.mozilla.org/files/2017/10/firebug-large.png 264w, https://hacks.mozilla.org/files/2017/10/firebug-large-250x200.png 250w&quot; sizes=&quot;(max-width: 264px) 100vw, 264px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Looking Forward, Looking Back&lt;/h3&gt;
&lt;p&gt;But before we move on, let’s take a few moments to remember all the great milestones of the Firebug project, and share some stories from early community members.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Jan 2006, Firebug 0.2&lt;/strong&gt;  Joe releases the single tab &lt;a href=&quot;https://youtu.be/JVCioNT-SYE&quot;&gt;console&lt;/a&gt; with AJAX logging.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;May 2006, Firebug 0.4&lt;/strong&gt;  There is a new top-level tab for JavaScript &lt;a href=&quot;https://youtu.be/LvdcAm1-4zU&quot;&gt;debugging&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dec 2006&lt;/strong&gt;  Firebug is open-sourced.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jan 2007, Firebug 1.0&lt;/strong&gt;  The start of Web 2.0!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Aug 2008, Firebug 1.2&lt;/strong&gt;  First FWG (Firebug Working Group) release.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Oct 2009, HTTP Archive (HAR)&lt;/strong&gt; &lt;a href=&quot;http://www.softwareishard.com/blog/har-12-spec/&quot;&gt;One archive&lt;/a&gt; for web performance and beyond.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Feb 2010&lt;/strong&gt;, &lt;strong&gt;Firebug Lite&lt;/strong&gt; for Google Chrome &lt;a href=&quot;https://blog.getfirebug.com/page/22/&quot;&gt;released&lt;/a&gt; (bookmarklet).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Apr 2010,&lt;/strong&gt; Dynamic and Graphical Web Page Breakpoints invented (&lt;a href=&quot;https://getfirebug.com/doc/breakpoints/paper/breakpoints.pdf&quot;&gt;pdf&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2011&lt;/strong&gt;Boom of Firebug &lt;a href=&quot;https://getfirebug.com/wiki/index.php/Firebug_Extensions&quot;&gt;extensions&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;June 2014, Firebug 2.0&lt;/strong&gt; Fresh new UI compatible with Firefox Australis.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;June 2016&lt;/strong&gt;, &lt;a href=&quot;https://blog.getfirebug.com/2016/06/07/unifying-firebug-firefox-devtools/&quot;&gt;Unifying&lt;/a&gt; Firebug &amp;amp; Firefox DevTools.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Oct 2017, Goodbye Firebug!&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/first-console.png&quot;&gt;&lt;img class=&quot;aligncenter wp-image-31489 size-full&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/first-console.png&quot; alt=&quot;&quot; width=&quot;385&quot; height=&quot;444&quot; srcset=&quot;https://hacks.mozilla.org/files/2017/10/first-console.png 385w, https://hacks.mozilla.org/files/2017/10/first-console-250x288.png 250w&quot; sizes=&quot;(max-width: 385px) 100vw, 385px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Firebug 0.2, Console panel&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I’d like to share some of my own fond Firebug memories and historic moments, beginning with how it all started.&lt;/p&gt;
&lt;p&gt;The very first version released in Jan 2006 on &lt;a href=&quot;https://addons.mozilla.org/cs/firefox/addon/firebug/versions/?page=4#version-0.2&quot;&gt;AMO&lt;/a&gt; is Firebug 0.2 with a short comment from Joe Hewitt:&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;em&gt;This is a very early release – the code is only a few days old. Beware of the leopard.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Later in December 2006, Joe makes the important decision to open source Firebug:&lt;/p&gt;
&lt;blockquote readability=&quot;14&quot;&gt;
&lt;p&gt;&lt;em&gt;The first announcement is in regards to Firebug’s licensing. As I was developing Firebug 1.0, I began to wonder if I should try to turn the project from a hobby into a business. When I proposed this idea on my blog, the response was very positive and reaffirmed my belief that Firebug could do well as a commercial product.&lt;br/&gt;However, in the end, I just don’t feel like that is the right thing to do. I love working on Firebug because I know I’m making a lot of people happy and helping to advance the state of the art. That’s a lot more meaningful to me than just about anything else, and so, I’ve decided that &lt;strong&gt;Firebug will remain free and open source&lt;/strong&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After releasing v1.0, Joe Hewitt moved on to his next adventure at Facebook and John J. Barton (IBM) soon became interested in resuscitating the project …&lt;/p&gt;
&lt;blockquote readability=&quot;19&quot;&gt;
&lt;p&gt;&lt;em&gt;Oh Firebug! Fun times. I started out as a user and contributor (of obscure debugging-of-eval features). When Joe Hewitt decided to move on, I hunted around IBM to gauge interest in continuing his work. At that time, enterprise Web apps were just starting to grow without much more than ‘window.alert()’ debugging. Once Jan ‘Honza’ Odvarko joined the Firebug effort, IBM’s Rational IDE team agreed to support my work on Firebug and I created an Eclipse plugin to integrate Firebug with the product. Honza and I filled in Joe’s great framework, scaling the tool to larger and more complex applications. We added tests and improved the release vetting, then fixed bugs and responded to bug reports to build community. Soon we had other contributors and a growing collection of Firebug extensions. Mike Collins joined me to help on the product side and I collaborated with Salman Mirghasemi at EPFL on research projects leveraging Firebug technology.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I’m proud of our collective efforts to sustain Firebug during the critical growth phase of Web technology. This tool helped countless developers build sites used by millions of people worldwide. Now every browser has a debugger inspired by our work. While I miss the scrappy self-reliant teamwork of Firebug development, we leave knowing we made big positive impact.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/net-panel.gif&quot;&gt;&lt;img class=&quot;aligncenter wp-image-31490 size-full&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/net-panel.gif&quot; alt=&quot;&quot; width=&quot;753&quot; height=&quot;342&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Firebug 1.2, Net panel&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/thumbnail-console.gif&quot;&gt;&lt;img class=&quot;aligncenter wp-image-31495 size-full&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/thumbnail-console.gif&quot; alt=&quot;&quot; width=&quot;214&quot; height=&quot;164&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The success of a project is always dependent on the dedication of developers, contributors, and involved users. But, there were also times when it wasn’t simple to keep up with the quickly evolving Firefox browser and we had to work hard.&lt;/p&gt;
&lt;p&gt;A snippet from John J. Barton’s &lt;a href=&quot;https://blog.getfirebug.com/2010/03/17/firebug-reflections/&quot;&gt;post&lt;/a&gt; (March 2010):&lt;/p&gt;
&lt;blockquote readability=&quot;14.334862385321&quot;&gt;
&lt;p&gt;&lt;em&gt;We’ve come along way since Joe Hewitt unleashed &lt;strong&gt;Firebug 1.0&lt;/strong&gt;. Arriving at the start of the Web 2.0 revolution, Firebug helped shift people from thinking&lt;/em&gt; &lt;a href=&quot;http://en.wikipedia.org/wiki/Web_2.0&quot;&gt;&lt;em&gt;Web 2.0&lt;/em&gt;&lt;/a&gt; &lt;em&gt;was a fad to realizing Web apps can be real. Firebug had to grow up in a hurry while we still did not understand the code well and certainly didn’t understand Firefox.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://ajaxian.com/archives/firebug-11-and-getfirebugcom&quot;&gt;&lt;em&gt;Firebug 1.1&lt;/em&gt;&lt;/a&gt; &lt;em&gt;wasn’t really meant to be, though it was used by a few dedicated and helpful folks. So&lt;/em&gt; &lt;a href=&quot;http://www.railsjedi.com/posts/24-Firebug-1-2-Excitement&quot;&gt;&lt;em&gt;Firebug 1.2&lt;/em&gt;&lt;/a&gt; &lt;em&gt;was our first real release beyond Joe’s original source. Behind the scenes we had lots of extra work to close a security hole in Firebug.  At the time we could not tell anyone: too many users were exposed.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/thumbnail-layout.gif&quot;&gt;&lt;img class=&quot;aligncenter wp-image-31496 size-full&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/thumbnail-layout.gif&quot; alt=&quot;&quot; width=&quot;214&quot; height=&quot;164&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Firebug has been always very popular project and many developers started working on Firebug features, fixing bugs and building extensions. Yes, many new extensions to extend  an extension. We were all using the same technology. Community happiness.&lt;/p&gt;
&lt;p&gt;There is a &lt;a href=&quot;http://www.softwareishard.com/blog/firebug/list-of-firebug-extensions/&quot;&gt;post&lt;/a&gt; I made about Firebug extensions, July 2008:&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;&lt;em&gt;Have you ever been interested in what extensions are available for Firebug? If yes, take a look at what I have found. Frankly, I was quite surprised how many Firebug extensions already exists out there.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There were about 10 Firebug extensions in 2008 and more than 60 in 2011. Not easy to evolve a code base that needs to support so many extensions, trust me!&lt;/p&gt;
&lt;p&gt;I started working on Firebug in 2007 and I joined John J. Barton when he was working on v1.2. At that time, the Firebug Working Group started and we all focused on building Firebug as well as the community around it. These were exciting times. We were relatively small group and every single new feature we introduced was used by millions of people the next day. We’d been getting great amount of feedback and learning a lot about how to build visual tools for web developers.&lt;/p&gt;
&lt;p&gt;The first Firebug piece I worked on was the Net panel. HTTP monitoring was always my &lt;a href=&quot;http://www.softwareishard.com/blog/firebug/introduction-to-firebug-net-panel/&quot;&gt;cup of tea&lt;/a&gt; and we soon noticed a lot of user requests to export data collected by the panel. Implementing such a feature wasn’t hard, the nice piece of work was introduction of a new format for exported data. A couple years later, around October 2009, we introduced the new HTTP Archive (HAR) format with Steve Souders (page-load-performance guru and author of YSlow, often considered the first Firebug extension) and Simon Perkins. This format was a great success and many tools support it now.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/YSlow.png&quot;&gt;&lt;img class=&quot;aligncenter wp-image-31491 size-full&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/YSlow.png&quot; alt=&quot;&quot; width=&quot;520&quot; height=&quot;323&quot; srcset=&quot;https://hacks.mozilla.org/files/2017/10/YSlow.png 520w, https://hacks.mozilla.org/files/2017/10/YSlow-250x155.png 250w, https://hacks.mozilla.org/files/2017/10/YSlow-500x311.png 500w&quot; sizes=&quot;(max-width: 520px) 100vw, 520px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;From Steve Souders &lt;a href=&quot;http://www.stevesouders.com/blog/2009/10/19/http-archive-specification-firebug-and-httpwatch/&quot;&gt;post&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;&lt;em&gt;I suggested that, rather than create yet another proprietary format, Firebug team up with HttpWatch to develop a common format, and drive that forward as a proposal for an industry standard. I introduced Simon Perkins (HttpWatch) and Jan “Honza” Odvarko (main Net Panel developer), then stepped back as they worked together to produce today’s announcement.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I had good times working with John and others on the project. Because Firebug was well written and well-architected, it was a pleasure to build on top of it. Joe did a great job laying the foundation to support dozens and dozens of extensions built atop Firebug. John J.was an excellent manager and peer to work with. One of the concepts we invented and implemented in Firebug was related to a new kind of breakpoint. We called it Dynamic and Graphical Web Page Breakpoints. Yeah, you might know these features as Break on XHR, Break on Next, Break on DOM mutation, etc.&lt;/p&gt;
&lt;p&gt;From Firebug &lt;a href=&quot;https://blog.getfirebug.com/2009/11/03/dynamic-and-graphical-web-page-breakpoints/&quot;&gt;blog&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote readability=&quot;9.9176470588235&quot;&gt;
&lt;p&gt;&lt;em&gt;Jan “Honza” Odvarko and I have submitted “&lt;/em&gt;&lt;a href=&quot;http://getfirebug.com/doc/breakpoints/paper/breakpoints.pdf&quot;&gt;&lt;em&gt;Dynamic and Graphical Web Page Breakpoints&lt;/em&gt;&lt;/a&gt;&lt;em&gt;” on the 1.5 breakpoints to&lt;/em&gt; &lt;a href=&quot;http://www2010.org/www/&quot;&gt;&lt;em&gt;WWW 2010&lt;/em&gt;&lt;/a&gt;&lt;em&gt;.  It motivates the various breakpoints, describes the user experience and the implementation, then relates this breakpoint work to academic papers.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you want the Cliff Notes version, we also have a&lt;/em&gt; &lt;a href=&quot;http://getfirebug.com/doc/breakpoints/demo.html&quot;&gt;&lt;em&gt;demo page&lt;/em&gt;&lt;/a&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/debugger-panel-20.png&quot;&gt;&lt;img class=&quot;aligncenter wp-image-31494 size-full&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/debugger-panel-20.png&quot; alt=&quot;&quot; width=&quot;720&quot; height=&quot;275&quot; srcset=&quot;https://hacks.mozilla.org/files/2017/10/debugger-panel-20.png 720w, https://hacks.mozilla.org/files/2017/10/debugger-panel-20-250x95.png 250w, https://hacks.mozilla.org/files/2017/10/debugger-panel-20-500x191.png 500w&quot; sizes=&quot;(max-width: 720px) 100vw, 720px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/thumbnail-net-waterfall.png&quot;&gt;&lt;img class=&quot;aligncenter wp-image-31497 size-full&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/thumbnail-net-waterfall.png&quot; alt=&quot;&quot; width=&quot;214&quot; height=&quot;164&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Firebug 2.0 was released in June 2014. It was a major rewrite of the UI in order to make it compatible with the new Firefox Australis theme. We delivered on time and we were proud of it, a true community achievement. Since that release, we’ve been in maintenance mode.  The latest Firebug version on AMO is 2.0.19.&lt;/p&gt;
&lt;p&gt;Officially, we started &lt;a href=&quot;https://blog.getfirebug.com/2016/06/07/unifying-firebug-firefox-devtools/&quot;&gt;unifying&lt;/a&gt; Firebug with built-in Firefox tools around 2016, but in fact the process began earlier. Mozilla’s strategy was to introduce new built-in developer tools offered as a default in Firefox. Modern developer tools written from scratch. The decision was made not to use Firebug as the platform to build upon. Some Firebug users and contributors were disappointed by this decision, but Mozilla’s infrastructure and requirements were different at that time. Sometimes it’s just better to start from scratch, which is especially true for software development.&lt;/p&gt;
&lt;p&gt;Most importantly, today’s Firefox DevTools are in great shape and faster than ever, based on web technologies like React/Redux/Webpack, cool things. The architecture is ready to support extensions. The team is great, with experienced tool developers. &lt;a href=&quot;https://twitter.com/FirefoxDevTools&quot;&gt;This is my team&lt;/a&gt;.  :-)&lt;/p&gt;

&lt;p&gt;The process of unifying Firebug with the rebuilt devtools was completed with the release of Firebug 3 (aka &lt;a href=&quot;https://github.com/firebug/firebug.next&quot;&gt;Firebug.next&lt;/a&gt;) in 2015. This prototype was built as an extension to built-in Firefox devtools and eventually integrated directly into devtools. You can learn about how to &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Tools/Migrating_from_Firebug&quot;&gt;migrate from Firebug&lt;/a&gt;. You can try Firefox Developer Tools by &lt;a href=&quot;https://www.mozilla.org/en-US/firefox/new/?utm_source=blog&amp;amp;utm_medium=hacks&amp;amp;utm_campaign=switch&quot;&gt;updating your release browser&lt;/a&gt; or downloading &lt;a href=&quot;https://www.mozilla.org/en-US/firefox/developer/?utm_source=blog&amp;amp;utm_medium=hacks&amp;amp;utm_campaign=switch&quot;&gt;Developer Edition&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Support for every old-school* extensions stops in Firefox Quantum (aka 57)&lt;/strong&gt;. Yes, &lt;strong&gt;including Firebug&lt;/strong&gt; and that’s why there was great opportunity to write this post.&lt;/p&gt;
&lt;p&gt;The king is dead, long live the king!&lt;/p&gt;

&lt;p&gt;Jan ‘Honza’ Odvarko&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;XUL &amp;amp; Add-on SDK based&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/original-firebug-logo.png&quot;&gt;&lt;img class=&quot;aligncenter wp-image-31498 size-full&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2017/10/original-firebug-logo.png&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;160&quot; srcset=&quot;https://hacks.mozilla.org/files/2017/10/original-firebug-logo.png 600w, https://hacks.mozilla.org/files/2017/10/original-firebug-logo-250x67.png 250w, https://hacks.mozilla.org/files/2017/10/original-firebug-logo-500x133.png 500w&quot; sizes=&quot;(max-width: 600px) 100vw, 600px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Of course, there are many more people who contributed to the Firebug project and made the lives of many other web developers happier.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;List of contributors&lt;/strong&gt;: Joe Hewitt, John J. Barton (IBM Almaden), Jan Odvarko (Mozilla Corp.), Max Stepanov (Aptana Inc.), Rob Campbell (Mozilla Corp.), Hans Hillen (Paciello Group, Mozilla), Curtis Bartley (Mozilla Corp.), Mike Collins (IBM Almaden), Kevin Decker, Mike Ratcliffe (Mozilla Corp.), Hernan Rodriguez Colmeiro, Austin Andrews, Christoph Dorn, Steven Roussey (Illuminations for Developers), Sebastian Zartner, Harutyun Amirjanyan, Simon Lindholm, Stampolidis Anastasios, Joe Walker (Mozilla Corp.), Vladimir Zhuravlev, Farshid Beheshti, Leon Sorokin, Florent Fayolle, Hector Zhao, Bharath Thiruveedula, Nathan Mische, Belakhdar Abdeldjalil, Jakob Kaltenbrunner, …&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;List of translators&lt;/strong&gt;: Leszek(teo)Zyczkowski (pl-PL), markh (nl), peter3 (sv-SE), AlleyKat (da-DK), Hector Zhao, lovelywcm (zh-CN), Lukas Kucharczyk, Michal Kec (cs-CZ), Team erweiterungen.de, ReinekeFux, Benedikt Langens, Sebastian Zartner (de-DE), l0stintranslation, gonzalopirobutirro, Luigi Grilli (it-IT), alexxed (ro-RO), Nicolas Martin, Franck Marcia (fr-FR), gLes (hu-HU), Xavi Ivars – Softcatala (ca), gezmen (tr-TR), eternoendless (es-AR), Dark Preacher (ru), Tiago Oliveira, Diego de Carvalho Zimmermann, Alexandre Rapaki (pt-BR), Juan Botias, Alvaro G. Vicario (es-ES), Andriy Zhouck (uk-UA), Hisateru Tanaka, k2jp (ja-JP), Mohsen Shadroo (fa-IR), Eduard Babayan (hy-AM), Helder Magalhaes (pt-PT), Tomaz Macus (sl-SI), Stoyan Stefanov, Alexander Shopov (bg), Kristjan Bjarni Guomundsson (is-IS), NGUYEN Manh Hung (vi-VN), Bwah (hr-HR), Sonickydon (el), David Gonzales (es), DakSrbija (sr), bootleq (zh-TW), Asier Iturralde Sarasola, Julen Irazoki Oteiza (eu), …&lt;/p&gt;
&lt;section class=&quot;about&quot; readability=&quot;0.47311827956989&quot;&gt;
&lt;p&gt;Firebug Team Leader&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;url&quot; href=&quot;https://hacks.mozilla.org/author/jodvarkomozilla-com/&quot;&gt;More articles by Jan Honza Odvarko…&lt;/a&gt;&lt;/p&gt;
&lt;/section&gt;</description>
<pubDate>Tue, 24 Oct 2017 15:26:58 +0000</pubDate>
<dc:creator>kungfudoi</dc:creator>
<og:url>https://hacks.mozilla.org/2017/10/saying-goodbye-to-firebug/</og:url>
<og:title>Saying Goodbye to Firebug</og:title>
<og:description>The most popular and powerful web development tool. Firebug has been a phenomenal success. Over its 12-year lifespan, the open source tool developed a near ...</og:description>
<og:image>https://hacks.mozilla.org/files/2017/10/firebug-large.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://hacks.mozilla.org/2017/10/saying-goodbye-to-firebug/</dc:identifier>
</item>
<item>
<title>Freedom of Information Release on Nikola Tesla (2011)</title>
<link>https://vault.fbi.gov/nikola-tesla/Nikola%20Tesla%20Part%2001%20of%2003/view</link>
<guid isPermaLink="true" >https://vault.fbi.gov/nikola-tesla/Nikola%20Tesla%20Part%2001%20of%2003/view</guid>
<description>[unable to retrieve full-text content]&lt;p&gt;Article URL: &lt;a href=&quot;https://vault.fbi.gov/nikola-tesla/Nikola%20Tesla%20Part%2001%20of%2003/view&quot;&gt;https://vault.fbi.gov/nikola-tesla/Nikola%20Tesla%20Part%2001%20of%2003/view&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=15541357&quot;&gt;https://news.ycombinator.com/item?id=15541357&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Points: 287&lt;/p&gt;&lt;p&gt;# Comments: 99&lt;/p&gt;</description>
<pubDate>Tue, 24 Oct 2017 13:30:52 +0000</pubDate>
<dc:creator>huntermeyer</dc:creator>
<og:title>Nikola Tesla Part 01 of 03</og:title>
<og:type>article</og:type>
<og:url>https://vault.fbi.gov/nikola-tesla/Nikola%20Tesla%20Part%2001%20of%2003</og:url>
<og:image>https://vault.fbi.gov/fbi_seal_mini.png</og:image>
<og:description></og:description>
<dc:language>en-us</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://vault.fbi.gov/nikola-tesla/Nikola%20Tesla%20Part%2001%20of%2003/view</dc:identifier>
</item>
<item>
<title>Portugal Bans Use of DRM to Limit Access to Public Domain Works</title>
<link>https://www.eff.org/deeplinks/2017/10/portugal-bans-use-drm-limit-access-public-domain-works</link>
<guid isPermaLink="true" >https://www.eff.org/deeplinks/2017/10/portugal-bans-use-drm-limit-access-public-domain-works</guid>
<description>&lt;p&gt;At EFF, we've become all too accustomed to &lt;a href=&quot;https://www.eff.org/deeplinks/2017/10/digital-rights-groups-demand-deletion-unlawful-filtering-mandate-proposed-eu&quot;&gt;bad news on copyright coming out of Europe&lt;/a&gt;, so it's refreshing to hear that Portugal has recently passed a law on copyright that helps to strike a fairer balance between users and copyright holders on DRM. The law doesn't abolish legal protection for DRM altogether—unfortunately, that wouldn't be possible for Portugal to do unilaterally, because it would be inconsistent with European Union law and with the WIPO Copyright Treaty to which the EU is a signatory. However, &lt;a href=&quot;http://www.wipo.int/wipolex/en/details.jsp?id=17389&amp;amp;utm_source=WIPO+Newsletters&amp;amp;utm_campaign=a58188490d-EMAIL_CAMPAIGN_2017_10_23&amp;amp;utm_medium=email&amp;amp;utm_term=0_bcb3de19b4-a58188490d-253950881&quot; target=&quot;_blank&quot;&gt;Law No. 36/2017 of June 2, 2017&lt;/a&gt;, which entered into force on June 3, 2017, does grant some important new exceptions to the law's anti-circumvention provisions, which make it easier for users to exercise their rights to access content without being treated as criminals.&lt;/p&gt;
&lt;p&gt;The amendments to Articles 217 and 221 of Portugal's &lt;a href=&quot;http://www.wipo.int/wipolex/en/details.jsp?id=17387&amp;amp;utm_source=WIPO+Newsletters&amp;amp;utm_campaign=a58188490d-EMAIL_CAMPAIGN_2017_10_23&amp;amp;utm_medium=email&amp;amp;utm_term=0_bcb3de19b4-a58188490d-253950881&quot; target=&quot;_blank&quot;&gt;Code of Copyright and Related Rights&lt;/a&gt; do three things. First, they provide that the anti-circumvention ban doesn't apply to circumvention of DRM in order to enjoy the normal exercise of copyright limitations and exceptions that are provided by Portuguese law. Although Portugal doesn't have a generalized fair use exception, the more specific copyright exceptions in Articles 75(2), 81, 152(4) and 189(1) of its law do include some key fair uses; including reproduction for private use, for news reporting, by libraries and archives, in teaching and education, in quotation, for persons with disabilities, and for digitizing orphan works. The circumvention of DRM in order to exercise these user rights is now legally protected.&lt;/p&gt;
&lt;p&gt;Second and perhaps even more significantly, the law prohibits the application of DRM to certain categories of works in the first place. These are works in the public domain (including new editions of works already in the public domain), and to works published or financed by the government. This provision alone will be a boon for libraries, archives, and for those with disabilities, ensuring that they never again have to worry about being unable to access or preserve works that ought to be free for everyone to use. The application of DRM to such works will now be an offence under the law, and if DRM has been applied to such works nevertheless, it will be permitted for a user to circumvent it.&lt;/p&gt;
&lt;p&gt;Third, the law also permits DRM to be circumvented where it was applied without the authorization of the copyright holder. From now on, if a licensee of a copyright work wishes to apply DRM to it when it is distributed in a new format or over a new streaming service, the onus will be on them to ask the copyright owner's permission first. If they don't do that, then it won't be an offence for its customers to bypass the DRM in order to obtain unimpeded access to the work, as its copyright owner may well have intended.&lt;/p&gt;
&lt;p&gt;If there's a shortcoming to the law, it's that it doesn't include any new exceptions to the ban on creating or distributing (or as lawmakers ludicrously call it, &quot;trafficking in&quot;) anti-circumvention devices.  This means that although users are now authorized to bypass DRM in more cases than before, they're on their own when it comes to accomplishing this. The amendments ought to have established clear exceptions authorizing the development and distribution of circumvention tools that have lawful uses, rather than leaving users to gain access to such tools through legally murky channels.&lt;/p&gt;
&lt;p&gt;Overall though, these amendments go to show just how much flexibility countries have to craft laws on DRM that strike a fairer balance between users and copyright holders—even if, like Portugal, those countries have international obligations that require them to have anti-circumvention laws. We applaud Portugal for recognizing the harmful effects that DRM has access to knowledge and information, and we hope that these amendments will provide a model for other countries wishing to make a similar stand for users' rights.&lt;/p&gt;
</description>
<pubDate>Tue, 24 Oct 2017 09:58:24 +0000</pubDate>
<dc:creator>DiabloD3</dc:creator>
<og:type>article</og:type>
<og:title>Portugal Bans Use of DRM to Limit Access to Public Domain Works</og:title>
<og:url>https://www.eff.org/deeplinks/2017/10/portugal-bans-use-drm-limit-access-public-domain-works</og:url>
<og:description>At EFF, we've become all too accustomed to bad news on copyright coming out of Europe, so it's refreshing to hear that Portugal has recently passed a law on copyright that helps to strike a fairer balance between users and copyright holders on DRM. The law doesn't abolish legal protection for...</og:description>
<og:image>https://www.eff.org/files/drm-og-2.png</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.eff.org/deeplinks/2017/10/portugal-bans-use-drm-limit-access-public-domain-works</dc:identifier>
</item>
<item>
<title>Sci-Hub: Public access to research papers</title>
<link>http://sci-hub.cc/</link>
<guid isPermaLink="true" >http://sci-hub.cc/</guid>
<description>&lt;p&gt;Sci-Hub&lt;/p&gt;
&lt;br /&gt;&lt;div id=&quot;first&quot; readability=&quot;8&quot;&gt;
&lt;p&gt;the first pirate website in the world to provide mass and public access to tens of millions of research papers&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;A research paper is a special publication written by scientists to be read by other researchers. Papers are &lt;em&gt;primary sources&lt;/em&gt; neccessary for research – for example, they contain detailed description of new results and experiments.&lt;/p&gt;
&lt;p&gt;papers we have in our library:&lt;br /&gt;more than &lt;span id=&quot;papercounter&quot;&gt;64,500,000&lt;/span&gt; and growing&lt;/p&gt;
&lt;p&gt;At this time the widest possible distribution of research papers, as well as of other scientific or educational sources, is artificially restricted by copyright laws. Such laws effectively slow down the development of science in human society. The Sci-Hub project, running from 5th September 2011, is challenging the status quo. At the moment, Sci-Hub provides access to &lt;em&gt;hundreds of thousands research papers every day&lt;/em&gt;, effectively bypassing any paywalls and restrictions.&lt;/p&gt;
</description>
<pubDate>Tue, 24 Oct 2017 07:30:43 +0000</pubDate>
<dc:creator>lorenzofeliz</dc:creator>
<og:image>/misc/img/logo_en.png</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>http://sci-hub.cc/</dc:identifier>
</item>
<item>
<title>The Future of Programming (2013)</title>
<link>http://worrydream.com/dbx/</link>
<guid isPermaLink="true" >http://worrydream.com/dbx/</guid>
<description>&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot; /&gt;&lt;base target=&quot;_top&quot; /&gt;&lt;title&gt;References for &quot;The Future of Programming&quot;&lt;/title&gt;&lt;link href=&quot;http://fonts.googleapis.com/css?family=Asap:400,400italic,700,700italic&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot; /&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;style.css&quot; type=&quot;text/css&quot; /&gt;&lt;/head&gt;&lt;body id=&quot;readabilityBody&quot; readability=&quot;245.67208053691&quot;&gt;

&lt;h4&gt;&lt;a class=&quot;selflink&quot; href=&quot;http://worrydream.com&quot;&gt;Bret Victor&lt;/a&gt; / July 30, 2013&lt;/h4&gt;
&lt;div class=&quot;intro&quot; readability=&quot;8.75&quot;&gt;
&lt;p&gt;I gave a talk at the DBX conference called &lt;strong&gt;&lt;a href=&quot;http://vimeo.com/71278954&quot;&gt;The Future of Programming&lt;/a&gt;&lt;/strong&gt;. Below are links and quotes from some primary sources I used, as well as links to wikipedia and elsewhere where you can learn more.&lt;/p&gt;
&lt;iframe src=&quot;http://player.vimeo.com/video/71278954&quot; width=&quot;470&quot; height=&quot;264&quot; frameborder=&quot;0&quot; webkitallowfullscreen=&quot;&quot; mozallowfullscreen=&quot;&quot; allowfullscreen=&quot;&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/div&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.002.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;p&gt;Much of the overall message and style of the talk was inspired by &lt;a href=&quot;http://en.wikipedia.org/wiki/Alan_Kay&quot;&gt;Alan Kay&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For more talks with a similar message, I highly recommend:&lt;/p&gt;
&lt;p&gt;For a broader overview of some of the systems and ideas in this talk, see:&lt;/p&gt;
&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.004.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Moore's law&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.005.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;IBM 650&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;slide clear&quot;&gt;
&lt;div class=&quot;pair&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.006.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.007.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Reactions to SOAP and Fortran&lt;/strong&gt;&lt;br /&gt;&lt;a class=&quot;indented&quot; href=&quot;http://worrydream.com/refs/Hamming-TheArtOfDoingScienceAndEngineering.pdf&quot;&gt;Richard Hamming -- The Art of Doing Science and Engineering, p25&lt;/a&gt; (pdf book)&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;In the beginning we programmed in absolute binary... Finally, a Symbolic Assembly Program was devised -- after more years than you are apt to believe during which most programmers continued their heroic absolute binary programming. At the time [the assembler] first appeared I would guess about 1% of the older programmers were interested in it -- using [assembly] was &quot;sissy stuff&quot;, and a real programmer would not stoop to wasting machine capacity to do the assembly.&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;Yes! Programmers wanted no part of it, though when pressed they had to admit their old methods used more machine time in locating and fixing up errors than the [assembler] ever used. One of the main complaints was when using a symbolic system you do not know where anything was in storage -- though in the early days we supplied a mapping of symbolic to actual storage, and believe it or not they later lovingly pored over such sheets rather than realize they did not need to know that information if they stuck to operating within the system -- no! When correcting errors they preferred to do it in absolute binary.&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;FORTRAN was proposed by Backus and friends, and again was opposed by almost all programmers. First, it was said it could not be done. Second, if it could be done, it would be too wasteful of machine time and capacity. Third, even if it did work, no respectable programmer would use it -- it was only for sissies!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;John von Neumann's reaction to assembly language and Fortran&lt;/strong&gt;&lt;br /&gt;&lt;a class=&quot;indented&quot; href=&quot;http://www.columbia.edu/cu/computinghistory/index.html&quot;&gt;John A.N. Lee, Virginia Polytechnical Institute&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;John von Neumann, when he first heard about FORTRAN in 1954, was unimpressed and asked &quot;why would you want more than machine language?&quot; One of von Neumann's students at Princeton recalled that graduate students were being used to hand assemble programs into binary for their early machine. This student took time out to build an assembler, but when von Neumann found out about it he was very angry, saying that it was a waste of a valuable scientific computing instrument to use it to do clerical work.&lt;/p&gt;
&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.008.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;h2&gt;coding -&amp;gt; direct manipulation of data&lt;/h2&gt;
&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.013.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Sketchpad&lt;/strong&gt; (Ivan Sutherland)&lt;/p&gt;
&lt;h2&gt;procedures -&amp;gt; goals and constraints&lt;/h2&gt;
&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.017.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;PLANNER&lt;/strong&gt; (Carl Hewitt)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Prolog&lt;/strong&gt; (Alain Colmerauer, et al)&lt;/p&gt;
&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.019.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;SNOBOL&lt;/strong&gt; (Ralph Griswold, et al)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;regular expressions&lt;/strong&gt; (Ken Thompson)&lt;/p&gt;
&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.020.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;ARPANET&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Communicating with aliens&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;see also&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;text dump -&amp;gt; spatial representations&lt;/h2&gt;
&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.024.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;NLS&lt;/strong&gt; (Doug Engelbart, SRI)&lt;/p&gt;
&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.026.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;GRAIL&lt;/strong&gt; (T.O. Ellis et al, RAND Corporation)&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://archive.org/details/AlanKeyD1987?start=1439.5&quot;&gt;video&lt;/a&gt; (from Alan Kay's talk &quot;Doing With Images Makes Symbols&quot;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/RAND_Tablet&quot;&gt;wikipedia&lt;/a&gt; (stub)&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.027.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Smalltalk&lt;/strong&gt; (Alan Kay et al, Xerox PARC)&lt;/p&gt;
&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.028.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;PLATO&lt;/strong&gt; (Don Bitzer et al, University of Illinois)&lt;/p&gt;
&lt;h2&gt;sequential -&amp;gt; concurrent&lt;/h2&gt;
&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.030.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;von Neumann computer architecture&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;von Neumann bottleneck&lt;/strong&gt;&lt;br /&gt;&lt;a class=&quot;indented&quot; href=&quot;http://worrydream.com/refs/Backus-CanProgrammingBeLiberated.pdf&quot;&gt;John Backus (1978) -- Can Programming Be Liberated from the von Neumann Style?&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;Surely there must be a less primitive way of making big changes in the store than by pushing vast numbers of words back and forth through the von Neumann bottleneck. Not only is this tube a literal bottleneck for the data traffic of a problem, but, more importantly, it is an intellectual bottleneck that has kept us tied to word-at-a-time thinking instead of encouraging us to think in terms of the larger conceptual units of the task at hand. Thus programming is basically planning and detailing the enormous traffic of words through the von Neumann bottleneck, and much of that traffic concerns not significant data itself, but where to find it.&lt;/p&gt;
&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.031.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;semiconductor integrated circuit&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Intel 4004 microprocessor&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;semiconductor memory&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.032.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;massively parallel processor array&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;see also&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;slide clear&quot;&gt;&lt;img src=&quot;http://worrydream.com/dbx/slides/slide.034.png&quot; width=&quot;420&quot; height=&quot;315&quot; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Actor model&lt;/strong&gt; (Carl Hewitt)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;referenced in passing&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;Closing&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;&quot;We don't know what programming is.&quot;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;indented&quot; href=&quot;http://www.infoq.com/presentations/We-Really-Dont-Know-How-To-Compute&quot;&gt;Gerry Sussman -- We Really Don't Know How To Compute!&lt;/a&gt; (video)&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;[intro] I think we're in real trouble. I think we haven't the foggiest idea how to compute real well... I think that most of the things we've been talking about, even here [at this conference], are obsolete.&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;[40:30] I'm only pushing this idea, not because I think it's the right answer. I'm trying to twist us, so we say, &quot;This is a different way to think.&quot; We have to think fifty-two different ways to fix this problem. I don't know how to make a machine that builds a person out of a cell. But I think the problem is that we've been stuck for too long diddling with our details. We've been sitting here worrying about our type system, when we should be worrying about how to get flexible machines and flexible programming.&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;[1:01:30] We have to throw away our current ways of thinking if we ever expect to solve these problems.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;indented&quot;&gt;See also &lt;a href=&quot;http://www.youtube.com/watch?v=oKg1hTOQXoY&quot;&gt;Alan Kay -- The Computer Revolution Hasn't Happened Yet&lt;/a&gt; (video)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&quot;The most dangerous thought you can have as a creative person is to think you know what you're doing.&quot;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;indented&quot; href=&quot;http://worrydream.com/refs/Hamming-TheArtOfDoingScienceAndEngineering.pdf&quot;&gt;Richard Hamming -- The Art of Doing Science and Engineering, p5&lt;/a&gt; (pdf book)&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;In science if you know what you are doing you should not be doing it.&lt;br /&gt;In engineering if you do not know what you are doing you should not be doing it.&lt;br /&gt;Of course, you seldom, if ever, see either pure state.&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;indented&quot; href=&quot;http://longnow.org/essays/richard-feynman-connection-machine&quot;&gt;Danny Hillis -- Richard Feynman and The Connection Machine&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;In retrospect I realize that in almost everything that we [Hillis and Feynman] worked on together, we were both amateurs. In digital physics, neural networks, even parallel computing, we never really knew what we were doing. But the things that we studied were so new that no one else knew exactly what they were doing either. It was amateurs who made the progress.&lt;/p&gt;
&lt;h2&gt;&quot;Why did all these ideas happen during this particular time period?&quot;&lt;/h2&gt;
&lt;p&gt;There may be a number of reasons.&lt;/p&gt;
&lt;p&gt;The story I told in the talk -- &quot;they didn't know what they were doing, so they tried everything&quot; -- was essentially that programming at the time was in the &quot;pre-&lt;a href=&quot;https://en.wikipedia.org/wiki/Paradigm&quot;&gt;paradigm&lt;/a&gt; phase&quot;, as defined by Thomas Kuhn in &lt;a href=&quot;http://en.wikipedia.org/wiki/The_Structure_of_Scientific_Revolutions&quot;&gt;The Structure of Scientific Revolutions&lt;/a&gt;. This is the period of time before researchers reach consensus on what problems they're actually trying to solve. The establishment of distinct &lt;a href=&quot;https://en.wikipedia.org/wiki/Programming_paradigm&quot;&gt;programming paradigms&lt;/a&gt; (e.g., functional, logic, etc.) led into Kuhn's &quot;normal science&quot; phase (or as Sussman put it, &quot;diddling with details&quot;) where the foundations of the subject tend to be taken for granted.&lt;/p&gt;
&lt;p&gt;But there's another story, which has to do with funding models. Much fundamental research at the time, including Engelbart's NLS and the Internet, was funded by &lt;a href=&quot;http://en.wikipedia.org/wiki/DARPA&quot;&gt;ARPA&lt;/a&gt;, an agency of the US Defense Department which had been given significant resources due to the cold war.&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;indented&quot; href=&quot;http://worrydream.com/refs/FoundingOfTheAILab.pdf&quot;&gt;Stefanie Chiou, et al -- The Founding of the MIT AI Lab&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;ARPA ushered in an era of abundant funding for university projects, offering far more in terms of funding than any other research funds at the time. Where institutions such as the National Science Foundation and the Three Services Program provided funding to research programs at the level of tens of thousands of dollars, ARPA was willing to throw millions into the creation and support of promising research efforts.&lt;/p&gt;
&lt;p&gt;Part of what made ARPA funding so successful was that its directors (such as &lt;a href=&quot;http://en.wikipedia.org/wiki/JCR_Licklider&quot;&gt;J.C.R. Licklider&lt;/a&gt; and &lt;a href=&quot;http://en.wikipedia.org/wiki/Robert_Taylor_(computer_scientist)&quot;&gt;Bob Taylor&lt;/a&gt;) were free to aggressively seek out and fund the most promising individuals with &quot;no strings attached&quot;.&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;indented&quot; href=&quot;http://worrydream.com/refs/FoundingOfTheAILab.pdf&quot;&gt;Ibid.&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;The funding model used within ARPA at the time was that of giving large chunks of money to individual laboratories to be divided up at the discretion of the laboratory director.&lt;/p&gt;
&lt;p&gt;This situation changed around 1973, when ARPA became DARPA. (The D is for Defense.)&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;indented&quot; href=&quot;http://en.wikipedia.org/wiki/DARPA&quot;&gt;wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;The Mansfield Amendment of 1973 expressly limited appropriations for defense research (through ARPA/DARPA) to projects with &lt;em&gt;direct military application&lt;/em&gt;. Some contend that the amendment devastated American science, since ARPA/DARPA was a major funding source for basic science projects of the time; the National Science Foundation never made up the difference as expected.&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;The resulting &quot;brain drain&quot; is also credited with boosting the development of the fledgling personal computer industry. Many young computer scientists fled from the universities to startups and private research labs like Xerox PARC.&lt;/p&gt;
&lt;p&gt;One way of interpreting this is that the Mansfield Amendment killed research, but &quot;induced labor&quot; on an industry. The industrial mindset -- short-term, results-driven, immediately-applicable -- is generally hostile to long-term, exploratory, foundational research. (The canonical counterexamples, &lt;a href=&quot;http://en.wikipedia.org/wiki/Bell_Labs&quot;&gt;Bell Labs&lt;/a&gt; and &lt;a href=&quot;http://en.wikipedia.org/wiki/PARC_(company)&quot;&gt;Xerox PARC&lt;/a&gt;, were anomalies for various reasons. See &lt;a href=&quot;http://www.amazon.com/dp/0143122797&quot;&gt;The Idea Factory&lt;/a&gt; and &lt;a href=&quot;http://www.amazon.com/dp/0887309895&quot;&gt;Dealers of Lightning&lt;/a&gt;, respectively.)&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;http://en.wikipedia.org/wiki/National_Science_Foundation&quot;&gt;National Science Foundation&lt;/a&gt; continued to exist as a basic-science funding agency. But unlike ARPA, the NSF funds &lt;em&gt;projects, not people&lt;/em&gt;, and project proposals must be accepted by a peer review board. Any sufficiently-revolutionary project, especially at the early stages, will sound too crazy for a board to accept. Worse, requiring a detailed project proposal means that the NSF simply can't fund truly exploratory research, where the goal is not to solve a problem, but to discover and understand the problem in the first place.&lt;/p&gt;
&lt;p&gt;A third story to explain why so many ideas happened during this time period was that everyone was on drugs. See &lt;a href=&quot;http://www.amazon.com/dp/0143036769&quot;&gt;What the Dormouse Said&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;A clarification about &quot;not knowing what you're doing&quot;&lt;/h2&gt;
&lt;div class=&quot;xoutro&quot; readability=&quot;70.019315188762&quot;&gt;
&lt;p&gt;&lt;strong&gt;&quot;The most dangerous thought you can have as a creative person is to think you know what you're doing.&quot;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It's possible to misinterpret what I'm saying here. When I talk about not knowing what you're doing, I'm arguing against &quot;expertise&quot;, a feeling of mastery that traps you in a particular way of thinking.&lt;/p&gt;
&lt;p&gt;But I want to be clear -- &lt;em&gt;I am not advocating ignorance.&lt;/em&gt; Instead, I'm suggesting a kind of informed skepticism, a kind of humility.&lt;/p&gt;
&lt;p&gt;Ignorance is remaining willfully unaware of the existing base of knowledge in a field, proudly jumping in and stumbling around. This approach is fashionable in certain hacker/maker circles today, and it's poison.&lt;/p&gt;
&lt;p&gt;Knowledge is essential. Past ideas are essential. Knowledge and ideas that have coalesced into &lt;em&gt;theory&lt;/em&gt; is one of the most beautiful creations of the human species. Without Maxwell's equations, you can spend a lifetime fiddling with radio equipment and never invent radar. Without dynamic programming, you can code for days and &lt;a href=&quot;http://pindancing.blogspot.com/2009/09/sudoku-in-coders-at-work.html&quot;&gt;not even build a sudoku solver&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It's good to learn how to do something. It's better to learn many ways of doing something. But it's best to learn all these ways as &lt;em&gt;suggestions or hints&lt;/em&gt;. Not &lt;em&gt;truth&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Learn tools, and use tools, but don't &lt;em&gt;accept&lt;/em&gt; tools. Always distrust them; always be alert for alternative ways of thinking. This is what I mean by avoiding the conviction that you &quot;know what you're doing&quot;.&lt;/p&gt;
&lt;p class=&quot;separator&quot;&gt;* * *&lt;/p&gt;
&lt;p&gt;This point is perhaps best made by David Hestenes. Here, he's writing about mathematical tools for physics, but his observation applies identically to any sort of tool or way of thinking:&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;indented&quot; href=&quot;http://worrydream.com/refs/Hestenes-ReformingTheMathematicalLanguageOfPhysics.pdf&quot;&gt;David Hestenes -- Reforming the Mathematical Language of Physics&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;Mathematics is taken for granted in the physics curriculum -- a body of immutable truths to be assimilated and applied. The profound influence of mathematics on our conceptions of the physical world is never analyzed. The possibility that mathematical tools used today were &lt;strong&gt;invented to solve problems in the past and might not be well suited for current problems&lt;/strong&gt; is never considered...&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;One does not have to go very deeply into the history of physics to discover the profound influence of mathematical invention. Two famous examples will suffice to make the point: The invention of analytic geometry and calculus was essential to Newton’s creation of classical mechanics. The invention of tensor analysis was essential to Einstein’s creation of the General Theory of Relativity.&lt;/p&gt;
&lt;p class=&quot;quote&quot;&gt;The point I wish to make by citing these two examples is that without essential mathematical concepts the two theories would have been literally inconceivable. &lt;strong&gt;The mathematical modeling tools we employ at once extend and limit our ability to conceive the world.&lt;/strong&gt; Limitations of mathematics are evident in the fact that the analytic geometry that provides the foundation for classical mechanics is insufficient for General Relativity. This should alert one to the possibility of other conceptual limits in the mathematics used by physicists.&lt;/p&gt;
&lt;p&gt;Lastly, here's some advice Alan Kay gave me (as I was going through a small personal crisis as a result of reading Jerome Bruner's &quot;Toward a Theory of Instruction&quot;):&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I think the trick with knowledge is to &quot;acquire it, and forget all except the perfume&quot; -- because it is noisy and sometimes drowns out one's own &quot;brain voices&quot;. The perfume part is important because it will help find the knowledge again to help get to the destinations the inner urges pick.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/body&gt;</description>
<pubDate>Tue, 24 Oct 2017 07:07:09 +0000</pubDate>
<dc:creator>illo</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>http://worrydream.com/dbx/</dc:identifier>
</item>
<item>
<title>Introduction to web scraping with Python</title>
<link>https://datawhatnow.com/introduction-web-scraping-python/</link>
<guid isPermaLink="true" >https://datawhatnow.com/introduction-web-scraping-python/</guid>
<description>&lt;p&gt;Data is the core of predictive modeling, visualization, and analytics. Unfortunately, the needed data is not always readily available to the user, it is most often unstructured. The biggest source of data is the Internet, and with programming, we can extract and process the data found on the Internet for our use – this is called web scraping. Web scraping allows us to extract data from websites and to do what we please with it. In this post, I will show you how to scrape a website with only a few of lines of code in Python. All the code used in this post can be found in my GitHub &lt;a href=&quot;https://github.com/Weenkus/DataWhatNow-Codes/blob/master/introduction_to_web_scraping_with_python/web_scraping.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;notebook&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Web scraping with Python&lt;/h3&gt;
&lt;p&gt;&lt;img class=&quot;border-color: 0 wp-image-338 alignright&quot; src=&quot;https://i2.wp.com/datawhatnow.com/wp-content/uploads/2017/05/web_scraping-1.png?resize=216%2C351&amp;amp;ssl=1&quot; alt=&quot;Web scraping&quot; srcset=&quot;https://i2.wp.com/datawhatnow.com/wp-content/uploads/2017/05/web_scraping-1.png?w=684&amp;amp;ssl=1 684w, https://i2.wp.com/datawhatnow.com/wp-content/uploads/2017/05/web_scraping-1.png?resize=185%2C300&amp;amp;ssl=1 185w, https://i2.wp.com/datawhatnow.com/wp-content/uploads/2017/05/web_scraping-1.png?resize=631%2C1024&amp;amp;ssl=1 631w&quot; sizes=&quot;(max-width: 216px) 100vw, 216px&quot; data-recalc-dims=&quot;1&quot;/&gt;Even though there are popular frameworks and services for scraping (&lt;a href=&quot;https://scrapy.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Scrapy&lt;/a&gt;, &lt;a href=&quot;https://scrapinghub.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Scrapinghub&lt;/a&gt;, etc.), sometimes their learning curve can be a bit steep or they might be an overkill for the task at hand. Learning to do it with simple Python libraries will give you better insight into how these frameworks work if you ever use them down the line. I hope you are sold on the idea, so let’s start!&lt;/p&gt;
&lt;p&gt;To scrape a website, we have to somehow communicate over the Internet (HTTP), for which we will use a popular Python library called &lt;a href=&quot;http://docs.python-requests.org/en/master/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Requests&lt;/a&gt;. When we retrieve the data, we will have to extract it from HTML, for which we will use &lt;a href=&quot;http://lxml.de/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;lxml&lt;/a&gt;  (&lt;a href=&quot;https://www.crummy.com/software/BeautifulSoup/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Beautiful Soup&lt;/a&gt; is a popular alternative).&lt;/p&gt;
&lt;pre class=&quot;EnlighterJSRAW&quot; data-enlighter-language=&quot;python&quot;&gt;
import requests
from lxml import html

url = 'https://www.datawhatnow.com'

def get_parsed_page(url):
 &quot;&quot;&quot;Return the content of the website on the given url in
 a parsed lxml format that is easy to query.&quot;&quot;&quot;
 
 response = requests.get(url)
 parsed_page = html.fromstring(response.content)
 return parsed_page

parsed_page = get_parsed_page(url)

# Print the website's title
parsed_page.xpath('//h1/a/text()')  # ['Data, what now?']
&lt;/pre&gt;
&lt;p&gt;The lxml library allows us to create a tree structure that is easily queried for information using XPath. Using XPath, we can define the path to the element that contains the information we need. For example, if we want to get the title of the website, we first have to find out in which HTML element it resides. That is easily done by using the &lt;em&gt;inspect&lt;/em&gt; function of the browser of your choice.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter size-full wp-image-355&quot; src=&quot;https://i0.wp.com/datawhatnow.com/wp-content/uploads/2017/05/web_scraping_inspect.png?resize=720%2C459&amp;amp;ssl=1&quot; alt=&quot;Web Scraping Inspect&quot; srcset=&quot;https://i0.wp.com/datawhatnow.com/wp-content/uploads/2017/05/web_scraping_inspect.png?w=902&amp;amp;ssl=1 902w, https://i0.wp.com/datawhatnow.com/wp-content/uploads/2017/05/web_scraping_inspect.png?resize=300%2C191&amp;amp;ssl=1 300w, https://i0.wp.com/datawhatnow.com/wp-content/uploads/2017/05/web_scraping_inspect.png?resize=768%2C490&amp;amp;ssl=1 768w&quot; sizes=&quot;(max-width: 720px) 100vw, 720px&quot; data-recalc-dims=&quot;1&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter wp-image-358 size-full&quot; src=&quot;https://i0.wp.com/datawhatnow.com/wp-content/uploads/2017/05/web_scraping_html-1.png?resize=537%2C152&amp;amp;ssl=1&quot; alt=&quot;Web Scraping Inspect&quot; srcset=&quot;https://i0.wp.com/datawhatnow.com/wp-content/uploads/2017/05/web_scraping_html-1.png?w=537&amp;amp;ssl=1 537w, https://i0.wp.com/datawhatnow.com/wp-content/uploads/2017/05/web_scraping_html-1.png?resize=300%2C85&amp;amp;ssl=1 300w&quot; sizes=&quot;(max-width: 537px) 100vw, 537px&quot; data-recalc-dims=&quot;1&quot;/&gt;&lt;/p&gt;

&lt;p&gt;All the scraping examples in this post will be done on this very website, &lt;a href=&quot;https://datawhatnow.com&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;datawhatnow.com&lt;/a&gt;. The title of this website is the text inside an &amp;lt;a&amp;gt; tag, which has a parent &amp;lt;h1&amp;gt; tag. To get the text, we run the query ‘//h1/a/text()’. It reads as “starting from the root, find an &amp;lt;h1&amp;gt; tag, then find its child &amp;lt;a&amp;gt; tag and extract the text inside it”. Using “//” allows us to write shorter queries because we don’t have to specify all the nodes in a path.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter wp-image-330 size-full&quot; src=&quot;https://i2.wp.com/datawhatnow.com/wp-content/uploads/2017/05/xpath-1.png?resize=661%2C407&amp;amp;ssl=1&quot; alt=&quot;web scraping&quot; srcset=&quot;https://i2.wp.com/datawhatnow.com/wp-content/uploads/2017/05/xpath-1.png?w=661&amp;amp;ssl=1 661w, https://i2.wp.com/datawhatnow.com/wp-content/uploads/2017/05/xpath-1.png?resize=300%2C185&amp;amp;ssl=1 300w&quot; sizes=&quot;(max-width: 661px) 100vw, 661px&quot; data-recalc-dims=&quot;1&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Using what we learned so far, we can scrape the titles of the blog posts on this website.&lt;/p&gt;
&lt;pre class=&quot;EnlighterJSRAW&quot; data-enlighter-language=&quot;python&quot;&gt;
# Print post names
parsed_page.xpath('//h2/a/text()')

# Output
# ['SimHash for question deduplication',
#  'Feature importance and why it’s important']
&lt;/pre&gt;
&lt;h3&gt; Crawling&lt;/h3&gt;
&lt;p&gt;Web scraping is the act of extracting information from the website. Sometimes the program has to move from one link to another to collect all needed information – this is called crawling. We will find URLs of interest and process them just as before (request and parse).&lt;/p&gt;
&lt;p&gt;Let’s try to extract paragraph titles from blog posts on &lt;a href=&quot;https://datawhatnow.com&quot;&gt;datawhatnow.com&lt;/a&gt;. We have to find the links to the posts, request their HTML code and parse it. So far we have only been extracting text from tags – now we have to extract the link from the “href” attribute in the &amp;lt;a&amp;gt; tag. Luckily for us, that’s easy: instead of writing “text()” like we did before, we just write “@attribute_name”, in our case “@href”.&lt;/p&gt;
&lt;pre class=&quot;EnlighterJSRAW&quot; data-enlighter-language=&quot;python&quot;&gt;
# Getting paragraph titles in blog posts
post_urls = parsed_page.xpath('//h2//a/@href')

for post_url in post_urls:
    print('Post url:', post_url)
    
    parsed_post_page = get_parsed_page(post_url)
    paragraph_titles = parsed_post_page.xpath('//h3/text()')
    paragraph_titles = map(lambda x: ' \n  ' + x, paragraph_titles)
    print(''.join(paragraph_titles) + '\n')

# Output
# Post url: https://datawhatnow.com/simhash-question-deduplicatoin/
# 
#  SimHash 
#  Features 
#  Model performance 
#  Conclusion 
#  References 
#  Leave a Reply  
#  GitHub 
#  Newsletter 
#  Recent Posts 
#  Archives
#
# Post url: https://datawhatnow.com/feature-importance/
# 
#  Data exploration 
#  Feature engineering 
#  Baseline model performance 
#  Feature importance 
#  Model performance with feature importance analysis 
#  Conclusion 
#  Leave a Reply  
#  GitHub 
#  Newsletter 
#  Recent Posts 
#  Archives
&lt;/pre&gt;
&lt;p&gt;Obviously, something is wrong – we extracted the paragraph titles but we also collected other &amp;lt;h3&amp;gt; texts (‘Leave a Reply’, ‘GitHub’, ‘Newsletter’, etc.). Our XPath query was not specific enough. Inspecting the blog post links shows that their parent is a &amp;lt;div&amp;gt; tag with an attribute “class=”entry-content””. We can use this information to write a more specific query (‘//div[@class=”entry-content”]/h3/text()’).&lt;/p&gt;
&lt;pre class=&quot;EnlighterJSRAW&quot; data-enlighter-language=&quot;python&quot;&gt;
for post_url in post_urls:
    print('Post url:', post_url)
    
    parsed_post_page = get_parsed_page(post_url)
    paragraph_title_xpath = '//div[@class=&quot;entry-content&quot;]/h3/text()'
    paragraph_titles = parsed_post_page.xpath(paragraph_title_xpath)
    paragraph_titles = map(lambda x: ' \n  ' + x, paragraph_titles)
    print(''.join(paragraph_titles) + '\n')

# Post url: https://datawhatnow.com/simhash-question-deduplicatoin/
# 
#  SimHash 
#  Features 
#  Model performance 
#  Conclusion 
#  References
#
# Post url: https://datawhatnow.com/feature-importance/
#
#  Data exploration 
#  Feature engineering 
#  Baseline model performance 
#  Feature importance 
#  Model performance with feature importance analysis 
#  Conclusion
&lt;/pre&gt;
&lt;p&gt;Now the paragraph headings are the only ones being printed.&lt;/p&gt;
&lt;h3&gt;Robots&lt;/h3&gt;
&lt;p&gt;Web scraping is powerful, but with great power comes great responsibility. When you are scraping somebody’s website, you should be mindful of not sending too many requests. Most websites have a “robots.txt” which shows the rules that your web scraper should obey (which URLs are allowed to be scraped, which ones are not, the rate of requests you can send, etc.). You can check out &lt;a href=&quot;https://datawhatnow.com/robots.txt&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;my robots.txt file&lt;/a&gt;, or, for example, the ones from &lt;a href=&quot;https://news.ycombinator.com/robots.txt&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Hacker News&lt;/a&gt; or &lt;a href=&quot;http://www.datatau.com/robots.txt&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;DataTau&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Using Python with lxml and Requests allows us to do web scraping with relative ease, usually requiring only a few lines of code. Using this as a foundation, you can do basic web scraping, and when you feel more comfortable, you can check out other frameworks and libraries. If you do, I would recommend &lt;a href=&quot;https://scrapy.org/&quot;&gt;Scrapy&lt;/a&gt; as the next step, because it’s relatively simple and flexible, yet pretty powerful.&lt;/p&gt;
&lt;p&gt;Happy scraping!&lt;/p&gt;

</description>
<pubDate>Tue, 24 Oct 2017 06:17:37 +0000</pubDate>
<dc:creator>weenkus</dc:creator>
<og:type>article</og:type>
<og:title>Introduction to web scraping with Python - Data, what now?</og:title>
<og:description>Data is the core of predictive modeling, visualization, and analytics. Unfortunately, the needed data is not always readily available to the user, it is most often unstructured. The biggest source of data is the Internet, and with programming, we can extractContinue reading... Introduction to web scraping with Python</og:description>
<og:url>https://datawhatnow.com/introduction-web-scraping-python/</og:url>
<og:image>https://datawhatnow.com/wp-content/uploads/2017/05/web_scraping-1.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://datawhatnow.com/introduction-web-scraping-python/</dc:identifier>
</item>
</channel>
</rss>