<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Using Dark Mode in CSS with MacOS Mojave</title>
<link>https://paulmillr.com/posts/using-dark-mode-in-css/</link>
<guid isPermaLink="true" >https://paulmillr.com/posts/using-dark-mode-in-css/</guid>
<description>&lt;p&gt;MacOS Mojave has been recently released with the &lt;a href=&quot;https://www.apple.com/macos/mojave/&quot;&gt;Dark Mode&lt;/a&gt; option.&lt;/p&gt;&lt;p&gt;The option allows you to enable dark interface through all the system, which is very useful while working in the evenings and nights. Native apps are able to take advantage of the mode by following &lt;a href=&quot;https://developer.apple.com/documentation/appkit/supporting_dark_mode_in_your_interface&quot;&gt;some interface guidelines&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What about web apps? Safari 12 that shipped with Mojave does not have a way to detect whether a user has a dark mode or not.&lt;/p&gt;
&lt;p&gt;The good news is: &lt;a href=&quot;https://developer.apple.com/safari/technology-preview/&quot;&gt;Safari Tech Preview 68&lt;/a&gt; supports Dark Mode! And &lt;strong&gt;Safari 12.1&lt;/strong&gt; might support it in a few months too. The CSS itself is very simple:&lt;/p&gt;
&lt;div class=&quot;language-css highlighter-rouge&quot; readability=&quot;7&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;9&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;c&quot;&gt;/* Text and background color for light mode */&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;#333&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;/* Text and background color for dark mode */&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;@media&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prefers-color-scheme&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nl&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;#ddd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;nl&quot;&gt;background-color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;#222&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;prefers-color-scheme&lt;/code&gt; query supports three values: &lt;code class=&quot;highlighter-rouge&quot;&gt;dark&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;light&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;no-preference&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;No polyfills are required, the media query code would be skipped if your browser doesn’t support it.&lt;/p&gt;
&lt;p&gt;For the demo, open this site in Safari Tech Preview with MacOS Dark Mode enabled. iOS and Chrome would probably also get a dark mode in the next major update.&lt;/p&gt;
</description>
<pubDate>Thu, 25 Oct 2018 05:57:56 +0000</pubDate>
<dc:creator>alwillis</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://paulmillr.com/posts/using-dark-mode-in-css/</dc:identifier>
</item>
<item>
<title>End-to-end implementation of a machine learning pipeline (2017)</title>
<link>https://spandan-madan.github.io/DeepLearningProject/docs/Deep_Learning_Project-Pytorch.html</link>
<guid isPermaLink="true" >https://spandan-madan.github.io/DeepLearningProject/docs/Deep_Learning_Project-Pytorch.html</guid>
<description>&lt;pre&gt;
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 332 1006
train Loss: 0.0996 Acc: 0.3300
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 92 236
test Loss: 0.0958 Acc: 0.3898
('new best accuracy = ', 0.3898305084745763)
Epoch 1/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 479 1006
train Loss: 0.0638 Acc: 0.4761
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 156 236
test Loss: 0.0334 Acc: 0.6610
('new best accuracy = ', 0.6610169491525424)
Epoch 2/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 587 1006
train Loss: 0.0218 Acc: 0.5835
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 171 236
test Loss: 0.0127 Acc: 0.7246
('new best accuracy = ', 0.7245762711864406)
Epoch 3/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 701 1006
train Loss: 0.0100 Acc: 0.6968
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 196 236
test Loss: 0.0074 Acc: 0.8305
('new best accuracy = ', 0.8305084745762712)
Epoch 4/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 799 1006
train Loss: 0.0061 Acc: 0.7942
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 215 236
test Loss: 0.0041 Acc: 0.9110
('new best accuracy = ', 0.9110169491525424)
Epoch 5/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 859 1006
train Loss: 0.0042 Acc: 0.8539
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 206 236
test Loss: 0.0041 Acc: 0.8729
Epoch 6/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 882 1006
train Loss: 0.0034 Acc: 0.8767
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 210 236
test Loss: 0.0034 Acc: 0.8898
Epoch 7/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 923 1006
train Loss: 0.0025 Acc: 0.9175
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 227 236
test Loss: 0.0025 Acc: 0.9619
('new best accuracy = ', 0.961864406779661)
Epoch 8/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 953 1006
train Loss: 0.0019 Acc: 0.9473
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 224 236
test Loss: 0.0016 Acc: 0.9492
Epoch 9/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 965 1006
train Loss: 0.0015 Acc: 0.9592
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 224 236
test Loss: 0.0018 Acc: 0.9492
Epoch 10/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 962 1006
train Loss: 0.0014 Acc: 0.9563
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 235 236
test Loss: 0.0011 Acc: 0.9958
('new best accuracy = ', 0.9957627118644068)
Epoch 11/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 968 1006
train Loss: 0.0012 Acc: 0.9622
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 230 236
test Loss: 0.0012 Acc: 0.9746
Epoch 12/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 984 1006
train Loss: 0.0010 Acc: 0.9781
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 221 236
test Loss: 0.0021 Acc: 0.9364
Epoch 13/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 956 1006
train Loss: 0.0014 Acc: 0.9503
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 231 236
test Loss: 0.0011 Acc: 0.9788
Epoch 14/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 984 1006
train Loss: 0.0009 Acc: 0.9781
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 235 236
test Loss: 0.0007 Acc: 0.9958
Epoch 15/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 996 1006
train Loss: 0.0006 Acc: 0.9901
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 235 236
test Loss: 0.0006 Acc: 0.9958
Epoch 16/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 999 1006
train Loss: 0.0004 Acc: 0.9930
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 235 236
test Loss: 0.0005 Acc: 0.9958
Epoch 17/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1000 1006
train Loss: 0.0004 Acc: 0.9940
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 236 236
test Loss: 0.0005 Acc: 1.0000
('new best accuracy = ', 1.0)
Epoch 18/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 992 1006
train Loss: 0.0005 Acc: 0.9861
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 235 236
test Loss: 0.0006 Acc: 0.9958
Epoch 19/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 997 1006
train Loss: 0.0004 Acc: 0.9911
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 236 236
test Loss: 0.0004 Acc: 1.0000
Epoch 20/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 990 1006
train Loss: 0.0005 Acc: 0.9841
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 229 236
test Loss: 0.0024 Acc: 0.9703
Epoch 21/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 867 1006
train Loss: 0.0058 Acc: 0.8618
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 222 236
test Loss: 0.0037 Acc: 0.9407
Epoch 22/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 963 1006
train Loss: 0.0026 Acc: 0.9573
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 233 236
test Loss: 0.0011 Acc: 0.9873
Epoch 23/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 998 1006
train Loss: 0.0005 Acc: 0.9920
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 235 236
test Loss: 0.0004 Acc: 0.9958
Epoch 24/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1002 1006
train Loss: 0.0003 Acc: 0.9960
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 235 236
test Loss: 0.0004 Acc: 0.9958
Epoch 25/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1003 1006
train Loss: 0.0002 Acc: 0.9970
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 233 236
test Loss: 0.0005 Acc: 0.9873
Epoch 26/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1002 1006
train Loss: 0.0002 Acc: 0.9960
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 235 236
test Loss: 0.0003 Acc: 0.9958
Epoch 27/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1004 1006
train Loss: 0.0002 Acc: 0.9980
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 235 236
test Loss: 0.0003 Acc: 0.9958
Epoch 28/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 997 1006
train Loss: 0.0005 Acc: 0.9911
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 228 236
test Loss: 0.0016 Acc: 0.9661
Epoch 29/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 975 1006
train Loss: 0.0015 Acc: 0.9692
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 227 236
test Loss: 0.0021 Acc: 0.9619
Epoch 30/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 973 1006
train Loss: 0.0022 Acc: 0.9672
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 226 236
test Loss: 0.0018 Acc: 0.9576
Epoch 31/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 996 1006
train Loss: 0.0007 Acc: 0.9901
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 235 236
test Loss: 0.0004 Acc: 0.9958
Epoch 32/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1004 1006
train Loss: 0.0002 Acc: 0.9980
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 236 236
test Loss: 0.0003 Acc: 1.0000
Epoch 33/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1004 1006
train Loss: 0.0001 Acc: 0.9980
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 235 236
test Loss: 0.0004 Acc: 0.9958
Epoch 34/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1003 1006
train Loss: 0.0001 Acc: 0.9970
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 235 236
test Loss: 0.0003 Acc: 0.9958
Epoch 35/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1004 1006
train Loss: 0.0001 Acc: 0.9980
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 236 236
test Loss: 0.0003 Acc: 1.0000
Epoch 36/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1004 1006
train Loss: 0.0001 Acc: 0.9980
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 236 236
test Loss: 0.0002 Acc: 1.0000
Epoch 37/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 965 1006
train Loss: 0.0015 Acc: 0.9592
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 224 236
test Loss: 0.0040 Acc: 0.9492
Epoch 38/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 964 1006
train Loss: 0.0027 Acc: 0.9583
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 233 236
test Loss: 0.0008 Acc: 0.9873
Epoch 39/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 998 1006
train Loss: 0.0005 Acc: 0.9920
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 236 236
test Loss: 0.0005 Acc: 1.0000
Epoch 40/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1003 1006
train Loss: 0.0002 Acc: 0.9970
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 236 236
test Loss: 0.0002 Acc: 1.0000
Epoch 41/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1003 1006
train Loss: 0.0001 Acc: 0.9970
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 236 236
test Loss: 0.0002 Acc: 1.0000
Epoch 42/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1005 1006
train Loss: 0.0001 Acc: 0.9990
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 235 236
test Loss: 0.0003 Acc: 0.9958
Epoch 43/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1004 1006
train Loss: 0.0001 Acc: 0.9980
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 235 236
test Loss: 0.0002 Acc: 0.9958
Epoch 44/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1005 1006
train Loss: 0.0001 Acc: 0.9990
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 236 236
test Loss: 0.0004 Acc: 1.0000
Epoch 45/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 999 1006
train Loss: 0.0006 Acc: 0.9930
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 227 236
test Loss: 0.0020 Acc: 0.9619
Epoch 46/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 942 1006
train Loss: 0.0043 Acc: 0.9364
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 213 236
test Loss: 0.0045 Acc: 0.9025
Epoch 47/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 990 1006
train Loss: 0.0013 Acc: 0.9841
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 236 236
test Loss: 0.0004 Acc: 1.0000
Epoch 48/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1003 1006
train Loss: 0.0002 Acc: 0.9970
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 235 236
test Loss: 0.0004 Acc: 0.9958
Epoch 49/49
----------
TRAINING STARTED
loss done
('Reached iteration ', 0)
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([64]) torch.Size([64, 19])
loss done
loss backward
done loss backward
done optim
torch.Size([46]) torch.Size([46, 19])
trying epoch loss
train 1004 1006
train Loss: 0.0001 Acc: 0.9980
TESTING STARTED
loss done
('Reached iteration ', 0)
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([64]) torch.Size([64, 19])
loss done
torch.Size([44]) torch.Size([44, 19])
trying epoch loss
test 236 236
test Loss: 0.0003 Acc: 1.0000
Training complete in 35m 4s
Best val Acc: 1.000000
returning and looping back
&lt;/pre&gt;</description>
<pubDate>Thu, 25 Oct 2018 05:02:10 +0000</pubDate>
<dc:creator>spandan-madan</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://spandan-madan.github.io/DeepLearningProject/docs/Deep_Learning_Project-Pytorch.html</dc:identifier>
</item>
<item>
<title>Adblock filter rule list modified politically in Finland</title>
<link>https://github.com/uBlockOrigin/uBlock-issues/issues/285</link>
<guid isPermaLink="true" >https://github.com/uBlockOrigin/uBlock-issues/issues/285</guid>
<description>&lt;p&gt;Was redirected to here from &lt;a class=&quot;issue-link js-issue-link&quot; data-error-text=&quot;Failed to load issue title&quot; data-id=&quot;373423741&quot; data-permission-text=&quot;Issue title is private&quot; data-url=&quot;https://github.com/uBlockOrigin/uAssets/issues/3780&quot; data-hovercard-type=&quot;issue&quot; data-hovercard-url=&quot;/uBlockOrigin/uAssets/issues/3780/hovercard&quot; href=&quot;https://github.com/uBlockOrigin/uAssets/issues/3780&quot;&gt;uBlockOrigin/uAssets#3780&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;URL(s) where the issue occurs&lt;/h3&gt;
&lt;p&gt;superliitto.fi, sak.fi, akt.fi, selry.fi, akava.fi, oaj.fi, stthl.fi, proliitto.fi, pam.fi, sahkoliitto.fi&lt;/p&gt;
&lt;h3&gt;Describe the issue&lt;/h3&gt;
&lt;p&gt;There are currently happening several political strikes in Finland, where unions are taking their stance against the goverment.&lt;br/&gt;&lt;a href=&quot;https://yle.fi/uutiset/osasto/news/security_guard_3-day_strike_to_start_on_wednesday/10469154&quot; rel=&quot;nofollow&quot;&gt;https://yle.fi/uutiset/osasto/news/security_guard_3-day_strike_to_start_on_wednesday/10469154&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Few days ago the maintainer of FIN: Finnish Addition to Easylist -list, called Adblocker for Finland. Decided to block several union websites to make political statement about these strikes.&lt;/p&gt;
&lt;p&gt;Direct link to the list - &lt;a href=&quot;https://adb.juvander.net/Finland_adb.txt&quot; rel=&quot;nofollow&quot;&gt;https://adb.juvander.net/Finland_adb.txt&lt;/a&gt;&lt;br/&gt;Archive.is -version - &lt;a href=&quot;https://archive.is/1WYkz&quot; rel=&quot;nofollow&quot;&gt;https://archive.is/1WYkz&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I really think filter lists aren't suitable enviroment to make political statements and the maintainer is clearly abusing his power with actions like these. Thus please consider removing this filterlist from uBo's assets.json&lt;/p&gt;
&lt;h3&gt;Screenshot(s)&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://i.imgur.com/aK37Vh9.png&quot; rel=&quot;nofollow&quot;&gt;Screenshot of blocking the website pam.fi&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://i.imgur.com/9zHcfPB.png&quot; rel=&quot;nofollow&quot;&gt;Screenshot of the filters&lt;/a&gt;&lt;br/&gt;Rough ranslation: Statement about the union strikes. Will be removed after the strikes.&lt;br/&gt;&lt;a href=&quot;https://i.imgur.com/XCMwkm2.png&quot; rel=&quot;nofollow&quot;&gt;Screenshot of FB post made by the maintainer&lt;/a&gt;&lt;br/&gt;Rough translation: As an objection to actions of trade unions.The finnish adblocking list now block sites of those unions which are joining the strike. Not all sites are there, but more are coming. They will removed after the unions start to respect the goverment again by ending these political strikes.&lt;/p&gt;
&lt;h3&gt;Versions&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Browser/version: Firefox 63&lt;/li&gt;
&lt;li&gt;uBlock Origin version: uBlock Origin v1.17.2&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;Notes&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Central_Organisation_of_Finnish_Trade_Unions&quot; rel=&quot;nofollow&quot;&gt;Wikipedia page about the Central Organisation of Finnish Trade Unions&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.pam.fi/en/news/notice/2018/10/strike-in-the-security-guarding-sector-to-go-ahead-mediation-ended-without-any-settlement-proposal.html&quot; rel=&quot;nofollow&quot;&gt;Strike in the security guarding sector to go ahead – mediation ended without any settlement proposal . PAM.fi&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 25 Oct 2018 03:16:40 +0000</pubDate>
<dc:creator>Maakuth</dc:creator>
<og:image>https://avatars0.githubusercontent.com/u/14147811?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>Consider removing &quot;FIN: Finnish Addition to Easylist&quot; -filterlist from uBo assets.json · Issue #285 · uBlockOrigin/uBlock-issues</og:title>
<og:url>https://github.com/uBlockOrigin/uBlock-issues/issues/285</og:url>
<og:description>Was redirected to here from uBlockOrigin/uAssets#3780 URL(s) where the issue occurs superliitto.fi, sak.fi, akt.fi, selry.fi, akava.fi, oaj.fi, stthl.fi, proliitto.fi, pam.fi, sahkoliitto.fi Descri...</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/uBlockOrigin/uBlock-issues/issues/285</dc:identifier>
</item>
<item>
<title>First analysis of ‘pre-registered’ studies shows sharp rise in null findings</title>
<link>https://www.nature.com/articles/d41586-018-07118-1</link>
<guid isPermaLink="true" >https://www.nature.com/articles/d41586-018-07118-1</guid>
<description>&lt;div class=&quot;content position-relative cleared clear mq1200-padded&quot; data-component=&quot;article-container&quot; role=&quot;main&quot;&gt;
&lt;header class=&quot;article-item__header clear cleared pull--both&quot;&gt;&lt;div class=&quot;article__type&quot;&gt;NEWS
&lt;div class=&quot;ml10 article__date&quot;&gt;&lt;time itemprop=&quot;datePublished&quot;&gt;24 October 2018&lt;/time&gt;&lt;/div&gt;
&lt;/div&gt;


&lt;div class=&quot;article-item__teaser-text serif&quot;&gt;Logging hypotheses and protocols before performing research seems to work as intended: to reduce publication bias for positive results.&lt;/div&gt;
&lt;/header&gt;
&lt;div class=&quot;bordered-container clear cleared pull--both&quot;&gt;
&lt;div id=&quot;author-affiliations&quot; class=&quot;tab-group text14&quot; role=&quot;tablist&quot; data-test=&quot;author-affiliations&quot; data-tab-group=&quot;&quot;&gt;
&lt;div class=&quot;cleared&quot;&gt;
&lt;div id=&quot;author-affiliation-news-0&quot; class=&quot;tab-box js-box-wrapper&quot;&gt;
&lt;h3 id=&quot;author-affiliation-news-0-head&quot; data-track=&quot;click&quot; data-track-label=&quot;view author info&quot; class=&quot;sans-serif strong tab tab-skin&quot; role=&quot;tab&quot; aria-controls=&quot;author-affiliation-news-0-content&quot; data-tooltip=&quot;Show author information&quot;&gt;Matthew Warren&lt;/h3&gt;
&lt;div id=&quot;author-affiliation-news-0-content&quot; class=&quot;tab-content pin-right grid grid-12 last&quot; role=&quot;tabpanel&quot;&gt;
&lt;div class=&quot;pa10&quot; aria-labelledby=&quot;author-affiliation-news-0-head&quot;&gt;
&lt;div class=&quot;clear cleared&quot;&gt;
&lt;div class=&quot;align-left&quot;&gt;
&lt;h4 class=&quot;sans-serif&quot;&gt;Search for this author in:&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;align-left&quot;&gt;
&lt;div class=&quot;article__body serif cleared&quot;&gt;
&lt;div class=&quot;embed intensity--high&quot;&gt;&lt;img class=&quot;figure__image&quot; alt=&quot;Research Operations Inside the Mayo Clinic&quot; data-src=&quot;//media.nature.com/w800/magazine-assets/d41586-018-07118-1/d41586-018-07118-1_16215984.jpg&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;&quot; alt=&quot;Research Operations Inside the Mayo Clinic&quot; src=&quot;https://media.nature.com/w800/magazine-assets/d41586-018-07118-1/d41586-018-07118-1_16215984.jpg&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;
&lt;p class=&quot;figure__caption sans-serif&quot;&gt;&lt;span class=&quot;mr10&quot;&gt;Registering research protocols in advance of data collection could change the findings.&lt;/span&gt; &lt;span&gt;Credit: Ariana Lindquist/Bloomberg/Getty&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Studies that fail to find a positive result are often filed away, never to see the light of day, which leads to a publication bias that compromises the credibility of scientific literature&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-018-07118-1#ref-CR1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;An analysis now suggests that registering and peer-reviewing study protocols before research is conducted could improve this ‘file-drawer problem’, and help to correct the existing publication bias towards positive findings.&lt;/p&gt;
&lt;p&gt;Researchers from Cardiff University, UK, report what they say is the first analysis of whether the practice is effective. They find that studies for which protocols were pre-registered are much more likely than the general scientific literature to report null findings&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-018-07118-1#ref-CR2&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. The analysis was posted on 17 October to the PsyArXiv repository.&lt;/p&gt;
&lt;h2&gt;Better findings&lt;/h2&gt;
&lt;p&gt;In a registered report, researchers submit a study protocol to a journal before a study begins. If this passes peer review, the journal provisionally commits to publishing a paper when the study is completed, regardless of the results.&lt;/p&gt;
&lt;p&gt;The practice has emerged in the science community in the past few years, building on initiatives such as pre-registration in clinical trials, which is required by law in the United States. There are currently &lt;a href=&quot;https://cos.io/rr/&quot; data-track=&quot;click&quot; data-label=&quot;https://cos.io/rr/&quot; data-track-category=&quot;body text link&quot;&gt;around 140 journals&lt;/a&gt; using the format, and &lt;a href=&quot;https://www.zotero.org/groups/479248/osf/items/collectionKey/KEJP68G9&quot; data-track=&quot;click&quot; data-label=&quot;https://www.zotero.org/groups/479248/osf/items/collectionKey/KEJP68G9&quot; data-track-category=&quot;body text link&quot;&gt;130 registered reports&lt;/a&gt; that have published final results.&lt;/p&gt;
&lt;p&gt;Proponents of the format hope that it will combat dubious research practices, such as formulating hypotheses only after looking at the findings or not reporting negative results.&lt;/p&gt;
&lt;p&gt;To see whether registered reports increase the frequency at which null results are reported, psychologists Chris Allen and David Mehler analysed the outcomes of 113 registered reports in the biomedical and psychological sciences.&lt;/p&gt;
&lt;p&gt;The pair identified 296 discrete hypotheses across those studies, and found that, overall, 61% of these were not supported by the results that those studies later published. For studies that sought to replicate previous findings, the percentage of null results was slightly higher, at 66%, whereas this figure stood at 55% for original research (see ‘Registered reports cut publication bias’).&lt;/p&gt;
&lt;div class=&quot;embed intensity--high&quot;&gt;&lt;img class=&quot;figure__image&quot; alt=&quot;&quot; data-src=&quot;//media.nature.com/w800/magazine-assets/d41586-018-07118-1/d41586-018-07118-1_16221760.png&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;&quot; alt=&quot;&quot; src=&quot;https://media.nature.com/w800/magazine-assets/d41586-018-07118-1/d41586-018-07118-1_16221760.png&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;
&lt;p class=&quot;figure__caption sans-serif&quot;&gt;&lt;span class=&quot;mr10&quot;&gt;Source: Allen, C. &amp;amp; Mehler, D. Preprint at PsyArXiv https://psyarxiv.com/3czyt (2018).&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;These figures are much higher than the proportion of null results presented in the general scientific literature, which the authors estimate to be between 5% and 20%, on the basis of previous research.&lt;/p&gt;
&lt;h2&gt;Still not representative&lt;/h2&gt;
&lt;p&gt;The study might still underestimate the true proportion of null findings, says Anne Scheel, a psychology researcher at Eindhoven University of Technology in the Netherlands, who is also investigating registered reports.&lt;/p&gt;
&lt;p&gt;Other research has estimated that the proportion of hypotheses tested in psychology which are in fact false is greater than 90%&lt;sup&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-018-07118-1#ref-CR3&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;, she says, which would suggest that the rate of null findings in the current scientific literature is “drastically at odds with what we would expect without any publication bias”.&lt;/p&gt;
&lt;p&gt;Allen adds that their analysis is exploratory, and that there could be other explanations for the findings.&lt;/p&gt;
&lt;p&gt;For instance, says Scheel, people might use this format strategically for hypotheses that they anticipate will not work out, given that registered reports more or less guarantee publication.&lt;/p&gt;
&lt;p&gt;Registered reports are a young format, she adds, and it may be that the studies published so far are not representative of the field of psychology more generally. “There are so many unknowns at the moment,” Scheel says. “But that also makes it a very exciting time for meta-scientists.”&lt;/p&gt;
&lt;p&gt;The number of registered reports is growing exponentially, and Allen now hopes to conduct another study, with a larger sample size, to answer some of the questions the research has raised. And he plans to register it first.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;emphasis&quot;&gt;doi: 10.1038/d41586-018-07118-1&lt;/div&gt;
&lt;aside class=&quot;c-latest-content mt40 hide-print&quot; data-simple-tab=&quot;&quot; data-tab-group=&quot;&quot; data-component-id=&quot;latest-news&quot; data-track=&quot;in-view&quot; data-track-action=&quot;in-view&quot; data-track-category=&quot;latest content&quot; data-track-label=&quot;visible&quot;&gt;&lt;div id=&quot;latest-content&quot; role=&quot;tablist&quot;&gt;
&lt;p class=&quot;serif strong&quot;&gt;Latest on:&lt;/p&gt;
&lt;div class=&quot;cleared&quot;&gt;
&lt;div id=&quot;latest-content-0&quot; class=&quot;c-latest-content__container&quot; data-container=&quot;&quot;&gt;
&lt;p id=&quot;latest-content-0-head&quot; class=&quot;c-latest-content__category c-latest-content__switch serif&quot; data-switch=&quot;&quot; role=&quot;tab&quot; aria-controls=&quot;latest-content-0-content&quot; data-track=&quot;click&quot; data-track-label=&quot;latest tag (rank:0)&quot;&gt;Peer review&lt;/p&gt;

&lt;/div&gt;
&lt;div id=&quot;latest-content-1&quot; class=&quot;c-latest-content__container&quot; data-container=&quot;&quot;&gt;
&lt;p id=&quot;latest-content-1-head&quot; class=&quot;c-latest-content__category c-latest-content__switch serif&quot; data-switch=&quot;&quot; role=&quot;tab&quot; aria-controls=&quot;latest-content-1-content&quot; data-track=&quot;click&quot; data-track-label=&quot;latest tag (rank:1)&quot;&gt;Publishing&lt;/p&gt;

&lt;/div&gt;
&lt;div id=&quot;latest-content-2&quot; class=&quot;c-latest-content__container&quot; data-container=&quot;&quot;&gt;
&lt;p id=&quot;latest-content-2-head&quot; class=&quot;c-latest-content__category c-latest-content__switch serif&quot; data-switch=&quot;&quot; role=&quot;tab&quot; aria-controls=&quot;latest-content-2-content&quot; data-track=&quot;click&quot; data-track-label=&quot;latest tag (rank:2)&quot;&gt;Research data&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/aside&gt;&lt;div class=&quot;nature-briefing nature-briefing--article cleared hide-print&quot; data-component-id=&quot;nature-briefing-box&quot; data-track=&quot;in-view&quot; data-track-action=&quot;in-view&quot; data-track-category=&quot;nature briefing&quot; data-track-label=&quot;box visible&quot;&gt;
&lt;header class=&quot;nature-briefing__header&quot;&gt;&lt;span class=&quot;visually-hidden&quot;&gt;Nature Briefing&lt;/span&gt;&lt;/header&gt;&lt;div class=&quot;pa10 pt20&quot;&gt;
&lt;p class=&quot;serif nature-briefing__slogan mr30&quot;&gt;&lt;strong&gt;Sign up for the daily &lt;span class=&quot;emphasis&quot;&gt;Nature Briefing&lt;/span&gt; email newsletter&lt;/strong&gt;&lt;/p&gt;
&lt;p class=&quot;sans-serif nature-briefing__standfirst mr30&quot;&gt;Stay up to date with what matters in science and why, handpicked from &lt;span class=&quot;emphasis&quot;&gt;Nature&lt;/span&gt; and other publications worldwide.&lt;/p&gt;
&lt;p class=&quot;cleared&quot;&gt;&lt;a class=&quot;nature-briefing__link&quot; data-track-category=&quot;nature briefing&quot; data-track=&quot;click&quot; data-track-label=&quot;nature briefing article link&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener&quot; href=&quot;https://www.nature.com/briefing/signup/&quot;&gt;Sign Up&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;section aria-labelledby=&quot;Bib1&quot;&gt;&lt;div class=&quot;serif article-section js-article-section cleared clear&quot; id=&quot;Bib1-section&quot;&gt;
&lt;h2 class=&quot;js-section-title section-title strong position-relative tighten-line-height background-gray-light pt20 pb6 pl0 pr20 standard-space-below small-space-above mq640-pt10 mq640-pb10 mq640-pl20 mq640-mt0 mq640-ml-20 mq640-mr-20 extend-left&quot; id=&quot;Bib1&quot;&gt;References&lt;/h2&gt;
&lt;div class=&quot;pl20 mq875-pl0 js-collapsible-section&quot; id=&quot;Bib1-content&quot;&gt;
&lt;div data-container-section=&quot;references&quot;&gt;
&lt;ol class=&quot;clean-list ma0 standard-space-below indented-list&quot; data-test=&quot;references-list&quot;&gt;&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;1.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR1&quot;&gt;Hardwicke, T. E. &amp;amp; Ioannidis, J. P. A. &lt;em&gt;Nature Hum. Behav&lt;/em&gt;. https//doi.org/10.1038/s41562-018-0444-y (2018).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;2.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR2&quot;&gt;Allen, C. &amp;amp; Mehler, D. Preprint at PsyArXiv &lt;a href=&quot;https://psyarxiv.com/3czyt&quot;&gt;https://psyarxiv.com/3czyt&lt;/a&gt; (2018).&lt;/p&gt;
&lt;/li&gt;
&lt;li class=&quot;small-space-below border-gray-medium border-bottom-1 position-relative js-ref-item&quot; itemprop=&quot;citation&quot; itemscope=&quot;itemscope&quot; itemtype=&quot;http://schema.org/Article&quot; data-test=&quot;citation&quot;&gt;&lt;span class=&quot;indented-counter serif h2 tighten-line-height text-right position-absolute grade-c-hide&quot;&gt;3.&lt;/span&gt;
&lt;p class=&quot;tiny-space-below&quot; id=&quot;ref-CR3&quot;&gt;Johnson, V. E. &lt;em&gt;et al.&lt;/em&gt; &lt;em&gt;J. Am. Stat. Assoc.&lt;/em&gt; &lt;strong&gt;112&lt;/strong&gt;, 1–10 (2017).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p class=&quot;hide-print text-right&quot;&gt;&lt;a href=&quot;https://www.nature.com/articles/d41586-018-07118-1-references.ris&quot; class=&quot;text14 sans-serif strong&quot; data-track=&quot;click&quot; data-track-action=&quot;download citation references&quot; data-track-category=&quot;article body&quot; data-track-label=&quot;link&quot;&gt;Download references&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;&lt;/div&gt;
&lt;aside class=&quot;article__aside align-right&quot;&gt;&lt;div class=&quot;related-content shrink--aside hide-print&quot;&gt;
&lt;h3 class=&quot;aside__title sans-serif&quot;&gt;Related Articles&lt;/h3&gt;
&lt;/div&gt;

&lt;div id=&quot;div-gpt-ad-right-2&quot; class=&quot;div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide hide-overflow&quot; data-gpt-unitpath=&quot;/285/nature.com/article&quot; data-gpt-sizes=&quot;300x250&quot; data-gpt-targeting=&quot;pos=right;artid=/articles/d41586-018-07118-1;path=/articles/d41586-018-07118-1&quot;&gt;&lt;noscript&gt;
&lt;p&gt;&lt;a href=&quot;https://pubads.g.doubleclick.net/gampad/jump?iu=/285/nature.com/article&amp;amp;sz=300x250&amp;amp;c=-141635978&amp;amp;t=pos%3Dright%26artid%3D/articles/d41586-018-07118-1&quot;&gt;&lt;img data-test=&quot;gpt-advert-fallback-img&quot; src=&quot;https://pubads.g.doubleclick.net/gampad/ad?iu=/285/nature.com/article&amp;amp;sz=300x250&amp;amp;c=-141635978&amp;amp;t=pos%3Dright%26artid%3D/articles/d41586-018-07118-1&quot; alt=&quot;Advertisement&quot; width=&quot;300&quot; height=&quot;250&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/div&gt;
&lt;/aside&gt;&lt;/div&gt;
</description>
<pubDate>Thu, 25 Oct 2018 00:43:26 +0000</pubDate>
<dc:creator>danso</dc:creator>
<og:url>http://www.nature.com/articles/d41586-018-07118-1</og:url>
<og:type>article</og:type>
<og:title>First analysis of ‘pre-registered’ studies shows sharp rise in null findings</og:title>
<og:description>Logging hypotheses and protocols before performing research seems to work as intended: to reduce publication bias for positive results.</og:description>
<og:image>https://media.nature.com/lw1024/magazine-assets/d41586-018-07118-1/d41586-018-07118-1_16215980.jpg</og:image>
<dc:language>EN</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.nature.com/articles/d41586-018-07118-1</dc:identifier>
</item>
<item>
<title>Is Gutenberg the End or a New Beginning for WordPress?</title>
<link>https://deliciousbrains.com/wordpress-gutenberg/</link>
<guid isPermaLink="true" >https://deliciousbrains.com/wordpress-gutenberg/</guid>
<description>&lt;img width=&quot;1540&quot; height=&quot;748&quot; src=&quot;https://cdn.deliciousbrains.com/content/uploads/2018/01/09162551/db-Glutenberg-1540x748.jpg&quot; class=&quot;featured wp-post-image&quot; alt=&quot;&quot; srcset=&quot;https://cdn.deliciousbrains.com/content/uploads/2018/01/09162551/db-Glutenberg-1540x748.jpg 1540w, https://cdn.deliciousbrains.com/content/uploads/2018/01/09162551/db-Glutenberg-385x187.jpg 385w, https://cdn.deliciousbrains.com/content/uploads/2018/01/09162551/db-Glutenberg-770x374.jpg 770w&quot; sizes=&quot;(max-width: 1540px) 100vw, 1540px&quot;/&gt;&lt;p&gt;&lt;em&gt;Editor’s note: the opinion in this article is Iain’s and is not necessarily shared by the rest of the Delicious Brains team. Iain had a lot to say on the topic 🙂&lt;/em&gt;&lt;/p&gt;&lt;p&gt;I’ve been loosely following the noise and #wpdrama surrounding Gutenberg for as long as it has been around and honestly for the most part I’ve had negative feelings around it (I don’t like change at the best of times). However, I recently dived in and tried it out and you will never guess what happened next!&lt;/p&gt;
&lt;p&gt;But seriously. I came to two conclusions:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;It’s a lovely piece of software&lt;/li&gt;
&lt;li&gt;It does not belong in WordPress. (Yet. Or WordPress as we know it today)&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Let me explain.&lt;/p&gt;
&lt;h2 id=&quot;what-is-gutenberg&quot;&gt;What is Gutenberg?&lt;/h2&gt;
&lt;p&gt;As a customary catch-up for those who don’t know, Gutenberg is the new way to edit content in WordPress. It replaces the tired TinyMCE post content editor and can do a lot more too – think shortcodes, widgets, menus, and even &lt;a href=&quot;https://riad.blog/2017/12/11/with-gutenberg-what-happens-to-my-custom-fields/&quot;&gt;custom fields&lt;/a&gt;. It is a client-side interface built with React that uses a block based system to build up content:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.deliciousbrains.com/content/uploads/2018/01/05144358/gutenberg_screenshot.png&quot; alt=&quot;&quot; width=&quot;720&quot; height=&quot;458&quot; class=&quot;alignnone size-large wp-image-35375&quot; srcset=&quot;https://cdn.deliciousbrains.com/content/uploads/2018/01/05144358/gutenberg_screenshot.png 1590w, https://cdn.deliciousbrains.com/content/uploads/2018/01/05144358/gutenberg_screenshot-385x245.png 385w, https://cdn.deliciousbrains.com/content/uploads/2018/01/05144358/gutenberg_screenshot-770x489.png 770w, https://cdn.deliciousbrains.com/content/uploads/2018/01/05144358/gutenberg_screenshot-1540x978.png 1540w&quot; sizes=&quot;(max-width: 720px) 100vw, 720px&quot;/&gt;&lt;/p&gt;
&lt;p&gt;It is being developed as a feature plugin over on &lt;a href=&quot;https://github.com/WordPress/gutenberg/&quot;&gt;GitHub&lt;/a&gt; and it has been scheduled to land in core in the next version of WordPress, version 5.0 estimated for the first half of 2018. Here’s a &lt;a href=&quot;https://wptavern.com/a-collection-of-gutenberg-conversations-resources-and-videos&quot;&gt;great roundup&lt;/a&gt; of Gutenberg information.&lt;/p&gt;
&lt;p&gt;Gutenberg is an important step forward for publishers, reducing the visual difference between how content is crafted in the admin and how it is rendered on the frontend. It also opens up the possibility of unifying all the various different parts of the site building process, like the customizer and widgets.&lt;/p&gt;
&lt;h2 id=&quot;problem&quot;&gt;So What’s the Problem?&lt;/h2&gt;
&lt;p&gt;I’m not going to beat around the bush here, I’ve got some issues with Gutenberg, the motivations behind it, and how the implementation is being handled. And &lt;a href=&quot;https://wordpress.org/support/plugin/gutenberg/reviews/?filter=1&quot;&gt;I’m not alone&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;motivations&quot;&gt;Motivations&lt;/h3&gt;
&lt;p&gt;Gutenberg is an obvious reaction to competitors of WordPress; the writing experience of Medium, the quick and easy site builds using Wix and Squarespace.&lt;/p&gt;
&lt;p&gt;Clearly a project the size of WordPress needs some strong leadership and a clear roadmap. However, when that roadmap starts to be clouded by outside factors such as financial pressure to compete with the market, decisions aren’t made in the best interest of everyone. Don’t forget that whatever is implemented in WordPress.org is being built for WordPress.com (one of the main money-making arms of Automattic) and no doubt their biggest concern when considering losing customers to competitors. Gutenberg is a clear attempt to attract new users to the platform.&lt;/p&gt;
&lt;p&gt;But in doing this is WordPress stepping away from the values that make WordPress WordPress? This is a move away from one of WordPress’ &lt;a href=&quot;https://wordpress.org/about/philosophy&quot;&gt;key philosophies&lt;/a&gt;, &lt;a href=&quot;https://wordpress.org/about/philosophy/#clean&quot;&gt;‘Clean, Lean, and Mean’&lt;/a&gt;, which states that the “core of WordPress will always provide a solid array of basic features. It’s designed to be lean and fast and will always stay that way.”&lt;/p&gt;
&lt;p&gt;Given that Gutenberg is basically a very advanced page builder plugin (like the many premium plugins on the market that do a similar job and will likely &lt;a href=&quot;https://polevaultweb.com/2014/04/will-wordpress-plugin-business-killer/&quot;&gt;suffer&lt;/a&gt; because of Gutenberg), albeit with more scope, it is questionable why this feature plugin has been given the green light for a merge into core.&lt;/p&gt;
&lt;blockquote readability=&quot;6.4573643410853&quot;&gt;
&lt;p&gt;We are constantly asked “when will X feature be built” or “why isn’t X plugin integrated into the core”. The rule of thumb is that the core should provide features that 80% or more of end users will actually appreciate and use.&lt;/p&gt;
&lt;footer&gt;&lt;cite&gt;&lt;a href=&quot;https://wordpress.org/about/philosophy/#clean&quot;&gt;WordPress Philosophy&lt;/a&gt;&lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;
&lt;p&gt;Interesting. So who decides what will be useful for 80% of end users (a wide demographic), and on what basis?&lt;/p&gt;
&lt;p&gt;In Gutenberg’s case, this is quite clearly the &lt;a href=&quot;https://en.wikipedia.org/wiki/Benevolent_dictator_for_life&quot;&gt;Benevolent Dictator For Life&lt;/a&gt; of the WordPress project and Automattic CEO &lt;a href=&quot;https://twitter.com/photomatt&quot;&gt;Matt Mullenweg&lt;/a&gt;, after confirming at the &lt;a href=&quot;https://youtu.be/Nl6U7UotA-M?t=58m28s&quot;&gt;State of the Word 2016&lt;/a&gt; that he would now be project lead for 2017, and that the &lt;a href=&quot;https://youtu.be/Nl6U7UotA-M?t=1h2m58s&quot;&gt;visual editor would be one of the focuses&lt;/a&gt; for 2017. Early in 2017 he also established himself as the project lead of Gutenberg and moved a couple Automattic employees on the project to drive it forward. Matt is making executive &lt;a href=&quot;https://wordpress.org/about/philosophy/#decisions&quot;&gt;decisions, not options&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;things-will-break&quot;&gt;Things Will Break&lt;/h3&gt;
&lt;p&gt;WordPress has always been a project that prides itself on backwards compatibility, a choice that has left the codebase large, outdated, and full of technical debt. WordPress allows the software to be run on a version of PHP (5.2.4) that has been &lt;a href=&quot;http://php.net/eol.php&quot;&gt;unsupported by PHP&lt;/a&gt; since January 2011! Developers have been calling for this to be raised for some time but it has been postponed under the banner of backwards compatibility and the &lt;a href=&quot;https://wordpress.org/about/philosophy/#majority&quot;&gt;‘Design for the Majority’ philosophy&lt;/a&gt; because the “average WordPress user simply wants to be able to write without problems or interruption.”&lt;/p&gt;
&lt;p&gt;But Gutenberg is quite a departure from this stance. The goal of the project has dictated the need to use modern technologies (React, REST API), and therefore it circumvents the problematic parts of core. Matt Mullenweg views this as a positive, perhaps not willing to admit the double standard here:&lt;/p&gt;
&lt;blockquote readability=&quot;4.6184210526316&quot;&gt;
&lt;p&gt;Core developers will be able to work in modern technologies and not worry about 15 years of backwards compatibility.&lt;/p&gt;
&lt;footer&gt;&lt;cite&gt;&lt;a href=&quot;https://ma.tt/2017/08/we-called-it-gutenberg-for-a-reason/&quot;&gt;We Called it Gutenberg for a Reason&lt;/a&gt;&lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;
&lt;p&gt;For years developers in the community have fought to bring in modern PHP standards to the codebase, refactor, reduce technical debt, bump the minimum PHP version supported, and help to make WordPress easier and better for future contributors to work on. They have been pretty much quagmired by Trac ticket ‘discussions’, core committers who don’t agree, and a lack of interest from Matt to get on board and challenge the status quo. Change seems to be something that WordPress can pick and choose.&lt;/p&gt;
&lt;p&gt;The major part of backwards compatibility is not breaking things, or doing everything possible to avoid it. Gutenberg simply will break sites. This won’t be white screening, or breaking appearance on the frontend, but as soon as a site is updated to 5.0, a user will have a broken experience the next time they edit a post, if the site relies on custom meta boxes. For example, a site I develop uses &lt;a href=&quot;https://wordpress.org/plugins/advanced-custom-fields/&quot;&gt;Advanced Custom Fields&lt;/a&gt; to capture data for specific parts of the page and looks like this on WordPress 4.9:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://cdn.deliciousbrains.com/content/uploads/2018/01/08181834/Screen-Shot-2018-01-08-at-22.13.28.png&quot;&gt;&lt;img src=&quot;https://cdn.deliciousbrains.com/content/uploads/2018/01/08181834/Screen-Shot-2018-01-08-at-22.13.28.png&quot; alt=&quot;&quot; width=&quot;720&quot; height=&quot;381&quot; class=&quot;alignnone size-large wp-image-35461&quot; srcset=&quot;https://cdn.deliciousbrains.com/content/uploads/2018/01/08181834/Screen-Shot-2018-01-08-at-22.13.28.png 2216w, https://cdn.deliciousbrains.com/content/uploads/2018/01/08181834/Screen-Shot-2018-01-08-at-22.13.28-385x204.png 385w, https://cdn.deliciousbrains.com/content/uploads/2018/01/08181834/Screen-Shot-2018-01-08-at-22.13.28-770x407.png 770w, https://cdn.deliciousbrains.com/content/uploads/2018/01/08181834/Screen-Shot-2018-01-08-at-22.13.28-1540x814.png 1540w&quot; sizes=&quot;(max-width: 720px) 100vw, 720px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;With Gutenberg installed to show what it will look like when updated to WordPress 5.0, things don’t look right and the site’s editors will be left scratching their heads:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://cdn.deliciousbrains.com/content/uploads/2018/01/08181839/Screen-Shot-2018-01-08-at-22.14.52.png&quot;&gt;&lt;img src=&quot;https://cdn.deliciousbrains.com/content/uploads/2018/01/08181839/Screen-Shot-2018-01-08-at-22.14.52.png&quot; alt=&quot;&quot; width=&quot;720&quot; height=&quot;241&quot; class=&quot;alignnone size-large wp-image-35462&quot; srcset=&quot;https://cdn.deliciousbrains.com/content/uploads/2018/01/08181839/Screen-Shot-2018-01-08-at-22.14.52.png 2226w, https://cdn.deliciousbrains.com/content/uploads/2018/01/08181839/Screen-Shot-2018-01-08-at-22.14.52-385x129.png 385w, https://cdn.deliciousbrains.com/content/uploads/2018/01/08181839/Screen-Shot-2018-01-08-at-22.14.52-770x257.png 770w, https://cdn.deliciousbrains.com/content/uploads/2018/01/08181839/Screen-Shot-2018-01-08-at-22.14.52-1540x515.png 1540w&quot; sizes=&quot;(max-width: 720px) 100vw, 720px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The onus is on each site owner or developer to prepare the site to prevent this and protect their clients. That sucks, particularly for people who manage more than one site, or have forgotten about sites they may have worked on in the past.&lt;/p&gt;
&lt;h3 id=&quot;impact&quot;&gt;Impact on Agencies, Site Owners &amp;amp; Developers&lt;/h3&gt;
&lt;p&gt;The percentage number of sites on the web that are powered by WordPress is often touted and this number will be made up of a variety of different types of sites and site owners. A large number will be developers, freelancers and agencies who have built sites in the past, manage sites currently, and build every new site with WordPress. From experience, these developers typically don’t use page builder plugins but a combination of custom fields and meta boxes to give clients the ability to add all the data needed to be displayed on the site in a controlled and prescribed style.&lt;/p&gt;
&lt;p&gt;These people will need to prepare for 5.0 (more on that later) to make sure their clients aren’t affected by Gutenberg. This will come at quite a cost to this portion of users, and many sites will slip through the cracks and remain in a broken state. &lt;a href=&quot;https://twitter.com/youtoocanbeguru&quot;&gt;Briget Willard&lt;/a&gt; makes this point in an &lt;a href=&quot;https://github.com/WordPress/gutenberg/issues/3926&quot;&gt;excellent issue&lt;/a&gt; created on the Gutenberg repository calling for extended timelines for the implementation to help factor in the sheer effort and cost to cope with a change of this magnitude.&lt;/p&gt;
&lt;h3 id=&quot;higher-barrier-entry&quot;&gt;Higher Barrier to Entry&lt;/h3&gt;
&lt;p&gt;Out of all the modern frontend frameworks, React was always the first choice for Gutenberg, even after &lt;a href=&quot;https://wptavern.com/wordpress-core-javascript-framework-debate-heats-up-contributors-narrow-discussion-to-react-vs-vue&quot;&gt;some token debate&lt;/a&gt;, and weathering the storm of &lt;a href=&quot;https://wptavern.com/wordpress-abandons-react-due-to-patents-clause-gutenberg-to-be-rewritten-with-a-different-library&quot;&gt;patent clauses&lt;/a&gt;. But adding a shiny new framework to a critical piece of WordPress core is highly problematic and we’ve seen it before. WordPress 3.5 was released with a new media manager, built with Backbone and landed without documentation, no clear extensibility model, and a steep learning curve for core contributors and developers with media-related plugins.&lt;/p&gt;
&lt;p&gt;Gutenberg has the potential to go the same way, but undoubtedly it will reduce the amount of people able to contribute to it, without learning React deeply. It also places a burden on plugin developers (in a short timescale) to learn, adapt, and get their plugins ready.&lt;/p&gt;
&lt;p&gt;Of course this is possible for the big guys like &lt;a href=&quot;https://woocommerce.com/2017/11/woocommerce-gutenberg/&quot;&gt;WooCommerce&lt;/a&gt; (Automattic owned, large team) and &lt;a href=&quot;https://www.advancedcustomfields.com/blog/acf-year-review-2017/&quot;&gt;Advanced Custom Fields&lt;/a&gt; (independant small team, huge user base), but this will affect any plugin which registers a custom post type, or meta boxes. Most developers simply won’t have the time, inclination or skills to make them compatible with Gutenberg. We will likely see a lot of plugins broken which just won’t get fixed. That will have a detrimental effect on user experience and the WordPress ecosystem in general.&lt;/p&gt;
&lt;h3 id=&quot;technical-debt&quot;&gt;More Technical Debt&lt;/h3&gt;
&lt;p&gt;The way in which Gutenberg stores its data is, at first glance, a neat approach alongside the existing WordPress data structure. However, &lt;a href=&quot;https://twitter.com/EricMann&quot;&gt;Eric Mann&lt;/a&gt; makes a great point about how this isn’t the right way forward and exposes the double standard with backwards compatibility I mentioned earlier:&lt;/p&gt;
&lt;blockquote readability=&quot;7.3372781065089&quot;&gt;
&lt;p&gt;Gutenberg reimagines and reinvents the way WordPress is built. This is a good thing! But we shouldn’t be shoehorning the newer features into older structures because we’re afraid of breaking backwards compatibility on the back-end. Gutenberg already sacrifices backwards compatibility on the front-end!﻿&lt;/p&gt;
&lt;footer&gt;&lt;cite&gt;&lt;a href=&quot;https://ttmm.io/tech/gutenberg-and-the-road-ahead/&quot;&gt;Gutenberg and the Road Ahead&lt;/a&gt;&lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;
&lt;p&gt;He quotes &lt;a href=&quot;https://twitter.com/JJJ&quot;&gt;John James Jacoby&lt;/a&gt; who suggests a different underlying database model for Gutenberg:&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-width=&quot;550&quot; data-dnt=&quot;true&quot; readability=&quot;14.15&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Gutenberg should have its own database tables, or existing tables need to be altered to store and retrieve individual blocks in a more logical and performant way.&lt;/p&gt;
&lt;p&gt;• blocks&lt;br/&gt;• blockmeta&lt;br/&gt;• block_relationships&lt;br/&gt;• block_relationshipmeta&lt;/p&gt;
&lt;p&gt;Never gonna happen, though.&lt;/p&gt;
&lt;p&gt;— ʝ³ (@JJJ) &lt;a href=&quot;https://twitter.com/JJJ/status/940953146817380352?ref_src=twsrc%5Etfw&quot;&gt;December 13, 2017&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;Update: A big concern with the new React based editor from the outset has been about accessibility (a11y). Many have felt, as is typical with a11y work, that it’s a secondary design decision and treated as an afterthought. Despite the best efforts of the WordPress Accessibility Team, Gutenberg’s accessibility is severely lacking, and frustration around its development and communication between the wpa11y team has led to &lt;a href=&quot;https://rianrietveld.com/2018/10/09/i-have-resigned-the-wordpress-accessibility-team/&quot;&gt;Rian Rietveld resigning as lead of the WordPress Accessibility team&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This is sad news for the WordPress community, but unfortunately it seems it will be one of many examples of collateral damage as WordPress implements Gutenberg.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;approach&quot;&gt;What Should the Approach Be?&lt;/h2&gt;
&lt;p&gt;With hindsight I feel it would have been better to be upfront about the scope of the change. This is not just an editor replacement but a paradigm shift in how we edit in WordPress. This would have allowed the community more time to give feedback and understand the ramifications of the change.&lt;/p&gt;
&lt;p&gt;Was it needed? WordPress has limited means of garnering feedback from users, so it feels like a lot of decisions are based on assumptions. WordPress claims to work off the wishes of the ‘Vocal Minority’:&lt;/p&gt;
&lt;blockquote readability=&quot;9.4609164420485&quot;&gt;
&lt;p&gt;When making decisions on how to move forward with future versions of WordPress, we look to engage more of those users who are not so vocal online. We do this by meeting and talking to users at WordCamps across the globe, this gives us a better balance of understanding and ultimately allows us to make better decisions for everyone moving forward.﻿&lt;/p&gt;
&lt;footer&gt;&lt;cite&gt;&lt;a href=&quot;https://wordpress.org/about/philosophy/#minority&quot;&gt;WordPress Philosophy&lt;/a&gt;&lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;
&lt;p&gt;I would guess the majority of people if polled at a WordCamp would be excited about Gutenberg but worried about the implementation timeline we face now. I would also guess that if asked what they most wanted from WordPress, the equivalent of Gutenberg would not top the list. From my own experience and talking to users at the meetup I help organize, a sample wishlist would feature a simplified admin dashboard, native custom fields, improved developer experience, Composer support, PHP version bump, and an improved media library.&lt;/p&gt;
&lt;p&gt;Nevertheless, Gutenberg is a steam train that likely can’t be stopped, but I think the approach to its integration could be adjusted.&lt;/p&gt;
&lt;p&gt;Core should leave Gutenberg as a feature plugin for longer. The timeline is just too short for people to prepare. It is too great a change to be rushed. I think the decision to be merged should be rethought and only merged when a certain level of plugin adoption by users is reached. Let’s not forget Matt Mullenweg gave that same restriction for the merge of the REST API when it was a feature plugin and didn’t want to rush a merge (which it eventually was):&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-width=&quot;550&quot; data-dnt=&quot;true&quot; readability=&quot;9.4787234042553&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;&lt;a href=&quot;https://twitter.com/Krogsgard?ref_src=twsrc%5Etfw&quot;&gt;@Krogsgard&lt;/a&gt; No one is against iteration. It's: iterate in plugin with low stakes, or iterate in core, shipping to tens of millions of sites?&lt;/p&gt;
&lt;p&gt;— Matt Mullenweg (@photomatt) &lt;a href=&quot;https://twitter.com/photomatt/status/696765965334290432?ref_src=twsrc%5Etfw&quot;&gt;February 8, 2016&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;Update: Since this article was published, the Gutenberg team have &lt;a href=&quot;https://make.wordpress.org/core/2018/01/12/whats-new-in-gutenberg-12th-january/&quot;&gt;released version 2.0&lt;/a&gt; with a mammoth changelog, to me indicating it is not yet a stable and mature enough product to be considered for a merge.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If instead a merge has to happen, then Gutenberg should &lt;a href=&quot;https://github.com/WordPress/gutenberg/issues/4423&quot;&gt;only be on by default for new installs&lt;/a&gt; (but the issue has since been &lt;a href=&quot;https://github.com/WordPress/gutenberg/issues/4423#issuecomment-357949762&quot;&gt;closed&lt;/a&gt;) of WordPress 5.0. This would remove the possibility of breaking legacy sites, giving them time to prepare and the choice to switch from the classic editor. Sure, adoption would be slower but I believe the alternative could have a far greater cost in the long term.&lt;/p&gt;
&lt;p&gt;Eric Mann &lt;a href=&quot;https://ttmm.io/tech/gutenberg-and-the-road-ahead/&quot;&gt;suggests soft forking WordPress&lt;/a&gt;, leaving the 4.x branch Gutenberg free and allowing the 5.x branch to really go to town taking new approaches from Gutenberg across WordPress as a whole. &lt;a href=&quot;https://twitter.com/mor10&quot;&gt;Morten Rand-Hendriksen&lt;/a&gt; also suggests &lt;a href=&quot;https://www.linkedin.com/pulse/gutenberg-future-wordpress-conditions-success-morten-rand-hendriksen/&quot;&gt;drawing a line in the sand and forking&lt;/a&gt;. Forking would also have the same benefits as my previous suggestion.&lt;/p&gt;
&lt;h2 id=&quot;prepare&quot;&gt;How to Prepare&lt;/h2&gt;
&lt;p&gt;The best way to prevent sites breaking for users when Gutenberg lands, is to enable the &lt;a href=&quot;https://wordpress.org/plugins/classic-editor/&quot;&gt;Classic Editor plugin&lt;/a&gt; now and configure it to revert to the old editor. This will mean come 5.0 things will work as is, and will be the approach I take for now.&lt;/p&gt;
&lt;p&gt;If you have a site with custom post types (CPT) or develop a plugin with them registered, you can stop Gutenberg hijacking the usual UI with a couple of things. Either ensure you edit the registration arguments to explicitly set &lt;code&gt;show_in_rest&lt;/code&gt; to false, or if you need to use the REST API for your CPT, then you can use the following filter to turn off Gutenberg for your CPTs:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;add_filter( ‘gutenberg_can_edit_post_type’, ‘my_gutenberg_can_edit_post_types’ );
function my_gutenberg_can_edit_post_types( $can_edit, $post_type ) {
    If ( in_array( $post_type, array( ‘a_post_type’, ‘another_post_type’ ) ) {
        return false;
    }

    return $can_edit;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;A more drastic measure is not updating to WordPress 5.0 and only update to any security releases of 4.9.x.&lt;/p&gt;
&lt;h2 id=&quot;future&quot;&gt;The Future of WordPress&lt;/h2&gt;
&lt;p&gt;This is undoubtedly going to be a powerful feature for WordPress and could very well elevate it above its competitors even further and drive the market share even higher in the coming year. In essence, it could be a rejuvenation of WordPress, one that Matt hopes will see it through for another 10 years. But the impact of the Gutenberg project could potentially be a negative one with a far-reaching effect.&lt;/p&gt;
&lt;p&gt;What does this mean for WordPress in the long term? The steps taken above to disable Gutenberg will lead to two different WordPress admins, creating a fractured experience which &lt;a href=&quot;https://twitter.com/kevinwhoffman&quot;&gt;Kevin Hoffman&lt;/a&gt; believes has &lt;a href=&quot;https://github.com/WordPress/gutenberg/issues/2457#issuecomment-324521711&quot;&gt;little hope of future convergence&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For me, Gutenberg highlights the larger problem with WordPress. WordPress needs to evolve and grow. It wants to create a new way of doing things (see &lt;a href=&quot;https://www.linkedin.com/pulse/wordpress-changing-here-3-things-you-need-know-morten-rand-hendriksen/&quot;&gt;views and blocks&lt;/a&gt;, not posts and pages). But you can’t do that and carry the legacy of almost 15 years worth of code and technical debt. Is Gutenberg papering over the cracks?&lt;/p&gt;
&lt;p&gt;For many, especially in the enterprise WordPress space, Gutenberg is another nail in the coffin for WordPress. People have spent years using WordPress with plugins to turn it into the CMS they really need. In their eyes Gutenberg is undoing all that work and WordPress is, for them, ultimately no longer fit for purpose. This thread from &lt;a href=&quot;https://twitter.com/frontendben&quot;&gt;Ben Furfie&lt;/a&gt; is an interesting take of how many view WordPress and Gutenberg:&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-width=&quot;550&quot; data-dnt=&quot;true&quot; readability=&quot;9.5464285714286&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;I think we will look back at 2017 and see it as the year the &lt;a href=&quot;https://twitter.com/hashtag/WordPress?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#WordPress&lt;/a&gt; project started to fracture. As much as the community desperately wants to see WordPress as an enterprise CMS, projects like &lt;a href=&quot;https://twitter.com/hashtag/Gutenberg?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#Gutenberg&lt;/a&gt; show it is anything but.&lt;/p&gt;
&lt;p&gt;— Ben Furfie (@frontendben) &lt;a href=&quot;https://twitter.com/frontendben/status/946296693926047744?ref_src=twsrc%5Etfw&quot;&gt;December 28, 2017&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When people talk of leaving WordPress and finding a new CMS I do wonder where they will go. There is a raft of options out there (our &lt;a href=&quot;https://twitter.com/mattgrshaw&quot;&gt;Matt&lt;/a&gt; &lt;a href=&quot;https://deliciousbrains.com/craft-cms-self-hosted-wordpress-alternatives/&quot;&gt;reviewed three last year&lt;/a&gt;), but it feels like there is room in the market for a new competitor, albeit a huge project. Who knows, 2018 might be the year WordPress, like b2 before it, is forked into something new.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update: &lt;a href=&quot;https://www.classicpress.net/&quot;&gt;ClassicPress&lt;/a&gt; is a fork of WordPress specifically without the Gutenberg editor, looking to modernize the WordPress codebase and remove certain aspects from the code:&lt;/em&gt;&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-width=&quot;550&quot; data-dnt=&quot;true&quot; readability=&quot;8.3448275862069&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;The most requested feature for &lt;a href=&quot;https://twitter.com/GetClassicPress?ref_src=twsrc%5Etfw&quot;&gt;@GetClassicPress&lt;/a&gt; so far is to remove the Hello Dolly plugin from new installs.&lt;/p&gt;
&lt;p&gt;Feels like the start of deMattifying WordPress. &lt;a href=&quot;https://t.co/E19zw4W6kM&quot;&gt;https://t.co/E19zw4W6kM&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;— Iain Poulson (@polevaultweb) &lt;a href=&quot;https://twitter.com/polevaultweb/status/1038546868790329346?ref_src=twsrc%5Etfw&quot;&gt;September 8, 2018&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;blockquote readability=&quot;7.1256830601093&quot;&gt;
&lt;p&gt;If the next version of WordPress comes with a feature that the majority of users immediately want to turn off, or think they’ll never use, then we’ve blown it&lt;/p&gt;
&lt;footer&gt;&lt;cite&gt;&lt;a href=&quot;https://wordpress.org/about/philosophy/#clean&quot;&gt;WordPress Philosophy&lt;/a&gt;&lt;/cite&gt;&lt;/footer&gt;&lt;/blockquote&gt;
&lt;p&gt;Time will tell if the Gutenberg project is a success. It certainly is powerful software and could be a gamechanger. Although I joked about not liking change, I see the value in it. It is necessary to grow and push forward. But only when the change is well thought out, initiated for the right reasons, and adopted in a sensible fashion.&lt;/p&gt;
&lt;p&gt;I’m hugely impressed with what the Gutenberg team have accomplished so far and look forward to seeing it improve. However, I can’t help feeling that other parts of WordPress are suffering because of the drive to implement Gutenberg, and I hope perhaps full time Automatticians are similarly assigned to other much needed parts of core development. It would be great to see WordPress pushed forward with more than just Gutenberg in 2018.&lt;/p&gt;
&lt;p&gt;What are your thoughts on the Gutenberg project? What would you like to see in WordPress in 2018? Let us know in the comments.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-width=&quot;550&quot; data-dnt=&quot;true&quot; readability=&quot;6.075&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;So, are you team &lt;a href=&quot;https://twitter.com/hashtag/itstheend?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#itstheend&lt;/a&gt; or team &lt;a href=&quot;https://twitter.com/hashtag/newbeginning?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#newbeginning&lt;/a&gt; for Gutenberg?&lt;/p&gt;
&lt;p&gt;— Delicious Brains (@dliciousbrains) &lt;a href=&quot;https://twitter.com/dliciousbrains/status/951498579910283264?ref_src=twsrc%5Etfw&quot;&gt;January 11, 2018&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

</description>
<pubDate>Thu, 25 Oct 2018 00:13:42 +0000</pubDate>
<dc:creator>smacktoward</dc:creator>
<og:type>article</og:type>
<og:title>Is Gutenberg the End or a New Beginning for WordPress?</og:title>
<og:description>Is Gutenberg the right way forward for WordPress? In this post, Iain takes a look at the Gutenberg editor &amp; its inevitable impact on users.</og:description>
<og:url>https://deliciousbrains.com/wordpress-gutenberg/</og:url>
<og:image>https://cdn.deliciousbrains.com/content/uploads/2018/01/09162551/db-Glutenberg-1540x748.jpg</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://deliciousbrains.com/wordpress-gutenberg/</dc:identifier>
</item>
<item>
<title>Tesla Third Quarter 2018 Update [pdf]</title>
<link>http://ir.tesla.com/static-files/725970e6-eda5-47ab-96e1-422d4045f799</link>
<guid isPermaLink="true" >http://ir.tesla.com/static-files/725970e6-eda5-47ab-96e1-422d4045f799</guid>
<description>&lt;a href=&quot;http://ir.tesla.com/static-files/725970e6-eda5-47ab-96e1-422d4045f799&quot;&gt;Download PDF&lt;/a&gt;</description>
<pubDate>Wed, 24 Oct 2018 20:15:22 +0000</pubDate>
<dc:creator>chollida1</dc:creator>
<og:type>article</og:type>
<og:title>Is Gutenberg the End or a New Beginning for WordPress?</og:title>
<og:description>Is Gutenberg the right way forward for WordPress? In this post, Iain takes a look at the Gutenberg editor &amp; its inevitable impact on users.</og:description>
<og:url>https://deliciousbrains.com/wordpress-gutenberg/</og:url>
<og:image>https://cdn.deliciousbrains.com/content/uploads/2018/01/09162551/db-Glutenberg-1540x748.jpg</og:image>
<dc:language>en-US</dc:language>
<dc:format>application/pdf</dc:format>
<dc:identifier>http://ir.tesla.com/static-files/725970e6-eda5-47ab-96e1-422d4045f799</dc:identifier>
</item>
<item>
<title>Citus Data Donates 1% of Equity to PostgreSQL Organizations</title>
<link>https://www.citusdata.com/newsroom/press/citus-data-donates-1-percent-equity-to-non-profit-postgresql-organizations/</link>
<guid isPermaLink="true" >https://www.citusdata.com/newsroom/press/citus-data-donates-1-percent-equity-to-non-profit-postgresql-organizations/</guid>
<description>&lt;h2&gt;Stock grant to benefit efforts to advance growth of the open source PostgreSQL database in the U.S. and in Europe&lt;/h2&gt;
&lt;p&gt;&lt;span class=&quot;publish-info&quot;&gt;SAN ​​FRANCISCO, Oct. 24, 2018 -&lt;/span&gt; ​​​​&lt;a href=&quot;https://www.citusdata.com&quot;&gt;Citus Data&lt;/a&gt;, ​​a leading provider of scale-out Postgres database technologies, today announced it is donating 1 percent of its equity to the non-profit PostgreSQL organizations in the US and Europe. The United States PostgreSQL Association has received the stock grant and will work with the PostgreSQL Europe organization to support the growth, education, and future innovation of the open source Postgres database in both the US and in Europe.&lt;/p&gt;
&lt;p&gt;To coincide with Citus Data’s equity donation, the company is joining the &lt;a href=&quot;https://pledge1percent.org/&quot; target=&quot;_blank&quot;&gt;Pledge 1% movement&lt;/a&gt;, alongside well-known technology organizations such as Atlassian, Twilio, Box, and more.&lt;/p&gt;
&lt;p&gt;Founded in 2011, the founders of Citus Data set out to bring the performance and economics of scale-out systems to the field of relational databases. To give applications the memory, compute, and disk resources of a distributed database cluster, the team at Citus Data created an extension to Postgres that transforms PostgreSQL into a distributed database—something that was previously not possible with any other relational database, whether proprietary or open source. The Citus database is a popular choice for multi-tenant SaaS businesses that need horizontal scale in order to grow their user base; and for enterprises with customer-facing, real-time analytics dashboards that require sub-second latency.&lt;/p&gt;
&lt;p&gt;“When people think about contributing to open source and building sustainable open source communities, there are different approaches,” said Citus Data CEO Umur Cubukcu. “You can open source software you’ve created, you can maintain certain features and projects, and you can contribute to events with speakers and sponsorships—all of which our team spends a lot of time on. Today, we are excited to create a new way to contribute to open source, by donating 1 percent of our equity to the non-profit PostgreSQL organizations. As Ozgun Erdogan said in &lt;a href=&quot;https://www.citusdata.com/blog/2018/10/24/why-citus-data-is-donating-1-percent-equity/&quot;&gt;his blog post&lt;/a&gt;, we—the Citus Data founders—feel this 1% stock donation is a way for us to give back and to share a piece of our future success. And we believe the donation will make a real difference to future projects in the Postgres community.”&lt;/p&gt;
&lt;p&gt;“One the most important issues in modern software is building sustainable open source models in the age of the cloud,” said RedMonk Analyst and Co-Founder James Governor, “Citus Data is both making an innovative bet, and paying it forward, by applying the 1% Pledge model to underpin the renaissance of the Postgres community”.&lt;/p&gt;
&lt;p&gt;“The PostgreSQL community is committed to driving innovation on the world’s most advanced open source database. And to do this, we need advocates and community members to continue to do the great work they do… to invest time, energy, and resources into our always-evolving PostgreSQL database,” said Magnus Hagander, open source advocate, PostgreSQL core team member, and president of PostgreSQL Europe. “What do I think about this donation of 1 percent equity from the team at Citus Data? I think it’s a generous way to support the PostgreSQL community, and shines a light on the importance of supporting open source projects that underpin so many products and companies today.”&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;To learn more about the United States PostgreSQL Association (pgUS) visit: &lt;a href=&quot;https://postgresql.us/&quot; target=&quot;_blank&quot;&gt;https://postgresql.us/&lt;/a&gt;&lt;br/&gt;To learn more about Pledge 1% visit: &lt;a href=&quot;https://pledge1percent.org/&quot; target=&quot;_blank&quot;&gt;https://pledge1percent.org/&lt;/a&gt;&lt;br/&gt;To read the Citus Data CTO’s blog post on the 1% equity donation, please visit &lt;a href=&quot;https://www.citusdata.com/blog/2018/10/24/why-citus-data-is-donating-1-percent-equity/&quot;&gt;https://www.citusdata.com/blog/2018/10/24/why-citus-data-is-donating-1-percent-equity/&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 24 Oct 2018 19:29:18 +0000</pubDate>
<dc:creator>mitchbob</dc:creator>
<og:description>The donation of 1% of Citus Data stock is being made to advance the growth of the open source PostgreSQL database in both the U.S. &amp; in Europe. The Citus database is an extension to PostgreSQL. Citus Data is also joining the Pledge 1% movement alongside organizations such as Atlassian, Twilio, Box, &amp; more.</og:description>
<og:image>https://cl.ly/253E280b0x42/CitusData-OG-SiteImage-1200x630.png</og:image>
<og:title>Citus Data Donates 1% of Equity to Non-Profit PostgreSQL Organizations | Citus Data</og:title>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.citusdata.com/newsroom/press/citus-data-donates-1-percent-equity-to-non-profit-postgresql-organizations/</dc:identifier>
</item>
<item>
<title>gRPC-Web is going GA</title>
<link>https://www.cncf.io/blog/2018/10/24/grpc-web-is-going-ga/</link>
<guid isPermaLink="true" >https://www.cncf.io/blog/2018/10/24/grpc-web-is-going-ga/</guid>
<description>&lt;p class=&quot;copyright_text&quot;&gt;Copyright © 2017 The Linux Foundation®. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our &lt;a href=&quot;https://www.linuxfoundation.org/trademark-usage&quot;&gt;Trademark Usage&lt;/a&gt; page. Linux is a registered trademark of Linus Torvalds. &lt;a href=&quot;http://www.linuxfoundation.org/privacy&quot;&gt;Privacy Policy&lt;/a&gt; and &lt;a href=&quot;http://www.linuxfoundation.org/terms&quot;&gt;Terms of Use&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 24 Oct 2018 19:05:32 +0000</pubDate>
<dc:creator>biggestlou</dc:creator>
<og:type>article</og:type>
<og:title>gRPC-Web is going GA - Cloud Native Computing Foundation</og:title>
<og:description>On behalf of the Cloud Native Computing Foundation, I’m excited to announce the GA release of gRPC-Web, a JavaScript client library that enables web apps to communicate directly with backend...</og:description>
<og:url>https://www.cncf.io/blog/2018/10/24/grpc-web-is-going-ga/</og:url>
<og:image>https://www.cncf.io/wp-content/uploads/2018/10/1.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cncf.io/blog/2018/10/24/grpc-web-is-going-ga/</dc:identifier>
</item>
<item>
<title>PipelineDB 1.0 – High-Performance Time-Series Aggregation for PostgreSQL</title>
<link>https://www.pipelinedb.com/blog/pipelinedb-1-0-0-high-performance-time-series-aggregation-for-postgresql</link>
<guid isPermaLink="true" >https://www.pipelinedb.com/blog/pipelinedb-1-0-0-high-performance-time-series-aggregation-for-postgresql</guid>
<description>&lt;br/&gt;&lt;h2&gt;TL;DR&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;PipelineDB &lt;code&gt;1.0&lt;/code&gt; is a PostgreSQL extension for high-performance time-series aggregation via continuous SQL queries. &lt;a href=&quot;http://docs.pipelinedb.com/installation.html&quot;&gt;Get started here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;PipelineDB enables realtime reporting use cases at scale, where only summary data is needed&lt;/li&gt;
&lt;li&gt;PipelineDB is now licensed under the liberal Apache 2.0 license&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Overview&lt;/h2&gt;
&lt;p&gt;Just over three years ago we published the &lt;a href=&quot;https://www.pipelinedb.com/blog/to-be-continuous&quot;&gt;very first release&lt;/a&gt; of PipelineDB, which began as a fork of PostgreSQL. About thirty seconds after that, people from all corners of the earth began enthusiastically asking us if we could make PipelineDB an extension of PostgreSQL, rather than a standalone fork. We've always empathized with this sentiment from a user's perspective. In addition to the technical drawbacks, running a fork comes with a very real psychological burden as well.&lt;/p&gt;
&lt;p&gt;And from our own perspective, maintaining a fork has incurred its own unique challenges that often weigh heavily against the upside. So as PipelineDB has matured over the years based on usage and feedback from thousands of organizations worldwide&lt;br/&gt;--including several in the Fortune 100--and we as a company have found our financial footing with a reliable business model, the time became right to invest heavily into giving our users what they've asked for: PipelineDB factored out into a standard PostgreSQL extension.&lt;/p&gt;
&lt;p&gt;Our dear friends: we genuinely, seriously, from the bottom of our hearts could not be more excited and humbled to give that to you today with PipelineDB &lt;code&gt;1.0.0&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;What is PipelineDB?&lt;/h2&gt;
&lt;p&gt;PipelineDB is an open-source PostgreSQL extension that enables realtime reporting use cases by continuously aggregating large streams of time series data down into summary data. It shines the most at larger scales, where storing lots of raw time-series data and aggregating it over and over again becomes inefficient. The amount of value that PipelineDB adds is directly proportional to the amount of continuous aggregation that an analytics use case can benefit from. &lt;strong&gt;PipelineDB should be used for analytics use cases that only require summary data, like realtime reporting dashboards.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;PipelineDB challenges the widespread paradigm of storing all raw data in a database and then querying it on demand. Inversely, PipelineDB enables users to run continuous aggregations over streaming time-series data, and only store the compact output of these continuous queries as incrementally updated table rows that can be evaluated with minimal query latency.&lt;/p&gt;
&lt;p&gt;Our need for this “inverted database” was born out of our exhilarating experience building large-scale data infrastructure in the Ad Tech industry (hey &lt;a href=&quot;https://www.adroll.com/&quot;&gt;AdRoll&lt;/a&gt;), where the volumes of raw data we were dealing with required breaking new ground technologically just to make even the most basic sense of our streaming time-series data in a low-latency manner. A simple, yet powerful observation began to crystallize in our minds:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Everything we needed to know in realtime about these massive, perpetually growing datasets was well-known by us in advance, by definition.&lt;/strong&gt; If queries are not known in advance, there is likely not a realtime need.&lt;/p&gt;
&lt;p&gt;So, in scenarios where queries are known in advance, they can and should be run continuously in order to make the data infrastructure that powers these realtime analytics applications simpler, faster, and cheaper than they would otherwise be with the traditional “store first, query later” data processing model.&lt;/p&gt;
&lt;p&gt;Our use cases at AdRoll were nearly always comprised of some form of summary data: aggregations, unique user counts, sliding window queries, time-series charts, and things that could be displayed as compact visualizations suited for intuitive human consumption. One benefit of continuous computation is that summary data is always available for low-latency lookups. Realtime analytics use cases should never need to compute data more than once, especially over very large datasets. Systems should just had to glance at the always up-to-date aggregate results. Analytics use cases that do not involve a realtime need should be dealt with by a different system, one that does store granular data for ad hoc analysis.&lt;/p&gt;
&lt;p&gt;Back then, continuous aggregation at scale necessitated some extremely innovative but complex infrastructure. It was hard to build, but it worked. And most importantly, we saw the data infrastructure we were building at AdRoll as solving an extremely general problem that could be more easily solved in the future by the right product. And that realization brought us to where we are today: PipelineDB &lt;code&gt;1.&lt;/code&gt;0.&lt;/p&gt;
&lt;h2&gt;PipelineDB in Action&lt;/h2&gt;
&lt;p&gt;SQL is a natural choice for a product that enables high-performance continuous aggregation. In addition to allowing for the intuitive expression of continuous aggregations to perform, it becomes quite useful for running further SQL queries on continuously updating aggregate output, which is just stored as regular tables anyways. In PipelineDB, SQL is even used to write time-series events to a stream, which are also structured as tables:&lt;/p&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;INSERT INTO events_stream (ts, value) VALUES (now(), '0ef346ac');&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;To perform an aggregation over this stream, we can use PipelineDB's most fundamental abstraction: the continuous view. A continuous view is an aggregation query defined over a stream of time-series data. For example, here's a continuous view that aggregates unique values in our stream, bucketing them by hour:&lt;/p&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;CREATE VIEW uniques AS
 SELECT hour(ts), COUNT(DISTINCT value) FROM events_stream
GROUP BY hour;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Even if billions and billions of rows are written to &lt;code&gt;events_stream&lt;/code&gt;, our continuous view ensures that only one physical row per hour is actually persisted within the database. As soon as the continuous view reads new incoming events and the distinct count is updated the reflect new information, the raw events will be discarded. They aren't stored in PipelineDB, ever, although almost everybody writes their raw data somewhere else. And that simple idea enables PipelineDB users to achieve two important things:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Enormous levels of raw event throughput on modest hardware footprints&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Extremely low read query latencies&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;It also means that the traditional dependence between data volumes ingested and data volumes stored is broken, facilitating not only high performance but high performance sustained indefinitely. Data volumes can grow exponentially while aggregate data stored in PipelineDB remains constant, or grows only minimally.&lt;/p&gt;
&lt;p&gt;While our simple example is a canonical illustration of the core concept behind PipelineDB, it generalizes to virtually any SQL aggregation query you can imagine running on streams of time-series data.&lt;/p&gt;
&lt;p&gt;The other type of continuous queries that PipelineDB allows you to define are what we call continuous transforms. Unlike continuous views -- which store aggregate state in incrementally updated tables -- continuous transforms are stateless and simply apply a transformation to a stream, writing out the result to another stream. For example, this continuous transform unpacks a PostgreSQL JSON event into separate columns:&lt;/p&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;CREATE VIEW unpack WITH (action=transform) AS
 SELECT
  (payload-&amp;gt;&amp;gt;’timestamp’)::timestamp AS ts,
  payload-&amp;gt;&amp;gt;’user_id’ AS user_id,
  payload-&amp;gt;&amp;gt;’url’ AS url
FROM json_stream;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;The output of this transform can then be consumed by downstream continuous views and transforms:&lt;/p&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;CREATE VIEW hourly_uniques AS
 SELECT hour(ts), COUNT(DISTINCT user_id) FROM
output_of(‘unpack’);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;And realtime uniques counts can be retrieved with a simple &lt;code&gt;SELECT&lt;/code&gt; query against the continuous view:&lt;/p&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;SELECT * FROM hourly_uniques WHERE hour &amp;gt;= now() - interval ‘4 hours’;

   hour              | count 
-------------------------------+-------
 2018-10-24 00:00:00 |     44123
 2018-10-24 01:00:00 |     56332
 2018-10-24 02:00:00 |     64847
 2018-10-24 03:00:00 |     72905&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;PipelineDB ships with a rich set of builtin aggregates and other functionality indispensable for high-performance time-series analytics:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;HyperLogLog-based distincts counting, merging, and manipulation&lt;/li&gt;
&lt;li&gt;Bloom filters for set membership analysis&lt;/li&gt;
&lt;li&gt;Top-K and “heavy hitters” tracking&lt;/li&gt;
&lt;li&gt;Distributions and percentiles analysis&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://docs.pipelinedb.com/aggregates.html&quot;&gt;Much more&lt;/a&gt; and if we don’t have something you need, feel free to &lt;a href=&quot;https://github.com/pipelinedb/pipelinedb/issues&quot;&gt;let us know&lt;/a&gt;!&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;In addition to a rich set of functionality being available for defining continuous queries, continuous queries may also be chained together into arbitrarily complex topologies of continuous computation. Each continuous query produces its own output stream of its incremental updates, which can be consumed by another continuous query as any other stream.&lt;/p&gt;
&lt;h2&gt;Technical Notes&lt;/h2&gt;
&lt;p&gt;We began laying the groundwork for delivering PipelineDB as an extension beginning with version &lt;a href=&quot;https://www.pipelinedb.com/blog/pipelinedb-0-9-7-delta-streams-and-towards-a-postgresql-extension&quot;&gt;0.9.7&lt;/a&gt;. Each release since then has moved PipelineDB incrementally closer to a standalone extension, so version &lt;code&gt;1.0.0&lt;/code&gt; does not include any radical interface changes. The main things that have changed are:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Non-standard syntax has been removed. &lt;code&gt;CREATE CONTINUOUS ...&lt;/code&gt; syntax has been replaced by &lt;code&gt;CREATE VIEW&lt;/code&gt;, and &lt;code&gt;CREATE STREAM …&lt;/code&gt; has been replaced by &lt;code&gt;CREATE FOREIGN TABLE …&lt;/code&gt; (&lt;a href=&quot;http://docs.pipelinedb.com/streams.html&quot;&gt;docs&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Configuration parameters are now qualified by &lt;code&gt;pipelinedb&lt;/code&gt;. For example, &lt;code&gt;continuous_query_num_workers&lt;/code&gt; is now &lt;code&gt;pipelinedb.num_workers&lt;/code&gt;. (&lt;a href=&quot;http://docs.pipelinedb.com/conf.html&quot;&gt;docs&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;PostgreSQL &lt;code&gt;pg_dump&lt;/code&gt;, &lt;code&gt;pg_restore&lt;/code&gt;, and &lt;code&gt;pg_upgrade&lt;/code&gt; tooling is now used instead of the PipelineDB variants (&lt;code&gt;pipeline-dump&lt;/code&gt;, &lt;code&gt;pipeline-restore&lt;/code&gt;, &lt;code&gt;pipeline-upgrade&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;We have also renamed certain functions and aggregates to be descriptive about what problem they solve for you. Previous versions of PipelineDB had some fancy aggregates that operated on data structures useful for streaming computation, but we felt that their names were too opaque and thus not as helpful as they could be for users:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;“Top-K” now represents Filtered-Space-Saving (&lt;a href=&quot;http://docs.pipelinedb.com/aggregates.html#top-k-aggregates&quot;&gt;docs&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;“Distributions” now refer to T-Digests (&lt;a href=&quot;http://docs.pipelinedb.com/aggregates.html#distribution-aggregates&quot;&gt;docs&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;“Frequency” now refers to Count-Min-Sketch (&lt;a href=&quot;http://docs.pipelinedb.com/aggregates.html#frequency-tracking-aggregates]&quot;&gt;docs&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Beyond that, almost everything else in this release is internal rework that makes PipelineDB adhere to PostgreSQL’s standard extension interface. You won’t notice much difference in terms of how it feels to use PipelineDB, and we’ve taken great care to ensure that is the case.&lt;/p&gt;
&lt;p&gt;PipelineDB &lt;code&gt;1.0.0&lt;/code&gt; currently supports PostgreSQL versions &lt;code&gt;10.1&lt;/code&gt;, &lt;code&gt;10.2&lt;/code&gt;, &lt;code&gt;10.3&lt;/code&gt;, &lt;code&gt;10.4&lt;/code&gt;, and &lt;code&gt;10.5&lt;/code&gt;. Binaries supporting PostgreSQL &lt;code&gt;11&lt;/code&gt; will be published soon and will not require a new version release.&lt;/p&gt;
&lt;h2&gt;Licensing&lt;/h2&gt;
&lt;p&gt;Another important topic we’d like to address is licensing. Since its release, PipelineDB had been licensed under the GPL version 3. But packaging PipelineDB as an extension to an existing database warranted serious consideration about what PipelineDB’s license should be. The debate was extensive and interesting. There are compelling arguments to be made for more restrictive open-source licensing and for liberal licensing, each options with its own set of benefits and drawbacks.&lt;/p&gt;
&lt;p&gt;Ultimately we decided to relicense PipelineDB under the Apache 2.0 open-source license. We felt that a liberal license is more consistent with our philosophy about open-source software, and more inline with our values as a company. Greater adoption means a stronger community, maximized product usage and feedback, and a broader conduit into a sustainable business model that allows us to keep reinvesting into product engineering.&lt;/p&gt;
&lt;p&gt;We’ve been lucky enough to have a genuinely amazing community of users whose feedback, ideas and input have been instrumental in making PipelineDB what it is today. And we want to do everything we can to make PipelineDB accessible to even more people and organizations.&lt;/p&gt;
&lt;h2&gt;What’s Coming in the Next Release&lt;/h2&gt;
&lt;p&gt;Now that PipelineDB is packaged as a relatively lightweight extension, you can expect faster release cycles. Along with any necessary maintenance on &lt;code&gt;1.0.0&lt;/code&gt;, the release following this one is currently slated to add one new major area of functionality: automated partitioning for continuous views.&lt;/p&gt;
&lt;p&gt;It is a very common usage pattern with PipelineDB to summarize time-series by some temporal component (e.g. minute, hour, day), and thus partitioning by time range will allow users to keep queries against their continuous views as performant as possible as they grow over time. We’re keeping the work slated for the follow up release to &lt;code&gt;1.0.0&lt;/code&gt; minimal in order to get partitioning out to users as soon as we possibly can.&lt;/p&gt;
&lt;p&gt;Stay tuned, and enjoy PipelineDB &lt;code&gt;1.0.0&lt;/code&gt;!&lt;/p&gt;
</description>
<pubDate>Wed, 24 Oct 2018 18:26:45 +0000</pubDate>
<dc:creator>Fergi</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.pipelinedb.com/blog/pipelinedb-1-0-0-high-performance-time-series-aggregation-for-postgresql</dc:identifier>
</item>
<item>
<title>Digital Ocean Managed Databases</title>
<link>https://try.digitalocean.com/dbaas-beta/</link>
<guid isPermaLink="true" >https://try.digitalocean.com/dbaas-beta/</guid>
<description>&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-163&quot; readability=&quot;10&quot;&gt;
&lt;p&gt;&lt;span&gt;Fully hosted and managed database engines for your applications, so you can focus on building, not patching.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-318&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;Copyright © 2018 DigitalOcean™ Inc. Proudly made in NY.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;


&lt;div class=&quot;lp-element lp-pom-box&quot; id=&quot;lp-pom-box-337&quot;&gt;






&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-343&quot;&gt;
&lt;p&gt;&lt;span&gt;Developer Relations&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-box&quot; id=&quot;lp-pom-box-345&quot;&gt;



&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-348&quot;&gt;
&lt;p&gt;&lt;span&gt;Documentation&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;


&lt;/div&gt;


&lt;p&gt;
&lt;h2&gt;&lt;span&gt;Database Engines&lt;/span&gt;&lt;/h2&gt;
&lt;/p&gt;
&lt;div class=&quot;lp-element lp-pom-box&quot; id=&quot;lp-pom-box-525&quot; readability=&quot;8&quot;&gt;

&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-530&quot;&gt;
&lt;p&gt;&lt;span&gt;PostgreSQL&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-533&quot; readability=&quot;11&quot;&gt;
&lt;p&gt;&lt;span&gt;A powerful, open source object-relational database system with over 30 years of active development that has earned it a strong reputation for reliability, feature robustness, and performance.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-image&quot; id=&quot;lp-pom-image-709&quot;&gt;
&lt;div class=&quot;lp-pom-image-container&quot;&gt;&lt;img src=&quot;https://d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/transparent.gif&quot; alt=&quot;&quot; data-src-desktop-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/f72904f8-postgresql.svg&quot; data-src-mobile-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/f72904f8-postgresql.svg&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-box&quot; id=&quot;lp-pom-box-526&quot; readability=&quot;6.5&quot;&gt;


&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-534&quot; readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;span&gt;The world's most popular open source database. It uses a relational database and SQL (Structured Query Language) to manage data.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-image&quot; id=&quot;lp-pom-image-671&quot;&gt;
&lt;div class=&quot;lp-pom-image-container&quot;&gt;&lt;img src=&quot;https://d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/transparent.gif&quot; alt=&quot;&quot; data-src-desktop-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/bc94b1a2-11-mysql.svg&quot; data-src-mobile-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/bc94b1a2-11-mysql.svg&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-box&quot; id=&quot;lp-pom-box-527&quot; readability=&quot;8&quot;&gt;


&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-532&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;Available as a standalone service&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-535&quot; readability=&quot;9&quot;&gt;
&lt;p&gt;&lt;span&gt;Combine Spaces with other DigitalOcean products or use it as a standalone service, whichever suits your needs.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;h2&gt;&lt;span&gt;Full Featured Database Functionality&lt;/span&gt;&lt;/h2&gt;
&lt;/p&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-567&quot; readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;span&gt;Build apps and store data in minutes with easy access to one or more databases and sleep better knowing your data is backed up and optimized.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;a class=&quot;lp-element lp-pom-button&quot; id=&quot;lp-pom-button-610&quot; href=&quot;https://try.digitalocean.com/dbaas-beta/clkn/rel/a-4-lightbox.html&quot; name=&quot;lp-pom-button-610&quot;&gt;&lt;span class=&quot;label&quot;&gt;Request Access&lt;/span&gt;&lt;/a&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-665&quot;&gt;
&lt;p&gt;&lt;span&gt;NOW IN BETA&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-666&quot; readability=&quot;9&quot;&gt;
&lt;p&gt;&lt;span&gt;We will support the most popular database engines to meet your business needs, starting with PostgreSQL.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;a class=&quot;lp-element lp-pom-button&quot; id=&quot;lp-pom-button-672&quot; href=&quot;https://try.digitalocean.com/dbaas-beta/clkn/rel/a-4-lightbox.html&quot; name=&quot;lp-pom-button-672&quot;&gt;&lt;span class=&quot;label&quot;&gt;Request Access&lt;/span&gt;&lt;/a&gt;
&lt;div class=&quot;lp-element lp-pom-box&quot; id=&quot;lp-pom-box-679&quot; readability=&quot;10&quot;&gt;

&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-673&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;Multi-node database clustering&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-674&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;Automated failover support&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-675&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;Daily backups with Point in Time Recovery (7 days)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-676&quot;&gt;
&lt;p&gt;&lt;span&gt;Horizontal read scaling&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-677&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;Data encrypted on disk and network&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-678&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;Performance graphs (per minute)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-image&quot; id=&quot;lp-pom-image-680&quot;&gt;
&lt;div class=&quot;lp-pom-image-container&quot;&gt;&lt;img src=&quot;https://d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/transparent.gif&quot; alt=&quot;&quot; data-src-desktop-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; data-src-mobile-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-image&quot; id=&quot;lp-pom-image-681&quot;&gt;
&lt;div class=&quot;lp-pom-image-container&quot;&gt;&lt;img src=&quot;https://d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/transparent.gif&quot; alt=&quot;&quot; data-src-desktop-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; data-src-mobile-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-image&quot; id=&quot;lp-pom-image-682&quot;&gt;
&lt;div class=&quot;lp-pom-image-container&quot;&gt;&lt;img src=&quot;https://d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/transparent.gif&quot; alt=&quot;&quot; data-src-desktop-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; data-src-mobile-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-image&quot; id=&quot;lp-pom-image-683&quot;&gt;
&lt;div class=&quot;lp-pom-image-container&quot;&gt;&lt;img src=&quot;https://d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/transparent.gif&quot; alt=&quot;&quot; data-src-desktop-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; data-src-mobile-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-image&quot; id=&quot;lp-pom-image-687&quot;&gt;
&lt;div class=&quot;lp-pom-image-container&quot;&gt;&lt;img src=&quot;https://d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/transparent.gif&quot; alt=&quot;&quot; data-src-desktop-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; data-src-mobile-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-image&quot; id=&quot;lp-pom-image-692&quot;&gt;
&lt;div class=&quot;lp-pom-image-container&quot;&gt;&lt;img src=&quot;https://d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/transparent.gif&quot; alt=&quot;&quot; data-src-desktop-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; data-src-mobile-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-box&quot; id=&quot;lp-pom-box-694&quot; readability=&quot;10&quot;&gt;

&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-695&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;Multiple logical databases per cluster&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-image&quot; id=&quot;lp-pom-image-696&quot;&gt;
&lt;div class=&quot;lp-pom-image-container&quot;&gt;&lt;img src=&quot;https://d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/transparent.gif&quot; alt=&quot;&quot; data-src-desktop-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; data-src-mobile-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-image&quot; id=&quot;lp-pom-image-697&quot;&gt;
&lt;div class=&quot;lp-pom-image-container&quot;&gt;&lt;img src=&quot;https://d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/transparent.gif&quot; alt=&quot;&quot; data-src-desktop-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; data-src-mobile-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-698&quot;&gt;
&lt;p&gt;&lt;span&gt;Database cluster forks&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-image&quot; id=&quot;lp-pom-image-699&quot;&gt;
&lt;div class=&quot;lp-pom-image-container&quot;&gt;&lt;img src=&quot;https://d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/transparent.gif&quot; alt=&quot;&quot; data-src-desktop-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; data-src-mobile-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-image&quot; id=&quot;lp-pom-image-700&quot;&gt;
&lt;div class=&quot;lp-pom-image-container&quot;&gt;&lt;img src=&quot;https://d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/transparent.gif&quot; alt=&quot;&quot; data-src-desktop-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; data-src-mobile-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-701&quot;&gt;
&lt;p&gt;&lt;span&gt;Connection pooling&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-702&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;One-click upgrades to new versions&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-703&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;span&gt;Seamless switching of plans and regions&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-image&quot; id=&quot;lp-pom-image-704&quot;&gt;
&lt;div class=&quot;lp-pom-image-container&quot;&gt;&lt;img src=&quot;https://d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/transparent.gif&quot; alt=&quot;&quot; data-src-desktop-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; data-src-mobile-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-text nlh&quot; id=&quot;lp-pom-text-705&quot; readability=&quot;9&quot;&gt;
&lt;p&gt;&lt;span&gt;All Regions except AMS2, NYC2, SFO1 and SGP1&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;lp-element lp-pom-image&quot; id=&quot;lp-pom-image-706&quot;&gt;
&lt;div class=&quot;lp-pom-image-container&quot;&gt;&lt;img src=&quot;https://d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/transparent.gif&quot; alt=&quot;&quot; data-src-desktop-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; data-src-mobile-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/cdd7c4de-blue-checkmark.svg&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;a class=&quot;lp-element lp-pom-button&quot; id=&quot;lp-pom-button-712&quot; name=&quot;lp-pom-button-712&quot;&gt;&lt;span class=&quot;label&quot;&gt;Coming Soon&lt;/span&gt;&lt;/a&gt;
&lt;div class=&quot;lp-element lp-pom-box&quot; id=&quot;lp-pom-box-722&quot;&gt;


&lt;div class=&quot;lp-element lp-pom-image&quot; id=&quot;lp-pom-image-728&quot;&gt;
&lt;div class=&quot;lp-pom-image-container&quot;&gt;&lt;img src=&quot;https://d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/transparent.gif&quot; alt=&quot;&quot; data-src-desktop-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/95bf2ddd-overview-screenshot-dbaas_0q50fw0q40fw000000.png&quot; data-src-desktop-2x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/95bf2ddd-overview-screenshot-dbaas_1ga0vs1g80vs000000.png&quot; data-src-desktop-3x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/95bf2ddd-overview-screenshot-dbaas_26f1bo26c1bo000000.png&quot; data-src-mobile-1x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/95bf2ddd-overview-screenshot-dbaas_08v05e08v05e000000.png&quot; data-src-mobile-2x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/95bf2ddd-overview-screenshot-dbaas_0hq0as0hq0as000000.png&quot; data-src-mobile-3x=&quot;//d9hhrg4mnvzow.cloudfront.net/try.digitalocean.com/dbaas-beta/95bf2ddd-overview-screenshot-dbaas_0ql0g60ql0g6000000.png&quot; /&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Wed, 24 Oct 2018 17:23:40 +0000</pubDate>
<dc:creator>JonoBB</dc:creator>
<og:title>Managed Databases. Simplified.</og:title>
<dc:format>text/html</dc:format>
<dc:identifier>https://try.digitalocean.com/dbaas-beta/</dc:identifier>
</item>
</channel>
</rss>