<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>&quot;Pwned Passwords&quot; V2 With Half a Billion Passwords</title>
<link>https://www.troyhunt.com/ive-just-launched-pwned-passwords-version-2/</link>
<guid isPermaLink="true" >https://www.troyhunt.com/ive-just-launched-pwned-passwords-version-2/</guid>
<description>&lt;p&gt;Last August, I launched a little feature within &lt;a href=&quot;https://haveibeenpwned.com/&quot;&gt;Have I Been Pwned&lt;/a&gt; (HIBP) I called &lt;a href=&quot;https://www.troyhunt.com/introducing-306-million-freely-downloadable-pwned-passwords/&quot;&gt;Pwned Passwords&lt;/a&gt;. This was a list of 320 million passwords from a range of different data breaches which organisations could use to better protect their own systems. How? &lt;a href=&quot;https://pages.nist.gov/800-63-3/sp800-63b.html&quot;&gt;NIST explains&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;When processing requests to establish and change memorized secrets, verifiers SHALL compare the prospective secrets against a list that contains values known to be commonly-used, expected, or compromised.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;They then go on to recommend that passwords &quot;obtained from previous breach corpuses&quot; should be disallowed and that the service should &quot;advise the subscriber that they need to select a different secret&quot;. This makes a lot of sense when you think about it: if someone is signing up to a service with a password that has previously appeared in a data breach, either it's the same person reusing their passwords (bad) or two different people who through mere coincidence, have chosen &lt;em&gt;exactly&lt;/em&gt; the same password. In reality, this means they probably both have dogs with the same name or some other personal attribute they're naming their passwords after (also bad).&lt;/p&gt;
&lt;p&gt;Now all of this was great advice from NIST, but they stopped short of providing the one thing organisations really need to make all this work: the passwords themselves. That's why I created Pwned Passwords - because there was a gap that needed filling - and let's face it, I do have access to rather a lot of them courtesy of running HIBP. So 6 months ago I launched the service and today, I'm pleased to launch version 2 with more passwords, more features and something I'm particularly excited about - more privacy. Here's what it's all about:&lt;/p&gt;
&lt;h2 id=&quot;theresnow501636842pwnedpasswords&quot;&gt;There's Now 501,636,842 Pwned Passwords&lt;/h2&gt;
&lt;p&gt;Back at the V1 launch, I explained how the original data set was comprised of sources such as &lt;a href=&quot;https://www.troyhunt.com/password-reuse-credential-stuffing-and-another-1-billion-records-in-have-i-been-pwned/&quot;&gt;the Anti Public and Exploit.in combo lists&lt;/a&gt; as well as &quot;a variety of other data sources&quot;. In V2, I've expanded that to include a bunch of data sources along with 2 major ones:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;The 711 million record &lt;a href=&quot;https://www.troyhunt.com/inside-the-massive-711-million-record-onliner-spambot-dump/&quot;&gt;Onliner Spambot dump&lt;/a&gt;. This was a &lt;em&gt;lot&lt;/em&gt; of work to parse varying data formats and if you read the comments on that blog post, you'll get a sense of how much people wanted this (and why it was problematic).&lt;/li&gt;
&lt;li&gt;The 1.4B &lt;a href=&quot;https://www.troyhunt.com/making-light-of-the-dark-web-and-debunking-the-fud/&quot;&gt;clear text credentials from the &quot;dark web&quot;&lt;/a&gt;. This data resulted in many totally overblown news stories (and contributed to my &quot;dark web&quot; FUD blog post last week), but it did serve as a useful reference for V2. This data also had a bunch of integrity problems which meant the actual number was somewhat less. For example, the exact same username and password pairs appearing with different delimiters:&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://www.troyhunt.com/content/images/2017/12/1.4B-Data-Integrity.png&quot; alt=&quot;1.4B-Data-Integrity&quot;/&gt;&lt;/p&gt;
&lt;p&gt;There's also &lt;em&gt;a heap&lt;/em&gt; of other separate sources there where passwords were available in plain text. As with V1, I'm not going to name them here, suffice to say it's a broad collection from many more breaches than I used in the original version. It's taken a heap of effort to parse through these but it's helped build that list up to beyond the half billion mark which is a &lt;em&gt;significant&lt;/em&gt; amount of data. From a defensive standpoint, this is good - more data means more ability to block risky passwords.&lt;/p&gt;
&lt;p&gt;But I haven't just &lt;em&gt;added&lt;/em&gt; data, I've also removed some. Let me explain why and to begin with, let's do a quick recap on the rationale for hashing them.&lt;/p&gt;
&lt;h2 id=&quot;theyrestillsha1hashedbutwithsomejunkremoved&quot;&gt;They're Still SHA-1 Hashed, But with Some Junk Removed&lt;/h2&gt;
&lt;p&gt;When I launched V1, I explained why I SHA-1 hashed them:&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;It doesn't matter that SHA1 is a fast algorithm unsuitable for storing your customers' passwords with because that's not what we're doing here, it's simply about ensuring the source passwords are not immediately visible.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That's still 100% true as of today. There are certainly those that don't agree with this approach; they claim that either the data is easily discoverable enough online anyway or conversely, that SHA-1 is an insufficiently robust algorithm for password storage. They're right, too - on both points - but that's not what this is about. The entire point is to ensure that any personal info in the source data is obfuscated such that it requires a concerted effort to remove the protection, but that the data is still usable for its intended purposes. SHA-1 has done that in V1 and I'm still confident enough in the model to use the same approach in V2.&lt;/p&gt;
&lt;p&gt;One of the things that did surprise me a little in V1 was the effort some folks went to in order to crack the passwords. I was surprised primarily because the vast majority of those passwords were already available in the clear via the 2 combo lists I mentioned earlier anyway, so why bother? Just download the (easily discoverable) lists! The penny that later dropped was that it presented a challenge - and people like challenges!&lt;/p&gt;
&lt;p&gt;One upside from people cracking the passwords for fun was that &lt;a href=&quot;https://twitter.com/cynoprime&quot;&gt;CynoSure Prime&lt;/a&gt; managed to identify a bunch of junk. Due to the integrity of the source data being a bit patchy in places, there were entries such as the following.&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;$HEX[e3eeeb]&lt;/li&gt;
&lt;li&gt;6dcc978317511fd8&lt;/li&gt;
&lt;li&gt;&amp;lt;div align=\\\'center\\\' style=\\\'font:bold 11px Verdana; width:310px\\\'&amp;gt;&amp;lt;a style=\\\'background-color:#eeeeee;display:block;width:310px;border:solid 2px black; padding:5px\\\' href=\\\'http://...&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Of course, it's &lt;em&gt;possible&lt;/em&gt; people actually used these strings as passwords but applying a bit of &lt;a href=&quot;https://en.wikipedia.org/wiki/Occam%27s_razor&quot;&gt;Occam's Razor&lt;/a&gt; suggests that it's simply parsing issues upstream of this data set. In total, CynoSure Prime identified 3,472,226 junk records which I've removed in V2. (Incidentally, these are the same guys that &lt;a href=&quot;https://cynosureprime.blogspot.com.au/2015/09/how-we-cracked-millions-of-ashley.html&quot;&gt;found the shortcomings in Ashley Madison's password storage approach&lt;/a&gt; back in 2015 - they do quality work!)&lt;/p&gt;
&lt;p&gt;Frankly though, there's little point in removing a few million junk strings. It reduced the overall data size of V2 by 0.69% and other than the tiny fraction of extra bytes added to the set, it makes no practical difference to how the data is used. On that point and in terms of extraneous records, I want to be really clear about the following:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This list is not perfect - it's not &lt;em&gt;meant&lt;/em&gt; to be perfect - and there will be some junk due to input data quality and some missing passwords because they weren't in the source data sets. It's simply meant to be a list of strings that pose an elevated risk if used for passwords and for that purpose, it's enormously effective.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Whilst the total number of records included in V2 is significant, it also doesn't tell the whole story and indeed the feedback from V1 was that the 320M passwords needed something more: an indicator of just how bad each one really was.&lt;/p&gt;
&lt;h2 id=&quot;eachpasswordnowhasacountnexttoit&quot;&gt;Each Password Now Has a Count Next to It&lt;/h2&gt;
&lt;p&gt;Is the password &quot;abc123&quot; worse than &quot;acl567&quot;? Most password strength meters would consider them equivalent because mathematically, they are. But as I've said before, &lt;a href=&quot;https://www.troyhunt.com/password-strength-indicators-help-people-make-dumb-choices/&quot;&gt;password strength indicators help people make ill-informed choices&lt;/a&gt; and this is a perfect example of that. They're both terrible passwords - don't get me wrong - but a predictable keyboard pattern makes the former much worse and that's now reflected in the Pwned Passwords data.&lt;/p&gt;
&lt;p&gt;Now on the one hand, you could argue that once a password has appeared breached even just once, it's unfit for future use. It'll go into password dictionaries, be tested against the username it was next to and forever more be a weak choice regardless of where it appears in the future. However, I got a lot of feedback from V1 along the lines of &quot;simply blocking 320M passwords is a usability nightmare&quot;. Blocking half a billion, even more so.&lt;/p&gt;
&lt;p&gt;In V2, every single password has a count next to it. What this means is that next to &quot;abc123&quot; you'll see 2,670,319 - that's how many times it appeared in my data sources. Obviously with a number that high, it appeared many times over in the same sources because many people chose the same password. The password &quot;acl567&quot;, on the other hand, only appeared once. Having visibility to the prevalence means, for example, you might outright block every password that's appeared 100 times or more and force the user to choose another one (there are 1,858,690 of those in the data set), strongly recommend they choose a different password where it's appeared between 20 and 99 times (there's a further 9,985,150 of those), and merely flag the record if it's in the source data less than 20 times. Of course, the password &quot;acl567&quot; may well be deemed too weak by the requirements of the site even without Pwned Passwords so this is by no means the only test a site should apply.&lt;/p&gt;
&lt;p&gt;In total, there were 3,033,858,815 occurrences of those 501,636,842 unique passwords. In other words, on average, each password appeared 6 times across various data breaches. In some cases, the same password appeared many times in the one incident - &lt;em&gt;often thousands of times&lt;/em&gt; - because that's how many people chose the same damn password!&lt;/p&gt;
&lt;p&gt;Now, having said all that, in the lead-up to the launch of V2 I've had people argue vehemently that they all should be blocked or that none of them should be blocked or any combination in between. That's not up to me, that's up to whoever uses this data, my job is simply to give people enough information to be able to make informed decisions. My own subjective view on this is that &quot;it depends&quot;; different risk levels, different audiences and different mitigating controls should all factor into this decision.&lt;/p&gt;
&lt;h2 id=&quot;ihaventincludedpasswordlength&quot;&gt;I &lt;em&gt;Haven't&lt;/em&gt; Included Password Length&lt;/h2&gt;
&lt;p&gt;One request that came up a few times was to include a length attribute on each password hash. This way, those using the data could exclude passwords from the original data set that fall beneath their minimum password length requirements. The thinking there being that it would reduce the data size they're searching through thus realising some performance (and possibly financial) gains. But there are many reasons why this ultimately didn't make sense:&lt;/p&gt;
&lt;p&gt;The first is that from the perspective of protecting the source data (remember, it contains PII in places), explicitly specifying the length greatly reduces the effort required to crack the passwords. Yes, I know I said earlier that the hashing approach wasn't meant to be highly resilient, but providing a length would be significantly detrimental to the protection that SHA-1 &lt;em&gt;does&lt;/em&gt; provide.&lt;/p&gt;
&lt;p&gt;Then, I actually got a bit scientific about it and looked at what minimum length password websites required. In fact, that's why I wrote the piece on &lt;a href=&quot;https://www.troyhunt.com/how-long-is-long-enough-minimum-password-lengths-by-the-worlds-top-sites/&quot;&gt;minimum length by the world's top sites&lt;/a&gt; a couple of weeks back; I wanted to put hard numbers on it. 11 of the 15 sites I referred to had a minimum length of 6 chars or less. When I then went and looked at the data set I was using, excluding passwords of less than 6 chars would have only reduced the set by less than 1% Excluding anything under 8 chars would have reduced it by just under 16%. They're very small numbers.&lt;/p&gt;
&lt;p&gt;Then there's the overhead required to host and search this data, that is the overhead those organisations who use it will incur. It should be &lt;em&gt;very&lt;/em&gt; close to nothing with the whole half billion data set. Chuck it in a storage construct like Azure Table Storage and you're looking at single digit dollars per month with single digit millisecond lookup times. There's no need for this to be any more complex than that.&lt;/p&gt;
&lt;p&gt;So in short, it put the protection of the hashing at greater risk, there was very little value gained and it's easy to implement this in a way that's fast and cheap anyway. Some people will disagree, but a lot of thought went into this and I'm confident that the conclusion was the right one.&lt;/p&gt;
&lt;h2 id=&quot;downloadingthedata&quot;&gt;Downloading the Data&lt;/h2&gt;
&lt;p&gt;And now to the pointy bit - downloading the data. As with V1, there's one big 7z archive you can &lt;a href=&quot;https://haveibeenpwned.com/Passwords&quot;&gt;go and pull down immediately from the Pwned Passwords page on HIBP&lt;/a&gt;. Also as before, it's available via direct download from the site or via torrent. I want to &lt;em&gt;strongly&lt;/em&gt; encourage you to take it via the torrent, let me explain why:&lt;/p&gt;
&lt;p&gt;The underlying storage construct for this data is Azure Blob storage. If I was to serve the file directly from there, I'd cop a &lt;em&gt;very&lt;/em&gt; hefty data bill. Cloudflare came to rescue in V1 and gave me a free plan that enabled a file of that size to be cached as their edge nodes. The impact of that on my bill was &lt;em&gt;massive:&lt;/em&gt;&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot; readability=&quot;4.755980861244&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Another massive thanks to &lt;a href=&quot;https://twitter.com/Cloudflare?ref_src=twsrc%5Etfw&quot;&gt;@Cloudflare&lt;/a&gt; for supporting the &lt;a href=&quot;https://twitter.com/haveibeenpwned?ref_src=twsrc%5Etfw&quot;&gt;@haveibeenpwned&lt;/a&gt; Pwned Passwords, just did the maths on how much it saved me - whoa! &lt;a href=&quot;https://t.co/70kki5Uw7o&quot;&gt;pic.twitter.com/70kki5Uw7o&lt;/a&gt;&lt;/p&gt;
— Troy Hunt (@troyhunt) &lt;a href=&quot;https://twitter.com/troyhunt/status/897571703202603008?ref_src=twsrc%5Etfw&quot;&gt;August 15, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;p&gt;Imagine the discussion I'd be having with my wife if it wasn't for Cloudflare's support! And that was before another 6 months' worth of downloads too. Cloudflare might have given me the service for free, but they still have to pay for bandwidth so I'd like to ask for your support in pulling the data down via torrents rather than from the direct download link. To that effect, the UI actively encourages you to grab the torrent:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.troyhunt.com/content/images/2018/02/Download-Pwned-Passwords.png&quot; alt=&quot;Download Pwned Passwords&quot;/&gt;&lt;/p&gt;
&lt;p&gt;If you can't grab the torrent (and I'm conscious there are, for example, corporate environments where torrents are blocked), then download it direct but do your bit to help me out by supporting the folks supporting me where you can. As with V1, the torrent file is served directly from HIBP's Blob Storage and you'll find a SHA-1 hash of the Pwned Passwords file next to it so you can check integrity if you're so inclined.&lt;/p&gt;
&lt;p&gt;So that's the download - go forth and do good things with it! Now for something else cool and that's the online search.&lt;/p&gt;
&lt;h2 id=&quot;queryingthedataonline&quot;&gt;Querying the Data Online&lt;/h2&gt;
&lt;p&gt;In V1, I stood up &lt;a href=&quot;https://haveibeenpwned.com/Passwords&quot;&gt;an online search feature&lt;/a&gt; where you could plug in a password and see if it appeared in the data set. That sat on top of an API which I also made available for independent consumption should people wish to use it. And many people did use it. In fact, some of the entrants to &lt;a href=&quot;https://www.troyhunt.com/introducing-306-million-freely-downloadable-pwned-passwords/&quot;&gt;my competition to win a Lenovo laptop&lt;/a&gt; leveraged that particular endpoint including the winner of the competition, 16,year-old Félix Giffard. He created &lt;a href=&quot;https://passwordsecurity.info/&quot;&gt;PasswordSecurity.info&lt;/a&gt; which directly consumes the Pwned Passwords API via the client side:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.troyhunt.com/content/images/2018/02/PasswordSecurity.info.png&quot; alt=&quot;PasswordSecurity.info&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Getting back to the online search, being conscious of not wanting to send the wrong message to people, immediately before the search box I put a very clear, very &lt;strong&gt;bold&lt;/strong&gt; message: &quot;Do not send any password you actively use to a third-party service - even this one!&quot;&lt;/p&gt;
&lt;p&gt;But people don't always read these things. The service got &lt;em&gt;a heap&lt;/em&gt; of press and millions of people descended on the site to check their passwords. At least I &lt;em&gt;assume&lt;/em&gt; it was their passwords, I certainly don't log those searches but based on the news articles and social media commentary, yeah, it would have been a heap of real passwords. And I'm actually ok with that - let me explain:&lt;/p&gt;
&lt;p&gt;As much as I don't want to encourage people to plug their real password(s) into random third-party sites, I can &lt;em&gt;guarantee&lt;/em&gt; that a sizable number of people got a positive hit and then changed their security hygiene as a result. One of the biggest things that's resonated with me in running HIBP is how much impact it's had on changing user behaviour. Seeing either your email address or your password pwned has a way of making people reconsider some of their security decisions.&lt;/p&gt;
&lt;p&gt;The online search works &lt;em&gt;almost&lt;/em&gt; identically to V1 albeit with the count of the password now represented too:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.troyhunt.com/content/images/2018/02/Searching-for-a-Pwned-Password.jpg&quot; alt=&quot;Pwned Search&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Pretty simple stuff and for the most part, also pretty familiar. But there's one &lt;em&gt;really&lt;/em&gt; important - and &lt;em&gt;really&lt;/em&gt; cool - difference. Let me explain:&lt;/p&gt;
&lt;h2 id=&quot;cloudflareprivacyandkanonymity&quot;&gt;Cloudflare, Privacy and k-Anonymity&lt;/h2&gt;
&lt;p&gt;In what proved to be very fortuitous timing, &lt;a href=&quot;https://twitter.com/icyapril&quot;&gt;Junade Ali&lt;/a&gt; from Cloudflare reached out to me last month with an idea. They wanted to build a tool to search through Pwned Passwords V1 but to do so in a way that allowed external parties to use it &lt;em&gt;and&lt;/em&gt; maintain anonymity. You see, the problem with my existing implementation was that whilst you could pass just a SHA-1 hash of the password, if it returned a hit and I was to take that and reverse it back to the clear (which I could easily do because I created the hashes in the first place!) I'd know the password. That made the service hard to justify sending &lt;em&gt;real&lt;/em&gt; passwords to.&lt;/p&gt;
&lt;p&gt;Junade's idea was different though; he proposed using a mathematical property called &lt;a href=&quot;https://en.wikipedia.org/wiki/K-anonymity&quot;&gt;&lt;em&gt;k&lt;/em&gt;-anonymity&lt;/a&gt; and within the scope of Pwned Passwords, it works like this: imagine if you wanted to check whether the password &quot;P@ssw0rd&quot; exists in the data set. (Incidentally, the hackers have worked out people do stuff like this. I know, it sucks. They're onto us.) The SHA-1 hash of that string is &quot;21BD12DC183F740EE76F27B78EB39C8AD972A757&quot; so what we're going to do is take &lt;em&gt;just the first 5 characters&lt;/em&gt;, in this case that means &quot;21BD1&quot;. That gets sent to the Pwned Passwords API and it responds with 475 hash &lt;em&gt;suffixes&lt;/em&gt; (that is everything after &quot;21BD1&quot;) and a count of how many times the original password has been seen. For example:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;(21BD1) &lt;strong&gt;0018A45C4D1DEF81644B54AB7F969B88D65:1&lt;/strong&gt; (password &quot;lauragpe&quot;)&lt;/li&gt;
&lt;li&gt;(21BD1) &lt;strong&gt;00D4F6E8FA6EECAD2A3AA415EEC418D38EC:2&lt;/strong&gt; (password &quot;alexguo029&quot;)&lt;/li&gt;
&lt;li&gt;(21BD1) &lt;strong&gt;011053FD0102E94D6AE2F8B83D76FAF94F6:1&lt;/strong&gt; (password &quot;BDnd9102&quot;)&lt;/li&gt;
&lt;li&gt;(21BD1) &lt;strong&gt;012A7CA357541F0AC487871FEEC1891C49C:2&lt;/strong&gt; (password &quot;melobie&quot;)&lt;/li&gt;
&lt;li&gt;(21BD1) &lt;strong&gt;0136E006E24E7D152139815FB0FC6A50B15:2&lt;/strong&gt; (password &quot;quvekyny&quot;)&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;I added the prefix in brackets beforehand and the source passwords in brackets afterwards simply to illustrate what we're doing here; they're all just different strings that hash down to values with the same first 5 characters. In other words, they're all within the same &quot;range&quot; and you'll see that term referenced more later on. Using this model, someone searching the data set just gets back the hash suffixes and counts (everything in bold after the first 5 chars) and they can then see if everything after the first 5 chars of &lt;em&gt;their&lt;/em&gt; hash matches any of the returned strings. Now keep in mind that as far as I'm concerned, the partial hash I was sent could be any one of 475 different possible values. Or it could be something totally different, I simply don't know and therein lies the anonymity value.&lt;/p&gt;
&lt;p&gt;For the sake of perspective, here are some stats on what this means for the data within Pwned Passwords:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Every hash prefix from 00000 to FFFFF is populated with data (16^5 combinations)&lt;/li&gt;
&lt;li&gt;The average number of hashes returned is 478&lt;/li&gt;
&lt;li&gt;The smallest is 381 (hash prefixes &quot;E0812&quot; and &quot;E613D&quot;)&lt;/li&gt;
&lt;li&gt;The largest is 584 (hash prefixes &quot;00000&quot; and &quot;4A4E8&quot;)&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Junade has written a great piece that's just gone live on Cloudflare's blog titled &lt;a href=&quot;https://blog.cloudflare.com/validating-leaked-passwords-with-k-anonymity/&quot;&gt;Validating Leaked Passwords with k-Anonymity&lt;/a&gt; and he goes into more depth in that piece. As he explains, there are other cryptographic approaches which could also address the desire for anonymity (for example, private set intersections), but not with the ease and level of simplicity Junade proposed. I loved it so much that I offered to build and run it as a service out of HIBP. Junade (and Cloudflare) thought that was a great idea so they offered to point folks over to the HIBP version rather than build out something totally separate. That's a partnership I'm &lt;em&gt;enormously&lt;/em&gt; happy with I appreciate their confidence in my running it.&lt;/p&gt;
&lt;p&gt;This model of anonymity is what now sits behind the online search feature. You can see it in action by trying a search for &quot;P@ssw0rd&quot; which will return the screen in the previous image. If we drop down and take a look at the dev tools, here's the actual request that's been made:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.troyhunt.com/content/images/2018/02/Searching-for-a-range.png&quot; alt=&quot;Searching for a range&quot;/&gt;&lt;/p&gt;
&lt;p&gt;The password has been hashed client side and just the first 5 characters passed to the API (I'll talk more about the mechanics of that shortly). Here's what then comes back in the response:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.troyhunt.com/content/images/2018/02/Hit-found-in-password-range.png&quot; alt=&quot;Hit found in password range&quot;/&gt;&lt;/p&gt;
&lt;p&gt;As mentioned earlier, there are 475 hashes beginning with &quot;21BD1&quot;, but only 1 which matches the remainder of the hash for &quot;P@ssw0rd&quot; and that record indicates that the password has previously been seen 47,205 times. And that's it - that's what I've done with Cloudflare's support and that's what we've done together to protect anonymity and make the service available to everyone. Let me now talk about how you can use the API.&lt;/p&gt;
&lt;h2 id=&quot;consumingtheapiandthemechanicsbehindtherangesearch&quot;&gt;Consuming the API (and the Mechanics Behind the Range Search)&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://haveibeenpwned.com/API/v2#PwnedPasswords&quot;&gt;The existing API documentation on HIBP&lt;/a&gt; has been updated so you can go there for all the implementation details. There are a few things in particular I want to call out though:&lt;/p&gt;
&lt;p&gt;Firstly, you'll notice that I'm serving this API from a different domain to the other HIBP APIs and indeed from V1 of the Pwned Passwords service. For V2, I've stood up an Azure Function on the api.pwnedpasswords.com domain which gets the API out of the HIBP website and running on serverless infrastructure instead. &lt;a href=&quot;https://www.troyhunt.com/azure-functions-in-practice/&quot;&gt;I've written about Azure Functions in the past&lt;/a&gt; and they're an awesome way of building a highly scalable, resilient &quot;code as a service&quot; architecture. It ensures that load comes off the HIBP website and that I can scale the Pwned Passwords service infinitely, albeit with a line directly to my wallet! It's also given me the flexibility to do things like trim off a bunch of excessive headers such as the content security policy HIBP uses (that's of no use to a lone API endpoint).&lt;/p&gt;
&lt;p&gt;Secondly, the existing API (that many people have created dependencies on!) still works just fine. It also points to the storage repository for V2 of the password set so it's now searching through the full half billion records. I'll leave this running for the foreseeable future, but if you are using it then I'd &lt;em&gt;prefer&lt;/em&gt; you roll over to the endpoint on api.pwnedpasswords.com for the reasons mentioned above, and for these other reasons:&lt;/p&gt;
&lt;p&gt;If you were using the original API via HTTP GET, rolling over to the new one changes &lt;em&gt;absolutely nothing&lt;/em&gt; in your implementation other than the URL which will look like this:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;GET https://api.pwnedpasswords.com/pwnedpassword/{password}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;It'll still return HTTP 200 when a password is found and 404 when it's not. The only difference (and this shouldn't break any existing usages), is that the 200 response now also contains a count in the body by way of a single integer:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.troyhunt.com/content/images/2018/02/Password-Search.png&quot; alt=&quot;Password Search&quot;/&gt;&lt;/p&gt;
&lt;p&gt;And as before, you can always pass a hash if preferred:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.troyhunt.com/content/images/2018/02/Password-Search-by-Hash.png&quot; alt=&quot;Password Search by Hash&quot;/&gt;&lt;/p&gt;
&lt;p&gt;But, of course, we've just had the anonymity chat and you would have seen the path for calling that endpoint earlier on. Just to point it out again here, you can pass the first 5 chars of the hash to this address:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;https://api.pwnedpasswords.com/range/{hashPrefix}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Which returns a result like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.troyhunt.com/content/images/2018/02/Range-Search-Results.png&quot; alt=&quot;Range Search Results&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Remember, these are all hash &lt;em&gt;suffixes&lt;/em&gt; (followed by a count) so the full value of the first hash, for example, is &quot;21BD10018A45C4D1DEF81644B54AB7F969B88D65&quot;. Incidentally, input to the API is not case sensitive so &quot;21bd1&quot; works just as well as &quot;21BD1&quot;. All hash suffixes returned (and indeed those provided in the downloadable data) are uppercase simply because that's the default output from &lt;a href=&quot;https://docs.microsoft.com/en-us/sql/t-sql/functions/hashbytes-transact-sql&quot;&gt;SQL Server's HASHBYTES function&lt;/a&gt; (I processed the source data in a local RDBMS instance).&lt;/p&gt;
&lt;p&gt;Unlike the original version, there's no rate-limiting. That was a construct I needed primarily to protect personal data in the breached account search (i.e. when you search for your email address amongst data breaches), but I extended it to Pwned Passwords as well to help protect the infrastructure. Now running on serverless Azure Functions, I don't have that concern so I've dropped it altogether. I'd also dropped version numbers, I'll deal with that when I need them which may not be for a long time (if ever).&lt;/p&gt;
&lt;p&gt;Now, a few more things around some design decisions I've made: I'm &lt;em&gt;very&lt;/em&gt; wary of the potential impact on my wallet of running the service this way. It's one thing to stand up V1 that only returned an HTTP response code, was rate-limited and really wasn't designed to be called in bulk by a single consumer (considering the privacy implications), it's quite another to do what I've done with V2, especially when each search of the range API returns hundreds of records. That &quot;P@ssw0rd&quot; search, for example, returns 9,730 bytes when gzipped (that's a pretty average size) and I'm paying for egress bandwidth out of Azure, the execution of the function and the call to the underlying storage. Tiny amounts each time, mind you, but I've had to reduce that impact on me as far as possible through a range of measures.&lt;/p&gt;
&lt;p&gt;For example, the result of that range query is not a neatly formatted piece of JSON, it's just colon delimited rows. That impacts my ability to add attributes at a later date and pretty much locks in the current version to today's behaviour, but it saves on the response size. Yes, I know some curly braces and quotes wouldn't add a lot of size, but every byte counts when volumes get large.&lt;/p&gt;
&lt;p&gt;You'll also notice there's a long max-age on the cache-control header:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.troyhunt.com/content/images/2018/02/Cache-Settings.png&quot; alt=&quot;Cache Settings&quot;/&gt;&lt;/p&gt;
&lt;p&gt;This is 31 days' worth of cache and the subsequent Cloudflare cache status header explains why: by routing through their infrastructure, they can aggressively cache these results which ensures not only is the response &lt;em&gt;lightning&lt;/em&gt; fast (remember, they presently have &lt;a href=&quot;https://www.cloudflare.com/&quot;&gt;121 edge nodes around the world&lt;/a&gt; so there's one near you), but that I don't wear the financial hit of people hammering my origin. Especially when you consider the extent to which multiple people use the same password, when we're talking about the range search where many different passwords have identical hash prefixes, there's some significant benefits to be had from caching. As mentioned earlier, there are 16^5 different hash prefixes (1,048,576) within the range of 00000 to FFFFF so you can see how extensive usage would benefit greatly from caching across many millions of searches. The performance difference alone when comparing a cached result with a non-cached one makes a compelling argument:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.troyhunt.com/content/images/2018/02/Cached-versus-non-cached-V2-queries.png&quot; alt=&quot;Cached versus non-cached V2 queries&quot;/&gt;&lt;/p&gt;
&lt;p&gt;This means that even though the response is significantly larger than in V1, if I can serve a request to the new API from cache there's actually a &lt;em&gt;massive&lt;/em&gt; improvement. Here's a series of hits to V1 where every single time, the request had to go all the way to the origin server, hit the API and then query 320M records:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.troyhunt.com/content/images/2018/02/Query-times-of-V1-API.png&quot; alt=&quot;Query times of V1 API&quot;/&gt;&lt;/p&gt;
&lt;p&gt;In order to make aggressive caching feasible, I'm also &lt;em&gt;only&lt;/em&gt; supporting HTTP GET. Now, some people will lose their minds over this because they'll say &quot;that means it goes into logs and you'll track the passwords being searched for&quot;. If you're worried about me tracking anything, don't use the service. That's not intended to be a flippant statement, rather a simple acknowledgment that you need to trust the operator of the service if you're going to be sending passwords in any shape or form. Offsetting that is the whole k-Anonymity situation; even if you &lt;em&gt;don't&lt;/em&gt; trust the service or you think logs may be leaked and abused (and incidentally, &lt;em&gt;nothing&lt;/em&gt; is explicitly logged, they're transient system logs at most), the range search goes a very long way to protecting the source. If you &lt;em&gt;still&lt;/em&gt; don't trust it, then just download the hashes and host them yourself. No really, that's the whole point of making them available and in all honesty, if it was me building on top of these hashes then I'd definitely be querying my own repository of them.&lt;/p&gt;
&lt;p&gt;In summary, if you're using the range search then you get protection of the source password &lt;em&gt;well&lt;/em&gt; in excess of what I was able to do in V1 plus it's &lt;em&gt;massively&lt;/em&gt; faster if anyone else has done a search for any password that hashes down to the same first 5 characters of SHA-1. Plus, it helps me out an awful lot in terms of keeping the costs down!&lt;/p&gt;
&lt;h2 id=&quot;pwnedpasswordsinaction&quot;&gt;Pwned Passwords in Action&lt;/h2&gt;
&lt;p&gt;Lastly, I want to call out a number of examples of the first generation of Pwned Passwords in action. My hope is that they inspire others to build on top of this data set and ultimately, make a positive difference to web security for everyone.&lt;/p&gt;
&lt;p&gt;For example, Workbooks.com (they make CRM software, among other things) &lt;a href=&quot;https://www.workbooks.com/node/1798&quot;&gt;explains to customers that a Pwned Password is weak or has previously appeared in a data breach&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Then there's Colloq (they help you discover conferences) who've &lt;a href=&quot;https://colloq.io/blog/how-our-password-check-works&quot;&gt;written up a great piece with loads of performance stats&lt;/a&gt; about their implementation of the data.&lt;/p&gt;
&lt;p&gt;Or &lt;a href=&quot;https://toepoke.co.uk/user.aspx/create&quot;&gt;try creating an account on Toepoke&lt;/a&gt; with a password of &quot;P@ssw0rd&quot; and see how that goes for you:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.troyhunt.com/content/images/2018/02/toepoke.co.uk-password-check.png&quot; alt=&quot;toepoke.co.uk password check&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://safepass.me/&quot;&gt;safepass.me&lt;/a&gt; also picked up the data and wrapped it into an offline commercial Active Directory filter (plus a free home version).&lt;/p&gt;
&lt;p&gt;On the mobile front, there's &lt;a href=&quot;https://play.google.com/store/apps/details?id=pwnedpasswords.pwnedpasswords&quot;&gt;Pwned Pass in the Google Play store&lt;/a&gt; which sits on top of the existing API.&lt;/p&gt;
&lt;h2 id=&quot;thisisallstillfreeandistilllikebeer&quot;&gt;This is All Still Free (and I Still Like Beer!)&lt;/h2&gt;
&lt;p&gt;Nothing gains traction like free things! Keeping HIBP free to search your address (or your entire domain) was the best thing I ever did in terms of making it stick. A few months after I launched the service, I stood up &lt;a href=&quot;https://haveibeenpwned.com/Donate&quot;&gt;a donations page&lt;/a&gt; where you could buy me some beers (or coffee or other things). It only went up after people specifically asked for it (&quot;hey awesome service, can I get you a coffee?&quot;) and I've been really happy with the responses to it. As I say on the page, it's more the &lt;em&gt;time&lt;/em&gt; commitment that really costs me (I'm independent so while I'm building something like Pwned Passwords, I'm not doing something else), but there are also costs that may surprise you:&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot; readability=&quot;7.5090252707581&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Just burned through $100 of mobile data so that I could finish processing Pwned Passwords this weekend. 110kbps on unlimited broadband plan or 8,286kbps on 4G at $10/GB. It was going to be hard to get it live next week otherwise 🙁&lt;/p&gt;
— Troy Hunt (@troyhunt) &lt;a href=&quot;https://twitter.com/troyhunt/status/964785654847627265?ref_src=twsrc%5Etfw&quot;&gt;February 17, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;p&gt;This is one of those true &quot;Australianisms&quot; courtesy of the fact my &lt;em&gt;up-speed&lt;/em&gt; maxes out at about 1.5Mbps (and is then shared across all the things in my house that send data out). Down-speed is about 114 but getting anything up is a nightmare. (And for Aussie friends, no, there's no NBN available in my area of the Gold Coast yet, but apparently it's not far off.) And no, this is not a solvable problem by doing everything in the cloud and there are many reasons why that wouldn't have worked (I'll blog them at a later date).&lt;/p&gt;
&lt;p&gt;If you want to help kick in for these costs and &lt;a href=&quot;https://haveibeenpwned.com/Donate&quot;&gt;shout me a sympathy coffee or beer(s)&lt;/a&gt;, it's still very much appreciated!&lt;/p&gt;
&lt;h2 id=&quot;closing&quot;&gt;Closing&lt;/h2&gt;
&lt;p&gt;Pwned Passwords V2 is now live! Everything you need to use them is over on &lt;a href=&quot;https://haveibeenpwned.com/Passwords&quot;&gt;the Pwned Passwords page of HIBP&lt;/a&gt; where you can check them online, learn about the API or just download the whole lot. All those models are free, unrestricted and don't even require attribution if you don't want to provide it, just take what's there and go do good things with it 😀&lt;/p&gt;
</description>
<pubDate>Wed, 21 Feb 2018 19:46:52 +0000</pubDate>
<dc:creator>explodingcamera</dc:creator>
<og:type>article</og:type>
<og:title>I've Just Launched &quot;Pwned Passwords&quot; V2 With Half a Billion Passwords for Download</og:title>
<og:description>Last August, I launched a little feature within Have I Been Pwned (HIBP) I called Pwned Passwords. This was a list of 320 million passwords from a range of different data breaches which organisations could use to better protect their own systems. How? NIST explains: When processing requests to establish</og:description>
<og:url>https://www.troyhunt.com/ive-just-launched-pwned-passwords-version-2/</og:url>
<og:image>https://www.troyhunt.com/content/images/2018/02/Searching-for-a-Pwned-Password.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.troyhunt.com/ive-just-launched-pwned-passwords-version-2/</dc:identifier>
</item>
<item>
<title>Signal Foundation</title>
<link>https://signal.org/blog/signal-foundation/</link>
<guid isPermaLink="true" >https://signal.org/blog/signal-foundation/</guid>
<description>&lt;p&gt;Long before we knew that it would be called Signal, we knew what we wanted it to be. Instead of teaching the rest of the world cryptography, we wanted to see if we could develop cryptography that worked for the rest of the world. At the time, the industry consensus was largely that encryption and cryptography would remain unusable, but we started Signal with the idea that private communication could be simple.&lt;/p&gt;
&lt;p&gt;Since then, we’ve made some progress. We’ve built a service used by millions, and software used by billions. The stories that make it back to us and keep us going are the stories of people discovering each other in moments where they found they could speak freely over Signal, of people falling in love over Signal, of people organizing ambitious plans over Signal. When we ask friends who at their workplace is on Signal and they respond “every C-level executive, and the kitchen staff.” When we receive a subpoena for user data and have nothing to send back but a blank sheet of paper. When we catch that glimpse of “Signal blue” on a metro commuter’s phone and smile.&lt;/p&gt;
&lt;p&gt;However, we’ve always wanted to do much more, and our limitations have often been challenging. Over the lifetime of the project, there have only been an average of 2.3 full-time software developers, and the entire Signal team has never been more than 7 people. With three client platforms to develop, a service to build and run, a growing list of integrations to assist with, and millions of users to support, that has often left us wanting.&lt;/p&gt;
&lt;p&gt;Even so, Signal has never taken VC funding or sought investment, because we felt that putting profit first would be incompatible with building a sustainable project that put users first. As a consequence, Signal has sometimes suffered from our lack of resources or capacity in the short term, but we’ve always felt those values would lead to the best possible experience in the long term.&lt;/p&gt;
&lt;p&gt;We’re glad those are the choices we’ve made. Today, we are launching the &lt;a href=&quot;https://signalfoundation.org&quot;&gt;Signal Foundation&lt;/a&gt;, an emerging 501(c)(3) nonprofit created and made possible by Brian Acton, the co-founder of WhatsApp, to support, accelerate, and broaden Signal’s mission of making private communication accessible and ubiquitous. In case you missed it, Brian left WhatsApp and Facebook last year, and has been thinking about how to best focus his future time and energy on building nonprofit technology for public good.&lt;/p&gt;
&lt;p&gt;Starting with an initial $50,000,000 in funding, we can now increase the size of our team, our capacity, and our ambitions. This means reduced uncertainty on the path to sustainability, and the strengthening of our long-term goals and values. Perhaps most significantly, the addition of Brian brings an incredibly talented engineer and visionary with decades of experience building successful products to our team.&lt;/p&gt;
&lt;p&gt;The Signal Foundation completes our vision of Signal operating as part of a full 501(c)(3). Up until now, we’ve never been able to take on the 501(c)(3) management overhead ourselves, and we’ve relied on the generosity of the Freedom Of The Press Foundation as our fiscal sponsor. Without their support, Signal would not be where it is today, and they have graciously agreed to continue accepting donations on our behalf while our status is pending.&lt;/p&gt;
&lt;p&gt;Looking back at the progress we’ve made with such a small group, it’s exciting to imagine what an expanded team and the new foundation will help us accomplish in the future. We still know what we want Signal to be, and my personal commitment to Signal is as strong as ever.&lt;/p&gt;
&lt;h3 id=&quot;a-message-from-brian&quot;&gt;&lt;em&gt;A message from Brian&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;Hi everyone, Brian here. I am incredibly excited to be launching the Signal Foundation with Moxie. The Signal Foundation’s mission is to develop open source privacy technology that protects free expression and enables secure global communication.&lt;/p&gt;
&lt;p&gt;As more and more of our lives happen online, data protection and privacy are critical. This isn’t just important for select people in select countries. It’s important for people from all walks of life in every part of the world. Everyone deserves to be protected. We created the Signal Foundation in response to this global need. Our plan is to pioneer a new model of technology nonprofit focused on privacy and data protection for everyone, everywhere.&lt;/p&gt;
&lt;p&gt;Moxie and I share a belief that the best way to continue to ensure the universal availability of high-security and low-cost communications services like Signal is to do so through a foundation structure that is free of the inherent limitations of a for-profit company. Ultimately, our goal is to make the Signal Foundation financially self-sustaining. We believe there is an opportunity to act in the public interest and make a meaningful contribution to society by building sustainable technology that respects users and does not rely on the commoditization of personal data. Signal has always been a collaborative project with a strong community, and we will continue to learn from our users and experiment together.&lt;/p&gt;
&lt;p&gt;Moxie and his team have built something very special in Signal Messenger and I am thrilled to join their effort to provide the most trusted communications experience on the planet. I first met Moxie in 2013 when I was at WhatsApp and we were working on a joint effort to add end-to-end encryption to the app. I was blown away by his technical ability and admired his passion and absolute commitment to data protection and personal privacy. Moxie will continue to serve as CEO of the newly created Signal Messenger nonprofit organization, and I will serve as Executive Chairman of the Signal Foundation where I will take an active, daily role in operations and product development. After over 20 years of working for some of the largest technology companies in the world, I couldn’t be more excited for this opportunity to build an organization at the intersection of technology and the nonprofit world.&lt;/p&gt;
&lt;p&gt;Of course, this is just the beginning. There is a lot of work to be done to make our dream a reality and we will continually be asking our peers, our community, and ourselves if there are more effective ways to serve the public good. In the immediate future we are focused on adding to our talented-but-small team and improving Signal Messenger. Our long-term vision is for the Signal Foundation to provide multiple offerings that align with our core mission. That will come in time. For now, I invite you to sign up for Signal Messenger and join us in the experiment.&lt;/p&gt;
&lt;p&gt;Brian Acton&lt;/p&gt;

</description>
<pubDate>Wed, 21 Feb 2018 18:42:37 +0000</pubDate>
<dc:creator>conroy</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://signal.org/blog/signal-foundation/</dc:identifier>
</item>
<item>
<title>Startup Ideas We&amp;#039;d Like to Fund (2008)</title>
<link>http://old.ycombinator.com/ideas.html</link>
<guid isPermaLink="true" >http://old.ycombinator.com/ideas.html</guid>
<description>&lt;a href=&quot;http://old.ycombinator.com/index.html&quot;&gt;&lt;img src=&quot;http://old.ycombinator.com/images/yc500.gif&quot; border=&quot;0&quot; width=&quot;500&quot; /&gt;&lt;/a&gt;&lt;p&gt;&lt;strong&gt;Startup Ideas We'd Like to Fund&lt;/strong&gt;&lt;br /&gt;Paul Graham&lt;br /&gt;July 2008&lt;/p&gt;&lt;p&gt;When we read Y Combinator applications there are always ideas we're hoping to see. In the past we've never said publicly what they are. If we say we're looking for x, we'll get applications proposing x, certainly. But then it actually becomes harder to judge them: is this group proposing x because they were already thinking about it, or because they know that's what we want to hear?&lt;/p&gt;&lt;p&gt;We don't like to sit on these ideas, though, because we really want people to work on them. So we're trying something new: we're going to list some of the ideas we've been waiting to see, but only describe them in general terms. It may be that recipes for ideas are the most useful form anyway, because imaginative people will take them in directions we didn't anticipate.&lt;/p&gt;
&lt;p&gt;Please don't feel that if you want to apply to Y Combinator, you have to work on one of these types of ideas. If we've learned nothing else from doing YC, it's how little we know. Many of the best startups we've funded, like &lt;a href=&quot;http://loopt.com&quot;&gt;Loopt&lt;/a&gt;, proposed things we'd never considered.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. A cure for the disease of which the RIAA is a symptom.&lt;/strong&gt; Something is broken when Sony and Universal are suing children. Actually, at least two things are broken: the software that file sharers use, and the record labels' business model. The current situation can't be the final answer. And what happened with music is now happening with movies. When the dust settles in 20 years, what will this world look like? What components of it could you start building now?&lt;/p&gt;
&lt;p&gt;The answer may be far afield. The answer for the music industry, for example, is probably to give up insisting on payment for recorded music and focus on licensing and live shows. But what happens to movies? Do they morph into games?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. Simplified browsing.&lt;/strong&gt; There are a lot of cases where you'd trade some of the power of a web browser for greater simplicity. Grandparents and small children don't want the full web; they want to communicate and share pictures and look things up. What viable ideas lie undiscovered in the space between a digital photo frame and a computer running Firefox? If you built one now, who else would use it besides grandparents and small children?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. New news.&lt;/strong&gt; As &lt;a href=&quot;http://blog.pmarca.com/2008/02/inaugurating-th.html&quot;&gt;Marc Andreessen&lt;/a&gt; points out, newspapers are in trouble. The problem is not merely that they've been slow to adapt to the web. It's more serious than that: their problems are due to deep structural flaws that are exposed now that they have competitors. When the only sources of news were the wire services and a few big papers, it was enough to keep writing stories about how the president met with someone and they each said conventional things written in advance by their staffs. Readers were never that interested, but they were willing to consider this news when there were no alternatives.&lt;/p&gt;
&lt;p&gt;News will morph significantly in the more competitive environment of the web. So called &quot;blogs&quot; (because the old media call everything published online a &quot;blog&quot;) like PerezHilton and TechCrunch are one sign of the future. News sites like Reddit and Digg are another. But these are just the beginning.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. Outsourced IT.&lt;/strong&gt; In most companies the IT department is an expensive bottleneck. Getting them to make you a simple web form could take months. Enter &lt;a href=&quot;http://wufoo.com&quot;&gt;Wufoo&lt;/a&gt;. Now if the marketing department wants to put a form on the web, they can do it themselves in 5 minutes. You can take practically anything users still depend on IT departments for and base a startup on it, and you will have the enormous force of their present dissatisfaction pushing you forward.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5. Enterprise software 2.0.&lt;/strong&gt; Enterprise software companies sell bad software for huge amounts of money. They get away with it for a variety of reasons that link together to form a sort of protective wall. But the software world is changing. I suspect that if you study different parts of the enterprise software business (not just what the software does, but more importantly, how it's sold) you'll find parts that could be picked off by startups.&lt;/p&gt;
&lt;p&gt;One way to start is to make things for smaller companies, because they can't afford the overpriced stuff made for big ones. They're also easier to sell to.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6. More variants of CRM.&lt;/strong&gt; This is a form of enterprise software, but I'm mentioning it explicitly because it seems like this area has such potential. CRM (&quot;Customer Relationship Management&quot;) means all sorts of different things, but a lot of the current embodiments don't seem much more than mailing list managers. It should be possible to make interactions with customers much higher-res.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7. Something your company needs that doesn't exist.&lt;/strong&gt; Many of the best startups happened when someone needed something in their work, found it didn't exist, and &lt;a href=&quot;http://articles.latimes.com/2008/may/29/business/fiw-octopart29&quot;&gt;quit to build it&lt;/a&gt;. This is vaguer than most of the other recipes here, but it may be the most valuable. You're working on something you know customers want, because you were the customer. And if it was something you needed at work, other people will too, and they'll be willing to pay for it.&lt;/p&gt;
&lt;p&gt;So if you're working for a big company and you want to strike out on your own, here's a recipe for an idea. Start this sentence: &quot;We'd pay a lot if someone would just build a ...&quot; Whatever you say next is probably a good product idea.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8. Dating.&lt;/strong&gt; Current dating sites are not the last word. Better ones will appear. But anyone who wants to start a dating startup has to answer two questions: in addition to the usual question about how you're going to approach dating differently, you have to answer the even more important question of how to overcome the huge chicken and egg problem every dating site faces. A site like Reddit is interesting when there are only 20 users. But no one wants to use a dating site with only 20 users—which of course becomes a self-perpetuating problem. So if you want to do a dating startup, don't focus on the novel take on dating that you're going to offer. That's the easy half. Focus on novel ways to get around the chicken and egg problem.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9. Photo/video sharing services.&lt;/strong&gt; A lot of the most popular sites on the web are for photo sharing. But the sites classified as social networks are also largely about photo sharing. As much as people like to share words (IM and email and blogging are &quot;word sharing&quot; apps), they probably like to share pictures more. It's less work and the results are usually more interesting. I think there is huge growth still to come. There may ultimately be 30 different subtypes of image/video sharing service, half of which remain to be discovered.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10. Auctions.&lt;/strong&gt; Online auctions have more potential than most people currently realize. Auctions seem boring now because EBay is doing a bad job, but is still powerful enough that they have a de facto monopoly. Result: stagnation. But I suspect EBay could now be attacked on its home territory, and that this territory would, in the hands of a successful invader, turn out to be more valuable than it currently appears. As with dating, however, a startup that wants to do this has to expend more effort on their strategy for cracking the monopoly than on how their auction site will work.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;11. Web Office apps.&lt;/strong&gt; We're interested in funding anyone competing with Microsoft desktop software. Obviously this is a rich market, considering how much Microsoft makes from it. A startup that made a tenth as much would be very happy. And a startup that takes on such a project will be helped along by Microsoft itself, who between their increasingly bureaucratic culture and their desire to protect existing desktop revenues will probably do a bad job of building web-based Office variants themselves. Before you try to start a startup doing this, however, you should be prepared to explain why existing web-based Office alternatives haven't taken the world by storm, and how you're going to beat that.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;12. Fix advertising.&lt;/strong&gt; Advertising could be made much better if it tried to please its audience, instead of treating them like victims who deserve x amount of abuse in return for whatever free site they're getting. It doesn't work anyway; audiences learn to tune out boring ads, no matter how loud they shout.&lt;/p&gt;
&lt;p&gt;What we have now is basically print and TV advertising translated to the web. The right answer will probably look very different. It might not even seem like advertising, by current standards. So the way to approach this problem is probably to start over from scratch: to think what the goal of advertising is, and ask how to do that using the new ingredients technology gives us. Probably the new answers exist already, in some early form that will only later be recognized as the replacement for traditional advertising.&lt;/p&gt;
&lt;p&gt;Bonus points if you can invent new forms of advertising whose effects are measurable, above all in sales.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;13. Online learning.&lt;/strong&gt; US schools are often bad. A lot of parents realize it, and would be interested in ways for their kids to learn more. Till recently, schools, like newspapers, had geographical monopolies. But the web changes that. How can you teach kids now that you can reach them through the web? The possible answers are a lot more interesting than just putting books online.&lt;/p&gt;
&lt;p&gt;One route would be to start with test prep services, for which there's already demand, and then expand into teaching kids more than just how to score high on tests. Another would be to start with games and gradually make them more thoughtful. Another, particularly for younger kids, would be to let them learn by watching one another (anonymously) solve problems.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;14. Tools for measurement.&lt;/strong&gt; Now that so much happens on computers connected to networks, it's possible to measure things we may not have realized we could. And there are some big problems that may be soluble if we can measure more. The most important of all is the defining flaw of large organizations: you can't tell who the most &lt;a href=&quot;http://rescuetime.com&quot;&gt;productive&lt;/a&gt; people are. A small company is measured directly by the market. But once an organization gets big enough that people on in the interior are protected from market forces, politics starts to rule, instead of performance. An improvement of even a few percent in the ability to measure what actually happens in large organizations would have a huge impact on the world economy, and a startup that enabled it would be entitled to a cut.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;15. Off the shelf security.&lt;/strong&gt; Services like ADT charge a fortune. Now that houses and their owners are both connected to networks practically all the time, a startup could stitch together alternatives out of cheap, existing hardware and services.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;16. A form of search that depends on design.&lt;/strong&gt; Google doesn't have a lot of weaknesses. One of the biggest is that they have no sense of design. They do the next best thing, which is to keep things sparse. But if there were a kind of search that depended a lot on design, a startup might actually be able to beat Google at search. I don't know if there is, but if you do, we'd love to hear from you.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;17. New payment methods.&lt;/strong&gt; There are almost certainly things whose growth is held back because there's no way to charge for them. And the people who could implement solutions don't realize how much demand there would be, precisely because this growth has been held back. So pretty much any new way of paying for things that's easier for some class of situations will turn out to have a bigger market than its inventors expected. Look at Paypal. (Warning: Regulated industry.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;18. The WebOS.&lt;/strong&gt; It probably won't be a literal translation of a client OS shifted to servers. But as applications migrate to servers, it seems possible there will be something that plays a central role like an OS does. We've already funded several startups that could be candidates. But this is a big prize, and there will probably be multiple winners.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;19. Application and/or data hosting.&lt;/strong&gt; This is related to the preceding idea, but not identical. And again, while we've already funded several startups in this area, it's probably going to be big enough that it contains several rich markets.&lt;/p&gt;
&lt;p&gt;It may turn out that 4, 18, and 19 all have the same answer. Or rather, that there will be things that answer all three. But the way to find such a grand, overarching solution is probably not to approach it directly, but to start by solving smaller, specific problems, then gradually expand your scope. Start by writing Basic for the Altair.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;20. Shopping guides.&lt;/strong&gt; Like news, shopping used to be constrained by geography. You went to your local store and chose from what they had. Now the space of possibilities is bewilderingly large, and people need help navigating it. If you already know what you want, &lt;a href=&quot;http://bountii.com&quot;&gt;Bountii&lt;/a&gt; can find you the best price. But how do you decide what you want? Hint: One answer is related to number 3.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;21. Finance software for individuals and small businesses.&lt;/strong&gt; Intuit seems ripe for picking off. The difficulty is that they've got data connections with all the banks. That's hard for a small startup to match. But if you can start in a neighboring area and gradually expand into their territory, you could displace them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;22. A web-based Excel/database hybrid.&lt;/strong&gt; People often use Excel as a lightweight database. I suspect there's an opportunity to create the program such users wish existed, and that there are new things you could do if it were web-based. Like make it easier to get data into it, through forms or scraping.&lt;/p&gt;
&lt;p&gt;Don't make it feel like a database. That frightens people. The question to ask is: how much can I let people do without defining structure? You want the database equivalent of a language that makes its easy to keep data in linked lists. (Which means you probably want to write it in one.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;23. More open alternatives to Wikipedia.&lt;/strong&gt; Deletionists rule Wikipedia. Ironically, they're constrained by print-era thinking. What harm does it do if an online reference has a long tail of articles that are only interesting to a few people, so long as everyone can still find whatever they're looking for? There is room to do to Wikipedia what Wikipedia did to Britannica.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;24. A buffer against bad customer service.&lt;/strong&gt; A lot of companies (to say nothing of government agencies) have appalling customer service. &quot;Please stay on the line. Your call is important to us.&quot; Doesn't it make you cringe just to read that? Sometimes the UIs presented to customers are even deliberately difficult; some airlines deliberately make it hard to buy tickets using miles, for example. Maybe if you built a more user-friendly wrapper around common bad customer service experiences, people would pay to use it. Passport expediters are an encouraging example.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;25. A Craigslist competitor.&lt;/strong&gt; Craiglist is ambivalent about being a business. This is both a strength and a weakness. If you focus on the areas where it's a weakness, you may find there are better ways to solve some of the problems Craigslist solves.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;26. Better video chat.&lt;/strong&gt; Skype and Tokbox are just the beginning. There's going to be a lot of evolution in this area, especially on mobile devices.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;27. Hardware/software hybrids.&lt;/strong&gt; Most hackers find hardware projects alarming. You have to deal with messy, expensive physical stuff. But &lt;a href=&quot;http://meraki.com&quot;&gt;Meraki&lt;/a&gt; shows what you can do if you're willing to venture even a little way into hardware. There's a lot of low-hanging fruit in hardware; you can often do dramatically new things by making comparatively small tweaks to existing stuff.&lt;/p&gt;
&lt;p&gt;Hardware is already mostly software. What I mean by a hardware/software hybrid is one in which software plays a very visible role. If you work on an idea of this type you'll tend to have the field to yourself, because most hackers are afraid of hardware, and most hardware companies can't write good software. (One reason your iPod isn't made by Sony is that Sony can't write iTunes.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;28. Fixing email overload.&lt;/strong&gt; A lot of people, including me, feel they get too much email. A solution would find a ready market. But the best solution may not be anything as obvious as a new mail reader.&lt;/p&gt;
&lt;p&gt;Related problem: Using your inbox as a to-do list. The solution is probably to acknowledge this rather than prevent it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;29. Easy site builders for specific markets.&lt;/strong&gt; &lt;a href=&quot;http://weebly.com&quot;&gt;Weebly&lt;/a&gt; is a good, general-purpose site builder. But there are a lot of markets that could use more specialized tools. What's the best way to make a web site if you're a real estate agent, or a restaurant, or a lawyer? There still don't seem to be canonical answers.&lt;/p&gt;
&lt;p&gt;Obviously the way to build this is to write a flexible site builder, then write layers on top to produce different variants. Hint: The key to making a site builder for end-users is to make software that lets people with no design ability produce things that look good—or at least professional.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;30. Startups for startups.&lt;/strong&gt; The increasing number of startups is itself an opportunity for startups. We're one; TechCrunch is another. What other new things can you do?&lt;/p&gt;
&lt;p&gt;Consider this list to end with a giant ellipsis. It's not even a complete list of the types of ideas we're looking for, let alone of all types of startup ideas. So if you have a great idea that's not on this list, don't be deterred. Some of the best ideas are outliers everyone ignores because they seem crazy.&lt;/p&gt;
&lt;p&gt;It was an interesting exercise to write out this list. I noticed a lot of similarities between ideas that I never realized were there. In fact, when you read the list, you get a pretty accurate composite portrait of a startup: a combination of relentless predator upon the obsolete and benevolent solver of the world's problems. As ways of making money go, that's pretty good. Startups are often ruthless competitors, but they're competing in a game won by making what people want.&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://ycombinator.com/images/y18.gif&quot; /&gt;&lt;a href=&quot;http://news.ycombinator.com/item?id=250704&quot;&gt;Comment&lt;/a&gt; on this article.&lt;/p&gt;

</description>
<pubDate>Wed, 21 Feb 2018 17:17:52 +0000</pubDate>
<dc:creator>evsamsonov</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>http://old.ycombinator.com/ideas.html</dc:identifier>
</item>
<item>
<title>Paper review: IPFS – Content addressed, versioned, P2P file system</title>
<link>https://muratbuffalo.blogspot.com/2018/02/paper-review-ipfs-content-addressed.html</link>
<guid isPermaLink="true" >https://muratbuffalo.blogspot.com/2018/02/paper-review-ipfs-content-addressed.html</guid>
<description>This week we discussed &lt;a href=&quot;https://ipfs.io/ipfs/QmR7GSQM93Cx5eAg6a6yRzNde1FQv7uL6X1o4k7zrJa3LX/ipfs.draft3.pdf&quot;&gt;the IPFS whitepaper &lt;/a&gt;by Juan Benet &lt;a href=&quot;http://muratbuffalo.blogspot.com/2018/01/spring-18-distributed-systems-seminar.html&quot;&gt;in my Distributed Systems Seminar.&lt;/a&gt;&lt;p&gt;&lt;a href=&quot;http://muratbuffalo.blogspot.com/2018/01/remember-peer-to-peer-systems.html&quot;&gt;Remember peer-to-peer systems?&lt;/a&gt; &lt;a href=&quot;https://github.com/ipfs/ipfs&quot;&gt;IPFS is &quot;peer-to-peer systems reloaded&quot; with improved features.&lt;/a&gt; IPFS is a content-addressed distributed file system that combines Kademlia + BitTorrent + Git ideas. IPFS also offers better privacy/security features: it provides cryptographic hash content addressing, file integrity and versioning, and filesystem-level encryption and signing support.&lt;/p&gt;&lt;p&gt;The question is will it stick? I think it won't stick, but this work will still be very useful because we will transfer the best bits of IPFS to our datacenter computing as we did with other peer-to-peer systems technology. The reason I think it won't stick has nothing to do with the IPFS development/technology, but has everything to do with &lt;a href=&quot;http://muratbuffalo.blogspot.com/2014/07/distributed-is-not-necessarily-more.html&quot;&gt;the advantages of centralized coordination and the problems surrounding decentralization.&lt;/a&gt; I rant more about this later in this post. Read on for the more detailed review on IPFS components, killer app for IPFS, and MAD questions.&lt;/p&gt;&lt;h2&gt;IPFS components&lt;/h2&gt;&lt;h3&gt;Identities&lt;/h3&gt;
Nodes are identified by a NodeId, the cryptographic hash3 of a public-key, created with S/Kademlia’s static crypto puzzle. Nodes store their public and private keys (encrypted with a passphrase).&lt;br/&gt;&lt;h3&gt;Network&lt;/h3&gt;
Transport: IPFS can use any transport protocol, and is best suited for WebRTC DataChannels(for browser connectivity) or uTP.&lt;br/&gt;Reliability: IPFS can provide reliability if underlying networks do not provide it, using uTP or &lt;a href=&quot;https://en.wikipedia.org/wiki/Stream_Control_Transmission_Protocol&quot;&gt;SCTP&lt;/a&gt;.&lt;br/&gt;Connectivity: IPFS also uses the ICE NAT traversal techniques.&lt;br/&gt;Integrity: IPFS optionally checks integrity of messages using a hash checksum.&lt;br/&gt;Authenticity: IPFS optionally checks authenticity of messages using HMAC with sender’s public key.&lt;br/&gt;&lt;h3&gt;Routing&lt;/h3&gt;
To find other peers and objects, IPFS &lt;a href=&quot;https://en.wikipedia.org/wiki/Distributed_hash_table&quot;&gt;uses a DSHT&lt;/a&gt; based on S/Kademlia and Coral. Coral DSHT improves over by Kademlia based on the three rules of real-estate: location, location, location. Coral stores addresses to peers who can provide the data blocks taking advantage of data locality. Coral can distribute only subsets of the values to the nearest nodes avoiding hot-spots. Coral organizes a hierarchy of separate DSHTs called clusters depending on region and size. This enables nodes to query peers in their region first, &quot;finding nearby data without querying distant nodes&quot; and greatly reducing the latency of lookups.&lt;br/&gt;&lt;h3&gt;Exchange&lt;/h3&gt;
In IPFS, data distribution happens by exchanging blocks with peers using a BitTorrent inspired protocol: BitSwap. Unlike BitTorrent, BitSwap is not limited to the blocks in one torrent. The blocks can come from completely unrelated files in the filesystem. In a sense, nodes come together to &lt;em&gt;&lt;strong&gt;barter&lt;/strong&gt;&lt;/em&gt; in the marketplace. BitSwap incentivizes nodes to seed/serve blocks even when they do not need anything in particular. To avoid leeches (freeloading nodes that never share), peers track their balance (in bytes verified) with other nodes, and peers send blocks to debtor peers according to a function that falls as debt increases. For bartering, potentially, a virtual currency like &lt;a href=&quot;https://en.wikipedia.org/wiki/Filecoin&quot;&gt;FileCoin&lt;/a&gt; (again by Juan Benet) can be used.&lt;br/&gt;&lt;h3&gt;Objects&lt;/h3&gt;
IPFS builds a Merkle DAG, a directed acyclic graph where links between objects are cryptographic hashes of the targets embedded in the sources. (&lt;a href=&quot;https://www.youtube.com/watch?v=YIc6MNfv5iQ&quot;&gt;This video explains Merkle Trees superbly.&lt;/a&gt;) Merkle DAGs provide IPFS many useful properties:&lt;br/&gt;1. Content addressing: All content is uniquely identified by its multihash checksum.&lt;br/&gt;2. Tamper resistance: all content is verified with its checksum.&lt;br/&gt;3. Deduplication: all objects that hold the exact same content are equal, and only stored once.&lt;br/&gt;&lt;h3&gt;Files&lt;/h3&gt;
IPFS also defines a set of objects for modeling a versioned filesystem on top of the Merkle DAG. This object model is similar to Git’s:&lt;br/&gt;1. block: a variable-size block of data.&lt;br/&gt;2. list: an ordered collection of blocks or other lists.&lt;br/&gt;3. tree: a collection of blocks, lists, or other trees.&lt;br/&gt;4. commit: a snapshot in the version history of a tree.&lt;br/&gt;&lt;h3&gt;Naming&lt;/h3&gt;
IPNS is the DNS for IPFS. We have seen that NodeId is obtained by hash(node.PubKey). Then IPNS assigns every user a mutable namespace at: &lt;strong&gt;/ipns/&amp;lt;NodeId&amp;gt;&lt;/strong&gt;. A user can publish an Object to this &lt;strong&gt;/ipns/&amp;lt;NodeId&amp;gt;&lt;/strong&gt; path signed by her private key. When other users retrieve the object, they can check the signature matches the public key and NodeId. This verifies the authenticity of the Object published by the user, achieving mutable state retrieval.&lt;p&gt;Unfortunately since &lt;strong&gt;&amp;lt;NodeId&amp;gt;&lt;/strong&gt; is a hash, it is not human friendly to pronounce and recall. For this DNS TXT IPNS Records are employed. If &lt;strong&gt;/ipns/&amp;lt;domain&amp;gt;&lt;/strong&gt; is a valid domain name, IPFS looks up key ipns in its DNS TXT records:&lt;br/&gt;&lt;strong&gt;ipfs.benet.ai. TXT &quot;ipfs=XLF2ipQ4jD3U ...&quot; &lt;/strong&gt;&lt;br/&gt;# the above DNS TXT record behaves as symlink&lt;br/&gt;&lt;strong&gt;ln -s /ipns/XLF2ipQ4jD3U /ipns/fs.benet.ai&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;There is even the &lt;a href=&quot;https://github.com/beakerbrowser/beaker&quot;&gt;Beaker browser&lt;/a&gt; to help you surf IPFS. &lt;a href=&quot;https://www.youtube.com/watch?v=nKHJ4rLN9mo&quot;&gt;But its usability is not great.&lt;/a&gt;  If IPFS wants to manage the web, it should further improve its IPNS and content discovery game. Where is the search engine for IPFS content? Do we need to rely on links from friends like the 1993's Web?&lt;/p&gt;&lt;h2&gt;What is the killer app for IPFS?&lt;/h2&gt;
The introduction of the paper discusses HTTP and Web, and then says:&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;&quot;Industry has gotten away with using HTTP this long because moving small files around is relatively cheap, even for small organizations with lots of traffic. But we are entering a new era of data distribution with new challenges: (a) hosting and distributing petabyte datasets, (b) computing on large data across organizations, (c) high-volume high-definition on-demand or real-time media streams, (d) versioning and linking of massive datasets, (e) preventing accidental disappearance of important files, and more. Many of these can be boiled down to &quot;lots of data, accessible everywhere.&quot; Pressed by critical features and bandwidth concerns, we have already given up HTTP for different data distribution protocols. The next step is making them part of the Web itself. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;What remains to be explored is how [Merkle DAG] data structure can influence the design of high-throughput oriented file systems, and how it might upgrade the Web itself. This paper introduces IPFS, a novel peer-to-peer version-controlled filesystem seeking to reconcile these issues.&quot;&lt;/p&gt;
&lt;/blockquote&gt;
How common are petabyte or even gigabyte files on the Internet? There is definitely an increase in size trend due to the popularity of the multimedia files. But when will this become a pressing issue? It is not a pressing issue right now because CDNs help a lot for reducing traffic for the Internet. Also bandwidth is relatively easy to add compared to latency improvements. Going for a decentralized model globally comes with several issues/headaches, and I don't know how bad the bandwidth problems would need to get before starting to consider that option. And it is not even clear that the peer-to-peer model would provide more bandwidth savings than CDNs at the edge model.&lt;p&gt;I am not convinced that the Web is the killer application for IPFS, although at the end, the paper gets ambitious:&lt;br/&gt;&lt;/p&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;&quot;IPFS is an ambitious vision of new decentralized Internet infrastructure, upon which many different kinds of applications can be built. At the bare minimum, it can be used as a global, mounted, versioned filesystem and namespace, or as the next generation file sharing system. At its best, it could push the web to new horizons, where publishing valuable information does not impose hosting it on the publisher but upon those interested, where users can trust the content they receive without trusting the peers they receive it from, and where old but important files do not go missing. IPFS looks forward to bringing us toward the Permanent Web.&quot;&lt;/p&gt;
&lt;/blockquote&gt;
Decentralization opens a Pandora's box of issues. Centralized is efficient and effective. Coordination wants to be centralized. A common and overhyped misconception is not centralized is not scalable and centralized is a single point of failure. After close to two decades of work in cluster computing and cloud computing, we have good techniques in place for achieving scalability and fault-tolerance for centralized (or logically centralized, if you like) systems. For scalability, shard it, georeplicate it, and provide CDNs for reading. For fault-tolerance, slap Paxos on it, or use chain replication systems (where Paxos guards the chain configuration), or use the globe-spanning distributed datastores available today. Case in point, Dropbox is logically-centralized but is very highly available and fault-tolerant, while serving to millions of users. Facebook is able to serve billions of users.&lt;p&gt;If you want to make the natural disaster tolerance argument to motivate the use of IPFS, good luck trying to use IPFS over landlines when power and ISPs are down, and good luck trying to form a multihop wireless ad hoc network over laptops using IPFS. Our only hope in a big natural disaster is cell towers and satellite communication. Disaster tolerance is serious work and I hope governments around the world are funding sufficient research into operational, planning, and communications aspects of that.&lt;/p&gt;&lt;p&gt;In Section 3.8, the whitepaper talks about the use cases for IPFS:&lt;br/&gt;&lt;/p&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;1. As a mounted global filesystem, under /ipfs and /ipns.&lt;br/&gt;2. As a mounted personal sync folder that automatically versions, publishes, and backs up any writes.&lt;br/&gt;3. As an encrypted file or data sharing system.&lt;br/&gt;4. As a versioned package manager for all software.&lt;br/&gt;5. As the root filesystem of a Virtual Machine.&lt;br/&gt;6. As the boot filesystem of a VM (under a hypervisor).&lt;br/&gt;7. As a database: applications can write directly to the Merkle DAG data model and get all the versioning, caching, and distribution IPFS provides.&lt;br/&gt;8. As a linked (and encrypted) communications platform.&lt;br/&gt;9. As an integrity checked CDN for large files (without SSL).&lt;br/&gt;10. As an encrypted CDN.&lt;br/&gt;11. On webpages, as a web CDN.&lt;br/&gt;12. As a new Permanent Web where links do not die.&lt;/p&gt;
&lt;/blockquote&gt;
I don't think any of these warrant going full peer-to-peer. There are centralized solutions for them, or centralized solutions are possible for them.&lt;p&gt;An important use case for IPFS is to circumvent government censorship. But isn't it easier to use VPNs then to use IPFS for this purpose. (Opera browser comes with VPN build-in, and many easy to use VPN apps are available.) If the argument is that the governments can ban VPNs or prosecute people using VPN software, those issues also apply to IPFS unfortunately. Technology is not always the solution especially when dealing with big social issues.&lt;/p&gt;&lt;p&gt;IPFS may be a way of sticking it to the man. But the invisible hand of the free market forces also help here; when one big corporation starts playing foul and upsets the users, new companies and startups quickly move in to disrupt the space and fill in the void.&lt;/p&gt;&lt;p&gt;Again, I don't want to come across wrong. &lt;em&gt;I think IPFS is great work, and Juan Benet and IPFS contributors accomplished a gigantic task, with a lot of impact on future systems (I believe the good parts of IPFS will be &quot;adopted&quot; to improve Web and datacenter/cloud computing).&lt;/em&gt; I just don't believe dialing the crank to 11 on decentralization is the right strategy for wide adoption. I don't see the killer application that makes it worthwhile to move away from the convenience of the more centralized model to open the Pandora's box with a fully-decentralized model.&lt;/p&gt;&lt;h2&gt;MAD questions &lt;/h2&gt;
1) Today's networking ecosystem evolved for the client-server model, what kind of problems could this create for switching to peer-to-peer model? As a basic example, the uplink at residential (or even commercial) spaces is an order of magnitude less than downlink assuming they are consumers of traffic not originators of traffic. Secondly, ISPs (for good or bad) evolved to take on traffic shaping/engineering responsibilities peering with other ISPs. It is a complex system. How does popular IPFS use interact with that ecosystem.&lt;p&gt;2) As a related point, smartphones gained primary citizenship status in today's Internet. How well can peer-to-peer and IPFS get along with smartphones? Smartphones are very suitable to be thin clients in the cloud computing model, but they are not suitable to act as peers in a peer-to-peer system (both for battery and connection bandwidth reasons). To use a technical term, the smartphones will be leeches in a peer-to-peer model. (Well unless there is good token/credit system in place, but it is unrealistic to expect that soon.)&lt;/p&gt;&lt;p&gt;3) On the academic side of things, designing a decentralized search engine for IPFS sounds like a great research problem. Google had it easy in the datacenter but can you design a decentralized keyword/content based search engine (or one day old indexes) maintained in a P2P manner over IPFS nodes? Popularity of a file in the system (how many copies it has in the system) can play a role in its relevance ranking for the keyword. Also could a bloom filter like data structure be useful in a p2p search?&lt;/p&gt;&lt;p&gt;4) Here are some more pesky problems with decentralization. I am not clear if satisfactory answers exist on these. Does IPFS mean I may be storing some illegal content originated by other users?&lt;br/&gt;How does IPFS deal with the volatility? Just closing laptops at night may cause unavailability under an unfortunate sequence of events. What is the appropriate number of replicas for a data to avoid this fate? Would we have to over-replicate to be conservative and provide availability?&lt;br/&gt;If IPFS is commonly deployed, how do we charge big content providers that benefit from their content going viral over the network? Every peer chips in distributing that content, but the content generator benefits let's say by way of sales. Would there need to be a token economy that is all seeing and all fair to solve this issue?&lt;/p&gt;&lt;p&gt;5) Is it possible to use &lt;a href=&quot;https://en.wikipedia.org/wiki/Reed%E2%80%93Solomon_error_correction&quot;&gt;Reed-Solomon erasure coding&lt;/a&gt; with IPFS? Reed-Solomon codes are very popular in the datacenters as they provide great savings for replication.&lt;/p&gt;&lt;p&gt;6) IPFS does not tolerate Byzantine behavior, right? The crypto puzzle needed for Node Id can help reduce the false spammers, as it makes them do some work. But after joining, there is no guarantee that the peers will play it fair: they can be Byzantine to wreak havoc on the system. But how much problems can they cause? Using cryptos and signatures prevent many problems. But can the Byzantine nodes somehow collude to cause data loss in the system, making the originator think the data is replicated, but then deleting this data? What other things can go wrong?
&lt;/p&gt;
</description>
<pubDate>Wed, 21 Feb 2018 16:44:07 +0000</pubDate>
<dc:creator>mad44</dc:creator>
<og:url>http://muratbuffalo.blogspot.com/2018/02/paper-review-ipfs-content-addressed.html</og:url>
<og:title>Paper review. IPFS: Content addressed, versioned, P2P file system</og:title>
<og:description>This week we discussed  the IPFS whitepaper  by Juan Benet  in my Distributed Systems Seminar. Remember peer-to-peer systems? IPFS is &quot;pe...</og:description>
<dc:format>text/html</dc:format>
<dc:identifier>https://muratbuffalo.blogspot.com/2018/02/paper-review-ipfs-content-addressed.html</dc:identifier>
</item>
<item>
<title>Why It’s So Hard to Actually Work in Shared Offices</title>
<link>https://thewalrus.ca/why-its-so-hard-to-actually-work-in-shared-offices/</link>
<guid isPermaLink="true" >https://thewalrus.ca/why-its-so-hard-to-actually-work-in-shared-offices/</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://s3.amazonaws.com/walrus-assets/img/WEB_Hune-Brown_WeWork_art.jpg&quot; alt=&quot;Illustration by Josh Holinaty&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;dropcap&quot;&gt;O&lt;/span&gt;&lt;span class=&quot;smallcaps&quot;&gt;ne afternoon last&lt;/span&gt; May, on the fourth floor of a massive renovation site in downtown Toronto, a lanky twentysomething in a hard hat asked me to envision the future. Jarred was from WeWork, a company that was in the midst of building a six-storey communal workplace where self-employed strivers could rent desks, mingle, and share ideas around craft-beer taps. The space, he assured me, was going to be &lt;em&gt;funky&lt;/em&gt;. “There’ll be exposed brick and sockets to give it that modern look,” he said, gesturing at the dusty expanse.&lt;/p&gt;
&lt;p&gt;Jarred was trying to sell me on more than just aesthetics— he was offering a utopian vision of community. My future co-workers, he said, would be fascinating. They were startup founders and young creative types. A tequila company had rented office space and wanted to host tequila Tuesdays. He opened the WeWork app on his phone, and I watched as a cascade of posts from my soon-to-be colleagues and collaborators flew past. “I’ve heard from people who have tried other co-working spaces and…the other ones aren’t &lt;em&gt;bad&lt;/em&gt;,” Jarred said with an exaggerated pause. WeWork was just that much better. “We know your name, we remember your birthday, we remember your dog’s birthday,” he continued. I don’t have a dog, but I appreciated the sentiment. I signed up on the spot.&lt;/p&gt;
&lt;p&gt;WeWork was founded by Adam Neumann and Miguel McKelvey in 2010, and it started with a single office in New York City. Today, the company has 274 offices in fifty-nine cities, from Bogotá to Tel Aviv. It is the fourth-largest startup in America, and it is reportedly valued at more than $20 billion (US), which puts it below only Uber, Airbnb, and SpaceX. WeWork leases buildings, renovates them to a millennial-approved sheen, and then rents them out desk by desk and office by office. There are now five locations in Canada, and at the inaugural Toronto office, a “hot desk”— a spot at a communal table or couch— starts at $500 per month, a permanent desk at $700, and a private office at $1,000. The company is now trying to become the leader in a crowded market where dozens of hubs all promise a variation on the same thing: an inspirational environment among like-minded members of the creative class, plus coffee.&lt;/p&gt;
&lt;p&gt;According to a survey by Upwork and the Freelancers Union, more than one-third of workers in the United States were freelancers in 2016— some 55 million and counting. A study by accounting-software provider QuickBooks predicts that 45 percent of the Canadian workforce will be self-employed by 2020. WeWork, with its enormous pocketbook and hipster-capitalist aesthetic, is determined to become the default home for a new generation of white-collar workers. It believes that these budding entrepreneurs have no interest in the grey cubicles of the past. They want an office that matches their personality. And apparently, that means beer on tap and lots of it.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;dropcap&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;smallcaps&quot;&gt;hree months after&lt;/span&gt; my tour, my co-workers and I began our new life together. The office looked like the lobby of a hipster hotel. There was a graffiti mural in the foyer, and the prayer hands emoji that Drake has tattooed on his arm was rendered in neon on the sixth floor. Fresh pastries were laid out, to go with the bottomless citrus- and cucumber-infused water and micro-roasted coffee. Rows of simple wooden tables ran across the common area, and there were booths for private phone calls, couches for conversations, and an open kitchen for contemplative snacking. On the upper floors, startups and established companies occupied small offices separated by glass walls (&lt;span class=&quot;smallcaps&quot;&gt;RBC&lt;/span&gt;, in an attempt to find new inspiration and new customers, had rented nearly an entire floor). The place had a first-day-of-school air, with freelancers holding their phones in front of their faces as they entered their selfies into the WeWork app— the virtual community that would complement our physical community.&lt;/p&gt;
&lt;p&gt;Over the next few weeks, we showed up each day and tapped away on MacBook Airs to the sounds of Portuguese house music and old-school hip hop piped in through speakers. (“Rap is urban, and so is WeWork,” the company explains online. “But more profoundly, the common themes of rap are in tune with the company’s mission.”) While we created, cleaning crews in WeWork T-shirts quietly restocked the citrus water and wiped up our spilled drinks.&lt;/p&gt;
&lt;p&gt;Fotini Iconomopoulos, a negotiation consultant, perched on one of the many couches. She had spent years working on the road and from cafés before trying out a co-working space. “I like the idea of seeing people that I can connect with on a regular basis, seeing familiar faces,” she explained. Dane Jensen, a high-school classmate of mine who is now the head of a performance-coaching company, sat at a nearby desk. “This place must have more Apple AirPods per capita than anywhere in the world,” he said one afternoon, warily looking around. Even so, Jensen said, the building’s vibe could feel invigorating at times. “If I’ve been working at home for too many days in a row and I’m feeling sluggish, it’s nice to go somewhere where there’s a lot of busy people being productive.”&lt;/p&gt;
&lt;p&gt;Still, the future of work looked very much like, well, work. A hip hop soundtrack does not change the tedium of sending emails and updating spreadsheets. The most distinctive feature of the co-working life— imported from our social networks on Instagram and Facebook— was the pervasive sense that everyone was hustling, killing it, and eagerly selling themselves. The building was home to endless happy hours, meditation groups, and marketing seminars— elaborate PR affairs disguised as community events. On the WeWork app, a whir of requests whizzed past each day: a company offering “non-traditional lifestyle swag” was looking to barter its featured deals for business expertise; a food-ordering app that offers steep discounts on old food that’s destined for the dumpster (“think of it as the happy hour for food!”) was asking for beta users. The WeWork experience was recognizing that you were, at any given moment, both a product that needed selling and the target market for a noisy community of smiling, desperate salespeople.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;dropcap&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;smallcaps&quot;&gt;hen the WeWork&lt;/span&gt; founders talk about their company, they use the grandiose terms typical of Silicon Valley. Their stated mission is “to create a world where people work to make a life, not just a living.” A mere office-rental company, after all, could hardly justify a $20 billion valuation. As the &lt;em&gt;Wall Street Journal&lt;/em&gt; noted, the office-leasing company &lt;span class=&quot;smallcaps&quot;&gt;IWG&lt;/span&gt; manages five times the square footage of WeWork but has one-eighth the market valuation. WeWork has found its investors by insisting that it is something different entirely— “space as service,” or a platform, or a culture. And it is now bringing that culture into disparate segments of modern life. WeGrow, a proposed private elementary school in one of WeWork’s New York City offices, aims to groom the next generation of entrepreneurs by teaching children about supply and demand. WeLive has created dorm-room-like apartment buildings in New York City and Washington, DC. The company is currently involved in building wave pools, opening gyms, and buying coding schools, all with the aim of creating “a place where we’re redefining success measured by personal fulfillment, not just the bottom line.”&lt;/p&gt;
&lt;p&gt;And here, beneath the aspirational jargon, is a nugget of truth: WeWork is in the personal-fulfillment business. Because it’s offering a service that can be provided by anyone who can wrangle together a few desks and a French press, the product it’s actually selling is the contact high of being part of something that feels revolutionary. WeWork is promoting a mythology for those in the brave new gig economy: You, precarious worker who will never have a pension, are not a simple cog in a machine. You are an artist, the &lt;span class=&quot;smallcaps&quot;&gt;CEO&lt;/span&gt; of your own company, and the face of a dynamic personal brand. Your work is not merely labour, for which you deserve decent pay and security, but an extension of your personality. You’re doing what you love and paying $500 per month for the desk from which to do it.&lt;/p&gt;
&lt;p&gt;The appeal of that pitch can wear off quickly. When I spoke to Iconomopoulos in November, she told me that after three months at WeWork, she’d decided to move on. She had been trying to network— posting on the app, introducing herself in the common area, and even holding an event— but as a thirty-seven-year-old surrounded by enthusiastic people a decade younger, she felt old and slightly out of place. She looked at other co-working options and toured Workhaus and Verkspace (which takes its inspiration “from the Scandinavian way of life”). The buildings, she said, all felt strangely familiar: they had the same open kitchens, the same glass dividers, the same safely “offbeat” art on the walls. Near the end of the month, she opted for a private office in Spaces, which is owned by &lt;span class=&quot;smallcaps&quot;&gt;IWG&lt;/span&gt;. The company seemed to be looking for a slightly older demographic and had belatedly adopted some Silicon Valley razzle-dazzle of its own, promising tenants entry into a community of “thinkers, achievers and imagineers.” Perhaps personal fulfillment is a lot to ask of a workplace, but Iconomopoulos was going to give it another try.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;dropcap&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;smallcaps&quot;&gt;uring my final&lt;/span&gt; week at WeWork, the building held a party. All six floors were crowded with tenants and guests eagerly drinking WeWork margaritas and awkwardly swaying to Drake. A young, blond exec cut the music for a moment to stand up on a riser and say how much she loved fulfilling the company’s mission. “This is more like a bar or a club than a workspace,” said the local member of provincial parliament, taking in the scene. Entrepreneurial caterers handed out business cards along with their miniature cups of artisanal pho. This party was work, of course, just like work was always a party. I ate a plate of duck-ragù pasta served on a pillow of cauliflower foam, drank a craft beer called Food Truck, and felt an inexplicable and totally disproportionate sense of despair.&lt;/p&gt;
&lt;p&gt;The next morning, my last at WeWork, the building felt collectively hungover. I wandered in at 10:30 and found the place nearly empty, the desks still pushed to the edges of the office. I drank my citrus water and listlessly checked my email. A member of the cleaning staff— a young Spanish-speaking woman with a tight ponytail— was one of the few people actually working. She moved quietly, picking up the dirty mugs that people had left lying about and stacking them into the dishwasher. Her shirt was emblazoned with the company slogan: Do What You Love.&lt;/p&gt;
</description>
<pubDate>Wed, 21 Feb 2018 15:33:36 +0000</pubDate>
<dc:creator>devy</dc:creator>
<og:title>Why It’s so Hard to Actually Work in Shared Offices</og:title>
<og:description>WeWork offers freelancers a chic workspace and beer on tap—but are people productive?</og:description>
<og:type>article</og:type>
<og:url>https://thewalrus.ca/why-its-so-hard-to-actually-work-in-shared-offices/</og:url>
<og:image>https://s3.amazonaws.com/walrus-assets/img/WEB_Hune-Brown_WeWork_art.jpg</og:image>
<dc:language>en-CA</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://thewalrus.ca/why-its-so-hard-to-actually-work-in-shared-offices/</dc:identifier>
</item>
<item>
<title>Practical Tips for Cheating at Design</title>
<link>https://medium.com/refactoring-ui/7-practical-tips-for-cheating-at-design-40c736799886</link>
<guid isPermaLink="true" >https://medium.com/refactoring-ui/7-practical-tips-for-cheating-at-design-40c736799886</guid>
<description>&lt;p&gt;
&lt;h3 name=&quot;fc7a&quot; id=&quot;fc7a&quot; class=&quot;graf graf--h3 graf--leading&quot;&gt;7. Not every button needs a background color&lt;/h3&gt;
&lt;/p&gt;
&lt;div class=&quot;section-inner sectionLayout--outsetColumn&quot;&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*d4cSVthCYgX57KQjcw7SpA.png&quot; data-width=&quot;1530&quot; data-height=&quot;717&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*d4cSVthCYgX57KQjcw7SpA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/2000/1*d4cSVthCYgX57KQjcw7SpA.png&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;section-inner sectionLayout--insetColumn&quot; readability=&quot;41&quot;&gt;
&lt;p name=&quot;e9ac&quot; id=&quot;e9ac&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;When there are multiple actions a user can take on a page, it’s easy to fall into the trap of designing those actions based purely on semantics.&lt;/p&gt;
&lt;p name=&quot;1828&quot; id=&quot;1828&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Frameworks like Bootstrap sort of encourage this by giving you a menu of semantic styles to choose from whenever you’re adding a new button:&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*2xkDfSjvq7Xyb_ceInrMpw.png&quot; data-width=&quot;1562&quot; data-height=&quot;630&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*2xkDfSjvq7Xyb_ceInrMpw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*2xkDfSjvq7Xyb_ceInrMpw.png&quot;/&gt;&lt;/div&gt;
&lt;p name=&quot;e583&quot; id=&quot;e583&quot; class=&quot;graf graf--p graf--startsWithDoubleQuote graf-after--figure&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;“Is this a positive action? Make the button green.”&lt;/em&gt;&lt;/p&gt;
&lt;p name=&quot;2e41&quot; id=&quot;2e41&quot; class=&quot;graf graf--p graf--startsWithDoubleQuote graf-after--p&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;“Does this delete data? Make the button red.”&lt;/em&gt;&lt;/p&gt;
&lt;p name=&quot;9a60&quot; id=&quot;9a60&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Semantics are an important part of button design, but there’s a more important dimension that’s commonly forgotten: &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;hierarchy.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;779b&quot; id=&quot;779b&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Every action on a page sits somewhere in a pyramid of importance. Most pages only have one true primary action, a couple of less important secondary actions, and a few seldom used tertiary actions.&lt;/p&gt;
&lt;p name=&quot;286d&quot; id=&quot;286d&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;When designing these actions, &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;it’s important to communicate their place in the hierarchy.&lt;/strong&gt;&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li name=&quot;25d6&quot; id=&quot;25d6&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Primary actions should be obvious.&lt;/strong&gt; Solid, high contrast background colors work great here.&lt;/li&gt;
&lt;li name=&quot;f3a9&quot; id=&quot;f3a9&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Secondary actions should be clear but not prominent.&lt;/strong&gt; Outline styles or lower contrast background colors are great options.&lt;/li&gt;
&lt;li name=&quot;b61d&quot; id=&quot;b61d&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Tertiary actions should be discoverable but unobtrusive.&lt;/strong&gt; Styling these actions like links is usually the best approach.&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*CiEQ9mpfpfAXp62pTE2fbw.png&quot; data-width=&quot;1400&quot; data-height=&quot;722&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*CiEQ9mpfpfAXp62pTE2fbw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*CiEQ9mpfpfAXp62pTE2fbw.png&quot;/&gt;&lt;/div&gt;
&lt;p name=&quot;8d26&quot; id=&quot;8d26&quot; class=&quot;graf graf--p graf--startsWithDoubleQuote graf-after--figure&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;“What about destructive actions, shouldn’t they always be red?”&lt;/em&gt;&lt;/p&gt;
&lt;p name=&quot;93e5&quot; id=&quot;93e5&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Not necessarily! If the destructive action isn’t the &lt;em class=&quot;markup--em markup--p-em&quot;&gt;primary&lt;/em&gt; action on the page, it might be better to give it a secondary or tertiary button treatment.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*pIMOui8TSM_gUX9xNFyBng.png&quot; data-width=&quot;1400&quot; data-height=&quot;322&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*pIMOui8TSM_gUX9xNFyBng.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*pIMOui8TSM_gUX9xNFyBng.png&quot;/&gt;&lt;/div&gt;
&lt;p name=&quot;89a8&quot; id=&quot;89a8&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Save the big, red, and bold styling for when that negative action actually &lt;em class=&quot;markup--em markup--p-em&quot;&gt;is&lt;/em&gt; the primary action in the interface, like in a confirmation dialog:&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*cuYcwjOO26sKHImHaY6yFA.png&quot; data-width=&quot;1400&quot; data-height=&quot;808&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*cuYcwjOO26sKHImHaY6yFA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*cuYcwjOO26sKHImHaY6yFA.png&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Wed, 21 Feb 2018 14:34:21 +0000</pubDate>
<dc:creator>marvinpinto</dc:creator>
<og:title>7 Practical Tips for Cheating at Design – Refactoring UI – Medium</og:title>
<og:url>https://medium.com/refactoring-ui/7-practical-tips-for-cheating-at-design-40c736799886</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*YgsvBILjjtgtW1vz2L0alA.png</og:image>
<og:description>Improving your designs with tactics instead of talent.</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://medium.com/refactoring-ui/7-practical-tips-for-cheating-at-design-40c736799886</dc:identifier>
</item>
<item>
<title>Growing a company that sells miniature construction supplies to $17k a month</title>
<link>https://www.starterstory.com/mini-materials</link>
<guid isPermaLink="true" >https://www.starterstory.com/mini-materials</guid>
<description>[unable to retrieve full-text content]&lt;p&gt;Article URL: &lt;a href=&quot;https://www.starterstory.com/mini-materials&quot;&gt;https://www.starterstory.com/mini-materials&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=16429467&quot;&gt;https://news.ycombinator.com/item?id=16429467&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Points: 695&lt;/p&gt;&lt;p&gt;# Comments: 264&lt;/p&gt;</description>
<pubDate>Wed, 21 Feb 2018 14:02:45 +0000</pubDate>
<dc:creator>patwalls</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.starterstory.com/mini-materials</dc:identifier>
</item>
<item>
<title>Physics Makes Aging Inevitable, Not Biology (2016)</title>
<link>http://nautil.us/issue/36/aging/physics-makes-aging-inevitable-not-biology</link>
<guid isPermaLink="true" >http://nautil.us/issue/36/aging/physics-makes-aging-inevitable-not-biology</guid>
<description>&lt;p&gt;&lt;span class=&quot;dropcap&quot;&gt;T&lt;/span&gt;he inside of every cell in our body is like a crowded city, filled with tracks, transports, libraries, factories, power plants, and garbage disposal units. The city’s workers are protein machines, which metabolize food, take out the garbage, or repair DNA. Cargo is moved from one place to another by molecular machines that have been observed walking on two legs along protein tightropes. As these machines go about their business, they are surrounded by thousands of water molecules, which randomly crash into them a trillion times a second. This is what physicists euphemistically call “thermal motion.” Violent thermal chaos would be more apt.&lt;/p&gt;
&lt;p&gt;How any well-meaning molecular machine could do good work under such intolerable circumstances is puzzling. Part of the answer is that the protein machines of our cells, like tiny ratchets, turn the random energy they receive from water bombardment into the very directed motion that makes cells work. They turn chaos into order.&lt;/p&gt;
&lt;img src=&quot;http://static.nautil.us/9222_497d0b20f66cebdedc7935e3ffd46efa.png&quot; width=&quot;733&quot; alt=&quot;&quot;/&gt;Johner Images / Getty
&lt;p&gt;Four years ago, I published a book called &lt;em&gt;Life’s Ratchet&lt;/em&gt;, which explains how molecular machines create order in our cells. My main concern was how life avoids a descent into chaos. To my great surprise, soon after the book was published, I was contacted by researchers who study biological aging. At first I couldn’t see the connection. I knew nothing about aging except for what I had learned from being forced to observe the process in my own body.&lt;/p&gt;
&lt;p&gt;Then it dawned on me that by emphasizing the role of thermal chaos in animating molecular machines, I encouraged aging researchers to think more about it as a driver of aging. Thermal motion may seem beneficial in the short run, animating our molecular machines, but could it be detrimental in the long run? After all, in the absence of external energy input, random thermal motion tends to destroy order.&lt;/p&gt;
&lt;p&gt;This tendency is codified in the second law of thermodynamics, which dictates that everything ages and decays: Buildings and roads crumble; ships and rails rust; mountains wash into the sea. Lifeless structures are helpless against the ravages of thermal motion. But life is different: Protein machines constantly heal and renew their cells.&lt;/p&gt;
&lt;p&gt;In this sense, life pits biology against physics in mortal combat. So why do living things die? Is aging the ultimate triumph of physics over biology? Or is aging part of biology itself?&lt;/p&gt;
&lt;div class=&quot;reco&quot;&gt;
&lt;article class=&quot;issue-article&quot;&gt;&lt;div&gt;&lt;a href=&quot;http://nautil.us/issue/9/Time/the-quantum-mechanics-of-fate&quot; class=&quot;obnd_lnk&quot; data-trval=&quot;the-quantum-mechanics-of-fate&quot; data-trlbl=&quot;foc_rec&quot; data-tract=&quot;internal_art&quot;&gt;&lt;img src=&quot;http://static.nautil.us/2408_7cac11e2f46ed46c339ec3d569853759.png&quot; alt=&quot;Sapolsky_TH-F1&quot; width=&quot;314&quot; height=&quot;177&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;span class=&quot;article-tag&quot;&gt;&lt;span class=&quot;article-tag&quot;&gt;&lt;span class=&quot;article-tag-focus&quot;&gt;&lt;a href=&quot;http://nautil.us/term/f/Physics&quot;&gt;Also in Physics&lt;/a&gt;&lt;/span&gt;  &lt;/span&gt;&lt;/span&gt;
&lt;h4 class=&quot;article-title&quot;&gt;&lt;a href=&quot;http://nautil.us/issue/9/Time/the-quantum-mechanics-of-fate&quot; class=&quot;obnd_lnk&quot; data-trval=&quot;the-quantum-mechanics-of-fate&quot; data-trlbl=&quot;foc_rec&quot; data-tract=&quot;internal_art&quot;&gt;The Quantum Mechanics of Fate&lt;/a&gt;&lt;/h4&gt;
&lt;p class=&quot;article-author&quot;&gt;By George Musser&lt;/p&gt;
&lt;p&gt;“The objective world simply is, it does not happen,” wrote mathematician and physicist Hermann Weyl in 1949. From his point of view, the universe is laid out in time as surely as it is laid out in space. Time does...&lt;strong&gt;&lt;a href=&quot;http://nautil.us/issue/9/Time/the-quantum-mechanics-of-fate&quot; class=&quot;obnd_lnk&quot; data-trval=&quot;the-quantum-mechanics-of-fate&quot; data-trlbl=&quot;foc_rec&quot; data-tract=&quot;internal_art&quot;&gt;READ MORE&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;/article&gt;&lt;/div&gt;

&lt;p&gt;&lt;span class=&quot;dropcap&quot;&gt;I&lt;/span&gt;f there is a founding document for the modern study of aging, it may be &lt;em&gt;An Unsolved Problem of Biology&lt;/em&gt; by Sir Peter Medawar. Medawar was a Nobel Prize-winning biologist, as well as a witty and sometimes scathing writer of essays and books. In &lt;em&gt;An Unsolved Problem of Biology&lt;/em&gt;, Medawar pitted two explanations for aging against each other: On one hand was “innate senescence,” or aging as biological necessity. On the other was the “wearing out” theory of aging—aging due to the “accumulated effects of recurrent stress.” The former is biology, the latter physics. Innate senescence implies that aging and death are dictated by evolution to make space for younger generations.&lt;/p&gt;
&lt;p&gt;The idea of innate senescence suggests that we have a master clock inside of us that counts down the hours of our lives. There are indeed clocks like this. The most famous are telomeres—little snippets of DNA which get shortened each time a cell divides. The study of telomeres has been controversial: It is not clear if telomere shortening is a cause or an effect of aging. Telomeres do not shorten in constant amounts—while there is a minimum amount that comes off at each cell division, they will shorten at a faster rate if the cell has been damaged through other means. Many researchers now believe that telomere shortening is more of a symptom of aging than its cause.&lt;/p&gt;
&lt;blockquote class=&quot;pull-quote&quot;&gt;
&lt;p&gt;Life pits biology against physics in mortal combat.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Medawar himself argued for the “wearing out” theory—the physics viewpoint on aging. First, he said, it is difficult to see how natural selection could have selected for senescence, because we don’t reproduce in our elderly years and natural selection is driven by differences in reproduction rates. Second, it is unnecessary to actively kill off older individuals to keep an aging population small. Random chance can accomplish this on its own.&lt;/p&gt;
&lt;p&gt;Medawar argued that a biological master clock for aging is unnecessary. To illustrate why, he pointed to a decidedly non-living example: Test tubes in a lab. Assume test tubes break from time to time by accident. To keep the total number of test tubes constant, a fresh supply is purchased every week. After a few months pass, how many young test tubes are there, and how many are old? If we assume that the probability of accidental breakage is independent of age (a sensible assumption), and plot the number of test tubes versus the age of each test tube, we get a concave, exponential decay curve that looks like a child’s slide. This “life curve” has a steep drop at the top, and it’s flat on the bottom.&lt;/p&gt;
&lt;img src=&quot;http://static.nautil.us/9212_8386fa112ba70c3f60b6907d3812bb9e.png&quot; width=&quot;733&quot; alt=&quot;&quot;/&gt;&lt;span class=&quot;caption&quot;&gt;&lt;strong&gt;Death Without Aging:&lt;/strong&gt; A computer simulated life curve for randomly breaking test tubes and an exponential fitting curve (in red). The vertical axis is the number of test tubes in each age group, and the horizontal axis is the age of test tubes in weeks.&lt;/span&gt;&lt;span class=&quot;credit&quot;&gt;Peter Hoffmann&lt;/span&gt;
&lt;p&gt;Although the test tubes are not aging (old test tubes do not break easier than young ones), the constant probability of breakage diminishes the number of old test tubes significantly. Now, suppose that humans, like test tubes, were equally likely to die at any age. The number of old people would still be small. Probability would catch up with us eventually.&lt;/p&gt;
&lt;p&gt;The trouble is, life curves plotted for human populations do not look like Medawar’s test tube curve. They start out rather flat at the top, with a small number of losses at young age (except at birth). Then at some age, the curve suddenly drops. To obtain such a curve, we need to add another assumption to Medawar’s test tube model: Test tubes must accumulate tiny cracks over time, increasing their risk of breaking. In other words, they must age. If the risk of breaking increases exponentially, we get something called the Gompertz-Makeham law. This law matches human life curves quite well. In the language of test tubes, the law includes both a constant and an exponentially increasing risk of breakage. This exponential increase has been observed in humans, for whom the risk of death doubles every seven years after age 30.&lt;/p&gt;
&lt;p&gt;What is the origin of this exponential increase? Thermal motion is not the only source of damage in our cells. Some regular processes, especially metabolism in our mitochondria, are not perfect and tend to &lt;a href=&quot;http://nautil.us/issue/36/aging/yes-life-in-the-fast-lane-kills-you&quot; target=&quot;_blank&quot;&gt;produce radicals&lt;/a&gt;—highly reactive atoms that can damage DNA.  Together, thermal noise and free radical production constitute a background risk of cell damage. The damage is usually repaired, or, &lt;a href=&quot;http://nautil.us/issue/23/dominoes/the-executioner-we-cant-live-without&quot; target=&quot;_blank&quot;&gt;if a cell is deemed beyond repair&lt;/a&gt;, the cell is induced to commit suicide—a process called apoptosis. Usually, a stem cell replaces it.&lt;/p&gt;
&lt;blockquote class=&quot;pull-quote&quot;&gt;
&lt;p&gt;Eliminating cancer or Alzheimer’s disease would improve lives, but it would not make us immortal, or even allow us to live significantly longer.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Eventually, though, the damage accumulates. DNA can only be repaired when there is an intact replica to copy. Damaged proteins unfold and start sticking to each other, forming aggregates. The cell’s defense and apoptosis mechanism become compromised. “Senescent cells” start accumulating in organs, leading to inflammation. Stem cells are not activated, or become depleted. Mitochondria become damaged, reducing energy supply in cells, which is needed to power the molecular machines repairing DNA. It’s a vicious cycle—or, in technical jargon, a positive feedback loop. Mathematically, this positive feedback loop leads to an exponential increase in risk, which can explain the shape of human life curves.&lt;/p&gt;
&lt;p&gt;The scientific literature is full of explanations for aging: Protein aggregation, DNA damage, inflammation, telomeres. But these are the biological responses to an underlying cause, which is accumulating damage through thermal and chemical degradation. To prove that thermal damage effects really do cause aging, we would need to observe humans living with different internal temperatures. This is not possible—but there are organisms that can be subjected to various internal temperatures without immediate harm. In a recent paper in &lt;em&gt;Nature&lt;/em&gt;, a team at Harvard Medical School determined the temperature dependence of aging in the roundworm &lt;em&gt;C. elegans&lt;/em&gt;, a simple and well-studied creature. They found that the shape of the survival curve remained essentially the same, but it was stretched or contracted as the temperature was changed. Creatures raised at lower temperature enjoyed a stretched survival curve, while worms exposed to higher temperature lived shorter lives.&lt;/p&gt;
&lt;img src=&quot;http://static.nautil.us/9233_88052b22c8c2349c0599bd39a654c534.png&quot; width=&quot;733&quot; alt=&quot;&quot;/&gt;Kasman / Pixabay
&lt;p&gt;&lt;span&gt;What’s more, the stretch factor depended on temperature according to a pattern familiar to every scientist: It was the same as the dependence of the rate of chemical bond breakage on the temperature of random thermal motion.&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;I’ve even seen a potential connection between bond breaking and human aging in my own lab. When I first encountered the Gompertz-Makeham law, it looked oddly familiar. In my lab we study the survival probability of single molecular bonds using an atomic force microscope, which can measure the minute forces acting between two molecules. In a typical experiment, we attach one protein to a flat surface and another to the tip of a small cantilever spring. We let the two proteins bind to each other, then slowly pull on the spring to apply an increasing force to the two molecules. Eventually, the bond between two molecules breaks, and we measure the force needed to achieve that breaking.&lt;/p&gt;
&lt;p&gt;This is a random process, initiated by thermal motion. Each time we do the experiment, the breakage force is different. But the survival probability of the bonds plotted against applied force looks just like human survival plotted versus age. The similarity resonates with the &lt;em&gt;C. elegans&lt;/em&gt; results, which suggest a possible connection between breaking protein bonds and aging—and between aging and thermal motion.&lt;/p&gt;
&lt;img src=&quot;http://static.nautil.us/9220_e4d09d3f57c2c971c8b2bf8efb416a0a.png&quot; width=&quot;733&quot; alt=&quot;&quot;/&gt;&lt;span class=&quot;caption&quot;&gt;&lt;strong&gt;A Common Death:&lt;/strong&gt; Left: Human life curve with Gompertz-Makeham fitting line. Right: Survival plot for single protein bonds subjected to increasing force. The mathematical form of the two curves is identical.&lt;/span&gt;&lt;span class=&quot;credit&quot;&gt;Peter Hoffmann&lt;/span&gt;

&lt;p&gt;&lt;span class=&quot;dropcap&quot;&gt;T&lt;/span&gt;here is a vigorous discussion inside the aging research community about whether to classify aging as a disease. Many researchers studying specific diseases, cellular systems, or molecular components would like to see their favorite research subject take the mantle of “the cause” of aging. But the sheer number of possibilities being put forward refutes the very possibility. They can’t all be the cause of aging. Leonard Hayflick, the original discoverer of cellular aging, pointed out in his provocatively titled article “Biological Aging Is No Longer an Unsolved Problem” that the “common denominator that underlies all modern theories of aging is change in molecular structure and, hence, function.” The ultimate cause, according to Hayflick, is an “increasing loss of molecular fidelity or increasing molecular disorder.” This loss of fidelity and increase in disorder will manifest itself—by its very nature—randomly and therefore differently for different people. But the ultimate cause remains the same.&lt;/p&gt;
&lt;p&gt;If this interpretation of the data is correct, then aging is a natural process that can be reduced to nanoscale thermal physics—and not a disease. Up until the 1950s the great strides made in increasing human life expectancy, were almost entirely due to the elimination of infectious diseases, a constant risk factor that is not particularly age dependent. As a result, life expectancy (median age at death) increased dramatically, but the maximum life span of humans did not change. An exponentially increasing risk eventually overwhelms any reduction in constant risk. Tinkering with constant risk is helpful, but only to a point: The constant risk is environmental (accidents, infectious disease), but much of the exponentially increasing risk is due to internal wear. Eliminating cancer or Alzheimer’s disease would improve lives, but it would not make us immortal, or even allow us to live significantly longer.&lt;/p&gt;
&lt;p&gt;That doesn’t mean there is nothing we can do. More research into specific molecular changes in aging is needed. This may show us if there are key molecular components that are the first to break down, and whether that breakdown leads to the subsequent cascade of failure. If there are such key components, we would have clear targets for interventions and repair, possibly through nanotechnology, stem cell research, or gene editing. It’s worth a try. But we need to be clear about one thing: We’ll never defeat the laws of physics.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Peter Hoffmann is a professor of physics at Wayne State University and the associate dean of research in the College of Liberal Arts and Sciences.&lt;/em&gt;&lt;/p&gt;
&lt;section class=&quot;leaderboard-ad-belt&quot;&gt;&lt;div class=&quot;leaderboard-ad-belt-inner adarticle&quot;&gt;&lt;div id=&quot;div-gpt-ad-1380044019755-0&quot; class=&quot;leaderboard-ad&quot;/&gt;
&lt;/div&gt;
&lt;/section&gt;</description>
<pubDate>Wed, 21 Feb 2018 11:14:36 +0000</pubDate>
<dc:creator>dnetesn</dc:creator>
<og:type>website</og:type>
<og:url>http://nautil.us/issue/36/aging/physics-makes-aging-inevitable-not-biology</og:url>
<og:title>Physics Makes Aging Inevitable, Not Biology - Issue 36: Aging - Nautilus</og:title>
<og:description>The inside of every cell in our body is like a crowded city, filled with tracks, transports, libraries, factories, power plants, and&amp;#8230;</og:description>
<og:image>http://static.nautil.us/9230_c879ec4dfeaa4d0f14f8f395a09941c2.png</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>http://nautil.us/issue/36/aging/physics-makes-aging-inevitable-not-biology</dc:identifier>
</item>
<item>
<title>Ask HN: What&amp;#039;s the best algorithms and data structures online course?</title>
<link>https://news.ycombinator.com/item?id=16428309</link>
<guid isPermaLink="true" >https://news.ycombinator.com/item?id=16428309</guid>
<description>&lt;tr class=&quot;athing comtr&quot; id=&quot;16428949&quot; readability=&quot;2.8082191780822&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16429224&quot; readability=&quot;2.2020202020202&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16429567&quot; readability=&quot;2.5337837837838&quot;&gt;&lt;td&gt;
&lt;table border=&quot;0&quot; readability=&quot;1.2668918918919&quot;&gt;&lt;tr readability=&quot;2.5337837837838&quot;&gt;&lt;td class=&quot;ind&quot;&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;1&quot; width=&quot;80&quot;/&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;default&quot;&gt;

&lt;br/&gt;&lt;div class=&quot;comment&quot;&gt;&lt;span class=&quot;c00&quot;&gt;Would you say this is good for someone who has recently graduated and has been in industry for a year or so to refresh on?&lt;/span&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430041&quot; readability=&quot;5.5690607734807&quot;&gt;&lt;td&gt;
&lt;table border=&quot;0&quot; readability=&quot;2.7845303867403&quot;&gt;&lt;tr readability=&quot;5.5690607734807&quot;&gt;&lt;td class=&quot;ind&quot;&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;1&quot; width=&quot;120&quot;/&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;default&quot;&gt;

&lt;br/&gt;&lt;div class=&quot;comment&quot;&gt;&lt;span class=&quot;c00&quot;&gt;They touch on a bunch of decently exotic data structures like van Emde Boas trees and things like cache oblivious data structures. If you're comfortable with data structures and algorithm design (which it sounds like you are, from your description) it should be accessible. At the end of the day it's just a graduate level CS course.&lt;/span&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16429462&quot; readability=&quot;1.2&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16429725&quot; readability=&quot;11.773847802787&quot;&gt;&lt;td&gt;
&lt;table border=&quot;0&quot; readability=&quot;5.8869239013934&quot;&gt;&lt;tr readability=&quot;11.773847802787&quot;&gt;&lt;td class=&quot;ind&quot;&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;1&quot; width=&quot;0&quot;/&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;default&quot; readability=&quot;12.226688102894&quot;&gt;

&lt;br/&gt;&lt;div class=&quot;comment&quot; readability=&quot;24.059275521405&quot;&gt;&lt;span class=&quot;c00&quot;&gt;I know its not an online course and its a relatively massive tome, but I'd recommend just working through &quot;Introduction to Algorithms&quot; by Cormen/Leiserston/Rivest/Stein [1].&lt;/span&gt;
&lt;p&gt;&lt;span class=&quot;c00&quot;&gt;This book has great explanations and exercises for everything you could want to learn from the basics of sorting and algorithmic design and analysis, to graph algorithms, linear programming, and dynamic programming.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;c00&quot;&gt;It lacks some degree of depth on more advanced topics, but if you work your way through it and actually implement what you read and do the exercises, you will be more than well enough equipped to take on just about any problem.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;c00&quot;&gt;The key is going to be to actually implement what you read/learn, I think it might take you a little more time than watching an online course, but in the long run it will give you a much deeper knowledge of the material.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;c00&quot;&gt;1. &lt;a href=&quot;https://www.amazon.com/Introduction-Algorithms-Thomas-H-Cormen/dp/0262531968&quot; rel=&quot;nofollow&quot;&gt;https://www.amazon.com/Introduction-Algorithms-Thomas-H-Corm...&lt;/a&gt; &lt;/span&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430307&quot; readability=&quot;2.5909090909091&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16431147&quot; readability=&quot;12.636465324385&quot;&gt;&lt;td&gt;
&lt;table border=&quot;0&quot; readability=&quot;6.3182326621924&quot;&gt;&lt;tr readability=&quot;12.636465324385&quot;&gt;&lt;td class=&quot;ind&quot;&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;1&quot; width=&quot;80&quot;/&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;default&quot; readability=&quot;12.636465324385&quot;&gt;

&lt;br/&gt;&lt;div class=&quot;comment&quot; readability=&quot;24.856651376147&quot;&gt;&lt;span class=&quot;c00&quot;&gt;&amp;gt; Isn't this book too academical for any practical learning of algorithms and data structures?&lt;/span&gt;
&lt;p&gt;&lt;span class=&quot;c00&quot;&gt;I don't think so, I've worked through it and I didn't find it that difficult/academic. But I actually don't read a lot of computer science books / textbooks so I don't really have much to compare it to other than mathematical texts which I do read a lot of.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;c00&quot;&gt;If you don't like proofs or math then its probably not the best text to work through, on the other hand, if you like rigorously understanding the material I would highly recommend it.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;c00&quot;&gt;Either way, from what I remember it gives psuedocode for just about everything and has lots of graphs and pictures for elucidating the material, so you could probably just skip the math if you have an allergy to corrolaries, theorems, and proofs. Admittedly, that extra insight is probably a lot of the reason I liked it so much. &lt;/span&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430388&quot; readability=&quot;1.0444444444444&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16429791&quot; readability=&quot;3.1611570247934&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430193&quot; readability=&quot;5.6141235813367&quot;&gt;&lt;td&gt;
&lt;table border=&quot;0&quot; readability=&quot;2.8070617906683&quot;&gt;&lt;tr readability=&quot;5.6141235813367&quot;&gt;&lt;td class=&quot;ind&quot;&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;1&quot; width=&quot;0&quot;/&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;default&quot; readability=&quot;6.5498108448928&quot;&gt;

&lt;br/&gt;&lt;div class=&quot;comment&quot; readability=&quot;12.428940568475&quot;&gt;&lt;span class=&quot;c00&quot;&gt;It's not really a course but I found InterviewBit [0] a great resource. It structures everything around moving from simpler to more complex data structures and algorithms. It's kind of learning by doing lots and lots of questions. You have to complete enough problems in one section to move onto the next.&lt;/span&gt;
&lt;p&gt;&lt;span class=&quot;c00&quot;&gt;I spent a hundred hours going through the various tests and it showed the power of functional programming / recursion. The questions that took me much longer than average were the ones where I had a bug and had to track it down. The recursive problems didn't suffer from this, ie I would get the solution pretty much correct first time. This could just have been the questions / my programming style but I found it eye opening.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;c00&quot;&gt;[0]: &lt;a href=&quot;https://www.interviewbit.com/&quot; rel=&quot;nofollow&quot;&gt;https://www.interviewbit.com/&lt;/a&gt; &lt;/span&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16428392&quot; readability=&quot;1.6094420600858&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16429258&quot; readability=&quot;2.0736434108527&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16429643&quot; readability=&quot;3.6534296028881&quot;&gt;&lt;td&gt;
&lt;table border=&quot;0&quot; readability=&quot;1.826714801444&quot;&gt;&lt;tr readability=&quot;3.6534296028881&quot;&gt;&lt;td class=&quot;ind&quot;&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;1&quot; width=&quot;40&quot;/&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;default&quot; readability=&quot;3.6534296028881&quot;&gt;

&lt;br/&gt;&lt;div class=&quot;comment&quot; readability=&quot;6.86328125&quot;&gt;&lt;span class=&quot;c00&quot;&gt;Tim Roughgarden is a fantastic teacher. I personally love his style and speed. He throws in some humor here and there and makes learning a lot of fun. His lectures on graphs are absolutely brilliant.&lt;/span&gt;
&lt;p&gt;&lt;span class=&quot;c00&quot;&gt;This same course is available on Coursera as well. &lt;/span&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430810&quot; readability=&quot;3.0031948881789&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16429813&quot; readability=&quot;4.2380952380952&quot;&gt;&lt;td&gt;
&lt;table border=&quot;0&quot; readability=&quot;2.1190476190476&quot;&gt;&lt;tr readability=&quot;4.2380952380952&quot;&gt;&lt;td class=&quot;ind&quot;&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;1&quot; width=&quot;80&quot;/&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;default&quot;&gt;

&lt;br/&gt;&lt;div class=&quot;comment&quot;&gt;&lt;span class=&quot;c00&quot;&gt;Yes. Same as Coursera. I took this on Coursera only, before specialization thing happened. Don't know if the course videos and exercises are fully available for audit purpose.&lt;/span&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16428486&quot; readability=&quot;4.3681318681319&quot;&gt;&lt;td&gt;
&lt;table border=&quot;0&quot; readability=&quot;2.1840659340659&quot;&gt;&lt;tr readability=&quot;4.3681318681319&quot;&gt;&lt;td class=&quot;ind&quot;&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;1&quot; width=&quot;40&quot;/&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;default&quot;&gt;

&lt;br/&gt;&lt;div class=&quot;comment&quot;&gt;&lt;span class=&quot;c00&quot;&gt;Thanks, I've looked at the syllabus and it seems to be exactly what I'm looking for (Asymptotic analysis, and coverage of the most widely known algorithms).&lt;/span&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16428939&quot; readability=&quot;2.4893617021277&quot;&gt;&lt;td&gt;
&lt;table border=&quot;0&quot; readability=&quot;1.2446808510638&quot;&gt;&lt;tr readability=&quot;2.4893617021277&quot;&gt;&lt;td class=&quot;ind&quot;&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;1&quot; width=&quot;40&quot;/&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;default&quot;&gt;

&lt;br/&gt;&lt;div class=&quot;comment&quot;&gt;&lt;span class=&quot;c00&quot;&gt;Second this recommendation really enjoyed these courses as well. Tim explains everything in an easy to follow way.&lt;/span&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16429778&quot; readability=&quot;1.5102040816327&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430232&quot; readability=&quot;7.5355029585799&quot;&gt;&lt;td&gt;
&lt;table border=&quot;0&quot; readability=&quot;3.7677514792899&quot;&gt;&lt;tr readability=&quot;7.5355029585799&quot;&gt;&lt;td class=&quot;ind&quot;&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;1&quot; width=&quot;0&quot;/&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;default&quot; readability=&quot;3.3491124260355&quot;&gt;

&lt;br/&gt;&lt;div class=&quot;comment&quot; readability=&quot;6.2246835443038&quot;&gt;&lt;span class=&quot;c00&quot;&gt;If your eventual goal after learning the basics is programming questions for interviews, there are a tons of resources like leetcode, interviewbit, geeksforgeeks. I started writing some of the FAQ with explanations here[1], check it out to see if it is of any help for you.&lt;/span&gt;
&lt;p&gt;&lt;span class=&quot;c00&quot;&gt;[1] : &lt;a href=&quot;http://letstalkalgorithms.com/&quot; rel=&quot;nofollow&quot;&gt;http://letstalkalgorithms.com/&lt;/a&gt; &lt;/span&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16429987&quot; readability=&quot;3.3720930232558&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430542&quot; readability=&quot;0.92079207920792&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430120&quot; readability=&quot;1.6377551020408&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16431498&quot; readability=&quot;1.3793103448276&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430941&quot; readability=&quot;1.3541666666667&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16431596&quot; readability=&quot;2.4812030075188&quot;&gt;&lt;td&gt;
&lt;table border=&quot;0&quot; readability=&quot;1.2406015037594&quot;&gt;&lt;tr readability=&quot;2.4812030075188&quot;&gt;&lt;td class=&quot;ind&quot;&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;1&quot; width=&quot;40&quot;/&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;default&quot;&gt;

&lt;br/&gt;&lt;div class=&quot;comment&quot;&gt;&lt;span class=&quot;c00&quot;&gt;Yeah I'm currently going through this course. Some of it is going over my head but I get the basic concepts&lt;/span&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16429950&quot; readability=&quot;3.8333333333333&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430498&quot; readability=&quot;2.7970297029703&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16429766&quot; readability=&quot;4.4867549668874&quot;&gt;&lt;td&gt;
&lt;table border=&quot;0&quot; readability=&quot;2.2433774834437&quot;&gt;&lt;tr readability=&quot;4.4867549668874&quot;&gt;&lt;td class=&quot;ind&quot;&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;1&quot; width=&quot;0&quot;/&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;default&quot;&gt;

&lt;br/&gt;&lt;div class=&quot;comment&quot;&gt;&lt;span class=&quot;c00&quot;&gt;Is it wise to do any of these courses without taking a course in linear algebra first? I started watching Skiena's algorithm course on youtube recently and he seemed to really emphasize finishing a course in linear algebra before taking any algorithm course. Thoughts?&lt;/span&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430732&quot; readability=&quot;2.0808080808081&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430535&quot; readability=&quot;3.1404958677686&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430081&quot; readability=&quot;2.2159090909091&quot;&gt;&lt;td&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430111&quot; readability=&quot;5.5178571428571&quot;&gt;&lt;td&gt;
&lt;table border=&quot;0&quot; readability=&quot;2.7589285714286&quot;&gt;&lt;tr readability=&quot;5.5178571428571&quot;&gt;&lt;td class=&quot;ind&quot;&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;1&quot; width=&quot;80&quot;/&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;default&quot;&gt;

&lt;br/&gt;&lt;div class=&quot;comment&quot;&gt;&lt;span class=&quot;c00&quot;&gt;Linear algebra isn’t a prerequisite for learning data structures and algorithms. Though you typically do find linear algebra to be part of the lower division computer science curriculum at most colleges. I would recommend you take a course in it, I argue it expands one’s problem-solving mental models.&lt;/span&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430624&quot; readability=&quot;5.3235294117647&quot;&gt;&lt;td&gt;
&lt;table border=&quot;0&quot; readability=&quot;2.6617647058824&quot;&gt;&lt;tr readability=&quot;5.3235294117647&quot;&gt;&lt;td class=&quot;ind&quot;&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;1&quot; width=&quot;120&quot;/&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;default&quot;&gt;

&lt;br/&gt;&lt;div class=&quot;comment&quot;&gt;&lt;span class=&quot;c00&quot;&gt;I certainly agree. However, if OP is simply referring to learning the typical algorithms presented in an undergraduate CS course, then linear algebra isn't a strict prerequisite.&lt;/span&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;athing comtr&quot; id=&quot;16430298&quot; readability=&quot;3.3939393939394&quot;&gt;&lt;td&gt;
&lt;table border=&quot;0&quot; readability=&quot;1.6969696969697&quot;&gt;&lt;tr readability=&quot;3.3939393939394&quot;&gt;&lt;td class=&quot;ind&quot;&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;1&quot; width=&quot;40&quot;/&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;default&quot;&gt;

&lt;br/&gt;&lt;div class=&quot;comment&quot;&gt;&lt;span class=&quot;c00&quot;&gt;I took both of Tim Roughgarden's algorithm courses on Coursera, and in my opinion you don't need to know linear algebra to complete them.&lt;/span&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;</description>
<pubDate>Wed, 21 Feb 2018 10:03:58 +0000</pubDate>
<dc:creator>zabana</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://news.ycombinator.com/item?id=16428309</dc:identifier>
</item>
<item>
<title>Why has CPU frequency ceased to grow? (2014)</title>
<link>https://software.intel.com/en-us/blogs/2014/02/19/why-has-cpu-frequency-ceased-to-grow</link>
<guid isPermaLink="true" >https://software.intel.com/en-us/blogs/2014/02/19/why-has-cpu-frequency-ceased-to-grow</guid>
<description>&lt;p&gt;&lt;span class=&quot;floatLeft&quot;&gt;&lt;img hspace=&quot;10&quot; class=&quot;floatLeft&quot; src=&quot;https://software.intel.com/sites/default/files/managed/45/fa/cpu-frequency-image1.jpg&quot; alt=&quot;&quot;/&gt;&lt;/span&gt; All of you probably recall the rapid rate of CPU frequency advancement at the end of the last century and beginning of this one.  Tens of megahertz rapidly transformed into hundreds, and then hundreds of megahertz quickly became a full gigahertz, then a gigahertz and a bit, finally two gigs and a bit.&lt;/p&gt;
&lt;p&gt;However, in the last few years, we’ve seen the core CPU frequency growth has slowed. The 10 GHz result is still as unreachable now as it was five years ago. Why the slow down? What is the obstacle for an increasingly expanding rate of frequency?&lt;/p&gt;
&lt;h2&gt;&quot;Hot&quot; gigahertz&lt;/h2&gt;
&lt;p&gt;There is an opinion among experts that increased frequency growth will result in highly significant heat emissions. Others think that you can just turn &quot;a switch&quot; that will increase the frequency – and it will be increased as desired. But there are also strong concerns that the increased frequency will raise the CPU temperature so much that it will cause an actual physical melt down.  Note that many CPU manufactures will not allow a meltdown to happen, as the CPU has internal temperature monitors and will shut down the CPU before any catastrophic failure occurs.&lt;/p&gt;
&lt;p&gt;This opinion is expressed by computer users and, moreover, it has been proven by overclockers’ successes, as they speed up the processors two and more times as fast, they need to attach as powerful a cooling system as possible.&lt;/p&gt;
&lt;p&gt;We should validate that the &quot;switch&quot; mentioned above actually exists, as well as the heat emission problem, but these are just part of the battle for expanding gigahertz.&lt;/p&gt;
&lt;h2&gt;The main brake&lt;/h2&gt;
&lt;p&gt;Different processor architectures have their own difficulties with overclocking. Specifically here we’ll focus on superscalar architecture including the x86 architecture, which is the most popular among Intel® products.&lt;/p&gt;
&lt;p&gt;To address the problems related to frequency growth, it’s important to identify what prevents its development. Depending on architecture research level, there are a variety of limiting parameters. However, there’s one area of research that focuses on one parameter, which means that there is the only one limitation or main brake that needs to be removed in order to increase frequency.&lt;/p&gt;
&lt;h2&gt;The conveyor&lt;/h2&gt;
&lt;p&gt;The main limitation is found in the conveyor level, which is integral to superscalar structure. Functionally, every execution of a processor’s instruction is divided into several steps as illustrated by the diagram below.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://software.intel.com/sites/default/files/managed/2c/0e/cpu-frequency-image2.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;These steps follow each other sequentially, and each is executed on a separate computing device.&lt;/p&gt;
&lt;p&gt;When execution of a specific step is completed, the computing device can then be used to execute a different instruction.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://software.intel.com/sites/default/files/managed/42/f9/cpu-frequency-image3.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;As you see on the diagram above, the first computing device executes the first step of the first instruction during the &lt;strong&gt;t1&lt;/strong&gt; time period. By the beginning of the &lt;strong&gt;t2&lt;/strong&gt; period, the first step has been completed and the second step can begin on the second device. The first device is now free and ready to begin the first step of next instruction, and so on. During the &lt;strong&gt;t4&lt;/strong&gt; period, different steps of four instructions can be executed.&lt;/p&gt;
&lt;p&gt;What does this have to do with frequency?  Actually, different stages can vary in execution time. At the same time, different steps of the same instruction are executed during different clock ticks. Clock tick length (and frequency as well) of the processor should fit the longest step. The diagram below shows the longest step is the third.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://software.intel.com/sites/default/files/managed/85/92/cpu-frequency-image4.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;There’s no advantage in setting the clock tick length shorter than the longest step, even though it is possible technologically, as no actual processor acceleration will occur.&lt;/p&gt;
&lt;p&gt;Suppose that the longest step requires 500 ps (picosecond) for execution. This is the clock tick length when the computer frequency is 2 GHz. Then, we set a clock tick two times shorter, which would be 250 ps, and everything but the frequency remains the same. Now, what was identified as the longest step is executed during two clock ticks, which together takes 500 ps as well. Nothing is gained by making this change while designing such a change becomes much more complicated and heat emission increases.&lt;/p&gt;
&lt;p&gt;One could object to this and note that due to shorter clock ticks, the small steps will be executed faster, so the average speed will be greater. However, the following diagram shows that this is not the case.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://software.intel.com/sites/default/files/managed/36/a2/cpu-frequency-image5.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Initially, the execution will be much faster. But, beginning from the fourth clock tick, the third step and all of the following steps in our example will be delayed. This happens because the third computing device will be free every two clock ticks, not every clock tick. While it is busy with the third step of one instruction, the same step of another instruction cannot be executed. So, our hypothetical processor that uses 250 ps clock ticks will work at the same speed as the 500 ps processor, though nominally its frequency is two times higher.&lt;/p&gt;
&lt;h2&gt;The smaller the better&lt;/h2&gt;
&lt;p&gt;So, from the conveyor point of view, the only way to raise the frequency is to shorten the longest step. If we can reduce the longest step, there is a possibility to decrease the clock tick size up to this step—and, the smaller the clock tick, the higher the frequency.&lt;/p&gt;
&lt;p&gt;There are not many ways to influence the step length using available technologies. One of these ways is to develop a more advanced technological process. By reducing the physical size of the components of a processor, the faster it works. This happens because electrical impulses have to travel shorter distances, transistor switch time decreases, etc. Simply stated, everything speeds up uniformly. All steps are shortened uniformly, including the longest one, and the frequency can be increased as a result.&lt;/p&gt;
&lt;p&gt;It sounds quite simple, but the way down the nanometer scale is very complicated. Increased frequency depends heavily on the current level of technology and advances cannot move beyond these physical limitations. Nevertheless, processor manufacturers are continuously improving the technological processes, so the core CPU frequency is gradually increasing.&lt;/p&gt;
&lt;h2&gt;Cut the patient&lt;/h2&gt;
&lt;p&gt;Another way to raise the frequency in the example above is to divide-up the longest step into smaller steps. The instructions have been cut already. They have been cut several times successfully. Why not go on? The processor will work even faster!  Much work has been done by the processor architects to make the steps as efficient as possible and thus further dividing the steps into smaller steps will not only create a challenge, it may significantly impact overall CPU efficiency.&lt;/p&gt;
&lt;p&gt;Let’s use an analogy to building a house. A house is built floor by floor. We’ll assume a floor is analogous   to an instruction.  We’d like to divide building the floor into several parts. Initially starting with two parts; building of the floor itself and the finishing of that floor. While the finishing is being completed on the previous floor built, we can begin to build another floor, but only if the building and the finishing are performed by different teams. Sounds good.&lt;/p&gt;
&lt;p&gt;Now, let’s divide the two existing parts. Let’s split the finishing component into ceiling painting and wall papering. Easy enough. If the painters have finished one floor, they can go to another built floor, even if the paper-hangers haven’t completed their work on the first floor.&lt;/p&gt;
&lt;p&gt;And what about the actual building of the floors? For example, we’d like to divide the house building into wall building and ceiling building. We can do that but it isn’t useful to do so. We cannot build the walls of the next floor if the previous floor isn’t built. While we’ve made the division theoretically, we cannot fully employ wall and ceiling teams since at any given time, only one team can be working!&lt;/p&gt;
&lt;p&gt;The same problem is true in processors. There are some steps that are dependent on other steps, and it’s very hard to divide such steps as that would require extensive changes in processor architecture, as would be required to build several floors of a house at the same time.&lt;/p&gt;
&lt;h2&gt;To flip the switch&lt;/h2&gt;
&lt;p&gt;Let’s address overclockers now. They raise processor voltage for transistors to switch quicker, all the steps become shorter, and the frequency can be increased. It sounds so easy! But there are huge problems with heat emission. Here is the simplified formula of a processor’s power dissipation:&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;P ~ C&lt;sub&gt;dyn&lt;/sub&gt;*V&lt;sup&gt;2&lt;/sup&gt;*f&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;P = Power, C&lt;sub&gt;dyn&lt;/sub&gt; = dynamic capacitance, V = voltage, f = frequency&lt;/p&gt;
&lt;p&gt;Don’t worry if you don’t know what &lt;em&gt;dynamic capacitance&lt;/em&gt; is—the main thing that’s important here is voltage. It is squared! Looks awful…&lt;/p&gt;
&lt;p&gt;The reality is even worse. As stated before, voltage makes transistors work. A transistor is a kind of toggle. It needs to accumulate some charge to switch. The accumulation time is proportional to current, so if the current is big, a charge moves quicker. Current, in turn, is proportional to voltage.  So, the transistor switch speed is proportional to voltage. We need to take into consideration that processor frequency can be raised proportionally to transistor switch speed only. Let’s summarize:&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;f ~ V and P ~ C&lt;sub&gt;dyn&lt;/sub&gt;*V&lt;sup&gt;3&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Linear frequency growth causes power dissipation to be increasingly cubed! If the frequency is raised only twice, there will be eight times greater heat that must be accommodated or the processor will melt or shutdown.&lt;/p&gt;
&lt;p&gt;It’s obvious that this method of increasing the frequency is not suitable for processor manufacturers because of low efficiency. However, it is used by extreme overclockers.&lt;/p&gt;
&lt;h2&gt;Is that all?&lt;/h2&gt;
&lt;p&gt;There are instances when processor frequency has been increased a bit without voltage changing. It is possible in a very limited range, since processors are designed to work in widely varied conditions (which influences step length), so there is some frequency margin. For example, the longest step might take only 95% of the whole clock tick. This raises the possibility.  But remember, wrong overclocking can harm not only processor but you as well.&lt;/p&gt;
&lt;p&gt;There are some other ways to influence the step length which are much less important than what’s been discussed here. For example, temperature influences all electronic parts, but serious effects are seen only when temperature is very low.&lt;/p&gt;
&lt;p&gt;In conclusion, the struggle for increased frequency is extremely challenging. However, it is in progress, even though the frequency is increasing very slowly. But, take heart! Now that there are multicore processors, there is no reason why computers shouldn’t begin to work faster, whether due to higher frequency or because of parallel task execution. And with parallel task execution it provides even greater functionality and flexibility!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Original Russian blog with threads:&lt;/strong&gt;&lt;a href=&quot;http://habrahabr.ru/company/intel/blog/194836/&quot; rel=&quot;nofollow&quot;&gt;http://habrahabr.ru/company/intel/blog/194836/&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 21 Feb 2018 08:13:53 +0000</pubDate>
<dc:creator>Osiris</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://software.intel.com/en-us/blogs/2014/02/19/why-has-cpu-frequency-ceased-to-grow</dc:identifier>
</item>
</channel>
</rss>