<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>How to Be a Systems Thinker</title>
<link>https://www.edge.org/conversation/mary_catherine_bateson-how-to-be-a-systems-thinker</link>
<guid isPermaLink="true" >https://www.edge.org/conversation/mary_catherine_bateson-how-to-be-a-systems-thinker</guid>
<description>&lt;p class=&quot;rtecenter&quot;&gt;&lt;iframe allowfullscreen=&quot;&quot; frameborder=&quot;0&quot; height=&quot;360&quot; mozallowfullscreen=&quot;&quot; src=&quot;https://player.vimeo.com/video/257049449?color=e8e8e8&amp;amp;byline=0&amp;amp;portrait=0&quot; webkitallowfullscreen=&quot;&quot; width=&quot;640&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HOW TO BE A SYSTEMS THINKER&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At the moment, I’m asking myself how people think about complex wholes like the ecology of the planet, or the climate, or large populations of human beings that have evolved for many years in separate locations and are now re-integrating. To think about these things, I find that you need something like systems theory. So, I went back to thinking about systems theory two or three years ago, which I hadn’t for quite a long time.&lt;/p&gt;
&lt;p&gt;What prompted it was concern about the state of the world. One of the things that we’re all seeing is that a lot of work that has been done to enable international cooperation in dealing with various problems since World War II is being pulled apart. We’re seeing the progress we thought had been made in this country in race relations being reversed. We’re seeing the partial breakup—we don’t know how far that will go—of a united Europe. We’re moving ourselves back several centuries in terms of thinking about what it is to be human, what it is to share the same planet, how we’re going to interact and communicate with each other. We’re going to be starting from scratch pretty soon.&lt;/p&gt;
&lt;p&gt;Two or three years ago, I started getting invited to do things with the American Society for Cybernetics. I kept saying that I hadn't done anything or thought about that for years, but they persisted. I was invited to write a chapter for a huge handbook called &lt;em&gt;The Handbook of Human Computation&lt;/em&gt;. Basically, what they meant by human computation is human-computer collaboration of various sorts. I told them I didn't know anything about that, and they said, &quot;Since you don’t have time to write a chapter, please write the preface.&quot; I asked how I would do that if I couldn't write a chapter, and they said, &quot;We'll send you all the abstracts.&quot; I became quite cranky and told them to get someone else to do it, but they kept sending me things to read. First, I searched Google for what human computation was, and I found that I did know about some corners of the field. So, I wrote everything I knew about human computation, sent it in, and said to them, &quot;See, I don’t know anything about it.&quot; They published it.&lt;/p&gt;
&lt;p&gt;Then I went to the conference and I started to get back in the conversation with people working on AI. I had realized that I’d learned an awful lot as quite a young person, even as a child, from my parents, who were involved in the Cybernetic Macy Conferences right through the ‘50s. They and other figures that were involved, like Warren McCulloch or many other people, were drifting through the house and having conversations all the time, and I was listening.&lt;/p&gt;
&lt;p&gt;I didn’t go straight to AI; I was nibbling at edges of it. I had realized that our capacity to think about complex interactive systems seemed to be falling apart, that a great many efforts towards international cooperation were falling apart; states that involved multiple ethnic systems or dialects were breaking up; and, indeed, societies like the United States, with many ethnic groups and racial groups, were having a progressively harder time trying to cooperate.&lt;/p&gt;
&lt;p&gt;We all think with metaphors of various sorts, and we use metaphors to deal with complexity, but the way human beings use computers and AI depends on their basic epistemologies—whether they’re accustomed to thinking in systemic terms, whether they’re mainly interested in quantitative issues, whether they’re used to using games of various sorts. A great deal of what people use AI for is to simulate some pattern outside in the world. On the other hand, people use one pattern in the world as a metaphor for another one all the time.&lt;/p&gt;
&lt;p&gt;Americans are inclined to talk about the &quot;war against drugs,&quot; or the &quot;war against poverty,&quot; or the &quot;war against cancer,&quot; without questioning whether &quot;war&quot; is an appropriate metaphor. It’s a way of talking about complexity, but if it doesn’t fit, it will cause you to make errors in how you deal with your problems. The war on poverty failed partly because poverty is not something you can defeat, and that makes warfare an inappropriate metaphor. The same is true with the war on drugs, which has gotten us into some ugly situations.&lt;/p&gt;
&lt;p&gt;One of the problems when you bring technology into a new area is that it forces you to oversimplify. That is, the possibilities of AI have been there from the very beginning of thinking about computers, but there's always this feeling of disappointment that there are limitations to what you can do. We keep attempting to do more complex things.&lt;/p&gt;
&lt;p&gt;Until fairly recently, computers could not be said to learn. To create a machine that learns to think more efficiently was a big challenge. In the same sense, one of the things that I wonder about is how we'll be able to teach a machine to know what it doesn’t know but that it might need to know in order to address a particular issue productively and insightfully. This is a huge problem for human beings. It takes a while for us to learn to solve problems. And then it takes even longer for us to realize what we don’t know all that we would need to know to solve a particular problem, which obviously involves a lot of complexity.&lt;/p&gt;
&lt;p&gt;How do you deal with ignorance? I don’t mean how do you shut ignorance out. Rather, how do you deal with an awareness of what you don’t know, and you don’t know how to know, in dealing with a particular problem? When Gregory Bateson was arguing about human purposes, that was where he got involved in environmentalism. We were doing all sorts of things to the planet we live on without recognizing what the side effects would be and the interactions. Although, at that point we were thinking more about side effects than about interactions between multiple processes. Once you begin to understand the nature of side effects, you ask a different set of questions before you make decisions and projections and analyze what’s going to happen.&lt;/p&gt;
&lt;p&gt;The same thing is true, for instance, with drug testing. The first question people ask is, &quot;Does the drug work?&quot; But the next question should be, &quot;What else does the drug do besides dealing with the pathology?&quot; A certain number of drugs get pulled off the market every year when people realize that the long-side effects may be more serious than what they’re trying to correct.&lt;/p&gt;
&lt;p&gt;What the analog to that in the computer world is, I don’t know. What we do is try to set up processes for problem solving and supply the data for analysis, but we don’t give the machine a way of saying, &quot;What else should I know before I look at this question?&quot; There has been so much excitement and sense of discovery around the digital revolution that we’re at a moment where we overestimate what can be done with AI, certainly as it stands at the moment.&lt;/p&gt;
&lt;p&gt;One of the most essential elements of human wisdom at its best is humility, knowing that you don’t know everything. There’s a sense in which we haven’t learned how to build humility into our interactions with our devices. The computer doesn’t know what it doesn’t know, and it's willing to make projections when it hasn’t been provided with everything that would be relevant to those projections. How do we get there? I don’t know. It’s important to be aware of it, to realize that there are limits to what we can do with AI. It’s great for computation and arithmetic, and it saves huge amounts of labor. It seems to me that it lacks humility, lacks imagination, and lacks humor. It doesn’t mean you can’t bring those things into your interactions with your devices, particularly, in communicating with other human beings. But it does mean that elements of intelligence and wisdom—I like the word wisdom, because it's more multi-dimensional—are going to be lacking.&lt;/p&gt;
&lt;p&gt;As a child, I had the early conversations of the cybernetic revolution going on around me. I can look at examples and realize that when one of my parents was trying to teach me something, it was directly connected with what they were doing and thinking about in the context of cybernetics.  &lt;/p&gt;
&lt;p&gt;One of my favorite memories of my childhood was my father helping me set up an aquarium. In retrospect, I understand that he was teaching me to think about a community of organisms and their interactions, interdependence, and the issue of keeping them in balance so that it would be a healthy community. That was just at the beginning of our looking at the natural world in terms of ecology and balance. Rather than itemizing what was there, I was learning to look at the relationships and not just separate things.&lt;/p&gt;
&lt;p&gt;Bless his heart, he didn’t tell me he was teaching me about cybernetics. I think I would have walked out on him. Another way to say it is that he was teaching me to think about systems. Gregory coined the term &quot;schismogenesis&quot; in 1936, from observing the culture of a New Guinea tribe, the Iatmul, in which there was a lot of what he called schismogenesis. Schismogenesis is now called &quot;positive feedback&quot;; it’s what happens in an arms race. You have a point of friction, where you feel threatened by, say, another nation. So, you get a few more tanks. They look at that and say, &quot;They’re arming against us,&quot; and they get a lot more tanks. Then you get more tanks. And they get more tanks or airplanes or bombs, or whatever it is. That’s positive feedback.&lt;/p&gt;
&lt;p&gt;The alternative would be if you saw them getting tanks to say, &quot;I’d better get rid of my tanks. Let’s cool the arms race, instead of mutually escalating.&quot; Gregory was talking about that and didn’t really have a term for it, so he invented the term schismogenesis. Genesis to mean bringing into being greater and greater schisms, conflicts. That was before the concept of positive feedback had been coined. That’s what he was talking about, the kind of feedback that accelerates a process rather than controls it, which is a very important concept.                         &lt;/p&gt;
&lt;p&gt;I would say that the great majority of Americans still believe that &quot;positive feedback&quot; is when someone pats you on the back and says you did a good job. What positive feedback is saying is, do more of the same. So, if what you’re doing is taking heroin or quarreling with your neighbor, this is just going to lead to trouble. Negative feedback corrects what you’re doing. It’s not somebody saying, &quot;That was a lousy speech.&quot; It’s somebody saying, &quot;Reverse course. Stop building more bombs. Stop taking in more alcohol faster. Slow down.&quot; Negative feedback is corrective feedback.&lt;/p&gt;
&lt;p&gt;Gregory then wrote a paper about an arms race and made the move from thinking about the New Guinea tribe to the nature of arms races in the modern world, which we still have plenty of.&lt;/p&gt;
&lt;p&gt;At the beginning of the war, my parents, Margaret Mead and Gregory Bateson, had very recently met and married. They met Lawrence K. Frank, who was an executive of the Macy Foundation. As a result of that, both of them were involved in the Macy Conferences on Cybernetics, which continued then for twenty years. They still quote my mother constantly in talking about second-order cybernetics: the cybernetics of cybernetics. They refer to Gregory as well, though he was more interested in cybernetics as abstract analytical techniques. My mother was more interested in how we could apply this to human relations.&lt;/p&gt;
&lt;p&gt;My parents looked at the cybernetics conferences rather differently. My mother, who initially posed the concept of the cybernetics of cybernetics, second-order cybernetics, came out of the anthropological approach to participant observation: How can you do something and observe yourself doing it? She was saying, &quot;Okay, you’re inventing a science of cybernetics, but are you looking at your process of inventing it, your process of publishing, and explaining, and interpreting?&quot; One of the problems in the United States has been that pieces of cybernetics have exploded into tremendous economic activity in all of computer science, but much of the systems theory side of cybernetics has been sort of a stepchild. I firmly believe that it is the systems thinking that is critical.&lt;/p&gt;
&lt;p&gt;At the point where she said, &quot;You guys need to look at what you’re doing. What is the cybernetics of cybernetics?&quot; what she was saying was, &quot;Stop and look at your own process and understand it.&quot; Eventually, I suppose you do run into the infinite recursion problem, but I guess you get used to that.&lt;/p&gt;
&lt;p&gt;How do you know that you know what you know? When I think about the excitement of those early years of the cybernetic conferences, there have been several losses. One is that the explosion of devices and manufacturing and the huge economic effect of computer technology has overshadowed the epistemological curiosity on which it was built, of how we know what we know, and how that affects decision making.&lt;/p&gt;
&lt;p&gt;If you use the word &quot;cyber&quot; in our society now, people think that it means a device. It does not evoke the whole mystery of what maintains balance, or how a system is kept from going off kilter, which was the kind of thing that motivated the question in the first place. It’s probably not the first time that’s happened, that a technology with a very wide spectrum of uses has been so effective for certain problems that it’s obscured the other possible uses.&lt;/p&gt;
&lt;p&gt;People are not using cybernetic models as much as they should be. In thinking about medicine, for instance, we are thinking more than we used to about what happens when fifty years ago you had chicken pox and now you have shingles. What happened? How did the virus survive? It went into hiding. It took a different form. We’re finding examples of problems that we thought we’d solved but may have made worse.&lt;/p&gt;
&lt;p&gt;We have taller smoke stacks on factories now, trying to prevent smog and acid rain. What we’re getting is that the fumes are traveling further, higher up, and still coming down in the form of acid rain. Let’s look at that. Someone has tried to solve a problem, which they did—they reduced smog. But we still put smoke up the chimney and think it disappears. It isn't gone. It’s gone &lt;em&gt;somewhere&lt;/em&gt;. We need to look at the entire system. What happens to the smoke? What happens to the wash-off of fertilizer into brooks and streams? In that sense, we’re using the technology to correct a problem without understanding the epistemology of the problem. The problem is connected to a larger system, and it’s not solved by the quick fix.&lt;/p&gt;
&lt;p&gt;If you look back at the cybernetics conferences, you’d find a lot of examples that could be applied to social and human problems that have not been. Most people don’t learn about cybernetics. They buy devices. Cybernetics, because it developed a whole branch of communication theory, is a way of thinking, not an industry. In our relations with other nations, for instance, we get caught in schismogenesis—arms races, competitions, escalations of various sorts—without people being aware that that’s what’s happening, without them thinking through what needs to be attended to in order to solve a problem.&lt;/p&gt;
&lt;p&gt;We think that we can solve drug addiction by punitive police enforcement. Doesn’t work. In fact, it makes more jobs for policemen and prison guards. We are not using systems theory to think about social problems most of the time. Business problems, yes. There are specialists. Business schools even teach systems theory. But we’re not raising our children to be systems thinkers. That’s what we need to do.&lt;/p&gt;
&lt;p&gt;You don’t have to know a lot of technical terminology to be a systems thinker. One of the things that I’ve been realizing lately, and that I find fascinating as an anthropologist, is that if you look at belief systems and religions going way back in history, around the world, very often what you realize is that people have intuitively understood systems and used metaphors to think about them. The example that grabbed me was thinking about the pantheon of Greek gods—Zeus and Hera, Apollo and Demeter, and all of them. I suddenly realized that in the mythology they’re married, they have children, the sun and the moon are brother and sister. There are quarrels among the gods, and marriages, divorces, and so on. So you can use the Greek pantheon, because it is based on kinship, to take advantage of what people have learned from their observation of their friends and relatives.&lt;/p&gt;
&lt;p&gt;It turns out that the Greek religious system is a way of translating what you know about your sisters, and your cousins, and your aunts into knowledge about what’s happening to the weather, the climate, the crops, and international relations, all sorts of things. A metaphor is always a framework for thinking, using knowledge of this to think about that. Religion is an adaptive tool, among other things. It is a form of analogic thinking.&lt;/p&gt;
&lt;p&gt;The other thing that I like to talk about is that we carry an analog machine around with us all the time called our body. It’s got all these different organs that interact; they’re interdependent. If one of them goes out of kilter, the others go out of kilter, eventually. This is true in society. This is how dis-ease spreads through a community, because everything is connected.&lt;/p&gt;
&lt;p&gt;There are a couple of other things that are very striking. If you look at the Old Testament, the Hebrew Scriptures, what you see—which you can also see in young children—is that they start from the differences between things. Mommy’s not the same as Daddy. Daddy’s not the same as brother. I can remember my daughter learning the word &quot;Goggy,&quot; which obviously was &quot;Doggy.&quot; But then she said that the cow is a &quot;Goggy,&quot; because it had four legs, I guess. But then you have to learn to distinguish the cow from the dog. When we think about a child developing, you have to learn to distinguish between things—this is this and that is that. Starting with the Book of Genesis, each thing is created separately. They don’t evolve by differentiation. God separates the day from the night, the light from the dark, the dry land from the water. And then you end up with a large number of rules of things that have to be kept separate. You can’t weave two different kinds of fibers into the same fabric. You can’t plow with an ox and an ass, but must use two oxen.&lt;/p&gt;
&lt;p&gt;What you have is this process of differentiation, which is intellectually profound but only a beginning. Taxonomy is an essential basis for all we know about the natural world. We have learned to classify. A bee is not a butterfly. You can see that stage in many forms of religion and mythology. And then in some later forms, the switch is from making distinctions to recognizing relationships.&lt;/p&gt;
&lt;p&gt;What comes along if you look at the New Testament is Jesus keeps violating all the rules about keeping things separate, which makes people angry&lt;ins cite=&quot;mailto:Mary%20Catherine%20Bateson&quot; datetime=&quot;2018-03-29T12:32&quot;&gt;,&lt;/ins&gt; because that’s what they’ve been taught. He’s constantly posing the question, &quot;What’s the connection?&quot; And not, &quot;What’s the difference?&quot; You can see that this constant necessity of recognizing that things are separate and different and can be used in different ways, and then seeing that everything is connected, and how it’s connected and interdependent, that this is a sort of permanent balance in human intellect. If you look at the history of mythology, you can see people moving slowly forward. You can look at the history of science—things that were once equated we now see as separate. We can only go so far in breaking down more and more elementary particles, but we're still finding particles. We’re still interested in the separation of things, but we’re also still discovering relationships.&lt;/p&gt;
&lt;p&gt;I’ve become very much involved in issues around climate change. Climate change comes from proceeding on one path without recognizing how that will affect other aspects of our reality. Take it another step, one of the things that’s hard to get across to people is that when human beings are uncomfortable, they fight, or move. At this point we have a refugee crisis, migrations, people leaving areas where their ways of making a living don’t work any longer because of climate change. We also have conflict happening as one country wants to control more arable land—Lebensraum. So, people are fighting about land, or about fishing rights.&lt;/p&gt;
&lt;p&gt;Most people don’t realize it, but a myth has been put together about the so-called Arab Spring of a few years ago, where many Americans said, &quot;Oh, good, they’re rebelling against their authoritarian governments and they’re going to become democratic.&quot; Well, they didn’t. The cause of the Arab Spring was a five-year drought, with a lot of people having difficulty feeding their families, so they migrated from the villages to the cities, looking for jobs where they would be paid money and could buy food for their families. But there were no jobs in the cities, so they had revolutions.&lt;/p&gt;
&lt;p&gt;The tragedy of the cybernetic revolution, which had two phases, the computer science side and the systems theory side, has been the neglect of the systems theory side of it. We chose marketable gadgets in preference to a deeper understanding of the world we live in.&lt;/p&gt;
</description>
<pubDate>Sat, 14 Apr 2018 03:44:23 +0000</pubDate>
<dc:creator>raleighm</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.edge.org/conversation/mary_catherine_bateson-how-to-be-a-systems-thinker</dc:identifier>
</item>
<item>
<title>European Copyright Law Could Soon Get Worse</title>
<link>https://www.eff.org/deeplinks/2018/04/european-copyright-law-isnt-great-it-could-soon-get-lot-worse</link>
<guid isPermaLink="true" >https://www.eff.org/deeplinks/2018/04/european-copyright-law-isnt-great-it-could-soon-get-lot-worse</guid>
<description>&lt;p&gt;EFF has been writing about the upcoming European Digital Single Market directive on copyright &lt;a href=&quot;https://www.eff.org/deeplinks/2016/08/european-copyright-leak-exposes-plans-force-internet-subsidize-publishers&quot;&gt;for a long time now&lt;/a&gt;. But it's time to put away the keyboard, and pick up the phone, because the proposal just got worse—and it's headed for a crucial vote on June 20-21. &lt;/p&gt;
&lt;p&gt;For those who need no further introduction to the directive, which would impose an &lt;a href=&quot;https://www.eff.org/deeplinks/2017/10/end-game-european-upload-filtering-approaches&quot;&gt;upload filtering mandate&lt;/a&gt; on Internet platforms (Article 13) and a &lt;a href=&quot;https://www.eff.org/deeplinks/2016/08/european-copyright-leak-exposes-plans-force-internet-subsidize-publishers&quot;&gt;link tax in favor of news publishers&lt;/a&gt; (Article 11), you can skip to the &lt;a href=&quot;https://www.eff.org/deeplinks/2018/04/european-copyright-law-isnt-great-it-could-soon-get-lot-worse#action&quot;&gt;bottom of this post&lt;/a&gt;, where we link to an action that European readers can take to make their voice heard. But if you're new to this, here's a short version of how we got here and why we're worried.&lt;/p&gt;
&lt;h3&gt;A Brief History&lt;/h3&gt;
&lt;p&gt; The European Copyright Directive was enacted in 2001 and is now woefully out of date. Thanks in large part to the work of Pirate Party MEP Julia Reda, many good ideas for updating European copyright law were put forward in a &lt;a href=&quot;https://www.eff.org/deeplinks/2015/06/european-parliamentarians-vote-tomorrow-fix-our-broken-copyright-law&quot;&gt;report of the European Parliament&lt;/a&gt; in July 2015. The European Commission threw out most of these ideas, and instead released a legislative proposal in October 2016 that focused on &lt;a href=&quot;https://www.eff.org/deeplinks/2016/10/upload-filtering-mandate-would-shred-european-copyright-safe-harbor&quot;&gt;giving new powers to publishers&lt;/a&gt;. That proposal was referred to several of the committees of the European Parliament, with the Parliament's Legal Affairs (JURI) Committee taking the lead.&lt;/p&gt;
&lt;p&gt;As the final text must also be accepted by the Council of the European Union (which can be considered as the second part of the EU's bicameral legislature), the Council Presidency has recently been &lt;a href=&quot;https://www.eff.org/deeplinks/2018/02/how-have-europes-upload-filtering-and-link-tax-plans-changed&quot;&gt;weighing in with its own &quot;compromise&quot; proposals&lt;/a&gt; (although this is something of a misnomer, as they do little to improve the Commission's original text, and in some respects make it worse). Not to be outdone, German MEP (Member of the European Parliament) Axel Voss last month &lt;a href=&quot;https://juliareda.eu/wp-content/uploads/2018/03/voss11.pdf&quot;&gt;introduced a new set of his own proposals&lt;/a&gt; [PDF] for &quot;compromise,&quot; which are somehow worse still. Since Voss leads the JURI committee, this is a big problem.&lt;/p&gt;
&lt;h3&gt;Link Tax Proposal: A Turn for the (Even) Worse&lt;/h3&gt;
&lt;p&gt;The biggest and most worrisome changes are to the &quot;link tax&quot; proposal, which would establish a special copyright-like fee to be paid by websites to news publishers, in exchange for the privilege of using short snippets of quoted text as part of a link to the original news article. Voss's latest amendments would make the link tax an &lt;em&gt;inalienable&lt;/em&gt; right, that news publishers cannot waive even if they choose to.&lt;/p&gt;
&lt;p&gt;The practical effect of this could be to make it impossible for a news publisher to publish their stories for free use, for example by using a &lt;a href=&quot;https://creativecommons.org/2018/03/29/head-copyright-committee-wants-deny-eu-creators-right-share/&quot;&gt;Creative Commons&lt;/a&gt; license. When a similar inalienable link tax was passed into law in Spain, the country's biggest news aggregation website, which had been Google News, simply &lt;a href=&quot;https://www.eff.org/deeplinks/2014/12/google-news-shuts-shop-spain-thanks-ancillary-copyright-law&quot;&gt;closed its Spanish operation.&lt;/a&gt; We can well imagine similar results if the link tax went Europe-wide.&lt;/p&gt;
&lt;p&gt;That's not all. Voss proposes that the beneficiaries of the link tax should include press agencies (who often provide the raw information based upon which other journalists write stories), and that libraries should also be responsible for paying extra fees to publishers in &quot;compensation&quot; for their rental and lending activities.&lt;/p&gt;
&lt;p&gt;Although Voss hasn't managed to make the upload filtering proposal any worse than it was before, it was &lt;a href=&quot;https://www.eff.org/deeplinks/2017/10/digital-rights-groups-demand-deletion-unlawful-filtering-mandate-proposed-eu&quot;&gt;plenty bad enough already&lt;/a&gt;. Although targeted mainly at sites that host video and music uploaded by users, it's broad enough to extend to extend to &lt;em&gt;any&lt;/em&gt; sort of user-uploaded content, including &lt;a href=&quot;https://savecodeshare.eu/&quot;&gt;code contributed to platforms like Github&lt;/a&gt;, and even text contributed to a user-edited encyclopedia (although Voss would support an amendment excluding non-profit encyclopedias from the law, which may or may not save Wikipedia).&lt;/p&gt;
&lt;h3 id=&quot;action&quot;&gt;How You Can Take Action&lt;/h3&gt;
&lt;p&gt;These proposals benefit large publishers, but punish those who use the Internet as an open platform for sharing and innovation. Europeans are running out of time to convince their representatives to reject them. Our friends at Mozilla have developed an &lt;a href=&quot;https://act.eff.org/action/stop-europe-s-copyright-censorship-and-link-tax-plans&quot;&gt;excellent tool that Europeans can use to directly contact their representatives&lt;/a&gt; to deliver a simple message—delete Article 11, delete Article 13, and instead give us copyright laws that promote competition and innovation online.&lt;/p&gt;
&lt;p class=&quot;take-action&quot;&gt;&lt;a href=&quot;https://act.eff.org/action/stop-europe-s-copyright-censorship-and-link-tax-plans&quot;&gt;Take Action&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;take-explainer&quot;&gt;&lt;a href=&quot;https://act.eff.org/action/stop-europe-s-copyright-censorship-and-link-tax-plans&quot;&gt;Demand fair copyright policies&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 13 Apr 2018 22:38:03 +0000</pubDate>
<dc:creator>DiabloD3</dc:creator>
<og:type>article</og:type>
<og:title>European Copyright Law Isn't Great. It Could Soon Get a Lot Worse.</og:title>
<og:url>https://www.eff.org/deeplinks/2018/04/european-copyright-law-isnt-great-it-could-soon-get-lot-worse</og:url>
<og:description>EFF has been writing about the upcoming European Digital Single Market directive on copyright for a long time now. But it's time to put away the keyboard, and pick up the phone, because the proposal just got worse—and it's headed for a crucial vote on June 20-21. For those who need...</og:description>
<og:image>https://www.eff.org/files/eu-copyright.png</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.eff.org/deeplinks/2018/04/european-copyright-law-isnt-great-it-could-soon-get-lot-worse</dc:identifier>
</item>
<item>
<title>For mathematicians, = does not mean equality</title>
<link>https://jeremykun.com/2018/04/13/for-mathematicians-does-not-mean-equality/</link>
<guid isPermaLink="true" >https://jeremykun.com/2018/04/13/for-mathematicians-does-not-mean-equality/</guid>
<description>&lt;p&gt;Every now and then I hear some ridiculous things about the equals symbol. Some large subset of programmers—perhaps related to functional programmers, perhaps not—seem to think that = should only and ever mean “equality in the mathematical sense.” The argument usually goes,&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Functional programming gives us back that inalienable right to analyze things by using mathematics. Never again need we bear the burden of that foul mutant x = x+1! No novice programmer—nay, not even a mathematician!—could comprehend such flabbergastery. Tis a pinnacle of confusion!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;It’s ironic that so much of the merits or detriment of the use of = is based on a veiled appeal to the purity of mathematics. Just as often software engineers turn the tables, and any similarity to mathematics is decried as elitist jibber jabber (&lt;em&gt;Such an archaic and abstruse use of symbols! Oh no, big-O!&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;In fact, equality is more rigorously defined in a programming language than it will ever be in mathematics. Even in the hottest pits of software hell, where there’s = and == and ===, throwing in ==== just to rub salt in the wound, each operator gets its own coherent definition and documentation. Learn it once and you’ll never go astray.&lt;/p&gt;
&lt;p&gt;Not so in mathematics—oh yes, hide your children from the terrors that lurk. In mathematics equality is little more than a stand-in for the word “is,” oftentimes entirely dependent on context. Now gather round and listen to the tale of the true identities of the masquerader known as =.&lt;/p&gt;
&lt;p&gt;Let’s start with some low-hanging fruit, the superficial concerns.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%7Bi%3D1%7D%5En+i%5E2+%2B+3&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;\displaystyle \sum_{i=1}^n i^2 + 3&quot; title=&quot;\displaystyle \sum_{i=1}^n i^2 + 3&quot; class=&quot;latex&quot;/&gt;&lt;/p&gt;
&lt;p&gt;If = were interpreted literally, &lt;img src=&quot;https://s0.wp.com/latex.php?latex=i&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;i&quot; title=&quot;i&quot; class=&quot;latex&quot;/&gt; would be “equal” to 1, and “equal” to 2, and I’d facetiously demand &lt;img src=&quot;https://s0.wp.com/latex.php?latex=1+%3D+2&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;1 = 2&quot; title=&quot;1 = 2&quot; class=&quot;latex&quot;/&gt;. Aha! Where is your Gauss now?! But seriously, this bit of notation shows that mathematics has both expressions with scope and variables that change their value over time. And the &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Csum&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;\sum&quot; title=&quot;\sum&quot; class=&quot;latex&quot;/&gt; use for notation was established by &lt;em&gt;Euler&lt;/em&gt;, long before algorithms jumped from logic to computers to billionaire Senate testimonies.&lt;/p&gt;
&lt;p&gt;Likewise, set-builder notation often uses the same kind of equals-as-iterate.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+A+%3D+%5C%7B+n%5E2+%3A+n+%3D+1%2C+2%2C+%5Cdots%2C+100+%5C%7D&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;\displaystyle A = \{ n^2 : n = 1, 2, \dots, 100 \}&quot; title=&quot;\displaystyle A = \{ n^2 : n = 1, 2, \dots, 100 \}&quot; class=&quot;latex&quot;/&gt;&lt;/p&gt;
&lt;p&gt;In Python, or interpreting the expression literally, the value of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=n&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;n&quot; title=&quot;n&quot; class=&quot;latex&quot;/&gt; would be a tuple, producing a type error. (&lt;a href=&quot;https://jsconsole.com/?console.log%28%5B1%2C2%2C3%2C4%2C5%2C6%2C7%5D%20%5E%202%29%3B&quot;&gt;In Javascript, it produces 2&lt;/a&gt;. How could it be Javascript if it didn’t?)&lt;/p&gt;
&lt;p&gt;Next up we have the sloppiness of functions. Let &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f%28x%29+%3D+2x+%2B+3&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;f(x) = 2x + 3&quot; title=&quot;f(x) = 2x + 3&quot; class=&quot;latex&quot;/&gt;. This is a function, and &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;x&quot; title=&quot;x&quot; class=&quot;latex&quot;/&gt; is a variable. Rather than precisely say, &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f%282%29+%3D+7&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;f(2) = 7&quot; title=&quot;f(2) = 7&quot; class=&quot;latex&quot;/&gt;, we say that for &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x%3D2%2C+f%28x%29+%3D+7&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;x=2, f(x) = 7&quot; title=&quot;x=2, f(x) = 7&quot; class=&quot;latex&quot;/&gt;. So &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;x&quot; title=&quot;x&quot; class=&quot;latex&quot;/&gt; is simultaneously an indeterminate input and a concrete value. The same scoping for programming functions bypass the naive expectation that equality means “now and forever.” Couple that with the question-as-equation &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f%28x%29+%3D+7&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;f(x) = 7&quot; title=&quot;f(x) = 7&quot; class=&quot;latex&quot;/&gt;, in which one asks what values of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;x&quot; title=&quot;x&quot; class=&quot;latex&quot;/&gt; produce this result, if any, and you begin to see how deep the rabbit hole goes. To understand what someone means when they say &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f%28x%29+%3D+7&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;f(x) = 7&quot; title=&quot;f(x) = 7&quot; class=&quot;latex&quot;/&gt;, you need to know the context.&lt;/p&gt;
&lt;p&gt;But this is just the tip of the iceberg, and we’re drilling deep. The point is that = carries with it all &lt;em&gt;kinds&lt;/em&gt; of baggage, not just the scope of a particular binding of a variable.&lt;/p&gt;
&lt;p&gt;Continuing with functions, we have rational expressions like &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f%28x%29+%3D+%5Cfrac%7B%28x%2B1%29x%7D%7Bx%7D&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;f(x) = \frac{(x+1)x}{x}&quot; title=&quot;f(x) = \frac{(x+1)x}{x}&quot; class=&quot;latex&quot;/&gt;. One often starts by saying “let’s let &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;f&quot; title=&quot;f&quot; class=&quot;latex&quot;/&gt; be this function.” Then we want to analyze it, and in-so-doing we simplify to &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f%28x%29+%3D+x%2B1&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;f(x) = x+1&quot; title=&quot;f(x) = x+1&quot; class=&quot;latex&quot;/&gt;. To keep ourselves safe, we modify the domain of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=f&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;f&quot; title=&quot;f&quot; class=&quot;latex&quot;/&gt; to exclude &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x%3D0&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;x=0&quot; title=&quot;x=0&quot; class=&quot;latex&quot;/&gt; post-hoc. But the flow of the argument is the same: we defer the exclusion of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x%3D0&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;x=0&quot; title=&quot;x=0&quot; class=&quot;latex&quot;/&gt; until we need it, meaning the equality at the beginning is a different equality than at the end. In effect, we have an infinitude of different kinds of equality for functions, one for each choice of what to exclude from the domain. And a mathematical proof might switch between them as needed.&lt;/p&gt;
&lt;p&gt;“Why not just define a new function &lt;img src=&quot;https://s0.wp.com/latex.php?latex=g&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;g&quot; title=&quot;g&quot; class=&quot;latex&quot;/&gt; with a different domain,” you ask? You can, but mathematicians don’t. And if you’re arguing in favor or against a particular notation, and using “mathematics” as your impenetrable shield, you’ve got to remember the famous definition of Reuben Hersh, that “mathematics is what mathematicians do.” For us, that means you can’t claim superiority based on an idea of mathematics that disagrees with mathematical practice. And mathematics, dear reader, is messier than programmers and philosophers would have one believe.&lt;/p&gt;
&lt;p&gt;And now we turn to the Great Equality Contextualizer, the &lt;strong&gt;isomorphism. &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You see, all over mathematics there are objects which are not equal, but we want them to be. When you study symmetry, say, you learn that there is an algebraic structure to symmetry called a &lt;a href=&quot;https://jeremykun.com/2012/12/08/groups-a-primer/&quot;&gt;group&lt;/a&gt;. And the same structure—that is, the same true underlying relationships between the symmetries of a thing—can show up in many different guises. As a set, as a picture, as a class of functions, in polynomials and compass constructions and wallpapers, oh my! In each of these things we want to say that two symmetry structures are the same even if they look different. We want to overload equality when four-fold rotational symmetry applies to my table as well as a four-pointed star.&lt;/p&gt;
&lt;p&gt;The tool we use for that is called an isomorphism. In brief terms, it’s a function between two objects, with an inverse, that preserves the structure you care about both ways. In fact, there &lt;em&gt;is&lt;/em&gt; a special symbol for when two things are isomorphic, and it’s often &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ccong&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;\cong&quot; title=&quot;\cong&quot; class=&quot;latex&quot;/&gt;. But &lt;img src=&quot;https://s0.wp.com/latex.php?latex=%5Ccong&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;\cong&quot; title=&quot;\cong&quot; class=&quot;latex&quot;/&gt; is annoying to write, and it really just means “is the same as” the same way equality does. So mathematicians often drop the squiggle and use =.&lt;/p&gt;
&lt;p&gt;Plus, there are a million kinds of isomorphism. Groups, graphs, vector spaces, rings, fields, modules, algebras, rational functions, varieties, Lie groups, *breathe* topological spaces, manifolds of all stripes, sheaves, schemes, lattices, knots, the list just keeps going on and on and on! No way are we making up a symbol for each one of these and the hundreds of variations we might come up with. And moreover, when you say two things are isomorphic, that gives you absolutely no indication of &lt;em&gt;how&lt;/em&gt; they are isomorphic. It fact, it can be extremely tedious to compute isomorphisms between things, and it’s even known to be &lt;a href=&quot;https://en.wikipedia.org/wiki/Group_isomorphism_problem&quot;&gt;uncomputable&lt;/a&gt; in extreme cases! What good is equality if you can’t even check it?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;But wait!&lt;/em&gt; You might ask, having read this blog for a while and knowing better than to not question a claim. &lt;em&gt;All of these uses of equality are still equivalence relations, and x = x + 1 is not an equivalence relation!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Well, you got me there. Mathematicians love to keep equality as an equivalence relation. When mathematicians need to define an algorithm where the value of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;x&quot; title=&quot;x&quot; class=&quot;latex&quot;/&gt; changes in a nontrivial way, it’s usually done by setting &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x_0&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;x_0&quot; title=&quot;x_0&quot; class=&quot;latex&quot;/&gt; equal to some starting value and letting &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x_%7Bn%7D&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;x_{n}&quot; title=&quot;x_{n}&quot; class=&quot;latex&quot;/&gt; be defined as some function of &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x_%7Bn-1%7D&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;x_{n-1}&quot; title=&quot;x_{n-1}&quot; class=&quot;latex&quot;/&gt; and smaller terms, like the good ol’ Fibonacci sequence &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x_0+%3D+x_1+%3D+1&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;x_0 = x_1 = 1&quot; title=&quot;x_0 = x_1 = 1&quot; class=&quot;latex&quot;/&gt; and &lt;img src=&quot;https://s0.wp.com/latex.php?latex=x_n+%3D+x_%7Bn-1%7D+%2B+x_%7Bn-2%7D&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;x_n = x_{n-1} + x_{n-2}&quot; title=&quot;x_n = x_{n-1} + x_{n-2}&quot; class=&quot;latex&quot;/&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If mutation is so great, why do mathematicians use recursion so much? Huh? Huh?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Well, I’ve got two counterpoints. The first is that the goal here is to &lt;em&gt;reason&lt;/em&gt; about the sequence, not to describe it in a way that can be efficiently carried out by a computer. When you say x = x + 1, you’re telling the computer that the old value of x need not linger, and you can do away with the space occupied by the previous value of x. To achieve the same result with recursion requires a whole other can of worms: memoization and tail recursive style and compiler optimizations to shed stack frames. It’s a lot more work to understand all that (to get to an equivalent solution) than it is to understand mutation! Simply stated, the goals of mathematics and programming are quite differently aligned. The former is about understanding a thing, and the latter is more often about describing a concrete process under threat of limited resources.&lt;/p&gt;
&lt;p&gt;My second point is that mathematical notation is so flexible and adaptable that it doesn’t &lt;em&gt;need&lt;/em&gt; mutation the same way programming languages need it. In mathematics we have no stack overflows, no register limits or page swaps, no limitations on variable names or memory allocation, our brains do the continuation passing for us, and we can rewrite history ad hoc and pile on abstractions as needed to achieve a particular goal. Even when you’re describing an algorithm in mathematics, you get the benefits of mathematical abstractions. A mathematician could easily introduce = as mutation in their work. Nothing stops them from doing so! It’s just that they rarely have a genuine need for it.&lt;/p&gt;
&lt;p&gt;But of course, none of this changes that languages could use := or “let” instead of = for assignment. If a strict adherence to asymmetry for asymmetric operations helps you sleep at night, so be it. My point is that the case when = means assignment is an extremely simple bit of context. Much simpler than the albatrossian mental burden required to understand what mathematicians really mean when they write &lt;img src=&quot;https://s0.wp.com/latex.php?latex=A+%3D+B&amp;amp;bg=ffffff&amp;amp;fg=36312d&amp;amp;s=0&quot; alt=&quot;A = B&quot; title=&quot;A = B&quot; class=&quot;latex&quot;/&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Postscript: I hope everyone reading this realizes I’m embellishing a bit for the sake of entertainment. If you want to fight me, tell me the best tree isn’t aspen. I dare you.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Postpostscript: embarrassingly, I completely forgot about Big-O notation and friends (despite mentioning it in the article!) as a case where = does not mean equality! f(n) = O(log n) is a statement about upper bounds, not equality! Thanks to &lt;a href=&quot;https://twitter.com/lreyzin&quot;&gt;@lreyzin&lt;/a&gt; for keeping me honest.&lt;/em&gt;&lt;/p&gt;
&lt;div id=&quot;jp-post-flair&quot; class=&quot;sharedaddy sd-like-enabled sd-sharing-enabled&quot;&gt;
&lt;div class=&quot;sharedaddy sd-sharing-enabled&quot;&gt;
&lt;div class=&quot;robots-nocontent sd-block sd-social sd-social-icon sd-sharing&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Share this:&lt;/h3&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-unloaded&quot; id=&quot;like-post-wrapper-23934684-35861-5ad2254714f44&quot; data-src=&quot;//widgets.wp.com/likes/index.html?ver=20180319#blog_id=23934684&amp;amp;post_id=35861&amp;amp;origin=jeremykun.wordpress.com&amp;amp;obj_id=23934684-35861-5ad2254714f44&quot; data-name=&quot;like-post-frame-23934684-35861-5ad2254714f44&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Like this:&lt;/h3&gt;
&lt;div class=&quot;likes-widget-placeholder post-likes-widget-placeholder&quot;&gt;&lt;span class=&quot;button&quot;&gt;&lt;span&gt;Like&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;loading&quot;&gt;Loading...&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
</description>
<pubDate>Fri, 13 Apr 2018 19:55:55 +0000</pubDate>
<dc:creator>hds</dc:creator>
<og:type>article</og:type>
<og:title>For mathematicians, = does not mean equality</og:title>
<og:url>https://jeremykun.com/2018/04/13/for-mathematicians-does-not-mean-equality/</og:url>
<og:description>Every now and then I hear some ridiculous things about the equals symbol. Some large subset of programmers—perhaps related to functional programmers, perhaps not—seem to think that = should only an…</og:description>
<og:image>https://secure.gravatar.com/blavatar/ffc08531463d8605aef9e0b51a9ac71f?s=200&amp;ts=1523721543</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://jeremykun.com/2018/04/13/for-mathematicians-does-not-mean-equality/</dc:identifier>
</item>
<item>
<title>Why Entrepreneurs Start Companies Rather Than Join Them</title>
<link>https://steveblank.com/2018/04/11/why-entrepreneurs-start-companies-rather-than-join-them/</link>
<guid isPermaLink="true" >https://steveblank.com/2018/04/11/why-entrepreneurs-start-companies-rather-than-join-them/</guid>
<description>&lt;p&gt;If you asked me why I gravitated to startups rather than work in a large company I would have answered at various times: “I want to be my own boss.” “I love risk.” “I want flexible work hours.” “I want to work on tough problems that matter.” “I have a vision and want to see it through.” “I saw a better opportunity and grabbed it. …”&lt;/p&gt;
&lt;p&gt;It never crossed my mind that I gravitated to startups because I thought more of my abilities than the value a large company would put on them. At least not consciously. But that’s the conclusion of a provocative research paper, &lt;a href=&quot;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2596846&quot;&gt;Asymmetric Information and Entrepreneurship&lt;/a&gt;, that explains a new theory of why some people choose to be entrepreneurs. The authors’ conclusion — &lt;em&gt;Entrepreneurs think they are better than their resumes show and realize they can make more money by going it alone.&lt;/em&gt;  &lt;em&gt;And in most cases, they are right&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;I’ll summarize the paper’s conclusions, then share a few thoughts about what they might mean – for companies, entrepreneurs and entrepreneurial education. (By the way, as you read the conclusions keep in mind the authors are not talking just about high-tech entrepreneurs. They are talking about everyone who chooses to be self-employed – from a corner food vendor without a high school diploma to a high-tech founder with a PhD in Computer Science from Stanford.)&lt;/p&gt;
&lt;p&gt;The authors’ research came from following &lt;a href=&quot;https://www.nlsinfo.org/content/cohorts/nlsy79&quot;&gt;12,686 people&lt;/a&gt; over 30+ years. They found:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://steveblank.files.wordpress.com/2018/04/resume-rejected.png&quot;&gt;&lt;img data-attachment-id=&quot;24156&quot; data-permalink=&quot;https://steveblank.com/2018/04/11/why-entrepreneurs-start-companies-rather-than-join-them/resume-rejected/&quot; data-orig-file=&quot;https://steveblank.files.wordpress.com/2018/04/resume-rejected.png&quot; data-orig-size=&quot;937,937&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;resume rejected&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://steveblank.files.wordpress.com/2018/04/resume-rejected.png?w=200&amp;amp;h=200&quot; data-large-file=&quot;https://steveblank.files.wordpress.com/2018/04/resume-rejected.png?w=468&quot; class=&quot;wp-image-24156 alignright&quot; src=&quot;https://steveblank.files.wordpress.com/2018/04/resume-rejected.png?w=200&amp;amp;h=200&quot; alt=&quot;&quot; width=&quot;200&quot; height=&quot;200&quot; srcset=&quot;https://steveblank.files.wordpress.com/2018/04/resume-rejected.png?w=200&amp;amp;h=200 200w, https://steveblank.files.wordpress.com/2018/04/resume-rejected.png?w=400&amp;amp;h=400 400w, https://steveblank.files.wordpress.com/2018/04/resume-rejected.png?w=150&amp;amp;h=150 150w, https://steveblank.files.wordpress.com/2018/04/resume-rejected.png?w=300&amp;amp;h=300 300w&quot; sizes=&quot;(max-width: 200px) 100vw, 200px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;em&gt;Signaling&lt;/em&gt;. When you look for a job you “signal” your ability to employers via a resume with a list of your educational qualifications and work history. Signaling is a fancy academic term to describe how one party (in this case someone who wants a job) credibly conveys information to another party (a potential employer).&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Capable&lt;/em&gt;. People choose to be entrepreneurs when they feel that they are more capable than what employers can tell from their resume or an interview. So, entrepreneurs start ventures because they can’t signal their worth to potential employers.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Better Pay.&lt;/em&gt; Overall, when people choose entrepreneurship they earn 7% more than they would have in a corporate job. That’s because in companies pay is usually set by observable signals (your education and experience/work history).&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Less Predictable Pay&lt;/em&gt;. But the downside of being an entrepreneur is that as a group their pay is more variable – some make less than if they worked at a company, some much more.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Smarter&lt;/em&gt;. Entrepreneurs score higher on cognitive ability tests than their educational credentials would predict. And their cognitive ability is higher than those with the same educational and work credentials who choose to work in a company.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Immigrants and Funding&lt;/em&gt;. Signaling (or the lack of it) may explain why some groups such as immigrants, with less credible signals to existing companies (unknown schools, no license to practice, unverifiable job history, etc.) tend to gravitate toward entrepreneurship. And why funding from families and friends is a dominant source of financing for early-stage ventures (because friends and family know an entrepreneur’s ability better than any resume can convey).&lt;/li&gt;
&lt;li&gt;Entrepreneurs defer getting more formal education because they correctly expect their productivity will be higher than the market can infer from just their educational qualifications. (There are no signals for entrepreneurial skills.)&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/The_Market_for_Lemons&quot;&gt;Lemons Versus Cherries&lt;/a&gt;.&lt;/em&gt; The most provocative conclusion in the paper is that &lt;em&gt;asymmetric information about ability leads existing companies to employ only “lemons,” relatively unproductive workers&lt;/em&gt;. The &lt;u&gt;talented and more productive choose entrepreneurship&lt;/u&gt;. (Asymmetric Information is when one party has more or better &lt;a href=&quot;https://en.wikipedia.org/wiki/Information&quot;&gt;information&lt;/a&gt; than the other.) In this case the entrepreneurs know something potential employers don’t – that nowhere on their resume does it show resiliency, curiosity, agility, resourcefulness, pattern recognition, tenacity and having a passion for products.&lt;br/&gt;This implication, that entrepreneurs are, in fact, “cherries” contrasts with a large body of literature in social science, which says that the entrepreneurs are the “lemons”— those who cannot find, cannot hold, or cannot stand “real jobs.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So, what to make of all this?&lt;br/&gt;&lt;/strong&gt;If the authors are right, the way we signal ability (resumes listing education and work history) is not only a poor predictor of success, but has implications for existing companies, startups, education, and public policy that require further thought and research.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Companies:&lt;/em&gt; In the 20&lt;sup&gt;th&lt;/sup&gt;century when companies competed with peers with the same business model, they wanted employees to help them execute current business models (whether it was working on an assembly line or writing code supporting or extending current products). There was little loss when they missed hiring employees who had entrepreneurial skills. However, in the 21&lt;sup&gt;st&lt;/sup&gt;century companies face continuous disruption; now they’re looking for employees to help them act entrepreneurial.  Yet their recruiting and interviewing processes – which define signals they look for – are still focused on execution not entrepreneurial skills.&lt;/p&gt;
&lt;p&gt;Surprisingly, the company that best epitomized this was not some old-line manufacturing company but Google. When Marissa Mayer ran products at Google the &lt;a href=&quot;https://www.nytimes.com/2009/03/01/business/01marissa.html&quot;&gt;New York Times  described her hiring process&lt;/a&gt;, “More often than not, she relies on charts, graphs and quantitative analysis as a foundation for a decision, particularly when it comes to evaluating people…At a recent personnel meeting, she homes in on grade-point averages and SAT scores to narrow a list of candidates, many having graduated from Ivy League schools, …&lt;em&gt;One candidate got a C in macroeconomics. “That’s troubling to me,” Ms. Mayer says. “Good students are good at all things&lt;/em&gt;.”&lt;/p&gt;
&lt;p&gt;Really.  What a perfect example of adverse signaling. No wonder the most successful Google products, other than search, &lt;em&gt;have been acquisitions of startups&lt;/em&gt; not internal products: YouTube, Android, DoubleClick, Keyhole (Google Maps), Waze were started and run by entrepreneurs. The type of people Google and Marissa Mayer wouldn’t and didn’t hire started the companies they bought.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Entrepreneurship&lt;/em&gt;. When I shared &lt;a href=&quot;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2596846&quot;&gt;the&lt;/a&gt; &lt;a href=&quot;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2596846&quot;&gt;paper with&lt;/a&gt;&lt;a href=&quot;http://www.tinaseelig.com/&quot;&gt;Tina Seelig&lt;/a&gt; at Stanford she asked, “If schools provided better ways to signal someone’s potential to employers, will this lead to less entrepreneurship?”  Interesting question.&lt;/p&gt;
&lt;p&gt;Imagine if in a perfect world corporate recruiters found a way to identify the next Steve Jobs, Elon Musks, or Larry Ellisons. Would the existing corporate processes, procedures and business models crush their innovative talents, or would they steer the large companies into a new renaissance?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The Economic Environment.&lt;/em&gt; So, how much of signaling (hiring only by resume qualifications) is influenced by the economic environment? One could assume that in a period of low unemployment, it will be easier to get a traditional job, which would lead to fewer startups and explain why great companies are often founded during a downturn. Those who can’t get a traditional job start their own venture. Yet other public policies come into play. Between the late 1930s and the 1970s the U.S. tax rate for individuals making over $100,000 was 70% and 90% (taxes on capital gains fluctuated between 20% and 25%.) Venture capital flourished when the tax rates plummeted in the late 1970s. Was entrepreneurship stifled by high personal income taxes? And did it flourish only when entrepreneurs saw the opportunity to make a lot more money on their own?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Leaving a Company.&lt;/em&gt; Some new ventures are started by people who leave big companies to strike out on their own – meaning they weren’t trying to find employment in a corporation, they were trying to get away from it.  While starting your own company may look attractive from inside a company, the stark reality of risking one’s livelihood, financial stability, family, etc., is a tough bar to cross.  What motivates these people to leave the relative comfort of a steady corporate income and strike out on their own?  Is it the same reason – their company doesn’t value their skills for innovation and is just measuring them on execution? Or something else?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Entrepreneurial Education&lt;/em&gt;. Is entrepreneurship for everyone? Should we expect that we can teach entrepreneurship as a mandatory class? Or is it &lt;a href=&quot;http://www.youtube.com/watch?v=peX6wNbZrgQ&quot;&gt;calling&lt;/a&gt;? Increasing the number of new ventures will only generate aggregate wealth if those who start firms are truly more productive as entrepreneurs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lessons Learned&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;Entrepreneurs start their own companies because existing companies don’t value the skills that don’t fit on a resume&lt;/li&gt;
&lt;li&gt;The most talented people choose entrepreneurship (&lt;a href=&quot;https://en.wikipedia.org/wiki/The_Market_for_Lemons&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Lemons versus Cherries&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Read the paper and let me know what you think&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;  &lt;a href=&quot;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2596846&quot;&gt;&lt;img data-attachment-id=&quot;24157&quot; data-permalink=&quot;https://steveblank.com/2018/04/11/why-entrepreneurs-start-companies-rather-than-join-them/asymmetric-info/&quot; data-orig-file=&quot;https://steveblank.files.wordpress.com/2018/04/asymmetric-info.png&quot; data-orig-size=&quot;729,912&quot; data-comments-opened=&quot;1&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;Asymmetric Info&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://steveblank.files.wordpress.com/2018/04/asymmetric-info.png?w=240&amp;amp;h=300&quot; data-large-file=&quot;https://steveblank.files.wordpress.com/2018/04/asymmetric-info.png?w=468&quot; class=&quot;size-medium wp-image-24157&quot; src=&quot;https://steveblank.files.wordpress.com/2018/04/asymmetric-info.png?w=240&amp;amp;h=300&quot; alt=&quot;&quot; width=&quot;240&quot; height=&quot;300&quot; srcset=&quot;https://steveblank.files.wordpress.com/2018/04/asymmetric-info.png?w=240&amp;amp;h=300 240w, https://steveblank.files.wordpress.com/2018/04/asymmetric-info.png?w=480&amp;amp;h=600 480w, https://steveblank.files.wordpress.com/2018/04/asymmetric-info.png?w=120&amp;amp;h=150 120w&quot; sizes=&quot;(max-width: 240px) 100vw, 240px&quot;/&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;div id=&quot;jp-post-flair&quot; class=&quot;sharedaddy sd-like-enabled sd-sharing-enabled&quot;&gt;
&lt;div class=&quot;sharedaddy sd-sharing-enabled&quot;&gt;
&lt;div class=&quot;robots-nocontent sd-block sd-social sd-social-official sd-sharing&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Share this:&lt;/h3&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-unloaded&quot; id=&quot;like-post-wrapper-6599589-24155-5ad225c7af705&quot; data-src=&quot;//widgets.wp.com/likes/index.html?ver=20180319#blog_id=6599589&amp;amp;post_id=24155&amp;amp;origin=steveblank.wordpress.com&amp;amp;obj_id=6599589-24155-5ad225c7af705&quot; data-name=&quot;like-post-frame-6599589-24155-5ad225c7af705&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Like this:&lt;/h3&gt;
&lt;p&gt;&lt;span class=&quot;button&quot;&gt;&lt;span&gt;Like&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;loading&quot;&gt;Loading...&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p class=&quot;postinfo&quot;&gt;Filed under: &lt;a href=&quot;https://steveblank.com/category/corporate-innovation/&quot; rel=&quot;category tag&quot;&gt;Corporate Innovation&lt;/a&gt;, &lt;a href=&quot;https://steveblank.com/category/familycareerculture/&quot; rel=&quot;category tag&quot;&gt;Family/Career/Culture&lt;/a&gt; |&lt;/p&gt;
</description>
<pubDate>Fri, 13 Apr 2018 19:41:34 +0000</pubDate>
<dc:creator>thesumofall</dc:creator>
<og:type>article</og:type>
<og:title>Steve Blank Why Entrepreneurs Start Companies Rather Than Join Them</og:title>
<og:url>https://steveblank.com/2018/04/11/why-entrepreneurs-start-companies-rather-than-join-them/</og:url>
<og:description>If you asked me why I gravitated to startups rather than work in a large company I would have answered at various times: “I want to be my own boss.” “I love risk.” “I want flexible work hours.” “I …</og:description>
<og:image>https://steveblank.files.wordpress.com/2018/04/resume-rejected.png</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://steveblank.com/2018/04/11/why-entrepreneurs-start-companies-rather-than-join-them/</dc:identifier>
</item>
<item>
<title>In a Leaked Memo, Apple Warns Employees to Stop Leaking Information</title>
<link>https://www.bloomberg.com/news/articles/2018-04-13/apple-warns-employees-to-stop-leaking-information-to-media</link>
<guid isPermaLink="true" >https://www.bloomberg.com/news/articles/2018-04-13/apple-warns-employees-to-stop-leaking-information-to-media</guid>
<description>&lt;p&gt;&lt;a itemscope=&quot;itemscope&quot; itemprop=&quot;StoryLink&quot; href=&quot;https://www.bloomberg.com/quote/AAPL:US&quot; title=&quot;Apple leadership&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Apple Inc.&lt;/a&gt; warned employees to stop leaking internal information on future plans and raised the specter of potential legal action and criminal charges, one of the most-aggressive moves by the world’s largest technology company to control information about its activities.&lt;/p&gt;


&lt;p&gt;The Cupertino, California-based company said in a lengthy memo posted to its internal blog that it &quot;caught 29 leakers,&quot; last year and noted that 12 of those were arrested. &quot;These people not only lose their jobs, they can face extreme difficulty finding employment elsewhere,&quot; Apple added. The company declined to comment on Friday.&lt;/p&gt;


&lt;p&gt;Apple outlined situations in which information was leaked to the media, including a meeting earlier this year where Apple’s software engineering head Craig Federighi told employees that some planned iPhone software features would be delayed. Apple also cited a yet-to-be-released software package that revealed details about the unreleased iPhone X and new Apple Watch.&lt;/p&gt;




&lt;p&gt;Leaked information about a new product can negatively impact sales of current models, give rivals more time to begin on a competitive response, and lead to fewer sales when the new product launches, according to the memo. “We want the chance to tell our customers why the product is great, and not have that done poorly by someone else,” Greg Joswiak, an Apple product marketing executive, said in the memo.&lt;/p&gt;


&lt;p&gt;The crackdown is part of broader and long-running attempts by Silicon Valley technology companies to track and limit what information their employees share publicly. Firms like Google and Facebook Inc. are pretty open with staff about their plans, but keep close tabs on their outside communications and sometime fire people when they find leaks.&lt;/p&gt;
&lt;p&gt;Facebook executive Sheryl Sandberg last week talked about her disappointment with leakers. In 2016, Google fired an employee after the person shared internal posts criticizing an executive. The employee filed a lawsuit claiming their speech was protected under California law.&lt;/p&gt;
&lt;p&gt;In messages to staff, tech companies sometimes conflate conversations employees are allowed to have, such as complaining about working conditions, with sharing trade secrets, said Chris Baker, an attorney with Baker Curtis and Schwartz, PC, who represents the fired Googler. &quot;The overall broad definition of confidential information makes it so employees don’t say anything, even about issues they’re allowed to talk about,&quot; he said. &quot;That’s problematic.&quot;&lt;/p&gt;
&lt;p&gt;Apple is notoriously secretive about its product development. In 2012, Chief Executive Officer Tim Cook pledged to double down on keeping the company’s work under wraps. Despite that, the media has continued to report news on the firm to satisfy demand for information on a company that’s become a crucial part of investment portfolios, many of which support public retirement funds for teachers and other essential workers.&lt;/p&gt;

&lt;p&gt;In 2017, Apple held a confidential meeting with employees in another bid to stop leaks. Since then, publications, including Bloomberg News, published details about the iPhone X, a new Apple TV video-streaming box, a new Apple Watch with LTE, the company’s upcoming augmented-reality headset, new iPad models, software enhancements, and details about the upcoming iPhones and AirPods headphones.&lt;/p&gt;
&lt;h3&gt;Here’s the memo:&lt;/h3&gt;
&lt;p&gt;Last month, Apple caught and fired the employee responsible for leaking details from an internal, confidential meeting about Apple’s software roadmap. Hundreds of software engineers were in attendance, and thousands more within the organization received details of its proceedings. One person betrayed their trust.&lt;/p&gt;
&lt;p&gt;The employee who leaked the meeting to a reporter later told Apple investigators that he did it because he thought he wouldn’t be discovered. But people who leak -- whether they’re Apple employees, contractors or suppliers -- do get caught and they’re getting caught faster than ever.&lt;/p&gt;
&lt;p&gt;In many cases, leakers don’t set out to leak. Instead, people who work for Apple are often targeted by press, analysts and bloggers who befriend them on professional and social networks like LinkedIn, Twitter and Facebook and begin to pry for information. While it may seem flattering to be approached, it’s important to remember that you’re getting played. The success of these outsiders is measured by obtaining Apple’s secrets from you and making them public. A scoop about an unreleased Apple product can generate massive traffic for a publication and financially benefit the blogger or reporter who broke it. But the Apple employee who leaks has everything to lose.&lt;/p&gt;

&lt;p&gt;The impact of a leak goes far beyond the people who work on a project.&lt;/p&gt;
&lt;p&gt;Leaking Apple’s work undermines everyone at Apple and the years they’ve invested in creating Apple products. “Thousands of people work tirelessly for months to deliver each major software release,” says UIKit lead Josh Shaffer, whose team’s work was part of the iOS 11 leak last fall. “Seeing it leak is devastating for all of us.”&lt;/p&gt;
&lt;p&gt;The impact of a leak goes beyond the people who work on a particular project — it’s felt throughout the company. Leaked information about a new product can negatively impact sales of the current model; give rival companies more time to begin on a competitive response; and lead to fewer sales of that new product when it arrives. “We want the chance to tell our customers why the product is great, and not have that done poorly by someone else,” says Greg Joswiak of Product Marketing.&lt;/p&gt;
&lt;p&gt;Investments by Apple have had an enormous impact on the company’s ability to identify and catch leakers. Just before last September’s special event, an employee leaked a link to the gold master of iOS 11 to the press, again believing he wouldn’t be caught. The unreleased OS detailed soon-to-be-announced software and hardware including iPhone X. Within days, the leaker was identified through an internal investigation and fired. Global Security’s digital forensics also helped catch several employees who were feeding confidential details about new products including iPhone X, iPad Pro and AirPods to a blogger at 9to5Mac.&lt;/p&gt;
&lt;p&gt;Leakers in the supply chain are getting caught, too. Global Security has worked hand-in-hand with suppliers to prevent theft of Apple’s intellectual property as well as to identify individuals who try to exceed their access. They’ve also partnered with suppliers to identify vulnerabilities — both physical and technological — and ensure their security levels meet or exceed Apple’s expectations. These programs have nearly eliminated the theft of prototypes and products from factories, caught leakers and prevented many others from leaking in the first place.&lt;/p&gt;
&lt;p&gt;Leakers do not simply lose their jobs at Apple. In some cases, they face jail time and massive fines for network intrusion and theft of trade secrets both classified as federal crimes. In 2017, Apple caught 29 leakers. 12 of those were arrested. Among those were Apple employees, contractors and some partners in Apple’s supply chain. These people not only lose their jobs, they can face extreme difficulty finding employment elsewhere. “The potential criminal consequences of leaking are real,” says Tom Moyer of Global Security, “and that can become part of your personal and professional identity forever.”&lt;/p&gt;
&lt;aside class=&quot;inline-newsletter&quot; data-state=&quot;ready&quot;/&gt;&lt;p&gt;While they carry serious consequences, leaks are completely avoidable. They are the result of a decision by someone who may not have considered the impact of their actions. “Everyone comes to Apple to do the best work of their lives — work that matters and contributes to what all 135,000 people in this company are doing together,” says Joswiak. “The best way to honor those contributions is by not leaking.”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;— With assistance by Mark Bergen, and Sarah Frier&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 13 Apr 2018 17:56:49 +0000</pubDate>
<dc:creator>jsmthrowaway</dc:creator>
<og:description>Apple Inc. warned employees to stop leaking internal information on future plans and raised the specter of potential legal action and criminal charges, one of the most-aggressive moves by the world’s largest technology company to control information about its activities.</og:description>
<og:image>https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iU8FzsuKYRcU/v0/1200x834.jpg</og:image>
<og:title>In a Leaked Memo, Apple Warns Employees to Stop Leaking Information</og:title>
<og:type>article</og:type>
<og:url>https://www.bloomberg.com/news/articles/2018-04-13/apple-warns-employees-to-stop-leaking-information-to-media</og:url>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.bloomberg.com/news/articles/2018-04-13/apple-warns-employees-to-stop-leaking-information-to-media</dc:identifier>
</item>
<item>
<title>Someone Stole My Book (and My Job) and Is Selling It on Amazon</title>
<link>https://www.extremetech.com/internet/267446-someone-stole-my-entire-book-and-my-job-and-is-selling-it-on-amazon</link>
<guid isPermaLink="true" >https://www.extremetech.com/internet/267446-someone-stole-my-entire-book-and-my-job-and-is-selling-it-on-amazon</guid>
<description>&lt;div class=&quot;affiliate-text hide-for-large-up&quot; readability=&quot;27.373493975904&quot;&gt;This site may earn affiliate commissions from the links on this page. &lt;a href=&quot;https://www.ziffdavis.com/terms-of-use#endorsement&quot; target=&quot;_blank&quot;&gt;Terms of use&lt;/a&gt;.&lt;/div&gt;&lt;span id=&quot;intelliTXT&quot; name=&quot;intellitxt&quot;/&gt;
&lt;div class=&quot;featured-image&quot;&gt;&lt;span id=&quot;intelliTXT&quot; name=&quot;intellitxt&quot;/&gt;
&lt;div class=&quot;img-shadow&quot;&gt;&lt;span id=&quot;intelliTXT&quot; name=&quot;intellitxt&quot;&gt;&lt;img width=&quot;640&quot; height=&quot;353&quot; src=&quot;https://www.extremetech.com/wp-content/uploads/2017/03/Book-Desk-2-640x353.jpg&quot; class=&quot;attachment-full size-full wp-post-image&quot; alt=&quot;Atari book Breakout&quot; srcset=&quot;https://www.extremetech.com/wp-content/uploads/2017/03/Book-Desk-2-640x353.jpg 640w, https://www.extremetech.com/wp-content/uploads/2017/03/Book-Desk-2-300x166.jpg 300w, https://www.extremetech.com/wp-content/uploads/2017/03/Book-Desk-2-768x424.jpg 768w, https://www.extremetech.com/wp-content/uploads/2017/03/Book-Desk-2-106x59.jpg 106w, https://www.extremetech.com/wp-content/uploads/2017/03/Book-Desk-2-672x371.jpg 672w, https://www.extremetech.com/wp-content/uploads/2017/03/Book-Desk-2.jpg 1344w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;/&gt;&lt;/span&gt;&lt;/div&gt;
&lt;span id=&quot;intelliTXT&quot; name=&quot;intellitxt&quot;/&gt;&lt;/div&gt;
&lt;p&gt;&lt;span id=&quot;intelliTXT&quot; name=&quot;intellitxt&quot;&gt;My entire book was plagiarized on Amazon. I admit that in the grand scheme of things that could go wrong in tech these days, I wasn’t quite expecting this one.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span id=&quot;intelliTXT&quot; name=&quot;intellitxt&quot;&gt;It’s all the more surprising because the same distributor handles both books. Last year, our publisher Ziff Davis (ExtremeTech’s parent company) published my first book, &lt;a href=&quot;https://www.amazon.com/Breakout-Atari-Computers-Defined-Generation/dp/0692851275/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Breakout: How Atari 8-Bit Computers Defined a Generation&lt;/a&gt;. It’s about my favorite old computer lineup of Atari 8-bit machines released from 1979 through the 1980s. We produced both print and Kindle versions; for the former, we went through CreateSpace, an Amazon company that prints and distributes books on demand.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span id=&quot;intelliTXT&quot; name=&quot;intellitxt&quot;&gt;It’s been available about a year now. I was first alerted to the theft by Kevin Savetz, a well-known Atari 8-bit fan with an excellent radio show called &lt;a href=&quot;http://ataripodcast.libsyn.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Antic: The Atari 8-Bit Podcast&lt;/a&gt;, which he does with Randy Kindig and Brad Arnold. Savetz had bought a copy of the offending book out of sheer interest in the topic. Upon receiving it, he couldn’t help but notice it’s &lt;a href=&quot;https://www.amazon.com/gp/product/1985819376/ref=as_li_ss_tl&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;em&gt;exactly&lt;/em&gt; the same as mine&lt;/a&gt;, minus the word Breakout, my original cover, and the layout inside. Everything else is copied word for word, without my name–including the part on the back blurb where he says he’s the Editor-in-Chief of ExtremeTech, which is certainly news to me!&lt;/span&gt;&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-width=&quot;500&quot; data-dnt=&quot;true&quot; readability=&quot;7.9324894514768&quot;&gt;

&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;&lt;span id=&quot;intelliTXT&quot; name=&quot;intellitxt&quot;&gt;.&lt;a href=&quot;https://twitter.com/jlendino?ref_src=twsrc%5Etfw&quot;&gt;@jlendino&lt;/a&gt; can you explain what is happening here? The Steve S. Thomas book has the exact same text as yours throughout, the only thing changed is the author name. &lt;a href=&quot;https://t.co/o7sY6cI33o&quot;&gt;pic.twitter.com/o7sY6cI33o&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span id=&quot;intelliTXT&quot; name=&quot;intellitxt&quot;&gt;— Kevin Savetz (@KevinSavetz) &lt;a href=&quot;https://twitter.com/KevinSavetz/status/984539495268696065?ref_src=twsrc%5Etfw&quot;&gt;April 12, 2018&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;&lt;span id=&quot;intelliTXT&quot; name=&quot;intellitxt&quot;&gt;This “author” — I imagine Steve S. Thomas is not his real name — has &lt;a href=&quot;https://www.bokus.com/cgi-bin/product_search.cgi?authors=Steve%20S%20Thomas&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;stolen a number books&lt;/a&gt;, it turns out, from a variety of publishers and not just Ziff Davis:&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span id=&quot;intelliTXT&quot; name=&quot;intellitxt&quot;&gt;&lt;a href=&quot;https://www.extremetech.com/wp-content/uploads/2018/04/Screen-Shot-2018-04-13-at-11.53.49-AM.png&quot;&gt;&lt;img class=&quot;aligncenter size-full wp-image-267449&quot; src=&quot;https://www.extremetech.com/wp-content/uploads/2018/04/Screen-Shot-2018-04-13-at-11.53.49-AM-640x523.png&quot; alt=&quot;Bokus Atari Theft&quot; width=&quot;640&quot; height=&quot;523&quot; srcset=&quot;https://www.extremetech.com/wp-content/uploads/2018/04/Screen-Shot-2018-04-13-at-11.53.49-AM-640x523.png 640w, https://www.extremetech.com/wp-content/uploads/2018/04/Screen-Shot-2018-04-13-at-11.53.49-AM-300x245.png 300w, https://www.extremetech.com/wp-content/uploads/2018/04/Screen-Shot-2018-04-13-at-11.53.49-AM-768x628.png 768w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;/&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span id=&quot;intelliTXT&quot; name=&quot;intellitxt&quot;&gt;I reported the theft to CreateSpace yesterday and am currently waiting for a response. In the meantime, both my Atari book and the fake are still up on Amazon at the time of this writing, ready to be purchased. His copy of my book has been up on Amazon since October 23 of last year, which was also my last birthday! Who knew I had received such a present at the time? Apparently, you can save more than $5 by buying the fake one, though the inside layout leaves something to be desired:&lt;/span&gt;&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-width=&quot;500&quot; data-dnt=&quot;true&quot; readability=&quot;4.8316831683168&quot;&gt;

&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;&lt;span id=&quot;intelliTXT&quot; name=&quot;intellitxt&quot;&gt;The layout is a masterwork. &lt;a href=&quot;https://t.co/a7zApNHhRU&quot;&gt;pic.twitter.com/a7zApNHhRU&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span id=&quot;intelliTXT&quot; name=&quot;intellitxt&quot;&gt;— Kevin Savetz (@KevinSavetz) &lt;a href=&quot;https://twitter.com/KevinSavetz/status/984542842545569792?ref_src=twsrc%5Etfw&quot;&gt;April 12, 2018&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;&lt;span id=&quot;intelliTXT&quot; name=&quot;intellitxt&quot;&gt;I’ll update this post when I learn more. But in the meantime, there seems to be a genuine need for some kind of simple, automated check on CreateSpace whenever you upload a new book — at least against the already existing library of CreateSpace books. Seems like a very simple fix to prevent a bad situation like this one. Okay, I’m going to go have a small heart attack now.&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 13 Apr 2018 17:35:53 +0000</pubDate>
<dc:creator>artsandsci</dc:creator>
<og:type>article</og:type>
<og:title>Someone Stole My Entire Book (and My Job) and Is Selling It On Amazon - ExtremeTech</og:title>
<og:description>I admit that in the grand scheme of things that could go wrong in tech these days, I wasn't quite expecting this one.</og:description>
<og:url>https://www.extremetech.com/internet/267446-someone-stole-my-entire-book-and-my-job-and-is-selling-it-on-amazon</og:url>
<og:image>https://www.extremetech.com/wp-content/uploads/2017/03/Book-Desk-2.jpg</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.extremetech.com/internet/267446-someone-stole-my-entire-book-and-my-job-and-is-selling-it-on-amazon</dc:identifier>
</item>
<item>
<title>Apple Sued an iPhone Repair Shop Owner in Norway and Lost</title>
<link>https://motherboard.vice.com/en_us/article/a3yadk/apple-sued-an-independent-iphone-repair-shop-owner-and-lost</link>
<guid isPermaLink="true" >https://motherboard.vice.com/en_us/article/a3yadk/apple-sued-an-independent-iphone-repair-shop-owner-and-lost</guid>
<description>&lt;p&gt;Last year, Apple’s lawyers sent Henrik Huseby, the owner of a small electronics repair shop in Norway, a letter demanding that he immediately stop using aftermarket iPhone screens at his repair business and that he pay the company a settlement.&lt;/p&gt;
&lt;p&gt;Norway’s customs officials had seized a shipment of 63 iPhone 6 and 6S replacement screens on their way to Henrik’s shop from Asia and alerted Apple; the company said they were counterfeit.&lt;/p&gt;

&lt;p&gt;In order to avoid being sued, Apple asked Huseby for “copies of invoices, product lists, order forms, payment information, prints from the internet and other relevant material regarding the purchase [of screens], including copies of any correspondence with the supplier … we reserve the right to request further documentation at a later date.”&lt;/p&gt;
&lt;p&gt;The letter, sent by Frank Jorgensen, an attorney at the Njord law firm on behalf of Apple, included a settlement agreement that also notified him the screens would be destroyed. The settlement agreement said that Huseby agrees “not to manufacture, import, sell, market, or otherwise deal with any products that infringe Apple’s trademarks,” and asked required him to pay 27,700 Norwegian Krone ($3,566) to make the problem go away without a trial.&lt;/p&gt;
&lt;p&gt;“Intellectual Property Law is a specialized area of law, and seeking legal advice is in many instances recommended,” Jorgensen wrote in the letter accompanying the settlement agreement. “However, we can inform you that further proceedings and costs can be avoided by settling the case.”&lt;/p&gt;
&lt;p&gt;Huseby decided to fight the case.&lt;/p&gt;
&lt;p&gt;“That’s a letter I would never put my signature on,” Huseby told me in an email. “They threw all kinds of claims against me and told me the laws and acted so friendly and just wanted me to sign the letter so it would all be over. I had a good lawyer that completely understood the problem, did good research, and read the law correctly.”&lt;/p&gt;
&lt;div class=&quot;article__media&quot; readability=&quot;7&quot;&gt;&lt;img src=&quot;https://vice-web-statics-cdn.vice.com/images/blank.png&quot; alt=&quot;&quot; class=&quot;col-12-xs&quot; data-src=&quot;https://video-images.vice.com/_uncategorized/1523634889264-Screen-Shot-2018-04-13-at-115312-AM.png&quot;/&gt;&lt;p&gt;From the settlement agreement Apple asked Huseby to sign.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Apple sued him. &lt;a href=&quot;https://www.dn.no/nyheter/2018/01/28/1657/Teknologi/apple-sendte-fem-advokater-for-a-stoppe-63-mobilskjermer&quot; target=&quot;_blank&quot;&gt;Local news outlets&lt;/a&gt; reported that Apple had five lawyers in the courtroom working on the case, &lt;a href=&quot;https://www.documentcloud.org/documents/4437126-Dom-Apple-2.html&quot; target=&quot;_blank&quot;&gt;but Huseby won&lt;/a&gt;. Apple has appealed the decision to a higher court; the court has not yet decided whether to accept the appeal.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why a Norwegian court case should matter to Americans&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The specifics of Huseby’s legal case apply only in Norway, of course, but his case speaks to a problem faced by independent iPhone repair shops around the world. Apple’s use of the legal system and trademark law turns average repair professionals into criminals and helps the company corner the repair market for Apple products.&lt;/p&gt;
&lt;p&gt;In the United States, Apple has worked with the Department of Homeland Security and ICE to seize counterfeit parts in the United States and to &lt;a href=&quot;https://www.techdirt.com/articles/20130429/07214322874/homeland-security-participates-trademark-raid.shtml&quot; target=&quot;_blank&quot;&gt;raid the shops of independent iPhone repair professionals&lt;/a&gt;. ICE’s National Intellectual Property Rights Coordination Center &lt;a href=&quot;https://www.documentcloud.org/documents/4437127-ICE-Response-to-Requester-7A.html&quot; target=&quot;_blank&quot;&gt;rejected a Freedom of Information Act request&lt;/a&gt; I filed in 2016 regarding Apple’s involvement in its “Operation Chain Reaction” anti counterfeiting team, citing that doing so “could reasonably be expected to interfere with enforcement proceedings.” Apple declined to comment for this article.&lt;/p&gt;
&lt;p&gt;“In this case, Apple indirectly proves what they really want,” Par Harald Gjerstad, Huseby’s lawyer, told me in an email. “They want monopoly on repairs so they can keep high prices. And they therefore do not want to sell spare parts to anyone other than ‘to themselves.’”&lt;/p&gt;
&lt;p&gt;Apple makes its own replacement parts available only to Apple Stores and shops in its “Authorized Service Provider” program. By becoming “authorized,” repair companies have to pay Apple a fee (and buy parts from the company at a fixed rate.) They are also &lt;a href=&quot;https://motherboard.vice.com/en_us/article/ypkqxw/do-you-know-anything-about-apples-authorized-service-provider-program&quot; target=&quot;_blank&quot;&gt;restricted from performing certain types of repairs&lt;/a&gt;; there are many types of repairs—most commonly ones that require microsoldering for Logic Board damage—that independent companies can do that Apple itself does not do, so there are many reasons why a repair shop might want to remain independent.&lt;/p&gt;

&lt;p class=&quot;article__pull-quote&quot;&gt;&quot;Huseby is largely dependent on being able to import screens with covered up Apple logos to be able to operate in the market as a non-authorized iPhone repair technician&quot;&lt;/p&gt;
&lt;p&gt;Apple continues to lobby against right to repair legislation in &lt;a href=&quot;https://motherboard.vice.com/en_us/article/8xdp94/right-to-repair-california-bill&quot; target=&quot;_blank&quot;&gt;18 states around the United States&lt;/a&gt;, which would require electronics manufacturers to sell replacement parts and repair tools to the general public and independent repair companies.&lt;/p&gt;
&lt;p&gt;“Apple is proving themselves to be the worldwide poster child of the Right to Repair movement,” Gay Gordon-Byrne, executive director of Repair.org, which is pushing for this legislation, told me. “They continue to make our case for us—suing legal repair providers, such as Henrik, lying to consumers about CPU performance throttling instead of battery replacements, and the coup de grace of hypocrisy—building products that are hard to repair and then proclaiming they care about the environment.”&lt;/p&gt;
&lt;p&gt;In the absence of right to repair legislation, there are few ways for repair professionals to get replacement parts for iPhones and Apple computers. They can harvest parts from broken phones and computers, or they can buy aftermarket parts from the Chinese grey market, which is what Huseby and thousands of repair shops in the United States and around the world opt to do.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;63 aftermarket screens&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Parts on the grey market are of varying quality. Some are made in the same factories as original manufacturer parts; others are parts that “fell off the back of a truck,” or otherwise went missing or were stolen from production lines; others were made by the original manufacturer but didn’t pass diagnostic tests; others are copies made by third parties.&lt;/p&gt;

&lt;p&gt;The legal status of many of these parts remains an unanswered question around the world, but the general consensus seems to be that a part is “counterfeit” if it is masquerading as an original manufacturer part rather than an aftermarket one. Counterfeit parts are “tangible goods that infringe trademarks,” the Organization for Economic Cooperation and Development, a partnership between 35 countries and a United Nations observer, &lt;a href=&quot;http://www.oecd.org/gov/risk/trade-in-counterfeit-ict-goods-9789264270848-en.htm&quot; target=&quot;_blank&quot;&gt;wrote in a report last year&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This definition seems straightforward, but is further muddied because often broken parts—with original manufacturer logos—are sent back to China to be refurbished and sent back to independent repair companies. Are those “counterfeit” parts or are they repaired or refurbished genuine parts?&lt;/p&gt;
&lt;p&gt;For his repair operation, called PCKompaniet, Huseby imported 67 iPhone 6 and iPhone 6S screens that fell into this grey area. They were seized by Norwegian customs officials because Apple logos on the inside components of the screens “had been covered up by ink marker. The ink marker could be removed with rubbing alcohol,” according to the &lt;a href=&quot;https://www.documentcloud.org/documents/4437126-Dom-Apple-2.html&quot; target=&quot;_blank&quot;&gt;Oslo District Court decision&lt;/a&gt; that ruled in favor of Huseby.&lt;/p&gt;
&lt;p class=&quot;article__pull-quote&quot;&gt;&quot;It is not obvious to the court what trademark function justifies Apple’s choice of imprinting the Apple logo on so many internal components&quot;&lt;/p&gt;
&lt;p&gt;Huseby told me in an email that he bought the screens from a company he found at an electronics fair in Hong Kong, and that they were “refurbished screens assembled by a third party.” Huseby told the court that ‘the logo is covered up because it has never been relevant to market the products as Apple products,” the court decision states. “PCKompaniet has never removed the coverup of the Apple logo on the screens that have been imported and has no interest in doing so. PCKompaniet does not pretend or market itself as Apple authorized and does not give any indication that the repair comes with an Apple warranty.”&lt;/p&gt;

&lt;p&gt;The court decided that Norwegian law “does not prohibit a Norwegian mobile repair person from importing mobile screens from Asian manufacturers that are 100 percent compatible and completely identical to Apple’s own iPhone screens, so long as Apple’s trademark is not applied to the product.”&lt;/p&gt;
&lt;p&gt;The court noted that importing refurbished parts with visible Apple logos on them would be in violation of European Union trademark law (it would be legal, the court said, if the refurbishment of these screens had happened in the EU rather than Asia), but, crucially, decided that because the Apple logo would not be visible to customers while the product was in use, Huseby had not actually used Apple’s trademark.&lt;/p&gt;
&lt;p class=&quot;article__pull-quote&quot;&gt;&quot;Apple does not ‘own’ the product after they have sold it&quot;&lt;/p&gt;
&lt;p&gt;The court also acknowledged that Huseby doesn’t have many other options when it comes to importing quality parts that either have Apple logos permanently removed or never had them to begin with: “It is not obvious to the court what trademark function justifies Apple’s choice of imprinting the Apple logo on so many internal components,” the court wrote. “Huseby is largely dependent on being able to import screens with covered up Apple logos to be able to operate in the market as a non-authorized iPhone repair technician.”&lt;/p&gt;
&lt;p&gt;Gjerstad believes Apple will lose its appeal: “Apple does not ‘own’ the product after they have sold it,” he said. “Others have the right to remove the logo and sell it as an unoriginal, compatible part.”&lt;/p&gt;

&lt;p&gt;The specifics of Huseby’s case won’t matter for American repair shops, but that Apple continues to aggressively pursue a repair shop owner over 63 iPhone screens signals that Apple is not interested in changing its stance on independent repair, and that right to repair activists and independent repair companies should expect a long fight ahead of them: “I feel that this case was extremely important for them to win,” Huseby said.&lt;/p&gt;
&lt;p&gt;He just hopes to get back to his shop, he told me.&lt;/p&gt;
&lt;p&gt;“I will continue to repair iPhone like I did before, no change,” he said. “I’m glad I now don’t have to be afraid of importing compatible spare parts for iPhone again.”&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Anders Hillestad translated Norwegian court documents and legal documents to English for this article.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 13 Apr 2018 17:33:40 +0000</pubDate>
<dc:creator>dsr12</dc:creator>
<og:type>article</og:type>
<og:title>Apple Sued an Independent iPhone Repair Shop Owner and Lost</og:title>
<og:image>https://video-images.vice.com/articles/5ad0d2f94ad42a000d7e97fe/lede/1523634938262-Screen-Shot-2018-04-13-at-115410-AM.png?crop=1xw:0.7550223214285714xh;center,center&amp;resize=1200:*</og:image>
<og:url>https://motherboard.vice.com/en_us/article/a3yadk/apple-sued-an-independent-iphone-repair-shop-owner-and-lost</og:url>
<og:description>Apple said an unauthorized repair shop owner in Norway violated its trademark by using aftermarket iPhone parts, but a court decided in favor of the shop owner.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://motherboard.vice.com/en_us/article/a3yadk/apple-sued-an-independent-iphone-repair-shop-owner-and-lost</dc:identifier>
</item>
<item>
<title>Types of Regression Analysis</title>
<link>https://www.listendata.com/2018/03/regression-analysis.html</link>
<guid isPermaLink="true" >https://www.listendata.com/2018/03/regression-analysis.html</guid>
<description>&lt;div id=&quot;adsense-target&quot;&gt;
&lt;div dir=&quot;ltr&quot; trbidi=&quot;on&quot;&gt;
&lt;div class=&quot;tr_bq&quot;&gt;Regression techniques are one of the most popular statistical techniques used for predictive modeling and data mining tasks. On average, analytics professionals know only 2-3 types of regression which are commonly used in real world. They are linear and logistic regression. But the fact is there are more than 10 types of regression algorithms designed for various types of analysis. Each type has its own significance. Every analyst must know which form of regression to use depending on type of data and distribution.&lt;/div&gt;
&lt;br/&gt;&lt;strong&gt;&lt;span&gt;Table of Contents&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;ol&gt;&lt;li&gt;What is Regression Analysis?&lt;/li&gt;
&lt;li&gt;Terminologies related to Regression&lt;/li&gt;
&lt;li&gt;Types of Regressions
&lt;ul&gt;&lt;li&gt;Linear Regression&lt;/li&gt;
&lt;li&gt;Polynomial Regression&lt;/li&gt;
&lt;li&gt;Logistic Regression&lt;/li&gt;
&lt;li&gt;Quantile Regression&lt;/li&gt;
&lt;li&gt;Ridge Regression&lt;/li&gt;
&lt;li&gt;Lasso Regression&lt;/li&gt;
&lt;li&gt;ElasticNet Regression&lt;/li&gt;
&lt;li&gt;Principal Component Regression&lt;/li&gt;
&lt;li&gt;Partial Least Square Regression&lt;/li&gt;
&lt;li&gt;Support Vector Regression&lt;/li&gt;
&lt;li&gt;Ordinal Regression&lt;/li&gt;
&lt;li&gt;Poisson Regression&lt;/li&gt;
&lt;li&gt;Negative Binomial Regression&lt;/li&gt;
&lt;li&gt;Quasi-Poisson Regression&lt;/li&gt;
&lt;li&gt;Cox Regression&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;How to choose the correct Regression Model?&lt;/li&gt;
&lt;/ol&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-4EMj8azhdRI/WrfvScVzCVI/AAAAAAAAHJY/7l3J-uX2wFA49_Nkif7Wjm5SP713amRrgCLcBGAs/s1600/regression.PNG&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;224&quot; data-original-width=&quot;458&quot; src=&quot;https://2.bp.blogspot.com/-4EMj8azhdRI/WrfvScVzCVI/AAAAAAAAHJY/7l3J-uX2wFA49_Nkif7Wjm5SP713amRrgCLcBGAs/s1600/regression.PNG&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Regression Analysis Simplified&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2&gt;&lt;br/&gt;What is Regression Analysis?&lt;/h2&gt;
&lt;strong&gt;Lets take a simple example :&lt;/strong&gt; Suppose your manager asked you to predict annual sales. There can be a hundred of factors (drivers) that affects sales. In this case, sales is your &lt;strong&gt;dependent variable&lt;/strong&gt;. Factors affecting sales are &lt;strong&gt;independent variables&lt;/strong&gt;. Regression analysis would help you to solve this problem.&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;In simple words, regression analysis is used to model the relationship between a dependent variable and one or more independent variables.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;It helps us to answer the following questions -&lt;br/&gt;&lt;ol&gt;&lt;li&gt;Which of the drivers have a significant impact on sales. &lt;/li&gt;
&lt;li&gt;Which is the most important driver of sales&lt;/li&gt;
&lt;li&gt;How do the drivers interact with each other&lt;/li&gt;
&lt;li&gt;What would be the annual sales next year.&lt;/li&gt;
&lt;/ol&gt;&lt;br/&gt;&lt;h2&gt;&lt;strong&gt;Terminologies related to regression analysis&lt;/strong&gt;&lt;/h2&gt;
&lt;strong&gt;&lt;span&gt;1. Outliers&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;Suppose there is an observation in the dataset which is having a very high or very low value as compared to the other observations in the data, i.e. it does not belong to the population, such an observation is called an outlier. In simple words, it is extreme value. An outlier is a problem because many times it hampers the results we get.&lt;p&gt;&lt;span&gt;&lt;strong&gt;2. Multicollinearity&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;When the independent variables are highly correlated to each other then the variables are said to be multicollinear. Many types of regression techniques assumes multicollinearity should not be present in the dataset. It is because it causes problems in ranking variables based on its importance. Or it makes job difficult in selecting the most important independent variable (factor).&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. Heteroscedasticity&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;When dependent variable's variability is not equal across values of an independent variable, it is called heteroscedasticity. &lt;strong&gt;Example -&lt;/strong&gt; As one's income increases, the variability of food consumption will increase. A poorer person will spend a rather constant amount by always eating inexpensive food; a wealthier person may occasionally buy inexpensive food and at other times eat expensive meals. Those with higher incomes display a greater variability of food consumption.&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;4. Underfitting and Overfitting&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;When we use unnecessary explanatory variables it might lead to overfitting. Overfitting means that our algorithm works well on the training set but is unable to perform better on the test sets. It is also known as problem of &lt;strong&gt;high variance.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;When our algorithm works so poorly that it is unable to fit even training set well then it is said to &lt;strong&gt;underfit the data.&lt;/strong&gt; It is also known as &lt;strong&gt;problem of high bias.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In the following diagram we can see that fitting a linear regression (straight line in fig 1) would underfit the data i.e. it will lead to large errors even in the training set. Using a polynomial fit in fig 2 is balanced i.e. such a fit can work on the training and test sets well, while in fig 3 the fit will lead to low errors in training set but it will not work well on the test set.&lt;br/&gt;&lt;/p&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-dM4Iae3kVsQ/Wlt28eEHHiI/AAAAAAAACPg/X0dIT2a6RMwdEFUO44fQVX9HXakraYBagCLcBGAs/s1600/img1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img alt=&quot;Underfitting vs Overfitting&quot; border=&quot;0&quot; data-original-height=&quot;216&quot; data-original-width=&quot;715&quot; height=&quot;192&quot; src=&quot;https://4.bp.blogspot.com/-dM4Iae3kVsQ/Wlt28eEHHiI/AAAAAAAACPg/X0dIT2a6RMwdEFUO44fQVX9HXakraYBagCLcBGAs/s640/img1.png&quot; title=&quot;&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Regression : Underfitting and Overfitting&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2&gt;Types of Regression&lt;/h2&gt;
Every regression technique has some assumptions attached to it which we need to meet before running analysis. These techniques differ in terms of type of dependent and independent variables and distribution.&lt;div&gt;
&lt;h2&gt;&lt;span&gt;1. Linear Regression&lt;/span&gt;&lt;/h2&gt;
It is the simplest form of regression. It is a technique in which the &lt;strong&gt;dependent variable is continuous&lt;/strong&gt; in nature. The relationship between the dependent variable and independent variables is assumed to be linear in nature. We can observe that the given plot represents a somehow linear relationship between the mileage and displacement of cars. The &lt;span&gt;&lt;strong&gt;green points&lt;/strong&gt;&lt;/span&gt; are the actual observations while the &lt;strong&gt;black line fitted&lt;/strong&gt; is the line of regression&lt;/div&gt;
&lt;br/&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-IOOxgPaXMVc/Wlj3LWvcnjI/AAAAAAAACKE/UeTFYvAxDmUDel5UBjdifeWaApB3-dXVgCLcBGAs/s1600/img1.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img alt=&quot;regression analysis&quot; border=&quot;0&quot; data-original-height=&quot;299&quot; data-original-width=&quot;496&quot; src=&quot;https://4.bp.blogspot.com/-IOOxgPaXMVc/Wlj3LWvcnjI/AAAAAAAACKE/UeTFYvAxDmUDel5UBjdifeWaApB3-dXVgCLcBGAs/s1600/img1.jpg&quot; title=&quot;&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Regression Analysis&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;When you have &lt;code&gt;only 1 independent variable&lt;/code&gt; and 1 dependent variable, it is called simple linear regression.&lt;br/&gt;When you have &lt;code&gt;more than 1 independent variable&lt;/code&gt; and 1 dependent variable, it is called Multiple linear regression.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div&gt;

&lt;div&gt;&lt;strong&gt;&lt;span&gt;The equation of multiple linear regression is listed below -&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-xbqTM5K3bIU/WkzhtHMPEmI/AAAAAAAACFs/RULnlMKw_0U14oRWOUcuETJNt9TBYiJEgCLcBGAs/s1600/b.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;44&quot; data-original-width=&quot;320&quot; src=&quot;https://2.bp.blogspot.com/-xbqTM5K3bIU/WkzhtHMPEmI/AAAAAAAACFs/RULnlMKw_0U14oRWOUcuETJNt9TBYiJEgCLcBGAs/s1600/b.jpg&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;br/&gt;Multiple Regression Equation&lt;br/&gt;Here 'y' is the dependent variable to be estimated, and X are the independent variables and ε is the error term. βi’s are the regression coefficients.&lt;p&gt;&lt;strong&gt;&lt;span&gt;Assumptions of linear regression: &lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;There must be a linear relation between independent and dependent variables. &lt;/li&gt;
&lt;li&gt;There should not be any outliers present. &lt;/li&gt;
&lt;li&gt;No heteroscedasticity &lt;/li&gt;
&lt;li&gt;Sample observations should be independent. &lt;/li&gt;
&lt;li&gt;Error terms should be normally distributed with mean 0 and constant variance. &lt;/li&gt;
&lt;li&gt;Absence of multicollinearity and auto-correlation.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&quot;separator&quot;&gt;&lt;strong&gt;&lt;span&gt;Estimating the parameters&lt;/span&gt;&lt;/strong&gt;To estimate the regression coefficients βi’s we use principle of least squares which is to minimize the sum of squares due to the error terms i.e.&lt;/div&gt;
&lt;br/&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-bHdTkTHhk-A/Wlj7qArK-vI/AAAAAAAACKQ/Afedqlb4p1AFVg9MO623FbdUhZKmIeFXACLcBGAs/s1600/img2.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;38&quot; data-original-width=&quot;332&quot; height=&quot;43&quot; src=&quot;https://3.bp.blogspot.com/-bHdTkTHhk-A/Wlj7qArK-vI/AAAAAAAACKQ/Afedqlb4p1AFVg9MO623FbdUhZKmIeFXACLcBGAs/s400/img2.jpg&quot; width=&quot;400&quot;/&gt;&lt;/a&gt;&lt;br/&gt;&lt;div&gt;On solving the above equation mathematically we obtain the regression coefficients as:&lt;/div&gt;
&lt;div class=&quot;separator&quot;&gt;&lt;span&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-Srjys9kedH8/Wlj8XpIW4dI/AAAAAAAACKY/KeuZNb4RZpkoKrtFmpoDbq07ZXeKBvI1wCLcBGAs/s1600/img3.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;35&quot; data-original-width=&quot;135&quot; height=&quot;51&quot; src=&quot;https://4.bp.blogspot.com/-Srjys9kedH8/Wlj8XpIW4dI/AAAAAAAACKY/KeuZNb4RZpkoKrtFmpoDbq07ZXeKBvI1wCLcBGAs/s200/img3.jpg&quot; width=&quot;200&quot;/&gt;&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;
&lt;br/&gt;&lt;strong&gt;&lt;span&gt;Interpretation of regression coefficients&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;Let us consider an example where the dependent variable is marks obtained by a student and explanatory variables are number of hours studied and no. of classes attended. Suppose on fitting linear regression we got the linear regression as:&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;Marks obtained = 5 + 2 (no. of hours studied) + 0.5(no. of classes attended)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div&gt;Thus we can have the regression coefficients 2 and 0.5 which can interpreted as:&lt;/div&gt;
&lt;div&gt;
&lt;ol&gt;&lt;li&gt;If no. of hours studied and no. of classes are 0 then the student will obtain 5 marks.&lt;/li&gt;
&lt;li&gt;Keeping no. of classes attended constant, if student studies for one hour more then he will score 2 more marks in the examination. &lt;/li&gt;
&lt;li&gt;Similarly keeping no. of hours studied constant, if student attends one more class then he will attain 0.5 marks more.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div&gt;&lt;span&gt;Linear Regression in R&lt;/span&gt;&lt;/div&gt;
&lt;div&gt;
&lt;div&gt;We consider the swiss data set for carrying out linear regression in R. We use lm() function in the base package. We try to estimate Fertility with the help of other variables.&lt;/div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;library(datasets)&lt;br/&gt;model = lm(Fertility ~ .,data = swiss)&lt;br/&gt;lm_coeff = model$coefficients&lt;br/&gt;lm_coeff&lt;br/&gt;summary(model)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;span&gt;The output we get is:&lt;/span&gt;&lt;/div&gt;
&lt;br/&gt;&amp;gt; lm_coeff&lt;pre&gt;
     (Intercept)      Agriculture      Examination        Education         Catholic 
      66.9151817       -0.1721140       -0.2580082       -0.8709401        0.1041153 
Infant.Mortality 
       1.0770481 
&amp;gt; summary(model)

Call:
lm(formula = Fertility ~ ., data = swiss)

Residuals:
     Min       1Q   Median       3Q      Max 
-15.2743  -5.2617   0.5032   4.1198  15.3213 

Coefficients:
                 Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)      66.91518   10.70604   6.250 1.91e-07 ***
Agriculture      -0.17211    0.07030  -2.448  0.01873 *  
Examination      -0.25801    0.25388  -1.016  0.31546    
Education        -0.87094    0.18303  -4.758 2.43e-05 ***
Catholic          0.10412    0.03526   2.953  0.00519 ** 
Infant.Mortality  1.07705    0.38172   2.822  0.00734 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 7.165 on 41 degrees of freedom
Multiple R-squared:  0.7067, Adjusted R-squared:  0.671 
F-statistic: 19.76 on 5 and 41 DF,  p-value: 5.594e-10
&lt;/pre&gt;
&lt;div&gt;Hence we can see that 70% of the variation in Fertility rate can be explained via linear regression.&lt;/div&gt;
&lt;h2&gt;&lt;span&gt;2. Polynomial Regression&lt;/span&gt;&lt;/h2&gt;
&lt;div&gt;It is a technique to fit a nonlinear equation by taking polynomial functions of independent variable.&lt;br/&gt;In the figure given below, you can see the red curve fits the data better than the green curve. Hence in the situations where the relation between the dependent and independent variable seems to be non-linear we can deploy &lt;strong&gt;Polynomial Regression Models.&lt;/strong&gt;&lt;/div&gt;
&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-dODuK8N5h1Q/Wlnyb3V9HFI/AAAAAAAACL4/WxQtCJ1pM5wccDABg4wIrTBUB0vlikXQQCLcBGAs/s1600/poly1.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;258&quot; data-original-width=&quot;469&quot; src=&quot;https://1.bp.blogspot.com/-dODuK8N5h1Q/Wlnyb3V9HFI/AAAAAAAACL4/WxQtCJ1pM5wccDABg4wIrTBUB0vlikXQQCLcBGAs/s1600/poly1.jpg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;Thus a polynomial of degree k in one variable is written as:&lt;/div&gt;
&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-wrJdHn0X_Y8/Wln1K2YZO5I/AAAAAAAACMI/gScVjBesYCY0S4bqUV_tVL6DELUjVcvLwCLcBGAs/s1600/poly2.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;43&quot; data-original-width=&quot;242&quot; src=&quot;https://1.bp.blogspot.com/-wrJdHn0X_Y8/Wln1K2YZO5I/AAAAAAAACMI/gScVjBesYCY0S4bqUV_tVL6DELUjVcvLwCLcBGAs/s1600/poly2.jpg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;Here we can create new features like&lt;/div&gt;
&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-cCV9hGqL9LQ/Wln157jicDI/AAAAAAAACMQ/oiIreV5AsTYAB26KLHAI_fnoxbVMevuNgCLcBGAs/s1600/poly3.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;29&quot; data-original-width=&quot;158&quot; height=&quot;35&quot; src=&quot;https://2.bp.blogspot.com/-cCV9hGqL9LQ/Wln157jicDI/AAAAAAAACMQ/oiIreV5AsTYAB26KLHAI_fnoxbVMevuNgCLcBGAs/s200/poly3.jpg&quot; width=&quot;200&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;and can fit linear regression in the similar manner.&lt;/div&gt;
&lt;br/&gt;In case of multiple variables say X1 and X2, we can create a third new feature (say X3) which is the product of X1 and X2 i.e.&lt;br/&gt;&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-7PfDLmtSWJk/Wln2md8NJ2I/AAAAAAAACMc/XpDcnrF4Md0jd-jmBXRI5yY_TgMnGWChACLcBGAs/s1600/poly5.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;27&quot; data-original-width=&quot;78&quot; src=&quot;https://1.bp.blogspot.com/-7PfDLmtSWJk/Wln2md8NJ2I/AAAAAAAACMc/XpDcnrF4Md0jd-jmBXRI5yY_TgMnGWChACLcBGAs/s1600/poly5.jpg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;strong&gt;Disclaimer:&lt;/strong&gt; It is to be kept in mind that creating unnecessary extra features or fitting polynomials of higher degree may lead to overfitting.&lt;/div&gt;
&lt;div&gt;&lt;span&gt;&lt;strong&gt;Polynomial regression in R:&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;div&gt;&lt;span&gt;We are using &lt;a href=&quot;https://sites.google.com/site/breathe42/poly.csv&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;poly.csv&lt;/strong&gt;&lt;/a&gt; data for fitting polynomial regression where we try to estimate the Prices of the house given their area.&lt;/span&gt;&lt;/div&gt;
&lt;br/&gt;Firstly we read the data using &lt;strong&gt;read.csv( )&lt;/strong&gt; and divide it into the dependent and independent variable&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;data = read.csv(&quot;poly.csv&quot;)&lt;br/&gt;x = data$Area&lt;br/&gt;y = data$Price&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
In order to compare the results of linear and polynomial regression, firstly we fit linear regression:&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;model1 = lm(y ~x)&lt;br/&gt;model1$fit&lt;br/&gt;model1$coeff&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;div&gt;The coefficients and predicted values obtained are:&lt;/div&gt;
&lt;pre&gt;
&amp;gt; model1$fit
       1        2        3        4        5        6        7        8        9       10 
169.0995 178.9081 188.7167 218.1424 223.0467 266.6949 291.7068 296.6111 316.2282 335.8454 
&amp;gt; model1$coeff
 (Intercept)            x 
120.05663769   0.09808581 &lt;span&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;div&gt;We create a dataframe where the new variable are x and x square.&lt;/div&gt;
&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;new_x = cbind(x,x^2)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;new_x&lt;pre&gt;
         x        
 [1,]  500  250000
 [2,]  600  360000
 [3,]  700  490000
 [4,] 1000 1000000
 [5,] 1050 1102500
 [6,] 1495 2235025
 [7,] 1750 3062500
 [8,] 1800 3240000
 [9,] 2000 4000000
[10,] 2200 4840000
&lt;/pre&gt;
Now we fit usual OLS to the new data:&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;model2 = lm(y~new_x)&lt;br/&gt;model2$fit&lt;br/&gt;model2$coeff&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;The fitted values and regression coefficients of polynomial regression are:&lt;pre&gt;
&amp;gt; model2$fit
       1        2        3        4        5        6        7        8        9       10 
122.5388 153.9997 182.6550 251.7872 260.8543 310.6514 314.1467 312.6928 299.8631 275.8110 
&amp;gt; model2$coeff
  (Intercept)        new_xx         new_x 
-7.684980e+01  4.689175e-01 -1.402805e-04 
&lt;/pre&gt;

Using ggplot2 package we try to create a plot to compare the curves by both linear and polynomial regression.&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;library(ggplot2)&lt;br/&gt;ggplot(data = data) + geom_point(aes(x = Area,y = Price)) +&lt;br/&gt;geom_line(aes(x = Area,y = model1$fit),color = &quot;red&quot;) +&lt;br/&gt;geom_line(aes(x = Area,y = model2$fit),color = &quot;blue&quot;) +&lt;br/&gt;theme(panel.background = element_blank())&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-GC6CZTGEsW0/Wls-Q-ROh_I/AAAAAAAACN0/1USwBPjxa60fgR_0K62HH2XUVGIl8T7-wCLcBGAs/s1600/poly.jpeg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;356&quot; data-original-width=&quot;500&quot; src=&quot;https://3.bp.blogspot.com/-GC6CZTGEsW0/Wls-Q-ROh_I/AAAAAAAACN0/1USwBPjxa60fgR_0K62HH2XUVGIl8T7-wCLcBGAs/s1600/poly.jpeg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;span&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;h2&gt;&lt;strong&gt;3. Logistic Regression&lt;/strong&gt;&lt;/h2&gt;
&lt;div&gt;In logistic regression, the dependent variable is binary in nature (having two categories). Independent variables can be continuous or binary. In multinomial logistic regression, you can have more than two categories in your dependent variable.&lt;/div&gt;
&lt;br/&gt;&lt;div&gt;Here my model is:&lt;br/&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-rsjL8rX6Q38/VryuBND_wZI/AAAAAAAAD_w/Fpb9x6BfsuY/s1600/Optimized-prob%2Blogit%2B%25281%2529.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img alt=&quot;logistic regression&quot; border=&quot;0&quot; data-original-height=&quot;81&quot; data-original-width=&quot;314&quot; src=&quot;https://1.bp.blogspot.com/-rsjL8rX6Q38/VryuBND_wZI/AAAAAAAAD_w/Fpb9x6BfsuY/s1600/Optimized-prob%2Blogit%2B%25281%2529.png&quot; title=&quot;&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;logistic regression equation&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br/&gt;&lt;/div&gt;
&lt;span&gt;&lt;strong&gt;Why don't we use linear regression in this case?&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;ul&gt;&lt;li&gt;The homoscedasticity assumption is violated.&lt;/li&gt;
&lt;li&gt;Errors are not normally distributed&lt;/li&gt;
&lt;li&gt;y follows binomial distribution and hence is not normal.&lt;/li&gt;
&lt;/ul&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;Examples&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;HR Analytics:&lt;/strong&gt; IT firms recruit large number of people, but one of the problems they encounter is after accepting the job offer many candidates do not join. So, this results in cost over-runs because they have to repeat the entire process again. Now when you get an application, can you actually predict whether that applicant is likely to join the organization (Binary Outcome - Join / Not Join).&lt;/li&gt;
&lt;li&gt;&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Elections: &lt;/strong&gt;Suppose that we are interested in the factors that influence whether a political candidate wins an election. The outcome (response) variable is binary (0/1); win or lose. The predictor variables of interest are the amount of money spent on the campaign and the amount of time spent campaigning negatively.&lt;/li&gt;
&lt;/ul&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;Predicting the category of dependent variable for a given vector X of independent variables&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;Through logistic regression we have -&lt;/span&gt;&lt;br/&gt;&lt;div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;P(Y=1) = exp(a + BₙX)  / (1+ exp(a + BₙX))&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;/div&gt;
&lt;div&gt;Thus we choose a cut-off of probability say 'p'  and if P(Yi = 1) &amp;gt; p then we can say that Yi belongs to class 1 otherwise 0.&lt;/div&gt;
&lt;br/&gt;&lt;span&gt;&lt;strong&gt;Interpreting the logistic regression coefficients (Concept of Odds Ratio)&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;div&gt;If we take exponential of coefficients, then we’ll get odds ratio for ith explanatory variable. Suppose odds ratio is equal to two, then the odds of event is 2 times greater than the odds of non-event. Suppose dependent variable is customer attrition (whether customer will close relationship with the company) and independent variable is citizenship status (National / Expat). The odds of expat attrite is 3 times greater than the odds of a national attrite.&lt;/div&gt;
&lt;div&gt;&lt;br/&gt;&lt;div&gt;&lt;span&gt;Logistic Regression in R:&lt;/span&gt;&lt;/div&gt;
&lt;div&gt;In this case, we are trying to estimate whether a person will have cancer depending whether he smokes or not.&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We fit logistic regression with &lt;strong&gt;glm( ) &lt;/strong&gt; function and we set &lt;strong&gt;family = &quot;binomial&quot;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;model &amp;lt;- glm(Lung.Cancer..Y.~Smoking..X.,data = data, family = &quot;binomial&quot;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div&gt;The predicted probabilities are given by:&lt;/div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;#Predicted Probablities&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;model$fitted.values&lt;pre&gt;
        1         2         3         4         5         6         7         8         9 
0.4545455 0.4545455 0.6428571 0.6428571 0.4545455 0.4545455 0.4545455 0.4545455 0.6428571 
       10        11        12        13        14        15        16        17        18 
0.6428571 0.4545455 0.4545455 0.6428571 0.6428571 0.6428571 0.4545455 0.6428571 0.6428571 
       19        20        21        22        23        24        25 
0.6428571 0.4545455 0.6428571 0.6428571 0.4545455 0.6428571 0.6428571 
&lt;/pre&gt;
&lt;div&gt;Predicting whether the person will have cancer or not when we choose the cut off probability to be 0.5&lt;/div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;data$prediction &amp;lt;- model$fitted.values&amp;gt;0.5&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&amp;gt; data$prediction
 [1] FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE  TRUE  TRUE  TRUE
[16] FALSE  TRUE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE
&lt;/pre&gt;

&lt;h2&gt;&lt;strong&gt;4. Quantile Regression&lt;/strong&gt;&lt;/h2&gt;
&lt;div&gt;Quantile regression is the extension of linear regression and we generally use it when outliers, high skeweness and heteroscedasticity exist in the data.&lt;p&gt;In linear regression, we predict the mean of the dependent variable for given independent variables. Since mean does not describe the whole distribution, so modeling the mean is not a full description of a relationship between dependent and independent variables. So we can use quantile regression which predicts a quantile (or percentile) for given independent variables.&lt;br/&gt;&lt;/p&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;The term “quantile” is the same as “percentile”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;br/&gt;&lt;strong&gt;&lt;span&gt;Basic Idea of Quantile Regression:&lt;/span&gt;&lt;/strong&gt; In quantile regression we try to estimate the quantile of the dependent variable given the values of X's. &lt;strong&gt;Note&lt;/strong&gt; that the dependent variable should be continuous.&lt;p&gt;&lt;strong&gt;The quantile regression model:&lt;/strong&gt;&lt;br/&gt;For qth quantile we have the following regression model:&lt;br/&gt;&lt;/p&gt;&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-v3umgz7unTs/Wllzkp4y5YI/AAAAAAAACK4/xAokU6rrQPMKyLsHtvn65bbIgfedSGMCwCLcBGAs/s1600/img5.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;29&quot; data-original-width=&quot;96&quot; src=&quot;https://3.bp.blogspot.com/-v3umgz7unTs/Wllzkp4y5YI/AAAAAAAACK4/xAokU6rrQPMKyLsHtvn65bbIgfedSGMCwCLcBGAs/s1600/img5.jpg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
This seems similar to linear regression model but here the objective function we consider to minimize is:&lt;br/&gt;&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-iQrIMqXI4Rk/Wll0V465mOI/AAAAAAAACLA/YPTqA4MhAGYE0u0P8NF23UTDIQM_R9PkQCLcBGAs/s1600/img6.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;48&quot; data-original-width=&quot;194&quot; src=&quot;https://1.bp.blogspot.com/-iQrIMqXI4Rk/Wll0V465mOI/AAAAAAAACLA/YPTqA4MhAGYE0u0P8NF23UTDIQM_R9PkQCLcBGAs/s1600/img6.jpg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
where q is the qth quantile.&lt;p&gt;If q  = 0.5 i.e. if we are interested in the median then it becomes &lt;strong&gt;median regression&lt;/strong&gt; (or least absolute deviation regression) and substituting the value of q = 0.5 in above equation we get the objective function as:&lt;br/&gt;&lt;/p&gt;&lt;div class=&quot;separator&quot;&gt;&lt;span&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-W3cULkOl6vs/Wll1AfbrzWI/AAAAAAAACLM/TYEZb0HImycDIAOMXh_dU1l7NeOWt9HVgCLcBGAs/s1600/img%2B7.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;59&quot; data-original-width=&quot;63&quot; src=&quot;https://2.bp.blogspot.com/-W3cULkOl6vs/Wll1AfbrzWI/AAAAAAAACLM/TYEZb0HImycDIAOMXh_dU1l7NeOWt9HVgCLcBGAs/s1600/img%2B7.jpg&quot;/&gt;&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;
&lt;strong&gt;&lt;span&gt;Interpreting the coefficients in quantile regression:&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;div class=&quot;separator&quot;&gt;Suppose the regression equation for 25th quantile of regression is: &lt;/div&gt;
&lt;div class=&quot;separator&quot;&gt;y = 5.2333 + 700.823 x&lt;/div&gt;

&lt;div class=&quot;separator&quot;&gt;It means that for one unit increase in x the estimated increase in 25th quantile of y by 700.823 units.&lt;/div&gt;
&lt;strong&gt;&lt;span&gt;Advantages of Quantile over Linear Regression&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;ul&gt;&lt;li&gt;Quite beneficial when heteroscedasticity is present in the data.&lt;/li&gt;
&lt;li&gt;Robust to outliers&lt;/li&gt;
&lt;li&gt;Distribution of dependent variable can be described via various quantiles.&lt;/li&gt;
&lt;li&gt;It is more useful than linear regression when the data is skewed.&lt;/li&gt;
&lt;/ul&gt;&lt;br/&gt;&lt;strong&gt;&lt;span&gt;Disclaimer on using quantile regression!&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;div class=&quot;separator&quot;&gt;It is to be kept in mind that the coefficients which we get in quantile regression for a particular quantile should differ significantly from those we obtain from linear regression. If it is not so then our usage of quantile regression isn't justifiable. This can be done by observing the confidence intervals of regression coefficients of the estimates obtained from both the regressions.&lt;/div&gt;

&lt;span&gt;Quantile Regression in R&lt;/span&gt;&lt;br/&gt;&lt;div&gt;
&lt;div&gt;We need to install &lt;strong&gt;quantreg&lt;/strong&gt; package in order to carry out quantile regression.&lt;/div&gt;
&lt;/div&gt;
&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;install.packages(&quot;quantreg&quot;)&lt;br/&gt;library(quantreg)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;div&gt;Using &lt;strong&gt;rq&lt;/strong&gt; function we try to predict the estimate the 25th quantile of Fertility Rate in &lt;strong&gt;Swiss data.&lt;/strong&gt; For this we set &lt;strong&gt;tau = 0.25.&lt;/strong&gt;&lt;/div&gt;
&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;model1 = rq(Fertility~.,data = swiss,tau = 0.25)&lt;br/&gt;summary(model1)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
tau: [1] 0.25

Coefficients:
                 coefficients lower bd upper bd
(Intercept)      76.63132      2.12518 93.99111
Agriculture      -0.18242     -0.44407  0.10603
Examination      -0.53411     -0.91580  0.63449
Education        -0.82689     -1.25865 -0.50734
Catholic          0.06116      0.00420  0.22848
Infant.Mortality  0.69341     -0.10562  2.36095
&lt;/pre&gt;
&lt;br/&gt;&lt;div&gt;Setting tau = 0.5 we run the median regression.&lt;/div&gt;
&lt;div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;model2 = rq(Fertility~.,data = swiss,tau = 0.5)&lt;br/&gt;summary(model2)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;pre&gt;
tau: [1] 0.5

Coefficients:
                 coefficients lower bd upper bd
(Intercept)      63.49087     38.04597 87.66320
Agriculture      -0.20222     -0.32091 -0.05780
Examination      -0.45678     -1.04305  0.34613
Education        -0.79138     -1.25182 -0.06436
Catholic          0.10385      0.01947  0.15534
Infant.Mortality  1.45550      0.87146  2.21101
&lt;/pre&gt;
&lt;br/&gt;&lt;div&gt;
&lt;div&gt;We can run quantile regression for multiple quantiles in a single plot.&lt;/div&gt;
&lt;/div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;model3 = rq(Fertility~.,data = swiss, tau = seq(0.05,0.95,by = 0.05))&lt;br/&gt;quantplot = summary(model3)&lt;br/&gt;quantplot&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;div&gt;We can check whether our quantile regression results differ from the OLS results using plots.&lt;/div&gt;
&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;plot(quantplot)&lt;/p&gt;
&lt;/blockquote&gt;
We get the following plot:&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-hQ1Vi3BsoC8/WlsZrq7z3mI/AAAAAAAACNk/PCxLz7EPpiIAtzUv3dWuNrluRr8mbo6dwCLcBGAs/s1600/quantplot.jpeg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;356&quot; data-original-width=&quot;500&quot; height=&quot;452&quot; src=&quot;https://3.bp.blogspot.com/-hQ1Vi3BsoC8/WlsZrq7z3mI/AAAAAAAACNk/PCxLz7EPpiIAtzUv3dWuNrluRr8mbo6dwCLcBGAs/s640/quantplot.jpeg&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
Various quantiles are depicted by X axis. The red central line denotes the estimates of OLS coefficients and the dotted red lines are the confidence intervals around those OLS coefficients for various quantiles. The black dotted line are the &lt;strong&gt;quantile regression estimates&lt;/strong&gt; and the gray area is the confidence interval for them for various quantiles. We can see that for all the variable both the regression estimated coincide for most of the quantiles. Hence our use of quantile regression is not justifiable for such quantiles. In other words we want that both the red and the gray lines should overlap as less as possible to justify our use of quantile regression.&lt;h2&gt;5. Ridge Regression&lt;/h2&gt;
&lt;div&gt;It's important to understand the concept of regularization before jumping to ridge regression.&lt;/div&gt;
&lt;br/&gt;&lt;h3&gt;1. Regularization&lt;/h3&gt;
&lt;div&gt;Regularization helps to solve over fitting problem which implies model performing well on training data but performing poorly on validation (test) data. Regularization solves this problem by adding a penalty term to the objective function and control the model complexity using that penalty term.&lt;p&gt;Regularization is generally useful in the following situations:&lt;br/&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Large number of variables&lt;/li&gt;
&lt;li&gt;Low ratio of number observations to number of variables&lt;/li&gt;
&lt;li&gt;High Multi-Collinearity&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
&lt;br/&gt;&lt;h3&gt;2. &lt;strong&gt;L1 Loss function or L1 Regularization&lt;/strong&gt;&lt;/h3&gt;
&lt;div&gt;In L1 regularization we try to minimize the objective function by adding a penalty term to the &lt;strong&gt;sum of the absolute values of coefficients. &lt;/strong&gt; This is also known as least absolute deviations method. Lasso Regression makes use of L1 regularization.&lt;/div&gt;
&lt;br/&gt;&lt;h3&gt;3. L2 Loss function or L2 Regularization&lt;/h3&gt;
&lt;div&gt;In L2 regularization we try to minimize the objective function by adding a penalty term to the &lt;strong&gt;sum of the squares of coefficients. &lt;/strong&gt;Ridge Regression or shrinkage regression makes use of L2 regularization.&lt;/div&gt;
&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;In general, L2 performs better than L1 regularization. L2 is efficient in terms of computation. There is one area where L1 is considered as a preferred option over L2. L1 has in-built feature selection for sparse feature spaces.  For example, you are predicting whether a person is having a brain tumor using more than 20,000 genetic markers (features). It is known that the vast majority of genes have little or no effect on the presence or severity of most diseases.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;div&gt;In the linear regression objective function we try to minimize the sum of squares of errors. &lt;strong&gt;In ridge regression&lt;/strong&gt; (also known as shrinkage regression) we add a constraint on the sum of squares of the regression coefficients. Thus in ridge regression our objective function is:&lt;/div&gt;
&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-mQhz_RBk_Rs/WlrsUXF0U3I/AAAAAAAACMs/OZ2nOGaYYVk457X9Y3h1cC0d_ajcMTUDACLcBGAs/s1600/ridge1.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;38&quot; data-original-width=&quot;461&quot; src=&quot;https://2.bp.blogspot.com/-mQhz_RBk_Rs/WlrsUXF0U3I/AAAAAAAACMs/OZ2nOGaYYVk457X9Y3h1cC0d_ajcMTUDACLcBGAs/s1600/ridge1.jpg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;Here &lt;strong&gt;λ is the regularization parameter&lt;/strong&gt; which is a non negative number. Here we do not assume normality in the error terms.&lt;/div&gt;
&lt;br/&gt;&lt;strong&gt;&lt;span&gt;Very Important Note: &lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;We do not regularize the intercept term. The constraint is just on the sum of squares of regression coefficients of X's.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div&gt;We can see that ridge regression makes use of &lt;strong&gt;L2 regularization.&lt;/strong&gt;&lt;/div&gt;
&lt;p&gt;On solving the above objective function we can get the estimates of &lt;span&gt;β as:&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-CDhsY4B8YWQ/WlrunCkg0KI/AAAAAAAACM4/ff1hN83GwjIjSdA1tBOhVxF_TI6xwzXpQCLcBGAs/s1600/ridge2.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;64&quot; data-original-width=&quot;314&quot; src=&quot;https://3.bp.blogspot.com/-CDhsY4B8YWQ/WlrunCkg0KI/AAAAAAAACM4/ff1hN83GwjIjSdA1tBOhVxF_TI6xwzXpQCLcBGAs/s1600/ridge2.jpg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;br/&gt;&lt;strong&gt;&lt;span&gt;How can we choose the regularization parameter λ?&lt;/span&gt;&lt;/strong&gt;&lt;p&gt;If we choose lambda = 0 then we get back to the usual OLS estimates. If lambda is chosen to be very large then it will lead to underfitting. Thus it is highly important to determine a desirable value of lambda. To tackle this issue, we plot the parameter estimates against different values of lambda and select the minimum value of λ after which the parameters tend to stabilize.&lt;br/&gt;&lt;/p&gt;
&lt;div&gt;
&lt;h3&gt;&lt;span&gt;R code for Ridge Regression&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;div&gt;Considering the swiss data set, we create two different datasets, one containing dependent variable and other containing independent variables.&lt;/div&gt;
&lt;/div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;X = swiss[,-1]&lt;br/&gt;y = swiss[,1]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;div&gt;We need to load &lt;strong&gt;glmnet&lt;/strong&gt; library to carry out ridge regression.&lt;/div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;library(glmnet)&lt;/p&gt;
&lt;/blockquote&gt;
Using &lt;strong&gt;cv.glmnet( )&lt;/strong&gt; function we can do cross validation. By default &lt;strong&gt;alpha = 0&lt;/strong&gt; which means we are carrying out ridge regression. &lt;strong&gt;lambda&lt;/strong&gt; is a sequence of various values of lambda which will be used for cross validation.&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;set.seed(123) #Setting the seed to get similar results.&lt;br/&gt;model = cv.glmnet(as.matrix(X),y,alpha = 0,lambda = 10^seq(4,-1,-0.1))&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;div&gt;We take the best lambda by using &lt;strong&gt;lambda.min&lt;/strong&gt; and hence get the regression coefficients using &lt;strong&gt;predict&lt;/strong&gt; function.&lt;/div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;best_lambda = model$lambda.min&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;ridge_coeff = predict(model,s = best_lambda,type = &quot;coefficients&quot;)&lt;br/&gt;ridge_coeff The coefficients obtained using ridge regression are:&lt;pre&gt;
6 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
                           1
(Intercept)      64.92994664
Agriculture      -0.13619967
Examination      -0.31024840
Education        -0.75679979
Catholic          0.08978917
Infant.Mortality  1.09527837
&lt;/pre&gt;
&lt;br/&gt;&lt;strong&gt;&lt;span&gt;6. Lasso Regression&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;div&gt;Lasso stands for &lt;strong&gt;Least Absolute Shrinkage and Selection Operator&lt;/strong&gt;. It makes use of &lt;strong&gt;L1 regularization&lt;/strong&gt; technique in the objective function. Thus the objective function in LASSO regression becomes:&lt;/div&gt;
&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-vy7hx5HBZog/WlrxD3WTeGI/AAAAAAAACNE/qXVszdrqEmEhd8FLFT_Hz6uu3MXVzVXBwCLcBGAs/s1600/lasso%2B1.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;42&quot; data-original-width=&quot;472&quot; src=&quot;https://1.bp.blogspot.com/-vy7hx5HBZog/WlrxD3WTeGI/AAAAAAAACNE/qXVszdrqEmEhd8FLFT_Hz6uu3MXVzVXBwCLcBGAs/s1600/lasso%2B1.jpg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;λ is the regularization parameter and the intercept term is not regularized. &lt;/div&gt;
We do not assume that the error terms are normally distributed.&lt;br/&gt;&lt;div&gt;For the estimates we don't have any specific mathematical formula but we can obtain the estimates using some statistical software.&lt;/div&gt;
&lt;br/&gt;&lt;strong&gt;&lt;em&gt;Note that lasso regression also needs standardization.&lt;/em&gt;&lt;/strong&gt;&lt;h3&gt;Advantage of lasso over ridge regression&lt;/h3&gt;
&lt;div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;Lasso regression can perform in-built variable selection as well as parameter shrinkage. While using ridge regression one may end up getting all the variables but with &lt;strong&gt;Shrinked Paramaters.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;h3&gt;&lt;span&gt;R code for Lasso Regression&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;div&gt;Considering the &lt;strong&gt;swiss dataset&lt;/strong&gt; from &quot;&lt;strong&gt;datasets&lt;/strong&gt;&quot; package, we have: &lt;/div&gt;
&lt;div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;#Creating dependent and independent variables.&lt;br/&gt;X = swiss[,-1]&lt;br/&gt;y = swiss[,1]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div&gt;Using &lt;strong&gt;cv.glmnet&lt;/strong&gt; in &lt;strong&gt;glmnet&lt;/strong&gt; package we do cross validation. For lasso regression we set alpha = 1. By default standardize = TRUE hence we do not need to standardize the variables seperately.&lt;/div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;#Setting the seed for reproducibility&lt;br/&gt;set.seed(123)&lt;br/&gt;model = cv.glmnet(as.matrix(X),y,alpha = 1,lambda = 10^seq(4,-1,-0.1))&lt;br/&gt;#By default standardize = TRUE&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;div&gt;We consider the best value of lambda by filtering out &lt;strong&gt;lamba.min&lt;/strong&gt; from the model and hence get the coefficients using &lt;strong&gt;predict&lt;/strong&gt; function.&lt;/div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;#Taking the best lambda&lt;br/&gt;best_lambda = model$lambda.min&lt;br/&gt;lasso_coeff = predict(model,s = best_lambda,type = &quot;coefficients&quot;)&lt;br/&gt;lasso_coeff The lasso coefficients we got are:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
6 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
                           1
(Intercept)      65.46374579
Agriculture      -0.14994107
Examination      -0.24310141
Education        -0.83632674
Catholic          0.09913931
Infant.Mortality  1.07238898
&lt;/pre&gt;
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;Which one is better - Ridge regression or Lasso regression?&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;div&gt;Both ridge regression and lasso regression are addressed to deal with multicollinearity. &lt;/div&gt;
Ridge regression is computationally more efficient over lasso regression. Any of them can perform better. So the best approach is to &lt;strong&gt;select that regression model which fits the test set data well.&lt;/strong&gt;&lt;br/&gt;
&lt;strong&gt;&lt;span&gt;7. Elastic Net Regression&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;div&gt;Elastic Net regression is preferred over both ridge and lasso regression when one is dealing with highly correlated independent variables.&lt;/div&gt;
&lt;br/&gt;It is a &lt;code&gt;combination of both L1 and L2 regularization&lt;/code&gt;.&lt;br/&gt;
The objective function in case of Elastic Net Regression is:&lt;br/&gt;&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-1C5RJPcZ1vk/Wlr2qDJsijI/AAAAAAAACNU/3bSXMjEcM5ALaeTsliyhvysR-ASuCFX4QCLcBGAs/s1600/elasticnet1.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;50&quot; data-original-width=&quot;606&quot; src=&quot;https://1.bp.blogspot.com/-1C5RJPcZ1vk/Wlr2qDJsijI/AAAAAAAACNU/3bSXMjEcM5ALaeTsliyhvysR-ASuCFX4QCLcBGAs/s1600/elasticnet1.jpg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div class=&quot;separator&quot;&gt;Like ridge and lasso regression, it does not assume normality.&lt;/div&gt;
&lt;br/&gt;&lt;h3&gt;R code for Elastic Net Regression&lt;/h3&gt;
&lt;div&gt;
&lt;div&gt;Setting some different value of alpha between 0 and 1 we can carry out elastic net regression.&lt;/div&gt;
&lt;/div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;set.seed(123)&lt;br/&gt;model = cv.glmnet(as.matrix(X),y,alpha = 0.5,lambda = 10^seq(4,-1,-0.1))&lt;br/&gt;#Taking the best lambda&lt;br/&gt;best_lambda = model$lambda.min&lt;br/&gt;en_coeff = predict(model,s = best_lambda,type = &quot;coefficients&quot;)&lt;br/&gt;en_coeff&lt;/p&gt;
&lt;/blockquote&gt;
The coeffients we obtained are:&lt;pre&gt;
6 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
                          1
(Intercept)      65.9826227
Agriculture      -0.1570948
Examination      -0.2581747
Education        -0.8400929
Catholic          0.0998702
Infant.Mortality  1.0775714
&lt;/pre&gt;
&lt;strong&gt;&lt;span&gt;8. Principal Components Regression (PCR)&lt;/span&gt; &lt;/strong&gt;&lt;br/&gt;PCR is a regression technique which is widely used when you have many independent variables OR multicollinearity exist in your data. It is divided into 2 steps:&lt;br/&gt;&lt;div&gt;
&lt;ol&gt;&lt;li&gt;Getting the Principal components&lt;/li&gt;
&lt;li&gt;Run regression analysis on principal components&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
The most common features of PCR are:&lt;br/&gt;&lt;div&gt;
&lt;ol&gt;&lt;li&gt;Dimensionality Reduction&lt;/li&gt;
&lt;li&gt;Removal of multicollinearity&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;h3&gt;&lt;span&gt;Getting the Principal components&lt;/span&gt;&lt;/h3&gt;
Principal components analysis is a statistical method to extract new features when the original features are highly correlated. We create new features with the help of original features such that the new features are uncorrelated.&lt;div&gt;&lt;span&gt;Let us consider the first principle component:&lt;/span&gt;&lt;br/&gt;&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-vFggXtE8i3k/WltkDFPjqFI/AAAAAAAACOw/ve6r9aZqK_QJ8ZXLcKkORF3__QMLnJuSgCLcBGAs/s1600/pca1.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;66&quot; data-original-width=&quot;176&quot; src=&quot;https://3.bp.blogspot.com/-vFggXtE8i3k/WltkDFPjqFI/AAAAAAAACOw/ve6r9aZqK_QJ8ZXLcKkORF3__QMLnJuSgCLcBGAs/s1600/pca1.jpg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;
The first PC is having the maximum variance.&lt;br/&gt;Similarly we can find the second PC U2 such that it is &lt;strong&gt;uncorrelated&lt;/strong&gt; with U1 and has the second largest variance.&lt;br/&gt;In a similar manner for 'p' features we can have a maximum of 'p' PCs such that all the PCs are uncorrelated with each other and the first PC has the maximum variance, then 2nd PC has the maximum variance and so on.&lt;h3&gt;&lt;span&gt;&lt;strong&gt;Drawbacks:&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;div&gt;It is to be mentioned that PCR is not a feature selection technique instead it is a feature extraction technique. Each principle component we obtain is a function of all the features. Hence on using principal components one would be unable to explain which factor is affecting the dependent variable to what extent.&lt;/div&gt;

&lt;h3&gt;&lt;span&gt;Principal Components Regression in R&lt;/span&gt;&lt;/h3&gt;
&lt;div&gt;We use the longley data set available in R which is used for high multicollinearity. We excplude the Year column.&lt;/div&gt;
&lt;div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;data1 = longley[,colnames(longley) != &quot;Year&quot;]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;br/&gt;View(data)  This is how some of the observations in our dataset will look like:&lt;br/&gt;&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-B6eJCR7lOOQ/WltvJ8-LTaI/AAAAAAAACPA/8myMa8mnSPcJLolt2U5u_zNTnYvdph8fgCLcBGAs/s1600/pca2.jpg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;368&quot; data-original-width=&quot;479&quot; src=&quot;https://4.bp.blogspot.com/-B6eJCR7lOOQ/WltvJ8-LTaI/AAAAAAAACPA/8myMa8mnSPcJLolt2U5u_zNTnYvdph8fgCLcBGAs/s1600/pca2.jpg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
We use &lt;strong&gt;pls package&lt;/strong&gt; in order to run PCR.&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;install.packages(&quot;pls&quot;)&lt;br/&gt;library(pls)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;div&gt;
&lt;div&gt;In PCR we are trying to estimate the number of Employed people; scale  = T denotes that we are standardizing the variables; validation = &quot;CV&quot; denotes applicability of cross-validation.&lt;/div&gt;
&lt;/div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;pcr_model &amp;lt;- pcr(Employed~., data = data1, scale = TRUE, validation = &quot;CV&quot;)&lt;br/&gt;summary(pcr_model)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;div&gt;We get the summary as:&lt;/div&gt;
&lt;pre&gt;
Data:  X dimension: 16 5 
 Y dimension: 16 1
Fit method: svdpc
Number of components considered: 5

VALIDATION: RMSEP
Cross-validated using 10 random segments.
       (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps
CV           3.627    1.194    1.118   0.5555   0.6514   0.5954
adjCV        3.627    1.186    1.111   0.5489   0.6381   0.5819

TRAINING: % variance explained
          1 comps  2 comps  3 comps  4 comps  5 comps
X           72.19    95.70    99.68    99.98   100.00
Employed    90.42    91.89    98.32    98.33    98.74
&lt;/pre&gt;
&lt;br/&gt;Here in the RMSEP the root mean square errors are being denoted. While in 'Training: %variance explained' the cumulative % of variance explained by principle components is being depicted. We can see that with 3 PCs more than 99% of variation can be attributed.&lt;br/&gt;We can also create a plot depicting the mean squares error for the number of various PCs.&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;validationplot(pcr_model,val.type = &quot;MSEP&quot;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-_v_Uv2PL1UQ/WltwxC64CqI/AAAAAAAACPM/qFUihMP8RPM590m466Dm-DHiyRSPEW7RgCLcBGAs/s1600/pca3.jpeg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;356&quot; data-original-width=&quot;500&quot; src=&quot;https://3.bp.blogspot.com/-_v_Uv2PL1UQ/WltwxC64CqI/AAAAAAAACPM/qFUihMP8RPM590m466Dm-DHiyRSPEW7RgCLcBGAs/s1600/pca3.jpeg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
By writing &lt;strong&gt;val.type = &quot;R2&quot;&lt;/strong&gt; we can plot the R square for various no. of PCs.&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;validationplot(pcr_model,val.type = &quot;R2&quot;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://4.bp.blogspot.com/-sHy2Oag4RSM/WltxEPdbeSI/AAAAAAAACPQ/hFAfZSVAFsEK_C8ZTNRaxTUIv0lrmsbsQCLcBGAs/s1600/pca4.jpeg&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;356&quot; data-original-width=&quot;500&quot; src=&quot;https://4.bp.blogspot.com/-sHy2Oag4RSM/WltxEPdbeSI/AAAAAAAACPQ/hFAfZSVAFsEK_C8ZTNRaxTUIv0lrmsbsQCLcBGAs/s1600/pca4.jpeg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
 If we want to fit pcr for 3 principal components and hence get the predicted values we can write:&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;pred = predict(pcr_model,data1,ncomp = 3)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;strong&gt;&lt;span&gt;9. Partial Least Squares (PLS) Regression &lt;/span&gt;&lt;/strong&gt;&lt;p&gt;It is an alternative technique of principal component regression when you have independent variables highly correlated. It is also useful when there are a large number of independent variables.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Difference between PLS and PCR&lt;/span&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;Both techniques create new independent variables called components which are linear combinations of the original predictor variables but PCR creates components to explain the observed variability in the predictor variables, without considering the response variable at all. While PLS takes the dependent variable into account, and therefore often leads to models that are able to fit the dependent variable with fewer components.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;span&gt;&lt;strong&gt;PLS Regression in R&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;library(plsdepot)&lt;br/&gt;data(vehicles)&lt;br/&gt;pls.model = plsreg1(vehicles[, c(1:12,14:16)], vehicles[, 13], comps = 3)&lt;br/&gt;# R-Square&lt;br/&gt;pls.model$R2&lt;/p&gt;
&lt;/blockquote&gt;

&lt;br/&gt;&lt;strong&gt;&lt;span&gt;10. Support Vector Regression&lt;/span&gt;&lt;/strong&gt;&lt;p&gt;Support vector regression can solve both linear and non-linear models. SVM uses non-linear kernel functions (such as polynomial) to find the optimal solution for non-linear models.&lt;/p&gt;&lt;p&gt;The main idea of SVR is to minimize error, individualizing the hyperplane which maximizes the margin.&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;
&lt;p&gt;library(e1071)&lt;br/&gt;svr.model &amp;lt;- svm(Y ~ X , data)&lt;br/&gt;pred &amp;lt;- predict(svr.model, data)&lt;br/&gt;points(data$X, pred, col = &quot;red&quot;, pch=4)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;strong&gt;&lt;span&gt;11. Ordinal Regression&lt;/span&gt;&lt;/strong&gt;&lt;p&gt;Ordinal Regression is used to &lt;strong&gt;predict ranked values&lt;/strong&gt;. In simple words, this type of regression is suitable when dependent variable is ordinal in nature. &lt;strong&gt;Example of ordinal variables -&lt;/strong&gt; Survey responses (1 to 6 scale), patient reaction to drug dose (none, mild, severe).&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;Why we can't use linear regression when dealing with ordinal target variable?&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In linear regression, the dependent variable assumes that changes in the level of the dependent variable are equivalent throughout the range of the variable. For example, the difference in weight between a person who is 100 kg and a person who is 120 kg is 20kg, which has the same meaning as the difference in weight between a person who is 150 kg and a person who is 170 kg. These relationships do not necessarily hold for ordinal variables.&lt;br/&gt;&lt;/p&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;library(ordinal)&lt;br/&gt;o.model &amp;lt;- clm(rating ~ ., data = wine)&lt;br/&gt;summary(o.model)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;div&gt;&lt;strong&gt;&lt;span&gt;12. Poisson Regression&lt;/span&gt;&lt;/strong&gt;&lt;/div&gt;

&lt;div&gt;
&lt;div&gt;Poisson regression is used &lt;strong&gt;when dependent variable has count data&lt;/strong&gt;.&lt;/div&gt;
&lt;/div&gt;

&lt;div&gt;&lt;strong&gt;&lt;span&gt;Application of Poisson Regression -&lt;/span&gt;&lt;/strong&gt;&lt;/div&gt;
&lt;div&gt;
&lt;div&gt;
&lt;ol&gt;&lt;li&gt;Predicting the number of calls in customer care related to a particular product&lt;/li&gt;
&lt;li&gt;Estimating the number of emergency service calls during an event&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;div&gt;The dependent variable must meet the following conditions&lt;/div&gt;
&lt;div&gt;
&lt;ol&gt;&lt;li&gt;The dependent variable has a Poisson distribution.&lt;/li&gt;
&lt;li&gt;Counts cannot be negative.&lt;/li&gt;
&lt;li&gt;This method is not suitable on non-whole numbers&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div&gt;In the code below, we are using dataset named warpbreaks which shows the number of breaks in Yarn during weaving. In this case, the model includes terms for wool type, wool tension and the interaction between the two.&lt;/div&gt;
&lt;div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;pos.model&amp;lt;-glm(breaks~wool*tension, data = warpbreaks, family=poisson)&lt;br/&gt;summary(pos.model)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;

&lt;div&gt;&lt;span&gt;13. Negative Binomial Regression&lt;/span&gt;&lt;/div&gt;

&lt;div&gt;Like Poisson Regression, it also deals with count data. The question arises &quot;how it is different from poisson regression&quot;. The answer is negative binomial regression does not assume distribution of count having variance equal to its mean. While poisson regression assumes the variance equal to its mean.&lt;br/&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;When the variance of count data is greater than the mean count, it is a case of &lt;strong&gt;overdispersion&lt;/strong&gt;. The opposite of the previous statement is a case of under-dispersion.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;library(MASS)&lt;br/&gt;nb.model &amp;lt;- glm.nb(Days ~ Sex/(Age + Eth*Lrn), data = quine)&lt;br/&gt;summary(nb.model)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;

&lt;div&gt;
&lt;div&gt;&lt;span&gt;14. Quasi Poisson Regression&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div&gt;It is an alternative to negative binomial regression. &lt;strong&gt;It can also be used for overdispersed count data. &lt;/strong&gt;Both the algorithms give similar results, there are differences in estimating the effects of covariates. The variance of a quasi-Poisson model is a linear function of the mean while the variance of a negative binomial model is a quadratic function of the mean.&lt;/div&gt;
&lt;div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;qs.pos.model &amp;lt;- glm(Days ~ Sex/(Age + Eth*Lrn), data = quine,  family = &quot;quasipoisson&quot;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div&gt;Quasi-Poisson regression can handle both over-dispersion and under-dispersion.&lt;/div&gt;


&lt;div&gt;
&lt;div&gt;
&lt;div&gt;&lt;span&gt;15. Cox Regression&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div&gt;
&lt;div&gt;Cox Regression is suitable for time-to-event data. See the examples below -&lt;/div&gt;
&lt;div&gt;
&lt;ol&gt;&lt;li&gt;Time from customer opened the account until attrition.&lt;/li&gt;
&lt;li&gt;Time after cancer treatment until death.&lt;/li&gt;
&lt;li&gt;Time from first heart attack to the second.&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
&lt;div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;Logistic regression uses a binary dependent variable but ignores the timing of events. &lt;/p&gt;
&lt;/blockquote&gt;
As well as estimating the time it takes to reach a certain event, survival analysis can also be used to compare time-to-event for multiple groups.&lt;/div&gt;
&lt;div&gt;&lt;br/&gt;&lt;div&gt;Dual targets are set for the survival model &lt;/div&gt;
&lt;div&gt;1. A continuous variable representing the time to event.&lt;/div&gt;
&lt;div&gt;2. A binary variable representing the status whether event occurred or not.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;blockquote class=&quot;tr_bq&quot;&gt;
&lt;p&gt;library(survival)&lt;br/&gt;# Lung Cancer Data&lt;br/&gt;# status: 2=death&lt;br/&gt;lung$SurvObj &amp;lt;- with(lung, Surv(time, status == 2))&lt;br/&gt;cox.reg &amp;lt;- coxph(SurvObj ~ age + sex + ph.karno + wt.loss, data =  lung)&lt;br/&gt;cox.reg&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br/&gt;&lt;div&gt;&lt;span&gt;How to choose the correct regression model?&lt;/span&gt;&lt;br/&gt;&lt;ol&gt;&lt;li&gt;If dependent variable is continuous and model is suffering from collinearity or there are a lot of independent variables, you can try PCR, PLS, ridge, lasso and elastic net regressions. You can select the final model based on Adjusted r-square, RMSE, AIC and BIC.&lt;/li&gt;
&lt;li&gt;If you are working on count data, you should try poisson, quasi-poisson and negative binomial regression.&lt;/li&gt;
&lt;li&gt;To avoid overfitting, we can use cross-validation method to evaluate models used for prediction. We can also use ridge, lasso and elastic net regressions techniques to correct overfitting issue.&lt;/li&gt;
&lt;li&gt;Try support vector regression when you have non-linear model.&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;br/&gt;&lt;h4&gt;&lt;strong&gt;R Tutorials :&lt;/strong&gt; &lt;strong&gt;&lt;a href=&quot;https://www.listendata.com/p/r-programming-tutorials.html&quot;&gt;75 Free R Tutorials&lt;/a&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;div class=&quot;share-post&quot;&gt;&lt;span&gt;Love this Post? Spread the Word&lt;/span&gt;

&lt;/div&gt;

&lt;div id=&quot;related-post&quot;&gt;&lt;span&gt;Related Posts:&lt;/span&gt; &lt;/div&gt;
</description>
<pubDate>Fri, 13 Apr 2018 17:10:51 +0000</pubDate>
<dc:creator>JulienRbrt</dc:creator>
<og:title>15 Types of Regression you should know</og:title>
<og:url>https://www.listendata.com/2018/03/regression-analysis.html</og:url>
<og:type>article</og:type>
<og:image>https://2.bp.blogspot.com/-4EMj8azhdRI/WrfvScVzCVI/AAAAAAAAHJY/7l3J-uX2wFA49_Nkif7Wjm5SP713amRrgCLcBGAs/s72-c/regression.PNG</og:image>
<og:description>This tutorial covers 15 common regression analysis techniques for predictive modeling and data science. It includes detailed explanation of regression along with R code</og:description>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.listendata.com/2018/03/regression-analysis.html</dc:identifier>
</item>
<item>
<title>Brutalist Design Is the Bad Influence We All Need</title>
<link>https://www.imaginarycloud.com/blog/why-we-need-web-brutalism/</link>
<guid isPermaLink="true" >https://www.imaginarycloud.com/blog/why-we-need-web-brutalism/</guid>
<description>&lt;p&gt;The UX/UI world has gradually come to be dominated by guidelines and aesthetics belonging to companies like Apple or Google.&lt;/p&gt;
&lt;p&gt;It’s absolutely normal and predictable that this would happen, considering &lt;strong&gt;most apps are designed to seamlessly fit&lt;/strong&gt; into the user experience of technologies belonging to these big titans.&lt;/p&gt;
&lt;p&gt;The success of any product depends on its coordination with the existing services and that requires some level of standardisation, be it on hardware or software level. &lt;strong&gt;Design is directly impacted by the state of the market.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Everyone (designers and developers alike) has access to Apple’s, Google’s or Microsoft's frameworks and guidelines. This way, even if one doesn't have much knowledge or experience in design, one should at least be within the safe zone when following those very specific structural and aesthetic advices.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It probably won’t come out great, but it shouldn’t be a train wreck either.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;everythingisacopyofacopyofacopy&quot;&gt;Everything is a copy, of a copy, of a copy&lt;/h2&gt;
&lt;p&gt;Naturally, a lot of graphical and aesthetic principles ended up dictated by languages such as Google’s Material Design or Apple’s Human Interface Guidelines.&lt;/p&gt;
&lt;p&gt;When you’re following a framework or some sort of guidelines with the purpose of providing the best User Experience possible, it’s very easy to follow their visual language too because it is also part of the structural and navigational tool set.&lt;/p&gt;
&lt;p&gt;A link is a link, text is text, and how you choose to distinguish them is not just a UX problem, it’s a matter of &lt;strong&gt;visual communication&lt;/strong&gt; and, consequently, &lt;strong&gt;visual aesthetics&lt;/strong&gt; too. &lt;strong&gt;With that, comes the product’s visual identity.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.imaginarycloud.com/blog/content/images/2018/04/guidelinesArtboard-6.jpg&quot; alt=&quot;guidelinesArtboard-6&quot;/&gt;&lt;br/&gt;&lt;em&gt;IMG1: Some of &lt;a href=&quot;https://material.io/guidelines/material-design/introduction.html&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;Google's Material Design&lt;/a&gt; guidelines and views.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Consequence: &lt;strong&gt;one way or another, everything is slowly starting to get homogenised.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On a User Experience level this brings a lot of advantages, such as the settlement of universal languages that pretty much every user will get and, if the designer follows the rules, the product will be in the safe zone and its users won’t be lost.&lt;/p&gt;
&lt;p&gt;On the other hand, it doesn’t mean that the current universal languages are the best they could ever be - and by best I mean easiest, healthiest and safest.&lt;/p&gt;
&lt;p&gt;Maybe there would be better patterns to follow but, as any language that is very well established, introducing new patterns is extremely messy. &lt;strong&gt;Turns out old habits do indeed die hard.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.imaginarycloud.com/blog/content/images/2018/04/Artboard-1.jpg&quot; alt=&quot;Artboard-1&quot;/&gt;&lt;br/&gt;&lt;em&gt;IMG2: Behold, every single template in 2017 - Squarespace templates.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;On a visual level, the scenario is way less positive.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The mainstream current of graphic work is becoming repetitively bland and a copy of everyone else's.&lt;/strong&gt; Most designs are using the same typefaces, the same sets of colors, the same visual effects.&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;strong&gt;User Experience is everyone's ultimate pretext for the lack of originality and differentiating identity.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Of course there’s still space for a visual identity within, for example, material design's patterns. But can a brand or a product &lt;em&gt;truly&lt;/em&gt; stand out anymore if they decide to settle with the same fonts, boxes, shadows and colors?&lt;/p&gt;
&lt;p&gt;Some big, commercially successful companies don’t think so. Web-Brutalism has taught them something very valuable.&lt;/p&gt;
&lt;h2 id=&quot;sowhatiswebbrutalism&quot;&gt;So what is Web-brutalism?&lt;/h2&gt;
&lt;blockquote readability=&quot;10.021186440678&quot;&gt;
&lt;p&gt;&quot;In its ruggedness and lack of concern to look comfortable or easy, Brutalism can be seen as a reaction by a younger generation to the lightness, optimism, and frivolity of today's web design.” - Pascall Deville, &lt;a href=&quot;http://brutalistwebsites.com&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;brutalistwebsites.com&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As a movement, web-brutalism has no founder or original birth place. It started all over the world, by professionals who had no relation to each other.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The name references Brutalist architecture&lt;/strong&gt;, which was a 50's to 70's movement that chose to stay away from all decoration - from architectonic ornaments to simple wall-paint.&lt;/p&gt;
&lt;p&gt;Contrary to what might seem obvious, &lt;em&gt;Brutalism&lt;/em&gt; doesn't stem from &lt;em&gt;brutal&lt;/em&gt;. &lt;strong&gt;Brutalism is born out of &quot;raw-concrete&quot;&lt;/strong&gt; - physically and etymologically - &lt;em&gt;béton-brut&lt;/em&gt; in French.&lt;/p&gt;
&lt;p&gt;The Brutalist arquitecture movement was usually &lt;strong&gt;expressed through massive, solid structures&lt;/strong&gt;, with exposed concrete and sometimes exposed architectural plan.&lt;/p&gt;
&lt;p&gt;The idea was that &lt;strong&gt;the buildings were honest, unpretentious and anti-bourgeois&lt;/strong&gt;, which was not only born out of low-budget projects within economically depressed communities, but also adopted as the philosophy and mindset of large budget private and government comissioned works.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.imaginarycloud.com/blog/content/images/2018/04/Artboard-5.jpg&quot; alt=&quot;Artboard-5&quot;/&gt;&lt;br/&gt;&lt;em&gt;IMG3: Trellick Tower, London, 1966–1972, designed by Ernő Goldfinger; Le Corbusier's Unité d'habitation in Marseille, France (1952); Habitat 67 in Montreal, Quebec, Canada.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Web-brutalism is no different from brutalism in the sense that it not only embodies a counter-reaction - in this case, to standardized visual design - but also manifests itself through &lt;strong&gt;a sense of roughness, exposed structures and visible thought processes.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Some would even consider some of its works &quot;ugly&quot; because of how unpolished they might look - just like the architectural movement. &lt;strong&gt;Some would say this web-movement is basically &quot;extreme&quot; flat design.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let's also keep in mind that UX wise, the raw, &quot;original&quot; Web-Brutalism will straight up ignore all the User Centered design principles there are as a statement and also, for those of us with a geeky sense of humour, as a gag.&lt;/p&gt;
&lt;blockquote readability=&quot;7.3122171945701&quot;&gt;
&lt;p&gt;The first (and only) step is to throw elements on the screen, without worrying too much about how they work together. Who are you to define hierarchy anyway? Let each element fight for the spotlight. - &lt;a href=&quot;https://www.uxbrutalism.com&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;www.uxbrutalism.com&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;But since a picture is worth a thousand words, here are some examples of what this design tendency looks like:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.imaginarycloud.com/blog/content/images/2018/04/Artboard-2.jpg&quot; alt=&quot;Artboard-2&quot;/&gt;&lt;br/&gt;&lt;em&gt;IMG4: &lt;a href=&quot;http://christopherbabb.com&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;http://christopherbabb.com&lt;/a&gt;; &lt;a href=&quot;http://www.zku-berlin.org&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;http://www.zku-berlin.org&lt;/a&gt;; &lt;a href=&quot;http://patchworkarchitecture.co.nz&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;http://patchworkarchitecture.co.nz&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.imaginarycloud.com/blog/content/images/2018/04/Artboard-2-copy.jpg&quot; alt=&quot;Artboard-2-copy&quot;/&gt;&lt;br/&gt;&lt;em&gt;IMG5: &lt;a href=&quot;http://6thfinger.studio&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;http://6thfinger.studio&lt;/a&gt;; &lt;a href=&quot;http://spin.co.uk&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;http://spin.co.uk&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;coolkidsgotangryatthesystemwhatsnew&quot;&gt;Cool kids got angry at the system, what's new?&lt;/h2&gt;
&lt;p&gt;Like it or not - personal opinions and memes aside - &lt;strong&gt;web-brutalism is moving from something edgy and almost punk, to something very mainstream and commercially viable.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Just ask &lt;a href=&quot;https://www.balenciaga.com/pt&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;Balenciaga&lt;/a&gt;, &lt;a href=&quot;https://dropbox.design&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;Dropbox&lt;/a&gt;, news-outlet &lt;a href=&quot;https://www.bloomberg.com/europe&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;Bloomberg&lt;/a&gt; or digital media company &lt;a href=&quot;https://theoutline.com&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;The Outline&lt;/a&gt; - which, by the way, is also re-inventing &lt;a href=&quot;http://www.adweek.com/digital/the-outline-is-making-visual-interactive-content-and-ads-for-a-post-text-internet/&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;visual, interactive content and Ads for a &quot;Post-Text&quot; Internet&lt;/a&gt;, effectively reaching new, underfed audiences.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.imaginarycloud.com/blog/content/images/2018/04/Artboard-4.jpg&quot; alt=&quot;Artboard-4&quot;/&gt;&lt;br/&gt;&lt;em&gt;IMG6: &lt;a href=&quot;https://theoutline.com&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;https://theoutline.com&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;What these brands are taking from web-brutalism - and truly, we should all be learning something here - is that &lt;strong&gt;User-centered design doesn't need to be monopolized by the same colors, same buttons, same photography&lt;/strong&gt; and even same copy you see in pretty much every single website or product.&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;UX is not an excuse for lack of visual identity.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The same way well-designed and interesting packaging will make you choose one product over the other, a powerful and solid visual identity will set you aside too.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.imaginarycloud.com/blog/content/images/2018/04/Artboard-3.jpg&quot; alt=&quot;Artboard-3&quot;/&gt;&lt;br/&gt;&lt;em&gt;IMG7: &lt;a href=&quot;https://www.bloomberg.com&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;https://www.bloomberg.com&lt;/a&gt;; &lt;a href=&quot;https://dropbox.design&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;https://dropbox.design&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This doesn't mean we should all go make &lt;a href=&quot;http://gailepranckunaite.com&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;extremely&lt;/a&gt; &lt;a href=&quot;http://delirium-magazin.ch&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;disfunctional&lt;/a&gt; &lt;a href=&quot;http://g-p-b.net&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;designs&lt;/a&gt; for the sake of difference and experimentation, but &lt;strong&gt;it means that there is another way besides the one we've been abusing lately.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Minimalism as a usability and visual principle is not synonym to Material Design, and User Centered Design doesn't mean you cannot think outside the box visually.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UX is not a style or visual language&lt;/strong&gt; - it's a discipline that interprets qualitative and quantitative data in order to optimize design decisions, but it doesn't tell you which shapes, colors or fonts to use.&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;strong&gt;Let go of your safe zones because the current tendency tells us they won't be safe for very much longer.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It won't take much longer until rigid grids, full screen faux analog photos, gradients and neat google fonts become outdated and unable to compete with all the other outstanding, new and interesting designs.&lt;/p&gt;
&lt;p&gt;Bottom-line is: &lt;strong&gt;Brutalism has brought back a touch of irreverence and confidence that is lacking in most mainstream designs.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A system of bold colors unafraid to be mixed with pastels and unusual fonts is meant to stand out and, if used wisely, it will do so for all the right reasons.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;em&gt;At &lt;strong&gt;&lt;a href=&quot;https://www.imaginarycloud.com?utm_source=blog&amp;amp;utm_medium=blogpost&amp;amp;utm_campaign=blogposthp&quot; target=&quot;_blank&quot;&gt;Imaginary Cloud&lt;/a&gt;&lt;/strong&gt;, we simplify complex systems, delivering interfaces that users love with our own &lt;strong&gt;&lt;a href=&quot;https://www.imaginarycloud.com/ourprocess?utm_source=blog&amp;amp;utm_medium=blogpost&amp;amp;utm_campaign=blogpostop&quot; target=&quot;_blank&quot;&gt;Product Design Process&lt;/a&gt;&lt;/strong&gt;. If you’ve enjoyed this article, you will certainly enjoy our newsletter too, which may be subscribed below. If there is any project that you think we can help with, feel free to &lt;strong&gt;&lt;a href=&quot;https://www.imaginarycloud.com/contacts?utm_source=blog&amp;amp;utm_medium=blogpost&amp;amp;utm_campaign=blogpostcon&quot; target=&quot;_blank&quot;&gt;reach us&lt;/a&gt;&lt;/strong&gt;. We look forward to hearing from you!&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 13 Apr 2018 17:00:14 +0000</pubDate>
<dc:creator>vanni</dc:creator>
<og:type>article</og:type>
<og:title>Brutalist design is the bad influence we all need</og:title>
<og:description>Like it or not - personal opinions and memes aside - web-brutalism is moving from something edgy and almost punk, to something very mainstream and commercially viable.</og:description>
<og:url>http://www.imaginarycloud.com/blog/why-we-need-web-brutalism/</og:url>
<og:image>http://www.imaginarycloud.com/blog/content/images/2018/04/brutalism.png</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.imaginarycloud.com/blog/why-we-need-web-brutalism/</dc:identifier>
</item>
<item>
<title>NEON is the new black: fast JPEG optimization on ARM servers</title>
<link>https://blog.cloudflare.com/neon-is-the-new-black/</link>
<guid isPermaLink="true" >https://blog.cloudflare.com/neon-is-the-new-black/</guid>
<description>&lt;p&gt;As engineers at Cloudflare quickly adapt our software stack to run on ARM, a few parts of our software stack have not been performing as well on ARM processors as they currently do on our Xeon® Silver 4116 CPUs. For the most part this is a matter of Intel specific optimizations some of which utilize SIMD or other special instructions.&lt;/p&gt;
&lt;p&gt;One such example is the venerable jpegtran, one of the workhorses behind our Polish image optimization service.&lt;/p&gt;
&lt;p&gt;A while ago I &lt;a href=&quot;https://blog.cloudflare.com/doubling-the-speed-of-jpegtran/&quot;&gt;optimized&lt;/a&gt; our version of jpegtran for Intel processors. So when I ran a comparison on my &lt;a href=&quot;https://blog.cloudflare.com/content/images/2015/10/print_poster_0025.jpg&quot;&gt;test image&lt;/a&gt;, I was expecting that the Xeon would outperform ARM:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;vlad@xeon:~$ time  ./jpegtran -outfile /dev/null -progressive -optimise -copy none test.jpg

real    0m2.305s
user    0m2.059s
sys     0m0.252s
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;vlad@arm:~$ time ./jpegtran -outfile /dev/null -progressive -optimise -copy none test.jpg

real    0m8.654s
user    0m8.433s
sys     0m0.225s
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Ideally we want to have the ARM performing at or above 50% of the Xeon performance per core. This would make sure we have no performance regressions, and net performance gain, since the ARM CPUs have double the core count as our current 2 socket setup.&lt;/p&gt;
&lt;p&gt;In this case, however, I was disappointed to discover an almost 4X slowdown.&lt;/p&gt;
&lt;p&gt;Not one to despair, I figured out that applying the same optimizations I did for Intel would be trivial. Surely the NEON instructions map neatly to the SSE instructions I used before?&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://farm4.staticflickr.com/3063/2535574361_30730d9a7b_o_d.jpg&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;&lt;small&gt;&lt;a href=&quot;https://creativecommons.org/licenses/by-sa/2.0/&quot;&gt;CC BY-SA 2.0&lt;/a&gt; &lt;a href=&quot;https://www.flickr.com/photos/vizzzual-dot-com/2535574361/in/photolist-4S4tVk-8yutL-ge8Q-5fXXRQ-wJcRY-yrvgf-9vXGvq-hGx4N-4NZ4L-5cjA7-iJrnwJ-7VXhaz-866BCb-auGuG-68BjeT-92L4-9rXsu-3Pfaz-5GZs6n-oAKSY-LhdKa-7BLZ96-VRGZ2H-ofm5ZJ-8xC1bv-5DePNQ-ZouKg-afu4r-49ThBC-7VyeQT-qfr6P3-4zpUM8-hgPbs-naTubk-S7khvM-6hTftH-ByLAg-9sNftz-8G4os2-zsq8-oBEf6L-5y1nxR-7aTZfD-9fYMH-wJcnp-8yhgk-wJcDS-qsPXVn-kbW5A6-bPx3gX&quot;&gt;image&lt;/a&gt; by &lt;a href=&quot;https://www.flickr.com/photos/vizzzual-dot-com/&quot;&gt;viZZZual.com&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;
&lt;h3 id=&quot;whatisneon&quot;&gt;What is NEON&lt;/h3&gt;
&lt;p&gt;NEON is the ARMv8 version of SIMD, Single Instruction Multiple Data instruction set, where a single operation performs (generally) the same operation on several operands.&lt;/p&gt;
&lt;p&gt;NEON operates on 32 dedicated 128-bit registers, similarly to Intel SSE. It can perform operations on 32-bit and 64-bit floating point numbers, or 8-bit, 16-bit, 32-bit and 64-bit signed or unsigned integers.&lt;/p&gt;
&lt;p&gt;As with SSE you can program either in the assembly language, or in C using intrinsics. The intrinsics are usually easier to use, and depending on the application and the compiler can provide better performance, however intrinsics based code tends to be quite verbose.&lt;/p&gt;
&lt;p&gt;If you opt to use the NEON intrinsics you have to include &lt;code&gt;&amp;lt;arm_neon.h&amp;gt;&lt;/code&gt;. While SSE intrinsic use __m128i for all SIMD integer operations, the intrinsics for NEON have distinct type for each integer and float width. For example operations on signed 16-bit integers use the int16x8_t type, which we are going to use. Similarly there is a uint16x8_t type for unsigned integer, as well as int8x16_t, int32x4_t and int64x2_t and their uint derivatives, that are self explanatory.&lt;/p&gt;
&lt;h3 id=&quot;gettingstarted&quot;&gt;Getting started&lt;/h3&gt;
&lt;p&gt;Running perf tells me that the same two culprits are responsible for most of the CPU time spent:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;perf record ./jpegtran -outfile /dev/null -progressive -optimise -copy none test.jpeg
perf report
  71.24%  lt-jpegtran  libjpeg.so.9.1.0   [.] encode_mcu_AC_refine
  15.24%  lt-jpegtran  libjpeg.so.9.1.0   [.] encode_mcu_AC_first
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Aha, &lt;code&gt;encode_mcu_AC_refine&lt;/code&gt; and &lt;code&gt;encode_mcu_AC_first&lt;/code&gt;, my old nemeses!&lt;/p&gt;
&lt;h3 id=&quot;thestraightforwardapproach&quot;&gt;The straightforward approach&lt;/h3&gt;
&lt;br/&gt;&lt;h4 id=&quot;encode_mcu_ac_refine&quot;&gt;encode_mcu_AC_refine&lt;/h4&gt;
&lt;p&gt;Let's recoup the optimizations we applied to &lt;code&gt;encode_mcu_AC_refine&lt;/code&gt; previously. The function has two loops, with the heavier loop performing the following operation:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;for (k = cinfo-&amp;gt;Ss; k &amp;lt;= Se; k++) {
  temp = (*block)[natural_order[k]];
  if (temp &amp;lt; 0)
    temp = -temp;      /* temp is abs value of input */
  temp &amp;gt;&amp;gt;= Al;         /* apply the point transform */
  absvalues[k] = temp; /* save abs value for main pass */
  if (temp == 1)
    EOB = k;           /* EOB = index of last newly-nonzero coef */
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;And the SSE solution to this problem was:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;__m128i x1 = _mm_setzero_si128(); // Load 8 16-bit values sequentially
x1 = _mm_insert_epi16(x1, (*block)[natural_order[k+0]], 0);
x1 = _mm_insert_epi16(x1, (*block)[natural_order[k+1]], 1);
x1 = _mm_insert_epi16(x1, (*block)[natural_order[k+2]], 2);
x1 = _mm_insert_epi16(x1, (*block)[natural_order[k+3]], 3);
x1 = _mm_insert_epi16(x1, (*block)[natural_order[k+4]], 4);
x1 = _mm_insert_epi16(x1, (*block)[natural_order[k+5]], 5);
x1 = _mm_insert_epi16(x1, (*block)[natural_order[k+6]], 6);
x1 = _mm_insert_epi16(x1, (*block)[natural_order[k+7]], 7);

x1 = _mm_abs_epi16(x1);       // Get absolute value of 16-bit integers
x1 = _mm_srli_epi16(x1, Al);  // &amp;gt;&amp;gt; 16-bit integers by Al bits

_mm_storeu_si128((__m128i*)&amp;amp;absvalues[k], x1);   // Store

x1 = _mm_cmpeq_epi16(x1, _mm_set1_epi16(1));     // Compare to 1
unsigned int idx = _mm_movemask_epi8(x1);        // Extract byte mask
EOB = idx? k + 16 - __builtin_clz(idx)/2 : EOB;  // Compute index
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;For the most part the transition to NEON is indeed straightforward.&lt;/p&gt;
&lt;p&gt;To initialize a register to all zeros, we can use the &lt;code&gt;vdupq_n_s16&lt;/code&gt; intrinsic, that duplicates a given value across all lanes of a register. The insertions are performed with the &lt;code&gt;vsetq_lane_s16&lt;/code&gt; intrinsic. Use &lt;code&gt;vabsq_s16&lt;/code&gt; to get the absolute values.&lt;/p&gt;
&lt;p&gt;The shift right instruction made me pause for a while. I simply couldn't find an instruction that can shift right by a non constant integer value. It doesn't exist. However the solution is very simple, you shift left by a negative amount! The intrinsic for that is &lt;code&gt;vshlq_s16&lt;/code&gt;.&lt;/p&gt;
&lt;blockquote readability=&quot;14&quot;&gt;
&lt;p&gt;The absence of a right shift instruction is no coincidence. Unlike the x86 instruction set, that can theoretically support arbitrarily long instructions, and thus don't have to think twice before adding a new instruction, no matter how specialized or redundant it is, ARMv8 instruction set can only support 32-bit long instructions, and have a very limited opcode space. For this reason the instruction set is much more concise, and many instructions are in fact aliases to other instruction. Even the most basic MOV instruction is an alias for ORR (binary or). That means that programming for ARM and NEON sometimes requires greater creativity.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The final step of the loop, is comparing each element to 1, then getting the mask. Comparing for equality is performed with &lt;code&gt;vceqq_s16&lt;/code&gt;. But again there is no operation to extract the mask. That is a problem. However, instead of getting a bitmask, it is possible to extract a whole byte from every lane into a 64-bit value, by first applying &lt;code&gt;vuzp1q_u8&lt;/code&gt; to the comparison result. &lt;code&gt;vuzp1q_u8&lt;/code&gt; interleaves the even indexed bytes of two vectors (whereas &lt;code&gt;vuzp2q_u8&lt;/code&gt; interleaves the odd indexes). So the solution would look something like that:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;int16x8_t zero = vdupq_n_s16(0);
int16x8_t al_neon = vdupq_n_s16(-Al);
int16x8_t x0 = zero;
int16x8_t x1 = zero;

// Load 8 16-bit values sequentially
x1 = vsetq_lane_s16((*block)[natural_order[k+0]], x1, 0);
// Interleave the loads to compensate for latency
x0 = vsetq_lane_s16((*block)[natural_order[k+1]], x0, 1);
x1 = vsetq_lane_s16((*block)[natural_order[k+2]], x1, 2);
x0 = vsetq_lane_s16((*block)[natural_order[k+3]], x0, 3);
x1 = vsetq_lane_s16((*block)[natural_order[k+4]], x1, 4);
x0 = vsetq_lane_s16((*block)[natural_order[k+5]], x0, 5);
x1 = vsetq_lane_s16((*block)[natural_order[k+6]], x1, 6);
x0 = vsetq_lane_s16((*block)[natural_order[k+7]], x0, 7);
int16x8_t x = vorrq_s16(x1, x0);

x = vabsq_s16(x);            // Get absolute value of 16-bit integers
x = vshlq_s16(x, al_neon);   // &amp;gt;&amp;gt; 16-bit integers by Al bits

vst1q_s16(&amp;amp;absvalues[k], x); // Store
uint8x16_t is_one = vreinterpretq_u8_u16(vceqq_s16(x, one));  // Compare to 1
is_one = vuzp1q_u8(is_one, is_one);  // Compact the compare result into 64 bits

uint64_t idx = vgetq_lane_u64(vreinterpretq_u64_u8(is_one), 0); // Extract
EOB = idx ? k + 8 - __builtin_clzl(idx)/8 : EOB;                // Get the index
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Note the intrinsics for explicit type casts. They don't actually emit any instructions, since regardless of the type the operands always occupy the same registers.&lt;/p&gt;
&lt;p&gt;On to the second loop:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;if ((temp = absvalues[k]) == 0) {
  r++;
  continue;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;The SSE solution was:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;__m128i t = _mm_loadu_si128((__m128i*)&amp;amp;absvalues[k]);
t = _mm_cmpeq_epi16(t, _mm_setzero_si128()); // Compare to 0
int idx = _mm_movemask_epi8(t);              // Extract byte mask
if (idx == 0xffff) {                         // Skip all zeros
  r += 8;
  k += 8;
  continue;
} else {                                     // Skip up to the first nonzero
  int skip = __builtin_ctz(~idx)/2;
  r += skip;
  k += skip;
  if (k&amp;gt;Se) break;      // Stop if gone too far
}
temp = absvalues[k];    // Load the next nonzero value
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;But we already know that there is no way to extract the byte mask. Instead of using NEON I chose to simply skip four zero values at a time, using 64-bit integers, like so:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;uint64_t tt, *t = (uint64_t*)&amp;amp;absvalues[k];
if ( (tt = *t) == 0) while ( (tt = *++t) == 0); // Skip while all zeroes
int skip = __builtin_ctzl(tt)/16 + ((int64_t)t - 
           (int64_t)&amp;amp;absvalues[k])/2;           // Get index of next nonzero
k += skip;
r += skip;
temp = absvalues[k];
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;How fast are we now?&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;vlad@arm:~$ time ./jpegtran -outfile /dev/null -progressive -optimise -copy none test.jpg

real    0m4.008s
user    0m3.770s
sys     0m0.241s
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Wow, that is incredible. Over 2X speedup!&lt;/p&gt;
&lt;h4 id=&quot;encode_mcu_ac_first&quot;&gt;encode_mcu_AC_first&lt;/h4&gt;
&lt;p&gt;The other function is quite similar, but the logic slightly differs on the first pass:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;temp = (*block)[natural_order[k]];
if (temp &amp;lt; 0) {
  temp = -temp;             // Temp is abs value of input
  temp &amp;gt;&amp;gt;= Al;              // Apply the point transform
  temp2 = ~temp;
} else {
  temp &amp;gt;&amp;gt;= Al;              // Apply the point transform
  temp2 = temp;
}
t1[k] = temp;
t2[k] = temp2;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Here it is required to assign the absolute value of temp to &lt;code&gt;t1[k]&lt;/code&gt;, and its inverse to &lt;code&gt;t2[k]&lt;/code&gt; if temp is negative, otherwise &lt;code&gt;t2[k]&lt;/code&gt; assigned the same value as &lt;code&gt;t1[k]&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To get the inverse of a value, we use the &lt;code&gt;vmvnq_s16&lt;/code&gt; intrinsic, to check if the values are negative we need to compare with zero using the &lt;code&gt;vcgezq_s16&lt;/code&gt; and finally selecting based on the mask using &lt;code&gt;vbslq_s16&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-c&quot;&gt;int16x8_t zero = vdupq_n_s16(0);
int16x8_t al_neon = vdupq_n_s16(-Al);

int16x8_t x0 = zero;
int16x8_t x1 = zero;

// Load 8 16-bit values sequentially
x1 = vsetq_lane_s16((*block)[natural_order[k+0]], x1, 0);
// Interleave the loads to compensate for latency
x0 = vsetq_lane_s16((*block)[natural_order[k+1]], x0, 1);
x1 = vsetq_lane_s16((*block)[natural_order[k+2]], x1, 2);
x0 = vsetq_lane_s16((*block)[natural_order[k+3]], x0, 3);
x1 = vsetq_lane_s16((*block)[natural_order[k+4]], x1, 4);
x0 = vsetq_lane_s16((*block)[natural_order[k+5]], x0, 5);
x1 = vsetq_lane_s16((*block)[natural_order[k+6]], x1, 6);
x0 = vsetq_lane_s16((*block)[natural_order[k+7]], x0, 7);
int16x8_t x = vorrq_s16(x1, x0);

uint16x8_t is_positive = vcgezq_s16(x); // Get positive mask

x = vabsq_s16(x);                 // Get absolute value of 16-bit integers
x = vshlq_s16(x, al_neon);        // &amp;gt;&amp;gt; 16-bit integers by Al bits
int16x8_t n = vmvnq_s16(x);       // Binary inverse
n = vbslq_s16(is_positive, x, n); // Select based on positive mask

vst1q_s16(&amp;amp;t1[k], x); // Store
vst1q_s16(&amp;amp;t2[k], n);
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;And the moment of truth:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;vlad@arm:~$ time ./jpegtran -outfile /dev/null -progressive -optimise -copy none test.jpg

real    0m3.480s
user    0m3.243s
sys     0m0.241s
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Overall 2.5X speedup from the original C implementation, but still 1.5X slower than Xeon.&lt;/p&gt;
&lt;h3 id=&quot;batchbenchmark&quot;&gt;Batch benchmark&lt;/h3&gt;
&lt;p&gt;While the improvement for the single image was impressive, it is not necessarily representative of all jpeg files. To understand the impact on overall performance I ran jpegtran over a set of 34,159 actual images from one of our caches. The total size of those images was 3,325,253KB. The total size after jpegtran was 3,067,753KB, or 8% improvement on average.&lt;/p&gt;
&lt;p&gt;Using one thread, the Intel Xeon managed to process all those images in 14 minutes and 43 seconds. The original jpegtran on our ARM server took 29 minutes and 34 seconds. The improved jpegtran took only 13 minutes and 52 seconds, slightly outperforming even the Xeon processor, despite losing on the test image.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog.cloudflare.com/content/images/2018/04/jpegtran.png&quot; alt=&quot;jpegtran&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;goingdeeper&quot;&gt;Going deeper&lt;/h3&gt;
&lt;p&gt;3.48 seconds, down from 8.654 represents a respectful 2.5X speedup.&lt;/p&gt;
&lt;p&gt;It definitely meets the goal of being at least 50% as fast as Xeon, and it is faster in the batch benchmark, but it still feels like it is slower than it could be.&lt;/p&gt;
&lt;p&gt;While going over the ARMv8 NEON instruction set, I found several unique instructions, that have no equivalent in SSE.&lt;/p&gt;
&lt;p&gt;The first such instruction is &lt;code&gt;TBL&lt;/code&gt;. It works as a lookup table, that can lookup 8 or 16 bytes from one to four consecutive registers. In the single register variant it is similar to the &lt;code&gt;pshufb&lt;/code&gt; SSE instruction. In the four register variant, however, it can simultaneously lookup 16 bytes in a 64 byte table! What sorcery is that?&lt;/p&gt;
&lt;p&gt;The intrinsic to use the 4 register variant is &lt;code&gt;vqtbl4q_u8&lt;/code&gt;. Interestingly there is an instruction that can lookup 64 bytes in AVX-512, but we don't want to &lt;a href=&quot;https://blog.cloudflare.com/on-the-dangers-of-intels-frequency-scaling/&quot;&gt;use that&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The next interesting thing I found, are instructions that can load or store and de/interleave data at the same time. They can load or store up to four registers simultaneously, while de/interleaving two, three or even four elements, of any supported width. The specifics are well presented in &lt;a href=&quot;https://community.arm.com/processors/b/blog/posts/coding-for-neon---part-1-load-and-stores&quot;&gt;here&lt;/a&gt;. The load intrinsics used are of the form: &lt;code&gt;vldNq_uW&lt;/code&gt;, where N can be 1,2,3,4 to indicate the interleave factor and W can be 8, 16, 32 or 64. Similarly &lt;code&gt;vldNq_sW&lt;/code&gt; is used for signed types.&lt;/p&gt;
&lt;p&gt;Finally very interesting instructions are the shift left/right and insert &lt;code&gt;SLI&lt;/code&gt; and &lt;code&gt;SRI&lt;/code&gt;. What they do is they shift the elements left or right, like a regular shift would, however instead of shifting in zero bits, the zeros are replaced with the original bits of the destination register! An intrinsic for that would look like &lt;code&gt;vsliq_n_u16&lt;/code&gt; or &lt;code&gt;vsriq_n_u32&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&quot;applyingthenewinstructions&quot;&gt;Applying the new instructions&lt;/h4&gt;
&lt;p&gt;It might not be visible at first how those new instruction can help. Since I didn't have much time to dig into libjpeg or the jpeg spec, I had to resolve to heuristics.&lt;/p&gt;
&lt;p&gt;From a quick look it became apparent that &lt;code&gt;*block&lt;/code&gt; is defined as an array of 64 16-bit values. &lt;code&gt;natural_order&lt;/code&gt; is an array of 32-bit integers that varies in length depending on the real block size, but is always padded with 16 entries. Also, despite the fact that it uses integers, the values are indexes in the range [0..63].&lt;/p&gt;
&lt;p&gt;Another interesting observation is that blocks of size 64 are the most common by far for both &lt;code&gt;encode_mcu_AC_refine&lt;/code&gt; and &lt;code&gt;encode_mcu_AC_first&lt;/code&gt;. And it always makes sense to optimize for the most common case.&lt;/p&gt;
&lt;p&gt;So essentially what we have here, is a 64 entry lookup table &lt;code&gt;*block&lt;/code&gt; that uses &lt;code&gt;natural_order&lt;/code&gt; as indices. Hmm, 64 entry lookup table, where did I see that before? Of course, the &lt;code&gt;TBL&lt;/code&gt; instruction. Although &lt;code&gt;TBL&lt;/code&gt; looks up bytes, and we need to lookup shorts, it is easy to do, since NEON lets us load and deinterleave the short into bytes in a single instruction using &lt;code&gt;LD2&lt;/code&gt;, then we can use two lookups for each byte individually, and finally interleave again with &lt;code&gt;ZIP1&lt;/code&gt; and &lt;code&gt;ZIP2&lt;/code&gt;. Similarly despite the fact that the indices are integers, and we only need the least significant byte of each, we can use &lt;code&gt;LD4&lt;/code&gt; to deinterleave them into bytes (the kosher way of course would be to rewrite the library to use bytes, but I wanted to avoid big changes).&lt;/p&gt;
&lt;p&gt;After the data loading step is done, the point transforms for both functions remain the same, but in the end, to get a single bitmask for all 64 values we can use &lt;code&gt;SLI&lt;/code&gt; and &lt;code&gt;SRI&lt;/code&gt; to intelligently align the bits such that only one bit of each comparison mask remains, using &lt;code&gt;TBL&lt;/code&gt; again to combine them.&lt;/p&gt;
&lt;p&gt;For whatever reason, the compiler in that case produces somewhat suboptimal code, so I had to revert to assembly language for this specific optimization.&lt;/p&gt;
&lt;p&gt;The code for &lt;code&gt;encode_mcu_AC_refine&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-asm&quot;&gt;    # Load and deintreleave the block
    ld2 {v0.16b - v1.16b}, [x0], 32
    ld2 {v16.16b - v17.16b}, [x0], 32
    ld2 {v18.16b - v19.16b}, [x0], 32
    ld2 {v20.16b - v21.16b}, [x0]

    mov v4.16b, v1.16b
    mov v5.16b, v17.16b
    mov v6.16b, v19.16b
    mov v7.16b, v21.16b
    mov v1.16b, v16.16b
    mov v2.16b, v18.16b
    mov v3.16b, v20.16b
    # Load the order 
    ld4 {v16.16b - v19.16b}, [x1], 64
    ld4 {v17.16b - v20.16b}, [x1], 64
    ld4 {v18.16b - v21.16b}, [x1], 64
    ld4 {v19.16b - v22.16b}, [x1]
    # Table lookup, LSB and MSB independently
    tbl v20.16b, {v0.16b - v3.16b}, v16.16b
    tbl v16.16b, {v4.16b - v7.16b}, v16.16b
    tbl v21.16b, {v0.16b - v3.16b}, v17.16b
    tbl v17.16b, {v4.16b - v7.16b}, v17.16b
    tbl v22.16b, {v0.16b - v3.16b}, v18.16b
    tbl v18.16b, {v4.16b - v7.16b}, v18.16b
    tbl v23.16b, {v0.16b - v3.16b}, v19.16b
    tbl v19.16b, {v4.16b - v7.16b}, v19.16b
    # Interleave MSB and LSB back
    zip1 v0.16b, v20.16b, v16.16b
    zip2 v1.16b, v20.16b, v16.16b
    zip1 v2.16b, v21.16b, v17.16b
    zip2 v3.16b, v21.16b, v17.16b
    zip1 v4.16b, v22.16b, v18.16b
    zip2 v5.16b, v22.16b, v18.16b
    zip1 v6.16b, v23.16b, v19.16b
    zip2 v7.16b, v23.16b, v19.16b
    # -Al
    neg w3, w3
    dup v16.8h, w3
    # Absolute then shift by Al
    abs v0.8h, v0.8h
    sshl v0.8h, v0.8h, v16.8h
    abs v1.8h, v1.8h
    sshl v1.8h, v1.8h, v16.8h
    abs v2.8h, v2.8h
    sshl v2.8h, v2.8h, v16.8h
    abs v3.8h, v3.8h
    sshl v3.8h, v3.8h, v16.8h
    abs v4.8h, v4.8h
    sshl v4.8h, v4.8h, v16.8h
    abs v5.8h, v5.8h
    sshl v5.8h, v5.8h, v16.8h
    abs v6.8h, v6.8h
    sshl v6.8h, v6.8h, v16.8h
    abs v7.8h, v7.8h
    sshl v7.8h, v7.8h, v16.8h
    # Store
    st1 {v0.16b - v3.16b}, [x2], 64
    st1 {v4.16b - v7.16b}, [x2]
    # Constant 1
    movi v16.8h, 0x1
    # Compare with 0 for zero mask
    cmeq v17.8h, v0.8h, #0
    cmeq v18.8h, v1.8h, #0
    cmeq v19.8h, v2.8h, #0
    cmeq v20.8h, v3.8h, #0
    cmeq v21.8h, v4.8h, #0
    cmeq v22.8h, v5.8h, #0
    cmeq v23.8h, v6.8h, #0
    cmeq v24.8h, v7.8h, #0
    # Compare with 1 for EOB mask
    cmeq v0.8h, v0.8h, v16.8h
    cmeq v1.8h, v1.8h, v16.8h
    cmeq v2.8h, v2.8h, v16.8h
    cmeq v3.8h, v3.8h, v16.8h
    cmeq v4.8h, v4.8h, v16.8h
    cmeq v5.8h, v5.8h, v16.8h
    cmeq v6.8h, v6.8h, v16.8h
    cmeq v7.8h, v7.8h, v16.8h
    # For both masks -&amp;gt; keep only one byte for each comparison
    uzp1 v0.16b, v0.16b, v1.16b
    uzp1 v1.16b, v2.16b, v3.16b
    uzp1 v2.16b, v4.16b, v5.16b
    uzp1 v3.16b, v6.16b, v7.16b

    uzp1 v17.16b, v17.16b, v18.16b
    uzp1 v18.16b, v19.16b, v20.16b
    uzp1 v19.16b, v21.16b, v22.16b
    uzp1 v20.16b, v23.16b, v24.16b
    # Shift left and insert (int16) to get a single bit from even to odd bytes
    sli v0.8h, v0.8h, 15
    sli v1.8h, v1.8h, 15
    sli v2.8h, v2.8h, 15
    sli v3.8h, v3.8h, 15

    sli v17.8h, v17.8h, 15
    sli v18.8h, v18.8h, 15
    sli v19.8h, v19.8h, 15
    sli v20.8h, v20.8h, 15
    # Shift right and insert (int32) to get two bits from off to even indices
    sri v0.4s, v0.4s, 18
    sri v1.4s, v1.4s, 18
    sri v2.4s, v2.4s, 18
    sri v3.4s, v3.4s, 18

    sri v17.4s, v17.4s, 18
    sri v18.4s, v18.4s, 18
    sri v19.4s, v19.4s, 18
    sri v20.4s, v20.4s, 18
    # Regular shift right to align the 4 bits at the bottom of each int64
    ushr v0.2d, v0.2d, 12
    ushr v1.2d, v1.2d, 12
    ushr v2.2d, v2.2d, 12
    ushr v3.2d, v3.2d, 12

    ushr v17.2d, v17.2d, 12
    ushr v18.2d, v18.2d, 12
    ushr v19.2d, v19.2d, 12
    ushr v20.2d, v20.2d, 12
    # Shift left and insert (int64) to combine all 8 bits into one byte
    sli v0.2d, v0.2d, 36
    sli v1.2d, v1.2d, 36
    sli v2.2d, v2.2d, 36
    sli v3.2d, v3.2d, 36

    sli v17.2d, v17.2d, 36
    sli v18.2d, v18.2d, 36
    sli v19.2d, v19.2d, 36
    sli v20.2d, v20.2d, 36
    # Combine all the byte mask insto a bit 64-bit mask for EOB and zero masks
    ldr d4, .shuf_mask
    tbl v5.8b, {v0.16b - v3.16b}, v4.8b
    tbl v6.8b, {v17.16b - v20.16b}, v4.8b
    # Extract lanes
    mov x0, v5.d[0]
    mov x1, v6.d[0]
    # Compute EOB
    rbit x0, x0
    clz x0, x0
    mov x2, 64
    sub x0, x2, x0
    # Not of zero mask (so 1 bits indecates non-zeroes)
    mvn x1, x1
    ret
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;If you look carefully at the code, you will see, that I decided that while generating the mask to find EOB is useful, I can use the same method to generate the mask for zero values, and then I can find the next nonzero value, and zero runlength this way:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;uint64_t skip =__builtin_clzl(zero_mask &amp;lt;&amp;lt; k);
r += skip;
k += skip;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Similarly for &lt;code&gt;encode_mcu_AC_first&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-asm&quot;&gt;    # Load the block
    ld2 {v0.16b - v1.16b}, [x0], 32
    ld2 {v16.16b - v17.16b}, [x0], 32
    ld2 {v18.16b - v19.16b}, [x0], 32
    ld2 {v20.16b - v21.16b}, [x0]

    mov v4.16b, v1.16b
    mov v5.16b, v17.16b
    mov v6.16b, v19.16b
    mov v7.16b, v21.16b
    mov v1.16b, v16.16b
    mov v2.16b, v18.16b
    mov v3.16b, v20.16b

    # Load the order 
    ld4 {v16.16b - v19.16b}, [x1], 64
    ld4 {v17.16b - v20.16b}, [x1], 64
    ld4 {v18.16b - v21.16b}, [x1], 64
    ld4 {v19.16b - v22.16b}, [x1]
    # Table lookup, LSB and MSB independently
    tbl v20.16b, {v0.16b - v3.16b}, v16.16b
    tbl v16.16b, {v4.16b - v7.16b}, v16.16b
    tbl v21.16b, {v0.16b - v3.16b}, v17.16b
    tbl v17.16b, {v4.16b - v7.16b}, v17.16b
    tbl v22.16b, {v0.16b - v3.16b}, v18.16b
    tbl v18.16b, {v4.16b - v7.16b}, v18.16b
    tbl v23.16b, {v0.16b - v3.16b}, v19.16b
    tbl v19.16b, {v4.16b - v7.16b}, v19.16b
    # Interleave MSB and LSB back
    zip1 v0.16b, v20.16b, v16.16b
    zip2 v1.16b, v20.16b, v16.16b
    zip1 v2.16b, v21.16b, v17.16b
    zip2 v3.16b, v21.16b, v17.16b
    zip1 v4.16b, v22.16b, v18.16b
    zip2 v5.16b, v22.16b, v18.16b
    zip1 v6.16b, v23.16b, v19.16b
    zip2 v7.16b, v23.16b, v19.16b
    # -Al
    neg w4, w4
    dup v24.8h, w4
    # Compare with 0 to get negative mask
    cmge v16.8h, v0.8h, #0
    # Absolute value and shift by Al
    abs v0.8h, v0.8h
    sshl v0.8h, v0.8h, v24.8h
    cmge v17.8h, v1.8h, #0
    abs v1.8h, v1.8h
    sshl v1.8h, v1.8h, v24.8h
    cmge v18.8h, v2.8h, #0
    abs v2.8h, v2.8h
    sshl v2.8h, v2.8h, v24.8h
    cmge v19.8h, v3.8h, #0
    abs v3.8h, v3.8h
    sshl v3.8h, v3.8h, v24.8h
    cmge v20.8h, v4.8h, #0
    abs v4.8h, v4.8h
    sshl v4.8h, v4.8h, v24.8h
    cmge v21.8h, v5.8h, #0
    abs v5.8h, v5.8h
    sshl v5.8h, v5.8h, v24.8h
    cmge v22.8h, v6.8h, #0
    abs v6.8h, v6.8h
    sshl v6.8h, v6.8h, v24.8h
    cmge v23.8h, v7.8h, #0
    abs v7.8h, v7.8h
    sshl v7.8h, v7.8h, v24.8h
    # ~
    mvn v24.16b, v0.16b
    mvn v25.16b, v1.16b
    mvn v26.16b, v2.16b
    mvn v27.16b, v3.16b
    mvn v28.16b, v4.16b
    mvn v29.16b, v5.16b
    mvn v30.16b, v6.16b
    mvn v31.16b, v7.16b
    # Select
    bsl v16.16b, v0.16b, v24.16b
    bsl v17.16b, v1.16b, v25.16b
    bsl v18.16b, v2.16b, v26.16b
    bsl v19.16b, v3.16b, v27.16b
    bsl v20.16b, v4.16b, v28.16b
    bsl v21.16b, v5.16b, v29.16b
    bsl v22.16b, v6.16b, v30.16b
    bsl v23.16b, v7.16b, v31.16b
    # Store t1
    st1 {v0.16b - v3.16b}, [x2], 64
    st1 {v4.16b - v7.16b}, [x2]
    # Store t2
    st1 {v16.16b - v19.16b}, [x3], 64
    st1 {v20.16b - v23.16b}, [x3]
    # Compute zero mask like before
    cmeq v17.8h, v0.8h, #0
    cmeq v18.8h, v1.8h, #0
    cmeq v19.8h, v2.8h, #0
    cmeq v20.8h, v3.8h, #0
    cmeq v21.8h, v4.8h, #0
    cmeq v22.8h, v5.8h, #0
    cmeq v23.8h, v6.8h, #0
    cmeq v24.8h, v7.8h, #0

    uzp1 v17.16b, v17.16b, v18.16b
    uzp1 v18.16b, v19.16b, v20.16b
    uzp1 v19.16b, v21.16b, v22.16b
    uzp1 v20.16b, v23.16b, v24.16b

    sli v17.8h, v17.8h, 15
    sli v18.8h, v18.8h, 15
    sli v19.8h, v19.8h, 15
    sli v20.8h, v20.8h, 15

    sri v17.4s, v17.4s, 18
    sri v18.4s, v18.4s, 18
    sri v19.4s, v19.4s, 18
    sri v20.4s, v20.4s, 18

    ushr v17.2d, v17.2d, 12
    ushr v18.2d, v18.2d, 12
    ushr v19.2d, v19.2d, 12
    ushr v20.2d, v20.2d, 12

    sli v17.2d, v17.2d, 36
    sli v18.2d, v18.2d, 36
    sli v19.2d, v19.2d, 36
    sli v20.2d, v20.2d, 36

    ldr d4, .shuf_mask
    tbl v6.8b, {v17.16b - v20.16b}, v4.8b

    mov x0, v6.d[0]
    mvn x0, x0
    ret
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;finalresultsandpower&quot;&gt;Final results and power&lt;/h2&gt;
&lt;p&gt;The final version of our jpegtran managed to reduce the test image in 2.756 seconds. Or an extra 1.26X speedup, that gets it incredibly close to the performance of the Xeon on that image. As a bonus batch performance also improved!&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog.cloudflare.com/content/images/2018/04/jpegtran-asm-1.png&quot; alt=&quot;jpegtran-asm-1&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Another favorite part of mine, working with the Qualcomm Centriq CPU is the ability to take power readings, and be pleasantly surprised every time.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog.cloudflare.com/content/images/2018/04/jpegtran-power-1.png&quot; alt=&quot;jpegtran-power-1&quot;/&gt;&lt;/p&gt;
&lt;p&gt;With the new implementation Centriq outperforms the Xeon at batch reduction for every number of workers. We usually run Polish with four workers, for which Centriq is now 1.3 times faster while also 6.5 times more power efficient.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;It is evident that the Qualcomm Centriq is a powerful processor, that definitely provides a good bang for a buck. However, years of Intel leadership in the server and desktop space mean that a lot of software is better optimized for Intel processors.&lt;/p&gt;
&lt;p&gt;For the most part writing optimizations for ARMv8 is not difficult, and we will be adjusting our software as needed, and publishing our efforts as we go.&lt;/p&gt;
&lt;p&gt;You can find the updated code on our &lt;a href=&quot;https://github.com/cloudflare/jpegtran&quot;&gt;Github&lt;/a&gt; page.&lt;/p&gt;
&lt;h3 id=&quot;usefulresources&quot;&gt;Useful resources&lt;/h3&gt;
</description>
<pubDate>Fri, 13 Apr 2018 16:39:47 +0000</pubDate>
<dc:creator>jgrahamc</dc:creator>
<og:type>article</og:type>
<og:title>NEON is the new black: fast JPEG optimization on ARM server</og:title>
<og:description>Cloudflare's jpegtran implementation was optimized for Intel CPUs. Now that we intend to integrate ARMv8 processors, new optimizations for those are required.</og:description>
<og:url>https://blog.cloudflare.com/neon-is-the-new-black/</og:url>
<og:image>https://blog.cloudflare.com/content/images/2018/04/2535574361_30730d9a7b_o.jpg</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.cloudflare.com/neon-is-the-new-black/</dc:identifier>
</item>
</channel>
</rss>