<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Intel ME Manufacturing Mode: obscured dangers and MacBook vulnerability</title>
<link>http://blog.ptsecurity.com/2018/10/intel-me-manufacturing-mode-macbook.html</link>
<guid isPermaLink="true" >http://blog.ptsecurity.com/2018/10/intel-me-manufacturing-mode-macbook.html</guid>
<description>&lt;div dir=&quot;ltr&quot; trbidi=&quot;on&quot;&gt;

&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/--goW46T1rD4/W7NbLrHLJtI/AAAAAAAAHUU/kuU0B6lmZS80LYSwDk7AJ899gS6-NDBwgCLcBGAs/s1600/Untitled.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;662&quot; data-original-width=&quot;799&quot; height=&quot;530&quot; src=&quot;https://1.bp.blogspot.com/--goW46T1rD4/W7NbLrHLJtI/AAAAAAAAHUU/kuU0B6lmZS80LYSwDk7AJ899gS6-NDBwgCLcBGAs/s640/Untitled.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;br/&gt;The weakness of &quot;security through obscurity&quot; is so well known as to be obvious. Yet major hardware manufacturers, citing the need to protect intellectual property, often require a non-disclosure agreement (NDA) before allowing access to technical documentation. The situation has become even more difficult with the growing intricacy of chip designs and integration of proprietary firmware. Such obstacles make it nearly impossible for independent researchers to analyze the security of these platforms. As a result, both ordinary users and hardware manufacturers lose out.&lt;p&gt;One example is Intel Management Engine (Intel ME), including its server (Intel SPS) and mobile (Intel TXE) versions (for background on Intel ME, we recommend consulting  [&lt;a href=&quot;https://github.com/ptresearch/me-disablement/blob/master/How%20to%20become%20the%20sole%20owner%20of%20your%20PC.pdf&quot;&gt;5&lt;/a&gt;] and [&lt;a href=&quot;http://blog.ptsecurity.com/2017/08/disabling-intel-me.html&quot;&gt;6&lt;/a&gt;]). In this article, we will describe how undocumented commands (although &quot;undocumented&quot; applies to practically everything about Intel ME) enable overwriting SPI flash memory and implementing the doomsday scenario: local exploitation of an ME vulnerability (INTEL-SA-00086). At the root of this problem is an undocumented Intel ME mode, specifically, Manufacturing Mode.&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;What is Manufacturing Mode?&lt;/h2&gt;
Intel ME Manufacturing Mode is intended for configuration and testing of the end platform during manufacturing, and as such should be disabled (closed) before sale and shipment to users. However, this mode and its potential risks are not described anywhere in Intel's public documentation. Ordinary users do not have the ability to disable this mode, since the relevant utility (part of Intel ME System Tools) is not officially available. As a result, there is no software that can protect, or even notify, the user if this mode is enabled for whatever reason. Even Chipsec [&lt;a href=&quot;https://github.com/chipsec/chipsec&quot;&gt;2&lt;/a&gt;], a utility specially designed to identify configuration errors in the chipset and CPU at the level of UEFI firmware (such as incorrect configuration of access rights for SPI flash regions), does not know anything about Intel Manufacturing Mode.&lt;p&gt;This mode allows configuring critical platform settings stored in one-time-programmable memory (FUSEs). These settings include those for BootGuard (the mode, policy, and hash for the digital signing key for the ACM and UEFI modules). Some of them are referred to as FPFs (Field Programmable Fuses). For a list of FPFs that can be written to FUSEs (a list that is incomplete, since a number of FPFs cannot be set directly), you can use the FPT (Flash Programming Tool) utility from Intel ME System Tools.&lt;/p&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-j1v2mVX11D0/W7NWldBmLyI/AAAAAAAAHSk/ocwJfsWEalUNukLZcVgAtMHN2Y0tAas_ACLcBGAs/s1600/me_1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;427&quot; data-original-width=&quot;800&quot; height=&quot;340&quot; src=&quot;https://2.bp.blogspot.com/-j1v2mVX11D0/W7NWldBmLyI/AAAAAAAAHSk/ocwJfsWEalUNukLZcVgAtMHN2Y0tAas_ACLcBGAs/s640/me_1.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 1. Output of the -FPFs option in FPT&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
FPFs account for only a part of the FUSE array: instead, most are used by Intel to store platform parameters. Part of this space is called IP FUSEs, used to store the settings of IP (Intelligent Property, hardware logic blocks) units. Thus, the DFx Aggregator special device stores in FUSEs a sign of whether the platform is for testing or mass production.&lt;p&gt;In addition to FPFs, in Manufacturing Mode the hardware manufacturer can specify settings for Intel ME, which are stored in the Intel ME internal file system (MFS) on SPI flash memory. These parameters can be changed by reprogramming the SPI flash. The parameters are known as CVARs (Configurable NVARs, Named Variables).&lt;/p&gt;&lt;p&gt;Setting CVARs is the responsibility of the Intel ME module named mca_server. MCA is short for &quot;Manufacture-Line Configuration Architecture,&quot; which is the general name for the process of configuring the platform during manufacturing. CVARs, just like FPFs, can be set and read via FPT.&lt;/p&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-Es7yvJ_KnIo/W7NW2fulmqI/AAAAAAAAHSs/2iyy1ERozUwSmetcloMbzwD4Uwf30QulQCLcBGAs/s1600/me2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;427&quot; data-original-width=&quot;800&quot; height=&quot;340&quot; src=&quot;https://2.bp.blogspot.com/-Es7yvJ_KnIo/W7NW2fulmqI/AAAAAAAAHSs/2iyy1ERozUwSmetcloMbzwD4Uwf30QulQCLcBGAs/s640/me2.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 2. List of CVARs output by FPT for the Broxton P platform&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
The list of CVARs depends on the platform and version of Intel ME. For chipsets supporting Intel AMT, one of the CVARs is the password for entering MEBx (ME BIOS Extension).&lt;p&gt;Setting FPFs, or almost any CVARs, requires that Intel ME be in Manufacturing Mode. The process of assigning FPFs consists of two steps: setting the values for FPFs (which are saved to temporary memory) and committing the FPF values to the FUSEs. The first step is possible only in Manufacturing Mode, but the actual &quot;burn&quot; occurs automatically after Manufacturing Mode is closed if, while in that mode, the manufacturer set FPF values and the corresponding range in the FUSE array has never been written to before. &lt;strong&gt;So, if a system is in Manufacturing Mode, the FPFs have likely never been initialized&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;A sign of Manufacturing Mode having been closed is stored in the file /home/mca/eom on MFS. When the SPI flash is overwritten by firmware with the basic file system (just after build by FIT [9]), the platform can once again function in Manufacturing Mode, although overwriting FUSEs is no longer possible.&lt;/p&gt;&lt;h2&gt;OEM public key&lt;/h2&gt;
Accordingly, the procedure for configuring Intel platforms is rather complicated and consists of multiple steps. Any error or deviation from this procedure by hardware manufacturers places the platform at serious risk. Even if Manufacturing Mode has been closed, a manufacturer may not have set FPFs, which allows attackers to do so themselves by writing their own values for example instead of the key for signing the start code of the BootGuard (AСM) and UEFI modules. In this case, the platform would load only with the attacker's malicious code—and persistently so. This would lead to irreversible hardware compromise, since the attacker's key is written to permanent memory, from which it can never be removed (for details of this attack, see &quot;Safeguarding rootkits: Intel BootGuard&quot; by Alexander Ermolov [&lt;a href=&quot;https://2016.zeronights.ru/wp-content/uploads/2017/03/Intel-BootGuard.pdf&quot;&gt;8&lt;/a&gt;]).&lt;p&gt;On newer systems (Apollo Lake, Gemini Lake, Cannon Point) FPFs store not just the key for BootGuard, but the OEM's public key (strictly speaking, the SHA256 hash for the RSA OEM public key), which underpins several ME security mechanisms. For example, the special section of SPI flash named Signed Master Image Profile (SMIP) stores manufacturer-specified PCH Straps (PCH hardware configuration). This section is signed using a key whose SHA256 hash is stored in a special file (partition) on SPI flash. This file name is oem.key in the FTPR partition (OEMP.man in OEMP partition for Cannon Point PCH) and contains various OEM-provided public keys for signing all sorts of data. In the following figure, you can see a full list of the sets of data signed by the manufacturer, each with a unique key, for the Cannon Point platform:&lt;/p&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-ns9k6911YjM/W7NXBanvV_I/AAAAAAAAHSw/iNUgwNS4NfgovEZQEjeWS5PlBskq2X5TQCLcBGAs/s1600/me3.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;251&quot; data-original-width=&quot;800&quot; height=&quot;200&quot; src=&quot;https://3.bp.blogspot.com/-ns9k6911YjM/W7NXBanvV_I/AAAAAAAAHSw/iNUgwNS4NfgovEZQEjeWS5PlBskq2X5TQCLcBGAs/s640/me3.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 3. List of OEM-signed data for the CNP platform&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
The oem.key file itself is signed with an OEM root key, whose public key’s hash should be written in the FPFs.&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-5viOEY2M7hQ/W7NXS5CKRAI/AAAAAAAAHS8/0s99ouiE0EkhLartbWoxdey92Sw4ZBslACLcBGAs/s1600/me5.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;471&quot; data-original-width=&quot;800&quot; height=&quot;376&quot; src=&quot;https://3.bp.blogspot.com/-5viOEY2M7hQ/W7NXS5CKRAI/AAAAAAAAHS8/0s99ouiE0EkhLartbWoxdey92Sw4ZBslACLcBGAs/s640/me5.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 4. OEM signing&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
Therefore, having compromised the OEM root key, an attacker can compromise all previously mentioned data, which is much worse than the Boot Guard–only takeover possible on older platforms.&lt;h2&gt;Bypassing block on writing to the ME region&lt;/h2&gt;
Until recently (prior to Intel Apollo Lake), Intel ME was located in a separate SPI region that had independent access rights for the CPU, GBE, and ME. So as long as access attributes were correctly configured, it was impossible to read or write to ME from the CPU (main system) side. However, current SPI controllers for Intel chipsets have a special mechanism called Master Grant. This mechanism assigns a strictly defined portion of SPI flash to each SPI master. A master controls its particular region, regardless of the access rights indicated in the SPI descriptor. Each master can provide access (read or write) for its region (but only its own region!) to any other master it wishes.&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-K8by8Iixh7c/W7NZYHAa7sI/AAAAAAAAHTo/tawOkbMg3bQujrcmX2bSwdScNJ8LZiW3gCEwYBhgL/s1600/Untitled2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;911&quot; data-original-width=&quot;800&quot; height=&quot;640&quot; src=&quot;https://3.bp.blogspot.com/-K8by8Iixh7c/W7NZYHAa7sI/AAAAAAAAHTo/tawOkbMg3bQujrcmX2bSwdScNJ8LZiW3gCEwYBhgL/s640/Untitled2.png&quot; width=&quot;562&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;/&gt;
&lt;td class=&quot;tr-caption&quot;&gt;&lt;span&gt;                             Figure 5. Excerpt from Intel documentation describing SPI Master Grant&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
What this means is that even if the SPI descriptor forbids host access to an SPI region of ME, it is possible for ME to still provide access. In our view, this change was likely intended to enable updating Intel ME in a way that bypasses the standard process.&lt;h2&gt;Host ME Region Flash Protection Override&lt;/h2&gt;
Intel ME implements a special HECI command that allows opening write access to ME SPI region on the CPU side. The command is called HMR FPO (Host ME Region Flash Protection Override). We have detailed this command at length previously [5]. There are some things worth knowing about it.&lt;p&gt;After receiving the HMR FPO command, Intel ME opens access to the region &lt;strong&gt;only after&lt;/strong&gt; a reset. Intel МЕ itself also includes security measures: the command is accepted only when the UEFI BIOS is owner of the platform boot process, prior to End Of Post (EOP). EOP is a different HECI command that sends the UEFI to ME before handing off control to the operating system (ExitBootServices). Sometimes, BIOS Setup contains an option for sending the HMRFPO command prior to EOP.&lt;/p&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-3PL5yWQnua0/W7NZHnxdjqI/AAAAAAAAHTc/RP8kZicDlq4ei1ova_Ng44TIBjMeW52VgCLcBGAs/s1600/me7.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;451&quot; data-original-width=&quot;800&quot; height=&quot;360&quot; src=&quot;https://2.bp.blogspot.com/-3PL5yWQnua0/W7NZHnxdjqI/AAAAAAAAHTc/RP8kZicDlq4ei1ova_Ng44TIBjMeW52VgCLcBGAs/s640/me7.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 6. Opening the ME region in the BIOS&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
After receiving EOP, Intel ME ignores HMR FPO and returns the corresponding error status. &lt;strong&gt;But this occurs only after Manufacturing Mode has been closed&lt;/strong&gt;. Therefore, in Manufacturing Mode, Intel ME accepts HMR FPO &lt;strong&gt;at any time, regardless of the presence (or absence) of End Of Post&lt;/strong&gt;. If the manufacturer has failed to close Manufacturing Mode, an attacker can alter Intel ME at any time (of course, administrator rights are needed, but even the OS kernel initially cannot re-flash Intel ME). At this stage, the attacker can re-flash the ME image, such as to exploit vulnerability INTEL-SA-00086. A reset is then needed to run the modified firmware, but this is no problem on nearly any platform, with the exception of the Apple MacBook. Apple's computers contain an additional check in the UEFI, which runs when the UEFI is launched and blocks startup of the system if the ME region has been opened with HMRFPO. However, as we will show here, this mechanism can be easily bypassed if Intel ME is in Manufacturing Mode.&lt;h2&gt;Resetting ME without resetting the main CPU&lt;/h2&gt;
Today's computers can be restarted in several different ways: the documented versions include a global reset and reset of the main CPU only (without resetting ME). But, if there is a way to reset ME &lt;strong&gt;without&lt;/strong&gt; resetting the main CPU (by running the HMRFPO command in advance as well), access to the region opens up and the main system continues to function.&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-cvWjU06Js1c/W7NZWUwuJ4I/AAAAAAAAHTg/IGorljX6LQkLeIHmO8d0N_SrxLb7u8_MQCLcBGAs/s1600/Untitled3.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;953&quot; data-original-width=&quot;800&quot; height=&quot;640&quot; src=&quot;https://2.bp.blogspot.com/-cvWjU06Js1c/W7NZWUwuJ4I/AAAAAAAAHTg/IGorljX6LQkLeIHmO8d0N_SrxLb7u8_MQCLcBGAs/s640/Untitled3.png&quot; width=&quot;536&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 7. Reset types&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br/&gt;
Having investigated the internal ME modules, we discovered that there is a HECI command (&quot;80 06 00 07 00 00 0b 00 00 00 03 00&quot;, see more about sending commands in [&lt;a href=&quot;https://github.com/ptresearch/me-disablement/blob/master/How%20to%20become%20the%20sole%20owner%20of%20your%20PC.pdf&quot;&gt;5&lt;/a&gt;]) for a reset of only (!!!) Intel ME. In Manufacturing Mode, this command can be sent at any time, even after EOP:&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-xka32IAC5lQ/W7NZ3C0z2hI/AAAAAAAAHT0/M146BP0SFzwwvcytch1AbjbOzFpSEr1eQCLcBGAs/s1600/me8.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;651&quot; data-original-width=&quot;800&quot; height=&quot;520&quot; src=&quot;https://3.bp.blogspot.com/-xka32IAC5lQ/W7NZ3C0z2hI/AAAAAAAAHT0/M146BP0SFzwwvcytch1AbjbOzFpSEr1eQCLcBGAs/s640/me8.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 8. Disassembler listing for the function responsible for handling HECI ME reset commands&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;strong&gt;Therefore, an attacker who sends these two HECI commands opens the ME region and can write arbitrary data there, without having to reset the platform as a whole&lt;/strong&gt;. And it doesn't even matter what the SPI descriptor contains—correctly set protection attributes for SPI regions will not protect ME from modifications if the system is running in Manufacturing Mode.&lt;h2&gt;Exploitation case: vulnerability &lt;a href=&quot;https://support.apple.com/hr-hr/HT208849&quot;&gt;CVE-2018-4251&lt;/a&gt;&lt;/h2&gt;
We analyzed several platforms from a number of manufacturers, including Lenovo and Apple MacBook Prо laptops. The Yoga and ThinkPad computers we examined did NOT have any issues related to Manufacturing Mode. But we found that &lt;strong&gt;Apple laptops on Intel chipsets are running in Manufacturing Mode&lt;/strong&gt;. After this information was reported to Apple, the vulnerability (CVE-2018-4251) was patched in macOS High Sierra update 10.13.5.&lt;h2&gt;Local exploitation of INTEL-SA-00086&lt;/h2&gt;
By exploiting CVE-2018-4251, an attacker could write old versions of Intel ME (such as versions containing vulnerability INTEL-SA-00086) to memory without needing an SPI programmer or access to the HDA_SDO bridge—in other words, without physical access to the computer. Thus, a local vector is possible for exploitation of INTEL-SA-00086, which enables running arbitrary code in ME.&lt;br/&gt;Notably, in the notes for the INTEL-SA-00086 security bulletin, Intel does not mention enabled Manufacturing Mode as a method for local exploitation in the absence of physical access. Instead, the company incorrectly claims that local exploitation is possible only if access settings for SPI regions have been misconfigured. So to keep users safe, we decided to describe how to check the status of Manufacturing Mode and how to disable it.&lt;h2&gt;What can users do?&lt;/h2&gt;
Intel System Tools includes MEInfo (and, for mobile and server platforms respectively, TXEInfo and SPSInfo) in order to allow obtaining thorough diagnostic information about the current state of ME and the platform overall. We demonstrated this utility in previous research about the undocumented HAP (High Assurance Platform) mode and how to disable ME [&lt;a href=&quot;http://blog.ptsecurity.com/2017/08/disabling-intel-me.html&quot;&gt;6&lt;/a&gt;]. The utility, when called with the -FWSTS flag, displays a detailed description of status HECI registers and the current status of Manufacturing Mode (when the fourth bit of the FWSTS status register is set, Manufacturing Mode is active).&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-sOIY2NZm250/W7NaNdyWEuI/AAAAAAAAHT8/RAnnC_0HcC0gEWXnMguRVhwYetJSpe1JQCLcBGAs/s1600/me9.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;418&quot; data-original-width=&quot;800&quot; height=&quot;334&quot; src=&quot;https://3.bp.blogspot.com/-sOIY2NZm250/W7NaNdyWEuI/AAAAAAAAHT8/RAnnC_0HcC0gEWXnMguRVhwYetJSpe1JQCLcBGAs/s640/me9.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 9. Example of MEInfo output&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
We also created a program [&lt;a href=&quot;https://github.com/ptresearch/mmdetect&quot;&gt;7&lt;/a&gt;] for checking the status of Manufacturing Mode if the user for whatever reason does not have access to Intel ME System Tools. Here is what the script shows on affected systems:&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-3JF-WAlHrPQ/W7NaTD0BbaI/AAAAAAAAHUA/8gWtAVS47hYCTeBTSuQGJULIDj0wYXdCwCLcBGAs/s1600/me10.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;387&quot; data-original-width=&quot;800&quot; height=&quot;308&quot; src=&quot;https://3.bp.blogspot.com/-3JF-WAlHrPQ/W7NaTD0BbaI/AAAAAAAAHUA/8gWtAVS47hYCTeBTSuQGJULIDj0wYXdCwCLcBGAs/s640/me10.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 10. mmdetect script&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
So one logical question is, how can users close Manufacturing Mode themselves if the manufacturer has failed to do so? To disable Manufacturing Mode, FPT has a special option (-CLOSEMNF) that in addition to its main purpose also allows setting the recommended access rights for SPI flash regions in the descriptor.&lt;p&gt;Here is what happens when we enter -CLOSEMNF:&lt;/p&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-z068cBRhBd0/W7Nai3fV_FI/AAAAAAAAHUI/ou5TwX7PEBowGv6AJu85Qriqciixb0JrQCLcBGAs/s1600/me11.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;418&quot; data-original-width=&quot;800&quot; height=&quot;334&quot; src=&quot;https://1.bp.blogspot.com/-z068cBRhBd0/W7Nai3fV_FI/AAAAAAAAHUI/ou5TwX7PEBowGv6AJu85Qriqciixb0JrQCLcBGAs/s640/me11.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 11. Process of closing Manufacturing Mode with FPT&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br/&gt;In this example, we used the NO parameter for -CLOSEMNF to avoid resetting the platform, as would otherwise happen by default immediately after closing Manufacturing Mode.&lt;h2&gt;Conclusion&lt;/h2&gt;
Our research shows that Intel ME has a Manufacturing Mode problem, and that even giant manufacturers such as Apple are not immune to configuration mistakes on Intel platforms. Worse still, there is no public information on the topic, leaving end users in the dark about weaknesses that could result in data theft, persistent irremovable rootkits, and even &quot;bricking&quot; of hardware.&lt;br/&gt;We also suspect that the ability to reset ME without resetting the main CPU may lead to yet additional security issues, due to the states of the BIOS/UEFI and ME falling out of sync.&lt;p&gt;[1] &lt;a href=&quot;https://www.intel.com/content/www/us/en/security-center/advisory/intel-sa-00086.html&quot;&gt;Intel Management Engine Critical Firmware Update, Intel-SA-00086&lt;/a&gt;&lt;br/&gt;[2] &lt;a href=&quot;https://github.com/chipsec/chipsec&quot;&gt;GitHub - chipsec/chipsec: Platform Security Assessment Framework&lt;/a&gt;&lt;br/&gt;[4] &lt;a href=&quot;https://www.coreboot.org/&quot;&gt;Fast, secure and flexible OpenSource firmware, Coreboot&lt;/a&gt;&lt;br/&gt;[5] &lt;a href=&quot;https://github.com/ptresearch/me-disablement/blob/master/How%20to%20become%20the%20sole%20owner%20of%20your%20PC.pdf&quot;&gt;Mark Ermolov, Maxim Goryachy, How to Become the Sole Owner of Your PC, PHDays VI, 2016&lt;/a&gt;&lt;br/&gt;[6] &lt;a href=&quot;http://blog.ptsecurity.com/2017/08/disabling-intel-me.html&quot;&gt;Mark Ermolov, Maxim Goryachy, Disabling Intel ME 11 via undocumented mode, Positive Technologies blog&lt;/a&gt;&lt;br/&gt;[7] &lt;a href=&quot;https://github.com/ptresearch/mmdetect&quot;&gt;Intel ME Manufacturing Mode Detection Tools&lt;/a&gt;&lt;br/&gt;[8] &lt;a href=&quot;https://2016.zeronights.ru/wp-content/uploads/2017/03/Intel-BootGuard.pdf%22&quot;&gt;Safeguarding rootkits: Intel BootGuard, Alexander Ermolov&lt;/a&gt;&lt;br/&gt;[9] &lt;a href=&quot;https://www.blackhat.com/docs/eu-17/materials/eu-17-Sklyarov-Intel-ME-Flash-File-System-Explained.pdf&quot;&gt;Dmitry Sklyarov. Intel ME: Flash File System. Explained&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Authors&lt;/strong&gt;: Maxim Goryachy, Mark Ermolov&lt;/p&gt;&lt;/div&gt;

</description>
<pubDate>Tue, 02 Oct 2018 22:44:05 +0000</pubDate>
<dc:creator>tomxor</dc:creator>
<og:url>http://blog.ptsecurity.com/2018/10/intel-me-manufacturing-mode-macbook.html</og:url>
<og:title>Intel ME Manufacturing Mode: obscured dangers and their relationship to Apple MacBook vulnerability CVE-2018-4251</og:title>
<og:description>The weakness of &quot;security through obscurity&quot; is so well known as to be obvious. Yet major hardware manufacturers, citing the need to p...</og:description>
<og:image>https://1.bp.blogspot.com/--goW46T1rD4/W7NbLrHLJtI/AAAAAAAAHUU/kuU0B6lmZS80LYSwDk7AJ899gS6-NDBwgCLcBGAs/w1200-h630-p-k-no-nu/Untitled.png</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>http://blog.ptsecurity.com/2018/10/intel-me-manufacturing-mode-macbook.html</dc:identifier>
</item>
<item>
<title>In Praise of Mediocrity</title>
<link>https://www.nytimes.com/2018/09/29/opinion/sunday/in-praise-of-mediocrity.html</link>
<guid isPermaLink="true" >https://www.nytimes.com/2018/09/29/opinion/sunday/in-praise-of-mediocrity.html</guid>
<description>&lt;div readability=&quot;50&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot; readability=&quot;45&quot;&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;I’m a little surprised by how many people tell me they have no hobbies. It may seem a small thing, but — at the risk of sounding grandiose — I see it as a sign of a civilization in decline. The idea of leisure, after all, is a hard-won achievement; it presupposes that we have overcome the exigencies of brute survival. Yet here in the United States, the wealthiest country in history, we seem to have forgotten the importance of doing things solely because we enjoy them.&lt;/p&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;Yes, I know: We are all so very busy. Between work and family and social obligations, where are we supposed to find the time?&lt;/p&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;But there’s a deeper reason, I’ve come to think, that so many people don’t have hobbies: We’re afraid of being bad at them. Or rather, we are intimidated by the expectation — itself a hallmark of our intensely public, performative age — that we must actually be skilled at what we do in our free time. Our “hobbies,” if that’s even the word for them anymore, have become too serious, too demanding, too much an occasion to become anxious about whether you are really the person you claim to be.&lt;/p&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;If you’re a jogger, it is no longer enough to cruise around the block; you’re training for the next marathon. If you’re a painter, you are no longer passing a pleasant afternoon, just you, your watercolors and your water lilies; you are trying to land a gallery show or at least garner a respectable social media following. When your identity is linked to your hobby — you’re a yogi, a surfer, a rock climber — you’d better be good at it, or else who are you?&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;&lt;div readability=&quot;35.5&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot; readability=&quot;16&quot;&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;Lost here is the gentle pursuit of a modest competence, the doing of something just because you enjoy it, not because you are good at it. Hobbies, let me remind you, are supposed to be something different from work. But alien values like “the pursuit of excellence” have crept into and corrupted what was once the realm of leisure, leaving little room for the true amateur. The population of our country now seems divided between the semipro hobbyists (some as devoted as Olympic athletes) and those who retreat into the passive, screeny leisure that is the signature of our technological moment.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;&lt;div readability=&quot;45&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot; readability=&quot;35&quot;&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;I don’t deny that you can derive a lot of meaning from pursuing an activity at the highest level. I would never begrudge someone a lifetime devotion to a passion or an inborn talent. There are depths of experience that come with mastery. But there is also a real and pure joy, a sweet, childlike delight, that comes from just learning and trying to get better. Looking back, you will find that the best years of, say, scuba-diving or doing carpentry were those you spent on the learning curve, when there was exaltation in the mere act of doing.&lt;/p&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;In a way that we rarely appreciate, the demands of excellence are at war with what we call freedom. For to permit yourself to do only that which you are good at is to be trapped in a cage whose bars are not steel but self-judgment. Especially when it comes to physical pursuits, but also with many other endeavors, most of us will be truly excellent only at whatever we started doing in our teens. What if you decide in your 40s, as I have, that you want to learn to surf? What if you decide in your 60s that you want to learn to speak Italian? The expectation of excellence can be stultifying.&lt;/p&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;Liberty and equality are supposed to make possible the pursuit of happiness. It would be unfortunate if we were to protect the means only to neglect the end. A democracy, when it is working correctly, allows men and women to develop into free people; but it falls to us as individuals to use that opportunity to find purpose, joy and contentment.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;&lt;div readability=&quot;36.399188092016&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot; readability=&quot;18.69147496617&quot;&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;Lest this sound suspiciously like an elaborate plea for people to take more time off from work — well, yes. Though I’d like to put the suggestion more grandly: The promise of our civilization, the point of all our labor and technological progress, is to free us from the struggle for survival and to make room for higher pursuits. But demanding excellence in all that we do can undermine that; it can threaten and even destroy freedom. It steals from us one of life’s greatest rewards — the simple pleasure of doing something you merely, but truly, enjoy.&lt;/p&gt;
&lt;p class=&quot;css-fdlzs e1kwarht0&quot;&gt;Tim Wu (&lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://twitter.com/superwuster&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;@superwuster&lt;/a&gt;) is a law professor at Columbia, the author of “The Attention Merchants: The Epic Struggle to Get Inside Our Heads” and a contributing opinion writer.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;</description>
<pubDate>Tue, 02 Oct 2018 20:29:13 +0000</pubDate>
<dc:creator>anarbadalov</dc:creator>
<og:url>https://www.nytimes.com/2018/09/29/opinion/sunday/in-praise-of-mediocrity.html</og:url>
<og:type>article</og:type>
<og:title>Opinion | In Praise of Mediocrity</og:title>
<og:image>https://static01.nyt.com/images/2018/10/01/opinion/sunday/30wu/30wu-facebookJumbo.jpg</og:image>
<og:description>The pursuit of excellence has infiltrated and corrupted the world of leisure.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.nytimes.com/2018/09/29/opinion/sunday/in-praise-of-mediocrity.html</dc:identifier>
</item>
<item>
<title>Announcing flicker-free boot for Fedora 29</title>
<link>https://hansdegoede.livejournal.com/19224.html</link>
<guid isPermaLink="true" >https://hansdegoede.livejournal.com/19224.html</guid>
<description>A big project I've been working on recently for Fedora Workstation is what we call flickerfree boot. The idea here is that the firmware lights up the display in its native mode and no further modesets are done after that. Likewise there are also no unnecessary jarring graphical transitions.&lt;p&gt;Basically the machine boots up in UEFI mode, shows its vendor logo and then the screen keeps showing the vendor logo all the way to a smooth fade into the gdm screen. &lt;a href=&quot;https://fedorapeople.org/~jwrdegoede/flickerfree-videos/workstation-normal.webm&quot; rel=&quot;nofollow&quot;&gt;Here&lt;/a&gt; is a &lt;a href=&quot;https://fedorapeople.org/~jwrdegoede/flickerfree-videos/workstation-normal.webm&quot; rel=&quot;nofollow&quot;&gt;video&lt;/a&gt; of my main workstation booting this way.&lt;/p&gt;&lt;p&gt;Part of this effort is the &lt;a href=&quot;https://fedoraproject.org/wiki/Changes/HiddenGrubMenu&quot; rel=&quot;nofollow&quot;&gt;hidden grub menu change&lt;/a&gt; for Fedora 29. I'm happy to announce that most of the other flickerfree changes have also landed for Fedora 29:&lt;br/&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;There have been changes to shim and grub to not mess with the EFI framebuffer, leaving the vendor logo intact, when they don't have anything to display (so when grub is hidden)&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;There have been changes to the kernel to properly inherit the EFI framebuffer when using Intel integrated graphics, and to delay switching the display to the framebuffer-console until the first kernel message is printed. Together with changes to make &lt;em&gt;&quot;quiet&quot;&lt;/em&gt; really quiet (except for oopses/panics) this means that the kernel now also leaves the EFI framebuffer with the logo intact if quiet is used.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;There have been changes to plymouth to allow pressing ESC as soon as plymouth loads to get detailed boot messages.&lt;br/&gt;&lt;/li&gt;
&lt;/ol&gt;
With all these changes in place it is possible to get a fully flickerfree boot today, as the &lt;a href=&quot;https://fedorapeople.org/~jwrdegoede/flickerfree-videos/workstation-normal.webm&quot; rel=&quot;nofollow&quot;&gt;video of my workstation&lt;/a&gt; shows. This video is made with a stock Fedora 29 with 2 small kernel commandline tweaks:
&lt;ol&gt;&lt;li&gt;&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Add &lt;em&gt;&quot;i915.fastboot=1&quot;&lt;/em&gt; to the kernel commandline, this removes the first and last modeset during the boot when using the i915 driver.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Add &lt;em&gt;&quot;plymouth.splash-delay=20&quot;&lt;/em&gt; to the kernel commandline. Normally plymouth waits 5 seconds before showing the charging Fedora logo so that on systems which boot in less then 5 seconds the system simply immediately transitions to gdm. On systems which take slightly longer to boot this makes &lt;a href=&quot;https://fedorapeople.org/~jwrdegoede/flickerfree-videos/workstation-plymouth.webm&quot; rel=&quot;nofollow&quot;&gt;the charging Fedora logo show up&lt;/a&gt;, which IMHO makes the boot &lt;a href=&quot;https://fedorapeople.org/~jwrdegoede/flickerfree-videos/workstation-plymouth.webm&quot; rel=&quot;nofollow&quot;&gt;less fluid&lt;/a&gt;. This option increases the time plymouth waits with showing the splash to 20 seconds.&lt;br/&gt;&lt;/li&gt;
&lt;/ol&gt;
So if you have a machine with Intel integrated graphics and booting in UEFI mode, you can give flickerfree boot support a spin with Fedora 29 by just adding these 2 commandline options. Note this requires the new grub hidden menu feature to be enabled, see the &lt;a href=&quot;https://hansdegoede.livejournal.com/19081.html&quot; rel=&quot;nofollow&quot;&gt;FAQ on this&lt;/a&gt;.&lt;p&gt;The need for these 2 commandline options shows that the work on this is not yet entirely complete, here is my current TODO list for finishing this feature:
&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Work with the upstream i915 driver devs to make i915.fastboot the default. If you try i915.fastboot=1 and it causes problems for you please let me know.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Write a new plymouth theme based on the spinner theme which used the vendor logo as background and draws the spinner beneath it. Since this keeps the logo and black background as is and just draws the spinner on top this avoids the current visually jarring transition from logo screen to plymouth, allowing us to set plymouth.splash-delay to 0. This also has the advantage that the spinner will provide visual feedback that something is actually happening as soon as plymouth loads.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Look into making this work with AMD and NVIDIA graphics.&lt;br/&gt;&lt;/li&gt;
&lt;/ol&gt;
Please give the new flickerfree support a spin and let me know if you have any issues with it.

</description>
<pubDate>Tue, 02 Oct 2018 17:50:58 +0000</pubDate>
<dc:creator>kbumsik</dc:creator>
<og:description>A big project Ive been working on recently for Fedora Workstation is what we call flickerfree boot. The idea here is that the firmware lights up the display in its native mode and no further modesets are done after that. Likewise there are also no unnecessary jarring graphical transitions.…</og:description>
<og:image>https://l-stat.livejournal.net/img/sign.png</og:image>
<og:title>Announcing flickerfree boot for Fedora 29</og:title>
<og:type>article</og:type>
<og:url>https://hansdegoede.livejournal.com/19224.html</og:url>
<dc:format>text/html</dc:format>
<dc:identifier>https://hansdegoede.livejournal.com/19224.html</dc:identifier>
</item>
<item>
<title>Fastai for PyTorch: Fast and accurate neural nets using modern best practices</title>
<link>http://www.fast.ai/2018/10/02/fastai-ai/</link>
<guid isPermaLink="true" >http://www.fast.ai/2018/10/02/fastai-ai/</guid>
<description>&lt;span class=&quot;post-date&quot;&gt;Written: 02 Oct 2018 by &lt;em&gt;Jeremy Howard&lt;/em&gt;&lt;/span&gt;
&lt;p class=&quot;message&quot;&gt;&lt;em&gt;Note from Jeremy&lt;/em&gt;: Want to learn more? Listen to me discuss fastai with Sam Charrington in this &lt;a href=&quot;https://twimlai.com/twiml-talk-186-the-fastai-v1-deep-learning-framework-with-jeremy-howard&quot;&gt;in-depth interview&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Today fast.ai is releasing v1 of a new free open source library for deep learning, called &lt;a href=&quot;http://docs.fast.ai&quot;&gt;fastai&lt;/a&gt;. The library sits on top of &lt;a href=&quot;https://code.fb.com/ai-research/facebook-accelerates-ai-development-with-new-partners-and-production-capabilities-for-pytorch-1-0&quot;&gt;PyTorch v1&lt;/a&gt; (released today in preview), and provides a single consistent API to the most important deep learning applications and data types. fast.ai’s &lt;a href=&quot;http://www.fast.ai/2018/08/10/fastai-diu-imagenet/&quot;&gt;recent research breakthroughs&lt;/a&gt; are embedded in the software, resulting in significantly improved accuracy and speed over other deep learning libraries, whilst requiring dramatically less code. You can download it today from conda, pip, or &lt;a href=&quot;https://github.com/fastai/fastai/&quot;&gt;GitHub&lt;/a&gt; or use it on &lt;a href=&quot;https://cloud.google.com/&quot;&gt;Google Cloud Platform&lt;/a&gt;. AWS support is coming soon.&lt;/p&gt;
&lt;h2 id=&quot;about-fastai&quot;&gt;About fast.ai&lt;/h2&gt;
&lt;p&gt;fast.ai’s mission is to make the power of state of the art deep learning available to anyone. In order to make that happen, we do three things:&lt;/p&gt;
&lt;ol readability=&quot;1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Research how to apply state of the art deep learning to practical problems quickly and reliably&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;Build software to make state of the art deep learning as easy to use as possible, whilst remaining easy to customize for researchers wanting to explore hypotheses&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Teach courses so that as many people as possible can use the research results and software&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;You may well already be familiar with our courses. Hundreds of thousands of people have already taken our &lt;a href=&quot;http://course.fast.ai/&quot;&gt;Practical Deep Learning for Coders&lt;/a&gt; course, and many alumni are now doing amazing work with their new skills, at organizations like Google Brain, OpenAI, and Github. (Many of them now actively contribute to our busy deep learning practitioner &lt;a href=&quot;http://forums.fast.ai/&quot;&gt;discussion forums&lt;/a&gt;, along with other members of the wider deep learning community.)&lt;/p&gt;
&lt;p&gt;You may also have heard about some of our recent research breakthroughs (with help from our students and collaborators!), including &lt;a href=&quot;https://www.technologyreview.com/s/611858/small-team-of-ai-coders-beats-googles-code/&quot;&gt;breaking deep learning speed records&lt;/a&gt; and achieving a new &lt;a href=&quot;http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html&quot;&gt;state of the art in text classification&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;the-new-fastai-library&quot;&gt;The new fastai library&lt;/h2&gt;
&lt;p&gt;So that covers the research and teaching parts of the three listed areas—but what about software? Today we’re releasing v1.0 of our new &lt;a href=&quot;http://docs.fast.ai&quot;&gt;fastai deep learning library&lt;/a&gt;, which has been under development for the last 18 months. fastai sits on top of &lt;a href=&quot;https://pytorch.org/&quot;&gt;PyTorch&lt;/a&gt;, which provides the foundation for our work. When we announced the initial development of fastai &lt;a href=&quot;http://www.fast.ai/2017/09/08/introducing-pytorch-for-fastai/&quot;&gt;over one year ago&lt;/a&gt;, we described many of the advantages that PyTorch provides us. For instance, we talked about how we could “&lt;em&gt;use all of the flexibility and capability of regular python code to build and train neural networks&lt;/em&gt;”, and “&lt;em&gt;we were able to tackle a much wider range of problems&lt;/em&gt;”. The PyTorch team has been very supportive throughout fastai’s development, including contributing critical performance optimizations that have enabled key functionality in our software.&lt;/p&gt;
&lt;p&gt;fastai is the first deep learning library to provide a single consistent interface to all the most commonly used deep learning applications for vision, text, tabular data, time series, and collaborative filtering. This is important for practitioners, because it means if you’ve learnt to create practical computer vision models with fastai, then you can use the same approach to create natural language processing (NLP) models, or any of the other types of model we support.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://cloud.google.com/&quot;&gt;Google Cloud Platform&lt;/a&gt; are making fastai v1 available to all their customers from today in an experimental Deep Learning image for Google Compute Engine, including ready-to-run notebooks and preinstalled datasets. To use it, simply head over to &lt;a href=&quot;https://cloud.google.com/deep-learning-vm/docs/images&quot;&gt;Deep Learning images page&lt;/a&gt; on Google Cloud Marketplace and setup configuration for your instance, set framework to PyTorch 1.0RC and click “deploy”. That’s it, you now have the VM with Jupyter Lab, PyTorch 1.0 and fastai on it! Read more about how you can use the images &lt;a href=&quot;https://blog.kovalevskyi.com/google-compute-engine-now-has-images-with-pytorch-1-0-0-and-fastai-1-0-2-57c49efd74bb&quot;&gt;in this post&lt;/a&gt; from Google’s Viacheslav Kovalevskyi. And if you want to use fastai in a GPU-powered Jupyter Notebook, it’s now a single click away thanks to fastai support on &lt;a href=&quot;https://salamander.ai/&quot;&gt;Salamander&lt;/a&gt;, also released today.&lt;/p&gt;
&lt;p&gt;Good news too from Bratin Saha, VP, &lt;a href=&quot;https://aws.amazon.com/&quot;&gt;Amazon Web Services&lt;/a&gt;: “To support fast.ai’s mission to make the power of deep learning available at scale, the fastai library will soon be available in the AWS &lt;a href=&quot;https://aws.amazon.com/machine-learning/amis/&quot;&gt;Deep Learning AMIs&lt;/a&gt; and &lt;a href=&quot;https://aws.amazon.com/sagemaker/&quot;&gt;Amazon SageMaker&lt;/a&gt;”.&lt;/p&gt;
&lt;h2 id=&quot;early-users&quot;&gt;Early users&lt;/h2&gt;
&lt;h3 id=&quot;semantic-code-search-at-github&quot;&gt;Semantic code search at GitHub&lt;/h3&gt;
&lt;p&gt;fast.ai are enthusiastic users of &lt;strong&gt;&lt;a href=&quot;https://github.com/&quot;&gt;Github&lt;/a&gt;’s&lt;/strong&gt; collaboration tools, and many of the Github team work with fast.ai tools too - even the &lt;a href=&quot;https://www.reddit.com/r/AMA/comments/8pc8mf/im_nat_friedman_future_ceo_of_github_ama/e0a2qjj/&quot;&gt;CEO of Github studies deep learning&lt;/a&gt; using our courses! &lt;a href=&quot;https://www.linkedin.com/in/hamelhusain/&quot;&gt;Hamel Husain&lt;/a&gt;, a Senior Machine Learning Scientist at Github who has been studying deep learning through fast.ai for the last two years, says:&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;“The fast.ai course has been taken by data scientists and executives at Github alike ushering in a new age of data literacy at GitHub. It gave data scientists at GitHub the confidence to tackle state of the art problems in machine learning, which were previously believed to be only accessible to large companies or folks with PhDs.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Husain and his colleague &lt;a href=&quot;https://www.linkedin.com/in/hohsiangwu/&quot;&gt;Ho-Hsiang Wu&lt;/a&gt; recently released a new experimental tool for &lt;a href=&quot;https://experiments.github.com/semantic-code-search&quot;&gt;semantic code search&lt;/a&gt;, which allows Github users to find useful code snippets using questions written in plain English. In a &lt;a href=&quot;https://githubengineering.com/towards-natural-language-semantic-code-search/&quot;&gt;blog post&lt;/a&gt; announcing the tool, they describe how they switched from Google’s Tensorflow Hub to fastai, because it “&lt;em&gt;gave us easy access to state of the art architectures such as AWD LSTMs, and techniques such as cyclical learning rates with random restarts&lt;/em&gt;”.&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;640&quot; src=&quot;http://www.fast.ai/images/fastai_v1beta/image_0.png&quot; alt=&quot;Screenshot from Github’s semantic code search tool&quot;/&gt; Screenshot from Github’s semantic code search tool
&lt;p&gt;Husain has been using a pre-release version of the fastai library for the last 12 months. He told us:&lt;/p&gt;
&lt;blockquote readability=&quot;11.053140096618&quot;&gt;
&lt;p&gt;“I choose fast.ai because of its modularity, high level apis that implemented &lt;a href=&quot;https://blog.floydhub.com/ten-techniques-from-fast-ai/&quot;&gt;state of the art techniques&lt;/a&gt;, and innovations that &lt;a href=&quot;http://www.fast.ai/2018/04/30/dawnbench-fastai/&quot;&gt;reduce the need for tons of compute&lt;/a&gt; but with the same performance characteristics. The semantic code search demo is only the tip of the iceberg, as folks in sales, marketing, fraud are currently leveraging the power of fastai to bring transformative change to their business areas.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;music-generation&quot;&gt;Music generation&lt;/h3&gt;
&lt;p&gt;One student that stood out in our last fast.ai deep learning course was &lt;a href=&quot;http://christinemcleavey.com/&quot;&gt;Christine McLeavey Payne&lt;/a&gt;, who had already had a fascinating journey as an award-winning classical pianist with an SF Symphony chamber group, a high performance computing expert in the finance world, and a neuroscience and medical researcher at Stanford. Her journey has only gotten more interesting since, and today she is a Research Fellow at the famous &lt;a href=&quot;https://openai.com/&quot;&gt;OpenAI&lt;/a&gt; research lab. In her most recent OpenAI project, she used fastai to help her create &lt;a href=&quot;http://christinemcleavey.com/clara-a-neural-net-music-generator/&quot;&gt;Clara: A Neural Net Music Generator&lt;/a&gt;. Here is some of her &lt;a href=&quot;http://christinemcleavey.com/wp-content/uploads/2018/08/0-2.wav&quot;&gt;generated chamber music&lt;/a&gt;. Christine says:&lt;/p&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;“The fastai library is an amazing resource. Even when I was just starting in deep learning, it was easy to get a fastai model up and running in only a few lines of code. At that point, I didn’t understand the state-of-the-art techniques happening under the hood, but still they worked, meaning my models trained faster, and reached significantly better accuracy.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Christine has even created a &lt;a href=&quot;http://christinemcleavey.com/human-or-ai/&quot;&gt;human or computer&lt;/a&gt; quiz that you can try for yourself; see if you can figure which pieces were generated by her algorithm! Clara is closely based on work she did on language modeling for one of her fast.ai student projects, and leverages the fastai library’s support for recent advances in natural language processing. Christine told us:&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;“It’s only more recently that I appreciate just how important these details are, and how much work the fastai library saves me. It took me just under two weeks to get this music generation project up and getting great initial results. I’m certain that speed couldn’t have been possible without fastai.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We think that Clara is a great example of the expressive power of deep learning—in this case, a model designed to generate and classify text has been used to generate music, with relatively few modifications. “&lt;em&gt;I took a fastai Language Model almost exactly (very slight changes in sampling the generation) and experimented with ways to write out the music in either a “notewise” or “chordwise” encoding&lt;/em&gt;” she &lt;a href=&quot;https://twitter.com/mcleavey/status/1043258046334595072&quot;&gt;wrote on Twitter&lt;/a&gt;. The result was a crowd favorite, with Vanessa M Garcia, a Senior Researcher at IBM Watson, declaring it her top choice at OpenAI’s Demo Day.&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;640&quot; src=&quot;http://www.fast.ai/images/fastai_v1beta/image_1.png&quot; alt=&quot;Twitter comment about Christine's music generation demo&quot;/&gt; Twitter comment about Christine's music generation demo
&lt;h3 id=&quot;fastai-for-art-projects&quot;&gt;fastai for art projects&lt;/h3&gt;
&lt;p&gt;Architect and Investor &lt;strong&gt;Miguel Pérez Michaus&lt;/strong&gt; has been using a pre-release version of fastai to research a system for art experiments that he calls &lt;a href=&quot;https://medium.com/@miguelpmich/was-this-your-face-vincent-48e4059ace69&quot;&gt;Style Reversion&lt;/a&gt;. This is definitely a case where a picture tells a thousand words, so rather than try to explain what it does, I’ll let you see for yourself:&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;640&quot; src=&quot;http://www.fast.ai/images/fastai_v1beta/image_2.png&quot; alt=&quot;Example of Style Reversion&quot;/&gt; Example of Style Reversion
&lt;p&gt;Pérez Michaus says he likes designing with fastai because “&lt;em&gt;I know that it can get me where [Google’s Tensorflow library] Keras can not, for example, whenever something ‘not standard’ has to be achieved&lt;/em&gt;”. As an early adopter, he’s seen the development of the library over the last 12 months:&lt;/p&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;“I was lucky enough to see alpha version of fastai evolving, and even back then its power and flexibility was evident. Additionally, it was fully usable for people like myself, with domain knowledge but no formal Computer Science background. And it only has gotten better. My quite humble intuition about the future of deep learning is that we will need a fine grained understanding of what is really goes on under the hood, and in that landscape I think fastai is going to shine.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;fastai-for-academic-research&quot;&gt;fastai for academic research&lt;/h3&gt;
&lt;p&gt;Entrepreneurs &lt;strong&gt;Piotr Czapla and Marcin Kardas&lt;/strong&gt; are the co-founders of &lt;a href=&quot;https://www.n-waves.com/&quot;&gt;n-waves&lt;/a&gt;, a deep learning consulting company. They used fastai to develop a &lt;a href=&quot;https://www.n-waves.com/perspectives/fastai-v1&quot;&gt;novel algorithm for text classification&lt;/a&gt; in Polish, based on ideas shown in fast.ai’s &lt;a href=&quot;http://course.fast.ai/part2.html&quot;&gt;Cutting Edge Deep Learning for Coders&lt;/a&gt; course. Polish is challenging for NLP, since it is a morphologically rich language (e.g. number, gender, animacy, and case are all collapsed into a word’s suffix). The algorithm that Czapla and Kardas developed won first prize in the top NLP academic competition in Poland, and a paper based on this new research will be published soon. According to Czapla, the fastai library was critical to their success:&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;“I love that fastai works well for normal people that do not have hundreds of servers at their disposal. It supports quick development and prototyping, and has all the best deep learning practices incorporated into it.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The course and community have also been important for them:&lt;/p&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;“fast.ai’s courses opened my eyes to deep learning, and helped me to think and develop intuitions around how deep learning really works. Most of the answers to my questions are already on the forum somewhere, just a search away. I love how the notes from the lectures are composed into Wiki topics, and that other students are creating transcriptions of the lessons so that they are easier to find.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;example-transfer-learning-in-computer-vision&quot;&gt;Example: Transfer learning in computer vision&lt;/h2&gt;
&lt;p&gt;fast.ai’s research is embedded in that fastai library, so you get the benefits of it automatically. Let’s take a look at an example of what that means…&lt;/p&gt;
&lt;p&gt;Kaggle’s &lt;a href=&quot;https://www.kaggle.com/c/dogs-vs-cats&quot;&gt;Dogs vs Cats&lt;/a&gt; competition has been a favorite part of our courses since the very start, and it represents an important class of problems: transfer learning of a pre-trained model. So we’ll take a look at how the fastai library goes on this task.&lt;/p&gt;
&lt;p&gt;Before we built fastai, we did most of our research and teaching using Keras (with the Tensorflow backend), and we’re still big fans of it. Keras really led the way in showing how to make deep learning easier to use, and it’s been a big inspiration for us. Today, it is (for good reason) the most popular way to train neural networks. In this brief example we’ll compare Keras and fastai on what we think are the three most important metrics: amount of code required, accuracy, and speed.&lt;/p&gt;
&lt;p&gt;Here’s all the code required to do 2-stage fine tuning with fastai - not only is there very little code to write, there’s very few parameters to set:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;10.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;16&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_from_imagefolder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/dogscats'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ds_tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imagenet_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ConvLearner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tvm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resnet34&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unfreeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;slice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3e-4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Let’s compare the two libraries on this task (we’ve tried to match &lt;a href=&quot;https://github.com/fastai/fastai_v1/blob/master/dev_nb/experiments/keras_lesson1.ipynb&quot;&gt;our Keras implementation&lt;/a&gt; as closely as possible, although since Keras doesn’t support all the features that fastai provides, it’s not identical):&lt;/p&gt;
&lt;table readability=&quot;2&quot;&gt;&lt;tr&gt;&lt;td/&gt;
&lt;td&gt;fastai resnet34*&lt;/td&gt;
&lt;td&gt;fastai resnet50&lt;/td&gt;
&lt;td&gt;Keras&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Lines of code (excluding imports)&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;31&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Stage 1 error&lt;/td&gt;
&lt;td&gt;0.70%&lt;/td&gt;
&lt;td&gt;0.65%&lt;/td&gt;
&lt;td&gt;2.05%&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Stage 2 error&lt;/td&gt;
&lt;td&gt;0.50%&lt;/td&gt;
&lt;td&gt;0.50%&lt;/td&gt;
&lt;td&gt;0.80%&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Test time augmentation (TTA) error&lt;/td&gt;
&lt;td&gt;0.30%&lt;/td&gt;
&lt;td&gt;0.40%&lt;/td&gt;
&lt;td&gt;N/A*&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Stage 1 time&lt;/td&gt;
&lt;td&gt;4:56&lt;/td&gt;
&lt;td&gt;9:30&lt;/td&gt;
&lt;td&gt;8:30&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Stage 2 time&lt;/td&gt;
&lt;td&gt;6:44&lt;/td&gt;
&lt;td&gt;12:48&lt;/td&gt;
&lt;td&gt;17:38&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;&lt;em&gt;* Keras does not provide resnet 34 or TTA&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;(It’s important to understand that these improved results over Keras in no way suggest that Keras isn’t an excellent piece of software. Quite the contrary! If you tried to complete this task with almost any other library, you would need to write &lt;em&gt;far&lt;/em&gt; more code, and would be unlikely to see better speed or accuracy than Keras. That’s why we’re showing Keras in this comparison - because we’re admirers of it, and it’s the strongest benchmark we know of!)&lt;/p&gt;
&lt;p&gt;fastai also show similarly strong performance for NLP. The state of the art text classification algorithm is &lt;a href=&quot;https://arxiv.org/abs/1801.06146&quot;&gt;ULMFit&lt;/a&gt;. Here’s the relative error of ULMFiT versus previous top ranked algorithms on the popular IMDb dataset, as shown in the ULMFiT paper:&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;640&quot; src=&quot;http://www.fast.ai/images/fastai_v1beta/image_3.png&quot; alt=&quot;Summary of text classification performance&quot;/&gt; Summary of text classification performance
&lt;p&gt;fastai is currently the only library to provide this algorithm. Because the algorithm is built in to fastai, you can match the paper’s results with similar code to that shown above for Dogs vs Cats. Here’s how you train the language model for ULMFiT:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;13.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;22&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_from_textcsv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LM_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RNNLearner&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;language_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drop_mult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pretrained_fnames&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'lstm_wt103'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'itos_wt103'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;moms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unfreeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;moms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pct_start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&quot;under-the-hood---pytorch-v1&quot;&gt;Under the hood - pytorch v1&lt;/h2&gt;
&lt;p&gt;A critical component of fastai is the extraordinary foundation provided by &lt;a href=&quot;https://pytorch.org/&quot;&gt;PyTorch&lt;/a&gt;, v1 (preview) of which is also being released today. fastai isn’t something that replaces and hides PyTorch’s API, but instead is designed to expand and enhance it. For instance, you can create new data augmentation methods by simply creating a function that does standard PyTorch tensor operations; here’s the entire definition of fastai’s &lt;code class=&quot;highlighter-rouge&quot;&gt;jitter&lt;/code&gt; function:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;7&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;9&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;jitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;magnitude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;magnitude&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;As another example, fastai uses and extends PyTorch’s concise and expressive Dataset and DataLoader classes for accessing data. When we wanted to add support for image segmentation problems, it was as simple as defining this standard PyTorch Dataset class:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;10&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;15&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MatchedFilesDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DatasetBase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__getitem__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;open_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;open_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This means that as practitioners want to dive deeper into their models, data, and training methods, they can take advantage of all the richness of the full PyTorch ecosystem. Thanks to PyTorch’s dynamic nature, programmers can easily debug their models using standard Python tools. In many areas of deep learning, PyTorch is the most common platform for researchers publishing their research; fastai makes it simple to test our these new approaches.&lt;/p&gt;
&lt;h2 id=&quot;under-the-hood---fastai&quot;&gt;Under the hood - fastai&lt;/h2&gt;
&lt;p&gt;In the coming months we’ll be publishing academic papers and blog posts describing the key pieces of the fastai library, as well as releasing a new course that will walk students through how the library was developed from scratch. To give you a taste, we’ll touch on a couple of interesting pieces here, focussing on computer vision.&lt;/p&gt;
&lt;p&gt;One thing we care a lot about is speed. That’s why we competed in Stanford’s &lt;a href=&quot;https://dawn.cs.stanford.edu/benchmark/&quot;&gt;DAWNBench&lt;/a&gt; competition for rapid and accurate model training, where (along with our collaborators) we have achieved first place in every category we entered. If you want to match our top single-machine CIFAR-10 result, it’s as simple as four lines of code:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;13.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;22&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;crop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_pct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col_pct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;flip_lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_from_imagefolder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/cifar10'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'test'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ds_tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cifar_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wrn_22&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_fp16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Much of the magic is buried underneath that &lt;code class=&quot;highlighter-rouge&quot;&gt;to_fp16()&lt;/code&gt; method call. Behind the scenes, we’re following all of Nvidia’s &lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html&quot;&gt;recommendations for mixed precision training&lt;/a&gt;. No other library that we know of provides such an easy way to leverage Nvidia’s latest technology, which gives two to three times better performance compared to previous approaches.&lt;/p&gt;
&lt;p&gt;Another thing we care a lot about is accuracy. We want your models to work well not just on your training data, but on new test data as well. Therefore, we’ve built an entirely new computer vision library from scratch that makes it easy to develop and use data augmentation methods, to improve your model’s performance on unseen data. The new library uses a new approach to minimize the number of lossy transformations that your data goes through. For instance, take a look at the three images below:&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;640&quot; src=&quot;http://www.fast.ai/images/fastai_v1beta/image_4.png&quot; alt=&quot;Example of fastai transforms&quot;/&gt; Example of fastai transforms
&lt;p&gt;On the left is the original low resolution image from the CIFAR-10 dataset. In the middle is the result of zooming and rotating this image using standard deep learning augmentation libraries. On the right is the same zoom and rotation, using fastai v1. As you can see, with fastai the detail is kept much better; for instance, take a look at how the pilot’s window is much crisper in the right-hand image than the middle image. This change to how data augmentation is applied means that practitioners using fastai can use far more augmentation than users of other libraries, resulting in models that generalize better.&lt;/p&gt;
&lt;p&gt;These data augmentations even work automatically with non-image data such as bounding boxes. For instance, here’s an example of how fastai’s works with an image detection dataset, automatically tracking each bounding box through all augmentations:&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;640&quot; src=&quot;http://www.fast.ai/images/fastai_v1beta/image_5.png&quot; alt=&quot;Transforming bounding box data&quot;/&gt; Transforming bounding box data
&lt;p&gt;These kinds of thoughtful features can be found throughout the fastai library. Over the coming months we’ll be doing deep dives in to many of them, for those of you interested in the details of how fastai is implemented behind the scenes.&lt;/p&gt;
&lt;h2 id=&quot;thanks&quot;&gt;Thanks!&lt;/h2&gt;
&lt;p&gt;Many thanks to the PyTorch team. Without PyTorch, none of this would have been possible. Thanks also to Amazon Web Services, who sponsored fast.ai’s first Researcher in Residence, Sylvain Gugger, who has contributed much of the development of fastai v1. Thanks also to fast.ai alumni Fred Monroe, &lt;a href=&quot;https://www.linkedin.com/in/anshaw/&quot;&gt;Andrew Shaw&lt;/a&gt;, and &lt;a href=&quot;https://www.linkedin.com/in/stasbekman/?originalSubdomain=ca&quot;&gt;Stas Bekman&lt;/a&gt;, who have all made significant contributions, to Yaroslav Bulatov, who was a key contributor to our most recent DAWNBench project, to Viacheslav Kovalevskyi, who handled Google Cloud integration, and of course to all the students and collaborators who have helped make the community and software successful.&lt;/p&gt;
</description>
<pubDate>Tue, 02 Oct 2018 17:11:40 +0000</pubDate>
<dc:creator>stablemap</dc:creator>
<dc:language>en-us</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.fast.ai/2018/10/02/fastai-ai/</dc:identifier>
</item>
<item>
<title>Startups I Want to Fund</title>
<link>https://startupandrew.com/posts/startups-i-want-to-fund/</link>
<guid isPermaLink="true" >https://startupandrew.com/posts/startups-i-want-to-fund/</guid>
<description>&lt;p&gt;I hear a lot of startup pitches. I’ve been angel investing now for ~4 years, and I’m an LP and advisor to a number of VC funds. I also heard a lot of pitches through my work at &lt;a href=&quot;https://firebase.google.com/&quot;&gt;Firebase&lt;/a&gt; (the company I co-founded), as many of its customers are startups.&lt;/p&gt;
&lt;p&gt;I like being pitched – partly because I enjoy meeting smart people, and partly because it’s a chance to pay-it-forward to the next cohort of entrepreneurs, but largely because it’s a chance to be a part of the solution to some of the world’s biggest problems.&lt;/p&gt;
&lt;p&gt;My favorite pitches solve a problem I’m already concerned about. These pitches present me with a novel approach I had not considered, and they back up their approach with some promising initial data and a high-powered team that’s ready to take this all the way to the finish line. I walk away from these pitches excited, hopeful, and with a new perspective on the problem. I find myself thinking “what can I do to make sure they are successful?” These are the startups I invest in, and they’re the ones I share with my investor friends.&lt;/p&gt;
&lt;p&gt;The pitches I’m most excited to hear are the ones solving the big, scary problems that most people don’t want to touch. Climate change? Here’s a credible path to solving it. Infectious diseases? Here’s how home testing can make a difference. Net neutrality? Here’s how a new model for ISPs can change things. Electricity access for the poor? Here’s how 1.3 billion more people can get it.&lt;/p&gt;
&lt;p&gt;So, without further ado, here are some startup pitches I’m just itching to hear!&lt;/p&gt;
&lt;h2 id=&quot;bigger-bolder-developer-platforms&quot;&gt;Bigger, bolder developer platforms&lt;/h2&gt;
&lt;p&gt;It should come as a surprise to no one that I’m an active investor in the developer products space (some of my investments here include &lt;a href=&quot;https://www.imgix.com/&quot;&gt;Imgix&lt;/a&gt;, &lt;a href=&quot;https://iterative.ai/&quot;&gt;Iterative.ai&lt;/a&gt;, &lt;a href=&quot;http://sentenai.com/&quot;&gt;Sentenai&lt;/a&gt;, and &lt;a href=&quot;https://www.envkey.com/&quot;&gt;EnvKey&lt;/a&gt;). Here are several ecosystem-wide problems that I think about a lot, and for which I’m eager to hear a good solution.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;An open app runtime&lt;/strong&gt; – Proprietary mobile app runtimes are winning, as they provide a better user experience, better performance, and greater security than the open web. Proprietary app stores are winning too – and in the process, they are distorting markets and censoring apps. The open web is in full retreat, but the war has not been lost. There are still far more web developers than native developers, and they’re just waiting for a platform that can really go toe-to-toe with native apps. Could a browser be built that provides an actually better app experience and performance than native apps? What legacy could we throw out to make this happen? URLs? The DOM? Even HTML?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A new developer-oriented touchscreen OS&lt;/strong&gt; – The number of touchscreens in our daily lives is exploding. Android and iOS are optimized for consumer tablets and phones, but what if you’re a developer building a non-consumer product? What if you want to build a cash register, or a digital menu, or an in-flight entertainment solution, or a vending machine?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Federated databases&lt;/strong&gt; – The most common use case I hear for “the blockchain” is the ability to have a database “in the cloud” that multiple parties can share without needing to trust a single, central authority to run it. We don’t need blockchain for this! Tools like git have already partially solved this problem for source code. Could a similar solution be built for structured data? Could cryptography provide solutions for access control and auditing that provide protections against malicious actors?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Re-inventing the package manager&lt;/strong&gt; – existing package managers are security and compliance nightmares. What if a package manager could give me confidence that the software I’m relying on is built by trustworthy people, has dependencies I understand, has a license I understand, and will continue to be maintained going forward? Or, what if a package manager could help developers of open source software monetize their work?&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;social-silo-busters&quot;&gt;Social Silo-busters&lt;/h2&gt;
&lt;p&gt;Facebook started as a way to share updates with your friends. Instagram and Snapchat started as ways to share photos. YouTube began as a way to share videos. Twitter began as a way to share short thoughts.&lt;/p&gt;
&lt;p&gt;Each of these services _started _as a way to help the producers of content get their message out to the world. They thrived and grew rapidly. But then they changed… the advertising business model created an incentive not just to help people produce and share content, but to keep people in the app as long as possible. They morphed into carefully engineered machines for sucking up as much of your time and attention as possible. They encouraged narcissism, clickbait, partisan politics, “fake news”, creepy videos, and other negatives. They stopped being healthy, fun ways to connect with your loved ones.&lt;/p&gt;
&lt;p&gt;Then came privacy issues. Advertising requires personal data, so these companies began mining our personal communications for ad targeting. This led to adverse product decisions – weakening of encryption, overly-liberal privacy defaults, merging of personal data between seemingly independent sources, “creepy” behavior, and so on.&lt;/p&gt;
&lt;p&gt;People are becoming aware of these problems like never before, and they’re beginning to demand better solutions. Below are some areas that I would be excited to invest in:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Social utilities&lt;/strong&gt; – What if a social app was optimized for the creation experience rather than the consumption experience? What if the goal was to minimize time-in-app rather than maximize it? What social products would people pay for? (note: Google Photos is the closest I’ve seen to this so far)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Messaging and Email&lt;/strong&gt; – in the beginning, we had email. And it was federated, and open, and it was good. Then came spam, and mobile, and tons of images and video, and new security threats. With these new requirements, we still had email, but now we also had SMS, and Whatsapp, and iMessage, and Messenger, and WeChat, and Skype, and Twitter DMs, and Hangouts, and Slack. And, it is unusable. Is it possible to return to a single, federated protocol that supports modern requirements? Could email be upgraded to make this possible, or could a new open, federated service be invented? Could we break up the messaging silos and return to a single unified inbox?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A social calendar&lt;/strong&gt; – Google seems to be winning the calendar fight without really trying. Their basic UI and functionality hasn’t changed in years. Why can’t my calendar better help me manage my day? Why can’t it make it easier for me to spend time with friends and family? Why can’t I more easily see the calendars of businesses and events nearby? The existence of Doodle, Stanza.co, and other products built around the calendar to plug its feature gaps tells me this space is ripe for a new approach.&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;capital-heavy-industries&quot;&gt;Capital-heavy Industries&lt;/h2&gt;
&lt;p&gt;Capital-lite startups have reigned for the last decade. AirBnB, Uber, and Instacart have been poster-children of this movement. “Let someone else own the assets,” they said. “We’ll just bring the software”.&lt;/p&gt;
&lt;p&gt;There were some big successes here, to be sure, but I think we’re now starting to see that there are limits to innovation when all you have is software. More recently, we’ve started to see what can be done when software is combined with capital assets: Bird and LimeBike are buying huge numbers of scooters, SpaceX, Rocket Lab, and others are building new launch vehicles, Joby Aviation is building new airplanes, and WeWork is one of the world’s biggest landlords. Public tech companies are even better examples of this: Tesla is investing billions in batteries and manufacturing, Amazon is investment billions in distribution centers, and Google, Microsoft, and Amazon are investing $10’s of billions on data centers for their cloud products.&lt;/p&gt;
&lt;p&gt;I’m very bullish on a capital-heavy, asset-full future for startups. I believe this combination will be needed to tackle our most pressing problems: energy, infrastructure, transportation, and so on. Some capital-heavy investments I’ve made already include &lt;a href=&quot;https://www.charmindustrial.com/&quot;&gt;Charm&lt;/a&gt;, &lt;a href=&quot;https://b8ta.com/&quot;&gt;B8ta&lt;/a&gt;, &lt;a href=&quot;https://www.crunchbase.com/organization/aurrion#section-overview&quot;&gt;Aurrion&lt;/a&gt;, and &lt;a href=&quot;https://sigora.co/&quot;&gt;Sigora&lt;/a&gt;, and. I remain very excited about the space, and below I’ve listed some specific areas I’d be excited to invest in.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Waste management&lt;/strong&gt; – how can technology transform this sector? For example, could AI be used to sort recyclables and other valuables efficiently out of trash? Why can’t I manage waste pickup from an app? What might a re-invented garbage truck look like?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Next-gen ISPs&lt;/strong&gt; – Fixed wireless radios, cheap satellites, LoRa, and mesh networking have the potential to make existing wired ISPs obsolete, as well as to bring internet access to billions in the developing world, and trillions of IoT devices.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Utility-scale batteries&lt;/strong&gt; – energy storage is critical to a clean energy future, but today’s batteries are too expensive. If size, weight, and mobility constraints are removed, could battery costs per KWh be reduced 90%? 99%? Many people are already working on flow batteries and other technologies in this space, but I believe much more investment is needed here.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Electric charging stations&lt;/strong&gt; – Electric charging is less dangerous, less toxic, and more space efficient than pumping gas, meaning it’s more practical to place it next to shopping, food, and entertainment. In addition, charging a car takes longer than filling a gas tank. Could the “gas stations” of the future be exciting destinations rather than eyesores?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Air conditioning&lt;/strong&gt; – As more people in hot climates enter the middle class, and as climate change accelerates, the demand for air conditioning will explode. What innovation is possible here?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alternative energy generation&lt;/strong&gt; – Ocean thermal? Fusion? Thorium? Biofuels? Fuel cells? Bring me your crazy.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Experiential retail&lt;/strong&gt; – many traditional retailers are dying at the same time that B8ta, Apple, Amazon, and Warby Parker are growing rapidly. People will always like to shop, but they’ll look to stores for experiences and product discovery, rather than as just a place to buy things. What new businesses will emerge from this shift?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;New aircraft for regional transit&lt;/strong&gt; – Aircraft have historically been used almost exclusively for long-range transportation, but could cheaper, denser batteries and smarter AI make short-range, regional air travel practical? How could these new aircraft change cities, especially in emerging markets? Many people are already working on this space, including Joby Aviation, Kitty Hawk, Lilium, and others, but I believe much more investment is warranted here, given the size of the opportunity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Receiver-centric package delivery&lt;/strong&gt; – why do we still mail packages to an address rather than to a person? When I shop online, why are my delivery options limited by what the retailer chooses to support? Why can’t I see a list of all packages en-route to me from a single app and re-route them to a different address with one button click? If I’m on vacation, why can’t I have my packages held and delivered on a future date, or placed in a nearby locker until I return?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Space&lt;/strong&gt; – what opportunities will cheap commercial rocket launches open up?&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;sleeper-markets&quot;&gt;Sleeper Markets&lt;/h2&gt;
&lt;p&gt;Despite all of the recent “disruption” from Silicon Valley, there are still many huge industries that have been left largely untouched. Many of these industries look boring from the outside, or appear to have intractable problems that software can’t solve. When a startup does manage to crack one of these markets, though, they find themselves with a huge market and no competition in site.&lt;/p&gt;
&lt;p&gt;Investments I’ve made in these “sleeper” markets include &lt;a href=&quot;https://openlattice.com/#/&quot;&gt;OpenLattice&lt;/a&gt;, &lt;a href=&quot;https://www.itsfairy.com/&quot;&gt;Fairy&lt;/a&gt;, and &lt;a href=&quot;https://embarktrucks.com/&quot;&gt;Embark&lt;/a&gt;. Here are some additional startups I’d like to fund:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;New staffing agencies&lt;/strong&gt; – companies like Adecco and Manpower take a huge cut of workers’ pay, and the industry hasn’t fundamentally changed in years. Could a new staffing agency use software to provide higher quality staffing to companies and better pay and services to workers?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;New insurance companies&lt;/strong&gt; – renters insurance, title insurance, business insurance, etc have yet to enter the 21st century.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;New media companies&lt;/strong&gt; – BuzzFeed, Vox, and Huffington Post have built successful online-first media businesses. What does the internet-native version of the WSJ or The Economist look like?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Online zoo&lt;/strong&gt; – Animals are more popular than ever. 700 million people visit a zoo each year. Online, videos of animals are among the most popular. Meanwhile, climate change and habitat destruction are threatening our world’s wildlife, and many endangered animals are at risk because local communities lack the funds to effectively protect them. Could an online zoo address a huge underserved market while simultaneously help to save wildlife? Could high speed internet and VR finally make this a really good experience?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you’re working in one of these areas, feel free to reach out to me: startupandrew (at) gmail dot com. I typically like to invest early in pre-seed or seed (though I’ve invested all the way up through Series B in the past). A normal first check from me ranges from $50k to $250k.&lt;/p&gt;
&lt;p&gt;Besides providing just money, as an investor I can be especially helpful advising on engineering plans, team-building, and overall business strategy. I also can provide introductions to other investors, and in some cases, help with hiring and business development.&lt;/p&gt;
&lt;p&gt;If you’re a founder who is just starting out, and you’re not yet looking for investment, feel free to borrow some ideas from this list. And, don’t be shy about reaching out as well. I’d be interested in hearing about your plans, and I may be able to provide more insight into the space you’re tackling too.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to Max Henderson, &lt;a href=&quot;https://twitter.com/JamesTamplin&quot;&gt;James Tamplin&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/reinpk&quot;&gt;Peter Reinhardt&lt;/a&gt;, and &lt;a href=&quot;https://twitter.com/binarybits&quot;&gt;Timothy Lee&lt;/a&gt; for reviewing drafts of this post.&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 02 Oct 2018 16:56:56 +0000</pubDate>
<dc:creator>vikrum</dc:creator>
<og:title>Startups I Want to Fund</og:title>
<og:description>I hear a lot of startup pitches. I’ve been angel investing now for ~4 years, and I’m an LP and advisor to a number of VC funds. I also heard a lot of pitches through my work at Firebase (the company I co-founded), as many of its customers are startups. I like being pitched – partly because I enjoy meeting smart people, and partly because it’s a chance to pay-it-forward to the next cohort of entrepreneurs, but largely because it’s a chance to be a part of the solution to some of the world’s biggest problems.</og:description>
<og:type>article</og:type>
<og:url>https://startupandrew.com/posts/startups-i-want-to-fund/</og:url>
<og:image>https://startupandrew.com/images/andrew.jpg</og:image>
<dc:language>en-us</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://startupandrew.com/posts/startups-i-want-to-fund/</dc:identifier>
</item>
<item>
<title>Facebook launches PyTorch 1.0</title>
<link>https://code.fb.com/ai-research/facebook-accelerates-ai-development-with-new-partners-and-production-capabilities-for-pytorch-1-0/</link>
<guid isPermaLink="true" >https://code.fb.com/ai-research/facebook-accelerates-ai-development-with-new-partners-and-production-capabilities-for-pytorch-1-0/</guid>
<description>&lt;p&gt;Earlier this year, &lt;a href=&quot;https://code.fb.com/ai-research/announcing-pytorch-1-0-for-both-research-and-production/&quot;&gt;we shared a vision&lt;/a&gt; for making AI development faster and more interoperable. Today, during our first-ever PyTorch Developer Conference, we are announcing updates about the growing ecosystem of software, hardware, and education partners that are deepening their investment in PyTorch. We’re also bringing together our active community of researchers, engineers, educators, and more to share how they’re using the open source deep learning platform for research and production, and walking through more details on the preview release of PyTorch 1.0.&lt;/p&gt;
&lt;p&gt;PyTorch 1.0 accelerates the workflow involved in taking breakthrough research in artificial intelligence to production deployment. With deeper cloud service support from Amazon, Google, and Microsoft, and tighter integration with technology providers ARM, Intel, IBM, NVIDIA, and Qualcomm, developers can more easily take advantage of PyTorch’s ecosystem of compatible software, hardware, and developer tools. The more software and hardware that is compatible with PyTorch 1.0, the easier it will be for AI developers to quickly build, train, and deploy state-of-the-art deep learning models.&lt;/p&gt;
&lt;h2&gt;What’s new in PyTorch 1.0&lt;/h2&gt;
&lt;p&gt;The latest additions to the framework include a new hybrid front end that enables tracing and scripting models from eager mode into graph mode for bridging the gap between exploration and production deployment, a revamped torch.distributed library that allows for faster training across Python and C++ environments, and an eager mode C++ interface (released in beta) for performance-critical research.&lt;/p&gt;
&lt;p&gt;Currently, researchers and engineers have to work across a number of frameworks and tools, many of which are often incompatible, to prototype new deep learning models and transfer them to run at scale in a production environment. Doing this slows down the rate at which we can deploy AI research breakthroughs at production scale. With this latest release, we’ve combined the flexibility of the existing PyTorch framework with the production capabilities of Caffe2 to deliver a seamless path from research to production-ready AI.&lt;/p&gt;
&lt;h2&gt;Deeper support from the ecosystem&lt;/h2&gt;
&lt;p&gt;AWS, Google, and Microsoft are deepening their investment in PyTorch 1.0 through more robust support for the framework across their cloud platforms, products, and services. For example, &lt;a href=&quot;https://aws.amazon.com/pytorch/&quot;&gt;Amazon SageMaker&lt;/a&gt;, AWS’s fully managed platform for training and deploying machine learning models at scale, now provides preconfigured environments for PyTorch 1.0, which include rich capabilities such as automatic model tuning.&lt;/p&gt;
&lt;p&gt;Google is &lt;a href=&quot;https://cloud.google.com/blog/products/ai-machine-learning/introducing-pytorch-across-google-cloud&quot;&gt;announcing new PyTorch 1.0 integrations&lt;/a&gt; across its software and hardware tools for AI development. Google Cloud Platform’s Deep Learning VM has a new VM image with PyTorch 1.0 that comes with NVIDIA drivers and tutorials preinstalled. Google also offers Cloud Tensor Processing Units (TPUs), which are custom-developed application-specific integrated circuits (ASIC) for machine learning (ML). Engineers on Google’s Cloud TPU team are in active collaboration with our PyTorch team to enable support for PyTorch 1.0 models on this custom hardware.&lt;/p&gt;
&lt;p&gt;Microsoft, an early partner with Facebook on another important AI initiative, &lt;a href=&quot;http://onnx.ai/&quot;&gt;ONNX&lt;/a&gt;, is also furthering its commitment to &lt;a href=&quot;https://azure.microsoft.com/en-us/blog/world-class-pytorch-support-on-azure/&quot;&gt;providing first-class support for PyTorch across its suite of machine learning offerings&lt;/a&gt;. Azure Machine Learning service now allows developers to seamlessly move from training PyTorch models on a local machine to scaling out on the Azure cloud. For data science experimentation, Microsoft is offering preconfigured Data Science Virtual Machines (DSVM) that are preinstalled with PyTorch. For developers looking to start exploring PyTorch without having to install software and set up a local machine, Azure Notebooks provides a free, cloud-hosted Jupyter Notebooks solution set up with PyTorch tutorials. Finally, Visual Studio Code’s Tools for AI extension provides tight integration of Azure ML and PyTorch APIs for streamlined PyTorch code development and training.&lt;/p&gt;
&lt;p&gt;In addition to software and cloud service providers, technology partners — including &lt;a href=&quot;https://community.arm.com/tools/b/blog/posts/facebook-arm-machine-learning-beyond-the-perfect-selfie&quot;&gt;ARM&lt;/a&gt;, &lt;a href=&quot;https://developer.ibm.com/blogs/2018/10/01/announcing-pytorch-1-support-in-fabric-for-deep-learning/&quot;&gt;IBM&lt;/a&gt;, &lt;a href=&quot;https://ai.intel.com/investing-in-the-pytorch-developer-community/&quot;&gt;Intel&lt;/a&gt;, &lt;a href=&quot;https://news.developer.nvidia.com/pytorch-1-0-accelerated-on-nvidia-gpus/&quot;&gt;NVIDIA&lt;/a&gt;, and &lt;a href=&quot;https://developer.qualcomm.com/blog/snapdragon-supports-pytorch-10-ai-research-and-production-same-framework&quot;&gt;Qualcomm&lt;/a&gt; — are adding support for PyTorch 1.0 through direct optimizations, kernel library integration, and support for additional tools such as compilers and inference runtimes. This extra support ensures that PyTorch developers can run models across a broad array of hardware, optimized for training and inference, for both data center and edge devices.&lt;/p&gt;
&lt;h2&gt;Educating future AI developers&lt;/h2&gt;
&lt;p&gt;We’ve already seen a variety of education providers using the existing PyTorch framework to teach deep learning in online programs and university courses. The framework’s approachability and deep integration into Python have made it easier for students to understand and experiment with various deep learning concepts. With the evolution of PyTorch 1.0, we’re thrilled that more partners will be further focusing their curricula around it.&lt;/p&gt;
&lt;p&gt;Udacity is partnering with Facebook to &lt;a href=&quot;https://blog.udacity.com/2018/10/introducing-the-pytorch-scholarship-challenge-from-facebook.html&quot;&gt;give developers access to a free Intro to Deep Learning course&lt;/a&gt;, which is taught entirely on PyTorch. In addition, Facebook will sponsor 300 students who have successfully completed this intermediate-level course to continue their education in Udacity’s Deep Learning Nanodegree program, which has been revamped to run on PyTorch 1.0.&lt;/p&gt;
&lt;p&gt;Fast.ai, which offers free online courses for introductory and advanced deep learning and machine learning using PyTorch, is &lt;a href=&quot;http://www.fast.ai/2018/10/02/fastai-ai/&quot;&gt;announcing the first release of fastai, an open source software library built on top of PyTorch 1.0&lt;/a&gt;. The library offers improved accuracy and speed with significantly less code, making deep learning more accessible to new and experienced developers.&lt;/p&gt;
&lt;h2&gt;Continued collaboration&lt;/h2&gt;
&lt;p&gt;We are excited to hear from the community as you begin working with PyTorch 1.0 over the coming months. We also look forward to continuing our collaboration with leaders in the deep learning ecosystem, to help more people take advantage of AI and accelerate the path from research to production.&lt;/p&gt;
&lt;p&gt;To get started, download the &lt;a href=&quot;https://pytorch.org/get-started&quot;&gt;developer preview&lt;/a&gt; of PyTorch 1.0, or experience it with one of our cloud partners. We also welcome the entire PyTorch community to join the full day of live stream talks from the core PyTorch team at Facebook, as well as from contributors and organizations in academia, industry, and more at &lt;a href=&quot;http://facebook.com/pytorch&quot;&gt;facebook.com/pytorch&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;We’d like to thank the entire PyTorch 1.0 team for its contributions to this work.&lt;/em&gt;&lt;/p&gt;

</description>
<pubDate>Tue, 02 Oct 2018 16:40:25 +0000</pubDate>
<dc:creator>jimarcey</dc:creator>
<og:type>article</og:type>
<og:title>Facebook accelerates AI development with new partners and production capabilities for PyTorch 1.0</og:title>
<og:url>https://code.fb.com/ai-research/facebook-accelerates-ai-development-with-new-partners-and-production-capabilities-for-pytorch-1-0/</og:url>
<og:description>Earlier this year, we shared a vision for making AI development faster and more interoperable. Today, during our first-ever PyTorch Developer Conference, we are announcing updates about the growing…</og:description>
<og:image>https://code.fb.com/wp-content/uploads/2018/09/PyTorch_Blog-Post_Hero.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://code.fb.com/ai-research/facebook-accelerates-ai-development-with-new-partners-and-production-capabilities-for-pytorch-1-0/</dc:identifier>
</item>
<item>
<title>Ferret – Declarative web scraping</title>
<link>https://github.com/MontFerret/ferret</link>
<guid isPermaLink="true" >https://github.com/MontFerret/ferret</guid>
<description>&lt;div class=&quot;Box-body p-6&quot;&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://travis-ci.com/MontFerret/ferret&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/13ebdef2cf9f039a31e38327efebe6f36638543b/68747470733a2f2f7472617669732d63692e636f6d2f4d6f6e744665727265742f6665727265742e7376673f6272616e63683d6d6173746572&quot; alt=&quot;Build Status&quot; data-canonical-src=&quot;https://travis-ci.com/MontFerret/ferret.svg?branch=master&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://raw.githubusercontent.com/MontFerret/ferret/master/assets/intro.jpg&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/MontFerret/ferret/master/assets/intro.jpg&quot; alt=&quot;ferret&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;What is it?&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;ferret&lt;/code&gt; is a web scraping system aiming to simplify data extraction from the web for such things like ui testing, machine learning and analytics.&lt;br/&gt;Having it's own declarative language, &lt;code&gt;ferret&lt;/code&gt; abstracts away technical details and complexity of the underlying technologies, helping to focus on the data itself.&lt;br/&gt;It's extremely portable, extensible and fast.&lt;/p&gt;
&lt;h2&gt;Show me some code&lt;/h2&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://raw.githubusercontent.com/MontFerret/ferret/master/assets/example.jpg&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/MontFerret/ferret/master/assets/example.jpg&quot; alt=&quot;example&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The following example demonstrates the use of dynamic pages.&lt;br/&gt;First of all, we load the main Google Search page, type search criteria into an input box and then click a search button.&lt;br/&gt;The click action triggers a redirect, so we wait till its end.&lt;br/&gt;Once the page gets loaded, we iterate over all elements in search results and assign output to a variable.&lt;br/&gt;The final for loop filters out empty elements that might be because of inaccurate use of selectors.&lt;/p&gt;
&lt;pre lang=&quot;aql&quot;&gt;
&lt;code&gt;LET google = DOCUMENT(&quot;https://www.google.com/&quot;, true)

INPUT(google, 'input[name=&quot;q&quot;]', &quot;ferret&quot;)
CLICK(google, 'input[name=&quot;btnK&quot;]')

WAIT_NAVIGATION(google)

LET result = (
    FOR result IN ELEMENTS(google, '.g')
       RETURN {
           title: ELEMENT(result, 'h3 &amp;gt; a'),
           description: ELEMENT(result, '.st'),
           url: ELEMENT(result, 'cite')
       }
)

RETURN (
    FOR page IN result
    FILTER page.title != NONE
    RETURN page
)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;Features&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;Declarative language&lt;/li&gt;
&lt;li&gt;Support of both static and dynamic web pages&lt;/li&gt;
&lt;li&gt;Embeddable&lt;/li&gt;
&lt;li&gt;Extensible&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Nowadays data is everything and who owns data - owns the world.&lt;br/&gt;I have worked on multiple data-driven projects where data was an essential part of a system and I realized how cumbersome writing tons of scrapers is.&lt;br/&gt;After some time looking for a tool that would let me to not write a code, but just express what data I need, decided to come up with my own solution.&lt;br/&gt;&lt;code&gt;ferret&lt;/code&gt; project is an ambitious initiative trying to bring universal platform for writing scrapers without any hassle.&lt;/p&gt;
&lt;h2&gt;Inspiration&lt;/h2&gt;
&lt;p&gt;FQL (Ferret Query Language) is heavily inspired by &lt;a href=&quot;https://www.arangodb.com/&quot; rel=&quot;nofollow&quot;&gt;AQL&lt;/a&gt; (ArangoDB Query Language).&lt;br/&gt;But due to the domain specifics, there are some differences in how things work.&lt;/p&gt;
&lt;h2&gt;WIP&lt;/h2&gt;
&lt;p&gt;Be aware, the the project is under heavy development. There is no documentation and some things may change in the final release.&lt;br/&gt;For query syntax, you may go to &lt;a href=&quot;https://docs.arangodb.com/3.3/AQL/index.html&quot; rel=&quot;nofollow&quot;&gt;ArangoDB web site&lt;/a&gt; and use AQL docs as docs for FQL - since they are identical.&lt;/p&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;h3&gt;Prerequisites&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Go &amp;gt;=1.6&lt;/li&gt;
&lt;li&gt;GoDep&lt;/li&gt;
&lt;li&gt;GNU Make&lt;/li&gt;
&lt;li&gt;Chrome or Docker (optional)&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
make build
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can use your local copy of Google Chrome / Chromium, but for ease of use it's recommended to run it inside a Docker container:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
docker pull alpeware/chrome-headless-trunk
docker run -d -p=0.0.0.0:9222:9222 --name=chrome-headless -v /tmp/chromedata/:/data alpeware/chrome-headless-trunk
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Quick start&lt;/h2&gt;
&lt;h3&gt;Browserless mode&lt;/h3&gt;
&lt;p&gt;If you want to play with &lt;code&gt;fql&lt;/code&gt; and check its syntax, you can run CLI with the following commands:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;go run ./cmd/cli/main.go
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;ferret&lt;/code&gt; will run in REPL mode.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
Welcome to Ferret REPL
Please use &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;Ctrl-D&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt; to &lt;span class=&quot;pl-c1&quot;&gt;exit&lt;/span&gt; this program.
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;%
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;LET doc = DOCUMENT(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;https://news.ycombinator.com/&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;FOR post IN ELEMENTS(doc, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;.storylink&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;RETURN post.attributes.href
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;%
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; symbol &lt;code&gt;%&lt;/code&gt; is used to start and end multi line queries. You also can use heredoc format.&lt;/p&gt;
&lt;p&gt;If you want to execute a query stored in a file, just pass a file name:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;go run ./cmd/cli/main.go ./docs/examples/hackernews.fql
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;cat ./docs/examples/hackernews.fql | go run ./cmd/cli/main.go 
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;go run ./cmd/cli/main.go &amp;lt; ./docs/examples/hackernews.fql
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3&gt;Browser mode&lt;/h3&gt;
&lt;p&gt;By default, &lt;code&gt;ferret&lt;/code&gt; loads HTML pages via http protocol, because it's faster.&lt;br/&gt;But nowadays, there are more and more websites rendered with JavaScript, and therefore, this 'old school' approach does not really work.&lt;br/&gt;For such cases, you may fetch documents using Chrome or Chromium via Chrome DevTools protocol (aka CDP).&lt;br/&gt;First, you need to make sure that you launched Chrome with &lt;code&gt;remote-debugging-port=9222&lt;/code&gt; flag.&lt;br/&gt;Second, you need to pass the address to &lt;code&gt;ferret&lt;/code&gt; CLI.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;go run ./cmd/cli/main.go --cdp http://127.0.0.1:9222
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; By default, &lt;code&gt;ferret&lt;/code&gt; will try to use this local address as a default one, so it makes sense to explicitly pass the parameter only in case of either different port number or remote address.&lt;/p&gt;
&lt;p&gt;Alternatively, you can tell CLI to launch Chrome for you.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
go run ./cmd/cli/main.go --cdp-launch
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Launch command is currently broken on MacOS.&lt;/p&gt;
&lt;p&gt;Once &lt;code&gt;ferret&lt;/code&gt; knows how to communicate with Chrome, you can use a function &lt;code&gt;DOCUMENT(url, isDynamic)&lt;/code&gt; with &lt;code&gt;true&lt;/code&gt; boolean value for dynamic pages:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
Welcome to Ferret REPL
Please use &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;exit&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt; or &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;Ctrl-D&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt; to &lt;span class=&quot;pl-c1&quot;&gt;exit&lt;/span&gt; this program.
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;%
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;LET doc = DOCUMENT(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;https://soundcloud.com/charts/top&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, true)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;WAIT_ELEMENT(doc, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;.chartTrack__details&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, 5000)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;LET tracks = ELEMENTS(doc, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;.chartTrack__details&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;FOR track IN tracks
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;    LET username = ELEMENT(track, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;.chartTrack__username&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;    LET title = ELEMENT(track, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;.chartTrack__title&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;    RETURN {
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;       artist: username.innerText,
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;        track: title.innerText
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;    }
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;%
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
Welcome to Ferret REPL
Please use &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;exit&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt; or &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;Ctrl-D&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt; to &lt;span class=&quot;pl-c1&quot;&gt;exit&lt;/span&gt; this program.
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;%
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;LET doc = DOCUMENT(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;https://github.com/&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;, true)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;LET btn = ELEMENT(doc, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;.HeaderMenu a&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;)

&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;CLICK(btn)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;WAIT_NAVIGATION(doc)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;WAIT_ELEMENT(doc, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;.IconNav&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;FOR el IN ELEMENTS(doc, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;.IconNav a&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;    RETURN TRIM(el.innerText)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;%
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Embedded mode&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;ferret&lt;/code&gt; is a very modular system and therefore, can be easily be embedded into your Go application.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-go&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-k&quot;&gt;package&lt;/span&gt; main

&lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; (
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;context&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;encoding/json&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;fmt&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;github.com/MontFerret/ferret/pkg/compiler&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;os&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
)

&lt;span class=&quot;pl-k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;pl-v&quot;&gt;Topic&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;struct&lt;/span&gt; {
        &lt;span class=&quot;pl-v&quot;&gt;Name&lt;/span&gt;        &lt;span class=&quot;pl-k&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;json:&quot;name&quot;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-v&quot;&gt;Description&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;json:&quot;description&quot;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-v&quot;&gt;Url&lt;/span&gt;         &lt;span class=&quot;pl-k&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;json:&quot;url&quot;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt;
}

&lt;span class=&quot;pl-k&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;main&lt;/span&gt;() {
        &lt;span class=&quot;pl-smi&quot;&gt;topics&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;getTopTenTrendingTopics&lt;/span&gt;()

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                fmt.&lt;span class=&quot;pl-c1&quot;&gt;Println&lt;/span&gt;(err)
                os.&lt;span class=&quot;pl-c1&quot;&gt;Exit&lt;/span&gt;(&lt;span class=&quot;pl-c1&quot;&gt;1&lt;/span&gt;)
        }

        &lt;span class=&quot;pl-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;pl-smi&quot;&gt;_&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;topic&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;range&lt;/span&gt; topics {
                fmt.&lt;span class=&quot;pl-c1&quot;&gt;Println&lt;/span&gt;(fmt.&lt;span class=&quot;pl-c1&quot;&gt;Sprintf&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;pl-c1&quot;&gt;%s&lt;/span&gt;: &lt;span class=&quot;pl-c1&quot;&gt;%s&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;, topic.&lt;span class=&quot;pl-smi&quot;&gt;Name&lt;/span&gt;, topic.&lt;span class=&quot;pl-smi&quot;&gt;Description&lt;/span&gt;, topic.&lt;span class=&quot;pl-smi&quot;&gt;Url&lt;/span&gt;))
        }
}

&lt;span class=&quot;pl-k&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;getTopTenTrendingTopics&lt;/span&gt;() ([]*&lt;span class=&quot;pl-v&quot;&gt;Topic&lt;/span&gt;, &lt;span class=&quot;pl-v&quot;&gt;error&lt;/span&gt;) {
        &lt;span class=&quot;pl-smi&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;             LET doc = DOCUMENT(&quot;https://github.com/topics&quot;)&lt;/span&gt;

&lt;span class=&quot;pl-s&quot;&gt;             FOR el IN ELEMENTS(doc, &quot;.py-4.border-bottom&quot;)&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                     LIMIT 10&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                     LET url = ELEMENT(el, &quot;a&quot;)&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                     LET name = ELEMENT(el, &quot;.f3&quot;)&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                     LET desc = ELEMENT(el, &quot;.f5&quot;)&lt;/span&gt;

&lt;span class=&quot;pl-s&quot;&gt;                     RETURN {&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                             name: TRIM(name.innerText),&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                             description: TRIM(desc.innerText),&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                             url: &quot;https://github.com&quot; + url.attributes.href&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                     }&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;     &lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt;

        &lt;span class=&quot;pl-smi&quot;&gt;comp&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; compiler.&lt;span class=&quot;pl-c1&quot;&gt;New&lt;/span&gt;()

        &lt;span class=&quot;pl-smi&quot;&gt;program&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; comp.&lt;span class=&quot;pl-c1&quot;&gt;Compile&lt;/span&gt;(query)

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;, err
        }

        &lt;span class=&quot;pl-smi&quot;&gt;out&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; program.&lt;span class=&quot;pl-c1&quot;&gt;Run&lt;/span&gt;(context.&lt;span class=&quot;pl-c1&quot;&gt;Background&lt;/span&gt;())

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;, err
        }

        &lt;span class=&quot;pl-smi&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;make&lt;/span&gt;([]*Topic, &lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;pl-c1&quot;&gt;10&lt;/span&gt;)

        err = json.&lt;span class=&quot;pl-c1&quot;&gt;Unmarshal&lt;/span&gt;(out, &amp;amp;res)

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;, err
        }

        &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; res, &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Extensibility&lt;/h2&gt;
&lt;p&gt;That said, &lt;code&gt;ferret&lt;/code&gt; is a very modular system which also allows not only embed it, but extend its standard library.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-go&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-k&quot;&gt;package&lt;/span&gt; main

&lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; (
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;context&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;encoding/json&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;fmt&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;github.com/MontFerret/ferret/pkg/compiler&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;github.com/MontFerret/ferret/pkg/runtime/core&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;github.com/MontFerret/ferret/pkg/runtime/values&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;os&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
)

&lt;span class=&quot;pl-k&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;main&lt;/span&gt;() {
        &lt;span class=&quot;pl-smi&quot;&gt;strs&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;getStrings&lt;/span&gt;()

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                fmt.&lt;span class=&quot;pl-c1&quot;&gt;Println&lt;/span&gt;(err)
                os.&lt;span class=&quot;pl-c1&quot;&gt;Exit&lt;/span&gt;(&lt;span class=&quot;pl-c1&quot;&gt;1&lt;/span&gt;)
        }

        &lt;span class=&quot;pl-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;pl-smi&quot;&gt;_&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;range&lt;/span&gt; strs {
                fmt.&lt;span class=&quot;pl-c1&quot;&gt;Println&lt;/span&gt;(str)
        }
}

&lt;span class=&quot;pl-k&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;getStrings&lt;/span&gt;() ([]&lt;span class=&quot;pl-v&quot;&gt;string&lt;/span&gt;, &lt;span class=&quot;pl-v&quot;&gt;error&lt;/span&gt;) {
        &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; function implements is a type of a function that ferret supports as a runtime function&lt;/span&gt;
        &lt;span class=&quot;pl-smi&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;func&lt;/span&gt;(ctx context.&lt;span class=&quot;pl-smi&quot;&gt;Context&lt;/span&gt;, args ...&lt;span class=&quot;pl-smi&quot;&gt;core&lt;/span&gt;.&lt;span class=&quot;pl-smi&quot;&gt;Value&lt;/span&gt;) (core.&lt;span class=&quot;pl-smi&quot;&gt;Value&lt;/span&gt;, &lt;span class=&quot;pl-k&quot;&gt;error&lt;/span&gt;) {
                &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; it's just a helper function which helps to validate a number of passed args&lt;/span&gt;
                &lt;span class=&quot;pl-smi&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; core.&lt;span class=&quot;pl-c1&quot;&gt;ValidateArgs&lt;/span&gt;(args, &lt;span class=&quot;pl-c1&quot;&gt;1&lt;/span&gt;)

                &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                        &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; it's recommended to return built-in None type, instead of nil&lt;/span&gt;
                        &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; values.&lt;span class=&quot;pl-smi&quot;&gt;None&lt;/span&gt;, err
                }

                &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; this is another helper functions allowing to do type validation&lt;/span&gt;
                err = core.&lt;span class=&quot;pl-c1&quot;&gt;ValidateType&lt;/span&gt;(args[&lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;], core.&lt;span class=&quot;pl-smi&quot;&gt;StringType&lt;/span&gt;)

                &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                        &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; values.&lt;span class=&quot;pl-smi&quot;&gt;None&lt;/span&gt;, err
                }

                &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; cast to built-in string type&lt;/span&gt;
                &lt;span class=&quot;pl-smi&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; args[&lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;].(values.&lt;span class=&quot;pl-smi&quot;&gt;String&lt;/span&gt;)

                &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; str.&lt;span class=&quot;pl-c1&quot;&gt;Concat&lt;/span&gt;(values.&lt;span class=&quot;pl-c1&quot;&gt;NewString&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;_ferret&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;)).&lt;span class=&quot;pl-c1&quot;&gt;ToUpper&lt;/span&gt;(), &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;
        }

        &lt;span class=&quot;pl-smi&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;             FOR el IN [&quot;foo&quot;, &quot;bar&quot;, &quot;qaz&quot;]&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                     // conventionally all functions are registered in upper case&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                     RETURN TRANSFORM(el)&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;     &lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt;

        &lt;span class=&quot;pl-smi&quot;&gt;comp&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; compiler.&lt;span class=&quot;pl-c1&quot;&gt;New&lt;/span&gt;()
        comp.&lt;span class=&quot;pl-c1&quot;&gt;RegisterFunction&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;transform&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;, transform)

        &lt;span class=&quot;pl-smi&quot;&gt;program&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; comp.&lt;span class=&quot;pl-c1&quot;&gt;Compile&lt;/span&gt;(query)

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;, err
        }

        &lt;span class=&quot;pl-smi&quot;&gt;out&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; program.&lt;span class=&quot;pl-c1&quot;&gt;Run&lt;/span&gt;(context.&lt;span class=&quot;pl-c1&quot;&gt;Background&lt;/span&gt;())

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;, err
        }

        &lt;span class=&quot;pl-smi&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;make&lt;/span&gt;([]&lt;span class=&quot;pl-k&quot;&gt;string&lt;/span&gt;, &lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;pl-c1&quot;&gt;3&lt;/span&gt;)

        err = json.&lt;span class=&quot;pl-c1&quot;&gt;Unmarshal&lt;/span&gt;(out, &amp;amp;res)

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;, err
        }

        &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; res, &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On top of that, you can completely turn off standard library, by passing the following option:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-go&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-smi&quot;&gt;comp&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; compiler.&lt;span class=&quot;pl-c1&quot;&gt;New&lt;/span&gt;(compiler.&lt;span class=&quot;pl-c1&quot;&gt;WithoutStdlib&lt;/span&gt;())
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And after that, you can easily provide your own implementation of functions from standard library.&lt;/p&gt;
&lt;p&gt;If you don't need a particular set of functions from standard library, you can turn off the entire &lt;code&gt;stdlib&lt;/code&gt; and register separate packages from that:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-go&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-k&quot;&gt;package&lt;/span&gt; main

&lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; (
    &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;github.com/MontFerret/ferret/pkg/compiler&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
    &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;github.com/MontFerret/ferret/pkg/stdlib/strings&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
)

&lt;span class=&quot;pl-k&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;main&lt;/span&gt;() {
    &lt;span class=&quot;pl-smi&quot;&gt;comp&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; compiler.&lt;span class=&quot;pl-c1&quot;&gt;New&lt;/span&gt;(compiler.&lt;span class=&quot;pl-c1&quot;&gt;WithoutStdlib&lt;/span&gt;())

    comp.&lt;span class=&quot;pl-c1&quot;&gt;RegisterFunctions&lt;/span&gt;(strings.&lt;span class=&quot;pl-c1&quot;&gt;NewLib&lt;/span&gt;())
}
&lt;/pre&gt;&lt;/div&gt;
&lt;/article&gt;&lt;/div&gt;
</description>
<pubDate>Tue, 02 Oct 2018 15:59:34 +0000</pubDate>
<dc:creator>ziflex</dc:creator>
<og:image>https://avatars0.githubusercontent.com/u/39228646?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>MontFerret/ferret</og:title>
<og:url>https://github.com/MontFerret/ferret</og:url>
<og:description>Declarative web scraping. Contribute to MontFerret/ferret development by creating an account on GitHub.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/MontFerret/ferret</dc:identifier>
</item>
<item>
<title>Should you learn C to “learn how the computer works”?</title>
<link>https://words.steveklabnik.com/should-you-learn-c-to-learn-how-the-computer-works</link>
<guid isPermaLink="true" >https://words.steveklabnik.com/should-you-learn-c-to-learn-how-the-computer-works</guid>
<description>&lt;time datetime=&quot;2018-10-02&quot; class=&quot;article_time&quot;&gt;October 2, 2018&lt;/time&gt;&lt;p&gt;I’ve often seen people suggest that you should learn C in order to learn how computers work. Is this a good idea? Is this accurate? I’m going to start with my conclusion right upfront, just to be crystal clear about what I’m saying here:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;C is not “how the computer works.”&lt;/li&gt;
&lt;li&gt;I don’t think most people mean this phrase literally, so that is sort of irrelevant.&lt;/li&gt;
&lt;li&gt;Understanding the context means that learning C for this reason may still be a good idea for you, depending on your objectives.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;I plan on making two follow-up posts as well, exploring more implications of this idea, but this is already quite a lot. I’ll update this post with links to them when I make them.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;I’ve often seen people suggest this:&lt;/p&gt;
&lt;blockquote class=&quot;large&quot; readability=&quot;6&quot;&gt;
&lt;p&gt;By learning C, you can learn how computers work.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I think that this idea is not inherently wrong, but does come with some caveats. As long as you keep those caveats in mind, I think this can be a viable strategy for learning new and important things. However, I rarely see people discuss this slogan in detail, so I’m writing this post so that I can provide that context that I believe is sorely needed. If you’re thinking about learning C for this reason, this post is written for you. I hope it’ll assist you as you learn.&lt;/p&gt;
&lt;blockquote class=&quot;large&quot; readability=&quot;11&quot;&gt;
&lt;p&gt;Before we truly begin, I’d like to say one more thing: if you want to learn C, then learn C! Learning things is great. Learning C was quite important to my understanding of computing and my career. Learning C and about its place in programming language history will make you a better programmer. You don’t need a justification. Learn stuff for the sake of learning it. This post is intended to be a guide to your quest for understanding, not a suggestion that you should or should not learn C.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;First of all, let’s talk about who is generally recommended this idea. If you’re trying to “learn how computers work,” then it stands to reason that you don’t currently understand that. Which programmers don’t understand how computers work? I’ve mostly seen this sentiment come from people who primarily program in dynamically typed, “scripting” languages, like Ruby, Python, or JavaScript. They “don’t know how computers work” because these languages operate inside of a virtual machine, and therefore, the semantics of the virtual machine are what actually matters. After all, the whole idea of a virtual machine is to provide portability. The goal is to only require knowledge of what’s portable, rather than rely on the details of the hardware that the VM is running on.&lt;/p&gt;
&lt;p&gt;There’s just one problem with this: C &lt;em&gt;also&lt;/em&gt; operates inside of a virtual machine.&lt;/p&gt;
&lt;h2 id=&quot;the-c-abstract-machine_2&quot;&gt;&lt;a class=&quot;head_anchor&quot; href=&quot;https://words.steveklabnik.com/should-you-learn-c-to-learn-how-the-computer-works#the-c-abstract-machine_2&quot;&gt; &lt;/a&gt;The C abstract machine&lt;/h2&gt;
&lt;p&gt;From the &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/WG14/www/docs/n1256.pdf&quot;&gt;C99 spec&lt;/a&gt;, Section 5.1.2.3, “Program Execution”:&lt;/p&gt;
&lt;blockquote class=&quot;large&quot; readability=&quot;6&quot;&gt;
&lt;p&gt;The semantic descriptions in this International Standard describe the behavior of an abstract machine in which issues of optimization are irrelevant.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In my opinion, this is the most important concept to understand when learning C. C does not “describe how the computer works,” it describes how the “C abstract machine” works. Everything else of importance flows from this concept and its implications.&lt;/p&gt;
&lt;blockquote class=&quot;large&quot; readability=&quot;12.539682539683&quot;&gt;
&lt;p&gt;A further note: I’ve chosen C99 here, which is not the latest C standard. Why? Well, &lt;a href=&quot;https://stackoverflow.com/questions/146381/visual-studio-support-for-new-c-c-standards&quot;&gt;MSVC has an …interesting amount of C support&lt;/a&gt;, and I’m a Windows user these days. Yes, you can run &lt;code class=&quot;prettyprint&quot;&gt;clang&lt;/code&gt; and &lt;code class=&quot;prettyprint&quot;&gt;gcc&lt;/code&gt; on Windows. There is not a ton of difference between C89, C99, and C11 with regards to what we’re talking about in these posts. At some point you have to pick. The version I’ve linked here includes some amendments to the initial spec.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You may have heard another slogan when talking about C: “C is portable assembler.” If you think about this slogan for a minute, you’ll also find that if it’s true, C cannot be how the computer works: there are many kinds of different computers, with different architectures. If C is like a version of assembly language that works on multiple computers with multiple architectures, then it cannot function exactly how each of those computers work simultaneously. It &lt;em&gt;must&lt;/em&gt; hide details, or else it wouldn’t be portable!&lt;/p&gt;
&lt;p&gt;That said, I think this fact is sort of irrelevant, because I don’t think people mean the phrase “C is how the computer works” literally. Before we can talk about that, let’s talk about the C abstract machine, and why many people don’t seem to understand this aspect of the C language.&lt;/p&gt;
&lt;h2 id=&quot;aside-why-do-people-get-this-wrong_2&quot;&gt;&lt;a class=&quot;head_anchor&quot; href=&quot;https://words.steveklabnik.com/should-you-learn-c-to-learn-how-the-computer-works#aside-why-do-people-get-this-wrong_2&quot;&gt; &lt;/a&gt;Aside: why do people get this wrong?&lt;/h2&gt;
&lt;p&gt;I can only relate my own experience, though I think it generalizes to many others.&lt;/p&gt;
&lt;p&gt;I learned GW-BASIC, then C, then C++, then Java. I had heard about Java before I started writing it in roughly 1999, four years after it was introduced. Java’s marketing at the time was very anti-C++, and it focused on the JVM as a platform, and how the machine model was what differentiated it from C++, and therefore C. Sun Microsystems no longer exists, but a &lt;a href=&quot;https://tech-insider.org/java/research/1996/0123.html&quot;&gt;mirror of the press release&lt;/a&gt; has this to say:&lt;/p&gt;
&lt;blockquote class=&quot;large&quot; readability=&quot;9&quot;&gt;
&lt;p&gt;Java-based applications are platform-independent; only the Java Virtual Machine needs to be ported to each platform. It acts as an interpreter between an end user’s computer and the Java-based application. An application written in the Java environment can run anywhere, ending the need for porting applications to multiple platforms.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;“Write once, run everywhere” was the big slogan. These two sentences were how I (and many others) came to understand Java, and how it differed from C++. Java has an interpreter, the Java Virtual Machine. C++ does not have a Virtual Machine.&lt;/p&gt;
&lt;p&gt;With this huge marketing push, “virtual machine” became synonymous with “large runtime and/or interpreter” in the minds of many. Languages without this feature were too tied to the particular computer, and required porting between platforms, because they are not truly platform independent. Java’s very reason to exist was to change this aspect of writing applications in C++.&lt;/p&gt;
&lt;blockquote class=&quot;large&quot; readability=&quot;10&quot;&gt;
&lt;p&gt;“Runtime”, “virtual machine”, and “abstract machine” are different words for the same fundamental thing. But they’ve since gained different connotations, due to non-essential variance in different implementations of these ideas.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I personally believe that this marketing, in 1995, is why programmers still misunderstand C’s nature today.&lt;/p&gt;
&lt;p&gt;So is this claim false? Why would Sun Microsystems spend millions and millions of dollars promoting a lie? If C is also based on an abstract machine that offers portability between platforms, why did Java need to exist? I think this is key to understanding what people &lt;em&gt;really&lt;/em&gt; mean when they say “C is how the computer works.”&lt;/p&gt;
&lt;h2 id=&quot;what-do-people-actually-mean_2&quot;&gt;&lt;a class=&quot;head_anchor&quot; href=&quot;https://words.steveklabnik.com/should-you-learn-c-to-learn-how-the-computer-works#what-do-people-actually-mean_2&quot;&gt; &lt;/a&gt;What do people actually mean?&lt;/h2&gt;
&lt;p&gt;Even though C operates in the context of a virtual machine, it still is significantly different than something like Java. Sun was not lying. In order to understand why, you have to understand C’s history.&lt;/p&gt;
&lt;p&gt;An operating system was written in assembly language for a computer called the “PDP-7” in 1969 at Bell Labs. In 1970, it was christened UNIX. As time went on, Bell Labs bought more and newer computers; including the PDP-11.&lt;/p&gt;
&lt;p&gt;When it came time to port Unix to the PDP-11, they considered using a higher-level language, which was a pretty radical idea at the time. Imagine that I said to you “I’m going to write an OS in Java” today, you’d probably laugh, even though &lt;a href=&quot;https://en.wikipedia.org/wiki/JavaOS&quot;&gt;it is possible&lt;/a&gt;. The situation (in my understanding, I wasn’t alive then) was pretty analogous. They considered a language called B, but it didn’t support some of the features that the PDP-11 had, and so they created a successor, naming it “C”, since C was the next letter in the alphabet.&lt;/p&gt;
&lt;blockquote class=&quot;large&quot; readability=&quot;6&quot;&gt;
&lt;p&gt;There was no “A”; B was a successor to BCPL, the “Basic Combined Programming Language.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In 1972, on a PDP-11, they wrote the first C compiler, and simultaneously re-wrote UNIX in C. Initially, portability wasn’t the actual goal, but C did resonate with a lot of people, and C compilers were ported to other systems.&lt;/p&gt;
&lt;p&gt;In 1978, the first edition of “The C Programming Language,” a book on C, was published. Affectionately known as “K&amp;amp;R,” after its authors, the book was very much not a specification, but provided enough of a description of the language that others attempted to write C compilers. This would later be called “K&amp;amp;R C.”&lt;/p&gt;
&lt;p&gt;As UNIX spread, so did C, and both were ported to many computers. In the 70s and 80s, the ports grew and grew. In the same way that C was created because B couldn’t support all of the features of the PDP-11, many compilers had extensions to the language. Since there was only K&amp;amp;R, and not a spec, as long as they were close enough, that was considered acceptable. By 1983, the lack of any sort of standardization was causing issues, and so a group was created at ANSI to produce a spec. C89 was published in 1989, and is sometimes called “ANSI C.”&lt;/p&gt;
&lt;p&gt;As such, the C specification was attempting to unify these diverse implementations, on diverse hardware. And so the C abstract machine is sort of the minimal possible specification that would allow the same code to run the same on all platforms. Implementations of C were compiled, not interpreted, and so there was no interpreter, so there was no “VM” in that 1995 sense. However, C programs are written against this abstract, non-existent machine, which is then translated into assembly that is specific to the actual computer that the program is running on. You could not rely on some specific details in order to write portable C code. This makes writing portable C very tricky, as you may have made a platform-specific assumption when writing the initial version of your code.&lt;/p&gt;
&lt;p&gt;This is best illustrated with an example. One of the fundamental data types in C is a &lt;code class=&quot;prettyprint&quot;&gt;char&lt;/code&gt;, named after “character.” However, the C abstract machine does not define how many bits a &lt;code class=&quot;prettyprint&quot;&gt;char&lt;/code&gt; is. Well, it defines it, but not with a number; it defines it as &lt;code class=&quot;prettyprint&quot;&gt;CHAR_BIT&lt;/code&gt; big, which is a constant. Section 5.2.4.2.1 of the spec:&lt;/p&gt;
&lt;blockquote class=&quot;large&quot; readability=&quot;8&quot;&gt;
&lt;p&gt;The values given below shall be replaced by constant expressions suitable or use in &lt;code class=&quot;prettyprint&quot;&gt;#if&lt;/code&gt; preprocessing directives. … Their implementation-defined values shall be equal or greater in magnitude (absolute value) to those shown, with the same sign.&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;prettyprint&quot;&gt;CHAR_BIT&lt;/code&gt;: &lt;code class=&quot;prettyprint&quot;&gt;8&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So in other words, you know that a &lt;code class=&quot;prettyprint&quot;&gt;char&lt;/code&gt; must be at least 8 bits in size, but implementations are allowed to be larger. In order to properly code against the “C abstract machine”, you must use &lt;code class=&quot;prettyprint&quot;&gt;CHAR_BIT&lt;/code&gt; instead of &lt;code class=&quot;prettyprint&quot;&gt;8&lt;/code&gt; as the size when doing &lt;code class=&quot;prettyprint&quot;&gt;char&lt;/code&gt;-by-&lt;code class=&quot;prettyprint&quot;&gt;char&lt;/code&gt; processing. But this isn’t some sort of interpreter feature, in the way that we think of virtual machines; it’s a property of how the compiler turns your source code into machine code.&lt;/p&gt;
&lt;blockquote class=&quot;large&quot; readability=&quot;0.75&quot;&gt;
&lt;p&gt;Yes, &lt;a href=&quot;https://stackoverflow.com/questions/2098149/what-platforms-have-something-other-than-8-bit-char&quot;&gt;there are systems where &lt;code class=&quot;prettyprint&quot;&gt;CHAR_BIT&lt;/code&gt; isn’t &lt;code class=&quot;prettyprint&quot;&gt;8&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So this “abstract machine”, while still technically being the same idea as the Java VM, is more of a compile-time construct to guide compilers in the task of emitting assembly code than some sort of runtime check or property. The equivalent type in Java is &lt;code class=&quot;prettyprint&quot;&gt;byte&lt;/code&gt;, which is always 8 bits, and it’s up to the implementation of the JVM to decide how to make that happen on platforms where a byte is larger. (I am not sure if the JVM runs on any of those platforms, but that’s how it would work.) The C abstract machine was created to be a minimal papering over of various hardware, not to be some sort of platform created from whole cloth that’s written in software that your code targets.&lt;/p&gt;
&lt;p&gt;So while Sun is technically incorrect, in practice, they mean something different than what they’re literally saying, and what they &lt;em&gt;mean&lt;/em&gt; is accurate. It’s the same with “learn C to learn how computers work.”&lt;/p&gt;
&lt;h2 id=&quot;learn-c-to-learn-emmoreem-about-how-computers_2&quot;&gt;&lt;a class=&quot;head_anchor&quot; href=&quot;https://words.steveklabnik.com/should-you-learn-c-to-learn-how-the-computer-works#learn-c-to-learn-emmoreem-about-how-computers_2&quot;&gt; &lt;/a&gt;Learn C to learn &lt;em&gt;more&lt;/em&gt; about how computers work&lt;/h2&gt;
&lt;p&gt;What &lt;em&gt;do&lt;/em&gt; people actually mean? In the context of “should a Rubyist learn C to learn about how computers work”, this desire to drop “down to the metal,” as it were, is an interest in understanding not only their program, and how it works inside the VM, but to understand how the combo of their program + their VM operates in the context of the machine itself.&lt;/p&gt;
&lt;p&gt;Learning C &lt;em&gt;will&lt;/em&gt; expose you to more of these kinds of details, because the abstract machine maps so much more closely to hardware, as well as abstractions provided by operating systems. C is very different than these sorts of languages, and so learning C can teach you a lot.&lt;/p&gt;
&lt;p&gt;But it’s also important to remember that C is fundamentally an &lt;em&gt;abstraction&lt;/em&gt; of hardware, and abstractions are leaky. Don’t conflate what C does or how it operates with the machine itself. If you do, you’re bound to run afoul of these differences, which can cause problems. Most learning resources for C, especially today, as hardware becomes more and more homogeneous, will promote the idea that this is how the computer works. So it can be hard, as a learner, to know what’s going on under the hood, and what’s an abstraction provided by C.&lt;/p&gt;
&lt;p&gt;We haven’t even touched on other factors in this discussion, like that due to C’s tremendous popularity, hardware has become more homogeneous because it tends towards being similar to the semantics of C’s abstract machine. If your architecture deviates too much from C’s semantics, C programs may run much more slowly than others, and C programs are often how the speed of hardware is tested. This post is long enough…&lt;/p&gt;
&lt;p&gt;For this reason, I think a more accurate version of this statement would be “By learning C, you can learn &lt;em&gt;more&lt;/em&gt; about how computers work.” I do think that a rough familiarity with C can be useful to many programmers, and will serve them well even if they don’t write any C themselves. Learning more about C can also give you insight into the history of how our field has developed.&lt;/p&gt;
&lt;p&gt;There are other ways to learn this stuff as well; C is not &lt;em&gt;inherently&lt;/em&gt; the way to learn these topics, but it is a good option. My next two posts will explore some of the implications of this intersection between portability, the C abstract machine, and how people think about C programs.&lt;/p&gt;
&lt;p&gt;There’s so many things to learn in computing. I wish you well on your journey.&lt;/p&gt;


&lt;p&gt;869&lt;/p&gt;
&lt;p&gt;Kudos&lt;/p&gt;


&lt;p&gt;869&lt;/p&gt;
&lt;p&gt;Kudos&lt;/p&gt;
</description>
<pubDate>Tue, 02 Oct 2018 15:56:58 +0000</pubDate>
<dc:creator>steveklabnik</dc:creator>
<og:title>Should you learn C to &quot;learn how the computer works&quot;? • Steve Klabnik</og:title>
<og:type>article</og:type>
<og:description>I’ve often seen people suggest that you should learn C in order to learn how computers work. Is this a good idea? Is this accurate? I’m going to start with my conclusion right upfront, just to be crystal clear about what I’m saying here: C is not... | Steve Klabnik | “The most violent element in society is ignorance.” - Emma Goldman</og:description>
<og:image>[]</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://words.steveklabnik.com/should-you-learn-c-to-learn-how-the-computer-works</dc:identifier>
</item>
<item>
<title>Tesla delivered 83,500 vehicles in the third quarter, more than expected</title>
<link>https://www.cnbc.com/2018/10/02/tesla-third-quarter-auto-production.html</link>
<guid isPermaLink="true" >https://www.cnbc.com/2018/10/02/tesla-third-quarter-auto-production.html</guid>
<description>&lt;div class=&quot;group&quot; itemprop=&quot;articleBody&quot;&gt;
&lt;p&gt;Tesla delivered 83,500 vehicles during the third quarter, beating Wall Street analysts' expectations for deliveries.&lt;/p&gt;
&lt;p&gt;But investors are still concerned about the company's profitability and were disappointed it didn't release more detailed data on its production costs and sale prices, analysts said.&lt;/p&gt;
&lt;p&gt;Tesla's shares fell 1.3 percent in midmorning trading despite beating Wall Street estimates for 80,500 deliveries during the quarter, according to data compiled by FactSet.&lt;/p&gt;

&lt;p&gt;The company produced 80,142 total vehicles: 26,903 Model S and X vehicles combined, and 53,239 Model 3 sedans.&lt;/p&gt;
&lt;p&gt;Its overall deliveries, which included 55,840 of its Model 3 sedans, were comparable to 80 percent of all of its deliveries for 2017, the company said Tuesday. Model 3 deliveries were slightly above consensus estimates of 55,600, according to FactSet. Analysts had lowered their prior estimates over the last week or so, making it easier for Tesla to beat Wall Street expectations.&lt;/p&gt;
&lt;p&gt;&quot;With production stabilized, delivery and outbound vehicle logistics were our main challenges&quot; during the third quarter, the company said in a statement. &quot;We made many improvements to these processes throughout the quarter, and plan to make further improvements in [the fourth quarter] so that we can scale successfully.&quot;&lt;/p&gt;
&lt;/div&gt;&lt;div class=&quot;group&quot; itemprop=&quot;articleBody&quot;&gt;
&lt;p&gt;Tesla said it was able to &quot;significantly increase&quot; Model S and X deliveries during the quarter, &quot;notwithstanding the headwinds we have been facing from the ongoing trade tensions between the US and China.&quot;&lt;/p&gt;
&lt;p&gt;&quot;The production and delivery numbers were a positive surprise for sure,&quot; said CFRA analyst Garrett Nelson. &quot;They actually delivered into their guidance. So it seems like they have really improved operationally during the quarter, based on these results.&quot;&lt;/p&gt;
&lt;p&gt;Investors are disappointed because Tesla didn't provide details on average sale prices or vehicle costs, he said. Investors have long been concerned about Tesla profit margins, especially the Model 3. Nelson said some of the company's good news came out ahead of the report and was already priced into the stock.&lt;/p&gt;
&lt;p&gt;The mix of vehicles — comprised in large part of more expensive versions of the Model 3 sedans — suggests that Tesla could be turning a profit on all of its cars, Oppenheimer analyst Colin Rusch said in a research note published Tuesday. But investors were hoping to see more detailed data on its manufacturing costs and cash flow, especially since the automaker said it plans to speed up construction of its factory in Shanghai.&lt;/p&gt;
&lt;p&gt;The company said it is accelerating construction of the Shanghai factory to try to minimize the impact of the tariffs, which have increased the tax rate on Teslas sold in China to 40 percent, compared with 15 percent for all other imported cars, the company said.&lt;/p&gt;
&lt;p&gt;&quot;Taking ocean transport costs and import tariffs into account, Tesla is now operating at a 55% to 60% cost disadvantage compared to the exact same car locally produced in China,&quot; the company said. &quot;This makes for a challenging competitive environment, given that China is by far the largest market for electric vehicles.&quot;&lt;/p&gt;
&lt;p&gt;Tesla said other disadvantages in China include a lack of cash incentives available to local automakers.&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;inline_quotes&quot; data-gdsid=&quot;74213&quot; data-inline-quote-symbol=&quot;TSLA&quot; href=&quot;https://www.cnbc.com/quotes/?symbol=TSLA&quot;&gt;Tesla&lt;/a&gt; previously set a goal of producing between 50,000 and 55,000 Model 3 sedans during the quarter. Heading into the report, &lt;a href=&quot;https://www.cnbc.com/2018/09/30/elon-musk-tells-tesla-to-ignore-distractions-hints-at-profitability.html&quot;&gt;expectations were that the company had exceeded that goal&lt;/a&gt;. The Model 3 is Tesla's midsize electric sedan, and the car that is meant to turn Tesla into a mass manufacturer of electric vehicles.&lt;/p&gt;
&lt;p&gt;CEO &lt;a href=&quot;https://www.cnbc.com/elon-musk/&quot;&gt;Elon Musk&lt;/a&gt; has repeatedly said he expects the company to be profitable for the third quarter. Tesla has had only two profitable quarters since it went public in 2010.&lt;/p&gt;
&lt;p&gt;Musk recently reached a settlement with the U.S. Securities and Exchange Commission over charges of fraud resulting from comments he made about taking Tesla private. Under &lt;a href=&quot;https://www.cnbc.com/2018/09/29/sec-settles-charges-with-teslas-elon-musk-will-remain-as-ceo.html&quot;&gt;the terms of the settlement&lt;/a&gt;, Musk and Tesla will pay fines of $20 million each, and Musk will step down for at least three years as chairman.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;PALO ALTO, Calif., Oct. 02, 2018 (GLOBE NEWSWIRE) -- In Q3, we produced 80,142 vehicles, 50% more than our prior all-time high in Q2, including:&lt;br/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;53,239 Model 3 vehicles, which was in line with our guidance and almost double the volume of Q2. During Q3, we transitioned Model 3 production from entirely rear wheel drive at the beginning of the quarter to almost entirely dual motor during the last few weeks of the quarter. This added significant complexity, but we successfully executed this transition and ultimately produced more dual motor than rear wheel drive cars in Q3. In the last week of the quarter, we produced over 5,300 Model 3 vehicles, almost all of which were dual motor, meaning that we achieved a production rate of more than 10,000 drive units per week.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;26,903 Model S and X vehicles, which was slightly higher than Q2 and in line with our full-year guidance.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Q3 deliveries totaled 83,500 vehicles: 55,840 Model 3, 14,470 Model S, and 13,190 Model X. To put this in perspective, in just Q3, we delivered more than 80% of the vehicles that we delivered in all of 2017, and we delivered about twice as many Model 3s as we did in all previous quarters combined.&lt;/p&gt;
&lt;p&gt;Our Q3 Model 3 deliveries were limited to higher-priced variants, cash/loan transactions, and North American customers only. There remain significant opportunities to grow the addressable market for Model 3 by introducing leasing, standard battery and other lower-priced variants of the car, and by starting international deliveries.&lt;/p&gt;
&lt;p&gt;Demand for Model S and X remains high. In Q3, we were able to significantly increase Model S and X deliveries notwithstanding the headwinds we have been facing from the ongoing trade tensions between the US and China. Those trade tensions have resulted in an import tariff rate of 40% on Tesla vehicles versus 15% for other imported cars in China.&lt;/p&gt;
&lt;p&gt;In addition, Tesla continues to lack access to cash incentives available to locally produced electric vehicles in China that are typically around 15% of MSRP or more. Taking ocean transport costs and import tariffs into account, Tesla is now operating at a 55% to 60% cost disadvantage compared to the exact same car locally produced in China. This makes for a challenging competitive environment, given that China is by far the largest market for electric vehicles. To address this issue, we are accelerating construction of our Shanghai factory, which we expect to be a capital efficient and rapid buildout, using many lessons learned from the Model 3 ramp in North America.&lt;/p&gt;
&lt;p&gt;With production stabilized, delivery and outbound vehicle logistics were our main challenges during Q3. We made many improvements to these processes throughout the quarter, and plan to make further improvements in Q4 so that we can scale successfully. As part of this effort, we plan to continue to expand direct deliveries to customers at their home or office, a service we launched in Q3 to improve customer convenience.&lt;/p&gt;
&lt;p&gt;8,048 Model 3 vehicles and 3,776 Model S and X vehicles were in transit to customers at the end of Q3, and will be delivered in early Q4. Our overall target of 100,000 Model S and X deliveries in 2018 remains unchanged.&lt;/p&gt;
&lt;p&gt;Our net income and cash flow results will be announced along with the rest of our financial performance when we announce Q3 earnings.&lt;/p&gt;
&lt;p&gt;We want to thank the entire Tesla team for executing so well during this challenging ramp up in deliveries. We also want to thank all of our customers who volunteered to help us with deliveries, and our new customers who are showing their faith in Tesla by purchasing our products in such large numbers. It was beyond inspiring to see the contributions made by the whole Tesla community.&lt;/p&gt;
&lt;p&gt;***************&lt;/p&gt;
&lt;p&gt;Our delivery count should be viewed as slightly conservative, as we only count a car as delivered if it is transferred to the customer and all paperwork is correct. Final numbers could vary by up to 0.5%. Tesla vehicle deliveries represent only one measure of the company's financial performance and should not be relied on as an indicator of quarterly financial results, which depend on a variety of factors, including the cost of sales, foreign exchange movements and mix of directly leased vehicles.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Forward-Looking Statements&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Certain statements herein, including statements regarding future production and delivery of Model S and Model X, expanding direct vehicle deliveries, growing the addressable market for Model 3, and accelerating the buildout of the Shanghai factory in a capital efficient and rapid manner, are &quot;forward-looking statements&quot; that are subject to risks and uncertainties. These forward-looking statements are based on management's current expectations. Various important factors could cause actual results to differ materially, including the risks identified in our SEC filings. Tesla disclaims any obligation to update this information.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;Correction: Tesla's third-quarter deliveries were more than 80 percent of the vehicles it delivered in all of 2017. An earlier version mischaracterized the percentage.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;WATCH:&lt;/strong&gt;&lt;a href=&quot;https://www.cnbc.com/video/2018/08/30/tesla-elon-musk-take-private-sec-investigation-autos.html&quot;&gt;Tesla and Elon Musk's wild August — in nine minutes&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;&lt;div class=&quot;group&quot; itemprop=&quot;articleBody&quot;/&gt;</description>
<pubDate>Tue, 02 Oct 2018 12:38:28 +0000</pubDate>
<dc:creator>jeffpalmer</dc:creator>
<og:type>article</og:type>
<og:url>https://www.cnbc.com/2018/10/02/tesla-third-quarter-auto-production.html</og:url>
<og:image>https://fm.cnbc.com/applications/cnbc.com/resources/img/editorial/2018/07/02/105306577-1530537945343rts1ub47.1910x1000.jpg</og:image>
<og:title>Tesla beats Wall Street estimates for overall vehicle deliveries</og:title>
<og:description>Its overall third-quarter deliveries beat estimates and were more than 80 percent of the vehicles delivered in all of 2017. But investors are still concerned about the company's profitability.</og:description>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cnbc.com/2018/10/02/tesla-third-quarter-auto-production.html</dc:identifier>
</item>
<item>
<title>Amazon increases minimum wage for all U.S. workers to $15 an hour</title>
<link>https://techcrunch.com/2018/10/02/amazon-minimum-wage/</link>
<guid isPermaLink="true" >https://techcrunch.com/2018/10/02/amazon-minimum-wage/</guid>
<description>&lt;p&gt;&lt;a class=&quot;crunchbase-link&quot; href=&quot;https://crunchbase.com/organization/amazon&quot; target=&quot;_blank&quot; data-type=&quot;organization&quot; data-entity=&quot;amazon&quot;&gt;Amazon&lt;/a&gt; just &lt;a href=&quot;https://www.businesswire.com/news/home/20181002005317/en/&quot;&gt;announced&lt;/a&gt; that it will be raising its minimum wage for all U.S. workers to $15 an hour, effective November 1.&lt;/p&gt;
&lt;p&gt;The policy will cover employees at Amazon subsidiaries, including Whole Foods, and well as seasonal and temporary employees. Amazon says that in total, this will cover 250,000 employees, plus 100,000 seasonal employees.&lt;/p&gt;
&lt;p&gt;This comes as Amazon is &lt;a href=&quot;https://techcrunch.com/2018/08/23/what-is-this-weird-twitter-army-of-amazon-drones-cheerfully-defending-warehouse-work/&quot;&gt;facing increasing scrutiny over how its workers are treated and paid&lt;/a&gt;. Senator Bernie Sanders, for example, &lt;a href=&quot;https://techcrunch.com/2018/09/05/bernie-sanders-intros-stop-bad-employers-by-zeroing-out-subsidies-bezos-bill/&quot;&gt;recently introduced legislation&lt;/a&gt; to end what he calls “corporate welfare” — and it’s &lt;a href=&quot;https://techcrunch.com/2018/08/28/bernie-sanders-problem-with-amazon/&quot;&gt;pretty clear who he had in mind&lt;/a&gt;, since the bill was titled Stop Bad Employers by Zeroing Out Subsidies (BEZOS).&lt;/p&gt;
&lt;p&gt;Meanwhile, &lt;a href=&quot;https://techcrunch.com/2018/09/06/whole-foods-workers-seek-to-unionize-says-amazon-is-exploiting-our-dedication/&quot;&gt;a group of Whole Foods workers have been pushing to unionize&lt;/a&gt;, with demands that included a $15 minimum wage.&lt;/p&gt;
&lt;p&gt;“We listened to our critics, thought hard about what we wanted to do, and decided we want to lead,” said Amazon CEO &lt;a class=&quot;crunchbase-link&quot; href=&quot;https://crunchbase.com/person/jeff-bezos&quot; target=&quot;_blank&quot; data-type=&quot;person&quot; data-entity=&quot;jeff-bezos&quot;&gt;Jeff Bezos&lt;/a&gt; in the announcement. “We’re excited about this change and encourage our competitors and other large employers to join us.”&lt;/p&gt;
&lt;p&gt;Amazon says its existing benefits will not change, except that its RSU stock grant program will be phased out for hourly fulfillment and customer service employees and replaced with a direct stock purchase plan, supposedly because those employees “prefer the predictability and immediacy of cash to RSUs.”&lt;/p&gt;
&lt;p&gt;In addition, the company &lt;a href=&quot;https://blog.aboutamazon.com/working-at-amazon/amazon-raises-minimum-wage-to-15-for-all-us-employees&quot;&gt;also pledges&lt;/a&gt; its public policy team will lobby for an increase to the federal minimum wage from $7.25 — it doesn’t identify a specific wage that it’s targeting, but instead says, “We believe $7.25 is too low. We would look to Congress to decide the parameters of a new, higher federal minimum wage.”&lt;/p&gt;
&lt;div class=&quot;embed breakout&quot; readability=&quot;7.8786885245902&quot;&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-width=&quot;550&quot; data-dnt=&quot;true&quot; readability=&quot;9.6295081967213&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;What Mr. Bezos has done today is not only enormously important for Amazon’s hundreds of thousands of employees, it could well be a shot heard around the world. I urge corporate leaders around the country to follow Mr. Bezos' lead. &lt;a href=&quot;https://t.co/06wIAHunPq&quot;&gt;https://t.co/06wIAHunPq&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;— Bernie Sanders (@SenSanders) &lt;a href=&quot;https://twitter.com/SenSanders/status/1047136187964694530?ref_src=twsrc%5Etfw&quot;&gt;October 2, 2018&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;

</description>
<pubDate>Tue, 02 Oct 2018 11:55:06 +0000</pubDate>
<dc:creator>doppp</dc:creator>
<og:title>Amazon increases minimum wage for all U.S. workers to $15 an hour</og:title>
<og:description>Amazon just announced that it will be raising its minimum wage for all U.S. workers to $15 an hour, effective November 1. The policy will cover employees at Amazon subsidiaries, including Whole Foods, and well as seasonal and temporary employees. Amazon says that in total, this will cover 250,000 e…</og:description>
<og:image>https://techcrunch.com/wp-content/uploads/2015/11/71595aa0e1e741bda40efd74e29e13c6.jpg?w=617</og:image>
<og:url>http://social.techcrunch.com/2018/10/02/amazon-minimum-wage/</og:url>
<og:type>article</og:type>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://techcrunch.com/2018/10/02/amazon-minimum-wage/</dc:identifier>
</item>
</channel>
</rss>