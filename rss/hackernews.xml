<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>All Things Sales: Mini-lessons for startup founders</title>
<link>https://a16z.com/2018/09/02/sales-startups-technical-founders/</link>
<guid isPermaLink="true" >https://a16z.com/2018/09/02/sales-startups-technical-founders/</guid>
<description>&lt;div class=&quot;entry-content__primary&quot;&gt;
&lt;div class=&quot;entry-content__post-body wp-content&quot;&gt;
&lt;p&gt;As a former CEO and software engineer (Citrix, XenSource, VERITAS, etc.), board member of GitHub (recently acquired by Microsoft), and lecturer in management at the Stanford Graduate School of Busines, a16z general partner Peter Levine is constantly asked “&lt;a href=&quot;https://a16z.com/2017/05/26/hiring-sales-why-what/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Why sales?&lt;/a&gt;” by entrepreneurs and technical founders. He himself used to hold the “engineer-centric” view that if you build a great product, customers will come. But the fact is, all world-class companies &lt;em&gt;must&lt;/em&gt; have a strong sales force. So — how do they get there? How does a technical founder begin to build a top tier sales motion?&lt;/p&gt;
&lt;p&gt;In &lt;a href=&quot;https://www.youtube.com/playlist?list=PLM4u6XbiXf5rtyzi7g-5ObKubmZFiTIlD&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;this series&lt;/a&gt; of snack-sized videos — which you can watch all together, or mix-and-match for your particular questions and needs — Levine distills the fundamentals that every founder should know about sales. The 16 lessons in this “mini-MOOC” offer everything from definitions to concrete guidance for the following:&lt;/p&gt;
&lt;h5&gt;1. All Things Sales! 16 Mini-Lessons for Startup Founders&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/jmJgb4GqIXw?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;start=2&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h5&gt;2. Understanding and Defining Sales Channels&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/Hc0x5yEHI1Q?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;start=1&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h5&gt;3. Engaging Sales: How Much to Spend on Marketing vs. Sales?&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/509zS9TZJuY?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;start=1&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h5&gt;4. Segmenting Markets for Go-to-Market&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/Ohjmf3eLNpk?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;start=2&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h5&gt;5. Why Build a Sales Organization?&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/MZWFYgyxc8k?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h5&gt;6. Building a Sales Org: Who, When, How&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/gUshO-xLvow?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h5&gt;7. Setting the Sales Number&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/Iasx35CjokE?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h5&gt;8. A Short Coda on (Sales) Quotas&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/dAXh5-oR-e4?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h5&gt;9. Mapping Go-to-Market to Customers: ‘The Coverage Matrix’&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/-_WyIeync8E?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h5&gt;10. Managing a Sales Org: Forecasting&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/f3m6AgokArk?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h5&gt;11. Managing a Sales Org: Revenue composition&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/QV0UdOrqrt4?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h5&gt;12. How to Compensate Sales Reps&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/tppma_89xYU?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;start=17&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h5&gt;13. Simplifying Sales Compensation&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/1NO7CzPugVs?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;start=14&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h5&gt;14. Sales Force Productivity: How do you know?&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/Pykl6LswyUs?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;start=2&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h5&gt;15. Predicting Your Pipeline&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/dTe6xi60r6s?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h5&gt;16. Conclusion: Takeaways on sales for technical founders&lt;/h5&gt;
&lt;p&gt;&lt;span class=&quot;embed-youtube&quot;&gt;&lt;iframe class=&quot;youtube-player&quot; type=&quot;text/html&quot; width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/5vhqKNhnkfA?version=3&amp;amp;rel=1&amp;amp;fs=1&amp;amp;autohide=2&amp;amp;showsearch=0&amp;amp;showinfo=1&amp;amp;iv_load_policy=1&amp;amp;wmode=transparent&quot; allowfullscreen=&quot;true&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Acknowledgements: With thanks to &lt;a href=&quot;https://www.gsb.stanford.edu/faculty-research/faculty/mark-leslie&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Mark Leslie&lt;/a&gt; and &lt;a href=&quot;https://www.gsb.stanford.edu/faculty-research/faculty/james-m-lattin&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Jim Lattin&lt;/a&gt; for their contributions to the concepts — including the “sales learning curve” (see this &lt;a href=&quot;https://hbr.org/2006/07/the-sales-learning-curve&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;2006 Harvard Business Review article&lt;/a&gt; by Leslie and Charles Holloway) — in this series. Many of these concepts are developed and discussed in an &lt;a href=&quot;http://explorecourses.stanford.edu/search?q=STRAMGT%2B351&amp;amp;academicYear=20182019&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;MBA elective course&lt;/a&gt; we teach at the Stanford Graduate School of Business, “Building and Managing Professional Sales Organizations”. &lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;entry-content__post-date&quot;&gt;September 2, 2018&lt;/div&gt;

&lt;/div&gt;
&lt;aside class=&quot;entry-sidebar sidebar sidebar--single&quot; role=&quot;complementary&quot;&gt;
&lt;/aside&gt;</description>
<pubDate>Mon, 03 Sep 2018 00:53:22 +0000</pubDate>
<dc:creator>dpeck</dc:creator>
<og:type>article</og:type>
<og:title>All Things Sales! 16 Mini-Lessons for Startup Founders</og:title>
<og:url>https://a16z.com/2018/09/02/sales-startups-technical-founders/</og:url>
<og:description>As a former CEO and software engineer (Citrix, XenSource, VERITAS, etc.), board member of GitHub (recently acquired by Microsoft), and lecturer in management at the Stanford Graduate School of Busi…</og:description>
<og:image>http://img.youtube.com/vi/jmJgb4GqIXw/0.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://a16z.com/2018/09/02/sales-startups-technical-founders/</dc:identifier>
</item>
<item>
<title>Japan starts space elevator experiments</title>
<link>https://www.electronicsweekly.com/news/business/japan-starts-space-elevator-experiments-2018-08/</link>
<guid isPermaLink="true" >https://www.electronicsweekly.com/news/business/japan-starts-space-elevator-experiments-2018-08/</guid>
<description>&lt;a rel=&quot;image&quot; href=&quot;https://static.electronicsweekly.com/wp-content/uploads/2018/08/26143535/1BFA4310-2200-4994-B9C7-221A0B397A99.jpeg&quot; target=&quot;_blank&quot;&gt;&lt;img class=&quot;alignleft size-medium wp-image-535293&quot; src=&quot;https://static.electronicsweekly.com/wp-content/uploads/2018/08/26143535/1BFA4310-2200-4994-B9C7-221A0B397A99-300x200.jpeg&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;200&quot;/&gt;&lt;/a&gt;&lt;p class=&quot;txt&quot;&gt;Shizuoka University and contractor Obayashi aim to launch two small (10 sq cm) satellites connected by a 10m steel cable from the International Space Station.&lt;/p&gt;
&lt;p class=&quot;txt&quot;&gt;Containers on the cable will move forward and back recorded by a camera.&lt;/p&gt;


&lt;p class=&quot;txt&quot;&gt; Obayashi envisages a space elevator using six oval-shaped cars, each measuring 18m x 7.2m holding 30 people, connected by a cable from a platform on the sea to a satellite at 36,000 kilometers above Earth.&lt;/p&gt;
&lt;p class=&quot;txt&quot;&gt;The  elevator would be powered by an electric motor pulley.&lt;/p&gt;
&lt;p class=&quot;txt&quot;&gt;The cars would travel at  up to 200kph and arrive at the space station eight days after departure from Earth.&lt;/p&gt;
&lt;p class=&quot;txt&quot;&gt;The total length of a cable to be used for the vehicle will be 96,000 kilometers, and the total cost is estimated at $9 billion.&lt;/p&gt;
&lt;p class=&quot;txt&quot;&gt;The cost of transport is expected to be about one-hundredth of that of the space shuttle.&lt;/p&gt;
&lt;p&gt;Carbon nanotube is the most likely material to be used for the cables.&lt;/p&gt;


</description>
<pubDate>Sun, 02 Sep 2018 19:14:34 +0000</pubDate>
<dc:creator>Futurebot</dc:creator>
<og:type>article</og:type>
<og:title>Japan starts space elevator experiments</og:title>
<og:description>Arthur C Clarke’s concept of a space elevator could start to be realised by experiments beginning next month by a Japanese university and construction comp</og:description>
<og:url>https://www.electronicsweekly.com/news/business/japan-starts-space-elevator-experiments-2018-08/</og:url>
<og:image>https://static.electronicsweekly.com/wp-content/uploads/2018/08/26143535/1BFA4310-2200-4994-B9C7-221A0B397A99.jpeg</og:image>
<dc:language>en-GB</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.electronicsweekly.com/news/business/japan-starts-space-elevator-experiments-2018-08/</dc:identifier>
</item>
<item>
<title>Why Read the Classics? (1986)</title>
<link>https://www.nybooks.com/articles/1986/10/09/why-read-the-classics/</link>
<guid isPermaLink="true" >https://www.nybooks.com/articles/1986/10/09/why-read-the-classics/</guid>
<description>&lt;p&gt;Let us begin with a few suggested definitions.&lt;/p&gt;&lt;p&gt;1) The classics are the books of which we usually hear people say: “I am rereading…” and never “I am reading….”&lt;/p&gt;
&lt;p&gt;This at least happens among those who consider themselves “very well read.” It does not hold good for young people at the age when they first encounter the world, and the classics as a part of that world.&lt;/p&gt;
&lt;p&gt;The reiterative prefix before the verb “read” may be a small hypocrisy on the part of people ashamed to admit they have not read a famous book. To reassure them, we need only observe that, however vast any person’s basic reading may be, there still remain an enormous number of fundamental works that he has not read.&lt;/p&gt;
&lt;p&gt;Hands up, anyone who has read the whole of Herodotus and the whole of Thucydides! And Saint-Simon? And Cardinal de Retz? But even the great nineteenth-century cycles of novels are more often talked about than read. In France they begin to read Balzac in school, and judging by the number of copies in circulation, one may suppose that they go on reading him even after that, but if a Gallup poll were taken in Italy, I’m afraid that Balzac would come in practically last. Dickens fans in Italy form a tiny elite; as soon as its members meet, they begin to chatter about characters and episodes as if they were discussing people and things of their own acquaintance. Years ago, while teaching in America, Michel Butor got fed up with being asked about Emile Zola, whom he had never read, so he made up his mind to read the entire &lt;em&gt;Rougon-Macquart&lt;/em&gt; cycle. He found it was completely different from what he had thought: a fabulous mythological and cosmogonical family tree, which he went on to describe in a wonderful essay.&lt;/p&gt;
&lt;p class=&quot;initial&quot;&gt;In other words, to read a great book for the first time in one’s maturity is an extraordinary pleasure, different from (though one cannot say greater or lesser than) the pleasure of having read it in one’s youth. Youth brings to reading, as to any other experience, a particular flavor and a particular sense of importance, whereas in maturity one appreciates (or ought to appreciate) many more details and levels and meanings. We may therefore attempt the next definition:&lt;/p&gt;
&lt;p&gt;2) We use the word “classics” for those books that are treasured by those who have read and loved them; but they are treasured no less by those who have the luck to read them for the first time in the best conditions to enjoy them.&lt;/p&gt;
&lt;p&gt;In fact, reading in youth can be rather unfruitful, owing to impatience, distraction, inexperience with the product’s “instructions for use,” and inexperience in life itself. Books read then can be (possibly at one and the same time) formative, in the sense that they give a form to future experiences, providing models, terms of comparison, schemes for classification, scales of value, exemplars of beauty—all things that continue to operate even if the book read in one’s youth is almost or totally forgotten. If we reread the book at a mature age we are likely to rediscover these constants, which by this time are part of our inner mechanisms, but whose origins we have long forgotten. A literary work can succeed in making us forget it as such, but it leaves its seed in us. The definition we can give is therefore this:&lt;/p&gt;
&lt;p&gt;3) The classics are books that exert a peculiar influence, both when they refuse to be eradicated from the mind and when they conceal themselves in the folds of memory, camouflaging themselves as the collective or individual unconscious.&lt;/p&gt;
&lt;p&gt;There should therefore be a time in adult life devoted to revisiting the most important books of our youth. Even if the books have remained the same (though they do change, in the light of an altered historical perspective), we have most certainly changed, and our encounter will be an entirely new thing.&lt;/p&gt;
&lt;p&gt;Hence, whether we use the verb “read” or the verb “reread” is of little importance. Indeed, we may say:&lt;/p&gt;
&lt;p&gt;4) Every rereading of a classic is as much a voyage of discovery as the first reading.&lt;/p&gt;
&lt;p&gt;5) Every reading of a classic is in fact a rereading.&lt;/p&gt;
&lt;p&gt;Definition 4 may be considered a corollary of this next one:&lt;/p&gt;
&lt;p&gt;6) A classic is a book that has never finished saying what it has to say.&lt;/p&gt;
&lt;p&gt;Whereas definition 5 depends on a more specific formula, such as this:&lt;/p&gt;
&lt;p&gt;7) The classics are the books that come down to us bearing upon them the traces of readings previous to ours, and bringing in their wake the traces they themselves have left on the culture or cultures they have passed through (or, more simply, on language and customs).&lt;/p&gt;
&lt;p class=&quot;initial&quot;&gt;All this is true both of the ancient and of the modern classics. If I read the &lt;em&gt;Odyssey&lt;/em&gt; I read Homer’s text, but I cannot forget all that the adventures of Ulysses have come to mean in the course of the centuries, and I cannot help wondering if these meanings were implicit in the text, or whether they are incrustations or distortions or expansions. When reading Kafka, I cannot avoid approving or rejecting the legitimacy of the adjective “Kafkaesque,” which one is likely to hear every quarter of an hour, applied indiscriminately. If I read Turgenev’s &lt;em&gt;Fathers and Sons&lt;/em&gt; or Dostoevsky’s &lt;em&gt;The Possessed&lt;/em&gt;, I cannot help thinking how these characters have continued to be reincarnated right down to our own day.&lt;/p&gt;

&lt;p&gt;The reading of a classic ought to give us a surprise or two vis-à-vis the notion that we had of it. For this reason I can never sufficiently highly recommend the direct reading of the text itself, leaving aside the critical biography, commentaries, and interpretations as much as possible. Schools and universities ought to help us to understand that no book that talks &lt;em&gt;about&lt;/em&gt; a book says more than the book in question, but instead they do their level best to make us think the opposite. There is a very widespread topsyturviness of values whereby the introduction, critical apparatus, and bibliography are used as a smoke screen to hide what the text has to say, and, indeed, can say only if left to speak for itself without intermediaries who claim to know more than the text does. We may conclude that:&lt;/p&gt;
&lt;p&gt;8) A classic does not necessarily teach us anything we did not know before. In a classic we sometimes discover something we have always known (or thought we knew), but without knowing that this author said it first, or at least is associated with it in a special way. And this, too, is a surprise that gives a lot of pleasure, such as we always gain from the discovery of an origin, a relationship, an affinity. From all this we may derive a definition of this type:&lt;/p&gt;
&lt;p&gt;9) The classics are books that we find all the more new, fresh, and unexpected upon reading, the more we thought we knew them from hearing them talked about.&lt;/p&gt;
&lt;p&gt;Naturally, this only happens when a classic really works as such—that is, when it establishes a personal rapport with the reader. If the spark doesn’t come, that’s a pity; but we do not read the classics out of duty or respect, but only out of love. Except at school. And school should enable you to know, either well or badly, a certain number of classics among which—or in reference to which—you can then choose &lt;em&gt;your&lt;/em&gt; classics. School is obliged to give you the instruments needed to make a choice, but the choices that count are those that occur outside and after school.&lt;/p&gt;
&lt;p&gt;It is only by reading without bias that you might possibly come across the book that becomes &lt;em&gt;your&lt;/em&gt; book. I know an excellent art historian, an extraordinarily well-read man, who out of all the books there are has focused his special love on the &lt;em&gt;Pickwick Papers&lt;/em&gt;; at every opportunity he comes up with some quip from Dickens’s book, and connects each and every event in life with some Pickwickian episode. Little by little he himself, and true philosophy, and the universe, have taken on the shape and form of the &lt;em&gt;Pickwick Papers&lt;/em&gt; by a process of complete identification. In this way we arrive at a very lofty and demanding notion of what a classic is:&lt;/p&gt;
&lt;p&gt;10) We use the word “classic” of a book that takes the form of an equivalent to the universe, on a level with the ancient talismans. With this definition we are approaching the idea of the “total book,” as Mallarmé conceived of it.&lt;/p&gt;
&lt;p&gt;But a classic can establish an equally strong rapport in terms of opposition and antithesis. Everything that Jean-Jacques Rousseau thinks and does is very dear to my heart, yet everything fills me with an irrepressible desire to contradict him, to criticize him, to quarrel with him. It is a question of personal antipathy on a temperamental level, on account of which I ought to have no choice but not to read him; and yet I cannot help numbering him among &lt;em&gt;my&lt;/em&gt; authors. I will therefore say:&lt;/p&gt;
&lt;p&gt;11) &lt;em&gt;Your&lt;/em&gt; classic author is the one you cannot feel indifferent to, who helps you to define yourself in relation to him, even in dispute with him.&lt;/p&gt;
&lt;p&gt;I think I have no need to justify myself for using the word “classic” without making distinctions about age, style, or authority. What distinguishes the classic, in the argument I am making, may be only an echo effect that holds good both for an ancient work and for a modern one that has already achieved its place in a cultural continuum. We might say:&lt;/p&gt;
&lt;p&gt;12) A classic is a book that comes before other classics; but anyone who has read the others first, and then reads this one, instantly recognizes its place in the family tree.&lt;/p&gt;
&lt;p class=&quot;initial&quot;&gt;At this point I can no longer put off the vital problem of how to relate the reading of the classics to the reading of all the other books that are anything but classics. It is a problem connected with such questions as, Why read the classics rather than concentrate on books that enable us to understand our own times more deeply? or, Where shall we find the time and peace of mind to read the classics, overwhelmed as we are by the avalanche of current events?&lt;/p&gt;
&lt;p&gt;We can, of course, imagine some blessed soul who devotes his reading time exclusively to Lucretius, Lucian, Montaigne, Erasmus, Quevedo, Marlowe, the &lt;em&gt;Discourse on Method, Wilhelm Meister&lt;/em&gt;, Coleridge, Ruskin, Proust, and Valéry, with a few forays in the direction of Murasaki or the Icelandic sagas. And all this without having to write reviews of the latest publications, or papers to compete for a university chair, or articles for magazines on tight deadlines. To keep up such a diet without any contamination, this blessed soul would have to abstain from reading the newspapers, and never be tempted by the latest novel or sociological investigation. But we have to see how far such rigor would be either justified or profitable. The latest news may well be banal or mortifying, but it nonetheless remains a point at which to stand and look both backward and forward. To be able to read the classics you have to know “from where” you are reading them; otherwise both the book and the reader will be lost in a timeless cloud. This, then, is the reason why the greatest “yield” from reading the classics will be obtained by someone who knows how to alternate them with the proper dose of current affairs. And this does not necessarily imply a state of imperturbable inner calm. It can also be the fruit of nervous impatience, of a huffing-and-puffing discontent of mind.&lt;/p&gt;
&lt;p&gt;Maybe the ideal thing would be to hearken to current events as we do to the din outside the window that informs us about traffic jams and sudden changes in the weather, while we listen to the voice of the classics sounding clear and articulate inside the room. But it is already a lot for most people if the presence of the classics is perceived as a distant rumble far outside a room that is swamped by the trivia of the moment, as by a television at full blast. Let us therefore add:&lt;/p&gt;
&lt;p&gt;13) A classic is something that tends to relegate the concerns of the moment to the status of background noise, but at the same time this background noise is something we cannot do without.&lt;/p&gt;
&lt;p&gt;14) A classic is something that persists as a background noise even when the most incompatible momentary concerns are in control of the situation.&lt;/p&gt;
&lt;p class=&quot;initial&quot;&gt;There remains the fact that reading the classics appears to clash with our rhythm of life, which no longer affords long periods of time or the spaciousness of humanistic leisure. It also contradicts the eclecticism of our culture, which would never be capable of compiling a catalog of things classical such as would suit our needs.&lt;/p&gt;
&lt;p&gt;These latter conditions were fully realized in the case of Leopardi, given his solitary life in his father’s house (his “&lt;em&gt;paterno ostello&lt;/em&gt;“), his cult of Greek and Latin antiquity, and the formidable library put at his disposal by his father, Monaldo. To which we may add the entire body of Italian literature and of French literature, with the exception of novels and the “latest thing out” in general, all of which were at least swept off into the sidelines, there to comfort the leisure of his sister Paolina (“&lt;em&gt;your&lt;/em&gt; Stendhal,” he wrote her once). Even with his intense interest in science and history, he was often willing to rely on texts that were not entirely up-to-date, taking the habits of birds from Buffon, the mummies of Frederik Ruysch from Fontanelle, the voyage of Columbus from Robertson.&lt;/p&gt;
&lt;p&gt;In these days a classical education like the young Leopardi’s is unthinkable; above all, Count Monaldo’s library has multiplied explosively. The ranks of the old titles have been decimated, while new ones have proliferated in all modern literatures and cultures. There is nothing for it but for all of us to invent our own ideal libraries of classics. I would say that such a library ought to be composed half of books we have read and that have really counted for us, and half of books we propose to read and presume will come to count—leaving a section of empty shelves for surprises and occasional discoveries.&lt;/p&gt;
&lt;p class=&quot;initial&quot;&gt;I realize that Leopardi is the only name I have cited from Italian literature—a result of the explosion of the library. Now I ought to rewrite the whole article to make it perfectly clear that the classics help us to understand who we are and where we stand, a purpose for which it is indispensable to compare Italians with foreigners and foreigners with Italians.&lt;/p&gt;
&lt;p&gt;Then I ought to rewrite it yet again lest anyone believe that the classics ought to be read because they “serve any purpose” whatever. The only reason one can possibly adduce is that to read the classics is better than not to read the classics.&lt;/p&gt;
&lt;p&gt;And if anyone objects that it is not worth taking so much trouble, then I will quote Cioran (who is not yet a classic, but will become one):&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;While they were preparing the hemlock, Socrates was learning a tune on the flute. “What good will it do you,” they asked, “to know this tune before you die?”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;—&lt;em&gt;translated by Patrick Creagh&lt;br/&gt;English translation copyright © 1986 Harcourt Brace Jovanovich, Inc.&lt;br/&gt;&lt;/em&gt;&lt;/p&gt;

</description>
<pubDate>Sun, 02 Sep 2018 17:57:24 +0000</pubDate>
<dc:creator>constantinum</dc:creator>
<og:type>article</og:type>
<og:title>Why Read the Classics?</og:title>
<og:description>A classic does not necessarily teach us anything we did not know before. In a classic we sometimes discover something we have always known (or thought we knew), but without knowing that this author said it first, or at least is associated with it in a special way. And this, too, is a surprise that gives a lot of pleasure, such as we always gain from the discovery of an origin, a relationship, an affinity. From all this we may derive a definition of this type: The classics are books that we find all the more new, fresh, and unexpected upon reading, the more we thought we knew them from hearing them talked about.</og:description>
<og:url>https://www.nybooks.com/articles/1986/10/09/why-read-the-classics/</og:url>
<og:image>https://cdn.nybooks.com/wp-content/uploads/1974/05/italo-calvino_1974-05-30.gif</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.nybooks.com/articles/1986/10/09/why-read-the-classics/</dc:identifier>
</item>
<item>
<title>An Introduction to Modern CMake</title>
<link>https://cliutils.gitlab.io/modern-cmake/</link>
<guid isPermaLink="true" >https://cliutils.gitlab.io/modern-cmake/</guid>
<description>&lt;p&gt;People love to hate build systems. Just watch the talks from CppCon17 to see examples of developers making the state of build systems the brunt of jokes. This raises the question: Why? Certainly there are no shortage of problems when building. But I think that, in 2018, we have a very good solution to quite a few of those problems. It's CMake. Not CMake 2.8 though; that was released before C++11 even existed! Nor the horrible examples out there for CMake (even those posted on KitWare's own tutorials list). I'm talking about Modern CMake. CMake 3.1+, maybe even CMake 3.12+! It's clean, powerful, and elegant, so you can spend most of your time coding, not adding lines to an unreadable, unmaintainable Make (Or CMake 2) file. And CMake 3.11+ is supposed to be significantly faster, as well!&lt;/p&gt;
&lt;div class=&quot;alert alert-warning hints-alert&quot; readability=&quot;6.121359223301&quot;&gt;

&lt;div class=&quot;hints-container&quot; readability=&quot;7.5339805825243&quot;&gt;
&lt;p&gt;This book is meant to be a living document. You can raise an issue or put in a merge request on &lt;a href=&quot;https://gitlab.com/CLIUtils/modern-cmake&quot; target=&quot;_blank&quot;&gt;GitLab&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In short, here are the most likely questions in your mind if you are considering Modern CMake:&lt;/p&gt;
&lt;h2 id=&quot;why-do-i-need-a-good-build-system&quot;&gt;Why do I need a good build system?&lt;/h2&gt;
&lt;p&gt;Do any of the following apply to you?&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;You want to avoid hard-coding paths&lt;/li&gt;
&lt;li&gt;You need to build a package on more than one computer&lt;/li&gt;
&lt;li&gt;You want to use CI (continuous integration)&lt;/li&gt;
&lt;li&gt;You need to support different OSs (maybe even just flavors of Unix)&lt;/li&gt;
&lt;li&gt;You want to support multiple compilers&lt;/li&gt;
&lt;li&gt;You want to use an IDE, but maybe not all of the time&lt;/li&gt;
&lt;li&gt;You want to describe how your program is structured logically, not flags and commands&lt;/li&gt;
&lt;li&gt;You want to use a library&lt;/li&gt;
&lt;li&gt;You want to use tools, like Clang-Tidy, to help you code&lt;/li&gt;
&lt;li&gt;You want to use a debugger&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;If so, you'll benefit from a CMake-like build system.&lt;/p&gt;
&lt;h2 id=&quot;why-must-the-answer-be-cmake&quot;&gt;Why must the answer be CMake?&lt;/h2&gt;
&lt;p&gt;Build systems is a hot topic. Of course there are many options. But even a really good one, or one that re-uses a familiar syntax, can't come close to CMake. Why? Support. Every IDE supports CMake (or CMake supports that IDE). More packages use CMake than any other system. So, if you use a library that is designed to be included in your code, you have a choice: Make your own build system, or use one of of the provided ones, and that will almost always include CMake. And that will quickly be the common denominator if you include multiple projects. And, if you need a library that's preinstalled, the chances of it having a find CMake script or config CMake script are excellent.&lt;/p&gt;
&lt;h2 id=&quot;why-use-a-modern-cmake&quot;&gt;Why use a Modern CMake?&lt;/h2&gt;
&lt;p&gt;Around CMake 2.6-2.8, CMake started taking over. It was in most of the package managers for Linux OS's, and was being used in lots of packages.&lt;/p&gt;
&lt;p&gt;Then Python 3 came out.&lt;/p&gt;
&lt;p&gt;I know, this should have nothing whatsoever to do with CMake.&lt;/p&gt;
&lt;p&gt;But it had a 3. And it followed 2. And it was a hard, ugly, transition that is still ongoing in some places, even today.&lt;/p&gt;
&lt;p&gt;I believe that CMake 3 had the bad luck to follow Python 3.&lt;sup&gt;&lt;a href=&quot;https://cliutils.gitlab.io/modern-cmake/#fn_1&quot; id=&quot;reffn_1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; Even though every version of CMake is insanely backward compatible, the 3 series was treated as if it was something new. And so, you'll find OS's like CentOS7 with GCC 4.8, with almost-complete C++14 support, and CMake 2.8, which came out before C++11.&lt;/p&gt;
&lt;p&gt;You really should &lt;em&gt;at least&lt;/em&gt; use a version of CMake that came out after your compiler, since it needs to know compiler flags, etc, for that version. And, since CMake will dumb itself down to the minimum required version in your CMake file, installing a new CMake, even system wide, is pretty safe. You should &lt;em&gt;at least&lt;/em&gt; install it locally. It's easy (1-2 lines in many cases), and you'll find that 5 minutes of work will save you hundreds of lines and hours of CMakeLists.txt writing, and will be much easier to maintain in the long run.&lt;/p&gt;
&lt;p&gt;This book tries to solve the problem of the poor examples and best practices that you'll find proliferating the web.&lt;/p&gt;
&lt;h2 id=&quot;other-sources&quot;&gt;Other sources&lt;/h2&gt;
&lt;p&gt;There are some other places to find good information on the web. Here are some of them:&lt;/p&gt;
&lt;blockquote id=&quot;fn_1&quot; readability=&quot;10.897832817337&quot;&gt;
&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt;. CMake 3.0 also removed several long deprecated features from very old versions of CMake and make one very tiny backwards incompatible change to syntax related to square brackets, so this is not entirely fair; there might be some very, very old CMake files that would stop working with 3. I've never seen one, though. &lt;a href=&quot;https://cliutils.gitlab.io/modern-cmake/#reffn_1&quot; title=&quot;Jump back to footnote [1] in the text.&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Sun, 02 Sep 2018 17:12:44 +0000</pubDate>
<dc:creator>uyoakaoma</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://cliutils.gitlab.io/modern-cmake/</dc:identifier>
</item>
<item>
<title>PaperTTY – Python module to render a TTY on e-ink</title>
<link>https://github.com/joukos/PaperTTY</link>
<guid isPermaLink="true" >https://github.com/joukos/PaperTTY</guid>
<description>&lt;div class=&quot;Box-body p-6&quot;&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/joukos/PaperTTY/blob/master/pics/logo.jpg&quot;&gt;&lt;img src=&quot;https://github.com/joukos/PaperTTY/raw/master/pics/logo.jpg&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is an experimental command-line driven Python module to render the contents of a Linux virtual terminal (&lt;code&gt;/dev/tty[1-63]&lt;/code&gt;) &lt;strong&gt;or standard input&lt;/strong&gt; onto a &lt;a href=&quot;https://www.waveshare.com/&quot; rel=&quot;nofollow&quot;&gt;Waveshare&lt;/a&gt; e-Paper display. See &lt;a href=&quot;https://github.com/joukos/PaperTTY/blob/master/drivers/README.md&quot;&gt;list of supported displays&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: Testing has been minimal and I probably forgot something, so 'caveat utilitor'.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Note: I am also not affiliated with Waveshare in any way.&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;Some features&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;Designed to be used with a &lt;strong&gt;Raspberry Pi&lt;/strong&gt; and Raspbian.&lt;/li&gt;
&lt;li&gt;It should enable you to run interactive console programs (&lt;code&gt;vim&lt;/code&gt;, &lt;code&gt;tmux&lt;/code&gt;, &lt;code&gt;irssi&lt;/code&gt;, &lt;code&gt;nethack&lt;/code&gt; ...) and display whatever you want easily with scripts.&lt;/li&gt;
&lt;li&gt;Especially with a small font, it is fast enough for interactive use but could be improved to be &lt;a href=&quot;http://benkrasnow.blogspot.com/2017/10/fast-partial-refresh-on-42-e-paper.html&quot; rel=&quot;nofollow&quot;&gt;even faster&lt;/a&gt;. Also, it's quite a bit snappier on the Raspberry Pi 3 than the Zero.&lt;/li&gt;
&lt;li&gt;Only the changed region is updated on the display, so typing is faster than full screen scrolling.&lt;/li&gt;
&lt;li&gt;The cursor is also drawn and the image updated as it moves.&lt;/li&gt;
&lt;li&gt;Flicker-free.&lt;/li&gt;
&lt;li&gt;Allows changing the font, font size, orientation and some other parameters.&lt;/li&gt;
&lt;li&gt;Supports TrueType and bitmap fonts (in PIL format).&lt;/li&gt;
&lt;li&gt;Bundled with a &lt;code&gt;systemd&lt;/code&gt; service unit to start the service early at boot and gracefully stop it.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;It isn't perfect and has only been tested with the monochrome 2.13&quot; HAT, but it &lt;em&gt;might&lt;/em&gt; work for other models too, and allows you to at least &lt;em&gt;try&lt;/em&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;em&gt;The PaperTTY code is in the public domain and you run it &lt;strong&gt;at your own risk.&lt;/strong&gt;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;The driver code (in &lt;code&gt;drivers/&lt;/code&gt;) is &lt;strong&gt;GPL 3.0&lt;/strong&gt; licensed, because it is based on Waveshare's GPL code - you still run it &lt;strong&gt;at your own risk.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Screenshots&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Collage of running various programs in &lt;code&gt;tmux&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/joukos/PaperTTY/blob/master/pics/collage.png&quot;&gt;&lt;img src=&quot;https://github.com/joukos/PaperTTY/raw/master/pics/collage.png&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Running Nethack outside in the noon sun, powered directly by a solar panel, connected to a Bluetooth keyboard&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/joukos/PaperTTY/blob/master/pics/sunlight.jpg&quot;&gt;&lt;img src=&quot;https://github.com/joukos/PaperTTY/raw/master/pics/sunlight.jpg&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Action video - terminal usage (Raspberry Pi Zero W)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Showcasing input feedback.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=mXBS4l3OvyE&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/101771e4e648475027f6bdf88e1a35b66e3c2293/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f6d584253346c334f7679452f302e6a7067&quot; alt=&quot;Youtube Video&quot; data-canonical-src=&quot;https://img.youtube.com/vi/mXBS4l3OvyE/0.jpg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Action video 2 - cacafire (Raspberry Pi 3)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The RPi3 is noticeably faster - &lt;code&gt;cacafire&lt;/code&gt; is 3x slower on the Zero. Typical terminal usage works pretty well.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=yWpT0xk8ufY&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/72e4372685ce32d15e2e026aa43ccedb1fc97ad4/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f7957705430786b387566592f302e6a7067&quot; alt=&quot;Youtube Video&quot; data-canonical-src=&quot;https://img.youtube.com/vi/yWpT0xk8ufY/0.jpg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;All of the code was written for Raspbian Stretch and Python 3.5+. These instructions assume you're going to run this on a Raspberry Pi, otherwise you're on your own.&lt;/p&gt;
&lt;p&gt;The code includes a reimplementation/refactoring of the Waveshare &lt;a href=&quot;https://github.com/soonuse/epd-library-python&quot;&gt;reference drivers&lt;/a&gt; - unlike the rest of the code which is CC0, &lt;strong&gt;the drivers have the GPL 3.0 license&lt;/strong&gt;, because that's what Waveshare used. The drivers for models that aren't in the repo have been acquired from their Wiki's demo code packages.&lt;/p&gt;
&lt;p&gt;See the &lt;a href=&quot;https://github.com/joukos/PaperTTY/blob/master/drivers&quot;&gt;driver page&lt;/a&gt; for details and the supported models.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The earlier, initial version of PaperTTY (tag: &lt;code&gt;v0.01&lt;/code&gt;) did not have instructions for using virtualenv (though it would work) - you can still run it as before using the system packages and alongside this new version. Using the virtualenv means that PIL and Pillow can also coexist on the same system.&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;Requirements&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;Enable SPI (&lt;code&gt;sudo raspi-config&lt;/code&gt;)
&lt;ul&gt;&lt;li&gt;&lt;code&gt;Interfacing Options -&amp;gt; SPI -&amp;gt; Yes&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Reboot&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h4&gt;Steps&lt;/h4&gt;
&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Clone the repo somewhere and enter the directory&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;git clone https://github.com/joukos/PaperTTY.git&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cd PaperTTY&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Install virtualenv and libopenjp2&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;sudo apt install virtualenvwrapper python3-virtualenv libopenjp2-7&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Source the wrapper to use &lt;code&gt;mkvirtualenv&lt;/code&gt; (&lt;em&gt;you may want to add this to &lt;code&gt;~/.bashrc&lt;/code&gt;&lt;/em&gt;)&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;source /usr/share/virtualenvwrapper/virtualenvwrapper.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Create the Python 3 virtualenv and install packages in &lt;code&gt;requirements.txt&lt;/code&gt;&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;mkvirtualenv -p /usr/bin/python3 -r requirements.txt papertty&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;This will create &lt;code&gt;~/.virtualenvs/papertty&lt;/code&gt; which contains the required environment&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;After creating the virtualenv, it should become active and you should see &lt;code&gt;(papertty)&lt;/code&gt; on your prompt&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Note:&lt;/strong&gt; the software needs to be run with &lt;code&gt;sudo&lt;/code&gt; in the typical case, &lt;em&gt;so you need to explicitly start the interpreter within the virtualenv - otherwise the program attempts to import system packages instead&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;You should now be able to run &lt;code&gt;sudo ~/.virtualenvs/papertty/bin/python3 ./papertty.py list&lt;/code&gt; to see the available drivers and start using the software&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Not really needed, but to (de)activate the virtualenv afterwards, run:&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;~/.virtualenvs/papertty/bin/activate&lt;/code&gt; - activate the virtualenv
&lt;ul&gt;&lt;li&gt;Or, &lt;code&gt;workon papertty&lt;/code&gt; if you have sourced &lt;code&gt;virtualenvwrapper.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;deactivate&lt;/code&gt; - deactivate the virtualenv&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h4&gt;Alternative install without virtualenv, using system packages&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;If you don't care to use the virtualenv, just install the requirements as system packages:
&lt;ul&gt;&lt;li&gt;&lt;code&gt;sudo apt install python3-rpi.gpio python3-spidev python3-pil python3-click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;And run the program directly: &lt;code&gt;sudo ./papertty.py list&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Fonts&lt;/h2&gt;
&lt;p&gt;You can use TrueType fonts or bitmap fonts, but the bitmap fonts need to be in the right format. With bitmap fonts the &lt;code&gt;--size&lt;/code&gt; option is ignored.&lt;/p&gt;
&lt;p&gt;Included as default is a very small bitmap font called &lt;a href=&quot;https://robey.lag.net/2010/01/23/tiny-monospace-font.html&quot; rel=&quot;nofollow&quot;&gt;Tom Thumb&lt;/a&gt;, it is fairly readable for its tiny size and fits 20 rows with 62 columns on the 2.13&quot;. Thanks go to Brian Swetland and Robey Pointer for their work on the font and for releasing it under &lt;a href=&quot;https://creativecommons.org/publicdomain/zero/1.0/legalcode&quot; rel=&quot;nofollow&quot;&gt;CC0&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Another included font is the &lt;a href=&quot;https://github.com/Michaelangel007/nanofont3x4&quot;&gt;nanofont&lt;/a&gt;, which is an extremely tiny (3x4 pixels) font and also released under CC0. Thanks go to the author, Michael Pohoreski. The conversion was done by generating the BMP, then transformed it with Pillow so that everything was on one line, then used &lt;a href=&quot;http://hukka.ncn.fi/?fony&quot; rel=&quot;nofollow&quot;&gt;Fony&lt;/a&gt; to save a BDF and converted that to PIL.&lt;/p&gt;
&lt;p&gt;Why would you use such a microscopic font, I hear you ask? One good reason is that some programs refuse to start unless the terminal size is big enough, and using this font will allow you to get things &lt;em&gt;theoretically&lt;/em&gt; readable and run those programs even on the smaller displays. One example being &lt;strong&gt;Dungeon Crawl Stone Soup&lt;/strong&gt; which wouldn't otherwise start on the 2.13&quot; display (&lt;em&gt;hooray!&lt;/em&gt;):&lt;/p&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/joukos/PaperTTY/blob/master/pics/dcss.jpg&quot;&gt;&lt;img src=&quot;https://github.com/joukos/PaperTTY/raw/master/pics/dcss.jpg&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Playing the game like this would be quite challenging, however...&lt;/p&gt;
&lt;p&gt;Unless you're happy with the awesome default font, find a nice &lt;em&gt;monospaced&lt;/em&gt; TrueType or bitmap font: Andale Mono (&lt;code&gt;sudo apt install ttf-mscorefonts-installer&lt;/code&gt;) is pretty great for very small sizes and on the 2.13&quot; (128x250 pixels) can fit 17 rows and 50 columns&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;You &lt;em&gt;can&lt;/em&gt; use a proportional font but the terminal will probably look horrible&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Pillow includes a utility called &lt;code&gt;pilfont.py&lt;/code&gt;, you can use this to convert a BDF/PCF font file into a &lt;code&gt;.pil&lt;/code&gt; and a &lt;code&gt;.pbm&lt;/code&gt; (I didn't have luck with some fonts - remember to use the &lt;code&gt;pilfont.py&lt;/code&gt; version that's on your Pi):&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# convert Terminus 
gunzip -c /usr/share/fonts/X11/misc/ter-u12b_unicode.pcf.gz &amp;gt; terminus-12.pcf
pilfont.py terminus-12.pcf
# you should get terminus-12.pil that you can pass with the --font option
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/joukos/PaperTTY/blob/master/pics/terminus.jpg&quot;&gt;&lt;img src=&quot;https://github.com/joukos/PaperTTY/raw/master/pics/terminus.jpg&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;All font options expect a path to the font file - the system font directories are not searched for them.&lt;/p&gt;
&lt;h2&gt;Usage&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Remember to activate the virtualenv&lt;/strong&gt;, then run &lt;code&gt;sudo ./papertty.py&lt;/code&gt; to get help.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;You'll want to &lt;code&gt;sudo&lt;/code&gt; unless you've set it up so that SPI works without and you've given read access to &lt;code&gt;/dev/vcsa*&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;To do anything, you'll need to tell the script which model you're using - in my case this would be &lt;strong&gt;&lt;code&gt;epd2in13&lt;/code&gt;&lt;/strong&gt;. Use the top-level option &lt;strong&gt;&lt;code&gt;--driver&lt;/code&gt;&lt;/strong&gt; to set the desired driver.&lt;/p&gt;
&lt;p&gt;Append &lt;code&gt;--help&lt;/code&gt; with the subcommands to get help with their parameters.&lt;/p&gt;
&lt;p&gt;You can just edit &lt;code&gt;papertty.py&lt;/code&gt; to your liking - the code is very simple and commented.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Top-level options&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Option&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Default&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--driver NAME&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Select driver to use - &lt;strong&gt;required&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;em&gt;no default&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--nopartial&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Disable partial refresh even if the display supported it&lt;/td&gt;
&lt;td&gt;disabled&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--encoding NAME&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Select encoding to use&lt;/td&gt;
&lt;td&gt;&lt;code&gt;utf-8&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The encoding settings are a bit questionable right now - encoding/decoding is done explicitly to have &lt;code&gt;ignore&lt;/code&gt; on any errors, but I think this needs some more work as it's not an entirely trivial issue. If you feel like there's a big dum-dum in the code regarding these, a PR is &lt;em&gt;very appreciated&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note 2:&lt;/strong&gt; &lt;em&gt;To get scandinavian accents to show (&lt;code&gt;ä&lt;/code&gt;,&lt;code&gt;ö&lt;/code&gt; etc.), try &lt;code&gt;--encoding cp852&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;Commands&lt;/h3&gt;
&lt;h4&gt;&lt;code&gt;list&lt;/code&gt; - List display drivers&lt;/h4&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; Example&lt;/span&gt;
sudo ./papertty.py list
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;code&gt;scrub&lt;/code&gt; - Scrub display&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;This command mostly makes sense with the partial refresh models, although you can run it with full refresh too - it's just going to take a pretty long time to run. I needed this because my own unit can't handle a full refresh so it was the only way to clear the screen properly!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;If you're left with &quot;burn-in&quot; or the display doesn't seem to work properly, this usually helps to even it out (may even need to run it twice sometimes if the display is not in a steady state).&lt;/p&gt;
&lt;p&gt;This will slowly fill the screen with bands of black, then white.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Option&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Default&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--size N&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Chunk width (pixels) to fill with (valid values: &lt;code&gt;8-32&lt;/code&gt;)&lt;/td&gt;
&lt;td&gt;&lt;code&gt;16&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; Example&lt;/span&gt;
sudo ./papertty.py --driver epd2in13 scrub
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;code&gt;stdin&lt;/code&gt; - Render standard input&lt;/h4&gt;
&lt;p&gt;Render &lt;code&gt;stdin&lt;/code&gt; on the display, simple as that. Leaves the image on the display until something else overwrites it. Very useful for showing script output or just about anything that updates irregularly.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Option&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Default&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--font FILENAME&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Path to a TrueType or PIL font to use - &lt;strong&gt;strongly recommended to use monospaced&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;tom-thumb.pil&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--size N&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Font size&lt;/td&gt;
&lt;td&gt;&lt;code&gt;8&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--width N&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fit to a particular width (characters)&lt;/td&gt;
&lt;td&gt;display width / font width&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--portrait&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Enable portrait mode&lt;/td&gt;
&lt;td&gt;disabled&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--nofold&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Disable folding (ie. don't wrap to width)&lt;/td&gt;
&lt;td&gt;disabled&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--spacing&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Set line spacing&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; Example&lt;/span&gt;
cowsay &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;Hello World&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;|&lt;/span&gt; sudo ./papertty.py --driver epd2in13 stdin --nofold
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;code&gt;terminal&lt;/code&gt; - Render a virtual terminal&lt;/h4&gt;
&lt;p&gt;The most prominent feature.&lt;/p&gt;
&lt;p&gt;This requires read permission to the virtual console device (&lt;code&gt;/dev/vcsa[1-63]&lt;/code&gt;) and optionally write permission to the associated terminal device (&lt;code&gt;/dev/tty[1-63]&lt;/code&gt;) if you want to set the TTY size via &lt;code&gt;ioctl&lt;/code&gt;s.&lt;/p&gt;
&lt;p&gt;If you're going to use &lt;code&gt;terminal&lt;/code&gt; with a display that doesn't support partial refresh, you probably want to set &lt;code&gt;--sleep&lt;/code&gt; a bit larger than the default, such as a few seconds, unless you enjoy blinking.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The process handles two signals:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;&lt;code&gt;SIGINT&lt;/code&gt;&lt;/strong&gt; - stop and clear the screen (unless &lt;code&gt;--noclear&lt;/code&gt; was given), same as pressing Ctrl-C
&lt;ul&gt;&lt;li&gt;&lt;code&gt;sudo pkill -INT -f papertty.py&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;By default, the &lt;code&gt;systemd&lt;/code&gt; service unit attempts to stop the process using SIGINT&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;SIGUSR1&lt;/code&gt;&lt;/strong&gt; - apply scrub and keep running
&lt;ul&gt;&lt;li&gt;&lt;code&gt;sudo pkill -USR1 -f papertty.py&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;See details on how all of this works further down this document.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Option&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;th&gt;Default&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--vcsa FILENAME&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Virtual console device (&lt;code&gt;/dev/vcsa[1-63]&lt;/code&gt;)&lt;/td&gt;
&lt;td&gt;&lt;code&gt;/dev/vcsa1&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--font FILENAME&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Path to a TrueType or PIL font to use - &lt;strong&gt;strongly recommended to use monospaced&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;tom-thumb.pil&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--size N&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Font size&lt;/td&gt;
&lt;td&gt;&lt;code&gt;8&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--noclear&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Leave display content on exit&lt;/td&gt;
&lt;td&gt;disabled&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--nocursor&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Don't draw cursor&lt;/td&gt;
&lt;td&gt;disabled&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--sleep&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Minimum delay between screen updates (seconds)&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0.1&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--rows&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Set TTY rows (&lt;code&gt;--cols&lt;/code&gt; required too)&lt;/td&gt;
&lt;td&gt;&lt;em&gt;no default&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--cols&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Set TTY columns (&lt;code&gt;--rows&lt;/code&gt; required too)&lt;/td&gt;
&lt;td&gt;&lt;em&gt;no default&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--portrait&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Enable portrait mode&lt;/td&gt;
&lt;td&gt;disabled&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--flipx&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Mirror X axis (experimental / buggy)&lt;/td&gt;
&lt;td&gt;disabled&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--flipy&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Mirror Y axis (experimental / buggy)&lt;/td&gt;
&lt;td&gt;disabled&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--spacing&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Set line spacing&lt;/td&gt;
&lt;td&gt;&lt;code&gt;0&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--scrub&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Apply scrub when starting&lt;/td&gt;
&lt;td&gt;disabled&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;--autofit&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Try to automatically set terminal rows/cols for the font&lt;/td&gt;
&lt;td&gt;disabled&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; Examples&lt;/span&gt;

&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; by default the first virtual terminal (/dev/vcsa1 == /dev/tty1) is displayed&lt;/span&gt;
sudo ./papertty.py --driver epd2in13 terminal

&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; set font size to 16, update every 10 seconds, set terminal rows/cols to 10x20&lt;/span&gt;
sudo ./papertty.py --driver epd2in13 terminal --size 16 --sleep 10 --rows 10 --cols 20

&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; auto-fit terminal rows/cols for the font and use a bitmap font&lt;/span&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; (fitting may not work for very small fonts in portrait mode because of terminal restrictions)&lt;/span&gt;
sudo ./papertty.py --driver epd2in13 terminal --autofit --font myfont.pil
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;How to use the terminal&lt;/h2&gt;
&lt;h4&gt;Logging in?&lt;/h4&gt;
&lt;p&gt;After you've gotten the terminal to render, you'll want to run something there.&lt;/p&gt;
&lt;p&gt;As the program mirrors the system virtual terminals, you can either attach a keyboard to the Pi and simply log in &lt;strong&gt;or&lt;/strong&gt; use the &lt;code&gt;openvt&lt;/code&gt; program to start something there without messing around with cables, if you already have SSH access.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The following commands are run over SSH.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For example, to start &lt;code&gt;htop&lt;/code&gt; for user &lt;code&gt;pi&lt;/code&gt; on &lt;code&gt;tty1&lt;/code&gt; (via &lt;code&gt;sudo&lt;/code&gt;, &lt;em&gt;twice&lt;/em&gt;):&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; &quot;as a sudoer, start sudo forcibly on VT 1 (tty1) to run 'htop' as the user 'pi'&quot;&lt;/span&gt;
sudo openvt -fc 1 -- sudo -u pi htop
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;After you exit the process, &lt;code&gt;agetty&lt;/code&gt; may go haywire though (hogging CPU). Give it a nudge to fix it:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
sudo pkill agetty
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And you should have the login prompt there again.&lt;/p&gt;
&lt;p&gt;In practice, you'll want to use &lt;strong&gt;&lt;code&gt;tmux&lt;/code&gt;&lt;/strong&gt; (or &lt;strong&gt;&lt;code&gt;screen&lt;/code&gt;&lt;/strong&gt;, if you prefer) to have the most flexible control over the terminal (these are terminal multiplexers, and if you haven't used one before, now is the time to start):&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; start a new tmux session (or just run 'tmux' with a connected keyboard)&lt;/span&gt;
sudo openvt -fc 1 -- sudo -u pi tmux
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; (see the session starting up on the display)&lt;/span&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; now, attach to the session&lt;/span&gt;
tmux attach
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Lo and behold! You should now be attached to the tiny session visible on the display.&lt;/p&gt;
&lt;p&gt;You can kill the &lt;code&gt;papertty.py&lt;/code&gt; process at any time - the stuff that runs in the TTY will be unaffected (unless they react badly to console resizing) and you can just restart the &lt;code&gt;terminal&lt;/code&gt; to get the display back and play around with the settings.&lt;/p&gt;
&lt;h4&gt;Start up at boot&lt;/h4&gt;
&lt;p&gt;A simple &lt;code&gt;systemd&lt;/code&gt; service unit file is included with the package, called &lt;code&gt;papertty.service&lt;/code&gt;. It calls &lt;code&gt;start.sh&lt;/code&gt; so that instead of editing the service file, you can edit the start script (and easily add whatever you need) without needing to run &lt;code&gt;systemctl daemon-reload&lt;/code&gt; all the time.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;You can simply put the command in the service file too, it's your choice&lt;/li&gt;
&lt;li&gt;You probably want to set the script to be owned and writable by root only: &lt;code&gt;sudo chown root:root start.sh; sudo chmod 700 start.sh&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Remember: to run the command under the virtualenv, you need to run the &lt;code&gt;python3&lt;/code&gt; command from within the virtualenv's &lt;code&gt;bin&lt;/code&gt; directory - this will ensure the environment is correct&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;To have the display turn on at boot, first &lt;strong&gt;edit&lt;/strong&gt; the command you're happy with into &lt;code&gt;start.sh&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; Remember: you probably want to set rows and cols here, because at reboot they're reset.&lt;/span&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; Also, when booting up after a power cycle the display may have some artifacts on it, so &lt;/span&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; you may want to add --scrub to get a clean display (during boot it's a bit slower than usual)&lt;/span&gt;
VENV=&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;/home/pi/.virtualenvs/papertty/bin/python3&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;pl-smi&quot;&gt;${VENV}&lt;/span&gt; papertty.py --driver epd2in13 terminal --autofit
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then make sure you have the right paths set in the service file:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
...
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt;## Change the paths below to match yours&lt;/span&gt;
WorkingDirectory=/home/pi/code/PaperTTY
ExecStart=/home/pi/code/PaperTTY/start.sh
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt;##&lt;/span&gt;
...
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then (read the unit file more carefully and) do the following steps:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
sudo cp papertty.service /etc/systemd/system
sudo systemctl daemon-reload
sudo systemctl &lt;span class=&quot;pl-c1&quot;&gt;enable&lt;/span&gt; papertty
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; To disable the service:&lt;/span&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; sudo systemctl disable papertty&lt;/span&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; sudo systemctl stop papertty&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will incorporate the service with &lt;code&gt;systemd&lt;/code&gt; and enables it. Before rebooting and trying it out, you may want to stop any other instances of the &lt;code&gt;papertty.py&lt;/code&gt; and then see if the service works:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
sudo systemctl start papertty
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; (the service should start and the terminal should appear on the display,&lt;/span&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; if you need to edit any settings, run 'systemctl daemon-reload' again after&lt;/span&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; saving the service file)&lt;/span&gt;
sudo systemctl stop papertty
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; (the service should stop and the display should be cleared, unless you used --noclear)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If the service seemed to work, try rebooting and enjoy watching the bootup. If you need to scrub the display while the service is running, you can send the &lt;code&gt;SIGUSR1&lt;/code&gt; signal to the process.&lt;/p&gt;
&lt;p&gt;If the service didn't work, check that the paths are correct and that &lt;code&gt;start.sh&lt;/code&gt; has the execute bit set.&lt;/p&gt;
&lt;hr/&gt;&lt;h2&gt;Why?&lt;/h2&gt;
&lt;p&gt;Kindles and the like have been around for a long time already, but there have been very few attempts at a general purpose e-ink display. General purpose meaning that I can use the programs I'm used to using and can display them on the e-ink display.&lt;/p&gt;
&lt;p&gt;Why would anyone want such a thing, anyway? Here are some reasons:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;First of all, their power consumption is very low, making them suitable for many embedded applications where you just need to display some information periodically&lt;/li&gt;
&lt;li&gt;They are &lt;em&gt;beautiful&lt;/em&gt; and easy on the eyes&lt;/li&gt;
&lt;li&gt;They are readable in direct sunlight with no glare to speak of - and could run indefinitely off solar too&lt;/li&gt;
&lt;li&gt;Many of us spend most of their time reading and editing mostly static text, and this is where e-ink should excel&lt;/li&gt;
&lt;li&gt;Sometimes the refresh rate does not matter at all, as long as the eventual feedback is there - you may not want a backlit, power-hungry display for something you need updated just once a day&lt;/li&gt;
&lt;li&gt;You can still read your ebooks - in Vim!&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;The problem&lt;/h2&gt;
&lt;p&gt;Aside from digital price tags and similar special markets, there &lt;em&gt;are&lt;/em&gt; some viable commercial offerings for mainstream computing on e-ink, such as the &lt;a href=&quot;https://onyxboox.com/boox_max2&quot; rel=&quot;nofollow&quot;&gt;Onyx Boox Max2&lt;/a&gt; that not only boasts a proper tablet form factor with an e-ink display, but also an HDMI input for using it as a secondary display (&lt;em&gt;squee!&lt;/em&gt;). While it seems really cool, it's quite expensive, rare and more than just a simple display unit (and those cost just as much).&lt;/p&gt;
&lt;p&gt;The display modules sold by Waveshare are exceptional in that they are very affordable (~15-90 USD), offer a wide range of sizes (1.54&quot; up to 7.5&quot;) and even have &quot;color&quot; models (black/white/red). Earlier such offerings simply weren't there and people used to hack Kindles in very complex ways to get any of the fun.&lt;/p&gt;
&lt;p&gt;So now that anyone can buy cheap e-ink, there is but one problem: &lt;strong&gt;how to get your content on it?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The display looks really cool and nifty but all you'll get in the package is just that and some code examples to draw something on it - with a program you need to write yourself. After unboxing, how does someone browse the Internet with it? Sadly, they &lt;strong&gt;don't&lt;/strong&gt;.&lt;/p&gt;
&lt;h2&gt;The solution&lt;/h2&gt;
&lt;p&gt;I've had a Waveshare 2.13&quot; HAT for the Raspberry Pi for a while now, and from time to time I've tried to find if someone had already implemented something like this since it sounds simple enough, but at the time of writing I don't know of any programs that mirror the terminal onto an e-ink, so I had a go at it.&lt;/p&gt;
&lt;p&gt;For my purposes I just need proper terminal program support. The next step might be implementing a VNC client which should naturally translate quite well to e-ink's partial updating, but I don't have the time.&lt;/p&gt;
&lt;h2&gt;How it works&lt;/h2&gt;
&lt;p&gt;The principle of operation is deceptively simple:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Reads the virtual terminal contents via &lt;code&gt;/dev/vcsa*&lt;/code&gt; (see &lt;code&gt;man vcsa&lt;/code&gt;)
&lt;ul&gt;&lt;li&gt;For example, content of &lt;code&gt;/dev/tty1&lt;/code&gt; (that you get with Ctrl-Alt-F1) is available at &lt;code&gt;/dev/vcsa1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;This includes the attributes, but they are ignored (if I had a tricolor display, they could be useful)&lt;/li&gt;
&lt;li&gt;Terminal size (character and pixel) is encoded in the first four bytes - this is used to read the rows and columns&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Optionally sets the desired terminal size with &lt;code&gt;ioctl&lt;/code&gt;s (requires write access to the &lt;code&gt;/dev/ttyX&lt;/code&gt; device)&lt;/li&gt;
&lt;li&gt;Adds newlines according to the terminal width (unlike the &lt;code&gt;screendump&lt;/code&gt; utility that reads from &lt;code&gt;/dev/tty*&lt;/code&gt;, reading from a &lt;code&gt;vcsa*&lt;/code&gt; does not include newlines)&lt;/li&gt;
&lt;li&gt;Renders the content and the cursor on an &lt;code&gt;Image&lt;/code&gt; object&lt;/li&gt;
&lt;li&gt;Compares the newly rendered content to the previous content and updates the changed region on the display
&lt;ul&gt;&lt;li&gt;Done in a very simple fashion with just one bounding box&lt;/li&gt;
&lt;li&gt;This results in non-flickering updates and decent speed in typical use cases&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Caveats, shortcomings&lt;/h2&gt;
&lt;p&gt;Some notes:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Hardly tested, developed for a particular model - other models may not work or may need some code tweaking first
&lt;ul&gt;&lt;li&gt;If it sorta works but crashes or something else goes wrong and your display doesn't seem to work like usual anymore, &lt;strong&gt;don't panic&lt;/strong&gt;, try the &lt;code&gt;scrub&lt;/code&gt; command a couple of times first and wait for it to finish - powering off and disconnecting the module completely ought to help as a last resort&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Turns out my particular unit is actually &lt;em&gt;flawed&lt;/em&gt; and doesn't do full refreshes properly so implementing it for other models has been mostly guesswork and wishful thinking&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;The &lt;code&gt;scrub&lt;/code&gt; feature may be entirely unnecessary for normally functioning units&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;The code is surely littered with bugs and could use some refactoring&lt;/li&gt;
&lt;li&gt;You need to figure out the parameters, font and encodings that work for &lt;em&gt;you&lt;/em&gt;
&lt;ul&gt;&lt;li&gt;Importantly, Unicode support is lacking because the virtual terminal stores glyph indices in the buffer and the original value is lost in translation - my understanding is that there is currently development &lt;a href=&quot;https://lkml.org/lkml/2018/6/26/1062&quot; rel=&quot;nofollow&quot;&gt;being done&lt;/a&gt; for the kernel to implement &lt;code&gt;/dev/vcsu*&lt;/code&gt; which would rectify this, but it's not yet in the mainline kernel - option to use a pseudo TTY would be welcome in the mean time&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Not much thought given to tricolor displays - you need to modify the part where attributes are skipped and implement it yourself (or donate such a display and I might take a look...)&lt;/li&gt;
&lt;li&gt;Minimal error handling&lt;/li&gt;
&lt;li&gt;You can't set an arbitrary size for the terminals with &lt;code&gt;ioctl&lt;/code&gt;s - it would be better to use some pseudo terminal for this but then again, sometimes you specifically want &lt;code&gt;tty1&lt;/code&gt; (imagine server crashing and having the kernel log imprinted on the e-ink)&lt;/li&gt;
&lt;li&gt;Cursor placement is a bit obscure - this has to do with how the imaging library handles fonts and their metrics and it's not always very clear to me how they scale with the font... it works well enough though&lt;/li&gt;
&lt;li&gt;The mirroring features were just an afterthought and don't work perfectly (probably simple to fix), also arbitrary rotation is missing (but easy to add)&lt;/li&gt;
&lt;li&gt;&lt;del&gt;The code was written for Python 2 - there are some forks and improvements on the Waveshare code around, but I wanted to make this work on the stock offering so didn't bother incorporating that stuff here&lt;/del&gt;
&lt;ul&gt;&lt;li&gt;&lt;em&gt;The code is now for Python 3&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;While testing out some imaging library functions, I noticed that on another computer the library seemed to lack the &lt;code&gt;spacing&lt;/code&gt; keyword argument for drawing text - this may be a problem in some environments but I didn't think much of it&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Even with all the caveats in mind, I still think the program is very useful and fills a niche. I wish I could have tested it with more than one display model, but that's why I'm releasing it as public domain, so anyone can try it out and hopefully turn it into something better.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;- Jouko Strömmer&lt;/em&gt;&lt;/p&gt;
&lt;/article&gt;&lt;/div&gt;
</description>
<pubDate>Sun, 02 Sep 2018 13:03:46 +0000</pubDate>
<dc:creator>messe</dc:creator>
<og:image>https://avatars3.githubusercontent.com/u/2530203?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>joukos/PaperTTY</og:title>
<og:url>https://github.com/joukos/PaperTTY</og:url>
<og:description>PaperTTY - Python module to render a TTY on e-ink. Contribute to joukos/PaperTTY development by creating an account on GitHub.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/joukos/PaperTTY</dc:identifier>
</item>
<item>
<title>An Intensive Introduction to Cryptography</title>
<link>https://www.intensecrypto.org/public/</link>
<guid isPermaLink="true" >https://www.intensecrypto.org/public/</guid>
<description>&lt;div id=&quot;section-div-intensive-crypto&quot; class=&quot;section level-1&quot;&gt;

&lt;p&gt;Boaz Barak&lt;/p&gt;
&lt;/div&gt;&lt;p&gt;&lt;em&gt;Work in progress&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;These are lecture notes for lecture notes for an introductory but fast-paced undergraduate/beginning graduate course on cryptography. I am using these notes for &lt;a href=&quot;http://cs127.boazbarak.org&quot; title=&quot;&quot;&gt;Harvard CS 127&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can also download &lt;a href=&quot;https://www.intensecrypto.org/public/lnotes_book.pdf&quot; title=&quot;&quot;&gt;all lecture notes in a single PDF file&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you have any comments, suggestions, typo fixes, etc.. I would be very grateful if you post them as an &lt;a href=&quot;https://github.com/boazbk/crypto/issues&quot; title=&quot;&quot;&gt;issue&lt;/a&gt; or &lt;a href=&quot;https://github.com/boazbk/crypto/pulls&quot; title=&quot;&quot;&gt;pull request&lt;/a&gt; in the &lt;a href=&quot;https://github.com/boazbk/crypto&quot; title=&quot;&quot;&gt;GitHub repository&lt;/a&gt; where I am maintaining the source files for these notes.&lt;/p&gt;

</description>
<pubDate>Sun, 02 Sep 2018 12:05:40 +0000</pubDate>
<dc:creator>angry_octet</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.intensecrypto.org/public/</dc:identifier>
</item>
<item>
<title>Modi’s Cash Crackdown Failed, Indian Bank Data Shows</title>
<link>https://www.nytimes.com/2018/08/30/world/asia/modi-india-rupee-cash.html</link>
<guid isPermaLink="true" >https://www.nytimes.com/2018/08/30/world/asia/modi-india-rupee-cash.html</guid>
<description>&lt;div readability=&quot;42.603174603175&quot;&gt;
&lt;div class=&quot;css-1h6whtw&quot; readability=&quot;31.952380952381&quot;&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;NEW DELHI — Almost two years ago, Prime Minister Narendra Modi of India &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.nytimes.com/2017/01/02/world/asia/modi-cash-ban-india.html&quot; title=&quot;&quot;&gt;threw the country into turmoil&lt;/a&gt; when he decided, by surprise and practically overnight, to effectively invalidate the old paper currency.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;Mr. Modi’s plan, kept secret even from his cabinet until it was announced, gave citizens a 50-day deadline to turn in their 500-rupee and 1,000-rupee notes to banks in exchange for new notes. After the deadline, the old notes would be totally useless.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;As Indians waited in interminable lines at banks, and everyone from rickshaw drivers to real estate agents suffered a hit to their businesses and lives, Mr. Modi’s team said the pain was necessary to punish those who were hoarding ill-gotten cash.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;These hoarders — including criminals, terrorists and tax evaders — would be too afraid to exchange their old bills for new ones, the thinking went, because going to banks would expose them to scrutiny and possible prosecution.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;&lt;div readability=&quot;44.625&quot;&gt;
&lt;div class=&quot;css-1h6whtw&quot; readability=&quot;35.307692307692&quot;&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;But according to the central bank, it didn’t work out that way.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;Figures released this week by the &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.rbi.org.in&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Reserve Bank of India&lt;/a&gt; showed that 99 percent of the value of the old bills that had been removed from circulation eventually found its way back into the financial system. The figures suggested that criminals and other hoarders, like nearly everyone else, found ways to change their old bills for new ones.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;Mr. Modi’s enemies instantly pounced on the findings, saying the prime minister should apologize for all the chaos he caused. Economists shook their heads.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;“This was a big mistake,” said Arun Kumar, an economics professor at the Institute of Social Sciences in New Delhi. “Employment was lost, output was lost and investment came down.”&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;Mr. Kumar said Mr. Modi’s decision clearly did not tackle the problem of illicit cash and was “a complete failure.”&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;Mr. Modi’s plan, called demonetization or just “demo” by many Indians, was a huge gamble, possibly Mr. Modi’s biggest, and some analysts say the prime minister will pay next year when he is up for re-election.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;&lt;div readability=&quot;32.79302832244&quot;&gt;
&lt;div class=&quot;css-1h6whtw&quot; readability=&quot;14.779956427015&quot;&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;It is also the way he did what he did that ruffled many feathers. He did not consult Parliament. He did not solicit advice from many learned advisers. He did not give the public any warning.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;Instead, Mr. Modi made the decision in intense secrecy with the input of only a few trusted lieutenants and then sprung it on the nation, announcing in an &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.youtube.com/watch?v=_KCII8OxlgA&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;unscheduled live television address&lt;/a&gt; on Nov. 8, 2016, that all the big bills in circulation were suddenly invalid.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;&lt;div readability=&quot;39.794444444444&quot;&gt;
&lt;div class=&quot;css-1h6whtw&quot; readability=&quot;29.274074074074&quot;&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;To keep the country in the dark, his government had largely avoided printing replacement notes in advance. So for months after his announcement, India suffered an acute cash shortage, with ATMs running dry and &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://qz.com/india/839763/in-photos-please-wait-india-you-are-in-queue-thanks-to-narendra-modis-demonetisation/&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;people lining up for hours&lt;/a&gt; to turn in their old bills and wait in vain for new ones. The &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://indianexpress.com/article/india/india-news-india/demonetisation-suicides-heart-attacks-and-even-a-murder-among-33-deaths-since-decision-4378135/&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;stress pushed several people to suicide&lt;/a&gt;; others died of heart attacks while waiting in bank lines.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;So much in India turns on cash, not just common purchases for goods and services like food and taxi rides. Even real estate deals worth millions of dollars are sometimes done partly in cash.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;Many economists believe that demonetization, along with stricter tax policies that Mr. Modi’s government has put into effect, has crimped India’s economic growth, which is &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.livemint.com/Politics/TQmmRQnpW1ZcB1qQsi3h6H/World-Bank-sees-India-as-fastest-growing-economy-for-next-th.html&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;running at around 7 percent&lt;/a&gt; a year.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;That growth rate, however, is still the envy of many countries. And some economists contend that it is wrong to consider demonetization a failure, because the government can now obtain much more data from the banks, forming a clearer picture of what’s happening in the economy.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;&lt;div readability=&quot;47.304966887417&quot;&gt;
&lt;div class=&quot;css-1h6whtw&quot; readability=&quot;44.090066225166&quot;&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;“The risk to tax evaders has jumped sharply and they should be on tenterhooks,” said Gautam Chikermane, vice president of the Observer Research Foundation, a research institute in New Delhi.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;Another goal of demonetization was to move Indians away from cash. The idea was that Indians would bank more of their money and the government could then track it more closely — and collect more taxes in a country where only a tiny fraction of earners pay income tax.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;To some degree, the banking sector did benefit. In the wake of demonetization, millions of Indians opened their first bank accounts.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;But not all of that is attributable to Mr. Modi’s efforts. India has been rapidly modernizing, and its economy is now the world’s sixth largest (behind the United States, China, Japan, Germany and Britain), though hundreds of millions of people are still very poor.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;And even to this day, cash is still king in India. Want to buy a table? More often than not merchants will offer two prices.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;If you want to pay by credit card, it’s this much. But if you pay cash (which means the merchant will most likely not report the sale), the price can be much cheaper.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;Mr. Modi has kept quiet about the recent demonetization findings, which basically confirmed &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.thehindu.com/business/Economy/only-12-of-demonetised-1000-notes-did-not-return-rbi/article19590311.ece&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;those released a year ago&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;css-1i0edl6 e2kc3sl0&quot;&gt;He is a &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://twitter.com/narendramodi&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;prolific Twitter user&lt;/a&gt;, with nearly 44 million followers. But his latest burst of Twitter postings show him &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://twitter.com/narendramodi/status/1035156931768471552&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;shaking hands with regional leaders&lt;/a&gt; or &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://twitter.com/narendramodi/status/1034806044759810048&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;congratulating Indian table tennis players&lt;/a&gt;, with nothing about the economy.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;&lt;div readability=&quot;29.385714285714&quot;&gt;

&lt;div class=&quot;css-k8fkhk&quot; readability=&quot;8&quot;&gt;
&lt;p&gt;Hari Kumar contributed reporting from New Delhi, and Ayesha Venkataraman from Mumbai.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;css-3glrhn&quot; readability=&quot;8.0412371134021&quot;&gt;A version of this article appears in print on , on Page A9 of the New York edition with the headline: Cash Ban Didn’t Work, Indian Bank Data Shows&lt;span&gt;. &lt;a href=&quot;http://www.nytreprints.com/&quot;&gt;Order Reprints&lt;/a&gt; | &lt;a href=&quot;http://www.nytimes.com/pages/todayspaper/index.html&quot;&gt;Today’s Paper&lt;/a&gt; | &lt;a href=&quot;https://www.nytimes.com/subscriptions/Multiproduct/lp8HYKU.html?campaignId=48JQY&quot;&gt;Subscribe&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;

&lt;/div&gt;</description>
<pubDate>Sun, 02 Sep 2018 02:47:18 +0000</pubDate>
<dc:creator>walterbell</dc:creator>
<og:url>https://www.nytimes.com/2018/08/30/world/asia/modi-india-rupee-cash.html</og:url>
<og:type>article</og:type>
<og:title>Modi’s Cash Crackdown Failed, Indian Bank Data Shows</og:title>
<og:image>https://static01.nyt.com/images/2018/08/31/world/31INDIA-ECON-print/31INDIA-ECON-01-facebookJumbo.jpg</og:image>
<og:description>The prime minister’s surprise decision in 2016 to scrap old paper currency did not deter criminals, who found ways to exchange the bills.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.nytimes.com/2018/08/30/world/asia/modi-india-rupee-cash.html</dc:identifier>
</item>
<item>
<title>USB-C Explorer – A development board to get started working with USB Type-C</title>
<link>https://www.reclaimerlabs.com/blog/2018/8/7/the-usb-c-explorer</link>
<guid isPermaLink="true" >https://www.reclaimerlabs.com/blog/2018/8/7/the-usb-c-explorer</guid>
<description>&lt;div class=&quot;sqs-layout sqs-grid-12 columns-12&quot; data-layout-label=&quot;Post Body&quot; data-type=&quot;item&quot; data-updated-on=&quot;1533622289271&quot; id=&quot;item-5b69368170a6add62b134ff4&quot;&gt;
&lt;div class=&quot;row sqs-row&quot;&gt;
&lt;div class=&quot;col sqs-col-12 span-12&quot;&gt;
&lt;div class=&quot;sqs-block html-block sqs-block-html&quot; data-block-type=&quot;2&quot; id=&quot;block-84154f4e0c3615eee8f8&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;p&gt;I've been quiet for a while, mostly because I've been working on a new USB-C board. Actually, the board didn't take the most time; that would be the firmware development. (Never underestimate firmware). The result is a cool piece of gear, a powerful development platform, and a stronger firmware library.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;sqs-block html-block sqs-block-html&quot; data-block-type=&quot;2&quot; id=&quot;block-yui_3_17_2_1_1533621849381_21600&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;p&gt;The USB-C Explorer is a development board with everything needed to start working with USB Type-C. It contains a USB-C port controller and Power Delivery PHY chip, a microcontroller, and several options for user interaction. Here are the hardware features.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.microchip.com/wwwproducts/en/ATSAMD21E17&quot;&gt;SAMD21E17A&lt;/a&gt; microcontroller&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.onsemi.com/PowerSolutions/product.do?id=FUSB302B&quot;&gt;FUSB302B&lt;/a&gt; USB PD PHY&lt;/li&gt;
&lt;li&gt;OLED Display&lt;/li&gt;
&lt;li&gt;Capacitive-sense slider&lt;/li&gt;
&lt;li&gt;Power header (up to 5 Amps)&lt;/li&gt;
&lt;li&gt;Debug port (UART and/or GPIO)&lt;/li&gt;
&lt;li&gt;SWD connector (&lt;a href=&quot;http://www.tag-connect.com/TC2050-IDC-NL&quot;&gt;Tag-Connect&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Reset and User Buttons&lt;/li&gt;
&lt;li&gt;Onboard regulator, input up to 20 V.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The default firmware will identify as a USB Power Delivery Sink and list out all power capabilities from a corresponding Source. It will then request the highest power option. This voltage will be available on the power header. The example photo shows the capabilities of an Apple MacBook 87W Charger.&lt;/p&gt;
&lt;p&gt;The default firmware also includes a USB bootloader. If you hold the User Button during reset, it will show up as a USB Mass Storage Device with a single file &quot;FLASH.BIN&quot;. Copy the file to inspect the application firmware. Delete it and replace it with a new .bin file to rewrite the firmware. No programming cable is required.&lt;/p&gt;
&lt;p&gt;To use the Single Wire Debug (SWD) function for live debugging, you will need a Tag-Connect TC2050-IDC-NL &quot;plug of nails&quot; &lt;a href=&quot;http://www.tag-connect.com/TC2050-IDC-NL&quot;&gt;cable&lt;/a&gt; and &lt;a href=&quot;http://www.tag-connect.com/TC2050-CLIP&quot;&gt;clip&lt;/a&gt;. You can then use an &lt;a href=&quot;http://www.tag-connect.com/ARM20-CTX&quot;&gt;adapter&lt;/a&gt; to something like a Segger or J-Link.&lt;/p&gt;
&lt;p&gt;The firmware library has also been redesigned from the ground up to support new platforms. The first of these is support for the Arduino M0. You can find that example &lt;a href=&quot;https://github.com/graycatlabs/usb-c-arduino&quot;&gt;here&lt;/a&gt;. The intention is that only four files, tcpm_driver.c/h and usb_pd_driver.c/h, need to be modified to support new microcontrollers. New pairs of files such as FUSB302.c/h can be added to support new Type-C Port Managers (TCPM chips).&lt;/p&gt;
&lt;p&gt;You can purchase a board from my &lt;a href=&quot;https://www.tindie.com/products/ReclaimerLabs/usb-c-explorer/&quot;&gt;Tindie store&lt;/a&gt;. This design is open source under an MIT license. All hardware designs, documentation, and firmware are freely available. You can find all design files at this &lt;a href=&quot;https://github.com/ReclaimerLabs/USB-C-Explorer&quot;&gt;github repository&lt;/a&gt;. I welcome feedback, so please let me know what you think. In particular, help with firmware would be appreciated.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Sun, 02 Sep 2018 02:23:00 +0000</pubDate>
<dc:creator>walterbell</dc:creator>
<og:title>The USB-C Explorer</og:title>
<og:url>https://www.reclaimerlabs.com/blog/2018/8/7/the-usb-c-explorer</og:url>
<og:type>article</og:type>
<og:description>I've been quiet for a while, mostly because I've been working on a new USB-C board. Actually, the board didn't take the most time; that would be the firmware development. (Never underestimate firmware). The result is a cool piece of gear, a powerful development platform, and a stronger firmware libr</og:description>
<og:image>http://static1.squarespace.com/static/54606523e4b054a6f866f6fc/5b6937c52b6a28624c0ee11c/5b6937db03ce6404fb717a51/1533622256616/Top_on_cropped.JPG?format=1000w</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.reclaimerlabs.com/blog/2018/8/7/the-usb-c-explorer</dc:identifier>
</item>
<item>
<title>TypeScript at Google</title>
<link>http://neugierig.org/software/blog/2018/09/typescript-at-google.html</link>
<guid isPermaLink="true" >http://neugierig.org/software/blog/2018/09/typescript-at-google.html</guid>
<description>&lt;div id=&quot;post-heading&quot;&gt;

&lt;p&gt;September 01, 2018&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I've been working on TypeScript for over two years now(!) so I thought I'd write a post or two to reflect. I should open with the standard disclaimer: I am just a random engineer at a company with tens of thousands of them, and others surely disagree with the opinions expressed here.&lt;/p&gt;
&lt;p&gt;Google embraced web applications early. Can you believe it's been 14 years since Gmail was released? JavaScript back then was pure madness. Gmail engineers had to worry so much about Internet Explorer's poor garbage collection algorithm that they'd need to manually hoist string literals out of for loops to avoid GC pauses. I recently found a design doc from that era where they considered doing what today we'd call &quot;minifying&quot; the JavaScript but noted that some candidate tools were Windows-only. Today that feels unimaginable.&lt;/p&gt;
&lt;p&gt;Over those years Google built lots of infrastructure for making big JavaScript apps. For example, there's a module system to let source files express their interdependencies. There's a bundler that combines and minifies source files into browser-compatible artifacts. Another piece analyzes an app's dependency graph by dynamically-loadable entry points and factors out common subset chunks for serving. Server-side rendering is common. All of these concepts are familiar to a web developer today but Google's stack predates today's, evolved in parallel, and is consequently conceptually similar but concretely totally different, with different processes, tools, and even names for these ideas.&lt;/p&gt;
&lt;p&gt;In another example of parallel evolution, each of Google, Facebook, and Microsoft built similar but incompatible compilers that add static checks to JavaScript. Google's compiler is colloquially called Closure. (Not to be confused with the Clojure language; for extra confusion note that ClojureScript uses the Closure compiler.)&lt;/p&gt;
&lt;p&gt;Google's JavaScript stack is unevenly great. It has enabled Google to write and maintain web apps that have changed the face of the internet. (Remember how amazing Maps was when it came out? Today it seems boringly obvious to make a draggy map widget.) There are pieces of it that surpass the best of today's technologies. For example, the Closure compiler is perhaps still the most sophisticated JavaScript optimizer, able to do things like optimize code using type information, inline functions across hot-loading chunk boundaries, and strip unused code down to &lt;a href=&quot;https://closure-compiler.appspot.com/home#code%3D%252F%252F%2520%253D%253DClosureCompiler%253D%253D%250A%252F%252F%2520%2540compilation_level%2520ADVANCED_OPTIMIZATIONS%250A%252F%252F%2520%2540output_file_name%2520default.js%250A%252F%252F%2520%253D%253D%252FClosureCompiler%253D%253D%250A%250Aclass%2520C%2520%257B%250A%2520%2520constructor()%2520%257B%250A%2520%2520%2520%2520this.member%2520%253D%25203%253B%250A%2520%2520%257D%250A%2520%2520f(x)%2520%257B%250A%2520%2520%2520%2520console.log('hello')%253B%250A%2520%2520%2520%2520if%2520(x)%2520console.log(this.member)%253B%250A%2520%2520%257D%250A%257D%250A%250Alet%2520c%2520%253D%2520new%2520C()%253B%250Ac.f(false)%253B&quot;&gt;individual symbols&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Google's JavaScript stack also has problems. The incremental evolution from a linter means Closure is a statically typed variant of JavaScript where language features are introduced in comments. Closure has unpredictable semantics, it's slow, it's buggy, and it tends to mangle your code unless you hold it just right. Though it is open source, perhaps because of these reasons it isn't widely used in the industry except at companies that hire Googlers who are familiar with it. Within Google I think JavaScript has a low reputation in part because of our finicky tools, which combine the verbosity of a static language with the unpredictability of a dynamic one.&lt;/p&gt;
&lt;p&gt;Meanwhile, outside of Google, JavaScript also continued to evolve and surprisingly even became popular. In part to work around those IE garbage collection bugs we built Chrome which led to v8 which led to nodejs which means most web tools today are themselves written in JavaScript, unlike the Java used to build this sort of tool at Google. Module systems (UMD, AMD, CommonJS) proliferated. (ES6 also came along and invented its own module system that is incompatible with all the others for some reason, sigh.) npm unified the way tools and libraries are shared. Webpack can &lt;a href=&quot;https://webpack.js.org/concepts/hot-module-replacement/&quot;&gt;dynamically swap modules&lt;/a&gt; into a running application while you develop it.&lt;/p&gt;
&lt;p&gt;Google uses none of this. Experienced webdevs show up at Google and it's like visiting an alternative timeline. There's a CSS preprocessing language like SASS but it's not SASS and nobody likes it. The fancy chunk-splitter doesn't really support third-party JavaScript libraries in part because the tools predate the existence of a JavaScript library ecosystem.&lt;/p&gt;
&lt;p&gt;That's all just history. You can argue we shouldn't have gotten to this place but it doesn't change that we're here now. Instead the interesting question is: where do we go now? There are a few options. My perspective is surely biased by the one I prefer.&lt;/p&gt;
&lt;p&gt;The first tempting option is to just abandon this ruined planet and settle a new one that doesn't even involve JavaScript. If only we invested more in GWT (a Google project that compiles Java to JavaScript) or Dart (a Google project that compiles a new language to JavaScript) or WASM or [insert your favorite language here — Clojure? Haxe? Elm?] we wouldn't need to worry about JavaScript at all!&lt;/p&gt;
&lt;p&gt;As a PL enthusiast I'm pretty fond of this idea. I'd like to give it the careful analysis it deserves, but this post is long enough and I think that discussion would work as its own post. Instead of a full refutation, here are some mundane concerns: adopting a different language (1) does nothing for the literally millions of lines of existing code we have — &quot;rewrite from scratch in a new language&quot; is the correct choice for some situations, but it's a hard argument to make as the best use of gmail engineers' time — and (2) it does little for the aforementioned experienced frontend programmers that we would like to hire.&lt;/p&gt;
&lt;p&gt;The opposite of rewriting everything is to change nothing. The public JavaScript world, you could correctly point out, is full of amateur code and leftpad disasters. A good engineer can always adapt to our idiosyncratic way of making frontends and we can always improve or build more of our own tools. The types of apps we build — the Google search page gets billions of hits per day — are different enough from the sorts of web apps others build that our tools are both superior and necessary. I am sympathetic to this view. I think there's a point in the space of tradeoffs where it makes sense to build our own tools, and another point at which we've diverged so far from the mainstream that our tools are a liability. The argument is then about where we are in that space, and I believe we're drifted too far towards the latter. We benefit from contributing to LLVM/Clang because we depend on C++, but we wouldn't get much additional value from building our own LLVM.&lt;/p&gt;
&lt;p&gt;Which leads me to the middle path, which my little team has been pursuing: incrementally adopt some external tooling where it makes sense, by figuring out how to make it interoperate with our existing code base. This task isn't as fun — we don't get to just throw away our legacy mess and &quot;do it right this time&quot; — but I like to think rather more humble, looking outward rather than inward.&lt;/p&gt;
&lt;p&gt;The first part of our bridge from the Google JavaScript Galapagos back to the mainland was adopting a well-supported static checker that is (1) not home-grown; (2) popular already, while similar to our existing code; (3) designed to bridge into JavaScript; (4) designed to support the large-scale development that motivated our custom tools in the first place. And that tool is TypeScript. The strength of the Closure compiler is its optimized output, while TypeScript has a great user interface and no optimization at all. The two tools are complementary and (with some work) can be layered together.&lt;/p&gt;
&lt;p&gt;Because TypeScript already mostly works — that's part of the reason to adopt it, after all — we get many of the benefits of adopting an established language, from IDE-style code completion to being able to check StackOverflow for answers. The work that's left for us has primarily been integration: allowing our apps to incrementally move into TypeScript without rewriting from scratch. &lt;a href=&quot;https://github.com/bazelbuild/rules_typescript&quot;&gt;Our integration into the Google-wide build system&lt;/a&gt; is careful to compile incrementally, which is critical for large apps; changes in one module that don't affect its exported API don't cause downstream modules to recompile. Our integration into the Closure type/module system means that ES6 TypeScript modules can &lt;a href=&quot;https://github.com/angular/clutz&quot;&gt;import Google-module-system modules&lt;/a&gt; and &lt;a href=&quot;https://github.com/angular/tsickle&quot;&gt;the reverse&lt;/a&gt;, with (much of) the type information preserved. &lt;a href=&quot;https://www.lucidchart.com/techblog/2017/11/16/converting-600k-lines-to-typescript-in-72-hours/&quot;&gt;One company successfully used the tools we published&lt;/a&gt; to automatically translate their entire code base while preserving their minified output.&lt;/p&gt;
&lt;p&gt;Within Google TypeScript is now found in varying quantities everywhere; it's likely if you use Google products you've interacted with some TypeScript code. TypeScript itself is a bunch of interesting compromises, balancing a statically typed programming language against the free-wheeling JavaScript ecosystem. But that's what we engineers do: we make interesting compromises that attempt to balance different concerns. I hope to write more in the future about some of interesting corners we've discovered over the years. As I &lt;a href=&quot;http://neugierig.org/software/blog/2016/02/revisiting-typescript.html&quot;&gt;wrote when we first started down this path&lt;/a&gt;, I think TypeScript makes good tradeoffs within the design space.&lt;/p&gt;
</description>
<pubDate>Sun, 02 Sep 2018 00:46:00 +0000</pubDate>
<dc:creator>wslh</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>http://neugierig.org/software/blog/2018/09/typescript-at-google.html</dc:identifier>
</item>
<item>
<title>Time Series Prediction Using LSTM Deep Neural Networks</title>
<link>https://www.altumintelligence.com/articles/a/Time-Series-Prediction-Using-LSTM-Deep-Neural-Networks</link>
<guid isPermaLink="true" >https://www.altumintelligence.com/articles/a/Time-Series-Prediction-Using-LSTM-Deep-Neural-Networks</guid>
<description>&lt;p&gt;This article focuses on using an LSTM neural network architecture to provide time series forecasting using Keras and Tensorflow - specifically on stock market datasets to provide momentum indicators of stock price.&lt;/p&gt;
&lt;p&gt;The code for this framework can be found in the following GitHub repo (it assumes python version 3.5.x and the requirement versions in the requirements.txt file. Deviating from these versions might cause errors): &lt;a href=&quot;https://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction&quot; target=&quot;_blank&quot;&gt;https://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The following article sections will briefly touch on LSTM neuron cells, give a toy example of predicting a sine wave then walk through the application to a stochastic time series. The article assumes a basic working knowledge of simple deep neural networks.&lt;/p&gt;
&lt;br/&gt;&lt;h2&gt;What Are LSTM Neurons?&lt;/h2&gt;
&lt;p&gt;One of the fundamental problems which plagued traditional neural network architectures for a long time was the ability to interpret sequences of inputs which relied on each other for information and context. This information could be previous words in a sentence to allow for a context to predict what the next word might be, or it could be temporal information of a sequence which would allow for context on the time based elements of that sequence.&lt;/p&gt;
&lt;p&gt;Simply put, traditional neural networks take in a stand-alone data vector each time and have no concept of memory to help them on tasks that need memory.&lt;/p&gt;
&lt;p&gt;An early attempt to tackle this was to use a simple feedback type approach for neurons in the network where the output was fed-back into the input to provide context on the last seen inputs. These were called Recurrent Neural Networks (RNNs). Whilst these RNNs worked to an extent, they had a rather large downfall that any significant uses of them lead to a problem called the Vanishing Gradient Problem. We will not expand on the vanishing gradient issue any further than to say that RNNs are poorly suited in most real-world problems due to this issue, hence, another way to tackle context memory needed to be found.&lt;/p&gt;
&lt;p&gt;This is where the Long Short Term Memory (LSTM) neural network came to the rescue. Like RNN neurons, LSTM neurons kept a context of memory within their pipeline to allow for tackling sequential and temporal problems without the issue of the vanishing gradient affecting their performance.&lt;/p&gt;
&lt;p&gt;Many research papers and articles can be found online which discuss the workings of LSTM cells in great mathematical detail. In this article however we will not discuss the complex workings of LSTMs as we are more concerned about their use for our problems.&lt;/p&gt;
&lt;p&gt;For context, below is a diagram of the typical inner workings of an LSTM neuron. It consists of several layers, and pointwise operations which act as gates for data input, output and forget which feed the LSTM cell state. This cell state is what keeps the long-term memory and context across the network and inputs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.altumintelligence.com/assets/time-series-prediction-using-lstm-deep-neural-networks/lstm_cell.png&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;A Simple Sine Wave Example&lt;/h2&gt;
&lt;p&gt;To demonstrate the use of LSTM neural networks in predicting a time series let us start with the most basic thing we can think of that's a time series: the trusty sine wave. And let us create the data we will need to model many oscillations of this function for the LSTM network to train over.&lt;/p&gt;
&lt;p&gt;The data provided in the code's data folder contains a sinewave.csv file we created which contains 5001 time periods of a sine wave with amplitude and frequency of 1 (giving an angular frequency of 6.28) and a time delta of 0.01. The result of this, when plotted looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.altumintelligence.com/assets/time-series-prediction-using-lstm-deep-neural-networks/sindata.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;Dataset for a sinewave&lt;/span&gt;&lt;/p&gt;
Now that we have the data, what are we actually trying to achieve? Well, simply we want the LSTM to learn the sine wave from a set window size of data that we will feed it and hopefully we can ask the LSTM to predict the next N-steps in the series and it will keep outputting a sine wave.
&lt;p&gt;We will start by transforming and loading the data from the CSV file to a pandas dataframe which will then be used to output a numpy array that will feed the LSTM. The way Keras LSTM layers work is by taking in a numpy array of 3 dimensions (N, W, F) where N is the number of training sequences, W is the sequence length and F is the number of features of each sequence. We chose to go with a sequence length (read window size) of 50 which allows for the network so get glimpses of the shape of the sine wave at each sequence and hence will hopefully teach itself to build up a pattern of the sequences based on the prior window received.&lt;/p&gt;
&lt;p&gt;The sequences themselves are sliding windows and hence shift by 1 each time, causing a constant overlap with the prior windows. A typical training window of sequence length 50, when plotted, is shown below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.altumintelligence.com/assets/time-series-prediction-using-lstm-deep-neural-networks/sinwindow.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;Sinewave dataset training window&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For loading this data we created a DataLoader class in our code to provide an abstraction for the data loading layer. You will notice that upon initialization of a DataLoader object, the filename is passed in, along with a split variable which determines the percentage of the data to use for training vs. testing and a columns variable which allows for selecting one or more columns of data for single dimensional or multidimensional analysis.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;python&quot;&gt;class DataLoader():

        def __init__(self, filename, split, cols):
                dataframe = pd.read_csv(filename)
                i_split = int(len(dataframe) * split)
                self.data_train = dataframe.get(cols).values[:i_split]
                self.data_test  = dataframe.get(cols).values[i_split:]
                self.len_train  = len(self.data_train)
                self.len_test   = len(self.data_test)
                self.len_train_windows = None

        def get_train_data(self, seq_len, normalise):
                data_x = []
                data_y = []
                for i in range(self.len_train - seq_len):
                        x, y = self._next_window(i, seq_len, normalise)
                        data_x.append(x)
                        data_y.append(y)
                return np.array(data_x), np.array(data_y)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;After we have a data object which allows for us to load the data we will need to build the deep neural network model. Again for abstraction our code framework uses a Model class alongside a config.json file to easily build an instance of our model given a required architecture and hyperparameters stored in the config file. The main function which builds our network is the build_model() functions that takes in the parsed configs file.&lt;/p&gt;
&lt;p&gt;This function code can be seen below and can easily be extended for future use on more complex architectures.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;python&quot;&gt;class Model():

        def __init__(self):
                self.model = Sequential()

        def build_model(self, configs):
                timer = Timer()
                timer.start()

                for layer in configs['model']['layers']:
                        neurons = layer['neurons'] if 'neurons' in layer else None
                        dropout_rate = layer['rate'] if 'rate' in layer else None
                        activation = layer['activation'] if 'activation' in layer else None
                        return_seq = layer['return_seq'] if 'return_seq' in layer else None
                        input_timesteps = layer['input_timesteps'] if 'input_timesteps' in layer else None
                        input_dim = layer['input_dim'] if 'input_dim' in layer else None

                        if layer['type'] == 'dense':
                                self.model.add(Dense(neurons, activation=activation))
                        if layer['type'] == 'lstm':
                                self.model.add(LSTM(neurons, input_shape=(input_timesteps, input_dim), return_sequences=return_seq))
                        if layer['type'] == 'dropout':
                                self.model.add(Dropout(dropout_rate))

                self.model.compile(loss=configs['model']['loss'], optimizer=configs['model']['optimizer'])

                print('[Model] Model Compiled')
                timer.stop()
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;With the data loaded and the model built we can now progress onto training the model with our training data. For this we create a separate run module which will utilize our Model and DataLoader abstractions to combine them for training, output and visualizations.&lt;/p&gt;
&lt;p&gt;Below is the general run thread code to train our model.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;python&quot;&gt;configs = json.load(open('config.json', 'r'))

data = DataLoader(
        os.path.join('data', configs['data']['filename']),
        configs['data']['train_test_split'],
        configs['data']['columns']
)

model = Model()
model.build_model(configs)
x, y = data.get_train_data(
        seq_len = configs['data']['sequence_length'],
        normalise = configs['data']['normalise']
)

model.train(
        x,
        y,
        epochs = configs['training']['epochs'],
        batch_size = configs['training']['batch_size']
)

x_test, y_test = data.get_test_data(
        seq_len = configs['data']['sequence_length'],
        normalise = configs['data']['normalise']
)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;For output we will run two types of predictions: the first will be predicting in a point-by-point way, that is we are only predicting a single point ahead each time, plotting this point as a prediction, then taking the next window along with the full testing data and predicting the next point along once again.&lt;/p&gt;
&lt;p&gt;The second prediction we will do is to predict a full sequence, by this we only initialize a training window with the first part of the training data once. The model then predicts the next point and we shift the window, as with the point-by-point method. The difference is we then predict using the data that we predicted in the prior prediction. In the second step this will mean only one data point (the last point) will be from the prior prediction. In the third prediction the last two data points will be from prior predictions and so forth. After 50 predictions our model will subsequently be predicting on its own prior predictions. This allows us to use the model to forecast many time steps ahead, but as it is predicting on predictions which can then in turn be based on predictions this will increase the error rate of the predictions the further ahead we predict.&lt;/p&gt;
&lt;p&gt;Below we can see the code and respective outputs for both the point-by-point predictions and the full sequence predictions.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;python&quot;&gt;def predict_point_by_point(self, data):
        #Predict each timestep given the last sequence of true data, in effect only predicting 1 step ahead each time
        predicted = self.model.predict(data)
        predicted = np.reshape(predicted, (predicted.size,))
        return predicted

def predict_sequence_full(self, data, window_size):
        #Shift the window by 1 new prediction each time, re-run predictions on new window
        curr_frame = data[0]
        predicted = []
        for i in range(len(data)):
                predicted.append(self.model.predict(curr_frame[newaxis,:,:])[0,0])
                curr_frame = curr_frame[1:]
                curr_frame = np.insert(curr_frame, [window_size-2], predicted[-1], axis=0)
        return predicted

predictions_pointbypoint = model.predict_point_by_point(x_test)
plot_results(predictions_pointbypoint, y_test)

predictions_fullseq = model.predict_sequence_full(x_test, configs['data']['sequence_length'])
plot_results(predictions_fullseq, y_test)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://www.altumintelligence.com/assets/time-series-prediction-using-lstm-deep-neural-networks/sinwave_pointbypoint.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;Sinewave point-by-point prediction&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.altumintelligence.com/assets/time-series-prediction-using-lstm-deep-neural-networks/sinwave_full_seq.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;Sinewave full sequence prediction&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For reference the network architecture and hyperparameters used for the sinewave example can be seen in the below config file.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;json&quot;&gt;{
        &quot;data&quot;: {
                &quot;filename&quot;: &quot;sinewave.csv&quot;,
                &quot;columns&quot;: [
                        &quot;sinewave&quot;
                ],
                &quot;sequence_length&quot;: 50,
                &quot;train_test_split&quot;: 0.8,
                &quot;normalise&quot;: false
        },
        &quot;training&quot;: {
                &quot;epochs&quot;: 2,
                &quot;batch_size&quot;: 32
        },
        &quot;model&quot;: {
                &quot;loss&quot;: &quot;mse&quot;,
                &quot;optimizer&quot;: &quot;adam&quot;,
                &quot;layers&quot;: [
                        {
                                &quot;type&quot;: &quot;lstm&quot;,
                                &quot;neurons&quot;: 50,
                                &quot;input_timesteps&quot;: 49,
                                &quot;input_dim&quot;: 1,
                                &quot;return_seq&quot;: true
                        },
                        {
                                &quot;type&quot;: &quot;dropout&quot;,
                                &quot;rate&quot;: 0.05
                        },
                        {
                                &quot;type&quot;: &quot;lstm&quot;,
                                &quot;neurons&quot;: 100,
                                &quot;return_seq&quot;: false
                        },
                        {
                                &quot;type&quot;: &quot;dropout&quot;,
                                &quot;rate&quot;: 0.05
                        },
                        {
                                &quot;type&quot;: &quot;dense&quot;,
                                &quot;neurons&quot;: 1,
                                &quot;activation&quot;: &quot;linear&quot;
                        }
                ]
        }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Overlaid with the true data we can see that with just 1 epoch and a reasonably small training set of data the LSTM deep neural network has already done a pretty good job of predicting the sine function.&lt;/p&gt;
&lt;p&gt;You can see that as we predict more and more into the future the error margin increases as the errors in the prior predictions are amplified more and more when they are used for future predictions. As such we see that in the full sequence example, the further into the future we predict the less accurate the frequency and amplitude of the predictions is compared to the true data. However as the sin function is a very easy oscillating function with zero noise it can still predict it to a good degree without overfitting - this is important, as we could easily overfit the model by increasing the epochs and taking out the dropout layers to make it almost perfectly accurate on this training data, which is of the same pattern as the test data, but for other real-world examples overfitting the model onto the training data would cause the test accuracy to plummet as the model would not be generalizing.&lt;/p&gt;
&lt;p&gt;In the next step we will try to use the model on such real-world data to see the effects.&lt;/p&gt;
&lt;br/&gt;&lt;h2&gt;The Not-So-Simple Stock Market&lt;/h2&gt;
&lt;p&gt;We predicted a several hundred time steps of a sine wave on an accurate point-by-point basis. So we can now just do the same on a stock market time series and make immediate profit, right? Unfortunately in the real-world this is not quite that simple.&lt;/p&gt;
&lt;p&gt;Unlike a sinewave, a stock market time series is not any sort of specific static function which can be mapped. The best property to describe the motion of a stock market time series would be a random walk. As a stochastic process, a true random walk has no predictable patterns and so attempting to model it would be pointless. Fortunately there are on-going arguments by many sides to say that a stock market isn't a pure stochastic process, which allows us to theorize that the time series may well have some kind of hidden pattern. And it is these hidden patterns that LSTM deep networks are prime candidates to predict.&lt;/p&gt;
&lt;p&gt;The data this example will be using is the sp500.csv file in the data folder. This file contains the Open, High, Low, Close prices as well as the daily Volume of the S&amp;amp;P 500 Equity Index from January 2000 to September 2018.&lt;/p&gt;
&lt;p&gt;In the first instance we will only create a single dimensional model using the Close price only. Adapting the config.json file to reflect the new data we will keep most of the parameters the same. One change which is needed however is that, unlike the sinewave which only had numerical ranges between -1 to +1 the close price is a constantly moving absolute price of the stock market. This means that if we tried to train the model on this without normalizing it, it would never converge.&lt;/p&gt;
&lt;p&gt;To combat this we will take each n-sized window of training/testing data and normalize each one to reflect percentage changes from the start of that window (so the data at point i=0 will always be 0). We'll use the following equations to normalize and subsequently de-normalize at the end of the prediction process to get a real world number out of the prediction:&lt;/p&gt;
&lt;p&gt;n = normalized list [window] of price changes&lt;br/&gt;p = raw list [window] of adjusted daily return prices&lt;/p&gt;
&lt;p&gt;Normalization: &lt;img src=&quot;http://latex.codecogs.com/svg.latex?n_i=/Big(/frac{p_i}{p_0}/Big)-1&quot;/&gt;&lt;/p&gt;
&lt;p&gt;De-Normalization: &lt;img src=&quot;http://latex.codecogs.com/svg.latex?p_i=p_0(n_i+1)&quot;/&gt;&lt;/p&gt;
&lt;p&gt;We have added the normalise_windows() function to our DataLoader class to do this transformation, and a Boolean normalise flag is contained in the config file which denotes the normalization of these windows.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;python&quot;&gt;def normalise_windows(self, window_data, single_window=False):
        '''Normalise window with a base value of zero'''
        normalised_data = []
        window_data = [window_data] if single_window else window_data
        for window in window_data:
                normalised_window = [((float(p) / float(window[0])) - 1) for p in window]
                normalised_window = np.reshape(normalised_window, (len(normalised_window), 1))
                normalised_data.append(normalised_window)
        return np.array(normalised_data)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;With the windows normalized, we can now run the model in the same way that we ran it against out sinewave data. We have however made an important change when running this data; instead of using our framework's model.train() method, we are instead using the model.train_generator() method which we have created. We are doing this because we have found that it is easy to run out of memory when trying to train large datasets, as the model.train() function loads the full dataset into memory, then applies the normalizations to each window in-memory, easily causing a memory overflow. So instead we utilized the fit_generator() function from Keras to allow for dynamic training of the dataset using a python generator to draw the data, which means memory utilization will be minimized dramatically. The code below details the new run thread for running three types of predictions (point-by-point, full sequence and multiple sequence).&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;python&quot;&gt;configs = json.load(open('config.json', 'r'))

data = DataLoader(
        os.path.join('data', configs['data']['filename']),
        configs['data']['train_test_split'],
        configs['data']['columns']
)

model = Model()
model.build_model(configs)
x, y = data.get_train_data(
        seq_len = configs['data']['sequence_length'],
        normalise = configs['data']['normalise']
)

# out-of memory generative training
steps_per_epoch = math.ceil((data.len_train - configs['data']['sequence_length']) / configs['training']['batch_size'])
model.train_generator(
        data_gen = data.generate_train_batch(
                seq_len = configs['data']['sequence_length'],
                batch_size = configs['training']['batch_size'],
                normalise = configs['data']['normalise']
        ),
        epochs = configs['training']['epochs'],
        batch_size = configs['training']['batch_size'],
        steps_per_epoch = steps_per_epoch
)

x_test, y_test = data.get_test_data(
        seq_len = configs['data']['sequence_length'],
        normalise = configs['data']['normalise']
)

predictions_multiseq = model.predict_sequences_multiple(x_test, configs['data']['sequence_length'], configs['data']['sequence_length'])
predictions_fullseq = model.predict_sequence_full(x_test, configs['data']['sequence_length'])
predictions_pointbypoint = model.predict_point_by_point(x_test)        

plot_results_multiple(predictions_multiseq, y_test, configs['data']['sequence_length'])
plot_results(predictions_fullseq, y_test)
plot_results(predictions_pointbypoint, y_test)
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code class=&quot;json&quot;&gt;{
        &quot;data&quot;: {
                &quot;filename&quot;: &quot;sp500.csv&quot;,
                &quot;columns&quot;: [
                        &quot;Close&quot;
                ],
                &quot;sequence_length&quot;: 50,
                &quot;train_test_split&quot;: 0.85,
                &quot;normalise&quot;: true
        },
        &quot;training&quot;: {
                &quot;epochs&quot;: 1,
                &quot;batch_size&quot;: 32
        },
        &quot;model&quot;: {
                &quot;loss&quot;: &quot;mse&quot;,
                &quot;optimizer&quot;: &quot;adam&quot;,
                &quot;layers&quot;: [
                        {
                                &quot;type&quot;: &quot;lstm&quot;,
                                &quot;neurons&quot;: 100,
                                &quot;input_timesteps&quot;: 49,
                                &quot;input_dim&quot;: 1,
                                &quot;return_seq&quot;: true
                        },
                        {
                                &quot;type&quot;: &quot;dropout&quot;,
                                &quot;rate&quot;: 0.2
                        },
                        {
                                &quot;type&quot;: &quot;lstm&quot;,
                                &quot;neurons&quot;: 100,
                                &quot;return_seq&quot;: true
                        },
                        {
                                &quot;type&quot;: &quot;lstm&quot;,
                                &quot;neurons&quot;: 100,
                                &quot;return_seq&quot;: false
                        },
                        {
                                &quot;type&quot;: &quot;dropout&quot;,
                                &quot;rate&quot;: 0.2
                        },
                        {
                                &quot;type&quot;: &quot;dense&quot;,
                                &quot;neurons&quot;: 1,
                                &quot;activation&quot;: &quot;linear&quot;
                        }
                ]
        }
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Running the data on a single point-by-point prediction as mentioned above gives something that matches the returns pretty closely. But this is slightly deceptive. Upon a closer examination, the prediction line is made up of singular prediction points that have had the whole prior true history window behind them. Because of that, the network doesn't need to know much about the time series itself other than that each next point most likely won't be too far from the last point. So even if it gets the prediction for the point wrong, the next prediction will then factor in the true history and disregard the incorrect prediction, yet again allowing for an error to be made.&lt;/p&gt;
&lt;p&gt;Whilst this might not initially sound promising for exact forecasts of the next price point, it does have some important uses. Whilst it doesn't know what the exact next price will be, it does give a very accurate representation of the range that the next price should be in.&lt;/p&gt;
&lt;p&gt;This information can be used in applications like volatility forecasting (being able to predict a period of high or low volatility in the market can be extremely advantageous for a particular trading strategy), or moving away from trading this could also be used as a good indicator for anomaly detection. Anomaly detection could be achieved by predicting the next point, then comparing it to the true data when it comes in, and if the true data value is significantly different to the predicted point an anomaly flag could be raised for that data point.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.altumintelligence.com/assets/time-series-prediction-using-lstm-deep-neural-networks/sp500_pointbypoint.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;S&amp;amp;P500 point-by-point prediction&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Moving on to the full sequence prediction it seems like this proves to be the least useful prediction for this type of time series (at least trained on this model with these hyperparameters). We can see a slight bump on the start of the prediction where the model followed a momentum of some sorts, however very quickly we can see the model decided that the most optimal pattern was to converge onto some equilibrium of the time series. At this stage this might seem like it doesn't offer much value, however mean reversion traders might step in there to proclaim that the model is simply finding the mean that the price series will revert to when volatility is removed.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.altumintelligence.com/assets/time-series-prediction-using-lstm-deep-neural-networks/sp500_full.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;S&amp;amp;P500 full sequence prediction&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Lastly we have made a third type of prediction for this model, something I call a multi-sequence prediction. This is a blend of the full sequence prediction in the sense that it still initializes the testing window with test data, predicts the next point over that and makes a new window with the next point. However, once it reaches a point where the input window is made up fully of past predictions it stops, shifts forward one full window length, resets the window with the true test data, and starts the process again. In essence this gives multiple trend-line like predictions over the test data to be able to analyze how well the model can pick up future momentum trends.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.altumintelligence.com/assets/time-series-prediction-using-lstm-deep-neural-networks/sp500_multi.png&quot;/&gt;&lt;br/&gt;&lt;span&gt;S&amp;amp;P500 multi-sequence prediction&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can see from the multi-sequence predictions that the network does appear to be correctly predicting the trends (and amplitude of trends) for a good majority of the time series. Whilst not perfect, it does give an indication of the usefulness of LSTM deep neural networks in sequential and time series problems. Greater accuracy could most certainly be achieved with careful hyperparameter tuning.&lt;/p&gt;
&lt;br/&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Whilst this article aims to give a working example of LSTM deep neural networks in practice, it has only scratched the surface of their potential and application in sequential and temporal problems.&lt;/p&gt;
&lt;p&gt;As of writing, LSTMs have been successfully used in a multitude of real-world problems from classical time series issues as described here, to text auto-correct, anomaly detection and fraud detection, to having a core in self-driving car technologies being developed.&lt;/p&gt;
&lt;p&gt;There are currently some limitations with using the vanilla LSTMs described above, specifically in the use of a financial time series, the series itself has non-stationary properties which is very hard to model (although advancements have been made in using Bayesian Deep Neural Network methods for tackling non-stationarity of time series). Also for some applications it has also been found that newer advancements in attention based mechanisms for neural networks have out-performed LSTMs (and LSTMs coupled with these attention based mechanisms have outperformed either on their own).&lt;/p&gt;
&lt;p&gt;As of now however, LSTMs provide significant advancements on more classical statistical time series approaches in being able to model the relationships non-linearly and being able to process data with multiple dimensions in a non-linear fashion.&lt;/p&gt;
&lt;p&gt;The full source code of the framework we have developed can be found under an MIT license on the following GitHub page (we ask that credit is clearly attributed as &quot;Jakob Aungiers, Altum Intelligence ltd&quot; wherever this code is re-used): &lt;a href=&quot;https://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction&quot; target=&quot;_blank&quot;&gt;https://github.com/jaungiers/LSTM-Neural-Network-for-Time-Series-Prediction&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 02 Sep 2018 00:26:51 +0000</pubDate>
<dc:creator>shivinski</dc:creator>
<og:type>article</og:type>
<og:title>Time Series Prediction Using LSTM Deep Neural Networks</og:title>
<og:description>This article focuses on using an LSTM neural network architecture to provide time series forecasting using Keras and Tensorflow � specifically on stock market datasets to provide momentum indicators of stock price.</og:description>
<og:image>http://www.altumintelligence.com/assets/time-series-prediction-using-lstm-deep-neural-networks/og.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.altumintelligence.com/articles/a/Time-Series-Prediction-Using-LSTM-Deep-Neural-Networks</dc:identifier>
</item>
</channel>
</rss>