<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Ask HN: My Microsoft account has been suspended by Microsoft without details</title>
<link>https://news.ycombinator.com/item?id=17627093</link>
<guid isPermaLink="true" >https://news.ycombinator.com/item?id=17627093</guid>
<description>&lt;td colspan=&quot;2&quot;/&gt;&lt;td readability=&quot;40&quot;&gt;My entire Microsoft account has been suspended, due to the violation of the Terms, by Microsoft, and without any further details. At the time of incident, I was not doing with the account or anything digital, and rather was cooking/eating dinner, when my computer received a notification about a problem with my Microsoft account.
&lt;p&gt;I am not given any other options than to Contact Support about it, which I did yesterday and got an answer today that tells me nothing more than the very few that I know:&lt;/p&gt;
&lt;p&gt;&amp;gt; Microsoft disabled access to the account due to a serious violation of the Microsoft Services Agreement https://www.microsoft.com/en-us/servicesagreement. As stated in the Microsoft Services Agreement, you will no longer be able to access any Services that require Microsoft account. For any subscriptions associated with the account, Microsoft will immediately cease charging the credit card on file for recurring charges. [...] Pursuant to our terms, we cannot reactivate your account, nor provide details as to why it was closed. This represents Microsoft’s final communication regarding this account.&lt;/p&gt;
&lt;p&gt;I hope that I am not violating any other terms by sharing these messages. I do it out of frustration to know what exactly I might have done to deserve this, something more detailed than &quot;you have violated our Terms as you eat your dinner&quot;, because without knowing which action of mine caused this, I either;&lt;/p&gt;
&lt;p&gt;a) Will be unable to understand my mistake and not repeat it,&lt;/p&gt;
&lt;p&gt;b) Will fear out of doing nearly everything and refrain from them, such as using a VPN on Amazon's AWS at Ohio, which I am sincerely suspicious of.&lt;/p&gt;
&lt;p&gt;Microsoft's own way of justice is against the legal systems in all the modern countries, which always makes sure that the accused knows their faults, as one of their rights, and for the benefit of the accused not getting involved in such acts for a second time, for that they this time will know.&lt;/p&gt;
&lt;/td&gt;
</description>
<pubDate>Fri, 27 Jul 2018 16:21:48 +0000</pubDate>
<dc:creator>ThoAppelsin</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://news.ycombinator.com/item?id=17627093</dc:identifier>
</item>
<item>
<title>How did Google get so big?</title>
<link>https://www.cbsnews.com/news/how-did-google-get-so-big/</link>
<guid isPermaLink="true" >https://www.cbsnews.com/news/how-did-google-get-so-big/</guid>
<description>&lt;p&gt;This past week the Federal Trade Commission was asked to investigate the data collected by Google on its Android operating system, which powers most of the world's smartphones. It was a tiny blip in the news cycle but another sign of Washington's and Europe's growing concerns about the enormous, largely unchecked power accumulated by tech giants like Facebook, Amazon and Google over the last two decades. Of the three, Google, which is part of a holding company called Alphabet is the most powerful, intriguing, and omnipresent in our lives. This is how it came to be.&lt;/p&gt;
&lt;p&gt;Most people love Google. It's changed our world, insinuated itself in our lives, made itself indispensable. You probably don't even have to type Google.com into your computer, it's often the default setting, a competitive advantage Google paid billions of dollars for. No worry. Google is worth more than three-quarters of a trillion dollars right now and you don't get that big by accident.&lt;/p&gt;
&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://cbsnews1.cbsistatic.com/hub/i/r/2018/05/20/5b536602-9b93-4819-b81e-f2d30598d16b/resize/770x/04e374d94a21c21481d2895374aff233/google-mobile-search.jpg#&quot; alt=&quot;google-mobile-search.jpg &quot; srcset=&quot;https://cbsnews1.cbsistatic.com/hub/i/r/2018/05/20/5b536602-9b93-4819-b81e-f2d30598d16b/resize/770x/04e374d94a21c21481d2895374aff233/google-mobile-search.jpg 1x&quot;/&gt;&lt;/span&gt;

&lt;p&gt;Since going public in 2004, Google has acquired more than 200 companies, expanding its reach across the internet. It bought YouTube, the biggest video platform. It bought Android, the operating system that runs 80% of the world's smartphones and it bought DoubleClick, which distributes much of the world's digital advertising, all of this barely raising an eyebrow with regulators in Washington.&lt;/p&gt;
&lt;p&gt;Steve Kroft: Were any of those acquisitions questioned by the antitrust division of the Justice Department?&lt;/p&gt;
&lt;p&gt;Gary Reback: Some were investigated, but only superficially, the government just really isn't enforcing our antitrust laws. And that's what's happened. None of these acquisitions have been challenged.&lt;/p&gt;
&lt;p&gt;Gary Reback is one of the most prominent antitrust lawyers in the country widely credited with persuading the Justice Department to sue Microsoft back in the 90s, the last major antitrust case against big tech. Now he is battling Google.&lt;/p&gt;
&lt;p&gt;Steve Kroft: You think Google's a monopoly?&lt;em&gt; &lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Gary Reback: Oh, yes, of course Google's a monopoly. In fact they're a monopoly in several markets. They're a monopoly in search. They're a monopoly in search advertising.&lt;/p&gt;
&lt;p&gt;Those technologies are less than 25 years old, and may seem small compared to the industrial monopolies like railroads and standard oil a century ago but Reback says there's nothing small about Google.&lt;/p&gt;
&lt;h4&gt;&quot;People tell their search engine things they wouldn't even tell their wives... And that gives the company that controls it a mind-boggling degree of control over our entire society&lt;strong&gt;.&quot;&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Gary Reback: Google makes the internet work. The internet would not be accessible to us without a search engine&lt;/p&gt;
&lt;p&gt;Steve Kroft: And they control it.&lt;/p&gt;
&lt;p&gt;Gary Reback: They control access to it. That's the important part. Google is the gatekeeper for-- for the World Wide Web, for the internet as we know it. It is every bit as important today as petroleum was when John D. Rockefeller was monopolizing that.&lt;em&gt; &lt;br/&gt;&lt;/em&gt;&lt;/p&gt;
&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://cbsnews3.cbsistatic.com/hub/i/r/2018/05/20/bccce213-ffb4-40be-9719-87a2950b1fcf/resize/770x/2c0c4b06d2a9a6a1dcddaea5ff1e68ab/gary-reback.jpg#&quot; alt=&quot;gary-reback.jpg &quot; srcset=&quot;https://cbsnews3.cbsistatic.com/hub/i/r/2018/05/20/bccce213-ffb4-40be-9719-87a2950b1fcf/resize/770x/2c0c4b06d2a9a6a1dcddaea5ff1e68ab/gary-reback.jpg 1x&quot;/&gt;&lt;/span&gt;
&lt;div class=&quot;caption&quot; readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;em&gt;Gary Reback, an antitrust lawyer who persuaded the Justice Department to sue Microsoft in the 90s&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;CBS News&lt;/p&gt;
&lt;p&gt;Last year, Google conducted 90% of the world's internet searches. When billions of people asked trillions of questions it was Google that provided the answers using computer algorithms known only to Google.&lt;/p&gt;
&lt;p&gt;Jonathan Taplin: They have this phrase they use, &quot;competition is just a click away.&quot; They have no competition. Bing, their competition, has 2% of the market. They have 90%.&lt;/p&gt;
&lt;p&gt;Jonathan Taplin is a digital media expert and director emeritus of the Annenberg Innovation Lab at the University of Southern California.  He says Google's expertise may be technology, but its business is advertising. And its most valuable commodity is highly specialized information about us. It's helped Google control roughly 60% of worldwide advertising revenue on the internet. Taplin says traditional companies can't compete because they don't have the data.&lt;/p&gt;
&lt;p&gt;Jonathan Taplin: They know who you are, where you are, what you just bought, what you might wanna buy. And so if I'm an advertiser and I say, &quot;I want 24-year-old women in Nashville, Tennessee who drive trucks and drink bourbon,&quot; I can do that on Google.&lt;/p&gt;
&lt;p&gt;Gary Reback: People tell their search engines things they wouldn't even tell their wives. I mean, it's a very powerful and yet very intimate technology. And that gives the company that controls it a mind-boggling degree of control over our entire society&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Google is so dominant in search and search advertising that analysts and venture capitalists in Silicon Valley say it's extremely difficult for startups to get funding if their business model requires them to compete with Google for ad revenue.&lt;/p&gt;
&lt;p&gt;Jeremy Stoppelman co-founded Yelp more than a decade ago -- a website that collects local reviews on everything from auto mechanics to restaurants nationwide and makes money selling ads.&lt;/p&gt;
&lt;p&gt;Jeremy Stoppelman: The initial promise of Google was to organize the world's information. And ultimately that manifested itself in you expecting that the top links, the things that it shows at the top of that page are the best from around the web. The best that the world has to offer. And I could tell you that is not the case. That is not the case anymore.&lt;/p&gt;
&lt;p&gt;Instead of doing what's best for consumers, Stoppelman says Google is doing what's best for Google.&lt;/p&gt;
&lt;p&gt;Jeremy Stoppelman: If I were starting out today, I would have no shot of building Yelp. That opportunity has been closed off by Google and their approach.&lt;/p&gt;
&lt;p&gt;Steve Kroft: In what way?&lt;/p&gt;
&lt;p&gt;Jeremy Stoppelman: Because if you provide great content in one of these categories that is lucrative to Google, and seen as potentially threatening, they will snuff you out.&lt;/p&gt;
&lt;p&gt;Steve Kroft: What do you mean snuff you out?&lt;/p&gt;
&lt;p&gt;Jeremy Stoppelman: They will make you disappear. They will bury you.&lt;/p&gt;
&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://cbsnews1.cbsistatic.com/hub/i/r/2018/05/20/5aa54a5d-35d1-44b6-8b97-c1f3223d0e92/resize/770x/23949d2e2d6cc3b06bc2bf8daee29fbd/jeremy-stoppleman.jpg#&quot; alt=&quot;jeremy-stoppleman.jpg &quot; srcset=&quot;https://cbsnews1.cbsistatic.com/hub/i/r/2018/05/20/5aa54a5d-35d1-44b6-8b97-c1f3223d0e92/resize/770x/23949d2e2d6cc3b06bc2bf8daee29fbd/jeremy-stoppleman.jpg 1x&quot;/&gt;&lt;/span&gt;
&lt;div class=&quot;caption&quot; readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;em&gt;Jeremy Stoppelman, co-founder of Yelp&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;CBS News&lt;/p&gt;
&lt;p&gt;Yelp and countless other sites depend on Google to bring them web traffic – eyeballs for their advertisers. But now Stoppelman says their biggest competitor in the most lucrative markets is Google. He says it's collecting and bundling its own information on things like shopping and travel and putting it at the very top of the search results, regardless of whether it belongs there on merit. He showed us how it worked by Googling sushi San Francisco.&lt;/p&gt;
&lt;p&gt;Jeremy Stoppelman: All the prime real estate is here. This is where the consumer, their eye focuses. And that's by design; Google wants you to pay attention to their content.&lt;/p&gt;
&lt;p&gt;All of the information here is owned by Google from the maps to the reviews.  Stoppelman says if you click on any of these links at the top of the page you may think you've gone to another website but in fact you will still be on Google, seeing what it wants you to see while it collects your personal information and maybe exposes you to Google advertising.&lt;/p&gt;
&lt;p&gt;Steve Kroft: If you click anything inside this box, you stay on Google and they make more money?&lt;/p&gt;
&lt;p&gt;Jeremy Stoppelman: That's right.&lt;/p&gt;
&lt;h4&gt;&quot;Google wields enormous power across the industry. And they set the rules. The question is who's watching Google?&quot;&lt;/h4&gt;
&lt;p&gt;Google told us it doesn't have anything to do with money, it's about improving its product by making searches quicker and easier for its customers by eliminating the need to click through lots of other sites.&lt;/p&gt;
&lt;p&gt;Stoppelman says it's about stifling competition, pushing it down the page where it's less likely to be seen. The advantage, he says, is even more striking if you look at the search results on a smartphone.&lt;/p&gt;
&lt;p&gt;Jeremy Stoppelman: This is exactly what your phone would look like in the palm of your hand. This is all of Google's own property, right here. It takes up the entire screen.&lt;/p&gt;
&lt;p&gt;Steve Kroft: How important is that first page?&lt;/p&gt;
&lt;p&gt;Jeremy Stoppelman: It's not even just the first page, it's the first few links on the page is the vast majority of where user attention goes, and where the traffic flows.&lt;/p&gt;
&lt;p&gt;Steve Kroft: So if you're not at the top of the page or at the bottom of the first page, or on the second page, that's gonna affect your business?&lt;/p&gt;
&lt;p&gt;Jeremy Stoppelman: Yeah, if you're on the second page, forget it you're not a real business.&lt;/p&gt;
&lt;p&gt;Yelp, Microsoft, Amazon, eBay, Expedia, and Yahoo all complained about Google's dominance and what they called its anti-competitive behavior to the Federal Trade Commission, which in 2011 conducted an investigation.&lt;/p&gt;
&lt;p&gt;According to a confidential memo – parts of which were inadvertently given to the Wall Street Journal years later – the FTC's Bureau of Competition had recommended that an antitrust lawsuit be filed against Google for some of its business practices. It said &quot;Google is in the unique position of being able to 'make or break any web-based business'&quot; and &quot;has  strengthened its monopolies over search and search advertising through anti-competitive means&quot; and &quot;forestalled competitors and would-be competitors' ability to challenge those monopolies.&quot; It specifically cited Google for stealing competitors' content, and imposing restrictions on advertisers and other websites that limited their ability to utilize other search engines. But the recommendations were rejected.&lt;/p&gt;
&lt;p&gt;Gary Reback: It flatly says that Google's conduct was anti-competitive. It flatly says that Google's conduct hurt consumers. I mean, what else would you need to know to vote out a complaint? There it is, written by your own staff. And yet, nothing happened.&lt;/p&gt;
&lt;p&gt;Steve Kroft: They closed the case?&lt;/p&gt;
&lt;p&gt;Gary Reback: They closed the case, correct&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The FTC's commissioners decided that Google's conduct could be addressed with voluntary improvements to some of its business practices - and that Google's decision to move its own products to the top of the search page could plausibly be of benefit to consumers. But Reback and others who were directly involved in the investigation have long suspected that the outcome had something to do with Google's political muscle in Washington and its close relationship with the Obama administration. Google spent more money on lobbying last year than any other corporation, employing 25 different firms and helping fund 300 trade associations, think tanks and other groups many of which influence policy.&lt;/p&gt;
&lt;p&gt;Gary Reback: They have a seat at the table in every discussion that implicates this issue at all. They know about developments that we never even hear about. So their influence – from my perspective is very, very difficult to challenge.&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Right now the only one taking aggressive action against Google and the power of big tech is Margrethe Vestager, the competition commissioner for the European Union. During her four years in office, Vestager has become a thorn in the side of Silicon Valley, fining Facebook $122 million for a merger violation and ordering Ireland to recover $15 billion in taxes owed by Apple. Last summer she levied a record $2.7 billion fine against Google for depriving certain competitors of a chance to compete with them.&lt;/p&gt;
&lt;span class=&quot;img&quot;&gt;&lt;img src=&quot;https://cbsnews2.cbsistatic.com/hub/i/r/2018/05/20/e9e5d34a-1698-4d85-9d5c-4e2dbdc7daf7/resize/770x/0e411255b34ca481d44af3180ecf62ea/margrethe-vestager.jpg#&quot; alt=&quot;margrethe-vestager.jpg &quot; srcset=&quot;https://cbsnews2.cbsistatic.com/hub/i/r/2018/05/20/e9e5d34a-1698-4d85-9d5c-4e2dbdc7daf7/resize/770x/0e411255b34ca481d44af3180ecf62ea/margrethe-vestager.jpg 1x&quot;/&gt;&lt;/span&gt;
&lt;div class=&quot;caption&quot; readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;em&gt;Margrethe Vestager, the competition commissioner for the European Union&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;CBS News&lt;/p&gt;
&lt;p&gt;Margrethe Vestager: Just as well as I admire some of the innovation by Google over the last decade-- well, I want their illegal behavior to stop.&lt;/p&gt;
&lt;p&gt;Steve Kroft: And that's what you feel has gone on.&lt;/p&gt;
&lt;p&gt;Margrethe Vestager: Not only do we feel it, we mean that we can prove it.&lt;em&gt; &lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In researching the case, Vestager says her staff went through 1.7 billion Google search queries and found that Google was manipulating its secret search formulas—or algorithms—to promote its own products and services and sending its competitors into oblivion.&lt;/p&gt;
&lt;p&gt;Margrethe Vestager: It's very difficult to find the rivals. Because on average, you'd find them only on page four in your search results.&lt;/p&gt;
&lt;p&gt;Steve Kroft: And why so far down?&lt;/p&gt;
&lt;p&gt;Margrethe Vestager: Well, because then you don't find them. I don't-- I don't know anyone who goes to page four in their search result. The-- jokingly, you could say that this is where you should keep your secrets. Because no one ever comes there.&lt;/p&gt;
&lt;p&gt;Steve Kroft: Do you think this has been deliberate on Google's part?&lt;/p&gt;
&lt;p&gt;Margrethe Vestager: Yes. We think that this is done on purpose.&lt;/p&gt;
&lt;p&gt;Steve Kroft: How do they do it? I think everybody has this idea that Google has this algorithm. And they put the best searches right at the top.&lt;/p&gt;
&lt;p&gt;Margrethe Vestager: Well, it is exactly the algorithm that does it. Both the-- the promotion of Google themselves and the demotion of others.&lt;/p&gt;
&lt;p&gt;Steve Kroft: So, they're rigging the game.&lt;/p&gt;
&lt;p&gt;Margrethe Vestager: Yes. And it is illegal.&lt;/p&gt;
&lt;p&gt;Google has paid its 2.7 billion fine and is aggressively appealing the decision. But for now, Stoppelman says everyone is still playing by Google's rules.&lt;/p&gt;
&lt;p&gt;Steve Kroft: If you're in business, you have to be on Google.&lt;/p&gt;
&lt;p&gt;Jeremy Stoppelman: Yeah. Google wields enormous power across the industry. And they set the rules. The question is who's watching Google?&lt;/p&gt;
&lt;p&gt;Google declined our request for an interview with one of its executives for this story, but in a written response to our questions, the company denied it was a monopoly in search or search advertising, citing many competitors including Amazon and Facebook. It says it does not make changes to its algorithm to disadvantage competitors and that, &quot;our responsibility is to deliver the best results possible to our users, not specific placements for sites within our results. We understand that those sites whose ranking falls will be unhappy and may complain publicly.&quot;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Produced by Maria Gavrilovic. Associate producer, Alex Ortiz.&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 27 Jul 2018 15:58:21 +0000</pubDate>
<dc:creator>jonwachob91</dc:creator>
<og:type>article</og:type>
<og:url>https://www.cbsnews.com/news/how-did-google-get-so-big/</og:url>
<og:title>How did Google get so big?</og:title>
<og:description>60 Minutes reports on the power of Google, a company whose critics say has stifled competition</og:description>
<og:image>https://cbsnews1.cbsistatic.com/hub/i/r/2018/05/20/231e6574-1204-405d-9e65-c6cf1e194695/thumbnail/1200x630/58906fffc8546e8b22bbb9bc6e77f61d/googlefull.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cbsnews.com/news/how-did-google-get-so-big/</dc:identifier>
</item>
<item>
<title>MoviePass couldn’t afford to pay for movie tickets on Thursday</title>
<link>https://money.cnn.com/2018/07/27/media/moviepass-service-outage/index.html</link>
<guid isPermaLink="true" >https://money.cnn.com/2018/07/27/media/moviepass-service-outage/index.html</guid>
<description>&lt;div id=&quot;js-ie-storytop&quot; class=&quot;ie--storytop&quot;&gt;&lt;div class=&quot;cnnplayer&quot; id=&quot;cnnplayer0&quot;&gt;
&lt;div class=&quot;cnnVidplayer&quot;&gt;
&lt;div class=&quot;summaryImg&quot; id=&quot;vid0&quot; href=&quot;/video/technology/2018/05/31/cloud-seeding-rain-snow-weather-modification.cnnmoney&quot;&gt;&lt;img src=&quot;https://i2.cdn.turner.com/money/dam/assets/171016102155-moviepass-logo-1024x576.jpg&quot; width=&quot;780&quot; height=&quot;439&quot; alt=&quot;MoviePass CEO: 'We have been so surprised by the growth rate'&quot; border=&quot;0&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class=&quot;speakable&quot;&gt;MoviePass is on life support.&lt;/h2&gt;
&lt;p class=&quot;speakable&quot;&gt;Helios and Matheson, the parent company of the popular movie subscription service, said that it had a service outage on Thursday because it couldn't afford to pay for movie tickets. The company borrowed $5 million in cash Friday to pay its merchant and fulfillment processors, according to a &lt;a href=&quot;https://www.sec.gov/Archives/edgar/data/1040792/000121390018009741/f8k072618_heliosmatheson.htm&quot; target=&quot;_blank&quot;&gt;regulatory filing&lt;/a&gt;.&lt;/p&gt;

&lt;p class=&quot;speakable&quot;&gt;Helios and Matheson missed a payment to one of its fulfillment processors, and that contractor temporarily refused to process payments for MoviePass.&lt;/p&gt;
&lt;p&gt;Some customers complained on social media Thursday that they couldn't use their MoviePass accounts to purchase movie tickets at theaters.&lt;/p&gt;
&lt;p&gt;By Friday afternoon, MoviePass said that its app was &quot;now up-and-running with stability at 100%.&quot;&lt;/p&gt;

&lt;p&gt;In a letter to subscribers, the company apologized for the outage.&lt;/p&gt;
&lt;p&gt;&quot;We ask for your understanding and vocal support during this time, as we continue to fundamentally change an industry that hasn't evolved much in years,&quot; it said.&lt;/p&gt;
&lt;p&gt;Stock in Helios and Matheson, meanwhile, tanked Friday from nearly $7 at market open to $2.&lt;/p&gt;
&lt;p&gt;The company approved a reverse stock split earlier this week to boost the price from 8 cents to $21 in an effort to keep it from falling off the Nasdaq stock exchange.&lt;/p&gt;
&lt;p&gt;The price has been in freefall ever since. If valued at its pre-split amount, Friday's closing price would be equivalent to less than a penny.&lt;/p&gt;


&lt;p&gt;&lt;span class=&quot;cnnStorySource&quot;&gt;CNNMoney (New York)&lt;/span&gt; &lt;span class=&quot;cnnDateStamp&quot;&gt;First published July 27, 2018: 11:21 AM ET&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 27 Jul 2018 15:36:36 +0000</pubDate>
<dc:creator>gbear605</dc:creator>
<og:title>MoviePass couldn't afford to pay for movie tickets on Thursday</og:title>
<og:type>article</og:type>
<og:url>https://money.cnn.com/2018/07/27/media/moviepass-service-outage/index.html</og:url>
<og:image>https://i2.cdn.turner.com/money/dam/assets/171016102155-moviepass-logo-780x439.jpg</og:image>
<og:description>The company borrowed money to pay its merchant and fulfillment processors, according to a regulatory filing.</og:description>
<dc:format>text/html</dc:format>
<dc:identifier>https://money.cnn.com/2018/07/27/media/moviepass-service-outage/index.html</dc:identifier>
</item>
<item>
<title>The last thing libraries need is Silicon Valley “disruption.”</title>
<link>https://www.vox.com/first-person/2018/7/26/17616516/amazon-silicon-valley-libraries-forbes</link>
<guid isPermaLink="true" >https://www.vox.com/first-person/2018/7/26/17616516/amazon-silicon-valley-libraries-forbes</guid>
<description>&lt;p id=&quot;CjwLa5&quot;&gt;In an opinion column published on Forbes on Saturday, a professor of economics argued that local public libraries should be replaced by Amazon. The essay, which sparked so much controversy that Forbes removed it from its website on Monday, argued, “At the core, Amazon has provided something better than a local library without the tax fees. The move would save taxpayers money and enhance the stockholder value of Amazon all in one fell swoop.”&lt;/p&gt;
&lt;p id=&quot;O0AUgd&quot;&gt;As someone who has worked in libraries for seven years, the suggestion that Amazon could be a &lt;em&gt;better&lt;/em&gt; provider than a library is unfathomable. Amazon charges people who want access to art and entertainment. By offering anybody free access to a massive collection of books, music, and movies, libraries fundamentally advance the idea that culture is a public good that everybody has a right to enjoy, regardless of their income. For anyone who believes in the power of art to change and enhance our lives, the idea that it should only be available to people who can pay for it is horrifying.&lt;/p&gt;
&lt;p id=&quot;Dw8LnL&quot;&gt;But libraries are not just a place to find books — they’re one of the few places that provide a number of free services to the American public. They offer a safe public space for people to gather, computer and internet access to those who don’t have it, story time for children, a safe space for teens, resources for the unemployed and homeless. Writer Panos Mourdoukoutas seemed to grossly underestimate just how much libraries and librarians provide to the public.&lt;/p&gt;
&lt;h3 id=&quot;enLroq&quot;&gt;Some two-thirds of my patrons are homeless or struggling with addiction&lt;/h3&gt;
&lt;p id=&quot;633IQh&quot;&gt;I work as a librarian in downtown Washington, DC, in a branch that serves nearly 100,000 visitors each year. My location is a “single-service desk,” meaning we only have one circulation desk that serves all visitors. Some two-thirds of our regular patrons fall into one of three categories: homeless, struggling with addiction, or recovering from addiction.&lt;/p&gt;
&lt;p id=&quot;WMtUqD&quot;&gt;Our library provides a space where they can use free computers and wifi, as well as access a climate-controlled environment with clean bathrooms and water. Many of our patrons arrive first thing in the morning from a homeless shelter and stay until a shuttle picks them up to take them back in the evening.&lt;/p&gt;
&lt;p id=&quot;zFT64i&quot;&gt;We know their names. We speak to the shelters or outreach programs when we haven’t seen them in a while. We ask other patrons about them to make sure they’re okay. We help them fill out free or low-income housing forms, which are often complicated and overwhelming. Sometimes this means showing them how to access and fill out an online PDF, sitting with them at a table for an hour to sort through the various documents they need, helping them use our free scanner to upload documents, and ensuring they’ve submitted everything correctly.&lt;/p&gt;
&lt;p id=&quot;kTMTwB&quot;&gt;We keep a four-page packet at the desk to hand out to our patrons experiencing homelessness — it’s a list we’ve put together of local shelters, food sources, open bathrooms and showers, and free legal services.&lt;/p&gt;
&lt;p id=&quot;60FBvO&quot;&gt;We help them find secure employment by offering free résumé building and editing services and walking them through the job hunting and application process. We provide the computers and free printing they need to go on interviews.&lt;/p&gt;
&lt;p id=&quot;M99MBn&quot;&gt;There are new immigrants who ask about visas. We show them the correct websites to go to, we help them translate the pages, and we teach them how to scan and email the necessary documents. We also provide an invaluable translation service: Any library patron who speaks a language other than English can access a free live translator through a phone service to communicate with us.&lt;/p&gt;
&lt;p id=&quot;EpOLBh&quot;&gt;There are mothers and fathers and grandparents and foster parents and nannies and children and schools who attend twice-weekly story times I lead. Many of them acknowledge this as some of the only time they spend out of the house socializing. It’s a rare place that creates a sense of community that bridges socioeconomic gaps.&lt;/p&gt;
&lt;h3 id=&quot;UtFEbp&quot;&gt;Libraries are one of the few public goods we’ve got left&lt;/h3&gt;
&lt;p id=&quot;HF7A5U&quot;&gt;I’ve often heard the argument, “That’s not the library’s job. There are agencies for that.”&lt;/p&gt;
&lt;p id=&quot;Q3X6rE&quot;&gt;But where are people without access to computers or internet supposed to go to find the agencies that will help them job-search or secure low-income housing? Where can they go to sit down and figure out their next steps, with knowledgeable help close by?&lt;/p&gt;
&lt;p id=&quot;i63qfN&quot;&gt;We search for the correct offices. We print Google maps with walking or bus instructions. We give them a running start in helping improve their lives. In a world heavily skewed toward people who can pay for access to resources, we do what we can to provide equity.&lt;/p&gt;
&lt;p id=&quot;f28iSk&quot;&gt;Just this week, a woman stopped by our desk because she needed to be taught how to open a new tab in an internet browser. She returned a few minutes later and said, “Please write ‘stomach ache’ on this piece of paper for me. I don’t know to spell it.” The man waiting behind her had no idea how to open an internet browser to begin his first job search in years. I walked him through the process and helped him get to a job site. This was a few minutes of a 40-hour workweek.&lt;/p&gt;
&lt;p id=&quot;Aw0I6f&quot;&gt;I can’t imagine where this woman and this man would go without the library. Would Amazon really be willing to help them with all of their needs free of charge?&lt;/p&gt;
&lt;h3 id=&quot;ItEF8o&quot;&gt;The last thing libraries need is Silicon Valley “disruption”&lt;/h3&gt;
&lt;p id=&quot;CXlWTy&quot;&gt;Amazon is a corporation. Profit is at the center of its ethos. Fundamentally, it is not here to provide a public good: It exists to make money. Even when presenting a charitable front, like Amazon’s Smile campaign, which donates only around 10 cents per $20 spent, it still benefits from the majority of its profits. At its core, Amazon is about providing services to people who can pay for them.&lt;/p&gt;
&lt;p id=&quot;6dzrRt&quot;&gt;Libraries and librarians fill in the significant gaps created by what I would argue is our society’s pandemic of ignoring our impoverished, underserved, and most vulnerable populations. Our government continues to take away from our public services — national parks, arts programs, museums funding, aid for children with disabilities.&lt;/p&gt;
&lt;p id=&quot;VEecjT&quot;&gt;I refuse to accept that everything must be “disrupted” and turned into a moneymaking machine for tech elites. It’s absurd to suggest that Silicon Valley look to profit from one of the few institutions available across the entire country that doesn’t exist to make money for someone else.&lt;/p&gt;
&lt;p id=&quot;K4c3W6&quot;&gt;Libraries are irreplaceable. Either discuss providing more funding for the invaluable work we do, or leave them alone.&lt;/p&gt;
&lt;p id=&quot;SuoAL1&quot;&gt;&lt;em&gt;Amanda Oliver is a writer and librarian. She is currently an MFA candidate in creative nonfiction at UC Riverside. You can find more of her writing at&lt;/em&gt; &lt;a href=&quot;http://amandaoliver.com/&quot;&gt;&lt;em&gt;AmandaOliver.com&lt;/em&gt;&lt;/a&gt; &lt;em&gt;or subscribe to her&lt;/em&gt; &lt;a href=&quot;http://tinyletter.com/decorouslines&quot;&gt;&lt;em&gt;Tinyletter email newsletter&lt;/em&gt;&lt;/a&gt;&lt;em&gt;, where she often writes about being a librarian.&lt;/em&gt;&lt;/p&gt;
&lt;hr class=&quot;p-entry-hr&quot; id=&quot;ZYUqOD&quot;/&gt;&lt;p id=&quot;kE2tCk&quot;&gt;&lt;a href=&quot;http://www.vox.com/first-person&quot;&gt;&lt;strong&gt;First Person&lt;/strong&gt;&lt;/a&gt; is Vox’s home for compelling, provocative narrative essays. Do you have a story to share? Read our &lt;a href=&quot;http://www.vox.com/2015/6/12/8767221/vox-first-person-explained&quot;&gt;&lt;strong&gt;submission guidelines&lt;/strong&gt;&lt;/a&gt;, and pitch us at &lt;a href=&quot;mailto:firstperson@vox.com&quot;&gt;&lt;strong&gt;firstperson@vox.com&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>Fri, 27 Jul 2018 14:05:50 +0000</pubDate>
<dc:creator>naters</dc:creator>
<og:description>A Forbes column arguing that Amazon should replace libraries grossly underestimates how many services libraries offer.</og:description>
<og:image>https://cdn.vox-cdn.com/thumbor/zpx2uNLJ-sdGvFOfmBN9q7QNmps=/0x370:3264x2079/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/11756299/GettyImages_688060661.jpg</og:image>
<og:title>&quot;I’m a librarian. The last thing we need is Silicon Valley ‘disruption.’&quot;</og:title>
<og:type>article</og:type>
<og:url>https://www.vox.com/first-person/2018/7/26/17616516/amazon-silicon-valley-libraries-forbes</og:url>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.vox.com/first-person/2018/7/26/17616516/amazon-silicon-valley-libraries-forbes</dc:identifier>
</item>
<item>
<title>ActivityPub could be the future</title>
<link>https://blog.digitalscofflaw.com/articles/activitypub-could-be-the-future/</link>
<guid isPermaLink="true" >https://blog.digitalscofflaw.com/articles/activitypub-could-be-the-future/</guid>
<description>&lt;div id=&quot;&quot;&gt;&lt;header&gt;&lt;hgroup id=&quot;brand&quot;&gt;
&lt;h5&gt;&lt;time datetime=&quot;2018-07-25 20:36:53 +0000 UTC&quot;&gt;Jul 25, 2018&lt;/time&gt;&lt;/h5&gt;
&lt;/hgroup&gt;&lt;hr class=&quot;sep&quot;/&gt;&lt;/header&gt;&lt;p&gt;&lt;span class=&quot;no-print&quot;&gt;I’ll admit, I’ve spent the last several years disillusioned with technology. All the quirky little tools people made gave way to ad-fueled companies that refused to play well with others.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;no-print&quot;&gt;This is the first time I’ve been excited for a new technology in memory.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;no-print&quot;&gt;ActivityPub is to HTTP what HTTP was to TCP/IP. TCP/IP bridged disparate systems and allowed them to communicate reliably. HTTP allowed the various services built on TCP/IP to communicate with each other reliably.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;no-print&quot;&gt;ActivityPub goes one step further and provides a way for users on those services to communicate in a way that has the appearance of directness. I can follow, for example, Blender’s videos on PeerTube from my Mastodon account. Or I can use a blog platform that speaks ActivityPub and let people follow it from other services. It’s all the best features of Twitter with the flexibility of RSS. And unlike Twitter, your Mastodon profile will probably never lose its RSS feed in a company’s pursuit of profit. The main project already funds itself through Patreon, as do most of the larger instances.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;no-print&quot;&gt;It’s still early. We could be looking at a situation like Usenet and Gopher where neither ended up being The Thing because AOL soaked up the nascent public internet, then Facebook soaked up the nascent commercial web.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;no-print&quot;&gt;Right now the popularity of Mastodon carries ActivityPub while projects like Plume (blogging), Pixelfed (image sharing), and others work toward their potential.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;no-print&quot;&gt;I have noticed a tendency for people supporting older, similar protocols to wonder why ActivityPub got so popular while their own stagnated. We could speculate. If people knew Ostatus at all, they understood it as a protocol for making Twitter clones. XMPP spoke XML in an age of JSON, and it was perceived as an instant messenger protocol.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;no-print&quot;&gt;Both focused on liberating people from commercial silos. Mastodon had some press to that effect regarding Twitter, but people on there have come to care less as its native and diverse community grows to a self-sufficient level.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;no-print&quot;&gt;Twitter and Facebook are struggling to cope with their place in a massive cultural shift and shaky transfer of generational power. As I write this, Facebook has just lost 25% of its share price on the announcement that it expects weak growth.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;no-print&quot;&gt;I think the growing ActivityPub federation has a good chance. No one interacts with my tweets anymore. Meanwhile, I get response on Mastodon that reminds me of the early days of Twitter, before they betrayed their developer community and hired a legion of people to cut ad deals.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;&lt;p&gt;&lt;span class=&quot;no-print&quot;&gt;You can sign up for infrequent news about what I'm up to with the form below.&lt;/span&gt;&lt;/p&gt;</description>
<pubDate>Fri, 27 Jul 2018 10:32:31 +0000</pubDate>
<dc:creator>jaywink</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.digitalscofflaw.com/articles/activitypub-could-be-the-future/</dc:identifier>
</item>
<item>
<title>Membrane Framework – An Elixir framework for multimedia streaming applications</title>
<link>https://www.membraneframework.org</link>
<guid isPermaLink="true" >https://www.membraneframework.org</guid>
<description>&lt;p&gt;FFmpeg is a vast library, containing multiple stream processing tools. It exports a low-level API in C, thus making it possible to do almost anything with multimedia, it requires significant effort to develop various non-trivial solutions, such as establishing a complex live stream. The Membrane Framework provides a high-level API in Elixir, which enables it to make linking following elements comfortable and convenient, taking care of fluent data flow, concurrency and fault tolerance. While supported tools are not as numerous as in case of FFmpeg, making them work with one another is straightforward, the way they cooperate is configurable, and if needed new ones can be implemented without pain. It is also possible to wrap functionality of other libraries, such as FFmpeg, in Membrane elements.&lt;/p&gt;
</description>
<pubDate>Fri, 27 Jul 2018 09:54:10 +0000</pubDate>
<dc:creator>thibaut_barrere</dc:creator>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.membraneframework.org/</dc:identifier>
</item>
<item>
<title>Russ Cox on Go dependency management</title>
<link>https://threadreaderapp.com/thread/1022588240501661696.html</link>
<guid isPermaLink="true" >https://threadreaderapp.com/thread/1022588240501661696.html</guid>
<description>&lt;div readability=&quot;34&quot;&gt;Batman Returns,&lt;p&gt;I am watching it,&lt;/p&gt;&lt;p&gt;I'm going to a mythological/archetypal breakdown of the film as I watch it.&lt;/p&gt;&lt;p&gt;You all will learn something&lt;/p&gt;&lt;/div&gt;&lt;div readability=&quot;43&quot;&gt;The opening scene and cinematics are quite atmospheric,&lt;p&gt;Tim Burton is masterful in establishing the tonality of a &quot;world&quot; very quickly&lt;/p&gt;&lt;p&gt;It opens with the Birth of a Monster, the Penguin&lt;/p&gt;&lt;p&gt;We dont &quot;see&quot; the monster&lt;/p&gt;&lt;p&gt;it is Implied, as monsters often are&lt;/p&gt;&lt;/div&gt;&lt;div readability=&quot;39&quot;&gt;This monster (the Penguin) is a Rejected Son,&lt;p&gt;this is a common villain archetype,&lt;/p&gt;&lt;p&gt;The Rejected Child that later on goes to hurt the world in vengeance for not being loved by the parents&lt;/p&gt;&lt;/div&gt;</description>
<pubDate>Fri, 27 Jul 2018 02:25:38 +0000</pubDate>
<dc:creator>aberoham</dc:creator>
<og:title>Thread by @_rsc: &quot;@mattfarina @Crell @sdboyer This is an absolutely fair criticism - we have not handled the community process around dependency management we […]&quot;</og:title>
<og:image>https://threadreaderapp.com/images/screenshots/thread/1022588240501661696.jpg</og:image>
<og:url>https://threadreaderapp.com/thread/1022588240501661696.html</og:url>
<og:description>Thread by @_rsc: &quot;@mattfarina @Crell @sdboyer This is an absolutely fair criticism - we have not handled the community process around dependegement well. The core Go team was not involved early or often enough for that process to lead to a smooth lan […]&quot;</og:description>
<og:type>article</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://threadreaderapp.com/thread/1022588240501661696.html</dc:identifier>
</item>
<item>
<title>Zulip – Open-source, threading-based Slack alternative</title>
<link>https://zulipchat.com/</link>
<guid isPermaLink="true" >https://zulipchat.com/</guid>
<description>&lt;h2&gt;Open Source&lt;/h2&gt;
&lt;p&gt;Zulip is 100% open source software, built by a vibrant community of hundreds of developers from all around the world. With 120,000 words of developer documentation, a high quality code base, and a welcoming community, it’s easy to extend or tweak Zulip.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/zulip/zulip/graphs/contributors&quot;&gt;Zulip&lt;/a&gt; has a significantly larger and more active development community than other modern open source group chat solutions like &lt;a href=&quot;https://github.com/mattermost/mattermost-server/graphs/contributors&quot;&gt;Mattermost&lt;/a&gt;, &lt;a href=&quot;https://github.com/RocketChat/Rocket.Chat/graphs/contributors&quot;&gt;Rocket.Chat&lt;/a&gt;, and &lt;a href=&quot;https://github.com/matrix-org/synapse/graphs/contributors&quot;&gt;matrix.org&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>Fri, 27 Jul 2018 02:16:10 +0000</pubDate>
<dc:creator>tonteldoos</dc:creator>
<og:url>https://zulipchat.com</og:url>
<og:type>website</og:type>
<og:title>The world's most productive team chat</og:title>
<og:description>Zulip combines the immediacy of real-time chat with an email threading model. With Zulip, you can catch up on important conversations while ignoring irrelevant ones.</og:description>
<og:image>https://zulipchat.com/static/images/logo/zulip-icon-128x128.png</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://zulipchat.com/</dc:identifier>
</item>
<item>
<title>Worms frozen in permafrost for up to 42,000 years come back to life</title>
<link>http://siberiantimes.com/science/casestudy/news/worms-frozen-in-permafrost-for-up-to-42000-years-come-back-to-life/</link>
<guid isPermaLink="true" >http://siberiantimes.com/science/casestudy/news/worms-frozen-in-permafrost-for-up-to-42000-years-come-back-to-life/</guid>
<description>&lt;div class=&quot;topListAlt&quot; readability=&quot;8&quot;&gt;
&lt;p&gt;Awake after 42,000 years... Picture: The Siberian Times&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The roundworms from two areas of Siberia came back to life in Petri dishes, says a new scientific study. &lt;/p&gt;
&lt;p&gt;‘We have obtained the first data demonstrating the capability of multicellular organisms for longterm cryobiosis in permafrost deposits of the Arctic,’ states a report from Russian scientists from four institutions in collaboration with Princetown University.&lt;/p&gt;
&lt;p&gt;Some 300 prehistoric worms were analysed - and two ‘were shown to contain viable nematodes’.&lt;/p&gt;
&lt;p&gt;‘After being defrosted, the nematodes showed signs of life,’ said a report today from Yakutia, the area where the worms were found.&lt;/p&gt;
&lt;p&gt;‘They started moving and eating.’ &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://siberiantimes.com/Back-life-42,000-years/1.jpg&quot; width=&quot;720&quot; height=&quot;541&quot; alt=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; title=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; /&gt;&lt;/p&gt;
&lt;hr /&gt;&lt;p&gt;&lt;img src=&quot;http://siberiantimes.com/Back-life-42,000-years/2.jpg&quot; width=&quot;720&quot; height=&quot;744&quot; alt=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; title=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; /&gt;&lt;/p&gt;
&lt;hr /&gt;&lt;p&gt;&lt;img src=&quot;http://siberiantimes.com/Back-life-42,000-years/3.jpg&quot; width=&quot;720&quot; height=&quot;543&quot; alt=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; title=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; /&gt;&lt;br /&gt;&lt;span&gt;Duvanny Yar and (in the middle) the nematodes. Pictures: Nikita Zimov, &lt;/span&gt;&lt;strong&gt;Doklady Biological Sciences/Pleiades Publishing&lt;/strong&gt;&lt;/p&gt;
&lt;hr /&gt;&lt;p&gt;One worm came from an ancient squirrel burrow in a permafrost wall of the Duvanny Yar outcrop in the lower reaches of the Kolyma River - close to the site of Pleistocene Park which is seeking to recreate the Arctic habitat of the extinct woolly mammoth, according to the scientific article published in Doklady Biological Sciences this week. &lt;/p&gt;
&lt;p&gt;&lt;span&gt;This is around 32,000 years old. &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Another was found in permafrost near Alazeya River in 2015, and is around 41,700 years old. &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Currently the nematodes are the oldest living animals on the planet.  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;They are both believed to be female. &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://siberiantimes.com/Back-life-42,000-years/10.jpg&quot; width=&quot;720&quot; height=&quot;497&quot; alt=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; title=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; /&gt;&lt;/p&gt;
&lt;hr /&gt;&lt;p&gt;&lt;img src=&quot;http://siberiantimes.com/Back-life-42,000-years/9.jpg&quot; width=&quot;720&quot; height=&quot;443&quot; alt=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; title=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; /&gt;&lt;/p&gt;
&lt;hr /&gt;&lt;p&gt;&lt;img src=&quot;http://siberiantimes.com/Back-life-42,000-years/4.jpg&quot; width=&quot;720&quot; height=&quot;539&quot; alt=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; title=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; /&gt;&lt;/p&gt;
&lt;hr /&gt;&lt;p&gt;&lt;img src=&quot;http://siberiantimes.com/Back-life-42,000-years/11.jpg&quot; width=&quot;720&quot; height=&quot;475&quot; alt=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; title=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; /&gt;&lt;/p&gt;
&lt;hr /&gt;&lt;p&gt;&lt;img src=&quot;http://siberiantimes.com/Back-life-42,000-years/12.jpg&quot; width=&quot;720&quot; height=&quot;530&quot; alt=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; title=&quot;Worms frozen in permafrost for 42,000 years come back to life&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;Duvanny Yar and Alazeya river marked on the map, Alazeya River, specialists of the Institite of Psycico-Chemical and Biological Problems and Soil Science in Moscow region&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;hr /&gt;&lt;p&gt;&lt;span&gt;The worms came back to life in a laboratory at The Institute of Physico-Chemical and Biological Problems &lt;/span&gt;of Soil Science in Moscow region. &lt;/p&gt;
&lt;p&gt;&lt;span&gt;The scientists say: “Our data demonstrate the ability of multicellular &lt;/span&gt;organisms to survive long-term (tens of thousands of years) cryobiosis under the conditions of natural cryoconservation. &lt;/p&gt;
&lt;p&gt;&lt;span&gt;'It is obvious that this ability &lt;/span&gt;suggests that the Pleistocene nematodes have some adaptive mechanisms that may be of scientific and practical importance for the related fields of science, such as cryomedicine, cryobiology, and astrobiology.”&lt;/p&gt;
&lt;p&gt;The Russian institutions involved in the pioneering research were: The Institute of Physico-Chemical and Biological Problems of Soil Science; Moscow State University; Pertsov White Sea Biological Station, part of Moscow State University; and the Higher School of Economics in Moscow.&lt;/p&gt;
&lt;p&gt;&lt;span&gt;The Department of Geosciences, Princeton University, was also involved. &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;iframe width=&quot;720&quot; height=&quot;593&quot; src=&quot;https://www.youtube.com/embed/Bk6g8kR4MJY&quot; frameborder=&quot;0&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 26 Jul 2018 23:23:23 +0000</pubDate>
<dc:creator>keeler</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://siberiantimes.com/science/casestudy/news/worms-frozen-in-permafrost-for-up-to-42000-years-come-back-to-life/</dc:identifier>
</item>
<item>
<title>Jeff Dean’s ML System Architecture Blueprint</title>
<link>https://medium.com/syncedreview/google-ai-chief-jeff-deans-ml-system-architecture-blueprint-a358e53c68a5</link>
<guid isPermaLink="true" >https://medium.com/syncedreview/google-ai-chief-jeff-deans-ml-system-architecture-blueprint-a358e53c68a5</guid>
<description>&lt;p name=&quot;8aa6&quot; id=&quot;8aa6&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;ML has revolutionized vision, speech and language understanding and is being applied in many other fields. That’s an extraordinary achievement in the tech’s short history and even more impressive considering there is still no dedicated ML hardware.&lt;/p&gt;
&lt;p name=&quot;483d&quot; id=&quot;483d&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Back in January, Google AI Chief and former head of Google Brain Jeff Dean co-published the paper &lt;a href=&quot;https://ieeexplore.ieee.org/document/8259424/&quot; data-href=&quot;https://ieeexplore.ieee.org/document/8259424/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;A New Golden Age in Computer Architecture: Empowering the Machine-Learning Revolution&lt;/em&gt;&lt;/a&gt; with Turing Award winner and computer architect David Patterson. The paper encouraged Machine Learning (ML) experts and computer architects to “work together to design the computing systems required to deliver on the potential of ML.”&lt;/p&gt;
&lt;p name=&quot;f863&quot; id=&quot;f863&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;At this month’s Tsinghua-Google AI Symposium in Beijing, Dean discussed trends regarding the kinds of models scientists want to train. Google Brain research scientist Azalia Mirhoseini meanwhile gave a presentation on autoML with Reinforcement Learning at the same event.&lt;/p&gt;
&lt;p name=&quot;35cd&quot; id=&quot;35cd&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The &lt;em class=&quot;markup--em markup--p-em&quot;&gt;Golden Age&lt;/em&gt; paper and recent talks by Google researchers provide a picture of how Google Brain is thinking through hardware and software challenges to improve ML system performance and productivity.&lt;/p&gt;
&lt;p name=&quot;6fab&quot; id=&quot;6fab&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Dean has often pointed out that &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;ML’s growth trend as reflected in related arXiv papers has already surpassed Moore’s Law,&lt;/strong&gt; the 1975 prediction for chip growth.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*znJS1Aygd_B-u9rA&quot; data-width=&quot;950&quot; data-height=&quot;515&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*znJS1Aygd_B-u9rA&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*znJS1Aygd_B-u9rA&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;ML arXiv papers per year for the cs.Computer Vision, cs.Computation and Language, cs.Machine Learning, cs.Artificial Intelligence, cs.Neural and Evolutionary Computing, and stat.Machine Learning topics. (Source: A New Golden Age in Computer Architecture: Empowering the Machine-Learning Revolution.&lt;/em&gt; &lt;a href=&quot;https://ieeexplore.ieee.org/document/8259424/&quot; data-href=&quot;https://ieeexplore.ieee.org/document/8259424/&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;DOI:&lt;/em&gt;&lt;/a&gt; &lt;a href=&quot;https://doi.org/10.1109/MM.2018.112130030&quot; data-href=&quot;https://doi.org/10.1109/MM.2018.112130030&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;10.1109/MM.2018.112130030&lt;/em&gt;&lt;/a&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;)&lt;/em&gt;
&lt;p name=&quot;db4f&quot; id=&quot;db4f&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Dean and Patterson dissect hardware design in their &lt;em class=&quot;markup--em markup--p-em&quot;&gt;Golden Age&lt;/em&gt; paper, using the example of the Google-developed TPUv1 and TPUv2 Tensor Processing Units (TPU), which are advanced application-specific integrated circuits (ASIC). The duo advises engineers to look forward at least five years for hardware development, as an appropriate design must remain relevant through at least a two-year design and three-year deployment window to maintain its competitive edge, assuming standard depreciation projections.&lt;/p&gt;
&lt;p name=&quot;163d&quot; id=&quot;163d&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Dean identifies six issues that impact ML hardware design within this five-year window, from purely architectural to mostly ML-driven concerns, including:&lt;/strong&gt;&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li name=&quot;dc66&quot; id=&quot;dc66&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Training&lt;/strong&gt;&lt;/li&gt;
&lt;li name=&quot;b0a5&quot; id=&quot;b0a5&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Batch Size&lt;/strong&gt;&lt;/li&gt;
&lt;li name=&quot;a970&quot; id=&quot;a970&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Sparsity and Embeddings&lt;/strong&gt;&lt;/li&gt;
&lt;li name=&quot;cd3b&quot; id=&quot;cd3b&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Quantization and Distillation&lt;/strong&gt;&lt;/li&gt;
&lt;li name=&quot;4736&quot; id=&quot;4736&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Networks with Soft Memory&lt;/strong&gt;&lt;/li&gt;
&lt;li name=&quot;bab9&quot; id=&quot;bab9&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Learning to Learn (L2L)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 name=&quot;91df&quot; id=&quot;91df&quot; class=&quot;graf graf--h3 graf-after--li&quot;&gt;Training&lt;/h3&gt;
&lt;p name=&quot;a284&quot; id=&quot;a284&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Two of the most important phases in the ML workflow are the production phase, called inference or prediction; and the development phase, called training or learning.&lt;/p&gt;
&lt;p name=&quot;a6c9&quot; id=&quot;a6c9&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Back in 2015, like many other companies, Google developed application-specific integrated circuit (ASIC) hardware. Their TPUv1 was designed for ML inference instead of training, mainly because: 1) Inference takes one-third as many arithmetic operations as training; 2) During training, activation values calculated through feedforward must be saved for back-propagation and thus occupy much more space than inference; 3) Training cannot scale up like inference, it requires numerous expensive follow up steps.&lt;/p&gt;
&lt;p name=&quot;c6b5&quot; id=&quot;c6b5&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This does not mean hardware design for training is unnecessary. On the contrary, training ASICs can save researchers’ valuable time: if training an ML model requires 30 days of computation time, that will deter most scientists from running the experiment.&lt;/p&gt;
&lt;p name=&quot;b219&quot; id=&quot;b219&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Consequently, in 2017 Google developed and deployed its second-generation ASIC TPUv2 in data centers for ML training. Sixty-four TPUv2 devices were assembled into a pod, achieving the computing performance of 11.5 peta floating point operations per second (PFLOPS) with 4 terabytes of High Bandwidth Memory (HBM).&lt;/p&gt;
&lt;p name=&quot;87d5&quot; id=&quot;87d5&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Jeff Dean shared some TPUv2 success stories in his presentation, such as increasing the Google Search Ranking model training speed by 14.2 times and speeding up image model training by 9.8 times, both using only one-quarter of the pod (16 TPUv2 devices). Moreover, the high-performance TPUv2 can also solve the scale-up challenge in ML training: It takes 1,402 minutes to train ResNet-50 (a pre-trained network for image recognition) to over 76% accuracy with one TPUv2 device, and only 45 minutes (31.2 times faster) using half the pod (32 TPUv2 devices).&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*WNq-23jTJHMd-u8N&quot; data-width=&quot;748&quot; data-height=&quot;720&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*WNq-23jTJHMd-u8N&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*WNq-23jTJHMd-u8N&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;TPUv2 in Model Training. (Source: Jeff Dean’s Presentation at Tsinghua-Google AI Symposium)&lt;/em&gt;
&lt;p name=&quot;b27a&quot; id=&quot;b27a&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;TPUs are very costly, however as part of its &lt;a href=&quot;https://www.tensorflow.org/tfrc/&quot; data-href=&quot;https://www.tensorflow.org/tfrc/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;TensorFlow Research Cloud&lt;/a&gt; (TFRC) program, Google now grants 1,000 TPU devices free of charge to top scientists who are devoting significant efforts to open ML research.&lt;/p&gt;
&lt;h3 name=&quot;30ba&quot; id=&quot;30ba&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Batch Size&lt;/h3&gt;
&lt;p name=&quot;edb7&quot; id=&quot;edb7&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Batch size enables an important form of operand reuse. The setting of minibatch size can greatly affect the efficiency of gradient descent in ML training. Unfortunately, the setting of minibatch size is still poorly understood.&lt;/p&gt;
&lt;p name=&quot;ca47&quot; id=&quot;ca47&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Current GPUs operate efficiently at minibatch sizes of 32 or larger. Building ML with very large or small minibatch sizes or with the Stochastic Gradient Descent (SGD) minibatch size of 1 has become a topic for heated debate among top-notch researchers, who have offered various solutions.&lt;/p&gt;
&lt;p name=&quot;3224&quot; id=&quot;3224&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The recent Facebook AI Research (FAIR) paper &lt;a href=&quot;https://arxiv.org/abs/1706.02677&quot; data-href=&quot;https://arxiv.org/abs/1706.02677&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;Accurate, Large Minibatch: Training ImageNet in 1 Hour&lt;/em&gt;&lt;/a&gt; shows that visual recognition models can be effectively trained at minibatch sizes of 8,192 and 32,768. Although such large-scale training may be suitable for the FAIR model, the approach cannot be assumed as a universal solution.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*sniEYzhiMRwxUK-k&quot; data-width=&quot;950&quot; data-height=&quot;527&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*sniEYzhiMRwxUK-k&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*sniEYzhiMRwxUK-k&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;ImageNet top-1 validation error vs. minibatch size. Such techniques enable a linear reduction in training time with ∼90% efficiency, training an accurate 8k minibatch ResNet-50 model in 1 hour on 256 GPUs. (source: Accurate, Large Minibatch: Training ImageNet in 1 Hour.&lt;/em&gt; &lt;a href=&quot;https://arxiv.org/abs/1706.02677&quot; data-href=&quot;https://arxiv.org/abs/1706.02677&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;arXiv:1706.02677&lt;/em&gt;&lt;/a&gt; &lt;em class=&quot;markup--em markup--figure-em&quot;&gt;)&lt;/em&gt;
&lt;p name=&quot;4583&quot; id=&quot;4583&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Facebook Chief AI Scientist Yann LeCun is not a fan of large minibatch size. In April he &lt;a href=&quot;https://twitter.com/ylecun/status/989610208497360896?lang=en&quot; data-href=&quot;https://twitter.com/ylecun/status/989610208497360896?lang=en&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;tweeted&lt;/a&gt;, “Training with large minibatches is bad for your health. More importantly, it’s bad for your test error. Friends don’t let friends use minibatches larger than 32.”&lt;/p&gt;
&lt;p name=&quot;86eb&quot; id=&quot;86eb&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Dean and Patterson take a more neutral position in &lt;em class=&quot;markup--em markup--p-em&quot;&gt;Golden Age&lt;/em&gt;, “If batch size could be made arbitrarily large while still training effectively, then training is amenable to standard weak scaling approaches. However, if the training rate of some models is restricted to small batch sizes, then we will need to find other algorithmic and architectural approaches to their acceleration.”&lt;/p&gt;
&lt;h3 name=&quot;0d3b&quot; id=&quot;0d3b&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Sparsity and Embeddings&lt;/h3&gt;
&lt;p name=&quot;d8ad&quot; id=&quot;d8ad&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Sparsity has different forms and exploiting this can help reduce the computational complexity of ML by skipping zeros and small values. Dean and Patterson believe that &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;coarse-grained sparsity has more potential than the commonly seen irregular fine-grained sparsity&lt;/strong&gt;.&lt;/p&gt;
&lt;p name=&quot;fe27&quot; id=&quot;fe27&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Dean argues researchers will want increasingly huge model capacity for larger datasets, but will want each individual example to only activate a tiny fraction of the large model, in other words, “bigger models, but sparsely activated.”&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*ddNEkm792LgsFCBT&quot; data-width=&quot;950&quot; data-height=&quot;377&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*ddNEkm792LgsFCBT&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*ddNEkm792LgsFCBT&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;Different sparse structures in a 4-dimensional weight tensor. Regular sparsity makes hardware acceleration easier. (Source: Exploring the Regularity of Sparse Structure in Convolutional Neural Networks.&lt;/em&gt; &lt;a href=&quot;https://arxiv.org/abs/1705.08922&quot; data-href=&quot;https://arxiv.org/abs/1705.08922&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;arXiv:1705.08922&lt;/em&gt;&lt;/a&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;)&lt;/em&gt;
&lt;p name=&quot;3387&quot; id=&quot;3387&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;One example is Google Brain’s Mixture of Experts (MoE) model, which consults the learned subset of a panel of “experts” as part of its network structure to achieve the desired level of sparsity.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*07IiAi-yvWPyQrLv&quot; data-width=&quot;950&quot; data-height=&quot;478&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*07IiAi-yvWPyQrLv&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*07IiAi-yvWPyQrLv&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;A Mixture of Experts (MoE) layer embedded within a recurrent language model. In this case, the sparse gating function selects two experts to perform computations. Their outputs are modulated by the outputs of the gating network. (Source: Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer.&lt;/em&gt; &lt;a href=&quot;https://arxiv.org/abs/1701.06538&quot; data-href=&quot;https://arxiv.org/abs/1701.06538&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;arXiv:1701.06538&lt;/em&gt;&lt;/a&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;)&lt;/em&gt;
&lt;p name=&quot;8099&quot; id=&quot;8099&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;As a result, MoE models train more weights using fewer flops for higher accuracy than previous approaches. On a Google English to French dataset, the MoE model scored 1.01 times higher in the Bilingual Evaluation Understudy (BLEU) test than the GNMT model after training for just one-sixth the time.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*ZPb542ep7R8MX_dC&quot; data-width=&quot;950&quot; data-height=&quot;143&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*ZPb542ep7R8MX_dC&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*ZPb542ep7R8MX_dC&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;(Source: Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer.&lt;/em&gt; &lt;a href=&quot;https://arxiv.org/abs/1701.06538&quot; data-href=&quot;https://arxiv.org/abs/1701.06538&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;arXiv:1701.06538&lt;/em&gt;&lt;/a&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;)&lt;/em&gt;
&lt;p name=&quot;d102&quot; id=&quot;d102&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Embeddings, which can transform large sparse data into more compact, dense representations suitable for linear algebra operations, also play an important role in big data applications such as web search, translation, and video recommendation. For text or video analysis, accesses to embedding tables only involve hundreds of small (100 to 1,000 byte) random accesses in very large (hundreds of gigabyte) data structures.&lt;/p&gt;
&lt;h3 name=&quot;54cc&quot; id=&quot;54cc&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Quantization and Distillation&lt;/h3&gt;
&lt;p name=&quot;7f44&quot; id=&quot;7f44&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Quantization has already proved useful in cost-effective ML inferences. Such reduced-precision computation, fortunately, has fewer resource requirements and higher computing efficiency with little accuracy loss for model inference. Dean thinks reduced-precision is effective and believes it should also work for training acceleration.&lt;/p&gt;
&lt;p name=&quot;c294&quot; id=&quot;c294&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Although there has been little work published in this area so far, last year Baidu and Nvidia researchers introduced a mixed-precision architecture for training deep neural networks. By replacing the single-precision floating-point format (FP32) with half-precision floating-point (FP16) for feedforward calculation, the memory requirement was reduced to half, but accuracy still matched the FP32 models. Mixed precision training is supported by the &lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/index.html&quot; data-href=&quot;https://docs.nvidia.com/deeplearning/sdk/index.html&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;NVIDIA Deep Learning SDK&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p name=&quot;109a&quot; id=&quot;109a&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;a href=&quot;https://arxiv.org/abs/1503.02531&quot; data-href=&quot;https://arxiv.org/abs/1503.02531&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;Distillation&lt;/a&gt; was first proposed by Google Brain’s Geoffrey Hinton at NIPS 2014. It uses a larger model to bootstrap the training of a smaller model while achieving higher accuracy, instead of directly training the smaller model on the same inputs. For method application, Dean suggests that for a small and cheap model that runs for example on a phone, it is possible to transfer knowledge from an existing giant model with high accuracy into the small model for suitable deployment.&lt;/p&gt;
&lt;p name=&quot;b06a&quot; id=&quot;b06a&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;As noted by Dean and Patterson in &lt;em class=&quot;markup--em markup--p-em&quot;&gt;Golden Age&lt;/em&gt;, the distillation method also raises questions, such as “&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Could better training methods allow us to directly train the smaller models (and perhaps all models) to higher accuracy?&lt;/strong&gt;” and &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;“Is there something fundamental about the having more degrees of freedom in the larger model that enables better training?&lt;/strong&gt;” These questions bring up different directions in ML development for both small and large models.&lt;/p&gt;
&lt;h3 name=&quot;1b25&quot; id=&quot;1b25&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Networks with Soft Memory&lt;/h3&gt;
&lt;p name=&quot;ddbd&quot; id=&quot;ddbd&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;In &lt;em class=&quot;markup--em markup--p-em&quot;&gt;Golden Age&lt;/em&gt;, Dean and Patterson indicate that some deep-learning techniques can provide features akin to memory access. The attention mechanism, for instance, is one such technique that can be used to improve ML performance in machine translation by paying attention to selected parts of the source during long sequences of data processing.&lt;/p&gt;
&lt;p name=&quot;0b7b&quot; id=&quot;0b7b&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Unlike traditional hard memory, soft memory computes a weighted average over all entries of a table for information-rich content selections. Doing so however is complicated and there is no current research into efficient or sparse implementations of soft memory models.&lt;/p&gt;
&lt;h3 name=&quot;30cf&quot; id=&quot;30cf&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Learning to Learning (L2L)&lt;/h3&gt;
&lt;p name=&quot;b260&quot; id=&quot;b260&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Currently, most large ML architecture and model designs still rely on human experts’ heuristics and intuitions. L2L is a revolution in model development as it enables automated machine learning that involves no human expert decisions. This approach is now used to address the growing shortage of ML experts.&lt;/p&gt;
&lt;p name=&quot;bde9&quot; id=&quot;bde9&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;For automated ML, the Google Brain team uses Reinforcement Learning (RL) — a method they proposed in the 2017 ICLR paper &lt;a href=&quot;https://arxiv.org/abs/1611.01578&quot; data-href=&quot;https://arxiv.org/abs/1611.01578&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;Neural Architecture Search with Reinforcement Learning&lt;/em&gt;&lt;/a&gt;. By using accuracy as a reward signal, a model can learn to self-improve over time. Authors applied the CIFAR-10 dataset for the discovery of a novel network architecture and Penn Treebank dataset for the composition of a novel recurrent cell with RL, and both achieved results comparable with previous state-of-the-art methods.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*gR4h9avij9xQz0bB&quot; data-width=&quot;950&quot; data-height=&quot;496&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*gR4h9avij9xQz0bB&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*gR4h9avij9xQz0bB&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;Left: Convolutional architecture discovered by neural architecture search using CIFAR-10 dataset. Right: Performance of Neural Architecture Search and other state-of-the-art models on CIFAR-10. (source: Neural Architecture Search with Reinforcement Learning.&lt;/em&gt; &lt;a href=&quot;https://arxiv.org/abs/1611.01578&quot; data-href=&quot;https://arxiv.org/abs/1611.01578&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;arXiv:1611.01578&lt;/em&gt;&lt;/a&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;)&lt;/em&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*7ZnqUuNlQ69aDFBx&quot; data-width=&quot;950&quot; data-height=&quot;516&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*7ZnqUuNlQ69aDFBx&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*7ZnqUuNlQ69aDFBx&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;Left: Normal LSTM cell vs. cell discovered by Neural Architecture Search neural architecture search using Penn Treebank dataset. Right: Single model perplexity on the test set of the Penn Treebank language modeling task. (source: Neural Architecture Search with Reinforcement Learning.&lt;/em&gt; &lt;a href=&quot;https://arxiv.org/abs/1611.01578&quot; data-href=&quot;https://arxiv.org/abs/1611.01578&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;arXiv:1611.01578&lt;/em&gt;&lt;/a&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;)&lt;/em&gt;
&lt;p name=&quot;fc3a&quot; id=&quot;fc3a&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Other applications of RL in meta-learning include optimal path detection, activation function selection, learning optimization update rule, and even device placement optimization. At the Tsinghua-Google AI Symposium, Mirhoseini spoke on &lt;a href=&quot;https://arxiv.org/abs/1706.04972&quot; data-href=&quot;https://arxiv.org/abs/1706.04972&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;Device Placement Optimization with RL&lt;/em&gt;&lt;/a&gt;, which was published at ICML 2017.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*2lGP_Erbr-yX_RY_&quot; data-width=&quot;950&quot; data-height=&quot;631&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*2lGP_Erbr-yX_RY_&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*2lGP_Erbr-yX_RY_&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;Google Brain Research Scientist Azalia Mirhoseini speaking at the Tsinghua-Google AI Symposium&lt;/em&gt;
&lt;p name=&quot;e2a5&quot; id=&quot;e2a5&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;As explained in Mirhoseini’s RL paper, “[The] key to the method is the use of a sequence-to-sequence model to read input information about the operations as well as the dependencies between them, and then propose a placement for each operation. Each proposal is executed in the hardware environment to measure the execution time.” Using execution time as a reward signal, the model gets a better device placement proposal over time.&lt;/p&gt;
&lt;p name=&quot;62af&quot; id=&quot;62af&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;In Neural Machine Translation (NMT) model training tests, even though the RL-based placement was inconsistent with human intuitions, it was nearly 65 hours faster than expert-designed placement, achieving a 27.8 percent speedup of total training time.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*C3TP3s1auJTr2Fo4&quot; data-width=&quot;857&quot; data-height=&quot;646&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*C3TP3s1auJTr2Fo4&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*C3TP3s1auJTr2Fo4&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;Training curves of NMT model using RL-based placement and expert-designed placement. The per-step running time as well as the perplexities are averaged over 4 runs. (Source: Device Placement Optimization with Reinforcement Learning.&lt;/em&gt; &lt;a href=&quot;https://arxiv.org/abs/1706.04972&quot; data-href=&quot;https://arxiv.org/abs/1706.04972&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;arXiv:1706.04972&lt;/em&gt;&lt;/a&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;)&lt;/em&gt;
&lt;h3 name=&quot;e684&quot; id=&quot;e684&quot; class=&quot;graf graf--h3 graf-after--figure&quot;&gt;Going Forward&lt;/h3&gt;
&lt;p name=&quot;b831&quot; id=&quot;b831&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;So what might a plausible future look like? At the Symposium, Dean proposed it could involve a combination of many ideas:&lt;/strong&gt;&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li name=&quot;a736&quot; id=&quot;a736&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;1. Large model, but sparsely activated;&lt;/strong&gt;&lt;/li&gt;
&lt;li name=&quot;1760&quot; id=&quot;1760&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;2. Single model to solve many tasks;&lt;/strong&gt;&lt;/li&gt;
&lt;li name=&quot;556a&quot; id=&quot;556a&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;3. Dynamically learn and grow pathways through a large model;&lt;/strong&gt;&lt;/li&gt;
&lt;li name=&quot;bff4&quot; id=&quot;bff4&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;4. Hardware specialized for ML supercomputing;&lt;/strong&gt;&lt;/li&gt;
&lt;li name=&quot;fb41&quot; id=&quot;fb41&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;5. ML for efficient mapping onto hardware.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p name=&quot;2630&quot; id=&quot;2630&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;Dean and Google’s research direction suggests that those considering stepping into the ML arena and contributing to its future modeling would do well to think broadly and develop skills across research, engineering, and hardware structure.&lt;/p&gt;
&lt;p name=&quot;c8cc&quot; id=&quot;c8cc&quot; class=&quot;graf graf--p graf-after--p graf--trailing&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Source:&lt;/strong&gt; &lt;a href=&quot;https://www.jiqizhixin.com/articles/2018-07-02-5&quot; data-href=&quot;https://www.jiqizhixin.com/articles/2018-07-02-5&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Synced China&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 26 Jul 2018 22:50:09 +0000</pubDate>
<dc:creator>trcytony</dc:creator>
<og:title>Google AI Chief Jeff Dean’s ML System Architecture Blueprint</og:title>
<og:url>https://medium.com/syncedreview/google-ai-chief-jeff-deans-ml-system-architecture-blueprint-a358e53c68a5</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*ueb0GAc-4amH0UY8W0YFVw.png</og:image>
<og:description>ML has revolutionized vision, speech and language understanding and is being applied in many other fields. That’s an extraordinary…</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://medium.com/syncedreview/google-ai-chief-jeff-deans-ml-system-architecture-blueprint-a358e53c68a5</dc:identifier>
</item>
</channel>
</rss>