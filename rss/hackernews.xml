<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Selected Essays of Richard M. Stallman [pdf]</title>
<link>https://www.gnu.org/philosophy/fsfs/rms-essays.pdf</link>
<guid isPermaLink="true" >https://www.gnu.org/philosophy/fsfs/rms-essays.pdf</guid>
<description>&lt;a href=&quot;https://www.gnu.org/philosophy/fsfs/rms-essays.pdf&quot;&gt;Download PDF&lt;/a&gt;</description>
<pubDate>Wed, 25 Apr 2018 22:58:36 +0000</pubDate>
<dc:creator>justinzollars</dc:creator>
<dc:format>application/pdf</dc:format>
<dc:identifier>https://www.gnu.org/philosophy/fsfs/rms-essays.pdf</dc:identifier>
</item>
<item>
<title>A Well-Known Expert on Student Loans Is Not Real</title>
<link>https://www.chronicle.com/article/Drew-Cloud-Is-a-Well-Known/243217</link>
<guid isPermaLink="true" >https://www.chronicle.com/article/Drew-Cloud-Is-a-Well-Known/243217</guid>
<description>&lt;p&gt;&lt;img alt=&quot;&quot; class=&quot;article__image img-responsive&quot; src=&quot;https://www.chronicle.com//img/photos/biz/photo_86978_landscape_850x566.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Chronicle photo illustration&lt;/p&gt;
&lt;p&gt;The fictional founder sprang from this website, which shares news about student loans.&lt;/p&gt;
&lt;span class=&quot;dropcap&quot;&gt;D&lt;/span&gt;rew Cloud is everywhere. The self-described journalist who specializes in student-loan debt has been quoted in major news outlets, including &lt;em&gt;&lt;a href=&quot;https://www.washingtonpost.com/business/get-there/with-new-degrees-in-hand-college-grads-face-another-hurdle-paying-back-student-loans/2017/06/02/7831cc06-4550-11e7-bcde-624ad94170ab_story.html?utm_term=.81a5a17cfd47&quot;&gt;The Washington Post&lt;/a&gt;,&lt;/em&gt; &lt;em&gt;&lt;a href=&quot;https://www.bostonglobe.com/business/2018/03/22/college-students-are-using-student-loans-invest-bitcoin-yes-really/Syr7mJpgIzDn6iOa6a0g5J/story.html&quot;&gt;The Boston Globe&lt;/a&gt;,&lt;/em&gt; and &lt;a href=&quot;https://www.cnbc.com/2018/03/23/college-students-use-financial-aid-money-to-invest-in-bitcoin.html&quot;&gt;CNBC&lt;/a&gt;, and is a fixture in the smaller, specialized blogosphere of student debt.
&lt;p&gt;He’s always got the new data, featuring irresistible twists:&lt;/p&gt;
&lt;p&gt;One in five students use extra money from their student loans to buy digital currencies.&lt;/p&gt;
&lt;p&gt;Nearly 8 percent of students would move to North Korea to free themselves of their debt.&lt;/p&gt;
&lt;p&gt;Twenty-seven percent would contract the Zika virus to live debt-free.&lt;/p&gt;
&lt;p&gt;All of those surveys came from Cloud’s website, &lt;a href=&quot;https://studentloans.net/&quot;&gt;The Student Loan Report&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Drew Cloud’s story was simple: He &lt;a href=&quot;https://web.archive.org/web/20180420191847/https://studentloans.net/about-contact/&quot;&gt;founded&lt;/a&gt; the website, an &quot;independent, authoritative news outlet&quot; covering all things student loans, &quot;after he had difficulty finding the most recent student loan news and information all in one place.&quot;&lt;/p&gt;
&lt;p&gt;He became ubiquitous on that topic. But he’s a fiction, the invention of a student-loan refinancing company.&lt;/p&gt;
&lt;div class=&quot;content-item__side-bar media-width-half media-pull-left&quot; readability=&quot;7.4761904761905&quot;&gt;
&lt;div class=&quot;content-item__side-bar--body&quot; readability=&quot;33.642857142857&quot;&gt;
&lt;p&gt;
&lt;h4&gt;Get Our Morning Newsletter&lt;/h4&gt;
&lt;/p&gt;
&lt;p&gt;Sign up to receive Academe Today, our free daily newsletter. You'll get the latest news and trusted insights on higher education.&lt;/p&gt;


&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;After &lt;em&gt;The Chronicle&lt;/em&gt; spent more than a week trying to verify Cloud’s existence, the company that owns The Student Loan Report confirmed that Cloud was fake. &quot;Drew Cloud is a pseudonym that a diverse group of authors at Student Loan Report, LLC use to share experiences and information related to the challenges college students face with funding their education,&quot; wrote Nate Matherson, CEO of &lt;a href=&quot;https://lendedu.com/about/&quot;&gt;LendEDU&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Before that admission, however, Cloud had corresponded at length with many journalists, pitching them stories and offering email interviews, many of which were published. When &lt;em&gt;The Chronicle&lt;/em&gt; attempted to contact him through the address last week, Cloud said he was traveling and had limited access to his account. He didn’t respond to additional inquiries.&lt;/p&gt;
&lt;p&gt;And on Monday, as &lt;em&gt;The Chronicle&lt;/em&gt; continued to seek comment, Cloud suddenly evaporated. His once-prominent &lt;a href=&quot;https://web.archive.org/web/20180415024307/https://studentloans.net/public-colleges-least-private-student-debt/&quot;&gt;placement&lt;/a&gt; on The Student Loan Report had been removed. His bylines were &lt;a href=&quot;https://studentloans.net/public-colleges-least-private-student-debt/&quot;&gt;replaced&lt;/a&gt; with &quot;SLR Editor.&quot; Matherson confirmed on Tuesday that Cloud was an invention.&lt;/p&gt;
&lt;p&gt;Pressed on whether he regretted deceiving news organizations with a fake source, Matherson said Cloud &quot;was created as a way to connect with our readers (ex. people struggling to repay student debt) and give us the technical ability to post content to the Wordpress website.&quot;&lt;/p&gt;
&lt;p&gt;Cloud had an elaborate back story. Before being scrubbed from the website, he was described as having &quot;a knack for reporting throughout high school and college where he picked up his topics of choice.&quot; Since graduating from college, the site said, &quot;Drew wanted to funnel his creative energy into an independent, authoritative news outlet covering an exclusive and developing industry.&quot;&lt;/p&gt;
&lt;p&gt;Cloud was not the only facade. The website’s affiliation with LendEDU was also not previously disclosed.&lt;/p&gt;

&lt;p&gt;In his email, Matherson called The Student Loan Report &quot;very much a side project for our organization.&quot;&lt;/p&gt;
&lt;p&gt;He continued: &quot;Our goal, from the beginning, is to create an informative source of news and educational content for consumers. We are not focused on monetizing from Student Loan Report, LLC. As you may have noticed, there are very few advertisements on the website.&quot;&lt;/p&gt;
&lt;p&gt;Matherson elaborated: &quot;Our parent company, Shop Tutors, Inc., acquired the online assets of studentloans.net in 2016. The Student Loan Report, LLC is a separate entity. For context, it is very common practice for online media companies to own or acquire additional media assets. Student Loan Report, LLC is a for-profit organization and is paid by some of the companies featured on our website. Student Loan Report, LLC may earn a fee when our readers apply or receive a financial product featured on our website.&quot;&lt;/p&gt;
&lt;p&gt;But in 2016, Matherson described the relationship in simpler terms in an email obtained by &lt;em&gt;The Chronicle&lt;/em&gt;. In that message, sent to a potential contributor, he wrote, &quot;We have a new project that you might be able to help us with. We are launching a student loan industry news site called Student Loan Report located at studentloans.net.&quot;&lt;/p&gt;
&lt;h4&gt;A Punch From Mike Tyson&lt;/h4&gt;
&lt;p&gt;Even without this evidence, close observers would have been able to divine the connection between the two organizations. In 2016, LendEDU and The Student Loan Report posed a series of oddball questions meant to test the lengths to which student borrowers would go to free themselves of debt. About 56 percent of them would take a punch from Mike Tyson, &lt;a href=&quot;https://web.archive.org/web/20180423215748/https://lendedu.com/blog/february-student-loan-survey&quot;&gt;wrote&lt;/a&gt; &lt;a href=&quot;https://lendedu.com/about/&quot;&gt;LendEDU&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A few months later, The Student Loan Report &lt;a href=&quot;https://web.archive.org/web/20180423215735/https://studentloans.net/insane-repayment-survey/&quot;&gt;issued&lt;/a&gt; a report on its own survey asking how far borrowers would go to erase their debt. About 62 percent said they would star in a pornographic film. Forty-three percent said they would hook up with Caitlyn Jenner. The report, issued by Cloud, included a link to a list of student-loan-refinancing companies, LendEDU among them.&lt;/p&gt;
&lt;p&gt;Both surveys featured an odd mixture of juvenile and mean-spirited humor. They had another similarity as well: an uncommon typo in the word &quot;meant.&quot; Here’s LendEDU on drug use: &quot;56.14 percent of borrowers would abstain from alcohol and drug use for life, if it mean’t that they would have no more student loan debt.&quot; And The Student Loan Report on a similar topic: &quot;85% of borrowers would give up smoking marijuana for life, if it mean’t that they would have no more student loan debt.&quot;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; class=&quot;article__image img-responsive&quot; src=&quot;https://www.chronicle.com//img/photos/biz/photo_86979_portrait_650x975.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;studentloans.net&lt;/p&gt;
&lt;p&gt;This is Drew Cloud, according to The Student Loan Report. &quot;He always had a knack for reporting throughout high school and college,&quot; read his website bio, which has been removed.&lt;/p&gt;
Cloud may no longer appear on his own site, but his footprint in the wider world remains. He was quoted by a number of media outlets this year in connection with a survey finding by The Student Loan Report that one in five students had used money from their student loans to invest in digital currencies. Experts in the field &lt;a href=&quot;https://www.chronicle.com/article/No-Students-Probably-Aren-t/243103&quot;&gt;told&lt;/a&gt; &lt;em&gt;The Chronicle&lt;/em&gt; that the study’s opaque methodology raised concerns.
&lt;p&gt;Cloud has often appeared on financial-advice sites, either as a &lt;a href=&quot;https://distilleddollar.com/2017/07/21/4-tips-to-overcome-student-debt/&quot;&gt;guest writer&lt;/a&gt; or as the &lt;a href=&quot;http://freedomisgroovy.com/student-loans-government-personal-finance-oh/&quot;&gt;subject&lt;/a&gt; of an interview. In those cases, he doesn’t mention where he attended college, but he does mention that he, too, had taken out student loans.&lt;/p&gt;
&lt;p&gt;When people reached out to Cloud for his expertise on student debt, he often &lt;a href=&quot;http://www.reversethecrush.com/pay-off-student-loan-debt-like-adult/&quot;&gt;suggested&lt;/a&gt; that they refinance their loans.&lt;/p&gt;
&lt;p&gt;That’s one of the services offered by LendEDU. Matherson and Matt Lenhard started what would become LendEDU while they were both students at the University of Delaware. The two had originally created a tool that allowed people to book tutors online. But they appeared to spin it into a place from which students can apply for multiple loans.&lt;/p&gt;
&lt;p&gt;Today, LendEDU describes itself as &quot;marketplace for private ﻿﻿student﻿﻿ loans, student loan refinancing, credit cards, and personal loans - among other financial products.&quot;&lt;/p&gt;
&lt;p&gt;In a &lt;a href=&quot;https://lendedu.com/editorial-integrity/&quot;&gt;post&lt;/a&gt; on the website, Matherson seemed to affirm his commitment to a virtuous way of conducting business.&lt;/p&gt;
&lt;p&gt;&quot;We started LendEDU to offer transparency in the student loan market,&quot; he wrote. &quot;Today, we are working to provide transparency to the personal finance industry as a whole.&quot;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Chris Quintana is a staff reporter. Follow him on Twitter &lt;a href=&quot;https://twitter.com/cquintanadc&quot;&gt;@cquintanadc&lt;/a&gt; or email him at &lt;a href=&quot;mailto:chris.quintana@chronicle.com&quot;&gt;chris.quintana@chronicle.com.&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Dan Bauman is a reporter who investigates and writes about all things data in higher education. Tweet him at &lt;a href=&quot;https://twitter.com/danbauman77&quot;&gt;@danbauman77&lt;/a&gt; or email him at &lt;a href=&quot;mailto:dan.bauman@chronicle.com&quot;&gt;dan.bauman@chronicle.com.&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 25 Apr 2018 22:23:55 +0000</pubDate>
<dc:creator>cpeterso</dc:creator>
<og:title>Drew Cloud Is a Well-Known Expert on Student Loans. One Problem: He’s Not Real.</og:title>
<og:description>His website, the Student Loan Report, is widely cited by news media for its surveys on loan debt, and Cloud is quoted at length. But both he and his organization are facades.</og:description>
<og:type>article</og:type>
<og:url>https://www.chronicle.com/article/Drew-Cloud-Is-a-Well-Known/243217/</og:url>
<og:image>https://www.chronicle.com/img/photos/biz/photo_86978_wide_large.jpg</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.chronicle.com/article/Drew-Cloud-Is-a-Well-Known/243217</dc:identifier>
</item>
<item>
<title>Giving Up on the Current MacBook Pro Keyboard</title>
<link>https://theoutline.com/post/4277/dont-buy-the-new-macbook-pros-even-on-sale-in-my-opinion</link>
<guid isPermaLink="true" >https://theoutline.com/post/4277/dont-buy-the-new-macbook-pros-even-on-sale-in-my-opinion</guid>
<description>&lt;p&gt;A few months ago, I wrote about how my one-year-old MacBook Pro's keyboard keys stopped working &lt;a href=&quot;https://theoutline.com/post/2402/the-new-macbook-keyboard-is-ruining-my-life?zd=1&amp;amp;zi=cseimgyt&quot;&gt;if a single piece of dust slipped under there&lt;/a&gt;, and more importantly, that neither Apple nor its Geniuses would acknowledge that this was actually a problem. Today, Best Buy announced it is &lt;a href=&quot;http://bgr.com/2018/04/24/macbook-pro-sale-2018-best-buy/&quot;&gt;having a significant sale&lt;/a&gt; on these computers, marking them hundreds of dollars off. Interesting. Still, I’d suggest you do not buy them.&lt;/p&gt;
&lt;p&gt;Since I wrote about my experience, many have asked me what happened with the new top half of the computer that the Apple Geniuses installed, with its pristine keyboard and maybe-different key switches. The answer is that after a couple of months, I started to get temporarily dead keys for seemingly no reason. Again.&lt;/p&gt;
&lt;p&gt;I still had my 2013 MacBook Pro around, so I sold my 2016 MacBook Pro back to Apple’s refurb program, and now I just use the 2013 as my laptop (I used the recovered money to build a PC, lord help me). This old MacBook Pro is still fine, and most importantly, all the keyboard keys work. The new MacBook Pro is gone. When I started working at &lt;em&gt;The Outline&lt;/em&gt;, I was offered a choice of a new MacBook Pro or a MacBook Air for my work computer, and I chose the MacBook Air, with its good keyboard that doesn’t break from dust. I’m fully committed to this bit.&lt;/p&gt;

&lt;p&gt;Apple still hasn’t said anything about this, save for the &lt;a href=&quot;https://support.apple.com/en-us/HT205662&quot;&gt;strange tech support page&lt;/a&gt; that tells you how to use a can of air on your non-functional keyboard. Since that time, plenty of other people have messaged me about their dead spacebars and V and N keys, sometimes pointing knives at them because there is no other way on this earth to cope. I sympathize.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot; readability=&quot;4.7619047619048&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;what am i supposed to do when the space bar stops working. WHAT WERE THEY THINKING WITH THIS F⚠️CKING KEYBOARD &lt;a href=&quot;https://t.co/tFHsLYT49T&quot;&gt;pic.twitter.com/tFHsLYT49T&lt;/a&gt;&lt;/p&gt;
— Casey Neistat (@CaseyNeistat) &lt;a href=&quot;https://twitter.com/CaseyNeistat/status/982430762640314370?ref_src=twsrc%5Etfw&quot;&gt;April 7, 2018&lt;/a&gt;&lt;/blockquote&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot; readability=&quot;6.6737967914439&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;&lt;a href=&quot;https://twitter.com/caseyjohnston?ref_src=twsrc%5Etfw&quot;&gt;@caseyjohnston&lt;/a&gt; got a new macbook, remembered your keyboard article, and was like “i’ll just be really careful.” got a dead key 36 hours in&lt;/p&gt;
— Jon Bois (@jon_bois) &lt;a href=&quot;https://twitter.com/jon_bois/status/942073927513321475?ref_src=twsrc%5Etfw&quot;&gt;December 16, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot; readability=&quot;4.0843373493976&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;.&lt;a href=&quot;https://twitter.com/caseyjohnston?ref_src=twsrc%5Etfw&quot;&gt;@caseyjohnston&lt;/a&gt; have you gotten an external keyboard yet? I'm seriously almost at that point &lt;a href=&quot;https://t.co/A8kS43SFSK&quot;&gt;https://t.co/A8kS43SFSK&lt;/a&gt;&lt;/p&gt;
— Louise Matsakis (@lmatsakis) &lt;a href=&quot;https://twitter.com/lmatsakis/status/920641570809901056?ref_src=twsrc%5Etfw&quot;&gt;October 18, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot; readability=&quot;5.3089005235602&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;My MacBook keyboard broke-just out of warranty. $700 for new keyboard. only solution &lt;a href=&quot;https://twitter.com/Apple?ref_src=twsrc%5Etfw&quot;&gt;@apple&lt;/a&gt; tried replacing keys. Seems like a systemic prob&lt;/p&gt;
— Scott Wright (@Scott_Wright1) &lt;a href=&quot;https://twitter.com/Scott_Wright1/status/920463124104278016?ref_src=twsrc%5Etfw&quot;&gt;October 18, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot; readability=&quot;7.4716981132075&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;My personal failure rate with the butterfly keyboard is 100%, and at the prices Apple charges, I am unwilling to take that chance again. (Went to Surface Pro instead.)&lt;/p&gt;
— Marko Kloos (@markokloos) &lt;a href=&quot;https://twitter.com/markokloos/status/985148481152143360?ref_src=twsrc%5Etfw&quot;&gt;April 14, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot; readability=&quot;6.4341637010676&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;When the time came to upgrade, I got the (still available) old body style of the MBP 15&quot; with the tried-and-true keyboard instead of the new thinner butterfly keyboard model. I partially blame &lt;a href=&quot;https://twitter.com/caseyjohnston?ref_src=twsrc%5Etfw&quot;&gt;@caseyjohnston&lt;/a&gt;. &lt;a href=&quot;https://t.co/yI69hghM2y&quot;&gt;pic.twitter.com/yI69hghM2y&lt;/a&gt;&lt;/p&gt;
— Marko Kloos (@markokloos) &lt;a href=&quot;https://twitter.com/markokloos/status/950738240063131648?ref_src=twsrc%5Etfw&quot;&gt;January 9, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;p&gt;Also since that time, other manufacturers have started using extremely low-profile keyboards in their notebooks that &lt;a href=&quot;https://mashable.com/2018/03/31/huawei-matebook-x-pro-review/#ktiQU7P9raqq&quot;&gt;look troublingly like the MacBook’s and MacBook Pro’s keyboards&lt;/a&gt;. At the risk of being too overzealous, I’d say don’t buy those either. What should you buy instead of all these bad computers? I have no earthly idea.&lt;/p&gt;
&lt;div class=&quot;post-embed&quot;&gt;
&lt;div class=&quot;post-embed__wrapper&quot;&gt;
&lt;div class=&quot;card color_filter--black-white filter_type--none text_color--color text_size--xsmall desktop_text_size--medium card_type--huh&quot; data-color-filter=&quot;black-white&quot;&gt;
&lt;div class=&quot;huh-card huh-card--3&quot;&gt;
&lt;div class=&quot;huh-card__bg&quot; data-color-filter=&quot;black-white&quot;&gt;
&lt;div class=&quot;card__bg__image&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://outline-prod.imgix.net/20171017-m01A7fVpblZgmc6q0vMj?auto=format&amp;amp;q=60&amp;amp;w=1280&amp;amp;s=2a6ce6dfae420ea709e4b3c664b2c788&quot; srcset=&quot;https://im-dev-proxy.imgix.net/https%3A%2F%2Foutline-prod.imgix.net%2F20171017-m01A7fVpblZgmc6q0vMj%3Fauto%3Dformat%26q%3D60%26w%3D1280%26s%3D2a6ce6dfae420ea709e4b3c664b2c788?auto=format&amp;amp;q=60&amp;amp;w=760&amp;amp;s=dd0b4ae2793ab3ec1079b7d775658a14 760w, https://im-dev-proxy.imgix.net/https%3A%2F%2Foutline-prod.imgix.net%2F20171017-m01A7fVpblZgmc6q0vMj%3Fauto%3Dformat%26q%3D60%26w%3D1280%26s%3D2a6ce6dfae420ea709e4b3c664b2c788?auto=format&amp;amp;q=60&amp;amp;w=960&amp;amp;s=c33cfbe12ba53a23043b262b8bf1653d 960w, https://im-dev-proxy.imgix.net/https%3A%2F%2Foutline-prod.imgix.net%2F20171017-m01A7fVpblZgmc6q0vMj%3Fauto%3Dformat%26q%3D60%26w%3D1280%26s%3D2a6ce6dfae420ea709e4b3c664b2c788?auto=format&amp;amp;q=60&amp;amp;w=1280&amp;amp;s=ba603fe09061818bd6ad6766dcf57d0a 1280w, https://im-dev-proxy.imgix.net/https%3A%2F%2Foutline-prod.imgix.net%2F20171017-m01A7fVpblZgmc6q0vMj%3Fauto%3Dformat%26q%3D60%26w%3D1280%26s%3D2a6ce6dfae420ea709e4b3c664b2c788?auto=format&amp;amp;q=60&amp;amp;w=1400&amp;amp;s=7392c4420033fef4cc26a7f1984750c0 1400w, https://im-dev-proxy.imgix.net/https%3A%2F%2Foutline-prod.imgix.net%2F20171017-m01A7fVpblZgmc6q0vMj%3Fauto%3Dformat%26q%3D60%26w%3D1280%26s%3D2a6ce6dfae420ea709e4b3c664b2c788?auto=format&amp;amp;q=60&amp;amp;w=1600&amp;amp;s=8c7c17745ab5d6e544271ef1633ffb3c 1600w, https://im-dev-proxy.imgix.net/https%3A%2F%2Foutline-prod.imgix.net%2F20171017-m01A7fVpblZgmc6q0vMj%3Fauto%3Dformat%26q%3D60%26w%3D1280%26s%3D2a6ce6dfae420ea709e4b3c664b2c788?auto=format&amp;amp;q=60&amp;amp;w=2000&amp;amp;s=b8eab159137ed0399053531f3de362ec 2000w, https://im-dev-proxy.imgix.net/https%3A%2F%2Foutline-prod.imgix.net%2F20171017-m01A7fVpblZgmc6q0vMj%3Fauto%3Dformat%26q%3D60%26w%3D1280%26s%3D2a6ce6dfae420ea709e4b3c664b2c788?auto=format&amp;amp;q=60&amp;amp;w=2400&amp;amp;s=3a98c2ae4ced6a7e409eb27221465a83 2400w, https://im-dev-proxy.imgix.net/https%3A%2F%2Foutline-prod.imgix.net%2F20171017-m01A7fVpblZgmc6q0vMj%3Fauto%3Dformat%26q%3D60%26w%3D1280%26s%3D2a6ce6dfae420ea709e4b3c664b2c788?auto=format&amp;amp;q=60&amp;amp;w=3000&amp;amp;s=df3baefcdc5988595fd83b7e2a3ac7a4 3000w&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;huh-card__container&quot;&gt;
&lt;div class=&quot;huh-card__content&quot;&gt;
&lt;p class=&quot;huh-card__eyebrow&quot;&gt;The Future&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Read More&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

</description>
<pubDate>Wed, 25 Apr 2018 21:52:11 +0000</pubDate>
<dc:creator>tomduncalf</dc:creator>
<og:type>article</og:type>
<og:url>https://theoutline.com/post/4277/dont-buy-the-new-macbook-pros-even-on-sale-in-my-opinion</og:url>
<og:title>Don’t buy the MacBook Pros even on sale, in my opinion</og:title>
<og:description>I sold mine back to Apple. Yes, that bad.</og:description>
<og:image>https://outline-prod.imgix.net/20180425-kcur1P8em6sfCSAWY3no?auto=format&amp;q=60&amp;w=1280&amp;s=a5d56054ccdfd43112d1b576abbe4479</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://theoutline.com/post/4277/dont-buy-the-new-macbook-pros-even-on-sale-in-my-opinion</dc:identifier>
</item>
<item>
<title>Kazakhstan is changing its alphabet from Cyrillic to Latin-based</title>
<link>http://www.bbc.com/capital/story/20180424-the-cost-of-changing-an-entire-countrys-alphabet</link>
<guid isPermaLink="true" >http://www.bbc.com/capital/story/20180424-the-cost-of-changing-an-entire-countrys-alphabet</guid>
<description>&lt;p&gt;&lt;a href=&quot;http://www.bbc.com/capital/tags/the-economics-of-change&quot;&gt; &lt;img src=&quot;http://ichef.bbci.co.uk/images/ic/raw/p064kt3r.jpg&quot; border=&quot;0&quot; alt=&quot;The Economics of Change&quot; width=&quot;100%&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt; The change, announced on a blustery Tuesday morning in mid-February, was small but significant – and it elicited a big response.&lt;/p&gt;&lt;p&gt;“This one is more beautiful!” Asset Kaipiyev exclaims in surprise. The co-founder of a small restaurant in Kazakhstan’s capital Astana, Kaipiyev had just been shown the latest version of the new alphabet, approved by President Nursultan Nazarbayev earlier in the day.&lt;/p&gt;&lt;p&gt;The government signed off on a new alphabet, based on a Latin script instead of Kazakhstan’s current use of Cyrillic, in October. But it has faced vocal criticism from the population – a rare occurrence in this nominally democratic country ruled by Nazarbayev’s iron fist for almost three decades.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Pinch and zoom on mobile to expand.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;In this first version of the new alphabet,apostrophes were used to depict sounds specific to the Kazakh tongue, prompting critics to call it “ugly”.&lt;/p&gt;&lt;p&gt;The second variation, which Kaipiyev liked better, makes use of acute accents above the extra letters. So, for example, the Republic of Kazakhstan, which would in the first version have been Qazaqstan Respy’bli’kasy, is now Qazaqstan Respýblıkasy, removing the apostrophes.&lt;/p&gt;&lt;p&gt;&lt;em&gt;You might also like:&lt;br/&gt;&lt;/em&gt;&lt;a href=&quot;http://www.bbc.com/capital/story/20180417-a-thrilling-mission-to-get-the-swedish-to-change-overnight&quot;&gt;- A 'thrilling' mission to get the Swedish to change overnight&lt;/a&gt;&lt;/p&gt;&lt;p&gt; “It is more beautiful than the former variant,” says Kaipiyev. “I don’t like the old one because it looks like a tadpole.”&lt;/p&gt;&lt;p&gt;Then it hit him. His restaurant, which opened in December, is called Sa’biz –spelt using the first version of the alphabet. All his marketing materials, the labelling on napkin holders and menus, and even the massive sign outside the building will have to be replaced.&lt;/p&gt;&lt;p&gt;In his attempt to get ahead by launching in the new alphabet, Kaipiyev had not predicted that the government would revise it. He thinks it will cost about $3,000 to change the spelling of the name on everything to the new version, Sábiz.&lt;/p&gt;&lt;p&gt;What Kaipiyev and other small business owners are going through will be happening at a larger scale as the government aims to transition fully to the Latin-based script by 2025. It’s an ambitious goal in a nation where the majority of the population are more fluent in Russian than in Kazakh.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Mother tongue&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;According to the 2016 census, ethnic Kazakhs make up about two-thirds of the population, while ethnic Russians are about 20%. But years under Soviet rule mean Russian is spoken by nearly everyone in country – roughly 94% of the more than 18 million citizens are fluent in it. Kazakh fluency is at second place, at 74%.&lt;/p&gt;&lt;blockquote readability=&quot;6&quot;&gt;&lt;p&gt; Years under Soviet rule mean Russian is spoken by nearly everyone in country – roughly 94% of the population is fluent in it &lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Frequency of usage depends on the environment. In the Russian-influenced northern provinces and city centres, like Almaty and the capital Astana, Russian is used both on the street and in state offices. But in the south and west, Kazakh is more regularly used.&lt;/p&gt;&lt;p&gt;That the Kazakh language is currently written in Cyrillic – and the persistent use of Russian in elite circles – is a legacy of the Soviet Union’s rule, one that some of its neighbouring countries sought to shed right after the union’s collapse in 1991. Azerbaijan, for example, started introducing textbooks in Latin script the next year, while Turkmenistan followed suit in 1993. Kazakhstan is making the transition almost three decades on, in a different economic environment that makes the costs hard to predict.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Pinch and zoom on mobile to expand.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The cost of change&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;So far, &lt;a href=&quot;https://www.ktk.kz/ru/news/video/2018/01/17/88098&quot;&gt;state media has reported&lt;/a&gt; that the government’s total budget for the seven-year transition – which has been divided into three stages – will amount to roughly 218 billion tenge ($664m). &lt;a href=&quot;https://vlast.kz/novosti/26488-na-publicnoe-obsuzdenie-vynesen-plan-meropriatij-po-perehodu-na-latinicu.html&quot;&gt;About 90% of that amount&lt;/a&gt; is going to education programmes the publication of textbooks for education programmes in the new Latin script, including for literature classes.&lt;/p&gt;&lt;p&gt;According to state news media, the government has allocated roughly 300 million tenge each ($922,000) for 2018 and 2019; this money will go towards education in primary and secondary schools, says Eldar Madumarov, an economist and professor at KIMEP University in Almaty.&lt;/p&gt;&lt;blockquote readability=&quot;7&quot;&gt;&lt;p&gt; The government’s total budget for the seven-year transition will amount to roughly 218 billion tenge, or $664 million &lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Meanwhile, the translation of teaching kits and textbooks will begin this year, according to state media, while teachers nationwide will start teaching pre-school and first grade students the new alphabet in 2020, adding a grade each year until 2025, when all levels from pre-school to the final grade will have fully transitioned.&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;http://ichef.bbci.co.uk/images/ic/raw/p0656d2w.jpg&quot; alt=&quot;“BBC&quot; capital=&quot;&quot; survey=&quot;&quot; on=&quot;&quot; us=&quot;&quot; worker=&quot;&quot; optimism=&quot;&quot; width=&quot;100%&quot;/&gt;&lt;/p&gt;&lt;p&gt;There is also budget for developing a language converter IT program to recode Cyrillic script into Latin in the third quarter of 2018 (approximately $166,000), improving the qualifications of secondary school teachers ($33.2m), and hiring influential bloggers to push forward an awareness campaign for the final stage of the transition, beginning in 2024 ($1.4 million).&lt;/p&gt;&lt;p&gt;But without a clear breakdown provided by the government, some economists have found it difficult to properly assess the direct costs of this massive undertaking. (The ministries of foreign affairs, education, and culture did not respond to requests for comment and clarification.)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Hidden costs&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The piecemeal reporting of how the transition will happen makes one economist worried about the unexpected costs.&lt;/p&gt;&lt;p&gt;“If this reform is not properly implemented, the risks are high that highly qualified people from the Russian-speaking majority, which includes also ethnic Kazakhs, may want to consider emigration,” says Madumarov. “The risks may be that some of their opportunities would be cut.”&lt;/p&gt;&lt;blockquote readability=&quot;7&quot;&gt;&lt;p&gt; If this reform is not properly implemented, highly qualified people from the Russian-speaking majority may want to consider emigration – Eldar Madumarov &lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;In late February, the extent of the issue was on display when Nazarbayev – who is comfortably bilingual – ordered that all cabinet meetings be held in Kazakh. Since Russian has long been the lingua franca of state affairs, government officials’ command of Russian often surpasses their Kazakh. One meeting was broadcast over TV, and it showed officials struggling to express themselves. Some even opted to wear translation headsets.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Bureaucratic characters&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;There’s also the cost of changing the language of government affairs. IDs, passports, printed laws and regulations – all the paperwork that governments need in order to function will have to be translated. While this has been reportedly part of the second and final stage of the transition, there has been no listed amount for this expense, says Kassymkhan Kapparov, director of the Almaty-based Bureau for Economic Research of Kazakhstan. &lt;/p&gt;&lt;p&gt;For things like passports and IDs, there is already a fixed fee to renew, “so the only thing that would change is that the letters would just change in the software,” Kapparov says, adding that a new passport costs roughly $60 while an ID card is about $1.50. “The government left it blank. I think the logic is that it would not cost anything.”&lt;/p&gt;&lt;p&gt;But he remains most curious about the third stage, which reportedly begins in 2024 and includes the translation of internal business documents within the central and local state bodies, while state media would also need to implement the new alphabet.&lt;/p&gt;&lt;p&gt;“For the state’s own media to use the new alphabet, you have to train people first of all, then you have to change all the IT infrastructure to embed this script. And then you have to change all the planks [signboards] and the letterheads and stamps and signs,” he says. “For that, they didn’t provide the estimate… based on my estimates, it would be somewhere between 15 to 30 million [dollars].”&lt;/p&gt;&lt;p&gt;That number is only for the public sector, though. “For the private sector, of course they would have to do it themselves. It could be double, it could be ten times,” Kapparov says. “It depends on how hard the government goes about it, like would they require it to change in a single year? It’s possible. With our government, you never know.”&lt;/p&gt;&lt;p&gt;Kapparov also worries that people, especially the older generation, would struggle to read and write in the new Latin script, so communications within the public sector may have to be in several languages at once.&lt;/p&gt;&lt;p&gt;“You can call it the language burden, because when you write a letter inside the public sector, you would have to write it in Russian, in Kazakh, and in Kazakh in the new script… and for that you would need to employ translators,” he says. “This creates additional costs and additional inefficiencies and of course the government doesn’t show it in their budget. But it will create an additional burden on the government.”&lt;/p&gt;&lt;p&gt;When it comes to direct costs, Kapparov is confident that his estimates – which he did in 2007 after the first feasibility study came out and again in January of this year when budgetary information started trickling out via state media – would not be more than $1bn for the entire transition.&lt;/p&gt;&lt;p&gt;But the director of Kazakhstan’s Centre for Macroeconomic Research, Olzhas Khudaibergenov, believes the whole transition will cost far less than Kapparov’s estimate. He thinks all paper documents costs will just be folded into the government’s usual budget. “Real expenses will be only for informational and explanatory programmes to support the transition.&lt;/p&gt;&lt;p&gt;“I estimate that the annual budget will not exceed two to three billion tenge [$6.1m-$9.2m] within 2018 to 2025.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Economic benefits?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Kapparov says this alphabet transition is “hard to sell” for the government, and there won’t be a direct return on investment.&lt;/p&gt;&lt;blockquote readability=&quot;6&quot;&gt;&lt;p&gt; The alphabet change should be seen as more of a social and cultural development programme – Kassymkhan Kapparov &lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Rather, it “should be seen as more of a social and cultural development programme of the government,” he says.&lt;/p&gt;&lt;p&gt;Khudaibergenov agrees. “It is more a question of national identity which we are trying to find, and are ready to pay for that.”&lt;/p&gt;&lt;p&gt;KIMEP University professor Madumarov believes the economy could be slowed by political ramifications of the language change. While some have speculated that Nazarbayev’s decision to switch might signal cooling ties with Russia, the gradual shift to a Latin-script language could also weaken trade relations with post-Soviet countries.&lt;/p&gt;&lt;p&gt;Currently, up to 10% of the current trade flow between Russia, Kazakhstan and Ukraine can be explained by the convenience of a shared language, which in some ways translates to a shared culture and mentality, says Madumarov. This also means that Russian-speaking Kazakhs have more economic mobility between countries. Meanwhile, Azerbaijan and Georgia, nations that are not as fluent in Russian, have weaker trade links.&lt;/p&gt;&lt;p&gt;Inversely, he says that the benefits to having a Latin-script alphabet means being better integrated with most of the Western world. As an example, Turkey, which switched to a Latin-based alphabet from its former Arabic script in 1928, has managed to form alliances with the European Union and was in negotiations – up until recently, when the government moved towards a more autocratic direction – to be a member.&lt;/p&gt;&lt;p&gt;Turkey has long been used as an example of how modernisation of the language and legal systems led to its position today as an economic power, says Barbara Kellner-Heinkele, a Berlin-based expert in Turkic languages and Turkic history. But she says this progress is due more to growing literacy and republic founder Ataturk’s firm grip over every aspect of society.&lt;/p&gt;&lt;p&gt;Turkey’s 1928 switch to a Latin script “was done in no time”, but back then, few Turks could read and write: Ataturk needed educated people for his country to be on the same level as Europe and the US, “and part of the education drive was the new alphabet”, she says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;An independent nation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Kazakhstan’s transition is more about setting itself apart from its Soviet past than literacy or economics, Kellner-Heinkele says. “It is a political argument to show that they are an independent state and they are modern and they are a nation.”&lt;/p&gt;&lt;p&gt;Fazylzhanova Muratkyzy, a linguist who worked with the government to create the new alphabet, echoes this assessment, and says many Kazakhs associate the Cyrillic-based script to Soviet control.&lt;/p&gt;&lt;p&gt;Young people, especially, are welcoming the change.&lt;/p&gt;&lt;p&gt;Based on surveys that her linguistic institute have conducted over the last decade, Muratkyzy says that 47% of the younger generation – aged 18 to 25 – supported a switch to a Latin-based script in 2007; that number jumped to 80% in 2016.&lt;/p&gt;&lt;blockquote readability=&quot;6&quot;&gt;&lt;p&gt; 47% of the younger generation supported a switch to a Latin-based script in 2007; that number jumped to 80% in 2016 &lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;“It is the choice of the people, of the nation. And with this new alphabet, it is connected to our dreams and our future,” she says. “It shows that our independent history is finally beginning.”&lt;/p&gt;&lt;p&gt;Munalbayeva Daurenbekovna, head of the National Academic Library, has been holding open classes for librarians and other interested parties to help them get used to the Latin script. She is optimistic the that young people especially will have no trouble learning the new script.&lt;/p&gt;&lt;p&gt;“Teachers would have to learn every day for one month. For children, it would only take 10 lessons, because children learn faster than adults.”&lt;/p&gt;&lt;p&gt;For Kaipiyev, the owner of Sa’biz, moving away from the Cyrillic script – no matter how tedious it is for him as a small business owner – is something he fully supports. “We want to connect with Europe and America, and with other foreign countries. This will help us turn the page to the next chapter,” he says.&lt;/p&gt;&lt;p&gt;As for changing his restaurant material to reflect the latest version of the alphabet?&lt;/p&gt;&lt;p&gt;“I think I will leave it the same for now,” Kaipiyev says, after a moment’s consideration. “We will change it when the people can actually read it.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;Additional reporting by Makhabbat Kozhabergenova. Additional research by Miriam Quick. &lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;--&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;To comment on this story or anything else you have seen on BBC Capital, please head over to our&lt;/em&gt; &lt;a href=&quot;https://www.facebook.com/BBCCapital&quot;&gt;&lt;strong&gt;&lt;em&gt;Facebook&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;em&gt;  page or message us on &lt;/em&gt;&lt;a href=&quot;https://twitter.com/BBC_Capital&quot;&gt;&lt;strong&gt;&lt;em&gt;Twitter&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;If you liked this story, sign up for the weekly bbc.com features &lt;/em&gt;&lt;a href=&quot;http://pages.emails.bbc.com/subscribe/&quot;&gt;&lt;strong&gt;&lt;em&gt;newsletter&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;em&gt; called &quot;If You Only Read 6 Things This Week&quot;. A handpicked selection of stories from BBC Future, Culture, Capital and Travel, delivered to your inbox every Friday.&lt;/em&gt;&lt;/p&gt;
                        </description>
<pubDate>Wed, 25 Apr 2018 20:19:17 +0000</pubDate>
<dc:creator>happy-go-lucky</dc:creator>
<og:title>The cost of changing an entire country’s alphabet</og:title>
<og:type>article</og:type>
<og:url>http://www.bbc.com/capital/story/20180424-the-cost-of-changing-an-entire-countrys-alphabet</og:url>
<og:description>The Central Asian nation of Kazakhstan is changing its alphabet from Cyrillic script to the Latin-based style favoured by the West. What are the economics of such a change?</og:description>
<og:image>http://ichef.bbci.co.uk/wwfeatures/live/624_351/images/live/p0/65/8x/p0658xm6.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.bbc.com/capital/story/20180424-the-cost-of-changing-an-entire-countrys-alphabet</dc:identifier>
</item>
<item>
<title>ReformedFelonForHire.com – High quality software skills, at a competitive price</title>
<link>http://reformedfelonforhire.com/index.html</link>
<guid isPermaLink="true" >http://reformedfelonforhire.com/index.html</guid>
<description>&lt;h4&gt;Hi. I'm a software engineer with 10 years of professional experience. I'm also married with 5.1 kids and have run out of money for May's bills. You can hire me at an &lt;em&gt;extremely competitive&lt;/em&gt; rate of &lt;em&gt;$25 / hour&lt;/em&gt;. Check out &lt;a href=&quot;http://sdegutis.com/&quot;&gt;my portfolio website&lt;/a&gt; to see the kind of work I can do for you.&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;I'm a felon.&lt;/strong&gt; My crime is flashing a 17 year old. The first offense is just a misdemeanor. The second offense is an automatic felony and requires life registration as a sex offender. My second offense was 2 years ago. I spent two months in jail for it. Since then, I've been in intensive therapy. Everyone I know agrees I'm a different person now, and my therapist says I'm no longer at-risk.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I'm a highly qualified software engineer.&lt;/strong&gt; My first software company was purchased 10 years ago for $30k. My apps were featured in MacWorld magazine. I worked directly under a veteran software guru for 5 years. I'm able to do front-end, back-end, full-stack, iOS, macOS, and Electron. I feel very comfortable in JavaScript (ES6), Ruby, Python, Java (7 and 8), HTML5, CSS (and Less, Sass, and Stylus), React.js, Vue.js, Objective-C, Swift, Clojure, Node.js, Express.js, Sinatra, C, Lua, some Rails and a little C++. But I can pick up any technology quickly. &lt;em&gt;I can pretty much write any software solution you need, in a reasonably short time.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;My skills are highly sought after.&lt;/strong&gt; I've been offered probably 20 jobs in the past 6 months, which is when I was released from jail and actively began my job search. Goldman Sachs offered me a position making $180k base with $45k potential in bonuses. Enova offered me $100k with $10k in potential bonuses. Expedia eagerly offered me $65/hour. These are just a few of the more recent job offers I've received. Every company is enthusiastic to hire me. But at the background check phase they all retract their offer. &lt;em&gt;This is good news for you, because it means you can hire me today at an extremely competitive price&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I'm a family man.&lt;/strong&gt; My wife and I have 5 kids and another one on the way. I've been unemployed for 13 months. We've run out of unemployment, we have used up all our financial aid. We don't have enough to pay our bills through May 2018. All I'm trying to do is support my family using the only skill I have at this point, writing software. &lt;em&gt;Fortunately for you, this means you can get high quality software work at a competitive rate, as early as &lt;strong&gt;today&lt;/strong&gt;!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I'm available for hire TODAY&lt;/strong&gt;. &lt;a href=&quot;mailto:sbdegutis@gmail.com&quot;&gt;Email me&lt;/a&gt; to set up a phone call. Also check out &lt;a href=&quot;http://sdegutis.com/&quot;&gt;my portfolio website.&lt;/a&gt; I can start working for you ASAP. I'm located near Chicago, and can't relocate or travel out of state, but I have years of experience working remotely. My rate is &lt;em&gt;extremely competitive&lt;/em&gt; and several people who have seen my portfolio have agreed that you can get an amazing deal by hiring me considering my skill set.&lt;/p&gt;
</description>
<pubDate>Wed, 25 Apr 2018 19:19:37 +0000</pubDate>
<dc:creator>FelonForHire</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>http://reformedfelonforhire.com/index.html</dc:identifier>
</item>
<item>
<title>Ethereum Sharding FAQ</title>
<link>https://github.com/ethereum/wiki/wiki/Sharding-FAQ</link>
<guid isPermaLink="true" >https://github.com/ethereum/wiki/wiki/Sharding-FAQ</guid>
<description>&lt;div class=&quot;markdown-body&quot;&gt;


&lt;p&gt;Currently, in all blockchain protocols each node stores all states (account balances, contract code and storage, etc.) and processes all transactions. This provides a large amount of security, but greatly limits scalability: a blockchain cannot process more transactions than a single node can. In large part because of this, Bitcoin is limited to ~3-7 transactions per second, Ethereum to 7-15, etc. However, this poses a question: are there ways to create a new mechanism, where only small subset of nodes verifies each transaction? As long as there are sufficiently many nodes verifying each transaction that the system is still highly secure, but a sufficiently small percentage of the total validator set that the system can process many transactions in parallel, could we not use such a technique to greatly increase a blockchain's throughput?&lt;/p&gt;
&lt;h3&gt;What are some trivial but flawed ways of solving the problem?&lt;/h3&gt;
&lt;p&gt;There are three main categories of “easy solutions”. The first is to give up on scaling individual blockchains, and instead assume that users will be using many different “altcoins”. This greatly increases throughput, but comes at a cost of security: an N-factor increase in throughput using this method necessarily comes with an N-factor decrease in security. Hence, it is arguably non-viable for more than small values of N.&lt;/p&gt;
&lt;p&gt;The second is to simply increase the block size limit. This can work and in some situations may well be the correct prescription, as block sizes may well be constrained more by politics than by realistic technical considerations. But regardless of one’s beliefs about any individual case such an approach inevitably has its limits: if one goes too far, then nodes running on consumer hardware will drop out, the network will start to rely exclusively on a very small number of supercomputers running the blockchain, which can lead to great centralization risk.&lt;/p&gt;
&lt;p&gt;The third is “merge mining”, a technique where there are many chains, but all chains share the same mining power (or, in proof of stake systems, stake). Currently, Namecoin gets a large portion of its security from the Bitcoin blockchain by doing this. If all miners participate, this theoretically can increase throughput by a factor of N without compromising security. However, this also has the problem that it increases the computational and storage load on each miner by a factor of N, and so in fact this solution is simply a stealthy form of block size increase.&lt;/p&gt;
&lt;p&gt;Even if this is deemed acceptable, there is still the defect that the chains are not truly &quot;tied together&quot;; only a small amount of economic incentive is required to convince the miners to abandon or compromise one specific chain. This possibility is in fact quite real, and there have been &lt;a href=&quot;https://web.archive.org/web/20170331105910/https://bitcoin.stackexchange.com/questions/3472/what-is-the-story-behind-the-attack-on-coiledcoin&quot; rel=&quot;nofollow&quot;&gt;actual historical incidents&lt;/a&gt; of merge-mined chains being attacked, as well as developers who have explicitly advocated using merge mining attacks as &lt;a href=&quot;http://www.truthcoin.info/blog/contracts-oracles-sidechains/&quot; rel=&quot;nofollow&quot;&gt;a &quot;governance&quot; feature&lt;/a&gt;, destroying chains that are not &quot;profitable&quot; to a given coalition.&lt;/p&gt;
&lt;p&gt;If only a few miners/mining pools participate in merge-mining each chain, then there is an imminent &lt;a href=&quot;https://eprint.iacr.org/2017/791.pdf&quot; rel=&quot;nofollow&quot;&gt;risk of centralization&lt;/a&gt;, while the security benefits of merge mining are also greatly reduced.&lt;/p&gt;
&lt;h3&gt;This sounds like there’s some kind of scalability trilemma at play. What is this trilemma and can we break through it?&lt;/h3&gt;
&lt;p&gt;The trilemma claims that blockchain systems can only at most have two of the following three properties:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Decentralization&lt;/strong&gt; (defined as the system being able to run in a scenario where each participant only has access to O(c) resources, ie. a regular laptop or small VPS)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt; (defined as being able to process O(n) &amp;gt; O(c) transactions)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt; (defined as being secure against attackers with up to O(n) resources)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;In the rest of this document, we’ll continue using &lt;strong&gt;c&lt;/strong&gt; to refer to the size of computational resources (including computation, bandwidth and storage) available to each node, and &lt;strong&gt;n&lt;/strong&gt; to refer to the size of the ecosystem in some abstract sense; we assume that transaction load, state size, and the market cap of a cryptocurrency are all proportional to &lt;strong&gt;n&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;Some people claim that because of Metcalfe’s law, the market cap of a cryptocurrency should be proportional to n^2, and not n. Do they have a point?&lt;/h3&gt;
&lt;p&gt;No.&lt;/p&gt;
&lt;h3&gt;Why not?&lt;/h3&gt;
&lt;p&gt;Metcalfe’s law claims that the value of a network is proportional to the square of the number of users (n^2), because if a network has n users then the network has value for each user, but then the value for each individual user is itself proportional to the number of users because if a network has n users that’s n-1 potential connections through the network that each individual user could benefit from.&lt;/p&gt;
&lt;p&gt;In practice, &lt;a href=&quot;https://en.wikipedia.org/wiki/Metcalfe%27s_law&quot; rel=&quot;nofollow&quot;&gt;empirical research suggests&lt;/a&gt; that the value of a network with n users is close to “n^2 proportionality for small values of n and (n × log n) proportionality for large values of n.” This makes sense because for small values, the argument holds true, but once a system gets bigger, two effects slow the growth down. First, growth in practice often happens in communities, and so in a medium-scale network the network often already provides most of the connections that each user cares about. Second, connections are often substitutes from each other, and you could argue that people only derive ~O(log(k)) value from having k connections – having 23 brands of deodorant to choose from is nice, but it’s not that much better than having 22 choices, whereas the difference between one choice and zero choices is very significant.&lt;/p&gt;
&lt;p&gt;Furthermore, even if the value of a cryptocurrency is proportional to O(k * log(k)) with k users, if we accept the above explanation as the reason why this is the case, then that also implies that transaction volume is also O(k * log(k)), as the log(k) value per user theoretically comes from that user exercising log(k) connections through the network, and state size should also in many cases grow with O(k * log(k)) as there are at least some kinds of state that are relationship-specific rather than user-specific. Hence, assuming n = O(k * log(k)) and basing everything off of &lt;strong&gt;n&lt;/strong&gt; (size of the ecosystem) and &lt;strong&gt;c&lt;/strong&gt; (a single node’s computing power) is a perfectly fine model for us to use.&lt;/p&gt;
&lt;h3&gt;What are some moderately simple but only partial ways of solving the scalability problem?&lt;/h3&gt;
&lt;p&gt;Many sharding proposals (eg. &lt;a href=&quot;https://www.comp.nus.edu.sg/%7Eloiluu/papers/elastico.pdf&quot; rel=&quot;nofollow&quot;&gt;this early BFT sharding proposal from Loi Luu et al at NUS&lt;/a&gt;, more recent application of similar ideas in &lt;a href=&quot;https://docs.zilliqa.com/whitepaper.pdf&quot; rel=&quot;nofollow&quot;&gt;Zilliqa&lt;/a&gt;, as well as &lt;a href=&quot;http://www.deadalnix.me/2016/11/06/using-merklix-tree-to-shard-block-validation&quot; rel=&quot;nofollow&quot;&gt;this Merklix tree&lt;/a&gt;&lt;sup&gt;&lt;a href=&quot;https://github.com/ethereum/wiki/wiki/Sharding-FAQ#ftnt_ref1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; approach that has been suggested for Bitcoin) attempt to either only shard transaction processing or only shard state, without touching the other&lt;sup&gt;&lt;a href=&quot;https://github.com/ethereum/wiki/wiki/Sharding-FAQ#ftnt_ref2&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. These efforts are admirable and may lead to some gains in efficiency, but they run into the fundamental problem that they only solve one of the two bottlenecks. We want to be able to process 10,000+ transactions per second without either forcing every node to be a supercomputer or forcing every node to store a terabyte of state data, and this requires a comprehensive solution where the workloads of state storage, transaction processing and even transaction downloading and re-broadcasting are all spread out across nodes.&lt;/p&gt;
&lt;p&gt;Particularly, note that this requires changes at the P2P level, as a broadcast model is not scalable since it requires every node to download and re-broadcast O(n) data (every transaction that is being sent), whereas our decentralization criterion assumes that every node only has access to O(c) resources of all kinds.&lt;/p&gt;
&lt;h3&gt;What about approaches that do not try to “shard” anything?&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://hackingdistributed.com/2015/10/14/bitcoin-ng/&quot; rel=&quot;nofollow&quot;&gt;Bitcoin-NG&lt;/a&gt; can increase scalability somewhat by means of an alternative blockchain design that makes it much safer for the network if nodes are spending large portions of their CPU time verifying blocks. In simple PoW blockchains, there are high centralization risks and the safety of consensus is weakened if capacity is increased to the point where more than about 5% of nodes’ CPU time is spent verifying blocks; Bitcoin-NG’s design alleviates this problem. However, this can only increase the scalability of transaction capacity by a constant factor of perhaps 5-50x&lt;sup&gt;&lt;a href=&quot;https://github.com/ethereum/wiki/wiki/Sharding-FAQ#ftnt_ref3&quot;&gt;3&lt;/a&gt;,&lt;a href=&quot;https://github.com/ethereum/wiki/wiki/Sharding-FAQ#ftnt_ref4&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;, and does not increase the scalability of state. That said, Bitcoin-NG-style approaches are not mutually exclusive with sharding, and the two can certainly be implemented at the same time.&lt;/p&gt;
&lt;p&gt;Channel-based strategies (lightning network, Raiden, etc) can scale transaction capacity by a constant factor but cannot scale state storage, and also come with their own unique sets of tradeoffs and limitations particularly involving denial-of-service attacks. On-chain scaling via sharding (plus other techniques) and off-chain scaling via channels are arguably both necessary and complementary.&lt;/p&gt;
&lt;p&gt;There exist approaches that use advanced cryptography, such as &lt;a href=&quot;https://scalingbitcoin.org/papers/mimblewimble.txt&quot; rel=&quot;nofollow&quot;&gt;Mimblewimble&lt;/a&gt; and strategies based on ZK-SNARKs, to solve one specific part of the scaling problem: initial full node synchronization. Instead of verifying the entire history from genesis, nodes could verify a cryptographic proof that the current state legitimately follows from the history. These approaches do solve a legitimate problem, although it is worth noting that one can rely on cryptoeconomics instead of pure cryptography to solve the same problem in a much simpler way - see Ethereum’s current implementations of &lt;a href=&quot;https://github.com/ethereum/go-ethereum/pull/1889&quot;&gt;fast syncing&lt;/a&gt; and &lt;a href=&quot;https://github.com/paritytech/parity/wiki/Warp-Sync&quot;&gt;warp syncing&lt;/a&gt;. Neither solution does anything to alleviate state size growth or the limits of online transaction processing.&lt;/p&gt;
&lt;h3&gt;How does Plasma, state channels and other layer 2 technologies fit into the trilemma?&lt;/h3&gt;
&lt;p&gt;In the event of a large attack on Plasma subchains, all users of the Plasma subchains would need to withdraw back to the root chain. If Plasma has O(N) users, then this will require O(N) transactions, and so O(N / C) time to process all of the withdrawals. If withdrawal delays are fixed to some D (ie. the naive implementation), then as soon as N &amp;gt; C * D, there will not be enough space in the blockchain to process all withdrawals in time, and so the system will be insecure; in this mode, Plasma should be viewed as increasing scalability only by a (possibly large) constant factor. If withdrawal delays are flexible, so they automatically extend if there are many withdrawals being made, then this means that as N increases further and further, the amount of time that an attacker can force everyone's funds to get locked up increases, and so the level of &quot;security&quot; of the system decreases further and further in a certain sense, as extended denial of access can be viewed as a security failure, albeit one milder than total loss of access. However, this is a different &lt;em&gt;direction&lt;/em&gt; of tradeoff from other solutions, and arguably a much milder tradeoff, hence why Plasma subchains are nevertheless a large improvement on the status quo. State channels have similar properties, though with different tradeoffs between versatility and speed of finality. Other layer 2 technologies include &lt;a href=&quot;https://people.cs.uchicago.edu/%7Eteutsch/papers/truebit.pdf&quot; rel=&quot;nofollow&quot;&gt;TrueBit&lt;/a&gt; off-chain interactive verification of execution and &lt;a href=&quot;https://raiden.network/&quot; rel=&quot;nofollow&quot;&gt;Raiden&lt;/a&gt;. &lt;a href=&quot;https://github.com/ethereum/wiki/wiki/Proof-of-Stake-FAQ&quot;&gt;Proof of stake&lt;/a&gt; with Casper would also improve scaling.&lt;/p&gt;
&lt;h3&gt;State size, history, cryptoeconomics, oh my! Define some of these terms before we move further!&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;State&lt;/strong&gt;: a set of information that represents the “current state” of a system; determining whether or not a transaction is valid, as well as the effect of a transaction, should in the simplest model depend only on state. Examples of state data include the UTXO set in bitcoin, balances + nonces + code + storage in ethereum, and domain name registry entries in Namecoin.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;History&lt;/strong&gt;: an ordered list of all transactions that have taken place since genesis. In a simple model, the present state should be a deterministic function of the genesis state and the history.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transaction&lt;/strong&gt;: an object that goes into the history. In practice, a transaction represents an operation that some user wants to make, and is cryptographically signed. In some systems transactions are called &lt;strong&gt;blobs&lt;/strong&gt;, to emphasize the fact that in these systems these objects may contain arbitrary data and may not in all cases represent an attempt to perform some operation in the protocol.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;State transition function&lt;/strong&gt;: a function that takes a state, applies a transaction and outputs a new state. The computation involved may involve adding and subtracting balances from accounts specified by the transaction, verifying digital signatures and running contract code.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Merkle tree&lt;/strong&gt;: a cryptographic hash tree structure that can store a very large amount of data, where authenticating each individual piece of data only takes O(log(n)) space and time. See &lt;a href=&quot;https://easythereentropy.wordpress.com/2014/06/04/understanding-the-ethereum-trie&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; for details. In Ethereum, the transaction set of each block, as well as the state, is kept in a Merkle tree, where the roots of the trees are committed to in a block.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Receipt&lt;/strong&gt;: an object that represents an effect of a transaction that is not directly stored in the state, but which is still stored in a Merkle tree and committed to in a block header or in a special location in the state so that its existence can later be efficiently proven even to a node that does not have all of the data. Logs in Ethereum are receipts; in sharded models, receipts are used to facilitate asynchronous cross-shard communication.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Light client&lt;/strong&gt;: a way of interacting with a blockchain that only requires a very small amount (we’ll say O(1), though O(log(c)) may also be accurate in some cases) of computational resources, keeping track of only the block headers of the chain by default and acquiring any needed information about transactions, state or receipts by asking for and verifying Merkle proofs of the relevant data on an as-needed basis.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;State root&lt;/strong&gt;: the root hash of the Merkle tree representing the state&lt;sup&gt;&lt;a href=&quot;https://github.com/ethereum/wiki/wiki/Sharding-FAQ#ftnt_ref5&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;img src=&quot;https://github.com/vbuterin/diagrams/raw/master/scalability_faq/image02.png&quot; width=&quot;450&quot;/&gt;&lt;br/&gt;&lt;em&gt;The Ethereum 1.0 state tree, and how the state root fits into the block structure&lt;/em&gt;
&lt;h3&gt;What is the basic idea behind sharding?&lt;/h3&gt;
&lt;p&gt;We split the state and history up into K = O(n / c) partitions that we call “shards”. For example, a sharding scheme on Ethereum might put all addresses starting with 0x00 into one shard, all addresses starting with 0x01 into another shard, etc. In the simplest form of sharding, each shard also has its own transaction history, and the effect of transactions in some shard k are limited to the state of shard k. One simple example would be a multi-asset blockchain, where there are K shards and each shard stores the balances and processes the transactions associated with one particular asset. In more advanced forms of sharding, some form of cross-shard communication capability, where transactions on one shard can trigger events on other shards, is also included.&lt;/p&gt;
&lt;h3&gt;What might a basic design of a sharded blockchain look like?&lt;/h3&gt;
&lt;p&gt;A simple approach is as follows. For simplicity, this design keeps track of data blobs only; it does not attempt to process a state transition function.&lt;/p&gt;
&lt;p&gt;There exist nodes called &lt;strong&gt;collators&lt;/strong&gt; that accept blobs on shard &lt;code&gt;k&lt;/code&gt; (depending on the protocol, collators either choose which &lt;code&gt;k&lt;/code&gt; or are randomly assigned some &lt;code&gt;k&lt;/code&gt;) and create &lt;strong&gt;collations&lt;/strong&gt;. A collation has a &lt;strong&gt;collation header&lt;/strong&gt;, a short message of the form &quot;This is a collation of blobs on shard &lt;code&gt;k&lt;/code&gt;, the parent collation is 0x7f1e74 and the Merkle root of the blobs is 0x3f98ea&quot;. Collations of each shard form a chain just like blocks in a traditional blockchain.&lt;/p&gt;
&lt;p&gt;A &quot;main chain&quot; processed by everyone still exists, but this main chain's role is limited to storing collation headers for all shards. The &quot;canonical chain&quot; of shard &lt;code&gt;k&lt;/code&gt; is the longest chain of valid collations on shard &lt;code&gt;k&lt;/code&gt; all of whose headers are inside the canonical main chain.&lt;/p&gt;
&lt;p&gt;Note that there are now several &quot;levels&quot; of nodes that can exist in such a system:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Super-full node&lt;/strong&gt; - fully downloads every collation of every shard, as well as the main chain, fully verifying everything.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Top-level node&lt;/strong&gt; - processes all main chain blocks, giving them &quot;light client&quot; access to all shards.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Single-shard node&lt;/strong&gt; - acts as a top-level node, but also fully downloads and verifies every collation on some specific shard that it cares more about.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Light node&lt;/strong&gt; - downloads and verifies the block headers of main chain blocks only; does not process any collation headers or transactions unless it needs to read some specific entry in the state of some specific shard, in which case it downloads the Merkle branch to the most recent collation header for that shard and from there downloads the Merkle proof of the desired value in the state.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;There is also a concept of &lt;strong&gt;windback verification&lt;/strong&gt;, where a light client can quickly gain a higher real-time assurance of the validity of a collation chain of some shard by fully downloading the most recent collations, with the goal of determining the longest collation header chain for which the most recent N collations (eg. N = 25) are verified to be fully valid and available.&lt;/p&gt;
&lt;h3&gt;What are the challenges here?&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Single-shard takeover attacks&lt;/strong&gt; - what if an attacker takes over the majority of the collators in one single shard, either to prevent any collations from getting enough signatures or, worse, to submit collations that are invalid?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;State transition execution&lt;/strong&gt; - single-shard takeover attacks are typically prevented with random sampling schemes, but such schemes also make it more difficult for collators to compute state roots, as they cannot have up-to-date state information for every shard that they could be assigned to. How do we ensure that light clients can still get accurate information about the state?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fraud detection&lt;/strong&gt; - if an invalid collation or state claim does get made, how can nodes (including light nodes) be reliably informed of this so that they can detect the fraud and reject the collation if it is truly fraudulent?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cross shard communication&lt;/strong&gt; - the above design supports no cross-shard communication. How do we add cross-shard communication safely?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The data availability problem&lt;/strong&gt; - as a subset of fraud detection, what about the specific case where data is missing from a collation?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Superquadratic sharding&lt;/strong&gt; - in the special case where n &amp;gt; c^2, in the simple design given above there would be more than O(c) collation headers, and so an ordinary node would not be able to process even just the top-level blocks. Hence, more than two levels of indirection between transactions and top-level block headers are required (ie. we need &quot;shards of shards&quot;). What is the simplest and best way to do this?&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;However, the effect of a transaction may depend on &lt;em&gt;events that earlier took place in other shards&lt;/em&gt;; a canonical example is transfer of money, where money can be moved from shard i to shard j by first creating a “debit” transaction that destroys coins in shard i, and then creating a “credit” transaction that creates coins in shard j, pointing to a receipt created by the debit transaction as proof that the credit is legitimate.&lt;/p&gt;
&lt;h3&gt;But doesn't the CAP theorem mean that fully secure distributed systems are impossible, and so sharding is futile?&lt;/h3&gt;
&lt;p&gt;The CAP theorem is a result that has to do with &lt;em&gt;distributed consensus&lt;/em&gt;; a simple statement is: &quot;in the cases that a network partition takes place, you have to choose either consistency or availability, you cannot have both&quot;. The intuitive argument is simple: if the network splits in half, and in one half I send a transaction &quot;send my 10 coins to A&quot; and in the other I send a transaction &quot;send my 10 coins to B&quot;, then either the system is unavailable, as one or both transactions will not be processed, or it becomes inconsistent, as one half of the network will see the first transaction completed and the other half will see the second transaction completed. Note that the CAP theorem has nothing to do with scalability; it applies to any situation where multiple nodes need to agree on a value, regardless of the amount of data that they are agreeing on. All existing decentralized systems have found some compromise between availability and consistency; sharding does not make anything fundamentally harder in this respect.&lt;/p&gt;
&lt;h3&gt;What are the security models that we are operating under?&lt;/h3&gt;
&lt;p&gt;There are several competing models under which the safety of blockchain designs is evaluated:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Honest majority&lt;/strong&gt; (or honest supermajority): we assume that there is some set of validators and up to 50% (or 33% or 25%) of those validators are controlled by an attacker, and the remaining validators honestly follow the protocol. Honest majority models can have &lt;strong&gt;non-adaptive&lt;/strong&gt; or &lt;strong&gt;adaptive&lt;/strong&gt; adversaries; an adversary is adaptive if they can quickly choose which portion of the validator set to &quot;corrupt&quot;, and non-adaptive if they can only make that choice far ahead of time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Uncoordinated majority&lt;/strong&gt;: we assume that all validators are rational in a game-theoretic sense (except the attacker, who is motivated to make the network fail in some way), but no more than some fraction (often between 25% and 50%) are capable of coordinating their actions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Coordinated choice&lt;/strong&gt;: we assume that most or all validators are controlled by the same actor, or are fully capable of coordinating on the economically optimal choice between themselves. We can talk about the &lt;strong&gt;cost to the coalition&lt;/strong&gt; (or profit to the coalition) of achieving some undesirable outcome.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bribing attacker model&lt;/strong&gt;: we take the uncoordinated majority model, but instead of making the attacker be one of the participants, the attacker sits outside the protocol, and has the ability to bribe any participants to change their behavior. Attackers are modeled as having a &lt;strong&gt;budget&lt;/strong&gt;, which is the maximum that they are willing to pay, and we can talk about their &lt;strong&gt;cost&lt;/strong&gt;, the amount that they &lt;em&gt;end up paying&lt;/em&gt; to disrupt the protocol equilibrium.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Bitcoin proof of work with &lt;a href=&quot;https://arxiv.org/abs/1311.0243&quot; rel=&quot;nofollow&quot;&gt;Eyal and Sirer’s selfish mining fix&lt;/a&gt; is robust up to 50% under the honest majority assumption, and up to ~23.21% under the uncoordinated majority assumption. &lt;a href=&quot;https://blog.ethereum.org/2014/03/28/schellingcoin-a-minimal-trust-universal-data-feed/&quot; rel=&quot;nofollow&quot;&gt;Schellingcoin&lt;/a&gt; is robust up to 50% under the honest majority and uncoordinated majority assumptions, has ε (ie. slightly more than zero) cost of attack in a coordinated choice model, and has a P + ε budget requirement and ε cost in a bribing attacker model due to &lt;a href=&quot;https://blog.ethereum.org/2015/01/28/p-epsilon-attack/&quot; rel=&quot;nofollow&quot;&gt;P + epsilon attacks&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Hybrid models also exist; for example, even in the coordinated choice and bribing attacker models, it is common to make an &lt;strong&gt;honest minority assumption&lt;/strong&gt; that some portion (perhaps 1-15%) of validators will act altruistically regardless of incentives. We can also talk about coalitions consisting of between 50-99% of validators either trying to disrupt the protocol or harm other validators; for example, in proof of work, a 51%-sized coalition can double its revenue by refusing to include blocks from all other miners.&lt;/p&gt;
&lt;p&gt;The honest majority model is arguably highly unrealistic and has already been empirically disproven - see Bitcoin's &lt;a href=&quot;https://www.reddit.com/r/Bitcoin/comments/3c305f/if_you_are_using_any_wallet_other_than_bitcoin/csrsrf9/&quot; rel=&quot;nofollow&quot;&gt;SPV mining fork&lt;/a&gt; for a practical example. It proves too much: for example, an honest majority model would imply that honest miners are willing to voluntarily burn their own money if doing so punishes attackers in some way. The uncoordinated majority assumption may be realistic; there is also an intermediate model where the majority of nodes is honest but has a budget, so they shut down if they start to lose too much money.&lt;/p&gt;
&lt;p&gt;The bribing attacker model has in some cases been criticized as being unrealistically adversarial, although its proponents argue that if a protocol is designed with the bribing attacker model in mind then it should be able to massively reduce the cost of consensus, as 51% attacks become an event that could be recovered from. We will evaluate sharding in the context of both uncoordinated majority and bribing attacker models. Bribing attacker models are similar to maximally-adaptive adversary models, except that the adversary has the additional power that it can solicit private information from all nodes; this distinction can be crucial, for example &lt;a href=&quot;https://people.csail.mit.edu/nickolai/papers/gilad-algorand.pdf&quot; rel=&quot;nofollow&quot;&gt;Algorand&lt;/a&gt; is secure under adaptive adversary models but not bribing attacker models because of how it relies on private information for random selection.&lt;/p&gt;
&lt;h3&gt;How can we solve the single-shard takeover attack in an uncoordinated majority model?&lt;/h3&gt;
&lt;p&gt;In short, random sampling. Each shard is assigned a certain number of collators (eg. 150), and the collators that approve blocks on each shard are taken from the sample for that shard. Samples can be reshuffled either semi-frequently (eg. once every 12 hours) or maximally frequently (ie. there is no real independent sampling process, collators are randomly selected for each shard from a global pool every block).&lt;/p&gt;
&lt;p&gt;Sampling can be explicit, as in protocols that choose specifically sized &quot;committees&quot; and ask them to vote on the validity and availability of specific collations, or it can be implicit, as in the case of &quot;longest chain&quot; protocols where nodes pseudorandomly assigned to build on specific collations and are expected to &quot;windback verify&quot; at least N ancestors of the collation they are building on.&lt;/p&gt;
&lt;p&gt;The result is that even though only a few nodes are verifying and creating blocks on each shard at any given time, the level of security is in fact not much lower, in an honest or uncoordinated majority model, than what it would be if every single node was verifying and creating blocks. The reason is simple statistics: if you assume a ~67% honest supermajority on the global set, and if the size of the sample is 150, then with 99.999% probability the honest majority condition will be satisfied on the sample. If you assume a 75% honest supermajority on the global set, then that probability increases to 99.999999998% (see &lt;a href=&quot;https://en.wikipedia.org/wiki/Binomial_distribution&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; for calculation details).&lt;/p&gt;
&lt;p&gt;Hence, at least in the honest / uncoordinated majority setting, we have:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Decentralization&lt;/strong&gt; (each node stores only O(c) data, as it’s a light client in O(c) shards and so stores O(1) * O(c) = O(c) data worth of block headers, as well as O(c) data corresponding to the recent history of one or several shards that it is assigned to at the present time)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt; (with O(c) shards, each shard having O(c) capacity, the maximum capacity is n = O(c^2))&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt; (attackers need to control at least ~33% of the entire O(n)-sized validator pool in order to stand a chance of taking over the network).&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;In the bribing attacker model (or in the &quot;very very adaptive adversary&quot; model), things are not so easy, but we will get to this later. Note that because of the imperfections of sampling, the security threshold does decrease from 50% to ~30-40%, but this is still a surprisingly low loss of security for what may be a 100-1000x gain in scalability with no loss of decentralization.&lt;/p&gt;
&lt;h3&gt;How do you actually do this sampling in proof of work, and in proof of stake?&lt;/h3&gt;
&lt;p&gt;In proof of stake, it is easy. There already is an “active validator set” that is kept track of in the state, and one can simply sample from this set directly. Either an in-protocol algorithm runs and chooses 150 validators for each shard, or each validator independently runs an algorithm that uses a common source of randomness to (provably) determine which shard they are at any given time. Note that it is very important that the sampling assignment is “compulsory”; validators do not have a choice of what shard they go into. If validators could choose, then attackers with small total stake could concentrate their stake onto one shard and attack it, thereby eliminating the system’s security.&lt;/p&gt;
&lt;p&gt;In proof of work, it is more difficult, as with “direct” proof of work schemes one cannot prevent miners from applying their work to a given shard. It may be possible to use &lt;a href=&quot;https://www.microsoft.com/en-us/research/publication/permacoin-repurposing-bitcoin-work-for-data-preservation/&quot; rel=&quot;nofollow&quot;&gt;proof-of-file-access forms&lt;/a&gt; of proof of work to lock individual miners to individual shards, but it is hard to ensure that miners cannot quickly download or generate data that can be used for other shards and thus circumvent such a mechanism. The best known approach is through a technique invented by Dominic Williams called “puzzle towers”, where miners first perform proof of work on a common chain, which then inducts them into a proof of stake-style validator pool, and the validator pool is then sampled just as in the proof-of-stake case.&lt;/p&gt;
&lt;p&gt;One possible intermediate route might look as follows. Miners can spend a large (O(c)-sized) amount of work to create a new “cryptographic identity”. The precise value of the proof of work solution then chooses which shard they have to make their next block on. They can then spend an O(1)-sized amount of work to create a block on that shard, and the value of that proof of work solution determines which shard they can work on next, and so on&lt;sup&gt;&lt;a href=&quot;https://github.com/ethereum/wiki/wiki/Sharding-FAQ#ftnt_ref8&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;. Note that all of these approaches make proof of work “stateful” in some way; the necessity of this is fundamental.&lt;/p&gt;
&lt;h3&gt;How is the randomness for random sampling generated?&lt;/h3&gt;
&lt;p&gt;First of all, it is important to note that even if random number generation is heavily exploitable, this is not a fatal flaw for the protocol; rather, it simply means that there is a medium to high centralization incentive. The reason is that because the randomness is picking fairly large samples, it is difficult to bias the randomness by more than a certain amount.&lt;/p&gt;
&lt;p&gt;The simplest way to show this is through the &lt;a href=&quot;https://en.wikipedia.org/wiki/Binomial_distribution&quot; rel=&quot;nofollow&quot;&gt;binomial distribution&lt;/a&gt;, as described above; if one wishes to avoid a sample of size N being more than 50% corrupted by an attacker, and an attacker has p% of the global stake pool, the chance of the attacker being able to get such a majority during one round is:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/vbuterin/diagrams/raw/master/scalability_faq/image00.gif&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Here’s a table for what this probability would look like in practice for various values of N and p:&lt;/p&gt;
&amp;lt;
&lt;table&gt;&lt;tr&gt;&lt;td/&gt;
&lt;td&gt;N = 50&lt;/td&gt;
&lt;td&gt;N = 100&lt;/td&gt;
&lt;td&gt;N = 150&lt;/td&gt;
&lt;td&gt;N = 250&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;p = 0.4&lt;/td&gt;
&lt;td&gt;0.0978&lt;/td&gt;
&lt;td&gt;0.0271&lt;/td&gt;
&lt;td&gt;0.0082&lt;/td&gt;
&lt;td&gt;0.0009&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;p = 0.33&lt;/td&gt;
&lt;td&gt;0.0108&lt;/td&gt;
&lt;td&gt;0.0004&lt;/td&gt;
&lt;td&gt;1.83 * 10-5&lt;/td&gt;
&lt;td&gt;3.98 * 10-8&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;p = 0.25&lt;/td&gt;
&lt;td&gt;0.0001&lt;/td&gt;
&lt;td&gt;6.63 * 10&lt;sup&gt;-8&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt;4.11 * 10&lt;sup&gt;-11&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt;1.81 * 10-17&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;p = 0.2&lt;/td&gt;
&lt;td&gt;2.09 * 10&lt;sup&gt;-6&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt;2.14 * 10&lt;sup&gt;-11&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt;2.50 * 10&lt;sup&gt;-16&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt;3.96 * 10&lt;sup&gt;-26&lt;/sup&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;Hence, for N &amp;gt;= 150, the chance that any given random seed will lead to a sample favoring the attacker is very small indeed&lt;sup&gt;&lt;a href=&quot;https://github.com/ethereum/wiki/wiki/Sharding-FAQ#ftnt_ref11&quot;&gt;11&lt;/a&gt;,&lt;a href=&quot;https://github.com/ethereum/wiki/wiki/Sharding-FAQ#ftnt_ref12&quot;&gt;12&lt;/a&gt;&lt;/sup&gt;. What this means from the perspective of security of randomness is that the attacker needs to have a very large amount of freedom in choosing the random values order to break the sampling process outright. Most vulnerabilities in proof-of-stake randomness do not allow the attacker to simply choose a seed; at worst, they give the attacker many chances to select the most favorable seed out of many pseudorandomly generated options. If one is very worried about this, one can simply set N to a greater value, and add a moderately hard key-derivation function to the process of computing the randomness, so that it takes more than 2&lt;sup&gt;100&lt;/sup&gt; computational steps to find a way to bias the randomness sufficiently.&lt;/p&gt;
&lt;p&gt;Now, let’s look at the risk of attacks being made that try to influence the randomness more marginally, for purposes of profit rather than outright takeover.  For example, suppose that there is an algorithm which pseudorandomly selects 1000 validators out of some very large set (each validator getting a reward of $1), an attacker has 10% of the stake so the attacker’s average “honest” revenue 100, and at a cost of $1 the attacker can manipulate the randomness to “re-roll the dice” (and the attacker can do this an unlimited number of times).&lt;/p&gt;
&lt;p&gt;Due to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Central_limit_theorem&quot; rel=&quot;nofollow&quot;&gt;central limit theorem&lt;/a&gt;, the standard deviation of the number of samples, and based &lt;a href=&quot;http://math.stackexchange.com/questions/89030/expectation-of-the-maximum-of-gaussian-random-variables&quot; rel=&quot;nofollow&quot;&gt;on other known results in math&lt;/a&gt; the expected maximum of N random samples is slightly under M + S * sqrt(2 * log(N)) where M is the mean and S is the standard deviation. Hence the reward for manipulating the randomness and effectively re-rolling the dice (ie. increasing N) drops off sharply, eg. with 0 re-trials your expected reward is $100, with one re-trial it's $105.5, with two it's $108.5, with three it's $110.3, with four it's $111.6, with five it's $112.6 and with six it's $113.5. Hence, after five retrials it stops being worth it. As a result, an economically motivated attacker with ten percent of stake will (socially wastefully) spend $5 to get an additional revenue of $13, for a net surplus of $8.&lt;/p&gt;
&lt;p&gt;However, this kind of logic assumes that one single round of re-rolling the dice is expensive. Many older proof of stake algorithms have a “stake grinding” vulnerability where re-rolling the dice simply means making a computation locally on one’s computer; algorithms with this vulnerability are certainly unacceptable in a sharding context. Newer algorithms (see the “validator selection” section in the &lt;a href=&quot;https://github.com/ethereum/wiki/wiki/Proof-of-Stake-FAQ&quot;&gt;proof of stake FAQ&lt;/a&gt;) have the property that re-rolling the dice can only be done by voluntarily giving up one’s spot in the block creation process, which entails giving up rewards and fees. The best way to mitigate the impact of marginal economically motivated attacks on sample selection is to find ways to increase this cost. One method to increase the cost by a factor of sqrt(N) from N rounds of voting is the &lt;a href=&quot;https://arxiv.org/pdf/1406.5694.pdf&quot; rel=&quot;nofollow&quot;&gt;majority-bit method devised by Iddo Bentov&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Another form of random number generation that is not exploitable by minority coalitions is the deterministic threshold signature approach most researched and advocated by Dominic Williams. The strategy here is to use a &lt;a href=&quot;https://eprint.iacr.org/2002/081.pdf&quot; rel=&quot;nofollow&quot;&gt;deterministic threshold signature&lt;/a&gt; to generate the random seed from which samples are selected. Deterministic threshold signatures have the property that the value is guaranteed to be the same regardless of which of a given set of participants provides their data to the algorithm, provided that at least ⅔ of participants do participate honestly. This approach is more obviously not economically exploitable and fully resistant to all forms of stake-grinding, but it has several weaknesses:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;It relies on more complex cryptography&lt;/strong&gt; (specifically, elliptic curves and pairings). Other approaches rely on nothing but the random-oracle assumption for common hash algorithms.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;It fails when many validators are offline&lt;/strong&gt;. A desired goal for public blockchains is to be able to survive very large portions of the network simultaneously disappearing, as long as a majority of the remaining nodes is honest; deterministic threshold signature schemes at this point cannot provide this property.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;It’s not secure in a bribing attacker or coordinated majority model&lt;/strong&gt; where more than 67% of validators are colluding. The other approaches described in the proof of stake FAQ above still make it expensive to manipulate the randomness, as data from all validators is mixed into the seed and making any manipulation requires either universal collusion or excluding other validators outright.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;One might argue that the deterministic threshold signature approach works better in consistency-favoring contexts and other approaches work better in availability-favoring contexts.&lt;/p&gt;
&lt;h3&gt;What are the tradeoffs in making sampling more or less frequent?&lt;/h3&gt;
&lt;p&gt;Selection frequency affects just how adaptive adversaries can be for the protocol to still be secure against them; for example, if you believe that an adaptive attack (eg. dishonest validators who discover that they are part of the same sample banding together and colluding) can happen in 6 hours but not less, then you would be okay with a sampling time of 4 hours but not 12 hours. This is an argument in favor of making sampling happen as quickly as possible.&lt;/p&gt;
&lt;p&gt;The main challenge with sampling taking place every block is that reshuffling carries a very high amount of overhead. Specifically, verifying a block on a shard requires knowing the state of that shard, and so every time validators are reshuffled, validators need to download the entire state for the new shard(s) that they are in. This requires both a strong state size control policy (ie. economically ensuring that the size of the state does not grow too large, whether by deleting old accounts, restricting the rate of creating new accounts or a combination of the two) and a fairly long reshuffling time to work well.&lt;/p&gt;
&lt;p&gt;Currently, the Parity client can download and verify a full Ethereum state snapshot via “warp-sync” in ~2-8 hours, suggesting that reshuffling periods of a few days but not less are safe; perhaps this could be reduced somewhat by shrinking the state size via &lt;a href=&quot;https://ethresear.ch/t/a-simple-and-principled-way-to-compute-rent-fees/1455&quot; rel=&quot;nofollow&quot;&gt;storage rent&lt;/a&gt; but even still reshuffling periods would need to be long, potentially making the system vulnerable to adaptive adversaries.&lt;/p&gt;
&lt;p&gt;However, there are ways of completely avoiding the tradeoff, choosing the creator of the next collation in each shard with only a few minutes of warning but without adding impossibly high state downloading overhead. This is done by shifting responsibility for state storage, and possibly even state execution, away from collators entirely, and instead assigning the role to either users or an interactive verification protocol.&lt;/p&gt;
&lt;h3&gt;Can we force more of the state to be held user-side so that transactions can be validated without requiring validators to hold all state data?&lt;/h3&gt;
&lt;p&gt;See also: &lt;a href=&quot;https://ethresear.ch/t/the-stateless-client-concept/172&quot; rel=&quot;nofollow&quot;&gt;https://ethresear.ch/t/the-stateless-client-concept/172&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The techniques here tend to involve requiring users to store state data and provide Merkle proofs along with every transaction that they send. A transaction would be sent along with a Merkle proof-of-correct-execution (or &quot;witness&quot;), and this proof would allow a node that only has the state root to calculate the new state root. This proof-of-correct-execution would consist of the subset of objects in the trie that would need to be traversed to access and verify the state information that the transaction must verify; because Merkle proofs are O(log(n)) sized, the proof for a transaction that accesses a constant number of objects would also be O(log(n)) sized.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://github.com/vbuterin/diagrams/raw/master/scalability_faq/image03.png&quot; width=&quot;450&quot;/&gt;&lt;br/&gt;&lt;em&gt;The subset of objects in a Merkle tree that would need to be provided in a Merkle proof of a transaction that accesses several state objects&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Implementing this scheme in its pure form has two flaws. First, it introduces O(log(n)) overhead (~10-30x in practice), although one could argue that this O(log(n)) overhead is not as bad as it seems because it ensures that the validator can always simply keep state data in memory and thus it never needs to deal with the overhead of accessing the hard drive&lt;sup&gt;&lt;a href=&quot;https://github.com/ethereum/wiki/wiki/Sharding-FAQ#ftnt_ref9&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;. Second, it can easily be applied if the addresses that are accessed by a transaction are static, but is more difficult to apply if the addresses in question are dynamic - that is, if the transaction execution has code of the form &lt;code&gt;read(f(read(x)))&lt;/code&gt; where the address of some state read depends on the execution result of some other state read. In this case, the address that the transaction sender thinks the transaction will be reading at the time that they send the transaction may well differ from the address that is actually read when the transaction is included in a block, and so the Merkle proof may be insufficient&lt;sup&gt;&lt;a href=&quot;https://github.com/ethereum/wiki/wiki/Sharding-FAQ#ftnt_ref10&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;This can be solved with access lists (think: a list of accounts and subsets of storage tries), which specify statically what data transactions can access, so when a miner receives a transaction with a witness they can determine that the witness contains all of the data the transaction could possibly access or modify. However, this harms censorship resistance, making attacks similar in form to the &lt;a href=&quot;http://hackingdistributed.com/2016/07/05/eth-is-more-resilient-to-censorship/&quot; rel=&quot;nofollow&quot;&gt;attempted DAO soft fork&lt;/a&gt; possible.&lt;/p&gt;
&lt;h3&gt;Can we split data and execution so that we get the security from rapid shuffling data validation without the overhead of shuffling the nodes that perform state execution?&lt;/h3&gt;
&lt;p&gt;Yes. We can create a protocol where we split up validators into two roles: &lt;strong&gt;collators&lt;/strong&gt; and &lt;strong&gt;executors&lt;/strong&gt;. Collators are responsible for simply building a chain of collations, and verifying that the data in the collations is available, but do not need to verify anything state-dependent (eg. whether or not someone trying to send ETH has enough money). Executors take the chain of collations agreed to by the collators as given, and then execute the transactions in the collations sequentially and compute the state. If any transaction included in a collation is invalid, executors simply skip over it. This way, validators that verify availability could be reshuffled instantly, and executors could stay on one shard.&lt;/p&gt;
&lt;p&gt;There would be a light client protocol that allows light clients to determine what the state is based on claims signed by executors, but this protocol is NOT a simple majority-voting consensus. Rather, the protocol is an interactive game with some similarities to Truebit, where if there is great disagreement then light client simply execute specific collations or portions of collations themselves. Hence, light clients can get a correct view of the state even if 90% of the executors in the shard are corrupted, making it much safer to allow executors to be very infrequently reshuffled or even permanently shard-specific.&lt;/p&gt;
&lt;p&gt;Choosing &lt;em&gt;what goes in&lt;/em&gt; to a collation does require knowing the state of that collation, as that is the most practical way to know what will actually pay transaction fees, but this can be solved by further separating the role of collators (who agree on the history) and proposers (who propose individual collations) and creating a market between the two classes of actors; see &lt;a href=&quot;https://ethresear.ch/t/separating-proposing-and-confirmation-of-collations/1000&quot; rel=&quot;nofollow&quot;&gt;here&lt;/a&gt; for more discussion on this.&lt;/p&gt;
&lt;h3&gt;Can SNARKs and STARKs help?&lt;/h3&gt;
&lt;p&gt;Yes! One can create a second-level protocol where a &lt;a href=&quot;https://medium.com/@VitalikButerin/zk-snarks-under-the-hood-b33151a013f6&quot; rel=&quot;nofollow&quot;&gt;SNARK&lt;/a&gt;, &lt;a href=&quot;https://vitalik.ca/general/2017/11/09/starks_part_1.html&quot; rel=&quot;nofollow&quot;&gt;STARK&lt;/a&gt; or similar succinct zero knowledge proof scheme is used to prove the state root of a shard chain, and proof creators can be rewarded for this. That said, shard chains to actually agree on what data gets included into the shard chains in the first place is still required.&lt;/p&gt;
&lt;h3&gt;How can we facilitate cross-shard communication?&lt;/h3&gt;
&lt;p&gt;The easiest scenario to satisfy is one where there are very many applications that individually do not have too many users, and which only very occasionally and loosely interact with each other; in this case, applications can live on separate shards and use cross-shard communication via receipts to talk to each other.&lt;/p&gt;
&lt;p&gt;This typically involves breaking up each transaction into a &quot;debit&quot; and a &quot;credit&quot;. For example, suppose that we have a transaction where account A on shard M wishes to send 100 coins to account B on shard N. The steps would looks as follows:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Send a transaction on shard M which (i) deducts the balance of A by 100 coins, and (ii) creates a receipt. A receipt is an object which is not saved in the state directly, but where the fact that the receipt was generated can be verified via a Merkle proof.&lt;/li&gt;
&lt;li&gt;Wait for the first transaction to be included (sometimes waiting for finalization is required; this depends on the system).&lt;/li&gt;
&lt;li&gt;Send a transaction on shard N which includes the Merkle proof of the receipt from (1). This transaction also checks in the state of shard N to make sure that this receipt is &quot;unspent&quot;; if it is, then it increases the balance of B by 100 coins, and saves in the state that the receipt is spent.&lt;/li&gt;
&lt;li&gt;Optionally, the transaction in (3) also saves a receipt, which can then be used to perform further actions on shard M that are contingent on the original operation succeeding.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://github.com/vbuterin/diagrams/raw/master/scalability_faq/image01.png&quot; width=&quot;400&quot;/&gt;&lt;/p&gt;
&lt;p&gt;In more complex forms of sharding, transactions may in some cases have effects that spread out across several shards and may also synchronously ask for data from the state of multiple shards.&lt;/p&gt;
&lt;h3&gt;What is the train-and-hotel problem?&lt;/h3&gt;
&lt;p&gt;The following example is courtesy of Andrew Miller. Suppose that a user wants to purchase a train ticket and reserve a hotel, and wants to make sure that the operation is atomic - either both reservations succeed or neither do. If the train ticket and hotel booking applications are on the same shard, this is easy: create a transaction that attempts to make both reservations, and throws an exception and reverts everything unless both reservations succeed. If the two are on different shards, however, this is not so easy; even without cryptoeconomic / decentralization concerns, this is essentially the problem of &lt;a href=&quot;https://en.wikipedia.org/wiki/Atomicity_(database_systems)&quot; rel=&quot;nofollow&quot;&gt;atomic database transactions&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;With asynchronous messages only, the simplest solution is to first reserve the train, then reserve the hotel, then once both reservations succeed confirm both; the reservation mechanism would prevent anyone else from reserving (or at least would ensure that enough spots are open to allow all reservations to be confirmed) for some period of time. However, this means that the mechanism relies on an extra security assumptions: that cross-shard messages from one shard can get included in another shard within some fixed period of time.&lt;/p&gt;
&lt;p&gt;With cross-shard synchronous transactions, the problem is easier, but the challenge of creating a sharding solution capable of making cross-shard atomic synchronous transactions is itself decidedly nontrivial; see Vlad Zamfir's &lt;a href=&quot;https://www.youtube.com/watch?v=GNGbd_RbrzE&quot; rel=&quot;nofollow&quot;&gt;presentation which talks about merge blocks&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Another solution involves making contracts themselves movable across shards; see the proposed &lt;a href=&quot;https://ethresear.ch/t/cross-shard-locking-scheme-1/1269&quot; rel=&quot;nofollow&quot;&gt;cross-shard locking scheme&lt;/a&gt; as well as &lt;a href=&quot;https://ethresear.ch/t/cross-shard-contract-yanking/1450&quot; rel=&quot;nofollow&quot;&gt;this proposal&lt;/a&gt; where contracts can be &quot;yanked&quot; from one shard to another, allowing two contracts that normally reside on different shards to be temporarily moved to the same shard at which point a synchronous operation between them can happen.&lt;/p&gt;
&lt;h3&gt;What are the concerns about sharding through random sampling in a bribing attacker or coordinated choice model?&lt;/h3&gt;
&lt;p&gt;In a bribing attacker or coordinated choice model, the fact that validators are randomly sampled doesn’t matter: whatever the sample is, either the attacker can bribe the great majority of the sample to do as the attacker pleases, or the attacker controls a majority of the sample directly and can direct the sample to perform arbitrary actions at low cost (O(c) cost, to be precise).&lt;/p&gt;
&lt;p&gt;At that point, the attacker has the ability to conduct 51% attacks against that sample. The threat is further magnified because there is a risk of cross-shard contagion: if the attacker corrupts the state of a shard, the attacker can then start to send unlimited quantities of funds out to other shards and perform other cross-shard mischief. All in all, security in the bribing attacker or coordinated choice model is not much better than that of simply creating O(c) altcoins.&lt;/p&gt;
&lt;h3&gt;How can we improve on this?&lt;/h3&gt;
&lt;p&gt;In the context of state execution, we can use interactive verification protocols that are not randomly sampled majority votes, and that can give correct answers even if 90% of the participants are faulty; see &lt;a href=&quot;https://people.cs.uchicago.edu/%7Eteutsch/papers/truebit.pdf&quot; rel=&quot;nofollow&quot;&gt;Truebit&lt;/a&gt; for an example of how this can be done. For data availability, the problem is harder, though there are several strategies that can be used alongside majority votes to solve it.&lt;/p&gt;
&lt;h3&gt;What is the data availability problem, and how can we use erasure codes to solve it?&lt;/h3&gt;
&lt;p&gt;See &lt;a href=&quot;https://github.com/ethereum/research/wiki/A-note-on-data-availability-and-erasure-coding&quot;&gt;https://github.com/ethereum/research/wiki/A-note-on-data-availability-and-erasure-coding&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Can we remove the need to solve data availability with some kind of fancy cryptographic accumulator scheme?&lt;/h3&gt;
&lt;p&gt;No. Suppose there is a scheme where there exists an object S representing the state (S could possibly be a hash) possibly as well as auxiliary information (&quot;witnesses&quot;) held by individual users that can prove the presence of existing state objects (eg. S is a Merkle root, the witnesses are the branches, though other constructions like RSA accumulators do exist). There exists an updating protocol where some data is broadcasted, and this data changes S to change the contents of the state, and also possibly changes witnesses.&lt;/p&gt;
&lt;p&gt;Suppose some user has the witnesses for a set of N objects in the state, and M of the objects are updated. After receiving the update information, the user can check the new status of all N objects, and thereby see which M were updated. Hence, the update information itself encoded at least ~M * log(N) bits of information. Hence, the update information that everyone needs for receive to implement the effect of M transactions must necessarily be of size O(M). &lt;a href=&quot;https://github.com/ethereum/wiki/wiki/Sharding-FAQ#ftnt_ref14&quot;&gt;14&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;So this means that we can actually create scalable sharded blockchains where the cost of making anything bad happen is proportional to the size of the entire validator set?&lt;/h3&gt;
&lt;p&gt;There is one trivial attack by which an attacker can always burn O(c) capital to temporarily reduce the quality of a shard: spam it by sending transactions with high transaction fees, forcing legitimate users to outbid you to get in. This attack is unavoidable; you could compensate with flexible gas limits, and you could even try “transparent sharding” schemes that try to automatically re-allocate nodes to shards based on usage, but if some particular application is non-parallelizable, Amdahl’s law guarantees that there is nothing you can do. The attack that is opened up here (reminder: it only works in the Zamfir model, not honest/uncoordinated majority) is arguably not substantially worse than the transaction spam attack. Hence, we've reached the known limit for the security of a single shard, and there is no value in trying to go further.&lt;/p&gt;
&lt;h3&gt;Let’s walk back a bit. Do we actually need any of this complexity if we have instant shuffling? Doesn’t instant shuffling basically mean that each shard directly pulls validators from the global validator pool so it operates just like a blockchain, and so sharding doesn’t actually introduce any new complexities?&lt;/h3&gt;
&lt;p&gt;Kind of. First of all, it’s worth noting that proof of work and simple proof of stake, even without sharding, both have very low security in a bribing attacker model; a block is only truly “finalized” in the economic sense after O(n) time (as if only a few blocks have passed, then the economic cost of replacing the chain is simply the cost of starting a double-spend from before the block in question). Casper solves this problem by adding its finality mechanism, so that the economic security margin immediately increases to the maximum. In a sharded chain, if we want economic finality then we need to come up with a chain of reasoning for why a validator would be willing to make a very strong claim on a chain based solely on a random sample, when the validator itself is convinced that the bribing attacker and coordinated choice models may be true and so the random sample could potentially be corrupted.&lt;/p&gt;
&lt;h3&gt;You mentioned transparent sharding. I’m 12 years old and what is this?&lt;/h3&gt;
&lt;p&gt;Basically, we do not expose the concept of “shards” directly to developers, and do not permanently assign state objects to specific shards. Instead, the protocol has an ongoing built-in load-balancing process that shifts objects around between shards. If a shard gets too big or consumes too much gas it can be split in half; if two shards get too small and talk to each other very often they can be combined together; if all shards get too small one shard can be deleted and its contents moved to various other shards, etc.&lt;/p&gt;
&lt;p&gt;Imagine if Donald Trump realized that people travel between New York and London a lot, but there’s an ocean in the way, so he could just take out his scissors, cut out the ocean, glue the US east coast and Western Europe together and put the Atlantic beside the South Pole - it’s kind of like that.&lt;/p&gt;
&lt;h3&gt;What are some advantages and disadvantages of this?&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Developers no longer need to think about shards&lt;/li&gt;
&lt;li&gt;There’s the possibility for shards to adjust manually to changes in gas prices, rather than relying on market mechanics to increase gas prices in some shards more than others&lt;/li&gt;
&lt;li&gt;There is no longer a notion of reliable co-placement: if two contracts are put into the same shard so that they can interact with each other, shard changes may well end up separating them&lt;/li&gt;
&lt;li&gt;More protocol complexity&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The co-placement problem can be mitigated by introducing a notion of “sequential domains”, where contracts may specify that they exist in the same sequential domain, in which case synchronous communication between them will always be possible. In this model a shard can be viewed as a set of sequential domains that are validated together, and where sequential domains can be rebalanced between shards if the protocol determines that it is efficient to do so.&lt;/p&gt;
&lt;h3&gt;How would synchronous cross-shard messages work?&lt;/h3&gt;
&lt;p&gt;The process becomes much easier if you view the transaction history as being already settled, and are simply trying to calculate the state transition function. There are several approaches; one fairly simple approach can be described as follows:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;A transaction may specify a set of shards that it can operate in&lt;/li&gt;
&lt;li&gt;In order for the transaction to be effective, it must be included at the same block height in all of these shards.&lt;/li&gt;
&lt;li&gt;Transactions within a block must be put in order of their hash (this ensures a canonical order of execution)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;A client on shard X, if it sees a transaction with shards (X, Y), requests a Merkle proof from shard Y verifying (i) the presence of that transaction on shard Y, and (ii) what the pre-state on shard Y is for those bits of data that the transaction will need to access. It then executes the transaction and commits to the execution result. Note that this process may be highly inefficient if there are many transactions with many different “block pairings” in each block; for this reason, it may be optimal to simply require blocks to specify sister shards, and then calculation can be done more efficiently at a per-block level. This is the basis for how such a scheme could work; one could imagine more complex designs. However, when making a new design, it’s always important to make sure that low-cost denial of service attacks cannot arbitrarily slow state calculation down.&lt;/p&gt;
&lt;h3&gt;What about semi-asynchronous messages?&lt;/h3&gt;
&lt;p&gt;Vlad Zamfir created a scheme by which asynchronous messages could still solve the “book a train and hotel” problem. This works as follows. The state keeps track of all operations that have been recently made, as well as the graph of which operations were triggered by any given operation (including cross-shard operations). If an operation is reverted, then a receipt is created which can then be used to revert any effect of that operation on other shards; those reverts may then trigger their own reverts and so forth. The argument is that if one biases the system so that revert messages can propagate twice as fast as other kinds of messages, then a complex cross-shard transaction that finishes executing in K rounds can be fully reverted in another K rounds.&lt;/p&gt;
&lt;p&gt;The overhead that this scheme would introduce has arguably not been sufficiently studied; there may be worst-case scenarios that trigger quadratic execution vulnerabilities. It is clear that if transactions have effects that are more isolated from each other, the overhead of this mechanism is lower; perhaps isolated executions can be incentivized via favorable gas cost rules. All in all, this is one of the more promising research directions for advanced sharding.&lt;/p&gt;
&lt;h3&gt;What are guaranteed cross-shard calls?&lt;/h3&gt;
&lt;p&gt;One of the challenges in sharding is that when a call is made, there is by default no hard protocol-provided guarantee that any asynchronous operations created by that call will be made within any particular timeframe, or even made at all; rather, it is up to some party to send a transaction in the destination shard triggering the receipt. This is okay for many applications, but in some cases it may be problematic for several reasons:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;There may be no single party that is clearly incentivized to trigger a given receipt. If the sending of a transaction benefits many parties, then there could be &lt;strong&gt;tragedy-of-the-commons effects&lt;/strong&gt; where the parties try to wait longer until someone else sends the transaction (ie. play &quot;chicken&quot;), or simply decide that sending the transaction is not worth the transaction fees for them individually.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gas prices across shards may be volatile&lt;/strong&gt;, and in some cases performing the first half of an operation compels the user to “follow through” on it, but the user may have to end up following through at a much higher gas price. This may be exacerbated by DoS attacks and related forms of &lt;strong&gt;griefing&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Some applications rely on there being an upper bound on the “latency” of cross-shard messages (eg. the train-and-hotel example). Lacking hard guarantees, such applications would have to have &lt;strong&gt;inefficiently large safety margins&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;One could try to come up with a system where asynchronous messages made in some shard automatically trigger effects in their destination shard after some number of blocks. However, this requires every client on each shard to actively inspect all other shards in the process of calculating the state transition function, which is arguably a source of inefficiency. The best known compromise approach is this: when a receipt from shard A at height &lt;code&gt;height_a&lt;/code&gt; is included in shard B at height &lt;code&gt;height_b&lt;/code&gt;, if the difference in block heights exceeds &lt;code&gt;MAX_HEIGHT&lt;/code&gt;, then all validators in shard B that created blocks from &lt;code&gt;height_a + MAX_HEIGHT + 1&lt;/code&gt; to &lt;code&gt;height_b - 1&lt;/code&gt; are penalized, and this penalty increases exponentially. A portion of these penalties is given to the validator that finally includes the block as a reward. This keeps the state transition function simple, while still strongly incentivizing the correct behavior.&lt;/p&gt;
&lt;h3&gt;Wait, but what if an attacker sends a cross-shard call from every shard into shard X at the same time? Wouldn’t it be mathematically impossible to include all of these calls in time?&lt;/h3&gt;
&lt;p&gt;Correct; this is a problem. Here is a proposed solution. In order to make a cross-shard call from shard A to shard B, the caller must pre-purchase “congealed shard B gas” (this is done via a transaction in shard B, and recorded in shard B). Congealed shard B gas has a fast demurrage rate: once ordered, it loses 1/k of its remaining potency every block. A transaction on shard A can then send the congealed shard B gas along with the receipt that it creates, and it can be used on shard B for free. Shard B blocks allocate extra gas space specifically for these kinds of transactions. Note that because of the demurrage rules, there can be at most GAS_LIMIT * k worth of congealed gas for a given shard available at any time, which can certainly be filled within k blocks (in fact, even faster due to demurrage, but we may need this slack space due to malicious validators). In case too many validators maliciously fail to include receipts, we can make the penalties fairer by exempting validators who fill up the “receipt space” of their blocks with as many receipts as possible, starting with the oldest ones.&lt;/p&gt;
&lt;p&gt;Under this pre-purchase mechanism, a user that wants to perform a cross-shard operation would first pre-purchase gas for all shards that the operation would go into, over-purchasing to take into account the demurrage. If the operation would create a receipt that triggers an operation that consumes 100000 gas in shard B, the user would pre-buy 100000 * e (ie. 271818) shard-B congealed gas. If that operation would in turn spend 100000 gas in shard C (ie. two levels of indirection), the user would need to pre-buy 100000 * e^2 (ie. 738906) shard-C congealed gas. Notice how once the purchases are confirmed, and the user starts the main operation, the user can be confident that they will be insulated from changes in the gas price market, unless validators voluntarily lose large quantities of money from receipt non-inclusion penalties.&lt;/p&gt;
&lt;h3&gt;Congealed gas? This sounds interesting for not just cross-shard operations, but also reliable intra-shard scheduling&lt;/h3&gt;
&lt;p&gt;Indeed; you could buy congealed shard A gas inside of shard A, and send a guaranteed cross-shard call from shard A to itself. Though note that this scheme would only support scheduling at very short time intervals, and the scheduling would not be exact to the block; it would only be guaranteed to happen within some period of time.&lt;/p&gt;
&lt;h3&gt;Does guaranteed scheduling, both intra-shard and cross-shard, help against majority collusions trying to censor transactions?&lt;/h3&gt;
&lt;p&gt;Yes. If a user fails to get a transaction in because colluding validators are filtering the transaction and not accepting any blocks that include it, then the user could send a series of messages which trigger a chain of guaranteed scheduled messages, the last of which reconstructs the transaction inside of the EVM and executes it. Preventing such circumvention techniques is practically impossible without shutting down the guaranteed scheduling feature outright and greatly restricting the entire protocol, and so malicious validators would not be able to do it easily.&lt;/p&gt;
&lt;h3&gt;Could sharded blockchains do a better job of dealing with network partitions?&lt;/h3&gt;
&lt;p&gt;The schemes described in this document would offer no improvement over non-sharded blockchains; realistically, every shard would end up with some nodes on both sides of the partition. There have been calls (eg. from &lt;a href=&quot;https://www.youtube.com/watch?v=cU-n_m-snxQ&quot; rel=&quot;nofollow&quot;&gt;IPFS’s Juan Benet&lt;/a&gt;) for building scalable networks with the specific goal that networks can split up into shards as needed and thus continue operating as much as possible under network partition conditions, but there are nontrivial cryptoeconomic challenges in making this work well.&lt;/p&gt;
&lt;p&gt;One major challenge is that if we want to have location-based sharding so that geographic network partitions minimally hinder intra-shard cohesion (with the side effect of having very low intra-shard latencies and hence very fast intra-shard block times), then we need to have a way for validators to choose which shards they are participating in. This is dangerous, because it allows for much larger classes of attacks in the honest/uncoordinated majority model, and hence cheaper attacks with higher griefing factors in the Zamfir model. Sharding for geographic partition safety and sharding via random sampling for efficiency are two fundamentally different things.&lt;/p&gt;
&lt;p&gt;Second, more thinking would need to go into how applications are organized. A likely model in a sharded blockchain as described above is for each “app” to be on some shard (at least for small-scale apps); however, if we want the apps themselves to be partition-resistant, then it means that all apps would need to be cross-shard to some extent.&lt;/p&gt;
&lt;p&gt;One possible route to solving this is to create a platform that offers both kinds of shards - some shards would be higher-security “global” shards that are randomly sampled, and other shards would be lower-security “local” shards that could have properties such as ultra-fast block times and cheaper transaction fees. Very low-security shards could even be used for data-publishing and messaging.&lt;/p&gt;
&lt;h3&gt;What are the unique challenges of pushing scaling past n = O(c^2)?&lt;/h3&gt;
&lt;p&gt;There are several considerations. First, the algorithm would need to be converted from a two-layer algorithm to a stackable n-layer algorithm; this is possible, but is complex. Second, n / c (ie. the ratio between the total computation load of the network and the capacity of one node) is a value that happens to be close to two constants: first, if measured in blocks, a timespan of several hours, which is an acceptable “maximum security confirmation time”, and second, the ratio between rewards and deposits (an early computation suggests a 32 ETH deposit size and a 0.05 ETH block reward for Casper). The latter has the consequence that if rewards and penalties on a shard are escalated to be on the scale of validator deposits, the cost of continuing an attack on a shard will be O(n) in size.&lt;/p&gt;
&lt;p&gt;Going above c^2 would likely entail further weakening the kinds of security guarantees that a system can provide, and allowing attackers to attack individual shards in certain ways for extended periods of time at medium cost, although it should still be possible to prevent invalid state from being finalized and to prevent finalized state from being reverted unless attackers are willing to pay an O(n) cost. However, the rewards are large - a super-quadratically sharded blockchain could be used as a general-purpose tool for nearly all decentralized applications, and could sustain transaction fees that makes its use virtually free.&lt;/p&gt;
&lt;h3&gt;Footnotes&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;
&lt;p&gt; Merklix tree == Merkle Patricia tree&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt; Later proposals from the NUS group do manage to shard state; they do this via the receipt and state-compacting techniques that I describe in later sections in this document. (This is Vitalik Buterin writing as the creator of this Wiki.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt; There are reasons to be conservative here. Particularly, note that if an attacker comes up with worst-case transactions whose ratio between processing time and block space expenditure (bytes, gas, etc) is much higher than usual, then the system will experience very low performance, and so a safety factor is necessary to account for this possibility. In traditional blockchains, the fact that block processing only takes ~1-5% of block time has the primary role of protecting against centralization risk but serves double duty of protecting against denial of service risk. In the specific case of Bitcoin, its current worst-case &lt;a href=&quot;https://bitcoin.org/en/bitcoin-core/capacity-increases-faq#size-bump&quot; rel=&quot;nofollow&quot;&gt;known quadratic execution vulnerability&lt;/a&gt; arguably limits any scaling at present to ~5-10x, and in the case of Ethereum, while all known vulnerabilities are being or have been removed after the denial-of-service attacks, there is still a risk of further discrepancies particularly on a smaller scale. In Bitcoin NG, the need for the former is removed, but the need for the latter is still there.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt; A further reason to be cautious is that increased state size corresponds to reduced throughput, as nodes will find it harder and harder to keep state data in RAM and so need more and more disk accesses, and databases, which often have an O(log(n)) access time, will take longer and longer to access. This was an important lesson from the last Ethereum denial-of-service attack, which bloated the state by ~10 GB by creating empty accounts and thereby indirectly slowed processing down by forcing further state accesses to hit disk instead of RAM.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt; In sharded blockchains, there may not necessarily be in-lockstep consensus on a single global state, and so the protocol never asks nodes to try to compute a global state root; in fact, in the protocols presented in later sections, each shard has its own state, and for each shard there is a mechanism for committing to the state root for that shard, which represents that shard’s state&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt; #MEGA&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt; If a non-scalable blockchain upgrades into a scalable blockchain, the author’s recommended path is that the old chain’s state should simply become a single shard in the new chain.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt; For this to be secure, some further conditions must be satisfied; particularly, the proof of work must be non-outsourceable in order to prevent the attacker from determining which &lt;em&gt;other miners' identities&lt;/em&gt; are available for some given shard and mining on top of those.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt; Recent Ethereum denial-of-service attacks have proven that hard drive access is a primary bottleneck to blockchain scalability.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt; You could ask: well why don’t validators fetch Merkle proofs just-in-time? Answer: because doing so is a ~100-1000ms roundtrip, and executing an entire complex transaction within that time could be prohibitive.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;  One hybrid solution that combines the normal-case efficiency of small samples with the greater robustness of larger samples is a multi-layered sampling scheme: have a consensus between 50 nodes that requires 80% agreement to move forward, and then only if that consensus fails to be reached then fall back to a 250-node sample. N = 50 with an 80% threshold has only a 8.92 * 10-9 failure rate even against attackers with p = 0.4, so this does not harm security at all under an honest or uncoordinated majority model.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt; The probabilities given are for one single shard; however, the random seed affects O(c) shards and the attacker could potentially take over any one of them. If we want to look at O(c) shards simultaneously, then there are two cases. First, if the grinding process is computationally bounded, then this fact does not change the calculus at all, as even though there are now O(c) chances of success per round, checking success takes O(c) times as much work. Second, if the grinding process is economically bounded, then this indeed calls for somewhat higher safety factors (increasing N by 10-20 should be sufficient) although it’s important to note that the goal of an attacker in a profit-motivated manipulation attack is to increase their participation across all shards in any case, and so that is the case that we are already investigating.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt; See &lt;a href=&quot;https://github.com/polkadot-io/polkadotpaper/raw/master/PolkaDotPaper.pdf&quot;&gt;Parity’s Polkadotpaper&lt;/a&gt; for further description of how their “fishermen” concept works. For up-to-date info and code for Polkadot, see &lt;a href=&quot;https://github.com/paritytech/polkadot&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt; Thanks to Justin Drake for pointing me to cryptographic accumulators, as well as &lt;a href=&quot;https://eprint.iacr.org/2009/612.pdf&quot; rel=&quot;nofollow&quot;&gt;this paper&lt;/a&gt; that gives the argument for the impossibility of sublinear batching. See also this thread: &lt;a href=&quot;https://ethresear.ch/t/accumulators-scalability-of-utxo-blockchains-and-data-availability/176&quot; rel=&quot;nofollow&quot;&gt;https://ethresear.ch/t/accumulators-scalability-of-utxo-blockchains-and-data-availability/176&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Further reading related to sharding, and more generally scalability and research, is available &lt;a href=&quot;https://github.com/ethereum/wiki/wiki/R&amp;amp;D&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;

</description>
<pubDate>Wed, 25 Apr 2018 18:42:45 +0000</pubDate>
<dc:creator>dmmalam</dc:creator>
<og:image>https://avatars3.githubusercontent.com/u/6250754?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>ethereum/wiki</og:title>
<og:url>https://github.com/ethereum/wiki</og:url>
<og:description>wiki - The Ethereum Wiki -</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/ethereum/wiki/wiki/Sharding-FAQ</dc:identifier>
</item>
<item>
<title>Ask HN: Anyone making money through algorithmic trading?</title>
<link>https://news.ycombinator.com/item?id=16922538</link>
<guid isPermaLink="true" >https://news.ycombinator.com/item?id=16922538</guid>
<description>&lt;tr readability=&quot;0.55737704918033&quot;&gt;&lt;td bgcolor=&quot;#FF6600&quot;&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;5.8386605783866&quot;&gt;&lt;td&gt;
&lt;table class=&quot;fatitem&quot; border=&quot;0&quot; readability=&quot;4.5875190258752&quot;&gt;&lt;tr class=&quot;athing&quot; id=&quot;16922538&quot; readability=&quot;0&quot;&gt;&lt;td align=&quot;right&quot; valign=&quot;top&quot; class=&quot;title&quot;/&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;title&quot;&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=16922538&quot; class=&quot;storylink&quot;&gt;Ask HN: Anyone making money through algorithmic trading?&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;0.72289156626506&quot;&gt;&lt;td colspan=&quot;2&quot;/&gt;
&lt;td class=&quot;subtext&quot;&gt;&lt;span class=&quot;score&quot; id=&quot;score_16922538&quot;&gt;314 points&lt;/span&gt; by &lt;a href=&quot;https://news.ycombinator.com/user?id=charlesdm&quot; class=&quot;hnuser&quot;&gt;charlesdm&lt;/a&gt; &lt;span class=&quot;age&quot;&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=16922538&quot;&gt;16 hours ago&lt;/a&gt;&lt;/span&gt; &lt;span id=&quot;unv_16922538&quot;/&gt; | &lt;a href=&quot;https://news.ycombinator.com/hide?id=16922538&amp;amp;goto=item%3Fid%3D16922538&quot;&gt;hide&lt;/a&gt; | &lt;a href=&quot;https://hn.algolia.com/?query=Ask%20HN%3A%20Anyone%20making%20money%20through%20algorithmic%20trading%3F&amp;amp;sort=byDate&amp;amp;dateRange=all&amp;amp;type=story&amp;amp;storyText=false&amp;amp;prefix&amp;amp;page=0&quot; class=&quot;hnpast&quot;&gt;past&lt;/a&gt; | &lt;a href=&quot;https://www.google.com/search?q=Ask%20HN%3A%20Anyone%20making%20money%20through%20algorithmic%20trading%3F&quot;&gt;web&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/fave?id=16922538&amp;amp;auth=200f8ee22da3083fb716a80fe769ae7a501d21da&quot;&gt;favorite&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/item?id=16922538&quot;&gt;217 comments&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;10.5&quot;&gt;&lt;td colspan=&quot;2&quot;/&gt;
&lt;td readability=&quot;10&quot;&gt;Is there anyone here making money on smaller trading strategies (i.e. in the stock market or cryptocurrencies) that would not be interesting enough for larger algorithmic trading firms?
&lt;p&gt;I'm aware the standard advice is that you will lose your shirt attempting to compete with algorithmic and HFT firms. But are there opportunities out there for smaller strategies to generate alpha? (I'm assuming yes, but would be great to find people who actually do this -- no need to disclose _how_ you actually do it, obviously)&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td/&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot;/&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;1&quot;&gt;&lt;td&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;10&quot; width=&quot;0&quot;/&gt;&lt;br/&gt;&lt;center&gt;&lt;span class=&quot;yclinks&quot;&gt;&lt;a href=&quot;https://news.ycombinator.com/newsguidelines.html&quot;&gt;Guidelines&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/newsfaq.html&quot;&gt;FAQ&lt;/a&gt; | &lt;a href=&quot;mailto:hn@ycombinator.com&quot;&gt;Support&lt;/a&gt; | &lt;a href=&quot;https://github.com/HackerNews/API&quot;&gt;API&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/security.html&quot;&gt;Security&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/lists&quot;&gt;Lists&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/bookmarklet.html&quot; rel=&quot;nofollow&quot;&gt;Bookmarklet&lt;/a&gt; | &lt;a href=&quot;http://www.ycombinator.com/legal/&quot;&gt;Legal&lt;/a&gt; | &lt;a href=&quot;http://www.ycombinator.com/apply/&quot;&gt;Apply to YC&lt;/a&gt; | &lt;a href=&quot;mailto:hn@ycombinator.com&quot;&gt;Contact&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;
&lt;/td&gt;
&lt;/tr&gt;</description>
<pubDate>Wed, 25 Apr 2018 15:38:41 +0000</pubDate>
<dc:creator>charlesdm</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://news.ycombinator.com/item?id=16922538</dc:identifier>
</item>
<item>
<title>Medicare will require hospitals to post prices online</title>
<link>https://www.msn.com/en-us/news/us/medicare-will-require-hospitals-to-post-prices-online/ar-AAwiccI</link>
<guid isPermaLink="true" >https://www.msn.com/en-us/news/us/medicare-will-require-hospitals-to-post-prices-online/ar-AAwiccI</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;span class=&quot;storyimage fullwidth inlineimage&quot; data-aop=&quot;image&quot;&gt;&lt;span class=&quot;image&quot; data-attrib=&quot;Steve Mason/Photodisc/Getty Images&quot; data-caption=&quot;A senior taking medication.&quot;&gt;&lt;img alt=&quot;A senior taking medication.&quot; height=&quot;220&quot; src=&quot;https://img.s-msn.com/tenant/amp/entityid/AA4Txu0.img?h=220&amp;amp;w=300&amp;amp;m=6&amp;amp;q=60&amp;amp;o=f&amp;amp;l=f&amp;amp;x=1304&amp;amp;y=668&quot; width=&quot;300&quot; /&gt;&lt;/span&gt; &lt;span class=&quot;caption truncate&quot;&gt;&lt;span class=&quot;attribution&quot;&gt;© Steve Mason/Photodisc/Getty Images&lt;/span&gt; A senior taking medication.&lt;/span&gt;&lt;/span&gt; WASHINGTON — Medicare will require hospitals to post their standard prices online and make electronic medical records more readily available to patients, officials said Tuesday.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The program is also starting a comprehensive review of how it will pay for costly new forms of immunotherapy to battle cancer.&lt;/p&gt;
&lt;p&gt;Seema Verma, head of the Centers for Medicare and Medicaid Services, said the new requirement for online prices reflects the Trump administration's ongoing efforts to encourage patients to become better-educated decision makers in their own care.&lt;/p&gt;
&lt;p&gt;&quot;We are just beginning on price transparency,&quot; said Verma. &quot;We know that hospitals have this information and we're asking them to post what they have online.&quot;&lt;/p&gt;
&lt;p&gt;Hospitals are required to disclose prices publicly, but the latest change would put that information online in machine-readable format that can be easily processed by computers. It may still prove to be confusing to consumers, since standard rates are like list prices and don't reflect what insurers and government programs pay.&lt;/p&gt;
&lt;p&gt;Patients concerned about their potential out-of-pocket costs from a hospitalization would still be advised to consult with their insurer. Most insurance plans nowadays have an annual limit on how much patients must pay in copays and deductibles — although traditional Medicare does not.&lt;/p&gt;
&lt;p&gt;Likewise, many health care providers already make computerized records available to patients, but starting in 2021 Medicare would base part of a hospital's payments on how good a job they do.&lt;/p&gt;
&lt;p&gt;Using electronic medical records remains a cumbersome task, and the Trump administration has invited technology companies to design secure apps that would let patients access their records from all their providers instead of having to go to different portals.&lt;/p&gt;
&lt;p&gt;Verma also announced Medicare is starting a comprehensive review of how it will pay for a costly new form of immunotherapy called CAR-T. It's gene therapy that turbocharges a patient's own immune system cells to attack cancer.&lt;/p&gt;
&lt;p&gt;Immune system T cells are filtered from the patient's own blood and reprogrammed to target and kill cancer cells that had managed to evade them. Hundreds of millions of copies of the revved-up cells are then returned to the patient's blood to take on the cancer.&lt;/p&gt;
&lt;p&gt;Though only a couple of such treatments have been approved for blood cancers, the cost can exceed $370,000 per patient.&lt;/p&gt;
&lt;p&gt;&quot;It's a new area for the agency,&quot; said Verma. &quot;We haven't seen drugs priced at this level and we're having to think about our strategy.&quot;&lt;/p&gt;
</description>
<pubDate>Wed, 25 Apr 2018 15:27:44 +0000</pubDate>
<dc:creator>DoreenMichele</dc:creator>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.msn.com/en-us/news/us/medicare-will-require-hospitals-to-post-prices-online/ar-AAwiccI</dc:identifier>
</item>
<item>
<title>Maker&amp;#039;s Schedule, Manager&amp;#039;s Schedule (2009)</title>
<link>http://paulgraham.com/makersschedule.html</link>
<guid isPermaLink="true" >http://paulgraham.com/makersschedule.html</guid>
<description>&lt;img src=&quot;http://ep.yimg.com/ca/I/paulgraham_2202_7710978&quot; width=&quot;318&quot; height=&quot;18&quot; border=&quot;0&quot; hspace=&quot;0&quot; vspace=&quot;0&quot; alt=&quot;Maker's Schedule, Manager's Schedule &quot; /&gt;&lt;p&gt;&lt;span&gt;July 2009&lt;/span&gt;&lt;/p&gt;&lt;p&gt;One reason programmers dislike meetings so much is that they're on a different type of schedule from other people. Meetings cost them more.&lt;/p&gt;&lt;p&gt;There are two types of schedule, which I'll call the manager's schedule and the maker's schedule. The manager's schedule is for bosses. It's embodied in the traditional appointment book, with each day cut into one hour intervals. You can block off several hours for a single task if you need to, but by default you change what you're doing every hour.&lt;/p&gt;&lt;p&gt;When you use time that way, it's merely a practical problem to meet with someone. Find an open slot in your schedule, book them, and you're done.&lt;/p&gt;&lt;p&gt;Most powerful people are on the manager's schedule. It's the schedule of command. But there's another way of using time that's common among people who make things, like programmers and writers. They generally prefer to use time in units of half a day at least. You can't write or program well in units of an hour. That's barely enough time to get started.&lt;/p&gt;&lt;p&gt;When you're operating on the maker's schedule, meetings are a disaster. A single meeting can blow a whole afternoon, by breaking it into two pieces each too small to do anything hard in. Plus you have to remember to go to the meeting. That's no problem for someone on the manager's schedule. There's always something coming on the next hour; the only question is what. But when someone on the maker's schedule has a meeting, they have to think about it.&lt;/p&gt;&lt;p&gt;For someone on the maker's schedule, having a meeting is like throwing an exception. It doesn't merely cause you to switch from one task to another; it changes the mode in which you work.&lt;/p&gt;&lt;p&gt;I find one meeting can sometimes affect a whole day. A meeting commonly blows at least half a day, by breaking up a morning or afternoon. But in addition there's sometimes a cascading effect. If I know the afternoon is going to be broken up, I'm slightly less likely to start something ambitious in the morning. I know this may sound oversensitive, but if you're a maker, think of your own case. Don't your spirits rise at the thought of having an entire day free to work, with no appointments at all? Well, that means your spirits are correspondingly depressed when you don't. And ambitious projects are by definition close to the limits of your capacity. A small decrease in morale is enough to kill them off.&lt;/p&gt;&lt;p&gt;Each type of schedule works fine by itself. Problems arise when they meet. Since most powerful people operate on the manager's schedule, they're in a position to make everyone resonate at their frequency if they want to. But the smarter ones restrain themselves, if they know that some of the people working for them need long chunks of time to work in.&lt;/p&gt;&lt;p&gt;Our case is an unusual one. Nearly all investors, including all VCs I know, operate on the manager's schedule. But &lt;a href=&quot;http://ycombinator.com&quot;&gt;Y Combinator&lt;/a&gt; runs on the maker's schedule. Rtm and Trevor and I do because we always have, and Jessica does too, mostly, because she's gotten into sync with us.&lt;/p&gt;&lt;p&gt;I wouldn't be surprised if there start to be more companies like us. I suspect founders may increasingly be able to resist, or at least postpone, turning into managers, just as a few decades ago they started to be able to resist switching from jeans to suits.&lt;/p&gt;&lt;p&gt;How do we manage to advise so many startups on the maker's schedule? By using the classic device for simulating the manager's schedule within the maker's: office hours. Several times a week I set aside a chunk of time to meet founders we've funded. These chunks of time are at the end of my working day, and I wrote a signup program that ensures all the appointments within a given set of office hours are clustered at the end. Because they come at the end of my day these meetings are never an interruption. (Unless their working day ends at the same time as mine, the meeting presumably interrupts theirs, but since they made the appointment it must be worth it to them.) During busy periods, office hours sometimes get long enough that they compress the day, but they never interrupt it.&lt;/p&gt;&lt;p&gt;When we were working on our own startup, back in the 90s, I evolved another trick for partitioning the day. I used to program from dinner till about 3 am every day, because at night no one could interrupt me. Then I'd sleep till about 11 am, and come in and work until dinner on what I called &quot;business stuff.&quot; I never thought of it in these terms, but in effect I had two workdays each day, one on the manager's schedule and one on the maker's.&lt;/p&gt;&lt;p&gt;When you're operating on the manager's schedule you can do something you'd never want to do on the maker's: you can have speculative meetings. You can meet someone just to get to know one another. If you have an empty slot in your schedule, why not? Maybe it will turn out you can help one another in some way.&lt;/p&gt;&lt;p&gt;Business people in Silicon Valley (and the whole world, for that matter) have speculative meetings all the time. They're effectively free if you're on the manager's schedule. They're so common that there's distinctive language for proposing them: saying that you want to &quot;grab coffee,&quot; for example.&lt;/p&gt;&lt;p&gt;Speculative meetings are terribly costly if you're on the maker's schedule, though. Which puts us in something of a bind. Everyone assumes that, like other investors, we run on the manager's schedule. So they introduce us to someone they think we ought to meet, or send us an email proposing we grab coffee. At this point we have two options, neither of them good: we can meet with them, and lose half a day's work; or we can try to avoid meeting them, and probably offend them.&lt;/p&gt;&lt;p&gt;Till recently we weren't clear in our own minds about the source of the problem. We just took it for granted that we had to either blow our schedules or offend people. But now that I've realized what's going on, perhaps there's a third option: to write something explaining the two types of schedule. Maybe eventually, if the conflict between the manager's schedule and the maker's schedule starts to be more widely understood, it will become less of a problem.&lt;/p&gt;&lt;p&gt;Those of us on the maker's schedule are willing to compromise. We know we have to have some number of meetings. All we ask from those on the manager's schedule is that they understand the cost.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Thanks&lt;/strong&gt; to Sam Altman, Trevor Blackwell, Paul Buchheit, Jessica Livingston, and Robert Morris for reading drafts of this.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Related:&lt;/strong&gt;&lt;/p&gt;</description>
<pubDate>Wed, 25 Apr 2018 15:05:48 +0000</pubDate>
<dc:creator>ibobev</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>http://paulgraham.com/makersschedule.html</dc:identifier>
</item>
<item>
<title>Notes on structured concurrency, or: Go statement considered harmful</title>
<link>https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/</link>
<guid isPermaLink="true" >https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/</guid>
<description>&lt;p&gt;Every concurrency API needs a way to run code concurrently. Here's some examples of what that looks like using different APIs:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
go myfunc();                                // Golang

pthread_create(&amp;amp;thread_id, NULL, &amp;amp;myfunc);  /* C with POSIX threads */

spawn(modulename, myfuncname, [])           % Erlang

threading.Thread(target=myfunc).start()     # Python with threads

asyncio.create_task(myfunc())               # Python with asyncio
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There are lots of variations in the notation and terminology, but the semantics are the same: these all arrange for &lt;tt class=&quot;docutils literal&quot;&gt;myfunc&lt;/tt&gt; to start running concurrently to the rest of the program, and then return immediately so that the parent can do other things.&lt;/p&gt;
&lt;p&gt;Another option is to use callbacks:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
QObject::connect(&amp;amp;emitter, SIGNAL(event()),        // C++ with Qt
                 &amp;amp;receiver, SLOT(myfunc()))

g_signal_connect(emitter, &quot;event&quot;, myfunc, NULL)   /* C with GObject */

document.getElementById(&quot;myid&quot;).onclick = myfunc;  // Javascript

promise.then(myfunc, errorhandler)                 // Javascript with Promises

deferred.addCallback(myfunc)                       # Python with Twisted

future.add_done_callback(myfunc)                   # Python with asyncio
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Again, the notation varies, but these all accomplish the same thing: they arrange that from now on, if and when a certain event occurs, then &lt;tt class=&quot;docutils literal&quot;&gt;myfunc&lt;/tt&gt; will run. Then once they've set that up, they immediately return so the caller can do other things. (Sometimes callbacks get dressed up with fancy helpers like &lt;a class=&quot;reference external&quot; href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/all&quot;&gt;promise&lt;/a&gt; &lt;a class=&quot;reference external&quot; href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/race&quot;&gt;combinators&lt;/a&gt;, or &lt;a class=&quot;reference external&quot; href=&quot;https://twistedmatrix.com/documents/current/core/howto/servers.html&quot;&gt;Twisted-style protocols/transports&lt;/a&gt;, but the core idea is the same.)&lt;/p&gt;
&lt;p&gt;And... that's it. Take any real-world, general-purpose concurrency API, and you'll probably find that it falls into one or the other of those buckets (or sometimes both, like asyncio).&lt;/p&gt;
&lt;p&gt;But my new library &lt;a class=&quot;reference external&quot; href=&quot;https://trio.readthedocs.io&quot;&gt;Trio&lt;/a&gt; is weird. It doesn't use either approach. Instead, if we want to run &lt;tt class=&quot;docutils literal&quot;&gt;myfunc&lt;/tt&gt; and &lt;tt class=&quot;docutils literal&quot;&gt;anotherfunc&lt;/tt&gt; concurrently, we write something like:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;open_nursery&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nursery&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nursery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_soon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;myfunc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nursery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_soon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;anotherfunc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When people first encounter this &quot;nursery&quot; construct, they tend to find it confusing. Why is there an indented block? What's this &lt;tt class=&quot;docutils literal&quot;&gt;nursery&lt;/tt&gt; object, and why do I need one before I can spawn a task? Then they realize that it prevents them from using patterns they've gotten used to in other frameworks, and they get really annoyed. It feels quirky and idiosyncratic and too high-level to be a basic primitive. These are understandable reactions! But bear with me.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;In this post, I want to convince you that nurseries aren't quirky or idiosyncratic at all, but rather a new control flow primitive that's just as fundamental as for loops or function calls. And furthermore, the other approaches we saw above – thread spawning and callback registration – should be removed entirely and replaced with nurseries.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Sound unlikely? Something similar has actually happened before: the &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; statement was once the king of control flow. Now it's a &lt;a class=&quot;reference external&quot; href=&quot;https://xkcd.com/292/&quot;&gt;punchline&lt;/a&gt;. A few languages still have something they call &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;, but it's different and far weaker than the original &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;. And most languages don't even have that. What happened? This was so long ago that most people aren't familiar with the story anymore, but it turns out to be surprisingly relevant. So we'll start by reminding ourselves what a &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; was, exactly, and then see what it can teach us about concurrency APIs.&lt;/p&gt;

&lt;div class=&quot;section&quot; id=&quot;what-is-a-goto-statement-anyway&quot;&gt;

&lt;p&gt;Let's review some history: Early computers were programmed using &lt;a class=&quot;reference external&quot; href=&quot;https://en.wikipedia.org/wiki/Assembly_language&quot;&gt;assembly language&lt;/a&gt;, or other even more primitive mechanisms. This kinda sucked. So in the 1950s, people like &lt;a class=&quot;reference external&quot; href=&quot;https://en.wikipedia.org/wiki/John_Backus&quot;&gt;John Backus&lt;/a&gt; at IBM and &lt;a class=&quot;reference external&quot; href=&quot;https://en.wikipedia.org/wiki/Grace_Hopper&quot;&gt;Grace Hopper&lt;/a&gt; at Remington Rand started to develop languages like &lt;a class=&quot;reference external&quot; href=&quot;https://en.wikipedia.org/wiki/Fortran&quot;&gt;FORTRAN&lt;/a&gt; and &lt;a class=&quot;reference external&quot; href=&quot;https://en.wikipedia.org/wiki/FLOW-MATIC&quot;&gt;FLOW-MATIC&lt;/a&gt; (better known for its direct successor &lt;a class=&quot;reference external&quot; href=&quot;https://en.wikipedia.org/wiki/COBOL&quot;&gt;COBOL&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;FLOW-MATIC was very ambitious for its time. You can think of it as Python's great-great-great-...-grandparent: the first language that was designed for humans first, and computers second. Here's some FLOW-MATIC code to give you a taste of what it looked like:&lt;/p&gt;

&lt;p&gt;You'll notice that unlike modern languages, there's no &lt;tt class=&quot;docutils literal&quot;&gt;if&lt;/tt&gt; blocks, loop blocks, or function calls here – in fact there's no block delimiters or indentation at all. It's just a flat list of statements. That's not because this program happens to be too short to use fancier control syntax – it's because block syntax wasn't invented yet!&lt;/p&gt;

&lt;p&gt;Instead, FLOW-MATIC had two options for flow control. Normally, it was sequential, just like you'd expect: start at the top and move downwards, one statement at a time. But if you execute a special statement like &lt;tt class=&quot;docutils literal&quot;&gt;JUMP TO&lt;/tt&gt;, then it could directly transfer control somewhere else. For example, statement (13) jumps back to statement (2):&lt;/p&gt;

&lt;p&gt;Just like for our concurrency primitives at the beginning, there was some disagreement about what to call this &quot;do a one-way jump&quot; operation. Here it's &lt;tt class=&quot;docutils literal&quot;&gt;JUMP TO&lt;/tt&gt;, but the name that stuck was &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; (like &quot;go to&quot;, get it?), so that's what I'll use here.&lt;/p&gt;
&lt;p&gt;Here's the complete set of &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; jumps in this little program:&lt;/p&gt;

&lt;p&gt;If you think this looks confusing, you're not alone! This style of jump-based programming is something that FLOW-MATIC inherited pretty much directly from assembly language. It's powerful, and a good fit to how computer hardware actually works, but it's super confusing to work with directly. That tangle of arrows is why the term &quot;spaghetti code&quot; was invented. Clearly, we needed something better.&lt;/p&gt;
&lt;p&gt;But... what is it about &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; that causes all these problems? Why are some control structures OK, and some not? How do we pick the good ones? At the time, this was really unclear, and it's hard to fix a problem if you don't understand it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;what-is-a-go-statement-anyway&quot;&gt;

&lt;p&gt;But let's hit pause on the history for a moment – everyone knows &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; was bad. What does this have to do with concurrency? Well, consider Golang's famous &lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt; statement, used to spawn a new &quot;goroutine&quot; (lightweight thread):&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;c1&quot;&gt;// Golang&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;go&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;myfunc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Can we draw a diagram of its control flow? Well, it's a little different from either of the ones we saw above, because control actually splits. We might draw it like:&lt;/p&gt;

&lt;p&gt;Here the colors are intended to indicate that &lt;em&gt;both&lt;/em&gt; paths are taken. From the perspective of the parent goroutine (green line), control flows sequentially: it comes in the top, and then immediately comes out the bottom. Meanwhile, from the perspective of the child (lavender line), control comes in the top, and then jumps over to the body of &lt;tt class=&quot;docutils literal&quot;&gt;myfunc&lt;/tt&gt;. Unlike a regular function call, this jump is one-way: when running &lt;tt class=&quot;docutils literal&quot;&gt;myfunc&lt;/tt&gt; we switch to a whole new stack, and the runtime immediately forgets where we came from.&lt;/p&gt;
&lt;p&gt;But this doesn't just apply to Golang. This is the flow control diagram for &lt;em&gt;all&lt;/em&gt; of the primitives we listed at the beginning of this post:&lt;/p&gt;
&lt;ul class=&quot;simple&quot;&gt;&lt;li&gt;Threading libraries usually provide some sort of handle object that lets you &lt;tt class=&quot;docutils literal&quot;&gt;join&lt;/tt&gt; the thread later – but this is an independent operation that the language doesn't know anything about. The actual thread spawning primitive has the control flow shown above.&lt;/li&gt;
&lt;li&gt;Registering a callback is semantically equivalent to starting a background thread that (a) blocks until some event occurs, and then (b) runs the callback. (Though obviously the implementation is different.) So in terms of high-level control flow, registering a callback is essentially a &lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt; statement.&lt;/li&gt;
&lt;li&gt;Futures and promises are the same too: when you call a function and it returns a promise, that means it's scheduled the work to happen in the background, and then given you a handle object to join the work later (if you want). In terms of control flow semantics, this is just like spawning a thread. Then you register callbacks on the promise, so see the previous bullet point.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;This same exact pattern shows up in many, many forms: the key similarity is that in all these cases, control flow splits, with one side doing a one-way jump and the other side returning to the caller. Once you know what to look for, you'll start seeing it all over the place – it's a fun game! &lt;a class=&quot;footnote-reference&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id5&quot; id=&quot;id1&quot;&gt;[1]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Annoyingly, though, there is no standard name for this category of control flow constructs. So just like &quot;&lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; statement&quot; became the umbrella term for all the different &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;-like constructs, I'm going to use &quot;&lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt; statement&quot; as a umbrella term for these. Why &lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt;? One reason is that Golang gives us a particularly pure example of the form. And the other is... well, you've probably guessed where I'm going with all this. Look at these two diagrams. Notice any similarities?&lt;/p&gt;

&lt;p&gt;That's right: &lt;strong&gt;go statements are a form of goto statement.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Concurrent programs are notoriously difficult to write and reason about. So are &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;-based programs. Is it possible that this might be for some of the same reasons? In modern languages, the problems caused by &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; are largely solved. If we study how they fixed &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;, will it teach us how to make more usable concurrency APIs? Let's find out.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;what-happened-to-goto&quot;&gt;

&lt;p&gt;So what is it about &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; that makes it cause so many problems? In the late 1960s, &lt;a class=&quot;reference external&quot; href=&quot;https://en.wikipedia.org/wiki/Edsger_W._Dijkstra&quot;&gt;Edsger W. Dijkstra&lt;/a&gt; wrote a pair of now-famous papers that helped make this much clearer: &lt;a class=&quot;reference external&quot; href=&quot;https://scholar.google.com/scholar?cluster=15335993203437612903&amp;amp;hl=en&amp;amp;as_sdt=0,5&quot;&gt;Go to statement considered harmful&lt;/a&gt;, and &lt;a class=&quot;reference external&quot; href=&quot;https://www.cs.utexas.edu/~EWD/ewd02xx/EWD249.PDF&quot;&gt;Notes on structured programming&lt;/a&gt; (PDF).&lt;/p&gt;
&lt;div class=&quot;section&quot; id=&quot;goto-the-destroyer-of-abstraction&quot;&gt;
&lt;h3&gt;&lt;a class=&quot;toc-backref&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id12&quot;&gt;&lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;: the destroyer of abstraction&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In these papers, Dijkstra was worried about the problem of how you write non-trivial software and get it correct. I can't give them due justice here; there's all kinds of fascinating insights. For example, you may have heard this quote:&lt;/p&gt;
&lt;img alt=&quot;Testing can be used to show the presence of bugs, but never to show their absence!&quot; src=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/testing.png&quot;/&gt;&lt;p&gt;Yep, that's from &lt;em&gt;Notes on structured programming&lt;/em&gt;. But his major concern was &lt;em&gt;abstraction&lt;/em&gt;. He wanted to write programs that are too big to hold in your head all at once. To do this, you need to treat parts of the program like a black box – like when you see a Python program do:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Hello world!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;then you don't need to know all the details of how &lt;tt class=&quot;docutils literal&quot;&gt;print&lt;/tt&gt; is implemented (string formatting, buffering, cross-platform differences, ...). You just need to know that it will somehow print the text you give it, and then you can spend your energy thinking about whether that's what you want to have happen at this point in your code. Dijkstra wanted languages to support this kind of abstraction.&lt;/p&gt;
&lt;p&gt;By this point, block syntax had been invented, and languages like ALGOL had accumulated ~5 distinct types of control structure: they still had sequential flow and &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;:&lt;/p&gt;

&lt;p&gt;And had also acquired variants on if/else, loops, and function calls:&lt;/p&gt;

&lt;p&gt;You can implement these higher-level constructs using &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;, and early on, that's how people thought of them: as a convenient shorthand. But what Dijkstra pointed out is that if you look at these diagrams, there's a big difference between &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; and the rest. For everything except &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;, flow control comes in the top → [stuff happens] → flow control comes out the bottom. We might call this the &quot;black box rule&quot;: if a control structure has this shape, then in contexts where you don't care about the details of what happens internally, you can ignore the [stuff happens] part, and treat the whole thing as regular sequential flow. And even better, this is also true of any code that's &lt;em&gt;composed&lt;/em&gt; out of those pieces. When I look at this code:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;nb&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Hello world!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I don't have to go read the definition of &lt;tt class=&quot;docutils literal&quot;&gt;print&lt;/tt&gt; and all its transitive dependencies just to figure out how the control flow works. Maybe inside &lt;tt class=&quot;docutils literal&quot;&gt;print&lt;/tt&gt; there's a loop, and inside the loop there's an if/else, and inside the if/else there's another function call... or maybe it's something else. It doesn't really matter: I know control will flow into &lt;tt class=&quot;docutils literal&quot;&gt;print&lt;/tt&gt;, the function will do its thing, and then eventually control will come back to the code I'm reading.&lt;/p&gt;
&lt;p&gt;It may seem like this is obvious, but if you have a language with &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; – a language where functions and everything else are built on top of &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;, and &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; can jump anywhere, at any time – then these control structures aren't black boxes at all! If you have a function, and inside the function there's a loop, and inside the loop there's an if/else, and inside the if/else there's a &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;... then that &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; could send the control anywhere it wants. Maybe control will suddenly return from another function entirely, one you haven't even called yet. You don't know!&lt;/p&gt;
&lt;p&gt;And this breaks abstraction: it means that &lt;em&gt;every function call is potentially a&lt;/em&gt; &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; &lt;em&gt;statement in disguise, and the only way to know is to keep the entire source code of your system in your head at once.&lt;/em&gt; As soon as &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; is in your language, you stop being able do local reasoning about flow control. That's &lt;em&gt;why&lt;/em&gt; &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; leads to spaghetti code.&lt;/p&gt;
&lt;p&gt;And now that Dijkstra understood the problem, he was able to solve it. Here's his revolutionary proposal: we should stop thinking of if/loops/function calls as shorthands for &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;, but rather as fundamental primitives in their own rights – and we should remove &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; entirely from our languages.&lt;/p&gt;
&lt;p&gt;From here in 2018, this seems obvious enough. But have you seen how programmers react when you try to take away their toys because they're not smart enough to use them safely? Yeah, some things never change. In 1969, this proposal was &lt;em&gt;incredibly controversial&lt;/em&gt;. &lt;a class=&quot;reference external&quot; href=&quot;https://en.wikipedia.org/wiki/Donald_Knuth&quot;&gt;Donald Knuth&lt;/a&gt; &lt;a class=&quot;reference external&quot; href=&quot;https://scholar.google.com/scholar?cluster=17147143327681396418&amp;amp;hl=en&amp;amp;as_sdt=0,5&quot;&gt;defended&lt;/a&gt; &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;. People who had become experts on writing code with &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; quite reasonably resented having to basically learn how to program again in order to express their ideas using the newer, more constraining constructs. And of course it required building a whole new set of languages.&lt;/p&gt;
&lt;div class=&quot;figure align-right&quot;&gt;&lt;img alt=&quot;On the left, a photo of a snarling wolf. On the right, a photo of a grumpy bulldog.&quot; src=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/wolf-and-bulldog.jpg&quot;/&gt;&lt;p class=&quot;caption&quot;&gt;Left: A traditional &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;. Right: A domesticated &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;, as seen in C, C#, Golang, etc. The inability to cross function boundaries means it can still pee on your shoes, but it probably won't rip your face off.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In the end, modern languages are a bit less strict about this than Dijkstra's original formulation. They'll let you break out of multiple nested structures at once using constructs like &lt;tt class=&quot;docutils literal&quot;&gt;break&lt;/tt&gt;, &lt;tt class=&quot;docutils literal&quot;&gt;continue&lt;/tt&gt;, or &lt;tt class=&quot;docutils literal&quot;&gt;return&lt;/tt&gt;. But fundamentally, they're all designed around Dijkstra's idea; even these constructs that push the boundaries do so only in strictly limited ways. In particular, functions – which are the fundamental tool for wrapping up control flow inside a black box – are considered inviolate. You can't &lt;tt class=&quot;docutils literal&quot;&gt;break&lt;/tt&gt; out of one function and into another, and a &lt;tt class=&quot;docutils literal&quot;&gt;return&lt;/tt&gt; can take you out of the current function, but no further. Whatever control flow shenanigans a function gets up to internally, other functions don't have to care.&lt;/p&gt;
&lt;p&gt;This even extends to &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; itself. You'll find a few languages that still have something they call &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;, like C, C#, Golang, ... but they've added heavy restrictions. At the very least, they won't let you jump out of one function body and into another. Unless you're working in assembly &lt;a class=&quot;footnote-reference&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id6&quot; id=&quot;id2&quot;&gt;[2]&lt;/a&gt;, the classic, unrestricted &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; is gone. Dijkstra won.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;a-surprise-benefit-removing-goto-statements-enables-new-features&quot;&gt;
&lt;h3&gt;&lt;a class=&quot;toc-backref&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id13&quot;&gt;A surprise benefit: removing &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; statements enables new features&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;And once &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; disappeared, something interesting happened: language designers were able to start adding features that depend on control flow being structured.&lt;/p&gt;
&lt;p&gt;For example, Python has some nice syntax for resource cleanup: the &lt;tt class=&quot;docutils literal&quot;&gt;with&lt;/tt&gt; statement. You can write things like:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;c1&quot;&gt;# Python&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;my-file&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;file_handle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and it guarantees that the file will be open during the &lt;tt class=&quot;docutils literal&quot;&gt;...&lt;/tt&gt; code, but then closed immediately afterward. Most modern languages have some equivalent (RAII, &lt;tt class=&quot;docutils literal&quot;&gt;using&lt;/tt&gt;, try-with-resource, &lt;tt class=&quot;docutils literal&quot;&gt;defer&lt;/tt&gt;, ...). And they all assume that control flows in an orderly, structured way. If we used &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; to jump into the middle of our &lt;tt class=&quot;docutils literal&quot;&gt;with&lt;/tt&gt; block... what would that even do? Is the file open or not? What if we jumped out again, instead of exiting normally? Would the file get closed? This feature just doesn't work in any coherent way if your language has &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; in it.&lt;/p&gt;
&lt;p&gt;Error handling has a similar problem: when something goes wrong, what should your code do? Often the answer is to pass the buck up the stack to your code's caller, let them figure out how to deal with it. Modern languages have constructs specifically to make this easier, like exceptions, or other forms of &lt;a class=&quot;reference external&quot; href=&quot;https://doc.rust-lang.org/std/result/index.html#the-question-mark-operator-&quot;&gt;automatic error propagation&lt;/a&gt;. But your language can only provide this help if it &lt;em&gt;has&lt;/em&gt; a stack, and a reliable concept of &quot;caller&quot;. Look again at the control-flow spaghetti in our FLOW-MATIC program and imagine that in the middle of that it tried to raise an exception. Where would it even go?&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;goto-statements-not-even-once&quot;&gt;
&lt;h3&gt;&lt;a class=&quot;toc-backref&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id14&quot;&gt;&lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; statements: not even once&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;So &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; – the traditional kind that ignores function boundaries – isn't just the regular kind of bad feature, the kind that's hard to use correctly. If it were, it might have survived – lots of bad features have. But it's much worse.&lt;/p&gt;
&lt;blockquote/&gt;
&lt;p&gt;Even if you don't use &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; yourself, merely having it as an option in your language makes &lt;em&gt;everything&lt;/em&gt; harder to use. Whenever you start using a third-party library, you can't treat it as a black box – you have to go read through it all to find out which functions are regular functions, and which ones are idiosyncratic flow control constructs in disguise. This is a serious obstacle to local reasoning. And you lose powerful language features like reliable resource cleanup and automatic error propagation. Better to remove &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; entirely, in favor of control flow constructs that follow the &quot;black box&quot; rule.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;go-statement-considered-harmful&quot;&gt;

&lt;p&gt;So that's the history of &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;. Now, how much of this applies to &lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt; statements? Well... basically, all of it! The analogy turns out to be shockingly exact.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Go statements break abstraction.&lt;/strong&gt; Remember how we said that if our language allows &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;, then any function might be a &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; in disguise? In most concurrency frameworks, &lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt; statements cause the exact same problem: whenever you call a function, it might or might not spawn some background task. The function seemed to return, but is it still running in the background? There's no way to know without reading all its source code, transitively. When will it finish? Hard to say. If you have &lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt; statements, then functions are no longer black boxes with respect to control flow. In my &lt;a class=&quot;reference external&quot; href=&quot;https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/&quot;&gt;first post on concurrency APIs&lt;/a&gt;, I called this &quot;violating causality&quot;, and found that it was the root cause of many common, real-world issues in programs using asyncio and Twisted, like problems with backpressure, problems with shutting down properly, and so forth.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Go statements break automatic resource cleanup.&lt;/strong&gt; Let's look again at that &lt;tt class=&quot;docutils literal&quot;&gt;with&lt;/tt&gt; statement example:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;c1&quot;&gt;# Python&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;my-file&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;file_handle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Before, we said that we were &quot;guaranteed&quot; that the file will be open while the &lt;tt class=&quot;docutils literal&quot;&gt;...&lt;/tt&gt; code is running, and then closed afterwards. But what if the &lt;tt class=&quot;docutils literal&quot;&gt;...&lt;/tt&gt; code spawns a background task? Then our guarantee is lost: the operations that &lt;em&gt;look&lt;/em&gt; like they're inside the &lt;tt class=&quot;docutils literal&quot;&gt;with&lt;/tt&gt; block might actually keep running &lt;em&gt;after&lt;/em&gt; the &lt;tt class=&quot;docutils literal&quot;&gt;with&lt;/tt&gt; block ends, and then crash because the file gets closed while they're still using it. And again, you can't tell from local inspection; to know if this is happening you have to go read the source code to all the functions called inside the &lt;tt class=&quot;docutils literal&quot;&gt;...&lt;/tt&gt; code.&lt;/p&gt;
&lt;p&gt;If we want this code to work properly, we need to somehow keep track of any background tasks, and manually arrange for the file to be closed only when they're finished. It's doable – unless we're using some library that doesn't provide any way to get notified when the task is finished, which is distressingly common (e.g. because it doesn't expose any task handle that you can join on). But even in the best case, the unstructured control flow means the language can't help us. We're back to implementing resource cleanup by hand, like in the bad old days.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Go statements break error handling.&lt;/strong&gt; Like we discussed above, modern languages provide powerful tools like exceptions to help us make sure that errors are detected and propagated to the right place. But these tools depend on having a reliable concept of &quot;the current code's caller&quot;. As soon as you spawn a task or register a callback, that concept is broken. As a result, every mainstream concurrency framework I know of simply gives up. If an error occurs in a background task, and you don't handle it manually, then the runtime just... drops it on the floor and crosses its fingers that it wasn't too important. If you're lucky it might print something on the console. (The only other software I've used that thinks &quot;print something and keep going&quot; is a good error handling strategy is grotty old Fortran libraries, but here we are.) Even Rust – the language voted Most Obsessed With Threading Correctness by its high school class – is guilty of this. If a background thread panics, Rust &lt;a class=&quot;reference external&quot; href=&quot;https://doc.rust-lang.org/std/thread/&quot;&gt;discards the error and hopes for the best&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Of course you &lt;em&gt;can&lt;/em&gt; handle errors properly in these systems, by carefully making sure to join every thread, or by building your own error propagation mechanism like &lt;a class=&quot;reference external&quot; href=&quot;https://twistedmatrix.com/documents/current/core/howto/defer.html#visual-explanation&quot;&gt;errbacks in Twisted&lt;/a&gt; or &lt;a class=&quot;reference external&quot; href=&quot;https://hackernoon.com/promises-and-error-handling-4a11af37cb0e&quot;&gt;Promise.catch in Javascript&lt;/a&gt;. But now you're writing an ad-hoc, fragile reimplementation of the features your language already has. You've lost useful stuff like &quot;tracebacks&quot; and &quot;debuggers&quot;. All it takes is forgetting to call &lt;tt class=&quot;docutils literal&quot;&gt;Promise.catch&lt;/tt&gt; once and suddenly you're dropping serious errors on the floor without even realizing. And even if you do somehow solve all these problems, you'll still end up with two redundant systems for doing the same thing.&lt;/p&gt;
&lt;div class=&quot;section&quot; id=&quot;go-statements-not-even-once&quot;&gt;
&lt;h3&gt;&lt;a class=&quot;toc-backref&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id16&quot;&gt;&lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt; statements: not even once&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Just like &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; was the obvious primitive for the first practical high-level languages, &lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt; was the obvious primitive for the first practical concurrency frameworks: it matches how the underlying schedulers actually work, and it's powerful enough to implement any other concurrent flow pattern. But again like &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;, it breaks control flow abstractions, so that merely having it as an option in your language makes everything harder to use.&lt;/p&gt;
&lt;p&gt;The good news, though, is that these problems can all be solved: Dijkstra showed us how! We need to:&lt;/p&gt;
&lt;ul class=&quot;simple&quot;&gt;&lt;li&gt;Find a replacement for &lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt; statements that has similar power, but follows the &quot;black box rule&quot;,&lt;/li&gt;
&lt;li&gt;Build that new construct into our concurrency framework as a primitive, and don't include any form of &lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt; statement.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;And that's what Trio did.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;nurseries-a-structured-replacement-for-go-statements&quot;&gt;

&lt;p&gt;Here's the core idea: every time our control splits into multiple concurrent paths, we want to make sure that they join up again. So for example, if we want to do three things at the same time, our control flow should look something like this:&lt;/p&gt;

&lt;p&gt;Notice that this has just one arrow going in the top and one coming out the bottom, so it follows Dijkstra's black box rule. Now, how can we turn this sketch into a concrete language construct? There are some existing constructs that meet this constraint, but (a) my proposal is slightly different than all the ones I'm aware of and has advantages over them (especially in the context of wanting to make this a standalone primitive), and (b) the concurrency literature is vast and complicated, and trying to pick apart all the history and tradeoffs would totally derail the argument, so I'm going to defer that to a separate post. Here, I'll just focus on explaining my solution. But please be aware that I'm not claiming to have like, invented the idea of concurrency or something, this draws inspiration from many sources, I'm standing on the shoulders of giants, etc. &lt;a class=&quot;footnote-reference&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id7&quot; id=&quot;id3&quot;&gt;[3]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Anyway, here's how we're going to do it: first, we declare that a parent task cannot start any child tasks unless it first creates a place for the children to live: a &lt;em&gt;nursery&lt;/em&gt;. It does this by opening a &lt;em&gt;nursery block&lt;/em&gt;; in Trio, we do this using Python's &lt;tt class=&quot;docutils literal&quot;&gt;async with&lt;/tt&gt; syntax:&lt;/p&gt;

&lt;p&gt;Opening a nursery block automatically creates an object representing this nursery, and the &lt;tt class=&quot;docutils literal&quot;&gt;as nursery&lt;/tt&gt; syntax assigns this object to the variable named &lt;tt class=&quot;docutils literal&quot;&gt;nursery&lt;/tt&gt;. Then we can use the nursery object's &lt;tt class=&quot;docutils literal&quot;&gt;start_soon&lt;/tt&gt; method to start concurrent tasks: in this case, one task calling the function &lt;tt class=&quot;docutils literal&quot;&gt;myfunc&lt;/tt&gt;, and another calling the function &lt;tt class=&quot;docutils literal&quot;&gt;anotherfunc&lt;/tt&gt;. Conceptually, these tasks execute &lt;em&gt;inside&lt;/em&gt; the nursery block. In fact, it's often convenient to think of the code written inside the nursery block as being an initial task that's automatically started when the block is created.&lt;/p&gt;

&lt;p&gt;Crucially, the nursery block doesn't exit until all the tasks inside it have exited – if the parent task reaches the end of the block before all the children are finished, then it pauses there and waits for them. The nursery automatically expands to hold the children.&lt;/p&gt;
&lt;p&gt;Here's the control flow: you can see how it matches the basic pattern we showed at the beginning of this section:&lt;/p&gt;

&lt;p&gt;This design has a number of consequences, not all of which are obvious. Let's think through some of them.&lt;/p&gt;
&lt;div class=&quot;section&quot; id=&quot;nurseries-preserve-the-function-abstraction&quot;&gt;
&lt;h3&gt;&lt;a class=&quot;toc-backref&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id18&quot;&gt;Nurseries preserve the function abstraction.&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The fundamental problem with &lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt; statements is that when you call a function, you don't know whether it's going to spawn some background task that keeps running after it's finished. With nurseries, you don't have to worry about this: any function can open a nursery and run multiple concurrent tasks, but the function can't return until they've all finished. So when a function does return, you know it's really done.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;nurseries-support-dynamic-task-spawning&quot;&gt;
&lt;h3&gt;&lt;a class=&quot;toc-backref&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id19&quot;&gt;Nurseries support dynamic task spawning.&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Here's a simpler primitive that would also satisfy our flow control diagram above. It takes a list of thunks, and runs them all concurrently:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;n&quot;&gt;run_concurrently&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;myfunc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anotherfunc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;But the problem with this is that you have to know up front the complete list of tasks you're going to run, which isn't always true. For example, server programs generally have &lt;tt class=&quot;docutils literal&quot;&gt;accept&lt;/tt&gt; loops, that take incoming connections and start a new task to handle each of them. Here's a minimal &lt;tt class=&quot;docutils literal&quot;&gt;accept&lt;/tt&gt; loop in Trio:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;open_nursery&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nursery&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;incoming_connection&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;await&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;server_socket&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accept&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nursery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_soon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connection_handler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;incoming_connection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With nurseries, this is trivial, but implementing it using &lt;tt class=&quot;docutils literal&quot;&gt;run_concurrently&lt;/tt&gt; would be &lt;em&gt;much&lt;/em&gt; more awkward. And if you wanted to, it would be easy to implement &lt;tt class=&quot;docutils literal&quot;&gt;run_concurrently&lt;/tt&gt; on top of nurseries – but it's not really necessary, since in the simple cases &lt;tt class=&quot;docutils literal&quot;&gt;run_concurrently&lt;/tt&gt; can handle, the nursery notation is just as readable.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;there-is-an-escape&quot;&gt;
&lt;h3&gt;&lt;a class=&quot;toc-backref&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id20&quot;&gt;There is an escape.&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The nursery object also gives us an escape hatch. What if you really do need to write a function that spawns a background task, where the background task outlives the function itself? Easy: pass the function a nursery object. There's no rule that only the code directly inside the &lt;tt class=&quot;docutils literal&quot;&gt;async with open_nursery()&lt;/tt&gt; block can call &lt;tt class=&quot;docutils literal&quot;&gt;nursery.start_soon&lt;/tt&gt; – so long as the nursery block remains open &lt;a class=&quot;footnote-reference&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id8&quot; id=&quot;id4&quot;&gt;[4]&lt;/a&gt;, then anyone who acquires a reference to the nursery object gets the capability of spawning tasks into that nursery. You can pass it in as a function argument, send it through a queue, whatever.&lt;/p&gt;
&lt;p&gt;In practice, this means that you can write functions that &quot;break the rules&quot;, but within limits:&lt;/p&gt;
&lt;ul class=&quot;simple&quot;&gt;&lt;li&gt;Since nursery objects have to be passed around explicitly, you can immediately identify which functions violate normal flow control by looking at their call sites, so local reasoning is still possible.&lt;/li&gt;
&lt;li&gt;Any tasks the function spawns are still bound by the lifetime of the nursery that was passed in.&lt;/li&gt;
&lt;li&gt;And the calling code can only pass in nursery objects that it itself has access to.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;So this is still very different from the traditional model where any code can at any moment spawn a background task with unbounded lifetime.&lt;/p&gt;
&lt;p&gt;One place this is useful is in the proof that nurseries have equivalent expressive power to &lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt; statements, but this post is already long enough so I'll leave that for another day.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;you-can-define-new-types-that-quack-like-a-nursery&quot;&gt;
&lt;h3&gt;&lt;a class=&quot;toc-backref&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id21&quot;&gt;You can define new types that quack like a nursery.&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The standard nursery semantics provide a solid foundation, but sometimes you want something different. Perhaps you're envious of Erlang and its supervisors, and want to define a nursery-like class that handles exceptions by restarting the child task. That's totally possible, and to your users, it'll look just like a regular nursery:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;k&quot;&gt;async&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_supervisor_library&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;open_supervisor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nursery_alike&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nursery_alike&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_soon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you have a function that takes a nursery as an argument, then you can pass it one of these instead to control the error-handling policy for the tasks it spawns. Pretty nifty. But there is one subtlety here that pushes Trio towards different conventions than asyncio or some other libraries: it means that &lt;tt class=&quot;docutils literal&quot;&gt;start_soon&lt;/tt&gt; has to take a function, not a coroutine object or a &lt;tt class=&quot;docutils literal&quot;&gt;Future&lt;/tt&gt;. (You can call a function multiple times, but there's no way to restart a coroutine object or a &lt;tt class=&quot;docutils literal&quot;&gt;Future&lt;/tt&gt;.) I think this is the better convention anyway for a number of reasons (especially since Trio doesn't even have &lt;tt class=&quot;docutils literal&quot;&gt;Future&lt;/tt&gt;s!), but still, worth mentioning.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;no-really-nurseries-always-wait-for-the-tasks-inside-to-exit&quot;&gt;
&lt;h3&gt;&lt;a class=&quot;toc-backref&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id22&quot;&gt;No, really, nurseries &lt;em&gt;always&lt;/em&gt; wait for the tasks inside to exit.&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;It's also worth talking about how task cancellation and task joining interact, since there are some subtleties here that could – if handled incorrectly – break the nursery invariants.&lt;/p&gt;
&lt;p&gt;In Trio, it's possible for code to receive a cancellation request at any time. After a cancellation is requested, then the next time the code executes a &quot;checkpoint&quot; operation (&lt;a class=&quot;reference external&quot; href=&quot;https://trio.readthedocs.io/en/latest/reference-core.html#checkpoints&quot;&gt;details&lt;/a&gt;), a &lt;tt class=&quot;docutils literal&quot;&gt;Cancelled&lt;/tt&gt; exception is raised. This means that there's a gap between when a cancellation is &lt;em&gt;requested&lt;/em&gt; and when it actually &lt;em&gt;happens&lt;/em&gt; – it might be a while before the task executes a checkpoint, and then after that the exception has to unwind the stack, run cleanup handlers, etc. When this happens, the nursery always waits for the full cleanup to happen. We &lt;em&gt;never&lt;/em&gt; terminate a task without giving it a chance to run cleanup handlers, and we &lt;em&gt;never&lt;/em&gt; leave a task to run unsupervised outside of the nursery, even if it's in the process of being cancelled.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;automatic-resource-cleanup-works&quot;&gt;
&lt;h3&gt;&lt;a class=&quot;toc-backref&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id23&quot;&gt;Automatic resource cleanup works.&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Because nurseries follow the black box rule, they make &lt;tt class=&quot;docutils literal&quot;&gt;with&lt;/tt&gt; blocks work again. There's no chance that, say, closing a file at the end of a &lt;tt class=&quot;docutils literal&quot;&gt;with&lt;/tt&gt; block will accidentally break a background task that's still using that file.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;automated-error-propagation-works&quot;&gt;
&lt;h3&gt;&lt;a class=&quot;toc-backref&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id24&quot;&gt;Automated error propagation works.&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;As noted above, in most concurrency systems, unhandled errors in background tasks are simply discarded. There's literally nothing else to do with them.&lt;/p&gt;
&lt;p&gt;In Trio, since every task lives inside a nursery, and every nursery is part of a parent task, and parent tasks are required to wait for the tasks inside the nursery... we &lt;em&gt;do&lt;/em&gt; have something we can do with unhandled errors. If a background task terminates with an exception, we can rethrow it in the parent task. The intuition here is that a nursery is something like a &quot;concurrent call&quot; primitive: we can think of our example above as calling &lt;tt class=&quot;docutils literal&quot;&gt;myfunc&lt;/tt&gt; and &lt;tt class=&quot;docutils literal&quot;&gt;anotherfunc&lt;/tt&gt; at the same time, so our call stack has become a tree. And exceptions propagate up this call tree towards the root, just like they propagate up a regular call stack.&lt;/p&gt;
&lt;p&gt;There is one subtlety here though: when we re-raise an exception in the parent task, it will start propagating in the parent task. Generally, that means that the parent task will exit the nursery block. But we've already said that the parent task cannot leave the nursery block while there are still child tasks running. So what do we do?&lt;/p&gt;
&lt;p&gt;The answer is that when an unhandled exception occurs in a child, Trio immediately cancels all the other tasks in the same nursery, and then waits for them to finish before re-raising the exception. The intuition here is that exceptions cause the stack to unwind, and if we want to unwind past a branch point in our stack tree, we need to unwind the other branches, by cancelling them.&lt;/p&gt;
&lt;p&gt;This does mean though that if you want to implement nurseries in your language, you may need some kind of integration between the nursery code and your cancellation system. This might be tricky if you're using a language like C# or Golang where cancellation is usually managed through manual object passing and convention, or (even worse) one that doesn't have a generic cancellation mechanism.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;a-surprise-benefit-removing-go-statements-enables-new-features&quot;&gt;
&lt;h3&gt;&lt;a class=&quot;toc-backref&quot; href=&quot;https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/#id25&quot;&gt;A surprise benefit: removing &lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt; statements enables new features&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Eliminating &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; allowed previous language designers to make stronger assumptions about the structure of programs, which enabled new features like &lt;tt class=&quot;docutils literal&quot;&gt;with&lt;/tt&gt; blocks and exceptions; eliminating &lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt; statements has a similar effect. For example:&lt;/p&gt;
&lt;ul class=&quot;simple&quot;&gt;&lt;li&gt;Trio's cancellation system is easier to use and more reliable than competitors, because it can assume that tasks are nested in a regular tree structure; see &lt;a class=&quot;reference external&quot; href=&quot;https://vorpus.org/blog/timeouts-and-cancellation-for-humans/&quot;&gt;Timeouts and cancellation for humans&lt;/a&gt; for a full discussion.&lt;/li&gt;
&lt;li&gt;Trio is the only Python concurrency library where control-C works the way Python developers expect (&lt;a class=&quot;reference external&quot; href=&quot;https://vorpus.org/blog/control-c-handling-in-python-and-trio/&quot;&gt;details&lt;/a&gt;). This would be impossible without nurseries providing a reliable mechanism for propagating exceptions.&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;nurseries-in-practice&quot;&gt;

&lt;p&gt;So that's the theory. How's it work in practice?&lt;/p&gt;
&lt;p&gt;Well... that's an empirical question: you should try it and find out! But seriously, we just won't know for sure until lots of people have pounded on it. At this point I'm pretty confident that the foundation is sound, but maybe we'll realize we need to make some tweaks, like how the early structured programming advocates eventually backed off from eliminating &lt;tt class=&quot;docutils literal&quot;&gt;break&lt;/tt&gt; and &lt;tt class=&quot;docutils literal&quot;&gt;continue&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;And if you're an experienced concurrent programmer who's just learning Trio, then you should expect to find it a bit rocky at times. You'll have to &lt;a class=&quot;reference external&quot; href=&quot;https://stackoverflow.com/questions/48282841/in-trio-how-can-i-have-a-background-task-that-lives-as-long-as-my-object-does&quot;&gt;learn new ways to do things&lt;/a&gt; – just like programmers in the 1970s found it challenging to learn how to write code without &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;But of course, that's the point. As Knuth wrote (&lt;a class=&quot;reference external&quot; href=&quot;https://scholar.google.com/scholar?cluster=17147143327681396418&amp;amp;hl=en&amp;amp;as_sdt=0,5&quot;&gt;Knuth, 1974&lt;/a&gt;, p. 275):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Probably the worst mistake any one can make with respect to the subject of &lt;strong&gt;go to&lt;/strong&gt; statements is to assume that &quot;structured programming&quot; is achieved by writing programs as we always have and then eliminating the &lt;strong&gt;go to&lt;/strong&gt;'s. Most &lt;strong&gt;go to&lt;/strong&gt;'s shouldn't be there in the first place! What we really want is to conceive of our program in such a way that we rarely even &lt;em&gt;think&lt;/em&gt; about &lt;strong&gt;go to&lt;/strong&gt; statements, because the real need for them hardly ever arises. The language in which we express our ideas has a strong influence on our thought processes. Therefore, Dijkstra asks for more new language features – structures which encourage clear thinking – in order to avoid the &lt;strong&gt;go to&lt;/strong&gt;'s temptations towards complications.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And so far, that's been my experience with using nurseries: they encourage clear thinking. They lead to designs that are more robust, easier to use, and just better all around. And the limitations actually make it easier to solve problems, because you spend less time being tempted towards unnecessary complications. Using Trio has, in a very real sense, taught me to be a better programmer.&lt;/p&gt;
&lt;p&gt;For example, consider the Happy Eyeballs algorithm (&lt;a class=&quot;reference external&quot; href=&quot;https://tools.ietf.org/html/rfc8305&quot;&gt;RFC 8305&lt;/a&gt;), which is a simple concurrent algorithm for speeding up the establishment of TCP connections. Conceptually, the algorithm isn't complicated – you race several connection attempts against each other, with a staggered start to avoid overloading the network. But if you look at &lt;a class=&quot;reference external&quot; href=&quot;https://github.com/twisted/twisted/compare/trunk...glyph:statemachine-hostnameendpoint&quot;&gt;Twisted's best implementation&lt;/a&gt;, it's almost 600 lines of Python, and still has &lt;a class=&quot;reference external&quot; href=&quot;https://twistedmatrix.com/trac/ticket/9345&quot;&gt;at least one logic bug&lt;/a&gt;. The equivalent in Trio is more than &lt;strong&gt;15x&lt;/strong&gt; shorter. More importantly, using Trio I was able to write it in minutes instead of months, and I got the logic correct on my first try. I never could have done this in any other framework, even ones where I have much more experience. For more details, you can &lt;a class=&quot;reference external&quot; href=&quot;https://www.youtube.com/watch?v=i-R704I8ySE&quot;&gt;watch my talk at Pyninsula last month&lt;/a&gt;. Is this typical? Time will tell. But it's certainly promising.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;conclusion&quot;&gt;

&lt;p&gt;The popular concurrency primitives – &lt;tt class=&quot;docutils literal&quot;&gt;go&lt;/tt&gt; statements, thread spawning functions, callbacks, futures, promises, ... they're all variants on &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;, in theory and in practice. And not even the modern domesticated &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;, but the old-testament fire-and-brimstone &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;, that could leap across function boundaries. These primitives are dangerous even if we don't use them directly, because they undermine our ability to reason about control flow and compose complex systems out of abstract modular parts, and they interfere with useful language features like automatic resource cleanup and error propagation. Therefore, like &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt;, they have no place in a modern high-level language.&lt;/p&gt;
&lt;p&gt;Nurseries provide a safe and convenient alternative that preserves the full power of your language, enables powerful new features (as demonstrated by Trio's cancellation scopes and control-C handling), and can produce dramatic improvements in readability, productivity, and correctness.&lt;/p&gt;
&lt;p&gt;Unfortunately, to fully capture these benefits, we do need to remove the old primitives entirely, and this probably requires building new concurrency frameworks from scratch – just like eliminating &lt;tt class=&quot;docutils literal&quot;&gt;goto&lt;/tt&gt; required designing new languages. But as impressive as FLOW-MATIC was for its time, most of us are glad that we've upgraded to something better. I don't think we'll regret switching to nurseries either, and Trio demonstrates that this is a viable design for practical, general-purpose concurrency frameworks.&lt;/p&gt;
&lt;/div&gt;


</description>
<pubDate>Wed, 25 Apr 2018 14:24:43 +0000</pubDate>
<dc:creator>m0meni</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/</dc:identifier>
</item>
</channel>
</rss>