<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>A rundown of the new Gmail</title>
<link>https://blog.google/products/gmail/stay-composed-heres-quick-rundown-new-gmail/</link>
<guid isPermaLink="true" >https://blog.google/products/gmail/stay-composed-heres-quick-rundown-new-gmail/</guid>
<description>&lt;h2&gt;Get started&lt;/h2&gt;
You can start using these new updates in Gmail on the web today, with some features appearing within the coming weeks. Go to Settings (the cog wheel in the top right corner of your inbox) and select “Try the new Gmail.” If you want to switch back later down the road, you can go to the same place and select “Go back to classic Gmail.” &lt;a href=&quot;https://goo.gl/Ct7DsK&quot;&gt;This handy product guide&lt;/a&gt; can help you get started.

&lt;p&gt;If you’re interested in learning more about how you can use Gmail in the workplace, check out our &lt;a href=&quot;https://www.blog.google/products/g-suite/new-security-and-intelligent-features-new-gmail-means-business&quot;&gt;G Suite post&lt;/a&gt; which has more detail on all of the ways Gmail can help you stay productive.&lt;br/&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 25 Apr 2018 07:18:11 +0000</pubDate>
<dc:creator>runesoerensen</dc:creator>
<og:type>article</og:type>
<og:title>Stay composed: here’s a quick rundown of the new Gmail</og:title>
<og:description>Time for an upgrade.</og:description>
<og:image>https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GmailLaunch-02.max-2800x2800.png</og:image>
<og:url>https://www.blog.google/products/gmail/stay-composed-heres-quick-rundown-new-gmail/</og:url>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.google/products/gmail/stay-composed-heres-quick-rundown-new-gmail/</dc:identifier>
</item>
<item>
<title>A one-second video taken by the Rosetta probe on the surface of a comet</title>
<link>https://twitter.com/Rainmaker1973/status/988711358358261762</link>
<guid isPermaLink="true" >https://twitter.com/Rainmaker1973/status/988711358358261762</guid>
<description>&lt;div class=&quot;UIWalkthrough-step UIWalkthrough-step--welcome&quot; readability=&quot;9&quot;&gt;
&lt;h3 class=&quot;UIWalkthrough-title&quot;&gt;Welcome home!&lt;/h3&gt;
&lt;p class=&quot;UIWalkthrough-message&quot;&gt;This timeline is where you’ll spend most of your time, getting instant updates about what matters to you.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;UIWalkthrough-step UIWalkthrough-step--unfollow&quot; readability=&quot;7&quot;&gt;
&lt;h3 class=&quot;UIWalkthrough-title&quot;&gt;Tweets not working for you?&lt;/h3&gt;
&lt;p class=&quot;UIWalkthrough-message&quot;&gt;Hover over the profile pic and click the Following button to unfollow any account.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;UIWalkthrough-step UIWalkthrough-step--like&quot; readability=&quot;9&quot;&gt;
&lt;h3 class=&quot;UIWalkthrough-title&quot;&gt;Say a lot with a little&lt;/h3&gt;
&lt;p class=&quot;UIWalkthrough-message&quot;&gt;When you see a Tweet you love, tap the heart — it lets the person who wrote it know you shared the love.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;UIWalkthrough-step UIWalkthrough-step--retweet&quot; readability=&quot;8&quot;&gt;
&lt;h3 class=&quot;UIWalkthrough-title&quot;&gt;Spread the word&lt;/h3&gt;
&lt;p class=&quot;UIWalkthrough-message&quot;&gt;The fastest way to share someone else’s Tweet with your followers is with a Retweet. Tap the icon to send it instantly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;UIWalkthrough-step UIWalkthrough-step--reply&quot; readability=&quot;9&quot;&gt;
&lt;h3 class=&quot;UIWalkthrough-title&quot;&gt;Join the conversation&lt;/h3&gt;
&lt;p class=&quot;UIWalkthrough-message&quot;&gt;Add your thoughts about any Tweet with a Reply. Find a topic you’re passionate about, and jump right in.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;UIWalkthrough-step UIWalkthrough-step--trends&quot; readability=&quot;7&quot;&gt;
&lt;h3 class=&quot;UIWalkthrough-title&quot;&gt;Learn the latest&lt;/h3&gt;
&lt;p class=&quot;UIWalkthrough-message&quot;&gt;Get instant insight into what people are talking about now.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;UIWalkthrough-step UIWalkthrough-step--wtf&quot; readability=&quot;7&quot;&gt;
&lt;h3 class=&quot;UIWalkthrough-title&quot;&gt;Get more of what you love&lt;/h3&gt;
&lt;p class=&quot;UIWalkthrough-message&quot;&gt;Follow more accounts to get instant updates about topics you care about.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;UIWalkthrough-step UIWalkthrough-step--search&quot; readability=&quot;7&quot;&gt;
&lt;h3 class=&quot;UIWalkthrough-title&quot;&gt;Find what's happening&lt;/h3&gt;
&lt;p class=&quot;UIWalkthrough-message&quot;&gt;See the latest conversations about any topic instantly.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;UIWalkthrough-step UIWalkthrough-step--moments&quot; readability=&quot;7&quot;&gt;
&lt;h3 class=&quot;UIWalkthrough-title&quot;&gt;Never miss a Moment&lt;/h3&gt;
&lt;p class=&quot;UIWalkthrough-message&quot;&gt;Catch up instantly on the best stories happening as they unfold.&lt;/p&gt;
&lt;/div&gt;
</description>
<pubDate>Wed, 25 Apr 2018 05:24:41 +0000</pubDate>
<dc:creator>mikecarlton</dc:creator>
<og:type>video</og:type>
<og:url>https://twitter.com/Rainmaker1973/status/988711358358261762</og:url>
<og:title>Massimo on Twitter</og:title>
<og:image>https://pbs.twimg.com/ext_tw_video_thumb/988711231442866176/pu/img/y5V3r42166J3xTCL.jpg</og:image>
<og:description>“This is what a view on a comet looks like, among dust, stars and cosmic ray hits, as captured by @ESA_Rosetta on June 1, 2016 and processed by @landru79 from these raw data: https://t.co/h3BV6Z2V71 https://t.co/w1Yv4OwIo1”</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://twitter.com/Rainmaker1973/status/988711358358261762</dc:identifier>
</item>
<item>
<title>How to write a spelling corrector (2016)</title>
<link>http://norvig.com/spell-correct.html</link>
<guid isPermaLink="true" >http://norvig.com/spell-correct.html</guid>
<description>&lt;head&gt;&lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;&lt;link href=&quot;prettify.css&quot; type=&quot;text/css&quot; rel=&quot;stylesheet&quot; /&gt;&lt;title&gt;How to Write a Spelling Corrector&lt;/title&gt;&lt;/head&gt;&lt;body onload=&quot;prettyPrint()&quot; id=&quot;readabilityBody&quot; readability=&quot;178.50530901171&quot;&gt;
&lt;p&gt;&lt;em&gt;Feb 2007&lt;br /&gt;to August 2016&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;One week in 2007, two friends (Dean and Bill) independently told me they were amazed at Google's spelling correction. Type in a search like &lt;a href=&quot;http://www.google.com/search?q=speling&quot;&gt;[speling]&lt;/a&gt; and Google instantly comes back with &lt;strong&gt;Showing results for: &lt;em&gt;&lt;a href=&quot;http://www.google.com/search?q=spelling&quot;&gt;spelling&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;. I thought Dean and Bill, being highly accomplished engineers and mathematicians, would have good intuitions about how this process works. But they didn't, and come to think of it, why should they know about something so far outisde their specialty?&lt;/p&gt;
&lt;p&gt;I figured they, and others, could benefit from an explanation. The full details of an industrial-strength spell corrector are quite complex (you can read a little about it &lt;a href=&quot;http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/pubs/archive/36180.pdf&quot;&gt;here&lt;/a&gt; or &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=52A3B869596656C9DA285DCE83A0339F?doi=10.1.1.146.4390&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;here&lt;/a&gt;). But I figured that in the course of a transcontinental plane ride I could write and explain a toy spelling corrector that achieves 80 or 90% accuracy at a processing speed of at least 10 words per second in about half a page of code.&lt;/p&gt;
&lt;p&gt;And here it is (or see &lt;a href=&quot;http://norvig.com/spell.py&quot;&gt;spell.py&lt;/a&gt;):&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
import re
from collections import Counter

def words(text): return re.findall(r'\w+', text.lower())

WORDS = Counter(words(open('big.txt').read()))

def P(word, N=sum(WORDS.values())): 
    &quot;Probability of `word`.&quot;
    return WORDS[word] / N

def correction(word): 
    &quot;Most probable spelling correction for word.&quot;
    return max(candidates(word), key=P)

def candidates(word): 
    &quot;Generate possible spelling corrections for word.&quot;
    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])

def known(words): 
    &quot;The subset of `words` that appear in the dictionary of WORDS.&quot;
    return set(w for w in words if w in WORDS)

def edits1(word):
    &quot;All edits that are one edit away from `word`.&quot;
    letters    = 'abcdefghijklmnopqrstuvwxyz'
    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]
    deletes    = [L + R[1:]               for L, R in splits if R]
    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)&amp;gt;1]
    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]
    inserts    = [L + c + R               for L, R in splits for c in letters]
    return set(deletes + transposes + replaces + inserts)

def edits2(word): 
    &quot;All edits that are two edits away from `word`.&quot;
    return (e2 for e1 in edits1(word) for e2 in edits1(e1))
&lt;/pre&gt;
&lt;p&gt;The function &lt;tt&gt;correction(word)&lt;/tt&gt; returns a likely spelling correction:&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
&amp;gt;&amp;gt;&amp;gt; correction('speling')
'spelling'

&amp;gt;&amp;gt;&amp;gt; correction('korrectud')
'corrected'
&lt;/pre&gt;
&lt;h2&gt;How It Works: Some Probability Theory&lt;/h2&gt;
&lt;p&gt;The call &lt;tt&gt;correction(w)&lt;/tt&gt; tries to choose the most likely spelling correction for &lt;tt&gt;w&lt;/tt&gt;. There is no way to know for sure (for example, should &quot;lates&quot; be corrected to &quot;late&quot; or &quot;latest&quot; or &quot;lattes&quot; or ...?), which suggests we use probabilities. We are trying to find the correction &lt;em&gt;c&lt;/em&gt;, out of all possible candidate corrections, that maximizes the probability that &lt;em&gt;c&lt;/em&gt; is the intended correction, given the original word &lt;em&gt;w&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;argmax&lt;sub&gt;&lt;em&gt;c ∈ candidates&lt;/em&gt;&lt;/sub&gt; P(&lt;em&gt;c&lt;/em&gt;|&lt;em&gt;w&lt;/em&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;By &lt;a href=&quot;http://en.wikipedia.org/wiki/Bayes'_theorem&quot;&gt;Bayes' Theorem&lt;/a&gt; this is equivalent to:&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;argmax&lt;sub&gt;&lt;em&gt;c ∈ candidates&lt;/em&gt;&lt;/sub&gt; P(&lt;em&gt;c&lt;/em&gt;) P(&lt;em&gt;w&lt;/em&gt;|&lt;em&gt;c&lt;/em&gt;) / P(&lt;em&gt;w&lt;/em&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since P(&lt;em&gt;w&lt;/em&gt;) is the same for every possible candidate &lt;em&gt;c&lt;/em&gt;, we can factor it out, giving:&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;argmax&lt;sub&gt;&lt;em&gt;c ∈ candidates&lt;/em&gt;&lt;/sub&gt; P(&lt;em&gt;c&lt;/em&gt;) P(&lt;em&gt;w&lt;/em&gt;|&lt;em&gt;c&lt;/em&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The four parts of this expression are:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Selection Mechanism&lt;/strong&gt;: argmax&lt;br /&gt;We choose the candidate with the highest combined probability.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Candidate Model&lt;/strong&gt;: &lt;em&gt;c ∈ candidates&lt;/em&gt;&lt;br /&gt;This tells us which candidate corrections, &lt;em&gt;c&lt;/em&gt;, to consider.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Language Model&lt;/strong&gt;: P(&lt;em&gt;c&lt;/em&gt;)&lt;br /&gt;The probability that &lt;em&gt;c&lt;/em&gt; appears as a word of English text. For example, occurrences of &quot;the&quot; make up about 7% of English text, so we should have P(&lt;em&gt;the&lt;/em&gt;) = 0.07.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Error Model&lt;/strong&gt;: P(&lt;em&gt;w&lt;/em&gt;|&lt;em&gt;c&lt;/em&gt;)&lt;br /&gt;The probability that &lt;em&gt;w&lt;/em&gt; would be typed in a text when the author meant &lt;em&gt;c&lt;/em&gt;. For example, P(&lt;em&gt;teh&lt;/em&gt;|&lt;em&gt;the&lt;/em&gt;) is relatively high, but P(&lt;em&gt;theeexyz&lt;/em&gt;|&lt;em&gt;the&lt;/em&gt;) would be very low.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;One obvious question is: why take a simple expression like P(&lt;em&gt;c&lt;/em&gt;|&lt;em&gt;w&lt;/em&gt;) and replace it with a more complex expression involving two models rather than one? The answer is that P(&lt;em&gt;c&lt;/em&gt;|&lt;em&gt;w&lt;/em&gt;) is &lt;em&gt;already&lt;/em&gt; conflating two factors, and it is easier to separate the two out and deal with them explicitly. Consider the misspelled word &lt;em&gt;w&lt;/em&gt;=&quot;thew&quot; and the two candidate corrections &lt;em&gt;c&lt;/em&gt;=&quot;the&quot; and &lt;em&gt;c&lt;/em&gt;=&quot;thaw&quot;. Which has a higher P(&lt;em&gt;c&lt;/em&gt;|&lt;em&gt;w&lt;/em&gt;)? Well, &quot;thaw&quot; seems good because the only change is &quot;a&quot; to &quot;e&quot;, which is a small change. On the other hand, &quot;the&quot; seems good because &quot;the&quot; is a very common word, and while adding a &quot;w&quot; seems like a larger, less probable change, perhaps the typist's finger slipped off the &quot;e&quot;. The point is that to estimate P(&lt;em&gt;c&lt;/em&gt;|&lt;em&gt;w&lt;/em&gt;) we have to consider both the probability of &lt;em&gt;c&lt;/em&gt; and the probability of the change from &lt;em&gt;c&lt;/em&gt; to &lt;em&gt;w&lt;/em&gt; anyway, so it is cleaner to formally separate the two factors.&lt;/p&gt;
&lt;h2&gt;How It Works: Some Python&lt;/h2&gt;
&lt;p&gt;The four parts of the program are:&lt;/p&gt;
&lt;ol readability=&quot;43.933437569801&quot;&gt;&lt;li&gt;&lt;strong&gt;Selection Mechanism&lt;/strong&gt;: In Python, &lt;tt&gt;max&lt;/tt&gt; with a &lt;tt&gt;key&lt;/tt&gt; argument does 'argmax'.&lt;/li&gt;
&lt;li readability=&quot;38&quot;&gt;&lt;strong&gt;Candidate Model&lt;/strong&gt;: First a new concept: a &lt;strong&gt;simple edit&lt;/strong&gt; to a word is a deletion (remove one letter), a transposition (swap two adjacent letters), a replacement (change one letter to another) or an insertion (add a letter). The function &lt;tt&gt;edits1&lt;/tt&gt; returns a set of all the edited strings (whether words or not) that can be made with one simple edit:
&lt;pre class=&quot;prettyprint&quot;&gt;
def edits1(word):
    &quot;All edits that are one edit away from `word`.&quot;
    letters    = 'abcdefghijklmnopqrstuvwxyz'
    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]
    deletes    = [L + R[1:]               for L, R in splits if R]
    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)&amp;gt;1]
    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]
    inserts    = [L + c + R               for L, R in splits for c in letters]
    return set(deletes + transposes + replaces + inserts)
&lt;/pre&gt;
&lt;p&gt;This can be a big set. For a word of length &lt;em&gt;n&lt;/em&gt;, there will be &lt;em&gt;n&lt;/em&gt; deletions, &lt;em&gt;n&lt;/em&gt;-1 transpositions, 26&lt;em&gt;n&lt;/em&gt; alterations, and 26(&lt;em&gt;n&lt;/em&gt;+1) insertions, for a total of 54&lt;em&gt;n&lt;/em&gt;+25 (of which a few are typically duplicates). For example,&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
&amp;gt;&amp;gt;&amp;gt; len(edits1('somthing'))
442
&lt;/pre&gt;
However, if we restrict ourselves to words that are &lt;em&gt;known&lt;/em&gt;—that is, in the dictionary— then the set is much smaller:
&lt;pre class=&quot;prettyprint&quot;&gt;
def known(words): return set(w for w in words if w in WORDS)

&amp;gt;&amp;gt;&amp;gt; known(edits1('somthing'))
{'something', 'soothing'}
&lt;/pre&gt;
We'll also consider corrections that require &lt;em&gt;two&lt;/em&gt; simple edits. This generates a much bigger set of possibilities, but usually only a few of them are known words:
&lt;pre class=&quot;prettyprint&quot;&gt;
def edits2(word): return (e2 for e1 in edits1(word) for e2 in edits1(e1))

&amp;gt;&amp;gt;&amp;gt; len(set(edits2('something'))
90902

&amp;gt;&amp;gt;&amp;gt; known(edits2('something'))
{'seething', 'smoothing', 'something', 'soothing'}

&amp;gt;&amp;gt;&amp;gt; known(edits2('somthing'))
{'loathing', 'nothing', 'scathing', 'seething', 'smoothing', 'something', 'soothing', 'sorting'}
&lt;/pre&gt;
We say that the results of &lt;tt&gt;edits2(w)&lt;/tt&gt; have an &lt;strong&gt;edit distance&lt;/strong&gt; of 2 from &lt;tt&gt;w&lt;/tt&gt;.&lt;/li&gt;
&lt;li readability=&quot;45.079569892473&quot;&gt;&lt;strong&gt;Language Model&lt;/strong&gt;: We can estimate the probability of a word, &lt;tt&gt;P(word)&lt;/tt&gt;, by counting the number of times each word appears in a text file of about a million words, &lt;a href=&quot;http://norvig.com/big.txt&quot;&gt;&lt;tt&gt;big.txt&lt;/tt&gt;&lt;/a&gt;. It is a concatenation of public domain book excerpts from &lt;a href=&quot;http://www.gutenberg.org/wiki/Main_Page&quot;&gt;Project Gutenberg&lt;/a&gt; and lists of most frequent words from &lt;a href=&quot;http://en.wiktionary.org/wiki/Wiktionary:Frequency_lists&quot;&gt;Wiktionary&lt;/a&gt; and the &lt;a href=&quot;http://www.kilgarriff.co.uk/bnc-readme.html&quot;&gt;British National Corpus&lt;/a&gt;. The function &lt;tt&gt;words&lt;/tt&gt; breaks text into words, then the variable &lt;tt&gt;WORDS&lt;/tt&gt; holds a Counter of how often each word appears, and &lt;tt&gt;P&lt;/tt&gt; estimates the probability of each word, based on this Counter:
&lt;pre class=&quot;prettyprint&quot;&gt;
def words(text): return re.findall(r'\w+', text.lower())

WORDS = Counter(words(open('big.txt').read()))

def P(word, N=sum(WORDS.values())): return WORDS[word] / N
&lt;/pre&gt;
We can see that there are 32,192 distinct words, which together appear 1,115,504 times, with 'the' being the most common word, appearing 79,808 times (or a probability of about 7%) and other words being less probable:
&lt;pre class=&quot;prettyprint&quot;&gt;
&amp;gt;&amp;gt;&amp;gt; len(WORDS)
32192

&amp;gt;&amp;gt;&amp;gt; sum(WORDS.values())
1115504

&amp;gt;&amp;gt;&amp;gt; WORDS.most_common(10)
[('the', 79808),
 ('of', 40024),
 ('and', 38311),
 ('to', 28765),
 ('in', 22020),
 ('a', 21124),
 ('that', 12512),
 ('he', 12401),
 ('was', 11410),
 ('it', 10681),
 ('his', 10034),
 ('is', 9773),
 ('with', 9739),
 ('as', 8064),
 ('i', 7679),
 ('had', 7383),
 ('for', 6938),
 ('at', 6789),
 ('by', 6735),
 ('on', 6639)]

&amp;gt;&amp;gt;&amp;gt; max(WORDS, key=P)
'the'

&amp;gt;&amp;gt;&amp;gt; P('the')
0.07154434228832886

&amp;gt;&amp;gt;&amp;gt; P('outrivaled')
8.9645577245801e-07

&amp;gt;&amp;gt;&amp;gt; P('unmentioned')
0.0
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;&lt;strong&gt;Error Model&lt;/strong&gt;: When I started to write this program, sitting on a plane in 2007, I had no data on spelling errors, and no internet connection (I know that may be hard to imagine today). Without data I couldn't build a good spelling error model, so I took a shortcut: I defined a trivial, flawed error model that says all known words of edit distance 1 are infinitely more probable than known words of edit distance 2, and infinitely less probable than a known word of edit distance 0. So we can make &lt;tt&gt;candidates(word)&lt;/tt&gt; produce the first non-empty list of candidates in order of priority:
&lt;ol&gt;&lt;li&gt;The original word, if it is known; otherwise&lt;/li&gt;
&lt;li&gt;The list of known words at edit distance one away, if there are any; otherwise&lt;/li&gt;
&lt;li&gt;The list of known words at edit distance two away, if there are any; otherwise&lt;/li&gt;
&lt;li&gt;The original word, even though it is not known.&lt;/li&gt;
&lt;/ol&gt;
Then we don't need to multiply by a P(&lt;em&gt;w&lt;/em&gt;|&lt;em&gt;c&lt;/em&gt;) factor, because every candidate at the chosen priority will have the same probability (according to our flawed model). That gives us:
&lt;pre class=&quot;prettyprint&quot;&gt;
def correction(word): return max(candidates(word), key=P)

def candidates(word): 
    return known([word]) or known(edits1(word)) or known(edits2(word)) or [word]
&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h2&gt;Evaluation&lt;/h2&gt;
&lt;p&gt;Now it is time to evaluate how well this program does. After my plane landed, I downloaded Roger Mitton's &lt;a href=&quot;http://ota.ahds.ac.uk/texts/0643.html&quot;&gt;Birkbeck spelling error corpus&lt;/a&gt; from the Oxford Text Archive. From that I extracted two test sets of corrections. The first is for development, meaning I get to look at it while I'm developing the program. The second is a final test set, meaning I'm not allowed to look at it, nor change my program after evaluating on it. This practice of having two sets is good hygiene; it keeps me from fooling myself into thinking I'm doing better than I am by tuning the program to one specific set of tests. I also wrote some unit tests:&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
def unit_tests():
    assert correction('speling') == 'spelling'              # insert
    assert correction('korrectud') == 'corrected'           # replace 2
    assert correction('bycycle') == 'bicycle'               # replace
    assert correction('inconvient') == 'inconvenient'       # insert 2
    assert correction('arrainged') == 'arranged'            # delete
    assert correction('peotry') =='poetry'                  # transpose
    assert correction('peotryy') =='poetry'                 # transpose + delete
    assert correction('word') == 'word'                     # known
    assert correction('quintessential') == 'quintessential' # unknown
    assert words('This is a TEST.') == ['this', 'is', 'a', 'test']
    assert Counter(words('This is a test. 123; A TEST this is.')) == (
           Counter({'123': 1, 'a': 2, 'is': 2, 'test': 2, 'this': 2}))
    assert len(WORDS) == 32192
    assert sum(WORDS.values()) == 1115504
    assert WORDS.most_common(10) == [
     ('the', 79808),
     ('of', 40024),
     ('and', 38311),
     ('to', 28765),
     ('in', 22020),
     ('a', 21124),
     ('that', 12512),
     ('he', 12401),
     ('was', 11410),
     ('it', 10681)]
    assert WORDS['the'] == 79808
    assert P('quintessential') == 0
    assert 0.07 &amp;lt; P('the') &amp;lt; 0.08
    return 'unit_tests pass'

def spelltest(tests, verbose=False):
    &quot;Run correction(wrong) on all (right, wrong) pairs; report results.&quot;
    import time
    start = time.clock()
    good, unknown = 0, 0
    n = len(tests)
    for right, wrong in tests:
        w = correction(wrong)
        good += (w == right)
        if w != right:
            unknown += (right not in WORDS)
            if verbose:
                print('correction({}) =&amp;gt; {} ({}); expected {} ({})'
                      .format(wrong, w, WORDS[w], right, WORDS[right]))
    dt = time.clock() - start
    print('{:.0%} of {} correct ({:.0%} unknown) at {:.0f} words per second '
          .format(good / n, n, unknown / n, n / dt))
    
def Testset(lines):
    &quot;Parse 'right: wrong1 wrong2' lines into [('right', 'wrong1'), ('right', 'wrong2')] pairs.&quot;
    return [(right, wrong)
            for (right, wrongs) in (line.split(':') for line in lines)
            for wrong in wrongs.split()]

print(unit_tests())
spelltest(Testset(open('&lt;a href=&quot;http://norvig.com/spell-testset1.txt&quot;&gt;spell-testset1.txt&lt;/a&gt;'))) # Development set
spelltest(Testset(open('&lt;a href=&quot;http://norvig.com/spell-testset1.txt&quot;&gt;spell-testset2.txt&lt;/a&gt;'))) # Final test set
&lt;/pre&gt;
&lt;p&gt;This gives the output:&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
unit_tests pass
75% of 270 correct at 41 words per second
68% of 400 correct at 35 words per second
None
&lt;/pre&gt;
&lt;p&gt;So on the development set we get 75% correct (processing words at a rate of 41 words/second), and on the final test set we get 68% correct (at 35 words/second). In conclusion, I met my goals for brevity, development time, and runtime speed, but not for accuracy. Perhaps my test set was extra tough, or perhaps my simple model is just not good enough to get to 80% or 90% accuracy.&lt;/p&gt;
&lt;h2&gt;Future Work&lt;/h2&gt;
&lt;p&gt;Let's think about how we could do better. (I've developed the ideas some more in a &lt;a href=&quot;http://norvig.com/ngrams/&quot;&gt;separate chapter&lt;/a&gt; for a book and in a &lt;a href=&quot;http://nbviewer.jupyter.org/url/norvig.com/ipython/How%20to%20Do%20Things%20with%20Words.ipynb&quot;&gt;Jupyter notebook&lt;/a&gt;.)&lt;/p&gt;
&lt;ol readability=&quot;48.85356029106&quot;&gt;&lt;li readability=&quot;18&quot;&gt;P(&lt;em&gt;c&lt;/em&gt;), the language model. We can distinguish two sources of error in the language model. The more serious is unknown words. In the development set, there are 15 unknown words, or 5%, and in the final test set, 43 unknown words or 11%. Here are some examples of the output of &lt;tt&gt;spelltest&lt;/tt&gt; with &lt;tt&gt;verbose=True)&lt;/tt&gt;:
&lt;pre class=&quot;prettyprint&quot;&gt;
correction('transportibility') =&amp;gt; 'transportibility' (0); expected 'transportability' (0)
correction('addresable') =&amp;gt; 'addresable' (0); expected 'addressable' (0)
correction('auxillary') =&amp;gt; 'axillary' (31); expected 'auxiliary' (0)
&lt;/pre&gt;
&lt;p&gt;In this output we show the call to &lt;tt&gt;correction&lt;/tt&gt; and the actual and expected results (with the &lt;tt&gt;WORDS&lt;/tt&gt; counts in parentheses). Counts of (0) mean the target word was not in the dictionary, so we have no chance of getting it right. We could create a better language model by collecting more data, and perhaps by using a little English morphology (such as adding &quot;ility&quot; or &quot;able&quot; to the end of a word).&lt;/p&gt;
&lt;p&gt;Another way to deal with unknown words is to allow the result of &lt;tt&gt;correction&lt;/tt&gt; to be a word we have not seen. For example, if the input is &quot;electroencephalographicallz&quot;, a good correction would be to change the final &quot;z&quot; to an &quot;y&quot;, even though &quot;electroencephalographically&quot; is not in our dictionary. We could achieve this with a language model based on components of words: perhaps on syllables or suffixes, but it is easier to base it on sequences of characters: common 2-, 3- and 4-letter sequences.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;35&quot;&gt;P(&lt;em&gt;w&lt;/em&gt;|&lt;em&gt;c&lt;/em&gt;), the error model. So far, the error model has been trivial: the smaller the edit distance, the smaller the error. This causes some problems, as the examples below show. First, some cases where &lt;tt&gt;correction&lt;/tt&gt; returns a word at edit distance 1 when it should return one at edit distance 2:
&lt;pre class=&quot;prettyprint&quot;&gt;
correction('reciet') =&amp;gt; 'recite' (5); expected 'receipt' (14)
correction('adres') =&amp;gt; 'acres' (37); expected 'address' (77)
correction('rember') =&amp;gt; 'member' (51); expected 'remember' (162)
correction('juse') =&amp;gt; 'just' (768); expected 'juice' (6)
correction('accesing') =&amp;gt; 'acceding' (2); expected 'assessing' (1)
&lt;/pre&gt;
&lt;p&gt;Why should &quot;adres&quot; be corrected to &quot;address&quot; rather than &quot;acres&quot;? The intuition is that the two edits from &quot;d&quot; to &quot;dd&quot; and &quot;s&quot; to &quot;ss&quot; should both be fairly common, and have high probability, while the single edit from &quot;d&quot; to &quot;c&quot; should have low probability.&lt;/p&gt;
&lt;p&gt;Clearly we could use a better model of the cost of edits. We could use our intuition to assign lower costs for doubling letters and changing a vowel to another vowel (as compared to an arbitrary letter change), but it seems better to gather data: to get a corpus of spelling errors, and count how likely it is to make each insertion, deletion, or alteration, given the surrounding characters. We need a lot of data to do this well. If we want to look at the change of one character for another, given a window of two characters on each side, that's 26&lt;sup&gt;6&lt;/sup&gt;, which is over 300 million characters. You'd want several examples of each, on average, so we need at least a billion characters of correction data; probably safer with at least 10 billion.&lt;/p&gt;
&lt;p&gt;Note there is a connection between the language model and the error model. The current program has such a simple error model (all edit distance 1 words before any edit distance 2 words) that it handicaps the language model: we are afraid to add obscure words to the model, because if one of those obscure words happens to be edit distance 1 from an input word, then it will be chosen, even if there is a very common word at edit distance 2. With a better error model we can be more aggressive about adding obscure words to the dictionary. Here are some examples where the presence of obscure words in the dictionary hurts us:&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
correction('wonted') =&amp;gt; 'wonted' (2); expected 'wanted' (214)
correction('planed') =&amp;gt; 'planed' (2); expected 'planned' (16)
correction('forth') =&amp;gt; 'forth' (83); expected 'fourth' (79)
correction('et') =&amp;gt; 'et' (20); expected 'set' (325)
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;6.5&quot;&gt;The enumeration of possible corrections, argmax&lt;sub&gt;&lt;em&gt;c&lt;/em&gt;&lt;/sub&gt;. Our program enumerates all corrections within edit distance 2. In the development set, only 3 words out of 270 are beyond edit distance 2, but in the final test set, there were 23 out of 400. Here they are:
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;pre&gt;
purple perpul
curtains courtens
minutes muinets

successful sucssuful
hierarchy heiarky
profession preffeson
weighted wagted
inefficient ineffiect
availability avaiblity
thermawear thermawhere
nature natior
dissension desention
unnecessarily unessasarily
disappointing dissapoiting
acquaintances aquantences
thoughts thorts
criticism citisum
immediately imidatly
necessary necasery
necessary nessasary
necessary nessisary
unnecessary unessessay
night nite
minutes muiuets
assessing accesing
necessitates nessisitates
&lt;/pre&gt;&lt;/blockquote&gt;
&lt;p&gt;We could consider extending the model by allowing a limited set of edits at edit distance 3. For example, allowing only the insertion of a vowel next to another vowel, or the replacement of a vowel for another vowel, or replacing close consonants like &quot;c&quot; to &quot;s&quot; would handle almost all these cases.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;34.654061022776&quot;&gt;There's actually a fourth (and best) way to improve: change the interface to &lt;tt&gt;correction&lt;/tt&gt; to look at more context. So far, &lt;tt&gt;correction&lt;/tt&gt; only looks at one word at a time. It turns out that in many cases it is difficult to make a decision based only on a single word. This is most obvious when there is a word that appears in the dictionary, but the test set says it should be corrected to another word anyway:
&lt;pre class=&quot;prettyprint&quot;&gt;
correction('where') =&amp;gt; 'where' (123); expected 'were' (452)
correction('latter') =&amp;gt; 'latter' (11); expected 'later' (116)
correction('advice') =&amp;gt; 'advice' (64); expected 'advise' (20)
&lt;/pre&gt;
&lt;p&gt;We can't possibly know that &lt;tt&gt;correction('where')&lt;/tt&gt; should be 'were' in at least one case, but should remain 'where' in other cases. But if the query had been &lt;tt&gt;correction('They where going')&lt;/tt&gt; then it seems likely that &quot;where&quot; should be corrected to &quot;were&quot;.&lt;/p&gt;
&lt;p&gt;The context of the surrounding words can help when there are obvious errors, but two or more good candidate corrections. Consider:&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
correction('hown') =&amp;gt; 'how' (1316); expected 'shown' (114)
correction('ther') =&amp;gt; 'the' (81031); expected 'their' (3956)
correction('quies') =&amp;gt; 'quiet' (119); expected 'queries' (1)
correction('natior') =&amp;gt; 'nation' (170); expected 'nature' (171)
correction('thear') =&amp;gt; 'their' (3956); expected 'there' (4973)
correction('carrers') =&amp;gt; 'carriers' (7); expected 'careers' (2)
&lt;/pre&gt;
&lt;p&gt;Why should 'thear' be corrected as 'there' rather than 'their'? It is difficult to tell by the single word alone, but if the query were &lt;tt&gt;correction('There's no there thear')&lt;/tt&gt; it would be clear.&lt;/p&gt;
&lt;p&gt;To build a model that looks at multiple words at a time, we will need a lot of data. Fortunately, Google has released a &lt;a href=&quot;http://googleresearch.blogspot.com/2006/08/all-our-n-gram-are-belong-to-you.html&quot;&gt;database of word counts&lt;/a&gt; for all sequences up to five words long, gathered from a corpus of a &lt;em&gt;trillion&lt;/em&gt; words.&lt;/p&gt;
&lt;p&gt;I believe that a spelling corrector that scores 90% accuracy will &lt;em&gt;need&lt;/em&gt; to use the context of the surrounding words to make a choice. But we'll leave that for another day...&lt;/p&gt;
&lt;p&gt;We could also decide what dialect we are trying to train for. The following three errors are due to confusion about American versus British spelling (our training data contains both):&lt;/p&gt;
&lt;pre class=&quot;prettyprint&quot;&gt;
correction('humor') =&amp;gt; 'humor' (17); expected 'humour' (5)
correction('oranisation') =&amp;gt; 'organisation' (8); expected 'organization' (43)
correction('oranised') =&amp;gt; 'organised' (11); expected 'organized' (70)
&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;Finally, we could improve the implementation by making it much faster, without changing the results. We could re-implement in a compiled language rather than an interpreted one. We could cache the results of computations so that we don't have to repeat them multiple times. One word of advice: before attempting any speed optimizations, profile carefully to see where the time is actually going.&lt;/li&gt;
&lt;/ol&gt;&lt;h2&gt;Further Reading&lt;/h2&gt;
&lt;h2&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;Ivan Peev, Jay Liang, Dmitriy Ryaboy and Darius Bacon pointed out problems in &lt;a href=&quot;https://web.archive.org/web/*/http://norvig.com/spell-correct.html&quot;&gt;earlier versions&lt;/a&gt; of this document.&lt;/p&gt;
&lt;h2&gt;Other Computer Languages&lt;/h2&gt;
&lt;p&gt;After I posted this article, various people wrote versions in different programming languages. These may be interesting for those who like comparing languages, or for those who want to borrow an implementation in their desired target language:&lt;/p&gt;
&lt;h2&gt;Other Natural Languages&lt;/h2&gt;
&lt;p&gt;This essay has been translated into:&lt;/p&gt;
&lt;p&gt;Thanks to all the authors for creating these implementations and translations.&lt;/p&gt;
&lt;hr /&gt;&lt;address&gt;&lt;a href=&quot;http://norvig.com&quot;&gt;&lt;em&gt;Peter Norvig&lt;/em&gt;&lt;/a&gt;&lt;/address&gt;
&lt;/body&gt;</description>
<pubDate>Wed, 25 Apr 2018 05:07:55 +0000</pubDate>
<dc:creator>partycoder</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>http://norvig.com/spell-correct.html</dc:identifier>
</item>
<item>
<title>Redux – Not Dead Yet</title>
<link>http://blog.isquaredsoftware.com/2018/03/redux-not-dead-yet/</link>
<guid isPermaLink="true" >http://blog.isquaredsoftware.com/2018/03/redux-not-dead-yet/</guid>
<description>&lt;p&gt;&lt;em&gt;Some clarification on what's going on with Redux&lt;/em&gt;&lt;/p&gt;&lt;p&gt;I'm a Redux maintainer. There's been a lot of confusion, claims, and misinformation about Redux going around lately, and I want to help clear things up.&lt;/p&gt;
&lt;h2 id=&quot;tl-dr&quot;&gt;TL;DR&lt;/h2&gt;
&lt;h3 id=&quot;is-redux-dead-dying-deprecated-or-about-to-be-replaced&quot;&gt;Is Redux dead, dying, deprecated, or about to be replaced?&lt;/h3&gt;
&lt;p&gt;No.&lt;/p&gt;
&lt;h3 id=&quot;are-there-situations-where-you-don-t-need-redux&quot;&gt;Are there situations where you don't need Redux?&lt;/h3&gt;
&lt;p&gt;Sure, but that's always been true.&lt;/p&gt;
&lt;h2 id=&quot;a-longer-explanation&quot;&gt;A Longer Explanation&lt;/h2&gt;
&lt;p&gt;There's been a whole slew of comments and articles lately that boil down to people asking &quot;Is Redux dead?&quot;, or asserting that &quot;Tool X replaces Redux&quot;. I'll recap several sources of confusion, and explain what's actually going on.&lt;/p&gt;
&lt;h3 id=&quot;redux-is-overused&quot;&gt;&quot;Redux is Overused&quot;&lt;/h3&gt;
&lt;h4 id=&quot;where-s-this-coming-from&quot;&gt;Where's this coming from?&lt;/h4&gt;
&lt;p&gt;Redux has been around for almost three years. In &quot;JS library years&quot;, that's like... &lt;em&gt;forever&lt;/em&gt; :) It got very popular very quickly, and as a result, a lot of people were told they &lt;em&gt;had&lt;/em&gt; to use Redux, without actually understanding the tradeoffs involved and when it actually makes sense to use Redux. So, there's been some inevitable backlash, and people have looked for alternatives, including adopting other state management libraries or creating their own.&lt;/p&gt;
&lt;p&gt;As part of that, there was a wave of tweets about a month ago about how Redux was being overused. One in particular was from Cory House, a well-known author/teacher in the React community. That tweet and various others got heavily retweeted, and the ensuing discussion ricocheted around Twitter for a while.&lt;/p&gt;
&lt;h4 id=&quot;clearing-the-confusion&quot;&gt;Clearing the Confusion&lt;/h4&gt;
&lt;p&gt;The Redux maintainers (first Dan Abramov and Andrew Clark, now Tim Dorr and myself) have always said that &lt;a href=&quot;https://medium.com/@dan_abramov/you-might-not-need-redux-be46360cf367&quot;&gt;you might not need Redux&lt;/a&gt;. There are &lt;em&gt;excellent&lt;/em&gt; reasons to use Redux, but it may not be the best fit for your situation. &lt;strong&gt;Like any tool, it's important to understand the tradeoffs and benefits before deciding to use something&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I've seen plenty of comments amongst the Twitterati that people have opted to move away from Redux to something else. But, at the same time, &lt;strong&gt;my own estimates are that somewhere between 50-60% of all React apps use Redux&lt;/strong&gt;, plus all of its usage with other JS frameworks like Angular, Ember, and Vue, and that is a userbase that isn't just going to disappear overnight. (There's also a big gap between what gets chatted about at lightning speed on social media, and what people are actually doing in &quot;the real world&quot;.)&lt;/p&gt;
&lt;p&gt;It's also worth noting that &lt;strong&gt;Redux is not owned by Facebook - it's a separate open-source project&lt;/strong&gt;. Both of its creators (Dan Abramov and Andrew Clark) now work at Facebook, but Tim Dorr and I have no affiliation with Facebook at all. We talk with the React team to help coordinate future plans, but Redux doesn't belong to them.&lt;/p&gt;
&lt;h3 id=&quot;the-new-context-api-can-replace-redux&quot;&gt;&quot;The new Context API can replace Redux&quot;&lt;/h3&gt;
&lt;h4 id=&quot;where-s-this-coming-from-1&quot;&gt;Where's this coming from?&lt;/h4&gt;
&lt;p&gt;React 16.3 is introducing a new stable version of the &lt;code&gt;context&lt;/code&gt; API, which is intended to replace the old unstable API. Context is specifically intended for the use case of passing data to deeply nested React components. That's one of the reasons why some people have chosen to use Redux, and so there's been claims that the new context API will replace Redux.&lt;/p&gt;
&lt;h4 id=&quot;clearing-the-confusion-1&quot;&gt;Clearing the Confusion&lt;/h4&gt;
&lt;p&gt;Yes, the new context API is going to be great for passing down data to deeply nested components - that's exactly what it was designed for. &lt;strong&gt;If you're only using Redux to avoid passing down props, context &lt;em&gt;could&lt;/em&gt; replace Redux - but then you probably didn't &lt;em&gt;need&lt;/em&gt; Redux in the first place&lt;/strong&gt;. Context also doesn't give you anything like the Redux DevTools, the ability to trace your state updates, middleware to add centralized application logic, and other powerful capabilities that Redux enables.&lt;/p&gt;
&lt;h3 id=&quot;graphql-can-replace-redux&quot;&gt;&quot;GraphQL can replace Redux&quot;&lt;/h3&gt;
&lt;h4 id=&quot;where-s-this-coming-from-2&quot;&gt;Where's this coming from?&lt;/h4&gt;
&lt;p&gt;Somewhat similarly, there's been a lot of noise around GraphQL and the Apollo Client. There have been articles specifically claiming that &quot;GraphQL will let you replace Redux&quot;. Also, Apollo has a new &lt;code&gt;apollo-link-state&lt;/code&gt; addon that can handle client-side state, and there's been discussion that that can also help replace Redux.&lt;/p&gt;
&lt;h4 id=&quot;clearing-the-confusion-2&quot;&gt;Clearing the Confusion&lt;/h4&gt;
&lt;p&gt;I'd agree that data fetching via GraphQL, and especially with Apollo, will likely reduce or eliminate your data-fetching related Redux code. And again, if that's &lt;em&gt;all&lt;/em&gt; you were using Redux for, you probably wouldn't need Redux after moving all the data-fetching handling into Apollo. I'll even go so far as to say that &lt;code&gt;apollo-link-state&lt;/code&gt; could probably handle most of your other client-side state logic, and I think Apollo ships with a DevTools setup of its own. The Apollo team has been doing some pretty neat work, and while I don't &lt;em&gt;like&lt;/em&gt; seeing people switch away from Redux, ultimately we all want to build great apps that help our users. But, as with context, I'd say there's definitely use cases where Redux is going to work better than GraphQL + Apollo, and possibly without requiring as much buy-in throughout your architecture. This is especially true if you need to do more than just fetch data or update a couple local state values, like persisting user data through page reloads or implementing complex workflow logic.&lt;/p&gt;
&lt;h3 id=&quot;redux-is-being-replaced-by-something-from-react&quot;&gt;&quot;Redux is being replaced by something from React&quot;&lt;/h3&gt;
&lt;h4 id=&quot;where-s-this-coming-from-3&quot;&gt;Where's this coming from?&lt;/h4&gt;
&lt;p&gt;Finally, &lt;a href=&quot;https://reactjs.org/blog/2018/03/01/sneak-peek-beyond-react-16.html&quot;&gt;Dan Abramov recently gave a great talk at JS Conf Iceland&lt;/a&gt; where he demoed two upcoming aspects of React's &quot;async rendering&quot;: time-slicing will allow React to split up update calculations for smoother updates, and &quot;React Suspense&quot; will allow deeply nested components to delay their rendering until fetched data is available. Unfortunately, shortly after the talk, a site known for writing misleading and poorly-written articles about React put up a post claiming that &quot;Dan Abramov announced a new 'future-fetcher' library that replaces Redux&quot;, and linked a tweet by Kent C Dodds with that statement as evidence.&lt;/p&gt;
&lt;h4 id=&quot;clearing-the-confusion-3&quot;&gt;Clearing the Confusion&lt;/h4&gt;
&lt;p&gt;One of the problems with social media is that it's easy for misinformation to spread quickly. And especially in this case, because &lt;strong&gt;that widely-spread article about Dan announcing a &quot;future-fetcher&quot; library was completely and utterly wrong!&lt;/strong&gt; Dan's announcement was purely about async React capabilities, and had &lt;em&gt;nothing&lt;/em&gt; to do with Redux. In addition, Kent's tweet about Redux being replaced was literally a joke tweet in a joke Twitter &quot;live-commentary&quot; thread about the talk. The article was either a complete misunderstanding of the React ecosystem, or a deliberate attempt to spread confusion and FUD.&lt;/p&gt;
&lt;h2 id=&quot;the-future-of-redux&quot;&gt;The Future of Redux&lt;/h2&gt;
&lt;p&gt;As a Redux maintainer, I can assure you that &lt;strong&gt;Redux isn't going anywhere&lt;/strong&gt;. The Redux core library is stable, and we've actually got a 4.0 beta release available. Despite the major version bump, it's really just about cleaning up some edge cases and improving the TypeScript typings. Besides that, &lt;a href=&quot;http://blog.isquaredsoftware.com/2017/09/presentation-might-need-redux-ecosystem/&quot;&gt;the Redux ecosystem is thriving&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The &lt;em&gt;real&lt;/em&gt; interesting near-future work is around the React-Redux library&lt;/strong&gt;. We're going to be updating it to work better with React's async capabilities. We have &lt;a href=&quot;https://github.com/reactjs/react-redux/issues/890&quot;&gt;an open issue for discussion of how Redux will work with async React&lt;/a&gt;, and I created &lt;a href=&quot;https://github.com/reactjs/react-redux/pull/898&quot;&gt;a proof of concept PR that updates &lt;code&gt;connect&lt;/code&gt; to use the new context API&lt;/a&gt;. There will be more work needed over the next few months, but we're committed to ensuring that React and Redux continue to be a great choice for building applications.&lt;/p&gt;
&lt;h2 id=&quot;ready-to-learn-redux&quot;&gt;Ready to Learn Redux?&lt;/h2&gt;
&lt;p&gt;So with all that in mind, it's a great time to learn how to use Redux. As always, I'll close with some links to further resources:&lt;/p&gt;
&lt;p&gt;I'd also encourage people to really understand when and why they should use Redux. Some suggested articles:&lt;/p&gt;
&lt;h3 id=&quot;learn-redux-in-person-from-me&quot;&gt;Learn Redux In Person from Me!&lt;/h3&gt;
&lt;p&gt;Besides all the articles and posts and links, &lt;strong&gt;I'm going to be teaching a series of &quot;Redux Fundamentals&quot; workshops through Workshop.me!&lt;/strong&gt; I'm excited for this chance to spend a couple days helping people learn exactly how Redux works and how to use it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://workshop.me/2018-04-react-redux/?a=mark&quot;&gt;My first &quot;Redux Fundamentals&quot; workshop is April 19-20, in New York City&lt;/a&gt;&lt;/strong&gt;, with other workshop locations and dates TBD later this year. &lt;strong&gt;Tickets for the NYC workshop are still available!&lt;/strong&gt; If you're not in NYC, or are already comfortable with Redux, spread the word to someone you know who might be interested! :)&lt;/p&gt;
</description>
<pubDate>Wed, 25 Apr 2018 01:10:56 +0000</pubDate>
<dc:creator>fagnerbrack</dc:creator>
<og:title>Blogged Answers: Redux - Not Dead Yet! · Mark's Dev Blog</og:title>
<og:url>http://blog.isquaredsoftware.com/2018/03/redux-not-dead-yet/</og:url>
<og:image>http://blog.isquaredsoftware.com/images/logo.png</og:image>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>http://blog.isquaredsoftware.com/2018/03/redux-not-dead-yet/</dc:identifier>
</item>
<item>
<title>Electric Buses Are Hurting the Oil Industry</title>
<link>https://www.bloomberg.com/news/articles/2018-04-23/electric-buses-are-hurting-the-oil-industry</link>
<guid isPermaLink="true" >https://www.bloomberg.com/news/articles/2018-04-23/electric-buses-are-hurting-the-oil-industry</guid>
<description>&lt;p&gt;Electric buses were seen as a joke at an industry conference in Belgium seven years ago when the Chinese manufacturer &lt;a href=&quot;https://www.bloomberg.com/quote/1211:HK&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot;&gt;BYD Co.&lt;/a&gt; showed an early model.&lt;/p&gt;


&lt;p&gt;“Everyone was laughing at BYD for making a toy,” recalled Isbrand Ho, the Shenzhen-based company’s managing director in Europe. “And look now. Everyone has one.”&lt;/p&gt;



&lt;div id=&quot;lazy-img-326892585&quot; class=&quot;lazy-img&quot;&gt;&lt;img src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ivzmfesaSMFc/v0/60x-1.jpg&quot; data-native-src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/ivzmfesaSMFc/v0/-1x-1.jpg&quot; class=&quot;lazy-img__image&quot; data-img-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;p&gt;Suddenly, buses with battery-powered motors are a serious matter with the potential to revolutionize city transport—and add to the forces reshaping the energy industry. With China leading the way, making the traditional smog-belching diesel behemoth run on electricity is starting to eat away at fossil fuel demand.&lt;/p&gt;



&lt;p&gt;The numbers are staggering. China had about 99 percent of the 385,000 electric buses on the roads worldwide in 2017, accounting for 17 percent of the country’s entire fleet. Every five weeks, Chinese cities add 9,500 of the zero-emissions transporters—the equivalent of London’s entire working fleet, according Bloomberg New Energy Finance.&lt;/p&gt;


&lt;p&gt;All this is starting to make an observable reduction in fuel demand. And because they consume 30 times more fuel than average sized cars, their impact on energy use so far has become much greater than the passenger sedans produced by companies from &lt;a href=&quot;https://www.bloomberg.com/quote/TSLA:US&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot;&gt;Tesla Inc.&lt;/a&gt; to &lt;a href=&quot;https://www.bloomberg.com/quote/7203:JP&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot;&gt;Toyota Motor Corp.&lt;/a&gt;&lt;/p&gt;
&lt;div&gt;
&lt;div class=&quot;chart&quot; data-responsive=&quot;true&quot; readability=&quot;7&quot;&gt;
&lt;div class=&quot;chart-js&quot; readability=&quot;9&quot;&gt;
&lt;h3 class=&quot;chart__title&quot;&gt;Keeping It in the Ground&lt;/h3&gt;
&lt;p class=&quot;chart__subtitle&quot;&gt;Cumulative global fuel displacement by e-buses and passenger EVs&lt;/p&gt;

&lt;p class=&quot;chart__source&quot;&gt;Source: Bloomberg New Energy Finance&lt;/p&gt;

&lt;/div&gt;
&lt;noscript&gt;
&lt;p&gt;&lt;img src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i1RfaNVo6YdA/v1/-1x-1.png&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;For every 1,000 battery-powered buses on the road, about 500 barrels a day of diesel fuel will be displaced from the market, according to BNEF calculations. This year, the volume of fuel not needed may rise 37 percent to 279,000 barrels a day because of electric transport including cars and light trucks, about as much oil as &lt;a href=&quot;https://www.eia.gov/beta/international/data/browser/#/?pa=0000001&amp;amp;c=ruvvvvvfvtvnvv1urvvvvfvvvvvvfvvvou20evvvvvvvvvnvvuvs&amp;amp;ct=0&amp;amp;tl_id=5-A&amp;amp;vs=INTL.5-2-AFG-TBPD.A&amp;amp;cy=2015&amp;amp;vo=0&amp;amp;v=H&amp;amp;end=2016&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Greece consumes&lt;/a&gt;, according to BNEF. Buses account for about 233,000 barrels of that total.&lt;/p&gt;
&lt;p&gt;“This segment is approaching the tipping point,” said Colin McKerracher, head of advanced transport at the London-based research unit of Bloomberg LP. “City governments all over the world are being taken to task over poor urban air quality. This pressure isn’t going away, and electric bus sales are positioned to benefit.”&lt;/p&gt;
&lt;p&gt;China is ahead on electrifying its fleet because it has the world’s worst pollution problem. With a growing urban population and galloping energy demand, the nation’s legendary smogs were responsible for 1.6 million extra deaths in 2015, according to non-profit Berkeley Earth.&lt;/p&gt;
&lt;div&gt;
&lt;div class=&quot;chart&quot; data-responsive=&quot;true&quot; readability=&quot;7&quot;&gt;
&lt;div class=&quot;chart-js&quot; readability=&quot;9&quot;&gt;
&lt;h3 class=&quot;chart__title&quot;&gt;Putting It Back&lt;/h3&gt;
&lt;p class=&quot;chart__subtitle&quot;&gt;Global fuel demand displaced by e-buses&lt;/p&gt;

&lt;p class=&quot;chart__source&quot;&gt;Source: Bloomberg New Energy Finance&lt;/p&gt;

&lt;/div&gt;
&lt;noscript&gt;
&lt;p&gt;&lt;img src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iaUjblOElLSk/v1/-1x-1.png&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;aside class=&quot;inline-newsletter&quot; data-state=&quot;ready&quot;/&gt;
&lt;p&gt;A decade ago, Shenzhen was a typical example of a booming Chinese city that had given little thought to the environment. Its smog became so notorious that the government picked it for a pilot program for energy conservation and zero emissions vehicles in 2009. Two years later, the first electric buses rolled off BYD’s production line there. And in December, all of Shenzhen’s 16,359 buses were electric.&lt;/p&gt;
&lt;p&gt;BYD had 13 percent of China’s electric bus market in 2016 and put 14,000 of the vehicles on the streets of Shenzhen alone. It’s built 35,000 so far and has capacity to build as many as 15,000 a year, Ho said.&lt;/p&gt;
&lt;div readability=&quot;9&quot;&gt;
&lt;div class=&quot;image&quot;&gt;
&lt;div id=&quot;lazy-img-326890480&quot; class=&quot;lazy-img&quot;&gt;&lt;img src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iMndNNJCNFAg/v1/60x-1.jpg&quot; data-native-src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iMndNNJCNFAg/v1/-1x-1.jpg&quot; class=&quot;lazy-img__image&quot; data-img-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;A worker charges an electric bus in Shenzhen.&lt;/p&gt;
&lt;p&gt;Photographer: Qilai Shen/Bloomberg&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;BYD estimates its buses have logged 17 billion kilometers (10 billion miles) and saved 6.8 billion liters (1.8 billion gallons) of fuel since they started ferrying passengers around the world’s busiest cities. That, according to Ho, adds up to 18 million tons of carbon dioxide pollution avoided, which is about as much as &lt;a href=&quot;https://www.epa.gov/energy/greenhouse-gas-equivalencies-calculator&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;3.8 million cars&lt;/a&gt; produce in each year.&lt;/p&gt;
&lt;p&gt;“The first fleet of pure electric buses provided by BYD started operation in Shenzhen in 2011,” Ho said by phone. “Now, almost 10 years later, in other cities the air quality has worsened while—compared with those cities—Shenzhen’s is much better.”&lt;/p&gt;
&lt;div&gt;
&lt;div class=&quot;chart&quot; data-responsive=&quot;true&quot; readability=&quot;6&quot;&gt;
&lt;div class=&quot;chart-js&quot; readability=&quot;7&quot;&gt;
&lt;h3 class=&quot;chart__title&quot;&gt;Driving the Revolution&lt;/h3&gt;
&lt;p class=&quot;chart__subtitle&quot;&gt;China electric bus sales&lt;/p&gt;

&lt;p class=&quot;chart__source&quot;&gt;Source: Bloomberg New Energy Finance&lt;/p&gt;

&lt;/div&gt;
&lt;noscript&gt;
&lt;p&gt;&lt;img src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/if5vZZT5ZKnQ/v1/-1x-1.png&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Other cities are taking notice. Paris, London, Mexico City and Los Angeles are among 13 authorities that have committed to only buying zero emissions transport by 2025.&lt;/p&gt;
&lt;p&gt;London is slowly transforming its fleet. Currently four routes in the city center serviced by single-decker units are being shifted to electricity. There are plans to make significant investments to the clean its public transport networks, including retrofitting 5,000 old diesel buses in a program to ensure all buses are emission-free by 2037.&lt;/p&gt;
&lt;div readability=&quot;9&quot;&gt;
&lt;div class=&quot;image&quot;&gt;
&lt;div id=&quot;lazy-img-326890202&quot; class=&quot;lazy-img&quot;&gt;&lt;img src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i3Yje0aeztl8/v3/60x-1.jpg&quot; data-native-src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i3Yje0aeztl8/v3/-1x-1.jpg&quot; class=&quot;lazy-img__image&quot; data-img-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;A BYD Co. double-decker electric bus at the EV Trend Korea exhibition in Seoul on April 12.&lt;/p&gt;
&lt;p&gt;Photographer: SeongJoon Cho/Bloomberg&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://www.bloomberg.com/quote/3124Z:LN&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot;&gt;Transport for London&lt;/a&gt;, responsible for the city’s transport system, declined to comment for this article because of rules around engaging with the media ahead of May local government elections.&lt;/p&gt;
&lt;p&gt;Those goals will have an impact on fuel consumption. London’s network draws about 1.5 million barrels a year of fuel. If the entire fleet goes electric, that may displace 430 barrels a day of diesel for each 1,000 buses going electric, reducing U.K. diesel consumption by about 0.7 percent, according to BNEF.&lt;/p&gt;
&lt;div&gt;
&lt;div class=&quot;chart&quot; data-responsive=&quot;true&quot; readability=&quot;6.5&quot;&gt;
&lt;div class=&quot;chart-js&quot; readability=&quot;8&quot;&gt;
&lt;h3 class=&quot;chart__title&quot;&gt;Ramping Up&lt;/h3&gt;
&lt;p class=&quot;chart__subtitle&quot;&gt;Top-10 European electric bus fleets, 2017&lt;/p&gt;



&lt;/div&gt;
&lt;noscript&gt;
&lt;p&gt;&lt;img src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i29f0TFu5aHM/v1/-1x-1.png&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Across the U.K. there were 344 electric and plug-in hybrid buses in 2017, and BYD hopes to be picked to supply more. It has partnered with a Scottish bus-maker to provide the batteries for 11 new electric buses that hit the city’s roads in March.&lt;/p&gt;
&lt;p&gt;Falkirk-based manufacturer &lt;a href=&quot;https://www.bloomberg.com/quote/395753Z:LN&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot;&gt;Alexander Dennis Ltd.&lt;/a&gt; began making electric buses in 2016 and has quickly become the European market leader with more than 170 vehicles operating in the U.K. alone.&lt;/p&gt;
&lt;p&gt;More work is on the horizon, with London’s transport authority planning a tender to electrify its iconic double-decker buses, Ho said.&lt;/p&gt;
&lt;p&gt;“The tech is ready,” Ho said. “We are ready, we have our plants in China, and Alexander Dennis in Scotland is geared up for TfL. Once we’re given the word, we are ready to go.”&lt;/p&gt;
&lt;p&gt;(&lt;span itemprop=&quot;description&quot;&gt;Corrects fifth paragraph to clarify total attributable to buses. &lt;/span&gt;)&lt;/p&gt;
</description>
<pubDate>Tue, 24 Apr 2018 23:22:50 +0000</pubDate>
<dc:creator>jseliger</dc:creator>
<og:description>Electric buses were seen as a joke at an industry conference in Belgium seven years ago when the Chinese manufacturer BYD Co. showed an early model.</og:description>
<og:image>https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i_md5.J22Uc4/v1/1200x800.jpg</og:image>
<og:title>Electric Buses Are Hurting the Oil Industry</og:title>
<og:type>article</og:type>
<og:url>https://www.bloomberg.com/news/articles/2018-04-23/electric-buses-are-hurting-the-oil-industry</og:url>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.bloomberg.com/news/articles/2018-04-23/electric-buses-are-hurting-the-oil-industry</dc:identifier>
</item>
<item>
<title>TSMC Kicks Off Volume Production of 7nm Chips</title>
<link>https://www.anandtech.com/show/12677/tsmc-kicks-off-volume-production-of-7nm-chips</link>
<guid isPermaLink="true" >https://www.anandtech.com/show/12677/tsmc-kicks-off-volume-production-of-7nm-chips</guid>
<description>&lt;p&gt;TSMC last week announced that it had started high volume production (HVM) of chips using their first-gen 7 nm (CLN7FF) process technology. The contract maker of semiconductors says it has over a dozen of customers with tens of designs eager to use the technology to make their integrated circuits.&lt;/p&gt;
&lt;p&gt;The 7 nm node is a big deal for the foundry industry in general and TSMC in particular. When compared to the CLN16FF+ technology (TSMC’s most widely used FinFET process technology) the CLN7FF will enable chip designers to shrink their die sizes by 70% (at the same transistor count), drop power consumption by 60%, or increase frequency by 30% (at the same complexity). So far, TSMC has taped out 18 customer products using the CLN7FF technology, more than 50 CLN7FF products will be taped out by the end of 2018.&lt;/p&gt;
&lt;p&gt;Unlike TSMC’s CLN10FF, which is used by a limited number of customers for a limited number of mobile SoCs, the CLN7FF is expected to be used to build CPUs, GPUs, FPGAs, neural network processors, cryptocurrency mining accelerators, mobile SoCs and so on. This is important because demand for smartphones is slowing down and TSMC needs other customers to offset lower orders for mobile SoCs.&lt;/p&gt;
&lt;p&gt;“So far, we have already favored out more than 18 customer products with good yield [and] performance,” said C. C. Wei, a Co-CEO and President of TSMC, during a conference call with financial analysts. “More than 50 products tape-outs has been planned by end of this year from applications across mobile, server CPU, network processor, gaming, GPU, PGA, cryptocurrency, automotive and AI. Our 7nm is already in volume production.”&lt;/p&gt;
&lt;p&gt;TSMC’s CLN7FF process technology will rely on deep ultraviolet (DUV) lithography with argon fluoride (ArF) excimer lasers operating on a 193 nm wavelength. As a result, the world’s largest contract maker of semiconductors will be able to use existing manufacturing tools to make 7 nm chips. Meanwhile, to keep using DUV lithography the company and its customers have to use multipatterning (triple and quadruple patterning), which increases design and production costs as well as product cycles.&lt;/p&gt;
&lt;table align=&quot;center&quot; border=&quot;0&quot; cellpadding=&quot;0&quot; cellspacing=&quot;1&quot; width=&quot;680&quot;&gt;&lt;tbody readability=&quot;2&quot;&gt;&lt;tr class=&quot;tgrey&quot; readability=&quot;4&quot;&gt;&lt;td align=&quot;center&quot; colspan=&quot;8&quot;&gt;Advertised PPA Improvements of New Process Technologies&lt;br/&gt;&lt;small&gt;Data announced by companies during conference calls, press briefings and in press releases&lt;/small&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;tlblue&quot;&gt;&lt;td rowspan=&quot;2&quot; width=&quot;186&quot;&gt; &lt;/td&gt;
&lt;td align=&quot;center&quot; colspan=&quot;5&quot; rowspan=&quot;1&quot; valign=&quot;middle&quot; width=&quot;137&quot;&gt;TSMC&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;tlblue&quot;&gt;&lt;td align=&quot;center&quot; valign=&quot;middle&quot; width=&quot;136&quot;&gt;16FF+&lt;br/&gt;vs&lt;br/&gt;20SOC&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot; width=&quot;136&quot;&gt;10FF&lt;br/&gt;vs&lt;br/&gt;16FF+&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot; width=&quot;136&quot;&gt;7FF&lt;br/&gt;vs&lt;br/&gt;16FF+&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot; width=&quot;136&quot;&gt;7FF&lt;br/&gt;vs&lt;br/&gt;10FF&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot; width=&quot;136&quot;&gt;7FF+&lt;br/&gt;vs&lt;br/&gt;7FF&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tlgrey&quot;&gt;Power&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;60%&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;40%&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;60%&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;&amp;lt;40%&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;10%&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tlgrey&quot;&gt;Performance&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;40%&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;20%&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;30%&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;?&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;higher&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tlgrey&quot;&gt;Area Reduction&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;none&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;&amp;gt;50%&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;70%&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;&amp;gt;37%&lt;/td&gt;
&lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;~17%&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Next year TSMC intends to introduce its first manufacturing tech that will use extreme ultraviolet lithography (EUVL) for select layers. The CLN7FF+ will be the company’s second-generation 7 nm fabrication process because of design rules compatibility and because it will keep using DUV tools that TSMC uses today for its CLN7FF production. From a general PPA (power, performance, area) improvement point of view, TSMC expects its CLN7FF+ to offer a 20% higher transistor density and a 10% lower power consumption at the same complexity and frequency when compared to the CLN7FF. Furthermore, TSMC’s EUV-based 7 nm technology could also feature higher performance and a tighter distribution of currents, but the company’s execs do not quantitate the improvements just now.&lt;/p&gt;
&lt;p&gt;“Our N7+ silicon result today are very encouraging,” said Mr. Wei. “Not only we have demonstrated equivalent or better performance [and] yield on both 256 Mb SRAM and on product like test vehicle when compared to [the] N7 baseline, we have also demonstrated a tighter distribution of electrical parameters in the areas, where EUV is supplied.”&lt;/p&gt;
&lt;p&gt;TSMC is on track to start HVM using its 7 nm EUV process technology in mid-2019. Going forward, the company will increase usage of ASML’s Twinscan NXE step and scan systems when it starts to process wafers using its CLN5 (5 nm) process technology in 2020. According to the co-CEO of TSMC, the EUV results have been encouraging so far: the company’s 256 Mb SRAM test chip is already made with a “consistent double-digit yield”, which is rather good for a technology that is two years away from HVM. The high-ranking executive of TSMC also noted that the EUV infrastructure in general has made a good progress in the recent quarters. In particular, the company observed lower pellicle defects, higher mask yields, and improved photoresists. &lt;/p&gt;
&lt;p&gt;Related Reading:&lt;/p&gt;
</description>
<pubDate>Tue, 24 Apr 2018 21:53:13 +0000</pubDate>
<dc:creator>dbcooper</dc:creator>
<og:title>TSMC Kicks Off Volume Production of 7nm Chips</og:title>
<og:type>article</og:type>
<og:url>https://www.anandtech.com/show/12677/tsmc-kicks-off-volume-production-of-7nm-chips</og:url>
<og:image>https://images.anandtech.com/doci/12677/semiconductor_wafer_678_678x452.jpg</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.anandtech.com/show/12677/tsmc-kicks-off-volume-production-of-7nm-chips</dc:identifier>
</item>
<item>
<title>Why I&amp;#039;ve lost faith in p values</title>
<link>https://lucklab.ucdavis.edu/blog/2018/4/19/why-i-lost-faith-in-p-values</link>
<guid isPermaLink="true" >https://lucklab.ucdavis.edu/blog/2018/4/19/why-i-lost-faith-in-p-values</guid>
<description>&lt;div class=&quot;sqs-layout sqs-grid-12 columns-12&quot; data-layout-label=&quot;Post Body&quot; data-type=&quot;item&quot; data-updated-on=&quot;1524152288970&quot; id=&quot;item-5ad8b5c5aa4a993dbd419bef&quot;&gt;
&lt;div class=&quot;row sqs-row&quot;&gt;
&lt;div class=&quot;col sqs-col-12 span-12&quot;&gt;
&lt;div class=&quot;sqs-block html-block sqs-block-html&quot; data-block-type=&quot;2&quot; id=&quot;block-29b6f841be031dddfc19&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;p&gt;There has been a lot written over the past decade (and even longer) about problems associated with null hypothesis statistical testing (NHST) and p values.  Personally, I have found most of these arguments unconvincing. However, one of the problems with p values has been gnawing at me for the past couple years, and it has finally gotten to the point that I'm thinking about abandoning p values.  Note: this has nothing to do with p-hacking (which is a huge but separate issue).&lt;/p&gt;
&lt;p&gt;Here's the problem in a nutshell: If you run 1000 experiments over the course of your career, and you get a significant effect (p &amp;lt; .05) in 95 of those experiments, you might expect that 5% of these 95 significant effects would be false positives.  However, as an example shown later in this blog will show, &lt;strong&gt;the actual false positive rate may be 47%&lt;/strong&gt;, even if you're not doing anything wrong (p-hacking, etc.).  In other words, nearly half of your significant effects may be false positives, leading you to draw completely bogus conclusions that you are able to publish.  On the other hand, your false positive rate might instead be 3%.  Or 20%.  And my false positive rate might be very different from your false positive rate, even though we are both using p &amp;lt; .05 as our criterion for significance (even if neither of us is engaged in p-hacking, etc.). In other words,&lt;strong&gt; p values do not actually tell you anything meaningful about the false positive rate&lt;/strong&gt;.  &lt;/p&gt;
&lt;p&gt;But isn't this exactly what p values are supposed to tell us?  Don't they tell us the false positive rate?  Not if you define &quot;false positive rate&quot; in a way that is actually useful. Here's why:&lt;/p&gt;
&lt;p&gt;The false positive rate (Type I error rate) as defined by NHST is the probability that you will falsely reject the null hypothesis when the null hypothesis is true.  In other words, if you reject the null hypothesis when p &amp;lt; .05, this guarantees that you will get a significant (but bogus) effect in only 5% of experiments in which the null hypothesis is true.  However, this is a statement about what happens when the null hypothesis is actually true. In real research, we don't know whether the null hypothesis is actually true.  If we knew that, we wouldn't need any statistics!  In real research, we have a p value, and we want to know whether we should accept or reject the null hypothesis.  The probability of a false positive in that situation is not the same as the probability of a false positive when the null hypothesis is true.  It can be way higher.&lt;/p&gt;
&lt;p&gt;For example, imagine that I am a journal editor, and I accept papers when the studies are well designed, well executed, and statistically significant (p &amp;lt; .05 without any p-hacking).  I would like to believe that no more than 5% of these effects are actually Type I errors (false positives).  In other words: I want to know the probability that the null is true given that an observed effect is significant. We can call this probability &quot;p(null | significant effect)&quot;.  However, what NHST actually tells me is the probability that I will get a significant effect if the null is true. We can call this probability &quot;p(significant effect | null)&quot;. These two probabilities seem pretty similar, because they have the exactly the same terms (but in opposite orders). Despite the superficial similarity, in practice they can be vastly different.&lt;/p&gt;
&lt;p&gt;The rest of this blog provides concrete examples of how these two probabilities can be very different and how the probability of a false positive can be much higher than 5%.  These examples involve a little bit of math (just multiplication and division — no algebra and certainly no calculus). But you can't avoid a little bit of math if you want to understand what p values can and cannot tell you.  If you've never gone through one of these examples before, it's well worth the small amount of effort needed.  It will change your understanding of p values.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sqs-block image-block sqs-block-image sqs-col-6 span-6 float float-left&quot; data-block-type=&quot;5&quot; id=&quot;block-yui_3_17_2_1_1524192347694_4171&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;div class=&quot;image-block-outer-wrapper layout-caption-hidden design-layout-inline&quot;&gt;
&lt;div class=&quot;intrinsic&quot;&gt;
&lt;div class=&quot;image-block-wrapper has-aspect-ratio&quot; data-description=&quot;&quot;&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img src=&quot;https://static1.squarespace.com/static/5ac114ac96d455c1a62e09e7/t/5ad956838a922dfbf2ebb787/1524192906405/Why+I+lost+faith+in+p+values-1.jpeg&quot; alt=&quot;Why I lost faith in p values-1.jpeg&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;img class=&quot;thumb-image&quot; alt=&quot;Why I lost faith in p values-1.jpeg&quot; data-src=&quot;https://static1.squarespace.com/static/5ac114ac96d455c1a62e09e7/t/5ad956838a922dfbf2ebb787/1524192906405/Why+I+lost+faith+in+p+values-1.jpeg&quot; data-image=&quot;https://static1.squarespace.com/static/5ac114ac96d455c1a62e09e7/t/5ad956838a922dfbf2ebb787/1524192906405/Why+I+lost+faith+in+p+values-1.jpeg&quot; data-image-dimensions=&quot;896x538&quot; data-image-focal-point=&quot;0.5,0.5&quot; data-load=&quot;false&quot; data-image-id=&quot;5ad956838a922dfbf2ebb787&quot; data-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sqs-block html-block sqs-block-html&quot; data-block-type=&quot;2&quot; id=&quot;block-yui_3_17_2_1_1524192347694_4439&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;p&gt;The first example simulates a simple situation in which—because it is a simulation—I can make assumptions that I couldn't make in actual research.  These assumptions let us see exactly what would happen under a set of simple, known conditions.  The simulation, which is summarized in Table 1, shows what I would expect to find if I ran 1000 experiments in which two things are assumed to be true: 1) the null and alternative hypotheses are equally likely to be true (i.e., the probability that there really is an effect is .5); 2) when an effect is present, there is a 50% chance that it will be statistically significant (i.e., my power to detect an effect is .5).  These two assumptions are somewhat arbitrary, but they are a reasonable approximation of a lot of studies.  &lt;/p&gt;
&lt;p&gt;Table 1 shows what I would expect to find in this situation.  The null will be true in 500 of my 1000 experiments (as a result of assumption 1).  In those 500 experiments, I would expect a significant effect 5% of the time (assuming that my alpha is .05).  This is because my Type I error rate is 5% (assuming an alpha of .05).  This Type I error rate is what I previously called p(significant effect | null), because it's the probability that I will get a significant effect when the null hypothesis is actually true.  In the other 500 experiments, the alternative hypothesis is true.  Because my power to detect an effect is .5 (as a result of assumption 2), I get a significant effect in half of these 500 experiments.  Unless you are running a lot of subjects in your experiments, this is a pretty typical level of statistical power.&lt;/p&gt;
&lt;p&gt;However, the Type I error rate of 5% does not help me determine the likelihood that I am falsely rejecting the null hypothesis when I get a significant effect, p(null | significant effect). This probability is shown in the yellow box.  In other words, in real research, I don't actually know when the null is actually true or false; all I know is whether the p value is &amp;lt; .05.  This example shows that—if the null is true in half of my experiments and my power is .05—I would expect to get 275 significant effects (i.e., 275 experiments in which p &amp;lt; .05), and I would expect that the null is actually true in 25 of these 275 experiments.  In other words, the probability that one of my significant effects is actually bogus (a false positive) is 9%, not 5%.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sqs-block image-block sqs-block-image sqs-col-6 span-6 float float-right&quot; data-block-type=&quot;5&quot; id=&quot;block-yui_3_17_2_1_1524192347694_24747&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;div class=&quot;image-block-outer-wrapper layout-caption-hidden design-layout-inline&quot;&gt;
&lt;div class=&quot;intrinsic&quot;&gt;
&lt;div class=&quot;image-block-wrapper has-aspect-ratio&quot; data-description=&quot;&quot;&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img src=&quot;https://static1.squarespace.com/static/5ac114ac96d455c1a62e09e7/t/5ad958472b6a28d5b2c5dab1/1524193358951/Why+I+lost+faith+in+p+values-2.jpeg&quot; alt=&quot;Why I lost faith in p values-2.jpeg&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;img class=&quot;thumb-image&quot; alt=&quot;Why I lost faith in p values-2.jpeg&quot; data-src=&quot;https://static1.squarespace.com/static/5ac114ac96d455c1a62e09e7/t/5ad958472b6a28d5b2c5dab1/1524193358951/Why+I+lost+faith+in+p+values-2.jpeg&quot; data-image=&quot;https://static1.squarespace.com/static/5ac114ac96d455c1a62e09e7/t/5ad958472b6a28d5b2c5dab1/1524193358951/Why+I+lost+faith+in+p+values-2.jpeg&quot; data-image-dimensions=&quot;897x545&quot; data-image-focal-point=&quot;0.5,0.5&quot; data-load=&quot;false&quot; data-image-id=&quot;5ad958472b6a28d5b2c5dab1&quot; data-type=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sqs-block html-block sqs-block-html&quot; data-block-type=&quot;2&quot; id=&quot;block-yui_3_17_2_1_1524192347694_26216&quot;&gt;
&lt;div class=&quot;sqs-block-content&quot;&gt;
&lt;p&gt;This might not seem so bad.  I'm still drawing the right conclusion over 90% of the time when I get a significant effect (assuming that I've done everything appropriately in running and analyzing my experiments).  However, there are many cases where I am testing bold, risky hypotheses—that is, hypotheses that are unlikely to be true.  As Table 2 shows, if there is a true effect in only 10% of the experiments I run, almost half of my significant effects will be bogus (i.e., p(null | significant effect) = .47).&lt;/p&gt;
&lt;p&gt;The probability of a bogus effect is also high if I run an experiment with low power.  For example, if the null and alternative are equally likely to be true (as in Table 1), but my power to detect an effect (when an effect is present) is only .1, fully 1/3 of my significant effects would be expected to be bogus (i.e., p(null | significant effect) = .33).  &lt;/p&gt;
&lt;p&gt;Of course, the research from most labs (and the papers submitted to most journals) consist of a mixture of high-risk and low-risk studies and a mixture of different levels of statistical power.  But without knowing the probability of the null and the statistical power, I can't know what proportion of the significant results are likely to be bogus.  This is why, as I stated earlier,&lt;strong&gt; p values do not actually tell you anything meaningful about the false positive rate&lt;/strong&gt;.  In a real experiment, you do not know when the null is true and when it is false, and a p value only tells you about what will happen when the null is false.  It does not tell you the probability that a significant effect is bogus. This is why I've lost my faith in p values.  They just don't tell me anything.&lt;/p&gt;
&lt;p&gt;Yesterday, one of my postdocs showed me a small but statistically significant effect that seemed unlikely to be true.  That is, if he had asked me how likely this effect was before I saw the result, I would have said something like 20%.  And the power to detect this effect, if real, was pretty small, maybe .25.  So I told him that I didn't believe the result, even though it was significant, because p(null | significant effect) is high when an effect is unlikely and when power is low.  He agreed.&lt;/p&gt;
&lt;p&gt;Tables 1 and 2 make me wonder why anyone ever thought that we should use p values as a heuristic to avoid publishing a lot of effects that are actually bogus.  The whole point of NHST is supposedly to maintain a low probability of false positives.  However, this would require knowing p(null | significant effect), which is something we can never know in real research. We can see what would be expected by conducting simulations (like those in Tables 1 and 2).  However, we do not know the probability that the null hypothesis is true (assumption 1) and we do not know the statistical power (assumption 2), and we would need to know these to be able to calculate p(null | significant effect). So why did statisticians tell us that we should use this approach?  And why did we believe them? [Moreover, why did they not insist that we do a correction for multiple comparison when we do a factorial ANOVA that produces multiple p values? &lt;a href=&quot;https://erpinfo.org/blog/p-hacking&quot;&gt;See this post on the Virtual ERP Boot Camp blog&lt;/a&gt; and this &lt;a href=&quot;https://link.springer.com/article/10.3758/s13423-015-0913-5&quot;&gt;related paper from the Wagenmakers lab&lt;/a&gt;.]&lt;/p&gt;
&lt;p&gt;Here's an even more pressing, practical question: What should we do given that p values can't tell us what we actually need to know?  I've spent the last year exploring Bayes factors as an alternative.  I've had a really interesting interchange with advocates of Bayesian approaches about this &lt;a href=&quot;https://www.facebook.com/groups/1249986448367985/&quot;&gt;on Facebook&lt;/a&gt; (see the series of posts beginning on April 7, 2018). This interchange has convinced me that Bayes factors are potentially useful.  However, they don't really solve the problem of wanting to know the probability that an effect is actually null.  This isn't what Bayes factors are for: this would be using a Bayesian statistic to ask a frequentist question.&lt;/p&gt;
&lt;p&gt;Another solution is to make sure that statistical power is high by testing larger sample sizes. I'm definitely in favor of greater power, and the typical N in my lab is about twice as high now as it was 15 years ago. But this doesn't solve the problem, because the false positive rate is still high when you are testing bold, novel hypotheses.  The fundamental problem is that p values don't mean what we &quot;need&quot; them to mean, that is p(null | significant effect).&lt;/p&gt;
&lt;p&gt;Many researchers are now arguing that we should, more generally, move away from using statistics to make all-or-none decisions and instead use them for &quot;estimation&quot;.  In other words, instead of asking whether an effect is null or not, we should ask how big the effect is likely to be given the data.  However, at the end of the day, editors need to make an all-or-none decision about whether to publish a paper, and if we do not have an agreed-upon standard of evidence, it would be very easy for people's theoretical biases to impact decisions about whether a paper should be published (even more than they already do). But I'm starting to warm up to the idea that we should focus more on estimation than on all-or-none decisions about the null hypothesis.&lt;/p&gt;
&lt;p&gt;I've come to the conclusion that best solution, at least in my areas of research, is what I was told many times by my  graduate advisor, Steve Hillyard: &quot;Replication is the best statistic.&quot;  Some have argued that replication can also be problematic.  However, most of these potential problems are relatively minor in my areas of research.  And the major research findings in these areas have held up pretty well over time, even in registered replications.&lt;/p&gt;
&lt;p&gt;I would like to end by noting that lots of people have discussed this issue before, and there are some great papers talking about this problem.  The most famous is &lt;a href=&quot;http://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124&quot;&gt;Ionnidis (2005, PLoS Medicine)&lt;/a&gt;.  A neuroscience-specific example is &lt;a href=&quot;https://www.nature.com/articles/nrn3475&quot;&gt;Button et al. (2015, Nature Reviews Neuroscience)&lt;/a&gt; (but see &lt;a href=&quot;http://www.jneurosci.org/content/37/34/8051&quot;&gt;Nord et al., 2017, Journal of Neuroscience&lt;/a&gt; for an important re-analysis). However, I often find that these papers are bombastic and/or hard to understand.  I hope that this post helps more people understand why p values are so problematic.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Tue, 24 Apr 2018 20:17:05 +0000</pubDate>
<dc:creator>anacleto</dc:creator>
<og:title>Why I've lost faith in p values</og:title>
<og:url>https://lucklab.ucdavis.edu/blog/2018/4/19/why-i-lost-faith-in-p-values</og:url>
<og:type>article</og:type>
<og:description>There has been a lot written over the past decade (and even longer) about problems associated with null hypothesis statistical testing (NHST) and p values. &amp;nbsp;Personally, I have found most of these arguments unconvincing.&amp;nbsp;However, one of the problems with p values has been gnawing at</og:description>
<og:image>http://static1.squarespace.com/static/5ac114ac96d455c1a62e09e7/t/5ad956838a922dfbf2ebb787/1524192906405/Why+I+lost+faith+in+p+values-1.jpeg?format=1000w</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://lucklab.ucdavis.edu/blog/2018/4/19/why-i-lost-faith-in-p-values</dc:identifier>
</item>
<item>
<title>Getting Laid Off in Tech: The Myth of Upper Middle Class Security</title>
<link>https://hackernoon.com/getting-laid-off-in-tech-4e3efed8649b</link>
<guid isPermaLink="true" >https://hackernoon.com/getting-laid-off-in-tech-4e3efed8649b</guid>
<description>&lt;p name=&quot;7e63&quot; id=&quot;7e63&quot; class=&quot;graf graf--p graf--leading&quot;&gt;And then, it was over. At 1:30, they called us all into the center common area, and told us that we’d survived. The layoffs had finished, and we had been chosen for the tremendous privilege of continued employment.&lt;/p&gt;
&lt;p name=&quot;4216&quot; id=&quot;4216&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;My first thought was relief. But that relief quickly turned back into fear. How disposable I was, I thought. How bound I was to the whims of others. So much of my life and wellbeing was in the hands of people who could easily and uncaringly take it all from me. And as I stood there listening to the propaganda blitz that those above had come up with to placate us “survivors,” I couldn’t stop thinking about how completely hollow my conception of my career and life was.&lt;/p&gt;
&lt;p name=&quot;2d12&quot; id=&quot;2d12&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Because my entire life has been spent chasing after this exact goal. I spent most of high school sitting in my room reading and studying and programming, because I needed to get into Berkeley. I spent most of Berkeley doing problem sets and going to tech events and networking, and I spent every summer interning at a new place, slowly pulling myself up the &lt;a href=&quot;https://en.wikipedia.org/wiki/Cursus_honorum&quot; data-href=&quot;https://en.wikipedia.org/wiki/Cursus_honorum&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;cursus honorum&lt;/em&gt;&lt;/a&gt; of software engineering.&lt;/p&gt;
&lt;p name=&quot;a147&quot; id=&quot;a147&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Every fall semester devolved into a mad race of interviewing and studying and anxiety and inferiority. I told myself that software engineering wasn’t a zero-sum game while secretly resenting everyone that looked to have made it, getting offers and passing interviews that I was seemingly incapable of.&lt;/p&gt;
&lt;p name=&quot;0767&quot; id=&quot;0767&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Finally, at the end of the October of my senior year, I’d “made it.” I got an offer at Snap, with what seemed to me like a lot of money, and then spent the last month of senior year decompressing. I went home in December, endured four months of boredom and guilt from my family for moving away, and left for Los Angeles in April, knowing nothing and no one, buoyed only by the fact that this nervousness was the nervousness of the “successful.”&lt;/p&gt;
&lt;p name=&quot;a8f7&quot; id=&quot;a8f7&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;And after all that, there I was, listening to some executive tell me about how &lt;em class=&quot;markup--em markup--p-em&quot;&gt;hard&lt;/em&gt; it was for him to let so many &lt;em class=&quot;markup--em markup--p-em&quot;&gt;good people&lt;/em&gt; go. I shouldn’t be here, I thought. I had done everything right to inoculate myself from this. I’d joined the &lt;em class=&quot;markup--em markup--p-em&quot;&gt;right&lt;/em&gt; team, ingratiated myself with the &lt;em class=&quot;markup--em markup--p-em&quot;&gt;right&lt;/em&gt; people, chosen the &lt;em class=&quot;markup--em markup--p-em&quot;&gt;right&lt;/em&gt; projects, justified every decision in the context of our larger “strategic initiatives.” I’d been promoted from L1 to L2 in six months, and I was on track to hit L3 by the end of the year.&lt;/p&gt;
&lt;p name=&quot;1715&quot; id=&quot;1715&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;And yet, I had to stand there in fear, because to the people that made these cuts, none of this mattered. I could’ve had a bad week when performance reviews had gone through, nullifying everything I’d done, or my manager could have not adequately justified my existence to the directors above. I could’ve fallen victim to one of the many internal political struggles that so engross the string-pullers.&lt;/p&gt;
&lt;p name=&quot;dec4&quot; id=&quot;dec4&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;None of this had happened, but the point was, it could have. None of the above things are under my control, but they could’ve sealed my fate at any time over the past year, and if they did, neither my by-the-book background, my personal contributions, nor my sustained effort, would have mattered at all.&lt;/p&gt;
&lt;p name=&quot;364d&quot; id=&quot;364d&quot; class=&quot;graf graf--p graf-after--p graf--trailing&quot;&gt;I would’ve been axed and replaced, and the world would have kept on turning.&lt;/p&gt;
</description>
<pubDate>Tue, 24 Apr 2018 19:25:12 +0000</pubDate>
<dc:creator>logicx24</dc:creator>
<og:title>Getting Laid Off In Tech – Hacker Noon</og:title>
<og:url>https://hackernoon.com/getting-laid-off-in-tech-4e3efed8649b</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*UqRdskIqjQrRtWIH2vNdQg.jpeg</og:image>
<og:description>The Myth of Upper Middle-Class Security</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://hackernoon.com/getting-laid-off-in-tech-4e3efed8649b?gi=d25c7d3732f3</dc:identifier>
</item>
<item>
<title>Nerves – Craft and deploy bulletproof embedded software in Elixir</title>
<link>https://nerves-project.org</link>
<guid isPermaLink="true" >https://nerves-project.org</guid>
<description>&lt;div class=&quot;text-center&quot;&gt;

&lt;h3&gt;Craft and deploy bulletproof embedded software in &lt;a href=&quot;http://elixir-lang.org&quot;&gt;&lt;strong&gt;Elixir&lt;/strong&gt;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;hr/&gt;&lt;div class=&quot;row&quot; readability=&quot;11.5&quot;&gt;
&lt;div class=&quot;col-md-4&quot; readability=&quot;8&quot;&gt;
&lt;h3&gt;Platform&lt;/h3&gt;
&lt;p class=&quot;text-justify&quot;&gt;Pack your whole application into as little as 12MB and have it start in seconds by booting a lean cross-compiled Linux directly to the battle-hardened Erlang VM.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;col-md-4&quot; readability=&quot;11&quot;&gt;
&lt;h3&gt;Framework&lt;/h3&gt;
&lt;p class=&quot;text-justify&quot;&gt;Let Nerves take care of the network, discovery, I/O, firmware updates and more. Focus on what matters and have fun writing robust and maintainable software.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;col-md-4&quot; readability=&quot;9&quot;&gt;
&lt;h3&gt;Tooling&lt;/h3&gt;
&lt;p class=&quot;text-justify&quot;&gt;Go from &quot;mix new&quot; to running code on your device in minutes. From cross-compilation to remote device access, our tools got you covered.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;hr/&gt;&lt;div class=&quot;row&quot; readability=&quot;9.3088531187123&quot;&gt;
&lt;div class=&quot;col-md-12&quot; readability=&quot;13.718309859155&quot;&gt;
&lt;p&gt;Nerves is young, but already powers rock-solid shipping industrial products! Check us out if you are a hearty experimenter and interested in a new way of creating embedded systems.&lt;/p&gt;
&lt;p&gt;Nerves is also fully open source with the majority of code licensed under &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;Apache 2.0&lt;/a&gt;. Nerves does make use of non-Apache 2.0 code such as the Linux kernel and Buildroot. Licensing details of non-Elixir components is provided via Buildroot tooling. Licensing details for Elixir components is available through hex.pm.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3&gt;Hardware Support&lt;/h3&gt;
&lt;div class=&quot;row&quot; readability=&quot;6.1034482758621&quot;&gt;
&lt;div class=&quot;col-md-12&quot; readability=&quot;7.8472906403941&quot;&gt;
&lt;p&gt;Nerves supports many popular prototyping boards such as the Beaglebone Black and Raspberry Pi family. If a board can run embedded Linux (not uClinux), it likely can run Nerves.&lt;/p&gt;
&lt;div class=&quot;row text-center&quot;&gt;&lt;a class=&quot;btn btn-info btn-lg&quot; href=&quot;https://hexdocs.pm/nerves/targets.html&quot;&gt;See All Supported Hardware&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;We would like to thank all of the companies and individuals that have made it financially possible for Nerves to remain a completely open source project. See &lt;a href=&quot;https://nerves-project.org/sponsoring&quot;&gt;sponsoring&lt;/a&gt; for more information.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.letote.com/careers&quot; target=&quot;_blank&quot;&gt;&lt;img width=&quot;150&quot; height=&quot;150&quot; src=&quot;https://nerves-project.org/images/sponsorship/letote.png&quot;/&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.smartrent.com&quot; target=&quot;_blank&quot;&gt;&lt;img width=&quot;150&quot; height=&quot;150&quot; src=&quot;https://nerves-project.org/images/sponsorship/smartrent.png&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://nerves-project.org/sponsoring&quot;&gt;[Become a metal level sponsor]&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://opencollective.com/nerves-project/sponsor/0/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/nerves-project/sponsor/0/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/nerves-project/sponsor/1/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/nerves-project/sponsor/1/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/nerves-project/sponsor/2/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/nerves-project/sponsor/2/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/nerves-project/sponsor/3/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/nerves-project/sponsor/3/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/nerves-project/sponsor/4/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/nerves-project/sponsor/4/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/nerves-project/sponsor/5/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/nerves-project/sponsor/5/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/nerves-project/sponsor/6/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/nerves-project/sponsor/6/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/nerves-project/sponsor/7/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/nerves-project/sponsor/7/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/nerves-project/sponsor/8/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/nerves-project/sponsor/8/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/nerves-project/sponsor/9/website&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/nerves-project/sponsor/9/avatar.svg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[&lt;a href=&quot;https://opencollective.com/nerves-project#sponsor&quot;&gt;Become a sponsor&lt;/a&gt;]&lt;/p&gt;
&lt;h3 id=&quot;open-collective-backers&quot;&gt;Open Collective Backers&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://opencollective.com/nerves-project#backers&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://opencollective.com/nerves-project/backers.svg?width=890&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[&lt;a href=&quot;https://opencollective.com/nerves-project#backer&quot;&gt;Become a backer&lt;/a&gt;]&lt;/p&gt;
&lt;h2 id=&quot;nerves-badges&quot;&gt;Nerves Badges&lt;/h2&gt;

</description>
<pubDate>Tue, 24 Apr 2018 18:36:12 +0000</pubDate>
<dc:creator>punnerud</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://nerves-project.org/</dc:identifier>
</item>
<item>
<title>Blloc – minimalist smartphone</title>
<link>https://www.blloc.com/</link>
<guid isPermaLink="true" >https://www.blloc.com/</guid>
<description>[unable to retrieve full-text content]&lt;p&gt;Article URL: &lt;a href=&quot;https://www.blloc.com/&quot;&gt;https://www.blloc.com/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=16914772&quot;&gt;https://news.ycombinator.com/item?id=16914772&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Points: 206&lt;/p&gt;&lt;p&gt;# Comments: 161&lt;/p&gt;</description>
<pubDate>Tue, 24 Apr 2018 17:44:07 +0000</pubDate>
<dc:creator>ryannevius</dc:creator>
<og:title>Blloc Phone</og:title>
<og:url>https://www.blloc.com/</og:url>
<og:image>https://www.blloc.com/images/bgs/IMG_0094.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.blloc.com/</dc:identifier>
</item>
</channel>
</rss>