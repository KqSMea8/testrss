<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Heart surgeons refuse difficult operations to avoid poor mortality ratings</title>
<link>https://www.telegraph.co.uk/science/2016/06/03/one-in-three-heart-surgeons-refuse-difficult-operations-to-avoid/</link>
<guid isPermaLink="true" >https://www.telegraph.co.uk/science/2016/06/03/one-in-three-heart-surgeons-refuse-difficult-operations-to-avoid/</guid>
<description>&lt;div class=&quot;articleBodyText version-2 section&quot;&gt;
&lt;div class=&quot;article-body-text component version-2&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;p&gt;&lt;span&gt;&lt;span class=&quot;m_first-letter&quot;&gt;A&lt;/span&gt;t least one in three heart surgeons has refused to treat critically ill patients because they are worried it will affect their &lt;a href=&quot;https://www.telegraph.co.uk/news/health/news/10108023/We-cant-judge-surgeons-by-league-tables-alone.html&quot;&gt;mortality ratings&lt;/a&gt; if things go wrong.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Patients have been able to see &lt;a href=&quot;https://www.telegraph.co.uk/journalists/laura-donnelly/10153437/Patients-will-get-clearer-data-on-surgeons-death-rates-next-year.html&quot;&gt;league tables&lt;/a&gt; showing &lt;a href=&quot;https://www.telegraph.co.uk/news/health/news/9935856/Heart-surgery-patients-given-online-access-to-their-doctors-performance-data.html&quot;&gt;how well surgeons perform since 2014&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But consultant cardiac surgeon Samer Nashef warned that increased transparency had led to doctors gaming the system to &lt;a href=&quot;https://www.telegraph.co.uk/news/health/news/10151716/Surgeons-mortality-rates-are-meaningless-say-patient-groups.html&quot;&gt;avoid poor scores&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For his new book The Naked Surgeon, Dr Nashef anonymously polled heart surgeons asking them if they had ever boosted their ratings by refusing to operate on patients who they feared might die in theatre.&lt;/p&gt;
&lt;p&gt;He said it &quot;confirmed without any doubt&quot; that clinical decision-making had been adversely affected by the culture of transparency.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&quot;articleBodyImage section&quot;&gt;
&lt;div class=&quot;article-body-image component&quot; itemscope=&quot;&quot; itemtype=&quot;https://schema.org/ImageObject&quot; data-frz-ancestor=&quot;&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;div class=&quot;lazy-image article-body-image-image&quot; data-js=&quot;LazyImage&quot; data-src=&quot;/content/dam/science/2016/06/02/99652028_Mcc0070540_The_Daily_Telegraph_Consultant_cardiac_surgeon_Samer_Nashef_is_seen_on_site_trans_NvBQzQNjv4BqqVzuuqpFlyLIwiB6NTmJwfSVWeZ_vEN7c6bHu2jJnT8.jpg?imwidth=480&quot; data-srcset=&quot;/content/dam/science/2016/06/02/99652028_Mcc0070540_The_Daily_Telegraph_Consultant_cardiac_surgeon_Samer_Nashef_is_seen_on_site_trans_NvBQzQNjv4BqqVzuuqpFlyLIwiB6NTmJwfSVWeZ_vEN7c6bHu2jJnT8.jpg?imwidth=480 480w,/content/dam/science/2016/06/02/99652028_Mcc0070540_The_Daily_Telegraph_Consultant_cardiac_surgeon_Samer_Nashef_is_seen_on_site_trans_NvBQzQNjv4BqqVzuuqpFlyLIwiB6NTmJwfSVWeZ_vEN7c6bHu2jJnT8.jpg?imwidth=960 960w,/content/dam/science/2016/06/02/99652028_Mcc0070540_The_Daily_Telegraph_Consultant_cardiac_surgeon_Samer_Nashef_is_seen_on_site_trans_NvBQzQNjv4BqqVzuuqpFlyLIwiB6NTmJwfSVWeZ_vEN7c6bHu2jJnT8.jpg?imwidth=580 580w,/content/dam/science/2016/06/02/99652028_Mcc0070540_The_Daily_Telegraph_Consultant_cardiac_surgeon_Samer_Nashef_is_seen_on_site_trans_NvBQzQNjv4BqqVzuuqpFlyLIwiB6NTmJwfSVWeZ_vEN7c6bHu2jJnT8.jpg?imwidth=1160 1160w,/content/dam/science/2016/06/02/99652028_Mcc0070540_The_Daily_Telegraph_Consultant_cardiac_surgeon_Samer_Nashef_is_seen_on_site_trans_NvBQzQNjv4BqqVzuuqpFlyLIwiB6NTmJwfSVWeZ_vEN7c6bHu2jJnT8.jpg?imwidth=620 620w,/content/dam/science/2016/06/02/99652028_Mcc0070540_The_Daily_Telegraph_Consultant_cardiac_surgeon_Samer_Nashef_is_seen_on_site_trans_NvBQzQNjv4BqqVzuuqpFlyLIwiB6NTmJwfSVWeZ_vEN7c6bHu2jJnT8.jpg?imwidth=1240 1240w&quot; data-sizes=&quot;100vw,(min-width: 480px) 480px,(min-width: 730px) 580px,(min-width: 1008px) 620px&quot; data-alt=&quot;Cardiac surgeon Samer Nashef&quot;&gt;&lt;span class=&quot;article-body-image-image-container&quot;&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;responsive article-body-image-image&quot; src=&quot;https://www.telegraph.co.uk/content/dam/science/2016/06/02/99652028_Mcc0070540_The_Daily_Telegraph_Consultant_cardiac_surgeon_Samer_Nashef_is_seen_on_site_trans_NvBQzQNjv4BqqVzuuqpFlyLIwiB6NTmJwfSVWeZ_vEN7c6bHu2jJnT8.jpg?imwidth=480&quot; alt=&quot;Cardiac surgeon Samer Nashef&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/span&gt;&lt;/div&gt;
&lt;span itemprop=&quot;caption&quot; class=&quot;article-body-image-caption&quot;&gt;Cardiac surgeon Samer Nashef&lt;/span&gt; &lt;span itemprop=&quot;copyrightHolder&quot; class=&quot;article-body-image-copyright&quot;&gt;&lt;span class=&quot;article-body-image-copyright-label&quot;&gt;Credit:&lt;/span&gt; Clara Molden&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;articleBodyText section&quot;&gt;
&lt;div class=&quot;article-body-text component&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;p&gt;&lt;span class=&quot;m_first-letter m_first-letter--flagged&quot;&gt;J&lt;/span&gt;ust under one third of the 115 specialists who responded said they had recommended a different treatment path to avoid adding another death to their score. And 84 percent said they were aware of other surgeons doing the same.&lt;/p&gt;
&lt;p&gt;Speaking at the &lt;a href=&quot;https://www.telegraph.co.uk/hay-festival/&quot;&gt;Hay Festival&lt;/a&gt;, Dr Nashef said the actual figure was probably &quot;somewhere in the middle&quot;.&lt;/p&gt;
&lt;p&gt;“We need to be aware that transparency is a good thing but we need to be aware of its pitfalls,” said Mr Nashef, who helped to design the euroSCORE measurement which predicts the risk of death after a heart operation and is used to help determine ratings.&lt;/p&gt;
&lt;p&gt;“&lt;a href=&quot;https://www.telegraph.co.uk/news/health/expat-health/11334747/Private-hospitals-seek-to-be-more-transparent.html&quot;&gt;Transparency&lt;/a&gt; has added a different dimension to the way surgeons think. Beforehand the surgeons would look at a patient and think, 'I know what’s best for you’, it’s this operation. Now a surgeon looks at a patient and says, ‘I know what’s best for you but is this going to be good for my figures?' &lt;/p&gt;
&lt;p&gt;“I conducted this survey to find out how much impact this has on surgeons' decision-making and tragically it is quite a big influence.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;htmlEmbed section&quot;&gt;
&lt;div class=&quot;html-embed component&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;div class=&quot;quote section&quot;&gt;
&lt;div class=&quot;quote component&quot; data-tmg-particle=&quot;tmg-pull-quote&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;&lt;q class=&quot;quote__content&quot;&gt;I conducted this survey to find out how much impact this has on surgeons' decision-making and tragically it is quite a big influence&lt;/q&gt;&lt;span class=&quot;quote__author&quot;&gt;Samer Nashef&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;articleBodyText section&quot;&gt;
&lt;div class=&quot;article-body-text component&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;p&gt;“About 30 percent of them said they had turned patients down for surgery even when they knew full well that surgery was in their best interest.&lt;/p&gt;
&lt;p&gt;“So [for] the high risk patients, and sometimes those that could benefit most for an operation, there is evidence that suggests they are not being offered surgery because of concerns about figures and outcomes.”&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;m_first-letter&quot;&gt;S&lt;/span&gt;ince 2014 the NHS has published the individual mortality rates for consultant surgeons on the publicly available website &lt;a href=&quot;https://www.nhs.uk/Service-Search/performance/search&quot;&gt;‘MyNHS’&lt;/a&gt;, which was supposed to represent a milestone in transparency. The UK was the first in the world to ever release such data.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;articleBodyText section&quot;&gt;
&lt;div class=&quot;article-body-text component&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;p&gt;&lt;span class=&quot;m_first-letter m_first-letter--flagged&quot;&gt;T&lt;/span&gt;he scheme was designed by Bruce Keogh, the NHS medical director for England, who hoped it would drive up standards and make surgeons more accountable and stop surgeons carrying out operations without the clinical expertise necessary.  &lt;/p&gt;
&lt;p&gt;However, at the time experts argued that judging surgeons by mortality rates was crude and misleading because outcomes were often based on how ill or old the patient was in the first place.&lt;/p&gt;
&lt;p&gt;The better surgeons were also often asked to do the most hopeless cases, meaning they were likely to be penalised under the new system.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;articleBodyImage section&quot;&gt;
&lt;div class=&quot;article-body-image component&quot; itemscope=&quot;&quot; itemtype=&quot;https://schema.org/ImageObject&quot; data-frz-ancestor=&quot;&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;div class=&quot;lazy-image article-body-image-image&quot; data-js=&quot;LazyImage&quot; data-src=&quot;/content/dam/science/2016/04/07/nhs_2893422b_trans_NvBQzQNjv4BqpJliwavx4coWFCaEkEsb3kvxIt-lGGWCWqwLa_RXJU8.jpg?imwidth=480&quot; data-srcset=&quot;/content/dam/science/2016/04/07/nhs_2893422b_trans_NvBQzQNjv4BqpJliwavx4coWFCaEkEsb3kvxIt-lGGWCWqwLa_RXJU8.jpg?imwidth=480 480w,/content/dam/science/2016/04/07/nhs_2893422b_trans_NvBQzQNjv4BqpJliwavx4coWFCaEkEsb3kvxIt-lGGWCWqwLa_RXJU8.jpg?imwidth=960 960w,/content/dam/science/2016/04/07/nhs_2893422b_trans_NvBQzQNjv4BqpJliwavx4coWFCaEkEsb3kvxIt-lGGWCWqwLa_RXJU8.jpg?imwidth=580 580w,/content/dam/science/2016/04/07/nhs_2893422b_trans_NvBQzQNjv4BqpJliwavx4coWFCaEkEsb3kvxIt-lGGWCWqwLa_RXJU8.jpg?imwidth=1160 1160w,/content/dam/science/2016/04/07/nhs_2893422b_trans_NvBQzQNjv4BqpJliwavx4coWFCaEkEsb3kvxIt-lGGWCWqwLa_RXJU8.jpg?imwidth=620 620w,/content/dam/science/2016/04/07/nhs_2893422b_trans_NvBQzQNjv4BqpJliwavx4coWFCaEkEsb3kvxIt-lGGWCWqwLa_RXJU8.jpg?imwidth=1240 1240w&quot; data-sizes=&quot;100vw,(min-width: 480px) 480px,(min-width: 730px) 580px,(min-width: 1008px) 620px&quot; data-alt=&quot;Surgeons have had to publish mortality rates since 2014&quot;&gt;&lt;span class=&quot;article-body-image-image-container&quot;&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;responsive article-body-image-image&quot; src=&quot;https://www.telegraph.co.uk/content/dam/science/2016/04/07/nhs_2893422b_trans_NvBQzQNjv4BqpJliwavx4coWFCaEkEsb3kvxIt-lGGWCWqwLa_RXJU8.jpg?imwidth=480&quot; alt=&quot;Surgeons have had to publish mortality rates since 2014&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/span&gt;&lt;/div&gt;
&lt;span itemprop=&quot;caption&quot; class=&quot;article-body-image-caption&quot;&gt;Surgeons have had to publish mortality rates since 2014&lt;/span&gt; &lt;span itemprop=&quot;copyrightHolder&quot; class=&quot;article-body-image-copyright&quot;&gt;&lt;span class=&quot;article-body-image-copyright-label&quot;&gt;Credit:&lt;/span&gt; Alamy &lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;articleBodyText section&quot;&gt;
&lt;div class=&quot;article-body-text component&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;p&gt;&lt;span class=&quot;m_first-letter m_first-letter--flagged&quot;&gt;T&lt;/span&gt;he Society for Cardiothoracic Surgery even wrote to Simon Stevens, the NHS England Chief Executive, calling for the policy to be abandoned, saying it was having a damaging effect on surgeons, destroying confidence and garnering unfair media attention.&lt;/p&gt;
&lt;p&gt;Dr Nashef, of Papworth Hospital Cambridge, where the first heart transplant was carried out, said it was too late to put the &quot;genie back in the bottle&quot;.&lt;/p&gt;
&lt;p&gt;“Sometimes the price of transparency is unacceptable,” he wrote in his new book. “Our poor old patient, if she is refused an operation, will die and become a statistic, but now a statistic that appears in the league table of heart surgery and nobody will ever know.”&lt;/p&gt;
&lt;p&gt;He said he came up with the concept of a Star Chamber at Papworth to offer operations to those who might be turned down by surgeons worried about their scores.&lt;/p&gt;
&lt;p&gt;Elaborating on his comments at Hay, he said: “This is something we need to be aware of and we need to try to work against it, because transparency is here to stay, we’ve made it available and we can’t take it back.”&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;


</description>
<pubDate>Sat, 21 Apr 2018 17:05:44 +0000</pubDate>
<dc:creator>prostoalex</dc:creator>
<og:title>One in three heart surgeons refuse difficult operations to avoid poor mortality ratings, survey shows </og:title>
<og:description>At least one in three heart surgeons has refused to treat critically ill patients because they are worried it will affect their mortality ratings if things go wrong.</og:description>
<og:type>article</og:type>
<og:url>https://www.telegraph.co.uk/science/2016/06/03/one-in-three-heart-surgeons-refuse-difficult-operations-to-avoid/</og:url>
<og:image>https://www.telegraph.co.uk/content/dam/science/2016/04/21/surgery-xlarge_trans_NvBQzQNjv4BqpJliwavx4coWFCaEkEsb3kvxIt-lGGWCWqwLa_RXJU8.jpg</og:image>
<dc:language>en-GB</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.telegraph.co.uk/science/2016/06/03/one-in-three-heart-surgeons-refuse-difficult-operations-to-avoid/</dc:identifier>
</item>
<item>
<title>VS Code can do that?</title>
<link>https://vscodecandothat.com/</link>
<guid isPermaLink="true" >https://vscodecandothat.com/</guid>
<description>[unable to retrieve full-text content]&lt;p&gt;Article URL: &lt;a href=&quot;https://vscodecandothat.com/&quot;&gt;https://vscodecandothat.com/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=16891784&quot;&gt;https://news.ycombinator.com/item?id=16891784&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Points: 400&lt;/p&gt;&lt;p&gt;# Comments: 241&lt;/p&gt;</description>
<pubDate>Sat, 21 Apr 2018 15:34:54 +0000</pubDate>
<dc:creator>kawera</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://vscodecandothat.com/</dc:identifier>
</item>
<item>
<title>A journalism student who found out she won a Pulitzer in class</title>
<link>https://www.cjr.org/the_profile/mariel-padilla-pulizter-cincinnnati.php</link>
<guid isPermaLink="true" >https://www.cjr.org/the_profile/mariel-padilla-pulizter-cincinnnati.php</guid>
<description>&lt;span class=&quot;caption-top hidden-print&quot;&gt;Mariel Padilla. Photo by Catherine Mazanek.&lt;/span&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;On Monday afternoon,&lt;/strong&gt; Mariel Padilla, a master’s student at Columbia Journalism School, sat around a table with classmates, listening to Professor Giannina&lt;/span&gt; &lt;span&gt;Segnini lead a discussion about email encryption for reporting across borders. A couple floors below, journalism bigwigs and other members of the press crowded into the World Room, an ornate, high-ceilinged chamber reserved for the event, eager to watch Pulitzer Prize Administrator Dana Canedy &lt;a href=&quot;https://www.cjr.org/business_of_news/pulitzer_prizes_2018.php&quot;&gt;announce this year’s winners&lt;/a&gt;. For Padilla, who moved to New York last year from the small town of Oxford, Ohio, just being in geographic proximity to the announcement was a thrill.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;“I knew I was going to be two floors above where it was happening,” she says, reflecting on the moment, “and I remember thinking,&lt;/span&gt; &lt;em&gt;&lt;span&gt;Oh, that’s cool, I can tell people that I was in the same building [where] the Pulitzers are being announced!&lt;/span&gt;&lt;/em&gt;&lt;span&gt;”&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ICYMI: &lt;a href=&quot;https://www.cjr.org/special_report/covering-protests-threats-press-freedom-tracker.php&quot;&gt;“She identified herself as a reporter. He then walked behind her and punched her in the side of the head”&lt;/a&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Little did she know she was about to become a Pulitzer winner herself.&lt;br/&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;In class, Padilla was typing notes on her laptop when a text bubble popped onto her screen. It was from a friend, Adiel Kaplan, sitting across the room.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;alignnone size-full wp-image-73670&quot; src=&quot;https://cdn.cjr.org/wp-content/uploads/2018/04/Screen-Shot-2018-04-20-at-12.28.47-PM.jpg&quot; alt=&quot;&quot; width=&quot;428&quot; height=&quot;206&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;The summer before starting her program at Columbia, Padilla interned at&lt;/span&gt; &lt;em&gt;&lt;span&gt;The Cincinnati Enquirer&lt;/span&gt;&lt;/em&gt;&lt;span&gt;. She got her start in journalism the year prior in a reporting class at Miami University Ohio, publishing hyperlocal stories on&lt;/span&gt; &lt;a href=&quot;https://patch.com/ohio/miamiuniversity-oxford/homelessness-increasing-oxford&quot;&gt;&lt;span&gt;the drug crisis&lt;/span&gt;&lt;/a&gt; &lt;span&gt;and&lt;/span&gt; &lt;a href=&quot;https://patch.com/ohio/miamiuniversity-oxford/food-program-expands-provide-talawanda-elementary-students&quot;&gt;&lt;span&gt;its impact on children&lt;/span&gt;&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;
&lt;div id=&quot;mc_embed_signup&quot; class=&quot;hidden-print&quot;&gt;
&lt;center&gt;&lt;span class=&quot;form-title-embed&quot;&gt;Sign up for &lt;span class=&quot;cjr-bold&quot;&gt;CJR&lt;/span&gt;'s &lt;nobr&gt;daily email&lt;/nobr&gt;&lt;/span&gt;

&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;&lt;span&gt;But this was no ordinary summer at the&lt;/span&gt; &lt;em&gt;&lt;span&gt;Enquirer&lt;/span&gt;&lt;/em&gt;&lt;span&gt;. As the 60-person newsroom reported an ambitious story chronicling a week in Cincinnati’s heroin crisis, Padilla, who had decided to pursue a career in journalism just two years prior, found herself at the center of what would become Pulitzer Prize–winning local reporting.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ICYMI: &lt;a href=&quot;https://www.cjr.org/the_lower_case/bad-headlines-april-13.php&quot;&gt;A pretty bad typo in the&lt;em&gt; LA Times&lt;/em&gt;&lt;/a&gt;&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;A breaking-news intern with a penchant for crime reporting, Padilla, 23, was tasked with visiting the county jail each morning during the project’s week of coverage to sort through hundreds of paper arrest slips and flag opioid mentions. From there, she took it upon herself to create a database for&lt;/span&gt; &lt;em&gt;&lt;span&gt;Enquirer&lt;/span&gt;&lt;/em&gt; &lt;span&gt;reporters, documenting the time, location, and nature of every opioid-related arrest that occured over those days.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;The&lt;/span&gt; &lt;em&gt;&lt;span&gt;Enquirer&lt;/span&gt;&lt;/em&gt; &lt;span&gt;had reporters booked around the clock. “It was a full-newsroom effort, that was the insanity,” Padilla remembers. “There were two or three people just in charge of managing the schedule. There would be people scheduled from, like, 4am to 10am. It was very intense.”&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;At the end of the project, despite dogged 24/7 reporting, there were gaps in coverage, especially in the late-night hours when the city slowed. Padilla’s database became a go-to for filling in those gaps, allowing the narrative to stretch uninterrupted, and revealing the rhythmic, ticking heartbreaks of an epidemic that does not sleep.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Published in September 2017, the story, “&lt;/span&gt;&lt;a href=&quot;https://www.cincinnati.com/pages/interactives/seven-days-of-heroin-epidemic-cincinnati/&quot;&gt;&lt;span&gt;Seven Days of Heroin&lt;/span&gt;&lt;/a&gt;&lt;span&gt;,” prompted a nationwide conversation about the opioid crisis, reflected in newsrooms around the country.  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Sitting in class, more than 500 miles from the&lt;/span&gt; &lt;em&gt;&lt;span&gt;Enquirer&lt;/span&gt;&lt;/em&gt; &lt;span&gt;newsroom and with nearly a year having passed since her internship, the story felt disconnected from Padilla’s new life in New York. “I haven’t really been keeping up with nominations, so I didn’t even know it was nominated,“ Padilla remembers, “&lt;/span&gt;&lt;a href=&quot;https://www.cjr.org/united_states_project/enquirer-heroin-epidemic.php&quot;&gt;&lt;span&gt;CJR did a piece&lt;/span&gt;&lt;/a&gt; &lt;span&gt;right after the story came out, so I knew then that people were saying it could win a Pulitzer, but people say that about lots of things.”&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Even when she found out the&lt;/span&gt; &lt;em&gt;&lt;span&gt;Enquirer&lt;/span&gt;&lt;/em&gt; &lt;span&gt;had won, she wasn’t sure she would be included in the list of prizewinners. But another text from Kaplan popped up:&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;alignnone size-full wp-image-73671&quot; src=&quot;https://cdn.cjr.org/wp-content/uploads/2018/04/Screen-Shot-2018-04-20-at-12.29.25-PM.jpg&quot; alt=&quot;&quot; width=&quot;429&quot; height=&quot;238&quot;/&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;And then a text from Padilla’s editor last summer, Bob Strickley, confirmed:&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img class=&quot;alignnone size-full wp-image-73667&quot; src=&quot;https://cdn.cjr.org/wp-content/uploads/2018/04/31045334_10204719382499886_4697610996712210432_n-1.jpg&quot; alt=&quot;&quot; width=&quot;750&quot; height=&quot;222&quot;/&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;span&gt;“I was in shock,” Padilla says. “My eyes just went so wide and I’m pretty sure my mouth was open. Obviously, I couldn’t make noise or anything because my professor was still talking.”&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;The classroom stayed quiet, but the news spread quickly around the table. “No one is supposed to be on their phones, but we have our laptops, so other students in class started messaging each other and finding out,” she says. It wasn’t until the class break that a classmate stood up and announced it.&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Despite the exchange of glances around the room, and what classmates have described as a “hilarious” expression on Padilla’s face, Professor Segnini, who was absent during the break, didn’t notice. It wasn’t after class that she heard the news and sent out a congratulatory email.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;“We kept talking, class was regular, I didn’t notice anything was happening,” Segnini says, reflecting on Monday’s class. “Why on earth did no one just say it loudly? If it was me, I would have totally disturbed the class. I would have caused a big mess! It’s a big deal!”&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Winning a Pulitzer while in journalism school is like winning a Grammy while you’re still in the high school choir. Padilla’s classmates joked, she says, about whether she even needs to be in journalism school, “but [that was] definitely never a thought in my mind,” Padilla says. “I mean, I technically am a Pulitzer winner, but I am just so humbled by the fact that they put the interns on the byline. I feel like I still need to learn all the things that I’m learning, which I think is why my general reaction was just straight shock. I still don’t believe it.”&lt;/span&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Padilla’s life-changing experience as a young reporter at the&lt;/span&gt; &lt;em&gt;&lt;span&gt;Enquirer&lt;/span&gt;&lt;/em&gt; &lt;span&gt;is just one of many merits of local newsrooms, which have historically served as an entry point for aspiring journalists. “My experiences at the&lt;/span&gt; &lt;em&gt;&lt;span&gt;Enquirer&lt;/span&gt;&lt;/em&gt; &lt;span&gt;[were invaluable and] prepared me…to be here,” she says.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;That preparation certainly paid off. “She has an ability to integrate journalism and technology—that doesn’t happen very often,” says Professor Segnini, who directs the data journalism program at Columbia. “She knows exactly how to find a story out of data and ask the right questions; that’s one of the most important skills.”&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Following the big news on on Monday, Kaplan insisted they celebrate, but with graduation less than a month away and the professional hereafter on everyone’s mind, the invitation came with a friendly reminder:&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-73672&quot; src=&quot;https://cdn.cjr.org/wp-content/uploads/2018/04/Screen-Shot-2018-04-20-at-12.30.02-PM.jpg&quot; alt=&quot;&quot; width=&quot;430&quot; height=&quot;179&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ICYMI: &lt;a href=&quot;https://www.cjr.org/q_and_a/hannity-cohen.php&quot;&gt;Lawyer behind Hannity revelation at Cohen hearing speaks&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;
&lt;div id=&quot;post-survey-box&quot; class=&quot;hidden-print&quot;&gt;&lt;em&gt;Has America ever needed a media watchdog more than now? Help us by &lt;a href=&quot;https://ssl.palmcoastd.com/18801/apps/MEMBER1?ikey=5**M02&quot; target=&quot;_blank&quot;&gt;joining CJR today&lt;/a&gt;.&lt;/em&gt;&lt;/div&gt;
&lt;/center&gt;
&lt;small class=&quot;bio-overline&quot;&gt;&lt;strong&gt;Kelsey Ables is an editorial assistant. Follow her on Twitter &lt;a href=&quot;https://twitter.com/ables_kelsey&quot;&gt;@ables_kelsey&lt;/a&gt;.&lt;/strong&gt;&lt;/small&gt;</description>
<pubDate>Sat, 21 Apr 2018 13:24:12 +0000</pubDate>
<dc:creator>mrleiter</dc:creator>
<og:title>Meet the journalism student who found out she won a Pulitzer in class</og:title>
<og:type>article</og:type>
<og:url>https://www.cjr.org/the_profile/mariel-padilla-pulizter-cincinnnati.php</og:url>
<og:image>https://cdn.cjr.org/wp-content/uploads/2018/04/Screen-Shot-2018-04-20-at-12.33.16-PM.jpg</og:image>
<og:description>&lt;p&gt;On Monday afternoon, Mariel Padilla, a master’s student at Columbia Journalism School, sat around a table with classmates, listening to Professor Giannina Segnini lead a discussion about email encryption for reporting across borders. A couple floors below, journalism bigwigs and other members of the press crowded into the World Room, an ornate, high-ceilinged chamber reserved […]&lt;/p&gt;</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.cjr.org/the_profile/mariel-padilla-pulizter-cincinnnati.php</dc:identifier>
</item>
<item>
<title>Mapping the internet with Hilbert curves</title>
<link>https://blog.benjojo.co.uk/post/scan-ping-the-internet-hilbert-curve</link>
<guid isPermaLink="true" >https://blog.benjojo.co.uk/post/scan-ping-the-internet-hilbert-curve</guid>
<description>&lt;p&gt;The internet is big. &lt;a href=&quot;http://www.quotationspage.com/quote/33085.html&quot;&gt;Really big&lt;/a&gt;. You just won’t believe how vastly, hugely, mind-bogglingly big it is. I mean, you may think the /22 you got as a &lt;a href=&quot;https://www.ripe.net/manage-ips-and-asns/resource-management/faq/independent-resources/def-terms/what-is-a-local-internet-registry-lir&quot;&gt;LIR&lt;/a&gt; was big, but that’s just peanuts to the internet.&lt;/p&gt;
&lt;p&gt;Well, actually, it wasn’t in the long run, that’s why we need IPv6. But that is a different story.&lt;/p&gt;
&lt;p&gt;The point is, IPv4 (the most common deployed version of the IP protocol) sets its address limits at 2³² addresses. This means you have roughly 4.2 billion IP addresses to work with, except you don’t really, because large sections are not usable:&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;IP Range&lt;/th&gt;
&lt;th&gt;Use&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;0.0.0.0/8&lt;/td&gt;
&lt;td&gt;Local System&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;10.0.0.0/8&lt;/td&gt;
&lt;td&gt;Local LAN&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;127.0.0.0/8&lt;/td&gt;
&lt;td&gt;Loopback&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;169.254.0.0/16&lt;/td&gt;
&lt;td&gt;“Link Local”&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;172.16.0.0/12&lt;/td&gt;
&lt;td&gt;Local LAN&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;224.0.0.0/4&lt;/td&gt;
&lt;td&gt;Multicast&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;240.0.0.0/4&lt;/td&gt;
&lt;td&gt;“Future use”&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;The blocks ( shown as &lt;a href=&quot;https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing&quot;&gt;CIDR notation&lt;/a&gt; ) above already wipe out 588,316,672 addresses, or about 13% of all addresses.&lt;/p&gt;
&lt;p&gt;However giving the remaining 3,706,650,624 addresses, When you consider it, isn’t that many and is perfectly within reach of sending a packet to &lt;em&gt;every single one&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Now. This isn’t the first time someone has done this, the internet has a considerable amount of “background noise” (unsolicited packets) on it. Mostly created by systems looking for other systems to hack.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog.benjojo.co.uk/asset/c2kbTm5fIs&quot; alt=&quot;a graph showing the top ports that are scanned for&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Here we can see that port 23 is far higher (on a logarithmic scale) than any other port, and that is port is for &lt;a href=&quot;https://en.wikipedia.org/wiki/Telnet&quot;&gt;telnet&lt;/a&gt;, commonly used in insecure routers and other IoT devices.&lt;/p&gt;
&lt;p&gt;With that known, I speeded ahead and send a ICMP ping to every host on the internet to see how much of the internet responds to a ping (and thus indicating there is a connected computer on the other side of it)&lt;/p&gt;
&lt;p&gt;After around a day later, I had sent 3.7 billion packets and had a large text file. Now we just had to find a way to draw it!&lt;/p&gt;
&lt;h2&gt;Introducing Hilbert curves&lt;/h2&gt;
&lt;p&gt;The problem with displaying IP addresses, is that they are a single dimensional, they only move up and down, however humans are not good at looking at a large amount of single dimensional points. So there has to be a way to fill a 2 dimensional space that can also help the structure of the graph stay in shape.&lt;/p&gt;
&lt;p&gt;Luckily maths has our back again, with &lt;a href=&quot;https://en.wikipedia.org/wiki/Space-filling_curve&quot;&gt;space filling curves&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog.benjojo.co.uk/asset/uUN2SBTNhu&quot; alt=&quot;gif showing the drawing of a hilbert curve&quot; /&gt;&lt;/p&gt;
&lt;p&gt;For me it didn’t make much sense until I numbered the nodes it was passing though.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog.benjojo.co.uk/asset/xs5bdRYCNP&quot; alt=&quot;gif showing the drawing of a hilbert curve with numbers&quot; /&gt;&lt;/p&gt;
&lt;p&gt;It took me even longer for me to fully get all of this until I realised. You can still show this same animation being unraveled into a single dimension again:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog.benjojo.co.uk/asset/OHMMBrt565&quot; alt=&quot;gif showing a hilbert being transformed into a 1D line&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Anyway, now that we know these graphs work, we can start applying them to IP addresses!&lt;/p&gt;
&lt;p&gt;Thankfully &lt;a href=&quot;https://github.com/measurement-factory/ipv4-heatmap&quot;&gt;there are tools that can already produce these graphs&lt;/a&gt; in relation to IP addresses so it is just a case of loading that data in and producing the graph:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cat ping.txt | pcregrep -o1 ': (\d+\.\d+\.\d+\.\d+)' | ./ipv4-heatmap -a ./labels/iana/iana-labels.txt -o out.png
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;This renders a hilbert curve with a color gradient showing how many systems are online in that /24&lt;/p&gt;
&lt;p&gt;and so I present, The IPv4 Internet on 16th April 2018:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://benjojo.co.uk/internet-2018.png&quot;&gt;&lt;img src=&quot;https://blog.benjojo.co.uk/asset/zKYQQTw1sm&quot; alt=&quot;IPv4 internet map as a hilbert curve&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can click on the image for a lossless and full resolution version, however do be warned that it’s 9MB.&lt;/p&gt;
&lt;p&gt;The last public scan I know if was in 2012 and was done by the Carna botnet, using this data we can easily see some changes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog.benjojo.co.uk/asset/SpxueToPMV&quot; alt=&quot;a RIPE block being consumed in 6 years&quot; /&gt;&lt;/p&gt;
&lt;p&gt;In 2012 &lt;a href=&quot;https://ripe.net/&quot;&gt;RIPE&lt;/a&gt; had not even touched the 185.0.0.0/8, it would later become the block they would use for the last allocations, and would only give out a /22 of IP space to every new member of RIPE. This makes 185.0.0.0/8 odd looking among the other blocks, and there are no mass allocations, and so the blocks looks very “spotty” compared to others.&lt;/p&gt;
&lt;p&gt;RIPE is not the only one to have completely used up blocks in this time. Below we see 3 different &lt;abbr title=&quot;regional Internet registry, regional distributors of IP addresses&quot;&gt;RIRs&lt;/abbr&gt; consume their blocks in the space of 6 years.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog.benjojo.co.uk/asset/wK41NSkj6i&quot; alt=&quot;other RIR blocks being consumed&quot; /&gt;&lt;/p&gt;
&lt;p&gt;On top of all of this, I also did a bonus scan of a few &lt;abbr title=&quot;the RIR for Asia&quot;&gt;APNIC&lt;/abbr&gt; IP blocks every 30 mins for 24 hours. The data from that allows you to see the internet “breathe” as clients come online in the morning and offline at night:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog.benjojo.co.uk/asset/du4vcT8nUl&quot; alt=&quot;24 hours of a APNIC block&quot; /&gt;&lt;/p&gt;
&lt;p&gt;One of the more interesting finds in this gif was a what looks like a dynamic IP pool from a ISP, showing clients come online for a short amount of time, and then connecting and getting a new IP address (hence more the more active IP addresses are “moving” during the day)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog.benjojo.co.uk/asset/1J33yVnnP9&quot; alt=&quot;hinet block&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Oh and if you were wondering what IPv6 looks like in this form and how much we are using already:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://blog.benjojo.co.uk/asset/a1lhpWxve2&quot; alt=&quot;a square of pure black&quot; /&gt;&lt;/p&gt;
&lt;p&gt;And if you enjoyed this, you will be glad to know that I am going to be at &lt;a href=&quot;https://recurse.com/&quot;&gt;Recurse Center&lt;/a&gt; in NY for the next 9 weeks! Meaning you can follow my &lt;a href=&quot;https://twitter.com/benjojo12&quot;&gt;Twitter&lt;/a&gt; or &lt;a href=&quot;https://blog.benjojo.co.uk/rss.xml&quot;&gt;RSS&lt;/a&gt; to keep up with the other silly (or sometimes sensible) things I will do!&lt;/p&gt;
</description>
<pubDate>Sat, 21 Apr 2018 06:45:26 +0000</pubDate>
<dc:creator>randomdrake</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.benjojo.co.uk/post/scan-ping-the-internet-hilbert-curve</dc:identifier>
</item>
<item>
<title>Google&amp;#039;s Project Zero exposes unpatched Windows 10 lockdown bypass</title>
<link>https://www.zdnet.com/article/googles-project-zero-reveals-windows-10-lockdown-bypass/</link>
<guid isPermaLink="true" >https://www.zdnet.com/article/googles-project-zero-reveals-windows-10-lockdown-bypass/</guid>
<description>&lt;p&gt;&lt;em&gt;Video: When it comes to malware, Windows 10 is twice as secure as Windows 7.&lt;/em&gt;&lt;/p&gt;

&lt;div class=&quot;relatedContent alignRight&quot;&gt;
&lt;h3 class=&quot;heading&quot;&gt;&lt;span class=&quot;int&quot;&gt;More security news&lt;/span&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;p&gt;Google's Project Zero researchers have published details and a proof-of-concept code for a method to bypass a Windows 10 security feature.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.zdnet.com/article/windows-10-security-google-exposes-how-malicious-sites-can-exploit-microsoft-edge/&quot;&gt;Once&lt;/a&gt; &lt;a href=&quot;https://www.zdnet.com/article/windows-10-bug-google-again-reveals-code-for-important-unpatched-flaw/&quot;&gt;again&lt;/a&gt;, Project Zero has knocked back Microsoft's request for an extension to the 90-day deadline it gives vendors to either disclose or release a fix for bugs it finds.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://bugs.chromium.org/p/project-zero/issues/detail?id=1514&amp;amp;q=&quot; target=&quot;_blank&quot;&gt;newly disclosed bypass&lt;/a&gt; is a medium-severity issue that affects Windows 10 S or any Windows 10 machine with user mode code integrity (UMCI) enabled, such as enterprise Windows 10 PCs configured with Microsoft's virtual container known as Device Guard.&lt;/p&gt;
&lt;p&gt;Project Zero researcher James Forshaw released a detailed description and proof-of-concept code for the bypass that allows an attacker to gain persistent code execution on a machine.&lt;/p&gt;

&lt;p&gt;The bug itself resides in .NET and how it behaves within the Windows Lockdown Policy (WLDP). The researcher downplayed the seriousness of disclosing the bug in the absence of a patch due to the existence of two other known and unfixed Device Guard bypasses in the .NET framework.&lt;/p&gt;
&lt;p&gt;&quot;So this issue isn't as serious as it might have been if all known avenues for bypass were fixed,&quot; he wrote.&lt;/p&gt;
&lt;section class=&quot;sharethrough-top&quot; data-component=&quot;medusaContentRecommendation&quot; data-medusa-content-recommendation-options=&quot;{&amp;quot;promo&amp;quot;:&amp;quot;promo_ZD_recommendation_sharethrough_top_in_article_desktop&amp;quot;,&amp;quot;spot&amp;quot;:&amp;quot;dfp-in-article&amp;quot;}&quot;&gt;
&lt;/section&gt;&lt;p&gt;The bug also can't be remotely exploited and would require an attacker to have already infected a machine with malware. However, Forshaw notes that an attacker could get around this obstacle by exploiting another remote code execution bug in, say, Edge.&lt;/p&gt;
&lt;p&gt;Google reported the issue to Microsoft on January 19. Microsoft confirmed the issue about three weeks later and said it could not be fixed by April's Patch Tuesday deadline due to an &quot;unforeseen code relationship&quot;.&lt;/p&gt;
&lt;p&gt;The two tech giants re-engaged in the beginning of April to haggle over disclosure dates. Microsoft asked for two weeks' grace on the 90-day deadline, which Google denied, and then asked Google to hold off disclosing the bug until May's Patch Tuesday, which Google also knocked back.&lt;/p&gt;
&lt;p&gt;Microsoft last week pitched the idea of an extension until its upcoming Redstone 4 Windows 10 release, which will have a fix. However, Google denied this request too because Microsoft hasn't set a firm date for its Spring Windows 10 release.&lt;/p&gt;
&lt;p&gt;Here's Forshaw's technical explanation of the bypass:&lt;/p&gt;
&lt;p&gt;&quot;The WLDP COM Class lockdown policy contains a hard-coded list of eight to 50 COM objects, which enlightened scripting engines can instantiate. Excluding issues related to the looking-up of the correct CLSID, such as previously reported abuse of TreatAs case 40189,&quot; he wrote.&lt;/p&gt;
&lt;p&gt;&quot;This shouldn't be a major issue even if you can write to the registry to register an existing DLL under one of the allowed COM CLSIDs, as a well-behaved COM implementation should compare the CLSID passed to DllGetObject against its internal list of known objects.&quot;&lt;/p&gt;
&lt;p&gt;However, Forshaw said it turns out that .NET is not one of these well-behaved COM implementations.&lt;/p&gt;
&lt;p&gt;&quot;When a .NET COM object is instantiated, the CLSID passed to mscoree's DllGetClassObject is only used to look up the registration information in HKCR. At this point, at least based on testing, the CLSID is thrown away and the .NET object created,&quot; he said.&lt;/p&gt;
&lt;p&gt;&quot;This has a direct impact on the class policy as it allows an attacker to add registry keys, including to HKCU, that would load an arbitrary COM visible class under one of the allowed CLSIDs. As .NET then doesn't care about whether the .NET Type has that specific GUID, you can use this to bootstrap arbitrary code execution by abusing something like &lt;a href=&quot;https://github.com/tyranid/DotNetToJScript&quot;&gt;DotNetToJScript&lt;/a&gt;.&quot;&lt;/p&gt;
&lt;h3&gt;Previous and related coverage&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.zdnet.com/article/windows-10-bug-google-again-reveals-code-for-important-unpatched-flaw/&quot;&gt;Windows 10 bug: Google again reveals code for 'important' unpatched flaw&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For the second time in a week, Google reveals another unpatched Windows 10 vulnerability.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.zdnet.com/article/windows-10-security-google-exposes-how-malicious-sites-can-exploit-microsoft-edge/&quot;&gt;Windows 10 security: Google exposes how malicious sites can exploit Microsoft Edge&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Microsoft misses Google's 90-day deadline, so Google has published details of an exploit mitigation bypass.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.zdnet.com/article/windows-10-credential-theft-google-is-working-on-fix-for-chrome-flaw/&quot;&gt;Windows 10 credential theft: Google is working on fix for Chrome flaw&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Google is addressing a problem that allows a crafty credential theft attack on Windows through Chrome's default behavior.&lt;/p&gt;
</description>
<pubDate>Sat, 21 Apr 2018 06:29:48 +0000</pubDate>
<dc:creator>_o_</dc:creator>
<og:type>article</og:type>
<og:url>https://www.zdnet.com/article/googles-project-zero-reveals-windows-10-lockdown-bypass/</og:url>
<og:title>Google's Project Zero exposes unpatched Windows 10 lockdown bypass | ZDNet</og:title>
<og:description>Google denies multiple requests by Microsoft for an extension to Project Zero's 90-day disclose-or-fix deadline.</og:description>
<og:image>https://zdnet3.cbsistatic.com/hub/i/r/2018/04/20/b8d1be7c-4958-471f-8868-ebe14287db93/thumbnail/770x578/a473f7a3efff6b2c44982f80282d095c/windows-10-hero-gif.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.zdnet.com/article/googles-project-zero-reveals-windows-10-lockdown-bypass/</dc:identifier>
</item>
<item>
<title>Mermaid: Markdown-like generation of diagrams and flowcharts from text</title>
<link>https://github.com/knsv/mermaid</link>
<guid isPermaLink="true" >https://github.com/knsv/mermaid</guid>
<description>&lt;h3&gt;README.md&lt;/h3&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://travis-ci.org/knsv/mermaid&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/9209ed42c4885883d319d06ac66b2f62f2d7d7d7/68747470733a2f2f7472617669732d63692e6f72672f6b6e73762f6d65726d6169642e7376673f6272616e63683d6d6173746572&quot; alt=&quot;Build Status&quot; data-canonical-src=&quot;https://travis-ci.org/knsv/mermaid.svg?branch=master&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://coveralls.io/github/knsv/mermaid?branch=master&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/a576f64f78d5c0b15c75aad2572b4007683aede5/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f6b6e73762f6d65726d6169642f62616467652e7376673f6272616e63683d6d6173746572&quot; alt=&quot;Coverage Status&quot; data-canonical-src=&quot;https://coveralls.io/repos/github/knsv/mermaid/badge.svg?branch=master&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://gitter.im/knsv/mermaid?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&amp;amp;utm_content=badge&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/da2edb525cde1455a622c58c0effc3a90b9a181c/68747470733a2f2f6261646765732e6769747465722e696d2f4a6f696e253230436861742e737667&quot; alt=&quot;Join the chat at https://gitter.im/knsv/mermaid&quot; data-canonical-src=&quot;https://badges.gitter.im/Join%20Chat.svg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/knsv/mermaid/blob/master/img/header.png&quot;&gt;&lt;img src=&quot;https://github.com/knsv/mermaid/raw/master/img/header.png&quot; alt=&quot;banner&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Generation of diagrams and flowcharts from text in a similar manner as markdown.&lt;/p&gt;
&lt;p&gt;Ever wanted to simplify documentation and avoid heavy tools like Visio when explaining your code?&lt;/p&gt;
&lt;p&gt;This is why mermaid was born, a simple markdown-like script language for generating charts from text via javascript.&lt;/p&gt;
&lt;h3&gt;Flowchart&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;graph TD;
    A--&amp;gt;B;
    A--&amp;gt;C;
    B--&amp;gt;D;
    C--&amp;gt;D;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/knsv/mermaid/blob/master/img/flow.png&quot;&gt;&lt;img src=&quot;https://github.com/knsv/mermaid/raw/master/img/flow.png&quot; alt=&quot;Flowchart&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Sequence diagram&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;sequenceDiagram
    participant Alice
    participant Bob
    Alice-&amp;gt;&amp;gt;John: Hello John, how are you?
    loop Healthcheck
        John-&amp;gt;&amp;gt;John: Fight against hypochondria
    end
    Note right of John: Rational thoughts &amp;lt;br/&amp;gt;prevail...
    John--&amp;gt;&amp;gt;Alice: Great!
    John-&amp;gt;&amp;gt;Bob: How about you?
    Bob--&amp;gt;&amp;gt;John: Jolly good!
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/knsv/mermaid/blob/master/img/sequence.png&quot;&gt;&lt;img src=&quot;https://github.com/knsv/mermaid/raw/master/img/sequence.png&quot; alt=&quot;Sequence diagram&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Gantt diagram&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;gantt
dateFormat  YYYY-MM-DD
title Adding GANTT diagram to mermaid

section A section
Completed task            :done,    des1, 2014-01-06,2014-01-08
Active task               :active,  des2, 2014-01-09, 3d
Future task               :         des3, after des2, 5d
Future task2               :         des4, after des3, 5d
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/knsv/mermaid/blob/master/img/gantt.png&quot;&gt;&lt;img src=&quot;https://github.com/knsv/mermaid/raw/master/img/gantt.png&quot; alt=&quot;Gantt diagram&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Class diagram - ❗️ experimental&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;classDiagram
Class01 &amp;lt;|-- AveryLongClass : Cool
Class03 *-- Class04
Class05 o-- Class06
Class07 .. Class08
Class09 --&amp;gt; C2 : Where am i?
Class09 --* C3
Class09 --|&amp;gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
Class08 &amp;lt;--&amp;gt; C2: Cool label
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/knsv/mermaid/blob/master/img/class.png&quot;&gt;&lt;img src=&quot;https://github.com/knsv/mermaid/raw/master/img/class.png&quot; alt=&quot;Class diagram&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Git graph - ❗️ experimental&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;gitGraph:
options
{
    &quot;nodeSpacing&quot;: 150,
    &quot;nodeRadius&quot;: 10
}
end
commit
branch newbranch
checkout newbranch
commit
commit
checkout master
commit
commit
merge newbranch

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/knsv/mermaid/blob/master/img/git.png&quot;&gt;&lt;img src=&quot;https://github.com/knsv/mermaid/raw/master/img/git.png&quot; alt=&quot;Git graph&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;h3&gt;CDN&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;https://unpkg.com/mermaid@&amp;lt;version&amp;gt;/dist/
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Replace &lt;code&gt;&amp;lt;version&amp;gt;&lt;/code&gt; with expected version number.&lt;/p&gt;
&lt;p&gt;Example: &lt;a href=&quot;https://unpkg.com/mermaid@7.1.0/dist/&quot; rel=&quot;nofollow&quot;&gt;https://unpkg.com/mermaid@7.1.0/dist/&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Node.js&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;yarn add mermaid
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;Documentation&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://mermaidjs.github.io&quot; rel=&quot;nofollow&quot;&gt;https://mermaidjs.github.io&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Sibling projects&lt;/h2&gt;

&lt;p&gt;Things are piling up and I have hard time keeping up. To remedy this it would be great if we could form a core team of developers to cooperate with the future development mermaid.&lt;/p&gt;
&lt;p&gt;As part of this team you would get write access to the repository and would represent the project when answering questions and issues.&lt;/p&gt;
&lt;p&gt;Together we could continue the work with things like:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;adding more typers of diagrams like mindmaps, ert digrams etc&lt;/li&gt;
&lt;li&gt;improving existing diagrams&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Don't hesitate to contact me if you want to get involved.&lt;/p&gt;

&lt;h2&gt;Setup&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;yarn install
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;Build&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;yarn build:watch
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;Lint&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;yarn lint
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;We use &lt;a href=&quot;https://github.com/feross/standard&quot;&gt;JavaScript Standard Style&lt;/a&gt;. We recommend you installing &lt;a href=&quot;https://github.com/feross/standard#are-there-text-editor-plugins&quot;&gt;editor plugins&lt;/a&gt; so you can get real time lint result.&lt;/p&gt;
&lt;h2&gt;Test&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;yarn test
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Manual test in browser:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;open dist/index.html
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;Release&lt;/h2&gt;
&lt;p&gt;For those who have the permission to do so:&lt;/p&gt;
&lt;p&gt;Update version number in &lt;code&gt;package.json&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;npm publish
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Command above generates files into the &lt;code&gt;dist&lt;/code&gt; folder and publishes them to npmjs.org.&lt;/p&gt;

&lt;p&gt;Many thanks to the &lt;a href=&quot;http://d3js.org/&quot; rel=&quot;nofollow&quot;&gt;d3&lt;/a&gt; and &lt;a href=&quot;https://github.com/cpettitt/dagre-d3&quot;&gt;dagre-d3&lt;/a&gt; projects for providing the graphical layout and drawing libraries!&lt;/p&gt;
&lt;p&gt;Thanks also to the &lt;a href=&quot;http://bramp.github.io/js-sequence-diagrams&quot; rel=&quot;nofollow&quot;&gt;js-sequence-diagram&lt;/a&gt; project for usage of the grammar for the sequence diagrams. Thanks to Jessica Peter for inspiration and starting point for gantt rendering.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Mermaid was created by Knut Sveidqvist for easier documentation.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://github.com/tylerlong&quot;&gt;Tyler Long&lt;/a&gt; has became a collaborator since April 2017.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Here is the full list of the projects &lt;a href=&quot;https://github.com/knsv/mermaid/graphs/contributors&quot;&gt;contributors&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;</description>
<pubDate>Fri, 20 Apr 2018 23:43:04 +0000</pubDate>
<dc:creator>tomcam</dc:creator>
<og:image>https://avatars0.githubusercontent.com/u/5837277?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>knsv/mermaid</og:title>
<og:url>https://github.com/knsv/mermaid</og:url>
<og:description>mermaid - Generation of diagram and flowchart from text in a similar manner as markdown</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/knsv/mermaid</dc:identifier>
</item>
<item>
<title>Smugmug Acquires Flickr</title>
<link>https://smugmug.com/together</link>
<guid isPermaLink="true" >https://smugmug.com/together</guid>
<description>&lt;br/&gt;&lt;div class=&quot;sky sky-2&quot;&gt;
                                
                                &lt;p&gt;But Wait...&lt;/p&gt;
                            &lt;/div&gt;&lt;br/&gt;&lt;div class=&quot;sky sky-4 small&quot; readability=&quot;11&quot;&gt;
                                
                                &lt;p&gt;
                                    SmugMug has acquired Flickr. &lt;br/&gt;If you use our products today, rest easy, they aren't going anywhere.&lt;br/&gt;The future is bright, but we'll only get there together.&lt;br/&gt;Let's do this.&lt;/p&gt;
                            &lt;/div&gt;

                        </description>
<pubDate>Fri, 20 Apr 2018 22:31:37 +0000</pubDate>
<dc:creator>uptown</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.smugmug.com/together/</dc:identifier>
</item>
<item>
<title>FFmpeg 4.0 released</title>
<link>http://ffmpeg.org/index.html#pr4.0</link>
<guid isPermaLink="true" >http://ffmpeg.org/index.html#pr4.0</guid>
<description>&lt;div class=&quot;row&quot; readability=&quot;8.2087912087912&quot;&gt;
&lt;p&gt;
&lt;h2 class=&quot;description&quot;&gt;A complete, cross-platform solution to record, convert and stream audio and video.&lt;/h2&gt;
&lt;/p&gt;

&lt;/div&gt;
&lt;div class=&quot;well example&quot; readability=&quot;6.0618556701031&quot;&gt;
&lt;h3&gt;Converting &lt;strong&gt;video&lt;/strong&gt; and &lt;strong&gt;audio&lt;/strong&gt; has never been so easy.&lt;/h3&gt;
&lt;pre&gt;
$ ffmpeg -i input.mp4 output.avi
&lt;/pre&gt;
&lt;div class=&quot;text-right&quot;&gt;&lt;a href=&quot;http://ffmpeg.org/about.html&quot; class=&quot;btn btn-success btn-lg&quot;&gt;Discover more&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;pr4.0&quot;&gt;April 20th, 2018, FFmpeg 4.0 &quot;Wu&quot;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_4.0&quot;&gt;FFmpeg 4.0 &quot;Wu&quot;&lt;/a&gt;, a new major release, is now available! Some of the highlights:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Bitstream filters for editing metadata in H.264, HEVC and MPEG-2 streams&lt;/li&gt;
&lt;li&gt;Experimental MagicYUV encoder&lt;/li&gt;
&lt;li&gt;TiVo ty/ty+ demuxer&lt;/li&gt;
&lt;li&gt;Intel QSV-accelerated MJPEG encoding&lt;/li&gt;
&lt;li&gt;native aptX and aptX HD encoder and decoder&lt;/li&gt;
&lt;li&gt;NVIDIA NVDEC-accelerated H.264, HEVC, MJPEG, MPEG-1/2/4, VC1, VP8/9 hwaccel decoding&lt;/li&gt;
&lt;li&gt;Intel QSV-accelerated overlay filter&lt;/li&gt;
&lt;li&gt;mcompand audio filter&lt;/li&gt;
&lt;li&gt;acontrast audio filter&lt;/li&gt;
&lt;li&gt;OpenCL overlay filter&lt;/li&gt;
&lt;li&gt;video mix filter&lt;/li&gt;
&lt;li&gt;video normalize filter&lt;/li&gt;
&lt;li&gt;audio lv2 wrapper filter&lt;/li&gt;
&lt;li&gt;VAAPI MJPEG and VP8 decoding&lt;/li&gt;
&lt;li&gt;AMD AMF H.264 and HEVC encoders&lt;/li&gt;
&lt;li&gt;video fillborders filter&lt;/li&gt;
&lt;li&gt;video setrange filter&lt;/li&gt;
&lt;li&gt;support LibreSSL (via libtls)&lt;/li&gt;
&lt;li&gt;Dropped support for building for Windows XP. The minimum supported Windows version is Windows Vista.&lt;/li&gt;
&lt;li&gt;deconvolve video filter&lt;/li&gt;
&lt;li&gt;entropy video filter&lt;/li&gt;
&lt;li&gt;hilbert audio filter source&lt;/li&gt;
&lt;li&gt;aiir audio filter&lt;/li&gt;
&lt;li&gt;Removed the ffserver program&lt;/li&gt;
&lt;li&gt;Removed the ffmenc and ffmdec muxer and demuxer&lt;/li&gt;
&lt;li&gt;VideoToolbox HEVC encoder and hwaccel&lt;/li&gt;
&lt;li&gt;VAAPI-accelerated ProcAmp (color balance), denoise and sharpness filters&lt;/li&gt;
&lt;li&gt;Add android_camera indev&lt;/li&gt;
&lt;li&gt;codec2 en/decoding via libcodec2&lt;/li&gt;
&lt;li&gt;native SBC encoder and decoder&lt;/li&gt;
&lt;li&gt;drmeter audio filter&lt;/li&gt;
&lt;li&gt;hapqa_extract bitstream filter&lt;/li&gt;
&lt;li&gt;filter_units bitstream filter&lt;/li&gt;
&lt;li&gt;AV1 Support through libaom&lt;/li&gt;
&lt;li&gt;E-AC-3 dependent frames support&lt;/li&gt;
&lt;li&gt;bitstream filter for extracting E-AC-3 core&lt;/li&gt;
&lt;li&gt;Haivision SRT protocol via libsrt&lt;/li&gt;
&lt;li&gt;vfrdet filter&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;We strongly recommend users, distributors, and system integrators to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;pr3.4&quot;&gt;October 15th, 2017, FFmpeg 3.4 &quot;Cantor&quot;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_3.4&quot;&gt;FFmpeg 3.4 &quot;Cantor&quot;&lt;/a&gt;, a new major release, is now available! Some of the highlights:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;deflicker video filter&lt;/li&gt;
&lt;li&gt;doubleweave video filter&lt;/li&gt;
&lt;li&gt;lumakey video filter&lt;/li&gt;
&lt;li&gt;pixscope video filter&lt;/li&gt;
&lt;li&gt;oscilloscope video filter&lt;/li&gt;
&lt;li&gt;update cuvid/nvenc headers to Video Codec SDK 8.0.14&lt;/li&gt;
&lt;li&gt;afir audio filter&lt;/li&gt;
&lt;li&gt;scale_cuda CUDA based video scale filter&lt;/li&gt;
&lt;li&gt;librsvg support for svg rasterization&lt;/li&gt;
&lt;li&gt;crossfeed audio filter&lt;/li&gt;
&lt;li&gt;spec compliant VP9 muxing support in MP4&lt;/li&gt;
&lt;li&gt;surround audio filter&lt;/li&gt;
&lt;li&gt;sofalizer filter switched to libmysofa&lt;/li&gt;
&lt;li&gt;Gremlin Digital Video demuxer and decoder&lt;/li&gt;
&lt;li&gt;headphone audio filter&lt;/li&gt;
&lt;li&gt;superequalizer audio filter&lt;/li&gt;
&lt;li&gt;roberts video filter&lt;/li&gt;
&lt;li&gt;additional frame format support for Interplay MVE movies&lt;/li&gt;
&lt;li&gt;support for decoding through D3D11VA in ffmpeg&lt;/li&gt;
&lt;li&gt;limiter video filter&lt;/li&gt;
&lt;li&gt;libvmaf video filter&lt;/li&gt;
&lt;li&gt;Dolby E decoder and SMPTE 337M demuxer&lt;/li&gt;
&lt;li&gt;unpremultiply video filter&lt;/li&gt;
&lt;li&gt;tlut2 video filter&lt;/li&gt;
&lt;li&gt;floodfill video filter&lt;/li&gt;
&lt;li&gt;pseudocolor video filter&lt;/li&gt;
&lt;li&gt;raw G.726 muxer and demuxer, left- and right-justified&lt;/li&gt;
&lt;li&gt;NewTek NDI input/output device&lt;/li&gt;
&lt;li&gt;FITS demuxer and decoder&lt;/li&gt;
&lt;li&gt;FITS muxer and encoder&lt;/li&gt;
&lt;li&gt;despill video filter&lt;/li&gt;
&lt;li&gt;haas audio filter&lt;/li&gt;
&lt;li&gt;SUP/PGS subtitle muxer&lt;/li&gt;
&lt;li&gt;convolve video filter&lt;/li&gt;
&lt;li&gt;VP9 tile threading support&lt;/li&gt;
&lt;li&gt;KMS screen grabber&lt;/li&gt;
&lt;li&gt;CUDA thumbnail filter&lt;/li&gt;
&lt;li&gt;V4L2 mem2mem HW assisted codecs&lt;/li&gt;
&lt;li&gt;Rockchip MPP hardware decoding&lt;/li&gt;
&lt;li&gt;vmafmotion video filter&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;We strongly recommend users, distributors, and system integrators to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;pr3.3&quot;&gt;April 13th, 2017, FFmpeg 3.3 &quot;Hilbert&quot;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_3.3&quot;&gt;FFmpeg 3.3 &quot;Hilbert&quot;&lt;/a&gt;, a new major release, is now available! Some of the highlights:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Apple Pixlet decoder&lt;/li&gt;
&lt;li&gt;NewTek SpeedHQ decoder&lt;/li&gt;
&lt;li&gt;QDMC audio decoder&lt;/li&gt;
&lt;li&gt;PSD (Photoshop Document) decoder&lt;/li&gt;
&lt;li&gt;FM Screen Capture decoder&lt;/li&gt;
&lt;li&gt;ScreenPressor decoder&lt;/li&gt;
&lt;li&gt;XPM decoder&lt;/li&gt;
&lt;li&gt;DNxHR decoder fixes for HQX and high resolution videos&lt;/li&gt;
&lt;li&gt;ClearVideo decoder (partial)&lt;/li&gt;
&lt;li&gt;16.8 and 24.0 floating point PCM decoder&lt;/li&gt;
&lt;li&gt;Intel QSV-accelerated VP8 video decoding&lt;/li&gt;
&lt;li&gt;native Opus encoder&lt;/li&gt;
&lt;li&gt;DNxHR 444 and HQX encoding&lt;/li&gt;
&lt;li&gt;Quality improvements for the (M)JPEG encoder&lt;/li&gt;
&lt;li&gt;VAAPI-accelerated MPEG-2 and VP8 encoding&lt;/li&gt;
&lt;li&gt;premultiply video filter&lt;/li&gt;
&lt;li&gt;abitscope multimedia filter&lt;/li&gt;
&lt;li&gt;readeia608 filter&lt;/li&gt;
&lt;li&gt;threshold filter&lt;/li&gt;
&lt;li&gt;midequalizer filter&lt;/li&gt;
&lt;li&gt;MPEG-7 Video Signature filter&lt;/li&gt;
&lt;li&gt;add internal ebur128 library, remove external libebur128 dependency&lt;/li&gt;
&lt;li&gt;Intel QSV video scaling and deinterlacing filters&lt;/li&gt;
&lt;li&gt;Sample Dump eXchange demuxer&lt;/li&gt;
&lt;li&gt;MIDI Sample Dump Standard demuxer&lt;/li&gt;
&lt;li&gt;Scenarist Closed Captions demuxer and muxer&lt;/li&gt;
&lt;li&gt;Support MOV with multiple sample description tables&lt;/li&gt;
&lt;li&gt;Pro-MPEG CoP #3-R2 FEC protocol&lt;/li&gt;
&lt;li&gt;Support for spherical videos&lt;/li&gt;
&lt;li&gt;CrystalHD decoder moved to new decode API&lt;/li&gt;
&lt;li&gt;configure now fails if autodetect-libraries are requested but not found&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;We strongly recommend users, distributors, and system integrators to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;gsoc2016finalreport&quot;&gt;October 30th, 2016, Results: Summer Of Code 2016.&lt;/h3&gt;
&lt;p&gt;This has been a long time coming but we wanted to give a proper closure to our participation in this run of the program and it takes time. Sometimes it's just to get the final report for each project trimmed down, others, is finalizing whatever was still in progress when the program finished: final patches need to be merged, TODO lists stabilized, future plans agreed; you name it.&lt;/p&gt;
&lt;p&gt;Without further ado, here's the silver-lining for each one of the projects we sought to complete during this Summer of Code season:&lt;/p&gt;
&lt;h4&gt;FFv1 (Mentor: Michael Niedermayer)&lt;/h4&gt;
&lt;p&gt;Stanislav Dolganov designed and implemented experimental support for motion estimation and compensation in the lossless FFV1 codec. The design and implementation is based on the snow video codec, which uses OBMC. Stanislav's work proved that significant compression gains can be achieved with inter frame compression. FFmpeg welcomes Stanislav to continue working beyond this proof of concept and bring its advances into the official FFV1 specification within the IETF.&lt;/p&gt;
&lt;h4&gt;Self test coverage (Mentor: Michael Niedermayer)&lt;/h4&gt;
&lt;p&gt;Petru Rares Sincraian added several self-tests to FFmpeg and successfully went through the in-some-cases tedious process of fine tuning tests parameters to avoid known and hard to avoid problems, like checksum mismatches due to rounding errors on the myriad of platforms we support. His work has improved the code coverage of our self tests considerably.&lt;/p&gt;
&lt;h4&gt;MPEG-4 ALS encoder implementation (Mentor: Thilo Borgmann)&lt;/h4&gt;
&lt;p&gt;Umair Khan updated and integrated the ALS encoder to fit in the current FFmpeg codebase. He also implemented a missing feature for the ALS decoder that enables floating-point sample decoding. FFmpeg support for MPEG-4 ALS has been improved significantly by Umair's work. We welcome him to keep maintaining his improvements and hope for great contributions to come.&lt;/p&gt;
&lt;h4&gt;Tee muxer improvements (Mentor: Marton Balint)&lt;/h4&gt;
&lt;p&gt;Ján Sebechlebský's generic goal was to improve the tee muxer so it tolerated blocking IO and allowed transparent error recovery. During the design phase it turned out that this functionality called for a separate muxer, so Ján spent his summer working on the so-called FIFO muxer, gradually fixing issues all over the codebase. He succeeded in his task, and the FIFO muxer is now part of the main repository, alongside several other improvements he made in the process.&lt;/p&gt;
&lt;h4&gt;TrueHD encoder (Mentor: Rostislav Pehlivanov)&lt;/h4&gt;
&lt;p&gt;Jai Luthra's objective was to update the out-of-tree and pretty much abandoned MLP (Meridian Lossless Packing) encoder for libavcodec and improve it to enable encoding to the TrueHD format. For the qualification period the encoder was updated such that it was usable and throughout the summer, successfully improved adding support for multi-channel audio and TrueHD encoding. Jai's code has been merged into the main repository now. While a few problems remain with respect to LFE channel and 32 bit sample handling, these are in the process of being fixed such that effort can be finally put in improving the encoder's speed and efficiency.&lt;/p&gt;
&lt;h4&gt;Motion interpolation filter (Mentor: Paul B Mahol)&lt;/h4&gt;
&lt;p&gt;Davinder Singh investigated existing motion estimation and interpolation approaches from the available literature and previous work by our own: Michael Niedermayer, and implemented filters based on this research. These filters allow motion interpolating frame rate conversion to be applied to a video, for example, to create a slow motion effect or change the frame rate while smoothly interpolating the video along the motion vectors. There's still work to be done to call these filters 'finished', which is rather hard all things considered, but we are looking optimistically at their future.&lt;/p&gt;
&lt;p&gt;And that's it. We are happy with the results of the program and immensely thankful for the opportunity of working with such an amazing set of students. We can be a tough crowd but our mentors did an amazing job at hand holding our interns through their journey. Thanks also to Google for this wonderful program and to everyone that made room in their busy lives to help making GSoC2016 a success. See you in 2017!&lt;/p&gt;
&lt;h3 id=&quot;sdl1&quot;&gt;September 24th, 2016, SDL1 support dropped.&lt;/h3&gt;
&lt;p&gt;Support for the SDL1 library has been dropped, due to it no longer being maintained (as of January, 2012) and it being superseded by the SDL2 library. As a result, the SDL1 output device has also been removed and replaced by an SDL2 implementation. Both the ffplay and opengl output devices have been updated to support SDL2.&lt;/p&gt;
&lt;h3 id=&quot;pr3.1.2&quot;&gt;August 9th, 2016, FFmpeg 3.1.2 &quot;Laplace&quot;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_3.1&quot;&gt;FFmpeg 3.1.2&lt;/a&gt;, a new point release from the 3.1 release branch, is now available! It fixes several bugs.&lt;/p&gt;
&lt;p&gt;We recommend users, distributors, and system integrators, to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;ffserv&quot;&gt;July 10th, 2016, ffserver program being dropped&lt;/h3&gt;
&lt;p&gt;After thorough deliberation, we're announcing that we're about to drop the ffserver program from the project starting with the next release. ffserver has been a problematic program to maintain due to its use of internal APIs, which complicated the recent cleanups to the libavformat library, and block further cleanups and improvements which are desired by API users and will be easier to maintain. Furthermore the program has been hard for users to deploy and run due to reliability issues, lack of knowledgable people to help and confusing configuration file syntax. Current users and members of the community are invited to write a replacement program to fill the same niche that ffserver did using the new APIs and to contact us so we may point users to test and contribute to its development.&lt;/p&gt;
&lt;h3 id=&quot;pr3.1.1&quot;&gt;July 1st, 2016, FFmpeg 3.1.1 &quot;Laplace&quot;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_3.1&quot;&gt;FFmpeg 3.1.1&lt;/a&gt;, a new point release from the 3.1 release branch, is now available! It mainly deals with a few ABI issues introduced in the previous release.&lt;/p&gt;
&lt;p&gt;We strongly recommend users, distributors, and system integrators, especially those who experienced issues upgrading from 3.0, to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;pr3.1&quot;&gt;June 27th, 2016, FFmpeg 3.1 &quot;Laplace&quot;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_3.1&quot;&gt;FFmpeg 3.1 &quot;Laplace&quot;&lt;/a&gt;, a new major release, is now available! Some of the highlights:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;DXVA2-accelerated HEVC Main10 decoding&lt;/li&gt;
&lt;li&gt;fieldhint filter&lt;/li&gt;
&lt;li&gt;loop video filter and aloop audio filter&lt;/li&gt;
&lt;li&gt;Bob Weaver deinterlacing filter&lt;/li&gt;
&lt;li&gt;firequalizer filter&lt;/li&gt;
&lt;li&gt;datascope filter&lt;/li&gt;
&lt;li&gt;bench and abench filters&lt;/li&gt;
&lt;li&gt;ciescope filter&lt;/li&gt;
&lt;li&gt;protocol blacklisting API&lt;/li&gt;
&lt;li&gt;MediaCodec H264 decoding&lt;/li&gt;
&lt;li&gt;VC-2 HQ RTP payload format (draft v1) depacketizer and packetizer&lt;/li&gt;
&lt;li&gt;VP9 RTP payload format (draft v2) packetizer&lt;/li&gt;
&lt;li&gt;AudioToolbox audio decoders&lt;/li&gt;
&lt;li&gt;AudioToolbox audio encoders&lt;/li&gt;
&lt;li&gt;coreimage filter (GPU based image filtering on OSX)&lt;/li&gt;
&lt;li&gt;libdcadec removed&lt;/li&gt;
&lt;li&gt;bitstream filter for extracting DTS core&lt;/li&gt;
&lt;li&gt;ADPCM IMA DAT4 decoder&lt;/li&gt;
&lt;li&gt;musx demuxer&lt;/li&gt;
&lt;li&gt;aix demuxer&lt;/li&gt;
&lt;li&gt;remap filter&lt;/li&gt;
&lt;li&gt;hash and framehash muxers&lt;/li&gt;
&lt;li&gt;colorspace filter&lt;/li&gt;
&lt;li&gt;hdcd filter&lt;/li&gt;
&lt;li&gt;readvitc filter&lt;/li&gt;
&lt;li&gt;VAAPI-accelerated format conversion and scaling&lt;/li&gt;
&lt;li&gt;libnpp/CUDA-accelerated format conversion and scaling&lt;/li&gt;
&lt;li&gt;Duck TrueMotion 2.0 Real Time decoder&lt;/li&gt;
&lt;li&gt;Wideband Single-bit Data (WSD) demuxer&lt;/li&gt;
&lt;li&gt;VAAPI-accelerated H.264/HEVC/MJPEG encoding&lt;/li&gt;
&lt;li&gt;DTS Express (LBR) decoder&lt;/li&gt;
&lt;li&gt;Generic OpenMAX IL encoder with support for Raspberry Pi&lt;/li&gt;
&lt;li&gt;IFF ANIM demuxer &amp;amp; decoder&lt;/li&gt;
&lt;li&gt;Direct Stream Transfer (DST) decoder&lt;/li&gt;
&lt;li&gt;loudnorm filter&lt;/li&gt;
&lt;li&gt;MTAF demuxer and decoder&lt;/li&gt;
&lt;li&gt;MagicYUV decoder&lt;/li&gt;
&lt;li&gt;OpenExr improvements (tile data and B44/B44A support)&lt;/li&gt;
&lt;li&gt;BitJazz SheerVideo decoder&lt;/li&gt;
&lt;li&gt;CUDA CUVID H264/HEVC decoder&lt;/li&gt;
&lt;li&gt;10-bit depth support in native utvideo decoder&lt;/li&gt;
&lt;li&gt;libutvideo wrapper removed&lt;/li&gt;
&lt;li&gt;YUY2 Lossless Codec decoder&lt;/li&gt;
&lt;li&gt;VideoToolbox H.264 encoder&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;We strongly recommend users, distributors, and system integrators to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;gsoc2016&quot;&gt;March 16th, 2016, Google Summer of Code&lt;/h3&gt;
&lt;p&gt;FFmpeg has been accepted as a &lt;a href=&quot;https://summerofcode.withgoogle.com/&quot;&gt;Google Summer of Code&lt;/a&gt; open source organization. If you wish to participate as a student see our &lt;a href=&quot;https://trac.ffmpeg.org/wiki/SponsoringPrograms/GSoC/2016&quot;&gt;project ideas page&lt;/a&gt;. You can already get in contact with mentors and start working on qualification tasks as well as register at google and submit your project proposal draft. Good luck!&lt;/p&gt;
&lt;h3 id=&quot;pr3.0&quot;&gt;February 15th, 2016, FFmpeg 3.0 &quot;Einstein&quot;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_3.0&quot;&gt;FFmpeg 3.0 &quot;Einstein&quot;&lt;/a&gt;, a new major release, is now available! Some of the highlights:&lt;/p&gt;
&lt;p&gt;We strongly recommend users, distributors, and system integrators to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;removing_external_aac_encoders&quot;&gt;January 30, 2016, Removing support for two external AAC encoders&lt;/h3&gt;
&lt;p&gt;We have just removed support for VisualOn AAC encoder (libvo-aacenc) and libaacplus in FFmpeg master.&lt;/p&gt;
&lt;p&gt;Even before marking our internal AAC encoder as &lt;a href=&quot;http://ffmpeg.org/index.html#aac_encoder_stable&quot;&gt;stable&lt;/a&gt;, it was known that libvo-aacenc was of an inferior quality compared to our native one for most samples. However, the VisualOn encoder was used extensively by the Android Open Source Project, and we would like to have a tested-and-true stable option in our code base.&lt;/p&gt;
&lt;p&gt;When first committed in 2011, libaacplus filled in the gap of encoding High Efficiency AAC formats (HE-AAC and HE-AACv2), which was not supported by any of the encoders in FFmpeg at that time.&lt;/p&gt;
&lt;p&gt;The circumstances for both have changed. After the work spearheaded by Rostislav Pehlivanov and Claudio Freire, the now-stable FFmpeg native AAC encoder is ready to compete with much more mature encoders. The Fraunhofer FDK AAC Codec Library for Android was added in 2012 as the fourth supported external AAC encoder, and the one with the best quality and the most features supported, including HE-AAC and HE-AACv2.&lt;/p&gt;
&lt;p&gt;Therefore, we have decided that it is time to remove libvo-aacenc and libaacplus. If you are currently using libvo-aacenc, prepare to transition to the native encoder (&lt;code&gt;aac&lt;/code&gt;) when updating to the next version of FFmpeg. In most cases it is as simple as merely swapping the encoder name. If you are currently using libaacplus, start using FDK AAC (&lt;code&gt;libfdk_aac&lt;/code&gt;) with an appropriate &lt;code&gt;profile&lt;/code&gt; option to select the exact AAC profile that fits your needs. In both cases, you will enjoy an audible quality improvement and as well as fewer licensing headaches.&lt;/p&gt;
&lt;p&gt;Enjoy!&lt;/p&gt;
&lt;h3 id=&quot;pr2.8.5&quot;&gt;January 16, 2016, FFmpeg 2.8.5, 2.7.5, 2.6.7, 2.5.10&lt;/h3&gt;
&lt;p&gt;We have made several new point releases (&lt;strong&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_2.8&quot;&gt;2.8.5&lt;/a&gt;, &lt;a href=&quot;http://ffmpeg.org/download.html#release_2.7&quot;&gt;2.7.5&lt;/a&gt;, &lt;a href=&quot;http://ffmpeg.org/download.html#release_2.6&quot;&gt;2.6.7&lt;/a&gt;, &lt;a href=&quot;http://ffmpeg.org/download.html#release_2.5&quot;&gt;2.5.10&lt;/a&gt;&lt;/strong&gt;). They fix various bugs, as well as CVE-2016-1897 and CVE-2016-1898. Please see the changelog for each release for more details.&lt;/p&gt;
&lt;p&gt;We recommend users, distributors and system integrators to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;aac_encoder_stable&quot;&gt;December 5th, 2015, The native FFmpeg AAC encoder is now stable!&lt;/h3&gt;
&lt;p&gt;After seven years the native FFmpeg AAC encoder has had its experimental flag removed and declared as ready for general use. The encoder is transparent at 128kbps for most samples tested with artifacts only appearing in extreme cases. Subjective quality tests put the encoder to be of equal or greater quality than most of the other encoders available to the public.&lt;/p&gt;
&lt;p&gt;Licensing has always been an issue with encoding AAC audio as most of the encoders have had a license making FFmpeg unredistributable if compiled with support for them. The fact that there now exists a fully open and truly free AAC encoder integrated directly within the project means a lot to those who wish to use accepted and widespread standards.&lt;/p&gt;
&lt;p&gt;The majority of the work done to bring the encoder up to quality was started during this year's GSoC by developer Claudio Freire and Rostislav Pehlivanov. Both continued to work on the encoder with the latter joining as a developer and mainainer, working on other parts of the project as well. Also, thanks to &lt;a href=&quot;http://d.hatena.ne.jp/kamedo2/&quot;&gt;Kamedo2&lt;/a&gt; who does comparisons and tests, the original authors and all past and current contributors to the encoder. Users are suggested and encouraged to use the encoder and provide feedback or breakage reports through our &lt;a href=&quot;https://trac.ffmpeg.org/&quot;&gt;bug tracker&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A big thank you note goes to our newest supporters: MediaHub and Telepoint. Both companies have donated a dedicated server with free of charge internet connectivity. Here is a little bit about them in their own words:&lt;/p&gt;
&lt;ul readability=&quot;1.9683098591549&quot;&gt;&lt;li readability=&quot;2.9239436619718&quot;&gt;
&lt;p&gt;&lt;a href=&quot;http://www.telepoint.bg/en/&quot;&gt;Telepoint&lt;/a&gt; is the biggest carrier-neutral data center in Bulgaria. Located in the heart of Sofia on a cross-road of many Bulgarian and International networks, the facility is a fully featured Tier 3 data center that provides flexible customer-oriented colocation solutions (ranging from a server to a private collocation hall) and a high level of security.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;MediaHub Ltd. is a Bulgarian IPTV platform and services provider which uses FFmpeg heavily since it started operating a year ago. &lt;em&gt;&quot;Donating to help keep FFmpeg online is our way of giving back to the community&quot;&lt;/em&gt; .&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Thanks Telepoint and MediaHub for their support!&lt;/p&gt;
&lt;h3 id=&quot;gsoc2015_result&quot;&gt;September 29th, 2015, GSoC 2015 results&lt;/h3&gt;
&lt;p&gt;FFmpeg participated to the latest edition of the &lt;a href=&quot;http://www.google-melange.com/gsoc/homepage/google/gsoc2015&quot;&gt;Google Summer of Code&lt;/a&gt; Project. FFmpeg got a total of 8 assigned projects, and 7 of them were successful.&lt;/p&gt;
&lt;p&gt;We want to thank &lt;a href=&quot;https://www.google.com&quot;&gt;Google&lt;/a&gt;, the participating students, and especially the mentors who joined this effort. We're looking forward to participating in the next GSoC edition!&lt;/p&gt;
&lt;p&gt;Below you can find a brief description of the final outcome of each single project.&lt;/p&gt;
&lt;h4&gt;Basic servers for network protocols, mentee: Stephan Holljes, mentor: Nicolas George&lt;/h4&gt;
&lt;p&gt;Stephan Holljes's project for this session of Google Summer of Code was to implement basic HTTP server features for libavformat, to complement the already present HTTP client and RTMP and RTSP server code.&lt;/p&gt;
&lt;p&gt;The first part of the project was to make the HTTP code capable of accepting a single client; it was completed partly during the qualification period and partly during the first week of the summer. Thanks to this work, it is now possible to make a simple HTTP stream using the following commands:&lt;/p&gt;
&lt;pre&gt;
    ffmpeg -i /dev/video0 -listen 1 -f matroska \
    -c:v libx264 -preset fast -tune zerolatency http://:8080
    ffplay http://localhost:8080/
  
&lt;/pre&gt;
&lt;p&gt;The next part of the project was to extend the code to be able to accept several clients, simultaneously or consecutively. Since libavformat did not have an API for that kind of task, it was necessary to design one. This part was mostly completed before the midterm and applied shortly afterwards. Since the ffmpeg command-line tool is not ready to serve several clients, the test ground for that new API is an example program serving hard-coded content.&lt;/p&gt;
&lt;p&gt;The last and most ambitious part of the project was to update ffserver to make use of the new API. It would prove that the API is usable to implement real HTTP servers, and expose the points where more control was needed. By the end of the summer, a first working patch series was undergoing code review.&lt;/p&gt;
&lt;h4&gt;Browsing content on the server, mentee: Mariusz Szczepańczyk, mentor: Lukasz Marek&lt;/h4&gt;
&lt;p&gt;Mariusz finished an API prepared by the FFmpeg community and implemented Samba directory listing as qualification task.&lt;/p&gt;
&lt;p&gt;During the program he extended the API with the possibility to remove and rename files on remote servers. He completed the implementation of these features for file, Samba, SFTP, and FTP protocols.&lt;/p&gt;
&lt;p&gt;At the end of the program, Mariusz provided a sketch of an implementation for HTTP directory listening.&lt;/p&gt;
&lt;h4&gt;Directshow digital video capture, mentee: Mate Sebok, mentor: Roger Pack&lt;/h4&gt;
&lt;p&gt;Mate was working on directshow input from digital video sources. He got working input from ATSC input sources, with specifiable tuner.&lt;/p&gt;
&lt;p&gt;The code has not been committed, but a patch of it was sent to the ffmpeg-devel mailing list for future use.&lt;/p&gt;
&lt;p&gt;The mentor plans on cleaning it up and committing it, at least for the ATSC side of things. Mate and the mentor are still working trying to finally figure out how to get DVB working.&lt;/p&gt;
&lt;h4&gt;Implementing full support for 3GPP Timed Text Subtitles, mentee: Niklesh Lalwani, mentor: Philip Langdale&lt;/h4&gt;
&lt;p&gt;Niklesh's project was to expand our support for 3GPP Timed Text subtitles. This is the native subtitle format for mp4 containers, and is interesting because it's usually the only subtitle format supported by the stock playback applications on iOS and Android devices.&lt;/p&gt;
&lt;p&gt;ffmpeg already had basic support for these subtitles which ignored all formatting information - it just provided basic plain-text support.&lt;/p&gt;
&lt;p&gt;Niklesh did work to add support on both the encode and decode side for text formatting capabilities, such as font size/colour and effects like bold/italics, highlighting, etc.&lt;/p&gt;
&lt;p&gt;The main challenge here is that Timed Text handles formatting in a very different way from most common subtitle formats. It uses a binary encoding (based on mp4 boxes, naturally) and stores information separately from the text itself. This requires additional work to track which parts of the text formatting applies to, and explicitly dealing with overlapping formatting (which other formats support but Timed Text does not) so it requires breaking the overlapping sections into separate non-overlapping ones with different formatting.&lt;/p&gt;
&lt;p&gt;Finally, Niklesh had to be careful about not trusting any size information in the subtitles - and that's no joke: the now infamous Android stagefright bug was in code for parsing Timed Text subtitles.&lt;/p&gt;
&lt;p&gt;All of Niklesh's work is committed and was released in ffmpeg 2.8.&lt;/p&gt;
&lt;h4&gt;libswscale refactoring, mentee: Pedro Arthur, mentors: Michael Niedermayer, Ramiro Polla&lt;/h4&gt;
&lt;p&gt;Pedro Arthur has modularized the vertical and horizontal scalers. To do this he designed and implemented a generic filter framework and moved the existing scaler code into it. These changes now allow easily adding removing, splitting or merging processing steps. The implementation was benchmarked and several alternatives were tried to avoid speed loss.&lt;/p&gt;
&lt;p&gt;He also added gamma corrected scaling support. An example to use gamma corrected scaling would be:&lt;/p&gt;
&lt;pre&gt;
    ffmpeg -i input -vf scale=512:384:gamma=1 output
  
&lt;/pre&gt;
&lt;p&gt;Pedro has done impressive work considering the short time available, and he is a FFmpeg committer now. He continues to contribute to FFmpeg, and has fixed some bugs in libswscale after GSoC has ended.&lt;/p&gt;
&lt;h4&gt;AAC Encoder Improvements, mentee: Rostislav Pehlivanov, mentor: Claudio Freire&lt;/h4&gt;
&lt;p&gt;Rostislav Pehlivanov has implemented PNS, TNS, I/S coding and main prediction on the native AAC encoder. Of all those extensions, only TNS was left in a less-than-usable state, but the implementation has been pushed (disabled) anyway since it's a good basis for further improvements.&lt;/p&gt;
&lt;p&gt;PNS replaces noisy bands with a single scalefactor representing the energy of that band, gaining in coding efficiency considerably, and the quality improvements on low bitrates are impressive for such a simple feature.&lt;/p&gt;
&lt;p&gt;TNS still needs some polishing, but has the potential to reduce coding artifacts by applying noise shaping in the temporal domain (something that is a source of annoying, notable distortion on low-entropy bands).&lt;/p&gt;
&lt;p&gt;Intensity Stereo coding (I/S) can double coding efficiency by exploiting strong correlation between stereo channels, most effective on pop-style tracks that employ panned mixing. The technique is not as effective on classic X-Y recordings though.&lt;/p&gt;
&lt;p&gt;Finally, main prediction improves coding efficiency by exploiting correlation among successive frames. While the gains have not been huge at this point, Rostislav has remained active even after the GSoC, and is polishing both TNS and main prediction, as well as looking for further improvements to make.&lt;/p&gt;
&lt;p&gt;In the process, the MIPS port of the encoder was broken a few times, something he's also working to fix.&lt;/p&gt;
&lt;h4&gt;Animated Portable Network Graphics (APNG), mentee: Donny Yang, mentor: Paul B Mahol&lt;/h4&gt;
&lt;p&gt;Donny Yang implemented basic keyframe only APNG encoder as the qualification task. Later he wrote interframe compression via various blend modes. The current implementation tries all blend modes and picks one which takes the smallest amount of memory.&lt;/p&gt;
&lt;p&gt;Special care was taken to make sure that the decoder plays correctly all files found in the wild and that the encoder produces files that can be played in browsers that support APNG.&lt;/p&gt;
&lt;p&gt;During his work he was tasked to fix any encountered bug in the decoder due to the fact that it doesn't match APNG specifications. Thanks to this work, a long standing bug in the PNG decoder has been fixed.&lt;/p&gt;
&lt;p&gt;For latter work he plans to continue working on the encoder, making it possible to select which blend modes will be used in the encoding process. This could speed up encoding of APNG files.&lt;/p&gt;
&lt;h3 id=&quot;pr2.8&quot;&gt;September 9th, 2015, FFmpeg 2.8&lt;/h3&gt;
&lt;p&gt;We published release &lt;strong&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_2.8&quot;&gt;2.8&lt;/a&gt;&lt;/strong&gt; as new major version. It contains all features and bug fixes of the git master branch from September 8th. Please see the &lt;strong&gt;&lt;a href=&quot;https://raw.githubusercontent.com/FFmpeg/FFmpeg/release/2.8/Changelog&quot;&gt;changelog&lt;/a&gt;&lt;/strong&gt; for a list of the most important changes.&lt;/p&gt;
&lt;p&gt;We recommend users, distributors and system integrators to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;message&quot;&gt;August 1st, 2015, A message from the FFmpeg project&lt;/h3&gt;
&lt;p&gt;Dear multimedia community,&lt;/p&gt;
&lt;p&gt;The resignation of Michael Niedermayer as leader of FFmpeg yesterday has come by surprise. He has worked tirelessly on the FFmpeg project for many years and we must thank him for the work that he has done. We hope that in the future he will continue to contribute to the project. In the coming weeks, the FFmpeg project will be managed by the active contributors.&lt;/p&gt;
&lt;p&gt;The last four years have not been easy for our multimedia community - both contributors and users. We should now look to the future, try to find solutions to these issues, and to have reconciliation between the forks, which have split the community for so long.&lt;/p&gt;
&lt;p&gt;Unfortunately, much of the disagreement has taken place in inappropriate venues so far, which has made finding common ground and solutions difficult. We aim to discuss this in our communities online over the coming weeks, and in person at the &lt;a href=&quot;https://www.videolan.org/videolan/events/vdd15/&quot;&gt;VideoLAN Developer Days&lt;/a&gt; in Paris in September: a neutral venue for the entire open source multimedia community.&lt;/p&gt;
&lt;p&gt;The FFmpeg project.&lt;/p&gt;
&lt;h3 id=&quot;needhost&quot;&gt;July 4th, 2015, FFmpeg needs a new host&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;UPDATE:&lt;/strong&gt; We have received more than 7 offers for hosting and servers, thanks a lot to everyone!&lt;/p&gt;
&lt;p&gt;After graciously hosting our projects (&lt;a href=&quot;http://www.ffmpeg.org&quot;&gt;FFmpeg&lt;/a&gt;, &lt;a href=&quot;http://www.mplayerhq.hu&quot;&gt;MPlayer&lt;/a&gt; and &lt;a href=&quot;http://rtmpdump.mplayerhq.hu&quot;&gt;rtmpdump&lt;/a&gt;) for 4 years, Arpi (our hoster) has informed us that we have to secure a new host somewhere else immediately.&lt;/p&gt;
&lt;p&gt;If you want to host an open source project, please let us know, either on &lt;a href=&quot;http://ffmpeg.org/mailman/listinfo/ffmpeg-devel&quot;&gt;ffmpeg-devel&lt;/a&gt; mailing list or irc.freenode.net #ffmpeg-devel.&lt;/p&gt;
&lt;p&gt;We use about 4TB of storage and at least 4TB of bandwidth / month for various mailing lists, &lt;a href=&quot;http://trac.ffmpeg.org&quot;&gt;trac&lt;/a&gt;, &lt;a href=&quot;http://samples.ffmpeg.org&quot;&gt;samples repo&lt;/a&gt;, svn, etc.&lt;/p&gt;
&lt;h3 id=&quot;pr2.6.1&quot;&gt;March 16, 2015, FFmpeg 2.6.1&lt;/h3&gt;
&lt;p&gt;We have made a new major release (&lt;strong&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_2.6&quot;&gt;2.6&lt;/a&gt;&lt;/strong&gt;) and now one week afterward 2.6.1. It contains all features and bugfixes of the git master branch from the 6th March. Please see the &lt;strong&gt;&lt;a href=&quot;http://git.videolan.org/?p=ffmpeg.git;a=blob;f=RELEASE_NOTES;hb=release/2.6&quot;&gt;Release Notes&lt;/a&gt;&lt;/strong&gt; for a list of note-worthy changes.&lt;/p&gt;
&lt;p&gt;We recommend users, distributors and system integrators to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;gsoc2015&quot;&gt;March 4, 2015, Google Summer of Code&lt;/h3&gt;
&lt;p&gt;FFmpeg has been accepted as a &lt;a href=&quot;http://www.google-melange.com/gsoc/homepage/google/gsoc2015&quot;&gt;Google Summer of Code&lt;/a&gt; Project. If you wish to participate as a student see our &lt;a href=&quot;https://trac.ffmpeg.org/wiki/SponsoringPrograms/GSoC/2015&quot;&gt;project ideas page&lt;/a&gt;. You can already get in contact with mentors and start working on qualification tasks. Registration at Google for students will open March 16th. Good luck!&lt;/p&gt;
&lt;h3 id=&quot;clt2015&quot;&gt;March 1, 2015, Chemnitzer Linux-Tage&lt;/h3&gt;
&lt;p&gt;We happily announce that FFmpeg will be represented at Chemnitzer Linux-Tage (CLT) in Chemnitz, Germany. The event will take place on 21st and 22nd of March.&lt;/p&gt;
&lt;p&gt;More information can be found &lt;a href=&quot;https://chemnitzer.linux-tage.de/2015/en/&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We demonstrate usage of FFmpeg, answer your questions and listen to your problems and wishes. &lt;strong&gt;If you have media files that cannot be processed correctly with FFmpeg, be sure to have a sample with you so we can have a look!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For the first time in our CLT history, there will be an &lt;strong&gt;FFmpeg workshop&lt;/strong&gt;! You can read the details &lt;a href=&quot;https://chemnitzer.linux-tage.de/2015/de/programm/beitrag/209&quot;&gt;here&lt;/a&gt;. The workshop is targeted at FFmpeg beginners. First the basics of multimedia will be covered. Thereafter you will learn how to use that knowledge and the FFmpeg CLI tools to analyse and process media files. The workshop is in German language only and prior registration is necessary. The workshop will be on Saturday starting at 10 o'clock.&lt;/p&gt;
&lt;p&gt;We are looking forward to meet you (again)!&lt;/p&gt;
&lt;h3 id=&quot;pr2.5&quot;&gt;December 5, 2014, FFmpeg 2.5&lt;/h3&gt;
&lt;p&gt;We have made a new major release (&lt;strong&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_2.5&quot;&gt;2.5&lt;/a&gt;&lt;/strong&gt;) It contains all features and bugfixes of the git master branch from the 4th December. Please see the &lt;strong&gt;&lt;a href=&quot;http://git.videolan.org/?p=ffmpeg.git;a=blob;f=RELEASE_NOTES;hb=release/2.5&quot;&gt;Release Notes&lt;/a&gt;&lt;/strong&gt; for a list of note-worthy changes.&lt;/p&gt;
&lt;p&gt;We recommend users, distributors and system integrators to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;ffmpeg_back_in_sid&quot;&gt;October 10, 2014, FFmpeg is in Debian unstable again&lt;/h3&gt;
&lt;p&gt;We wanted you to know there are &lt;a href=&quot;https://packages.debian.org/search?keywords=ffmpeg&amp;amp;searchon=sourcenames&amp;amp;suite=unstable&amp;amp;section=main&quot;&gt;FFmpeg packages in Debian unstable&lt;/a&gt; again. &lt;strong&gt;A big thank-you to Andreas Cadhalpun and all the people that made it possible.&lt;/strong&gt; It has been anything but simple.&lt;/p&gt;
&lt;p&gt;Unfortunately that was already the easy part of this news. The bad news is the packages probably won't migrate to Debian testing to be in the upcoming release codenamed jessie. &lt;a href=&quot;https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=763148&quot;&gt;Read the argumentation over at Debian.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;However things will come out in the end, we hope for your continued remarkable support!&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;opw03&quot;&gt;October 8, 2014, FFmpeg secured a place in OPW!&lt;/h3&gt;
&lt;p&gt;Thanks to a generous 6K USD donation by Samsung (Open Source Group), FFmpeg will be welcoming at least 1 &quot;Outreach Program for Women&quot; intern to work with our community for an initial period starting December 2014 (through March 2015).&lt;/p&gt;
&lt;p&gt;We all know FFmpeg is used by the industry, but even while there are countless products building on our code, it is not at all common for companies to step up and help us out when needed. So a big thank-you to Samsung and the OPW program committee!&lt;/p&gt;
&lt;p&gt;If you are thinking on participating in OPW as an intern, please take a look at our &lt;a href=&quot;https://trac.ffmpeg.org/wiki/SponsoringPrograms/OPW/2014-12&quot;&gt;OPW wiki page&lt;/a&gt; for some initial guidelines. The page is still a work in progress, but there should be enough information there to get you started. If you, on the other hand, are thinking on sponsoring work on FFmpeg through the OPW program, please get in touch with us at opw@ffmpeg.org. With your help, we might be able to secure some extra intern spots for this round!&lt;/p&gt;
&lt;h3 id=&quot;pr2.4&quot;&gt;September 15, 2014, FFmpeg 2.4&lt;/h3&gt;
&lt;p&gt;We have made a new major release (&lt;strong&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_2.4&quot;&gt;2.4&lt;/a&gt;&lt;/strong&gt;) It contains all features and bugfixes of the git master branch from the 14th September. Please see the &lt;strong&gt;&lt;a href=&quot;http://git.videolan.org/?p=ffmpeg.git;a=blob;f=RELEASE_NOTES;hb=release/2.4&quot;&gt;Release Notes&lt;/a&gt;&lt;/strong&gt; for a list of note-worthy changes.&lt;/p&gt;
&lt;p&gt;We recommend users, distributors and system integrators to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;pr2.3.3&quot;&gt;August 20, 2014, FFmpeg 2.3.3, 2.2.7, 1.2.8&lt;/h3&gt;
&lt;p&gt;We have made several new point releases (&lt;strong&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_2.3&quot;&gt;2.3.3&lt;/a&gt;, &lt;a href=&quot;http://ffmpeg.org/download.html#release_2.2&quot;&gt;2.2.7&lt;/a&gt;, &lt;a href=&quot;http://ffmpeg.org/download.html#release_1.2&quot;&gt;1.2.8&lt;/a&gt;&lt;/strong&gt;). They fix various bugs, as well as CVE-2014-5271 and CVE-2014-5272. Please see the changelog for more details.&lt;/p&gt;
&lt;p&gt;We recommend users, distributors and system integrators to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;opw02&quot;&gt;July 29, 2014, Help us out securing our spot in OPW&lt;/h3&gt;
&lt;p&gt;Following our previous post regarding our participation on this year's OPW (Outreach Program for Women), we are now reaching out to our users (both individuals and companies) to help us gather the needed money to secure our spot in the program.&lt;br/&gt;We need to put together 6K USD as a minimum but securing more funds would help us towards getting more than one intern.&lt;br/&gt;You can donate by credit card using &lt;a href=&quot;https://co.clickandpledge.com/advanced/default.aspx?wid=56226&quot;&gt;Click&amp;amp;Pledge&lt;/a&gt; and selecting the &quot;OPW&quot; option. If you would like to donate by money transfer or by check, please get in touch by &lt;a href=&quot;mailto:opw@ffmpeg.org&quot;&gt;e-mail&lt;/a&gt; and we will get back to you with instructions.&lt;br/&gt;Thanks!&lt;/p&gt;
&lt;h3 id=&quot;newweb&quot;&gt;July 20, 2014, New website&lt;/h3&gt;
&lt;p&gt;The FFmpeg project is proud to announce a brand new version of the website made by &lt;a href=&quot;http://db0.fr&quot;&gt;db0&lt;/a&gt;. While this was initially motivated by the need for a larger menu, the whole website ended up being redesigned, and most pages got reworked to ease navigation. We hope you'll enjoy browsing it.&lt;/p&gt;
&lt;h3 id=&quot;pr2.3&quot;&gt;July 17, 2014, FFmpeg 2.3&lt;/h3&gt;
&lt;p&gt;We have made a new major release (&lt;strong&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_2.3&quot;&gt;2.3&lt;/a&gt;&lt;/strong&gt;) It contains all features and bugfixes of the git master branch from the 16th July. Please see the &lt;strong&gt;&lt;a href=&quot;http://git.videolan.org/?p=ffmpeg.git;a=blob;f=RELEASE_NOTES;hb=489d066&quot;&gt;Release Notes&lt;/a&gt;&lt;/strong&gt; for a list of note-worthy changes.&lt;/p&gt;
&lt;p&gt;We recommend users, distributors and system integrators to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;opw01&quot;&gt;July 3, 2014, FFmpeg and the Outreach Program For Women&lt;/h3&gt;
&lt;p&gt;FFmpeg has started the process to become an OPW includer organization for the next round of the program, with internships starting December 9. The &lt;a href=&quot;https://gnome.org/opw/&quot;&gt;OPW&lt;/a&gt; aims to &quot;Help women (cis and trans) and genderqueer to get involved in free and open source software&quot;. Part of the process requires securing funds to support at least one internship (6K USD), so if you were holding on your donation to FFmpeg, this is a great chance for you to come forward, get in touch and help both the project and a great initiative!&lt;/p&gt;
&lt;p&gt;We have set up an &lt;a href=&quot;mailto:opw@ffmpeg.org&quot;&gt;email address&lt;/a&gt; you can use to contact us about donations and general inquires regarding our participation in the program. Hope to hear from you soon!&lt;/p&gt;
&lt;h3 id=&quot;pr2.2.4&quot;&gt;June 29, 2014, FFmpeg 2.2.4, 2.1.5, 2.0.5, 1.2.7, 1.1.12, 0.10.14&lt;/h3&gt;
&lt;p&gt;We have made several new point releases (&lt;strong&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_2.2&quot;&gt;2.2.4&lt;/a&gt;, &lt;a href=&quot;http://ffmpeg.org/download.html#release_2.1&quot;&gt;2.1.5&lt;/a&gt;, &lt;a href=&quot;http://ffmpeg.org/download.html#release_2.0&quot;&gt;2.0.5&lt;/a&gt;, &lt;a href=&quot;http://ffmpeg.org/download.html#release_1.2&quot;&gt;1.2.7&lt;/a&gt;, &lt;a href=&quot;http://ffmpeg.org/download.html#release_1.1&quot;&gt;1.1.12&lt;/a&gt;, &lt;a href=&quot;http://ffmpeg.org/download.html#release_0.10&quot;&gt;0.10.14&lt;/a&gt;&lt;/strong&gt;). They fix a &lt;a href=&quot;http://blog.securitymouse.com/2014/06/raising-lazarus-20-year-old-bug-that.html&quot;&gt;security issue in the LZO implementation&lt;/a&gt;, as well as several other bugs. See the git log for details.&lt;/p&gt;
&lt;p&gt;We recommend users, distributors and system integrators to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;lt2014&quot;&gt;May 1, 2014, LinuxTag&lt;/h3&gt;
&lt;p&gt;Once again FFmpeg will be represented at LinuxTag in Berlin, Germany. The event will take place from 8th to 10th of May. Please note that this year's LinuxTag is at a different location closer to the city center.&lt;/p&gt;
&lt;p&gt;We will have a shared booth with XBMC and VideoLAN. &lt;strong&gt;If you have media files that cannot be processed correctly with FFmpeg, be sure to have a sample with you so we can have a look!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;More information about LinuxTag can be found &lt;a href=&quot;http://www.linuxtag.org/2014/&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We are looking forward to see you in Berlin!&lt;/p&gt;
&lt;h3 id=&quot;heartbleed&quot;&gt;April 18, 2014, OpenSSL Heartbeat bug&lt;/h3&gt;
&lt;p&gt;Our server hosting the Trac issue tracker was vulnerable to the attack against OpenSSL known as &quot;heartbleed&quot;. The OpenSSL software library was updated on 7th of April, shortly after the vulnerability was publicly disclosed. We have changed the private keys (and certificates) for all FFmpeg servers. The details were sent to the mailing lists by Alexander Strasser, who is part of the project server team. Here is a link to the user mailing list &lt;a href=&quot;https://lists.ffmpeg.org/pipermail/ffmpeg-user/2014-April/020968.html&quot;&gt;archive&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;We encourage you to read up on &lt;a href=&quot;https://www.schneier.com/blog/archives/2014/04/heartbleed.html&quot;&gt;&quot;OpenSSL heartbleed&quot;&lt;/a&gt;. &lt;strong&gt;It is possible that login data for the issue tracker was exposed to people exploiting this security hole. You might want to change your password in the tracker and everywhere else you used that same password.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;pr2.2.1&quot;&gt;April 11, 2014, FFmpeg 2.2.1&lt;/h3&gt;
&lt;p&gt;We have made a new point releases (&lt;strong&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_2.2&quot;&gt;2.2.1&lt;/a&gt;&lt;/strong&gt;). It contains bug fixes for Tickets #2893, #3432, #3469, #3486, #3495 and #3540 as well as several other fixes. See the git log for details.&lt;/p&gt;
&lt;h3 id=&quot;pr2.2&quot;&gt;March 24, 2014, FFmpeg 2.2&lt;/h3&gt;
&lt;p&gt;We have made a new major release (&lt;strong&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_2.2&quot;&gt;2.2&lt;/a&gt;&lt;/strong&gt;) It contains all features and bugfixes of the git master branch from 1st March. A partial list of new stuff is below:&lt;/p&gt;
&lt;pre&gt;
    - HNM version 4 demuxer and video decoder
    - Live HDS muxer
    - setsar/setdar filters now support variables in ratio expressions
    - elbg filter
    - string validation in ffprobe
    - support for decoding through VDPAU in ffmpeg (the -hwaccel option)
    - complete Voxware MetaSound decoder
    - remove mp3_header_compress bitstream filter
    - Windows resource files for shared libraries
    - aeval filter
    - stereoscopic 3d metadata handling
    - WebP encoding via libwebp
    - ATRAC3+ decoder
    - VP8 in Ogg demuxing
    - side &amp;amp; metadata support in NUT
    - framepack filter
    - XYZ12 rawvideo support in NUT
    - Exif metadata support in WebP decoder
    - OpenGL device
    - Use metadata_header_padding to control padding in ID3 tags (currently used in
    MP3, AIFF, and OMA files), FLAC header, and the AVI &quot;junk&quot; block.
    - Mirillis FIC video decoder
    - Support DNx444
    - libx265 encoder
    - dejudder filter
    - Autodetect VDA like all other hardware accelerations
  
&lt;/pre&gt;
&lt;p&gt;We recommend users, distributors and system integrators to upgrade unless they use current git master.&lt;/p&gt;
&lt;h3 id=&quot;clt2014&quot;&gt;February 3, 2014, Chemnitzer Linux-Tage&lt;/h3&gt;
&lt;p&gt;We happily announce that FFmpeg will be represented at `Chemnitzer Linux-Tage' in Chemnitz, Germany. The event will take place on 15th and 16th of March.&lt;/p&gt;
&lt;p&gt;More information can be found &lt;a href=&quot;http://chemnitzer.linux-tage.de/2014/en/info/&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We invite you to visit us at our booth located in the Linux-Live area! There we will demonstrate usage of FFmpeg, answer your questions and listen to your problems and wishes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If you have media files that cannot be processed correctly with FFmpeg, be sure to have a sample with you so we can have a look!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We are looking forward to meet you (again)!&lt;/p&gt;
&lt;h3 id=&quot;trac_sec&quot;&gt;February 9, 2014, trac.ffmpeg.org / trac.mplayerhq.hu Security Breach&lt;/h3&gt;
&lt;p&gt;The server on which FFmpeg and MPlayer Trac issue trackers were installed was compromised. The affected server was taken offline and has been replaced and all software reinstalled. FFmpeg Git, releases, FATE, web and mailinglists are on other servers and were not affected. We believe that the original compromise happened to a server, unrelated to FFmpeg and MPlayer, several months ago. That server was used as a source to clone the VM that we recently moved Trac to. It is not known if anyone used the backdoor that was found.&lt;/p&gt;
&lt;p&gt;We recommend all users to change their passwords. &lt;strong&gt;Especially users who use a password on Trac that they also use elsewhere, should change that password at least elsewhere.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;ffmpeg_rfp&quot;&gt;November 12, 2013, FFmpeg RFP in Debian&lt;/h3&gt;
&lt;p&gt;Since the splitting of Libav the Debian/Ubuntu maintainers have followed the Libav fork. Many people have requested the packaging of ffmpeg in Debian, as it is more feature-complete and in many cases less buggy.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://cynic.cc/blog/&quot;&gt;Rogério Brito&lt;/a&gt;, a Debian developer, has proposed a Request For Package (RFP) in the Debian bug tracking system.&lt;/p&gt;
&lt;p&gt;Please let the Debian and Ubuntu developers know that you support packaging of the real FFmpeg! See Debian &lt;a href=&quot;http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=729203&quot;&gt;ticket #729203&lt;/a&gt; for more details.&lt;/p&gt;
&lt;h3 id=&quot;pr2.1&quot;&gt;October 28, 2013, FFmpeg 2.1&lt;/h3&gt;
&lt;p&gt;We have made a new major release (&lt;strong&gt;&lt;a href=&quot;http://ffmpeg.org/download.html#release_2.1&quot;&gt;2.1&lt;/a&gt;&lt;/strong&gt;) It contains all features and bugfixes of the git master branch from 28th October. A partial list of new stuff is below:&lt;/p&gt;
&lt;pre&gt;
    - aecho filter
    - perspective filter ported from libmpcodecs
    - ffprobe -show_programs option
    - compand filter
    - RTMP seek support
    - when transcoding with ffmpeg (i.e. not streamcopying), -ss is now accurate
    even when used as an input option. Previous behavior can be restored with
    the -noaccurate_seek option.
    - ffmpeg -t option can now be used for inputs, to limit the duration of
    data read from an input file
    - incomplete Voxware MetaSound decoder
    - read EXIF metadata from JPEG
    - DVB teletext decoder
    - phase filter ported from libmpcodecs
    - w3fdif filter
    - Opus support in Matroska
    - FFV1 version 1.3 is stable and no longer experimental
    - FFV1: YUVA(444,422,420) 9, 10 and 16 bit support
    - changed DTS stream id in lavf mpeg ps muxer from 0x8a to 0x88, to be
    more consistent with other muxers.
    - adelay filter
    - pullup filter ported from libmpcodecs
    - ffprobe -read_intervals option
    - Lossless and alpha support for WebP decoder
    - Error Resilient AAC syntax (ER AAC LC) decoding
    - Low Delay AAC (ER AAC LD) decoding
    - mux chapters in ASF files
    - SFTP protocol (via libssh)
    - libx264: add ability to encode in YUVJ422P and YUVJ444P
    - Fraps: use BT.709 colorspace by default for yuv, as reference fraps decoder does
    - make decoding alpha optional for prores, ffv1 and vp6 by setting
    the skip_alpha flag.
    - ladspa wrapper filter
    - native VP9 decoder
    - dpx parser
    - max_error_rate parameter in ffmpeg
    - PulseAudio output device
    - ReplayGain scanner
    - Enhanced Low Delay AAC (ER AAC ELD) decoding (no LD SBR support)
    - Linux framebuffer output device
    - HEVC decoder, raw HEVC demuxer, HEVC demuxing in TS, Matroska and MP4
    - mergeplanes filter
  
&lt;/pre&gt;
&lt;p&gt;We recommend users, distributors and system integrators to upgrade unless they use current git master.&lt;/p&gt;

</description>
<pubDate>Fri, 20 Apr 2018 21:33:46 +0000</pubDate>
<dc:creator>frakturfreund</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://ffmpeg.org/index.html</dc:identifier>
</item>
<item>
<title>Designing very large JavaScript applications</title>
<link>https://medium.com/@cramforce/designing-very-large-javascript-applications-6e013a3291a3</link>
<guid isPermaLink="true" >https://medium.com/@cramforce/designing-very-large-javascript-applications-6e013a3291a3</guid>
<description>&lt;p name=&quot;ce3f&quot; id=&quot;ce3f&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;This is a mildly edited transcript of my JSConf Australia talk. &lt;a href=&quot;https://www.youtube.com/watch?v=ZZmUwXEiPm4&quot; data-href=&quot;https://www.youtube.com/watch?v=ZZmUwXEiPm4&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;Watch the whole talk on YouTube&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*DqvlkOgHSKmp5Tu1eX5mdw.png&quot; data-width=&quot;2012&quot; data-height=&quot;1128&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*DqvlkOgHSKmp5Tu1eX5mdw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*DqvlkOgHSKmp5Tu1eX5mdw.png&quot;/&gt;&lt;/div&gt;
Slide text: Hello, I used to build very large JavaScript applications.
&lt;p name=&quot;bac5&quot; id=&quot;bac5&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Hello, I used to build very large JavaScript applications. I don’t really do that anymore, so I thought it was a good time to give a bit of a retrospective and share what I learned. Yesterday I was having a beer at the conference party and I was asked: “Hey Malte, what actually gives you the right, the authority, to talk about the topic?” and I suppose answering this is actually on topic for this talk, although I usually find it a bit weird to talk about myself. So, I build this JavaScript framework at Google. It is used by Photos, Sites, Plus, Drive, Play, the search engine, all these sites. Some of them are pretty large, you might have used a few of them.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*v0r4OVf-RXr9ePakdmv5LQ.png&quot; data-width=&quot;2016&quot; data-height=&quot;1136&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*v0r4OVf-RXr9ePakdmv5LQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*v0r4OVf-RXr9ePakdmv5LQ.png&quot;/&gt;&lt;/div&gt;
Slide text: I thought React was good.
&lt;p name=&quot;a1a0&quot; id=&quot;a1a0&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;This Javascript framework is not open source. The reason it is not open source is that it kind of came out at the same time as React and I was like “Does the world really need another JS framework to choose from?”. Google already has a few of those–Angular and Polymer–and felt like another one would confuse people, so I just thought we’d just keep it to ourselves. But besides not being open source, I think there is a lot to learn from it and it is worth sharing the things we learned along the way.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*LL3uYYDMT5uIFRxR_7JxPQ.png&quot; data-width=&quot;2016&quot; data-height=&quot;1134&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*LL3uYYDMT5uIFRxR_7JxPQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*LL3uYYDMT5uIFRxR_7JxPQ.png&quot;/&gt;&lt;/div&gt;
Picture of lots of people.
&lt;p name=&quot;e419&quot; id=&quot;e419&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;So, let’s talk about very large applications and the things they have in common. Certainly that there might be a lot of developers. It might be a few dozens or even more–and these are humans with feelings and interpersonal problems and you may have to factor that in.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*WEH24kaBbar8-1gzN_AO3w.png&quot; data-width=&quot;2016&quot; data-height=&quot;1130&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*WEH24kaBbar8-1gzN_AO3w.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*WEH24kaBbar8-1gzN_AO3w.png&quot;/&gt;&lt;/div&gt;
Picture of very old building.
&lt;p name=&quot;c9c5&quot; id=&quot;c9c5&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;And even if your team is not as big, maybe you’ve been working on the thing for a while, and maybe you’re not even the first person maintaining it, you might not have all the context, there might be stuff that you don’t really understand, there might be other people in your team that don’t understand everything about the application. These are the things we have to think about when we build very large applications.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*fzb42X35lNGmkQHhJLhEBQ.png&quot; data-width=&quot;2006&quot; data-height=&quot;1128&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*fzb42X35lNGmkQHhJLhEBQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*fzb42X35lNGmkQHhJLhEBQ.png&quot;/&gt;&lt;/div&gt;
Tweet saying: A team of senior engineers without junior engineers is a team of engineers.
&lt;p name=&quot;d2eb&quot; id=&quot;d2eb&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Another thing I wanted to do here is to give this a bit of context in terms of our careers. I think many of us would consider themselves senior engineers. Or we are not quite there yet, but we want to become one. What I think being senior means is that I’d be able to solve almost every problem that somebody might throw at me. I know my tools, I know my domain. And the other important part of that job is that I make the junior engineers eventually be senior engineers.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*xpRJ1dXHMlFq1V4oDKU__w.png&quot; data-width=&quot;2006&quot; data-height=&quot;1130&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*xpRJ1dXHMlFq1V4oDKU__w.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*xpRJ1dXHMlFq1V4oDKU__w.png&quot;/&gt;&lt;/div&gt;
Slide text: Junior -&amp;gt; Senior -&amp;gt; ?
&lt;p name=&quot;12f1&quot; id=&quot;12f1&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;But what happens is that at some point we may wonder “what might be the next step?”. When we reached that seniority stage, what is the next thing we are going to do? For some of us the answer may be management, but I don’t think that should be the answer for everyone, because not everyone should be a manager, right? Some of us are really great engineers and why shouldn’t we get to do that for the rest of our lives?&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*wL5wiTWICj1keue9YZOAhQ.png&quot; data-width=&quot;3344&quot; data-height=&quot;1892&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*wL5wiTWICj1keue9YZOAhQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*wL5wiTWICj1keue9YZOAhQ.png&quot;/&gt;&lt;/div&gt;
Slide text: “I know how I would solve the problem”
&lt;p name=&quot;2420&quot; id=&quot;2420&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;I want to propose a way to level up above that senior level. The way I would talk about myself as a senior engineer is that I’d say “I know how I would solve the problem” and because I know how I would solve it I could also teach someone else to do it.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*UyLoKH7y54JAYigVlwCJpQ.png&quot; data-width=&quot;3348&quot; data-height=&quot;1892&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*UyLoKH7y54JAYigVlwCJpQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*UyLoKH7y54JAYigVlwCJpQ.png&quot;/&gt;&lt;/div&gt;
Slide text: “I know how others would solve the problem”
&lt;p name=&quot;032b&quot; id=&quot;032b&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;And my theory is that the next level is that I can say about myself “I know how &lt;em class=&quot;markup--em markup--p-em&quot;&gt;others&lt;/em&gt; would solve the problem”.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*zBBGLRIZw94gp54pspvx-g.png&quot; data-width=&quot;2006&quot; data-height=&quot;1126&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*zBBGLRIZw94gp54pspvx-g.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*zBBGLRIZw94gp54pspvx-g.png&quot;/&gt;&lt;/div&gt;
Slide text: “I can anticipate how API choices and abstractions impact the way other people would solve the problem.”
&lt;p name=&quot;fb50&quot; id=&quot;fb50&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Let’s make that a bit more concrete. You make that sentence: “I can anticipate how the API choices that I’m making, or the abstractions that I’m introducing into a project, how they impact how other people would solve a problem.” I think this is a powerful concept that allows me to reason about how the choices I’m making impact an application.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*LnDv6Ry0Hq2MaQEARaD8rg.png&quot; data-width=&quot;2002&quot; data-height=&quot;1128&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*LnDv6Ry0Hq2MaQEARaD8rg.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*LnDv6Ry0Hq2MaQEARaD8rg.png&quot;/&gt;&lt;/div&gt;
Slide text: An application of empathy.
&lt;p name=&quot;3706&quot; id=&quot;3706&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;I would call this an application of empathy. You’re thinking with other software engineers and you’re thinking about how what you do and the APIs that you are giving them, how they impact how they write software.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*pnYiZTAfQqsbeS7kVkLe_g.png&quot; data-width=&quot;2010&quot; data-height=&quot;1122&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*pnYiZTAfQqsbeS7kVkLe_g.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*pnYiZTAfQqsbeS7kVkLe_g.png&quot;/&gt;&lt;/div&gt;
Slide text: Empathy on easy mode.
&lt;p name=&quot;4ad1&quot; id=&quot;4ad1&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Luckily this is empathy on easy mode. Empathy is generally hard, and this is still very hard. But at least the people that you are having empathy with, they are also other software engineers. And so while they might be very different from you, they at least have in common that they are building software. This type of empathy is really something you can get quite good at as you gain more experience.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*Op0wLWIqwZ-A5iSuWrqtKA.png&quot; data-width=&quot;2010&quot; data-height=&quot;1126&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*Op0wLWIqwZ-A5iSuWrqtKA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*Op0wLWIqwZ-A5iSuWrqtKA.png&quot;/&gt;&lt;/div&gt;
Slide text: Programming model
&lt;p name=&quot;c6c5&quot; id=&quot;c6c5&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Thinking about these topics there is one really important term that I want to talk about, which is the programming model–a word that I’m going to use a lot. It stands for “given a set of APIs, or of libraries, or of frameworks, or of tools–how do people write software in that context.” And my talk is really about, how subtle changes in APIs and so forth, how they impact the programming model.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*zuLA-tH9b8k4i1yfKMScmA.png&quot; data-width=&quot;2014&quot; data-height=&quot;1130&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*zuLA-tH9b8k4i1yfKMScmA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*zuLA-tH9b8k4i1yfKMScmA.png&quot;/&gt;&lt;/div&gt;
Slide text: Programming model impact examples: React, Preact, Redux, Date picker from npm, npm
&lt;p name=&quot;9633&quot; id=&quot;9633&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;I want to give a few examples of things that impact the programming model: Let’s say you have an Angular project and you say “I’m going to port this to React” that is obviously going to change how people write software, right? But then you’re like “Ah, 60KB for a bit of virtual DOM munging, let’s switch to Preact”–that is an API compatible library, it is not going to change how people write software, just because you make that choice. Maybe then you’re like “this is all really complex, I should have something orchestrating how my application works, I’m going to introduce Redux.”–that is going to change how people write software. You then get this requirement “we need a date picker” and you go to npm, there are 500 results, you pick one. Does it really matter which one you pick? It definitely won’t change how you write software. But having npm at your fingertips, this vast collection of modules, having that around absolutely changes how you write software. Of course, these are just a few examples of things that might or might impact how people write software.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*KfcGnWC3WcwBqGYLPiybgw.png&quot; data-width=&quot;2008&quot; data-height=&quot;1128&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*KfcGnWC3WcwBqGYLPiybgw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*KfcGnWC3WcwBqGYLPiybgw.png&quot;/&gt;&lt;/div&gt;
Slide text: Code splitting
&lt;p name=&quot;ed1d&quot; id=&quot;ed1d&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Now I want to talk about one aspect that all large JavaScript applications have in common, when you deliver them to users: Which is that they eventually get so big that you don’t want to deliver them all at once. And for this we’ve all introduced this technique called code splitting. What code splitting means is that you define a set of bundles for your application. So, you’re saying “Some users only use this part of my app, some users use another part”, and so you put together bundles that only get downloaded when the part of an application that a user is actually dealing with is executed. This is something all of us can do. Like many things it was invented by the closure compiler–at least in the JavaScript world. But I think the most popular way of doing code splitting is with webpack. And if you are using RollupJS, which is super awesome, they just recently added support for it as well. Definitely something y’all should do, but there are some things to think about when you introduce this to an application, because it does have impact on the programming model.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*vAR8HCbwiwX8bVa0xIsk6g.png&quot; data-width=&quot;2014&quot; data-height=&quot;1128&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*vAR8HCbwiwX8bVa0xIsk6g.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*vAR8HCbwiwX8bVa0xIsk6g.png&quot;/&gt;&lt;/div&gt;
Slide text: Sync -&amp;gt; Async
&lt;p name=&quot;c4fb&quot; id=&quot;c4fb&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;You have things that used to be sync that now become async. Without code splitting your application is nice and simple. There is this one big thing. It starts up, and then it is stable, you can reason about it, you don’t have to wait for stuff. With code splitting, you might sometimes say “Oh, I need that bundle”, so you now need to go to the network, and you have to factor in that this can happen, and so the applications becomes more complex.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*DqT7As1rm_M9cxyW1RIW6w.png&quot; data-width=&quot;2006&quot; data-height=&quot;1126&quot; data-is-featured=&quot;true&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*DqT7As1rm_M9cxyW1RIW6w.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*DqT7As1rm_M9cxyW1RIW6w.png&quot;/&gt;&lt;/div&gt;
Slide text: Human
&lt;p name=&quot;c9e2&quot; id=&quot;c9e2&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Also, we have humans entering the field, because code splitting requires you to define bundles, and it requires you to think about when to load them, so these humans, engineers on your team, they now have to make decisions what is going into which bundle and when to load that bundle. Every time you have a human involved, that clearly impacts the programming model, because they have to think about such things.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*0jNa8A5ciY6pCJCN65vLiA.png&quot; data-width=&quot;2014&quot; data-height=&quot;1130&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*0jNa8A5ciY6pCJCN65vLiA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*0jNa8A5ciY6pCJCN65vLiA.png&quot;/&gt;&lt;/div&gt;
Slide text: Route based code splitting
&lt;p name=&quot;eac7&quot; id=&quot;eac7&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;There is one very established way that solves this problem, that gets the human out of the mess when doing code splitting, which is called route based code splitting. If you’re not using code splitting yet, that is probably how you should do it as a first cut. Routes are the baseline URL structure of your application. You might, for example, have your product pages on `/product/` and you might have your category pages somewhere else. You just make each route one bundle, and your router in your application now understands there is code splitting. And whenever the user goes to a route, the router loads the associated bundle, and then within that route you can forget about code splitting existing. Now you are back to the programming model that is almost the same as having a big bundle for everything. It is a really nice way to do this, and definitely a good first step.&lt;/p&gt;
&lt;p name=&quot;40e0&quot; id=&quot;40e0&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;But the title of this talk is designing &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;VERY&lt;/strong&gt; large JavaScript applications, and they quickly become so big that a single bundle per route might not be feasible anymore, because the routes themselves become very big. I actually have a good example for an application that is big enough.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*ox94bGuhxWXE-OubL7St6w.png&quot; data-width=&quot;2010&quot; data-height=&quot;1132&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*ox94bGuhxWXE-OubL7St6w.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*ox94bGuhxWXE-OubL7St6w.png&quot;/&gt;&lt;/div&gt;
Google Search query screenshot for “public speaking 101”
&lt;p name=&quot;915e&quot; id=&quot;915e&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;I was figuring out how to become a public speaker coming up to this talk, and I get this nice list of blue links. You could totally envision that this page fits well into a single route bundle.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*P-XiIPnuzq9_KLA1nG-uRA.png&quot; data-width=&quot;2014&quot; data-height=&quot;1130&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*P-XiIPnuzq9_KLA1nG-uRA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*P-XiIPnuzq9_KLA1nG-uRA.png&quot;/&gt;&lt;/div&gt;
Google Search query screenshot for “weath”
&lt;p name=&quot;9f62&quot; id=&quot;9f62&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;But then I was wondering about the weather because California had a rough winter, and suddenly there was this completely different module. So, this seemingly simple route is more complicated than we thought.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*Y7e5LoeBggY01aRkJAiwWA.png&quot; data-width=&quot;2010&quot; data-height=&quot;1132&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*Y7e5LoeBggY01aRkJAiwWA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*Y7e5LoeBggY01aRkJAiwWA.png&quot;/&gt;&lt;/div&gt;
Google Search query screenshot for “20 usd to aud”
&lt;p name=&quot;369f&quot; id=&quot;369f&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;And then I was invited to this conference, and was checking out how much 1 US dollar is in Australian dollars, and there is this complex currency converter. Obviously there is about 1000s more of these specialized modules, and it infeasible to put them all in one bundle, because that bundle would be a few megabytes in size, and users would become really unhappy.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*qZhd4a0S-CCB5mUiN3fo5Q.png&quot; data-width=&quot;2012&quot; data-height=&quot;1122&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*qZhd4a0S-CCB5mUiN3fo5Q.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*qZhd4a0S-CCB5mUiN3fo5Q.png&quot;/&gt;&lt;/div&gt;
Slide text: Lazy load at component level?
&lt;p name=&quot;8d58&quot; id=&quot;8d58&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;So, we can’t just use route based code splitting, we have to come up with a different way of doing it. Route based code splitting was nice, because you split your app at the coarsest level, and everything further down could ignore it. Since I like simple things, how about doing super fine-grained instead of super coarse-grained splitting. Let’s think about what would happen if we lazy loaded every single component of our website. That seems really nice from an efficiency point of view when you only think about bandwidth. It might be super bad from other point of views like latency, but it is certainly worth a consideration.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*Lr2hIk4eH9uU33e77zeSmA.png&quot; data-width=&quot;2008&quot; data-height=&quot;1128&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*Lr2hIk4eH9uU33e77zeSmA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*Lr2hIk4eH9uU33e77zeSmA.png&quot;/&gt;&lt;/div&gt;
Slide text: React component statically depend on their children.
&lt;p name=&quot;e6f3&quot; id=&quot;e6f3&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;But let’s imagine, for example, your application uses React. And in React components statically depend on their children. That means if you stop doing that because you are lazy loading your children, then it changes your programming model, and things stop being so nice.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*SWkk2vyn344qCNCPSIkXPA.png&quot; data-width=&quot;2010&quot; data-height=&quot;1126&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*SWkk2vyn344qCNCPSIkXPA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*SWkk2vyn344qCNCPSIkXPA.png&quot;/&gt;&lt;/div&gt;
ES6 import example.
&lt;p name=&quot;8101&quot; id=&quot;8101&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Let’s say you have a currency converter component that you want to put on your search page, you import it, right? That is the normal way of doing it in ES6 modules.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*RxlHaYEav0OaODKYKiUubw.png&quot; data-width=&quot;2008&quot; data-height=&quot;1124&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*RxlHaYEav0OaODKYKiUubw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*RxlHaYEav0OaODKYKiUubw.png&quot;/&gt;&lt;/div&gt;
Loadable component example.
&lt;p name=&quot;66fa&quot; id=&quot;66fa&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;But if you want to lazy load it, you get code like this where you use dynamic import, which is a new fancy thing to lazy load ES6 modules and you wrap it in a loadable component. There are certainly 500 million ways to do this, and I am not a React expert, but all of these will change how you write the application.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*N5AMAbobPjsO_lXCPt9-ZA.png&quot; data-width=&quot;2006&quot; data-height=&quot;1122&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*N5AMAbobPjsO_lXCPt9-ZA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*N5AMAbobPjsO_lXCPt9-ZA.png&quot;/&gt;&lt;/div&gt;
Slide text: Static -&amp;gt; Dynanic
&lt;p name=&quot;7cf9&quot; id=&quot;7cf9&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;And things aren’t as nice anymore–something that was static, now becomes dynamic, which is another red flag for the programming model changing.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*j9OB_yjli59MZMyIs9V0_A.png&quot; data-width=&quot;2006&quot; data-height=&quot;1128&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*j9OB_yjli59MZMyIs9V0_A.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*j9OB_yjli59MZMyIs9V0_A.png&quot;/&gt;&lt;/div&gt;
Slide text: Who decides what to lazy load when?
&lt;p name=&quot;a925&quot; id=&quot;a925&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;You have to suddenly wonder: “Who decides what to lazy load when” because that is going to impact the latency of your application.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*rsJ-C7ph0BrJiwTjHKv6_w.png&quot; data-width=&quot;2010&quot; data-height=&quot;1124&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*rsJ-C7ph0BrJiwTjHKv6_w.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*rsJ-C7ph0BrJiwTjHKv6_w.png&quot;/&gt;&lt;/div&gt;
Slide text: Static or dynamic?
&lt;p name=&quot;a9c7&quot; id=&quot;a9c7&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The human is there again and they have to think about “there is static import, there is dynamic import, when do I use which?”. Getting this wrong is really bad because one static import, when it should have been dynamic suddenly may put stuff into the same bundle that shouldn’t be. These are the things that are going to go wrong when you have a lot of engineers over long periods of time.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*QGoX4bYhEAuNjuKwQhQ0hg.png&quot; data-width=&quot;2010&quot; data-height=&quot;1126&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*QGoX4bYhEAuNjuKwQhQ0hg.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*QGoX4bYhEAuNjuKwQhQ0hg.png&quot;/&gt;&lt;/div&gt;
Slide text: Split logic and rendering
&lt;p name=&quot;850c&quot; id=&quot;850c&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Now I’m going to talk about how Google actually does this and what is one way to get a good programming model, while also achieving good performance. What we do is we take our components and we split them by rendering logic, and by application logic, like what happens when you press a button on that currency converter.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*vMskVnAwJgkZmvl4E-8E4Q.png&quot; data-width=&quot;2010&quot; data-height=&quot;1126&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*vMskVnAwJgkZmvl4E-8E4Q.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*vMskVnAwJgkZmvl4E-8E4Q.png&quot;/&gt;&lt;/div&gt;
Slide text: Only load logic if it was rendered.
&lt;p name=&quot;a69e&quot; id=&quot;a69e&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;So, now we have two separate things, and we only ever load the application logic for a component when we previously rendered it. This turns out to be a very simple model, because you can simply server side render a page, and then whatever was actually rendered, triggers downloading the associated application bundles. This puts the human out of the system, as loading is triggered automatically by rendering.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*Doqt-GOkUp13Qgk5r7WR1g.png&quot; data-width=&quot;2012&quot; data-height=&quot;1128&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*Doqt-GOkUp13Qgk5r7WR1g.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*Doqt-GOkUp13Qgk5r7WR1g.png&quot;/&gt;&lt;/div&gt;
Slide text: Currency converter on search result page.
&lt;p name=&quot;0584&quot; id=&quot;0584&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;This model may seem nice, but it does have some tradeoffs. If you know how server side rendering typically works in frameworks like React or Vue.js, what they do is a process called hydration. The way hydration works, is you server side render something, and then on the client you render it again, which means you have to load the code to render something that is already on the page, which is incredibly wasteful both in terms of loading the code and in terms of executing it. It is a bunch of wasted bandwidth, it is a bunch of wasted CPU–but it is really nice, because you get to ignore on the client side that you server side rendered something. The method we use at Google is not like that. So, if you design this very large application, you have think about: Do I take that super fast method that is more complicated, or do I go with hydration which is less efficient, but such a nice programming model? You will have to make this decision.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*uteTbmuKZF1wGvoysgsBYw.png&quot; data-width=&quot;2006&quot; data-height=&quot;1124&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*uteTbmuKZF1wGvoysgsBYw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*uteTbmuKZF1wGvoysgsBYw.png&quot;/&gt;&lt;/div&gt;
Slide text: 2017 Happy New Year
&lt;p name=&quot;bf5a&quot; id=&quot;bf5a&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;My next topic is my favorite problem in computer science–which is not naming things, although I probably gave this a bad name. It is the &lt;em class=&quot;markup--em markup--p-em&quot;&gt;“2017 holiday special problem”&lt;/em&gt;. Who here has ever written some code, and now it is no longer needed but it is still in your codebase? … This happens, and I think CSS is particularly famous for it. You have this one big CSS file. There is this selector in there. Who really knows whether that still matches anything in your app? So, you end up just keeping it there. I think the CSS community is at the forefront of a revolution, because they realized this is a problem, and they created solutions like CSS-in-JS. With that you have a single file component, the 2017HolidaySpecialComponent, and you can say “it is not 2017 anymore” and you can delete the whole component and everything is gone in one swoop. That makes it very easy to delete code. I think this is a very big idea, and it should be applied to more than just CSS.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*rkAN_sLohIO63JCOTZ1JgA.png&quot; data-width=&quot;2000&quot; data-height=&quot;1124&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*rkAN_sLohIO63JCOTZ1JgA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*rkAN_sLohIO63JCOTZ1JgA.png&quot;/&gt;&lt;/div&gt;
Slide text: Avoid central configuration at all cost
&lt;p name=&quot;bd5a&quot; id=&quot;bd5a&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;I want to give a few examples of this general idea that you want to avoid central configuration of your application at all cost, because central configuration, like having a central CSS file, makes it very hard to delete code.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*-OoPTo-xaxFr2YOGGFnapw.png&quot; data-width=&quot;3348&quot; data-height=&quot;1876&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*-OoPTo-xaxFr2YOGGFnapw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*-OoPTo-xaxFr2YOGGFnapw.png&quot;/&gt;&lt;/div&gt;
Slide text: routes.js
&lt;p name=&quot;3406&quot; id=&quot;3406&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;I was talking before about routes in your application. Many applications would have a file like “routes.js” that has all your routes, and then those routes map themselves to some root component. That is an example of central configuration, something you do not want in a large application. Because with this some engineer says “Do I still need that root component? I need to update that other file, that is owned by some other team. Not sure I’m allowed to change it. Maybe I’ll do it tomorrow”. With that these files becomes addition-only.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*NsqgsGwmgEcy_PedNzmnbQ.png&quot; data-width=&quot;3352&quot; data-height=&quot;1876&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*NsqgsGwmgEcy_PedNzmnbQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*NsqgsGwmgEcy_PedNzmnbQ.png&quot;/&gt;&lt;/div&gt;
Slide text: webpack.config.js
&lt;p name=&quot;56ca&quot; id=&quot;56ca&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Another example of this anti-pattern is the webpack.config.js file, where you have this one thing that is assumed to build your entire application. That might go fine for a while, but eventually needing to know about every aspect of what some other team did somewhere in the app just doesn’t scale. Once again, we need a pattern to emerge how to decentralize the configuration of our build process.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*L7ZmdS2JvqwWJySz-X50xw.png&quot; data-width=&quot;3348&quot; data-height=&quot;1876&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*L7ZmdS2JvqwWJySz-X50xw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*L7ZmdS2JvqwWJySz-X50xw.png&quot;/&gt;&lt;/div&gt;
Slide text: package.json
&lt;p name=&quot;a36a&quot; id=&quot;a36a&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Here is a good example: package.json, which is used by npm. Every package says “I have these dependencies, this is how you run me, this is how you build me”. Obviously there can’t be one giant configuration file for all of npm. That just wouldn’t work with hundreds of thousands of files. It would definitely get you a lot of merge conflicts in git. Sure, npm is very big, but I’d argue that many of our applications get big enough that we have to worry about the same kind of problems and have to adopt the same kind of patterns. I don’t have all the solutions, but I think that the idea that CSS-in-JS brought to the table is going to come to other aspects of our applications.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*E_g_WgMXGuJtyG-F4AGTNg.png&quot; data-width=&quot;2010&quot; data-height=&quot;1122&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*E_g_WgMXGuJtyG-F4AGTNg.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*E_g_WgMXGuJtyG-F4AGTNg.png&quot;/&gt;&lt;/div&gt;
Slide text: Dependency trees
&lt;p name=&quot;c4aa&quot; id=&quot;c4aa&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;More abstractly I would describe this idea that we take responsibility for how our application is designed in the abstract, how it is organized, as &lt;em class=&quot;markup--em markup--p-em&quot;&gt;taking responsibility of shaping the dependency tree of our application&lt;/em&gt;. When I say “dependency” I mean that very abstractly. It could be module dependencies, it could be data dependencies, service dependencies, there are many different kinds.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*DfOMmyxC4guVZkyQ4IlF7g.png&quot; data-width=&quot;2008&quot; data-height=&quot;1122&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*DfOMmyxC4guVZkyQ4IlF7g.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*DfOMmyxC4guVZkyQ4IlF7g.png&quot;/&gt;&lt;/div&gt;
Slide text: Example dependency tree with router and 3 root components.
&lt;p name=&quot;dde3&quot; id=&quot;dde3&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Obviously, we all have super complicated applications, but I’m going to use a very simple example. It has only 4 components. It has a router that knows how to go from one route of your application to the next, and it has a few root components, A, B, and C.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*CivPR-20NP0dXlIkWfBk6w.png&quot; data-width=&quot;2006&quot; data-height=&quot;1122&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*CivPR-20NP0dXlIkWfBk6w.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*CivPR-20NP0dXlIkWfBk6w.png&quot;/&gt;&lt;/div&gt;
Slide text: The central import problem.
&lt;p name=&quot;65aa&quot; id=&quot;65aa&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;As I mentioned before this has the central import problem.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*Y9AgFj90bpFsKq6e7o7Jbw.png&quot; data-width=&quot;2008&quot; data-height=&quot;1124&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*Y9AgFj90bpFsKq6e7o7Jbw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*Y9AgFj90bpFsKq6e7o7Jbw.png&quot;/&gt;&lt;/div&gt;
Slide text: Example dependency tree with router and 3 root components. Router imports root components.
&lt;p name=&quot;49a7&quot; id=&quot;49a7&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Because the router now has to import all the root components, and if you want to delete one of them you have to go to the router, you have to delete the import, you have to delete the route, and eventually you have the holiday special 2017 problem.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*isSwE9e1XLiEw9sbZHwmQQ.png&quot; data-width=&quot;3348&quot; data-height=&quot;1878&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*isSwE9e1XLiEw9sbZHwmQQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*isSwE9e1XLiEw9sbZHwmQQ.png&quot;/&gt;&lt;/div&gt;
Slide text: Import -&amp;gt; Enhance
&lt;p name=&quot;d05b&quot; id=&quot;d05b&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;We at Google have come up with a solution for this, that I want to introduce to you, which I don’t think we have ever talked about. We invented a new concept. It is called enhance. It is something you use instead of import.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*7yPG-uXeixsnQk3k-X9UXw.png&quot; data-width=&quot;3336&quot; data-height=&quot;1848&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*7yPG-uXeixsnQk3k-X9UXw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*7yPG-uXeixsnQk3k-X9UXw.png&quot;/&gt;&lt;/div&gt;
Slide text: Import -&amp;gt; Enhance
&lt;p name=&quot;acca&quot; id=&quot;acca&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;In fact, it is the opposite of import. It is a reverse dependency. If you enhance a module, you make that module have a dependency on you.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*bDH4yzG0mrrYlrs2C9twsA.png&quot; data-width=&quot;2010&quot; data-height=&quot;1120&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*bDH4yzG0mrrYlrs2C9twsA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*bDH4yzG0mrrYlrs2C9twsA.png&quot;/&gt;&lt;/div&gt;
Slide text: Example dependency tree with router and 3 root components. Root components enhance router.
&lt;p name=&quot;d715&quot; id=&quot;d715&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Looking at the dependency graph, what happens it that there are still the same components, but the arrows point in the opposite direction. So, instead of the router importing the root component, the root components announce themselves using enhance to the router. This means I can get rid of a root component by just deleting the file. Because it is no longer enhancing the router, that is the only operation you have to do to delete the component.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*HDW95QuGKQCsXqwXiUtB5g.png&quot; data-width=&quot;2006&quot; data-height=&quot;1120&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*HDW95QuGKQCsXqwXiUtB5g.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*HDW95QuGKQCsXqwXiUtB5g.png&quot;/&gt;&lt;/div&gt;
Slide text: Who decides when to use enhance?
&lt;p name=&quot;868d&quot; id=&quot;868d&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;That is really nice, if it wasn’t for the humans again. They now have to think about “Do I import something, or do I use enhance? Which one do I use under which circumstances?”.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*Hr47VQZYSKiBuDap2XgbbQ.png&quot; data-width=&quot;2012&quot; data-height=&quot;1126&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*Hr47VQZYSKiBuDap2XgbbQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*Hr47VQZYSKiBuDap2XgbbQ.png&quot;/&gt;&lt;/div&gt;
Image: Danger. Hazardous chemicals.
&lt;p name=&quot;e4f6&quot; id=&quot;e4f6&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;This is particular bad case of this problem, because the power of enhancing a module, of being able to make everything else in the system have a dependency on you is very powerful and very dangerous if gotten wrong. It is easy to imagine that this might lead to really bad situations. So, at Google we decided it is a nice idea, but we make it illegal, nobody gets to use it–with one exception: generated code. It is a really good fit for generated code actually, and it solves some of the inherent problems of generated code. With generated code you sometimes have to import files you can’t even see, have to guess their names. If, however, the generated file is just there in the shadows and enhances whatever it needs, then you don’t have these problems. You never have to know about these files at all. They just magically enhance the central registry.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*od_6cmgitlBJk1g9QxU7Ng.png&quot; data-width=&quot;2008&quot; data-height=&quot;1128&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*od_6cmgitlBJk1g9QxU7Ng.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*od_6cmgitlBJk1g9QxU7Ng.png&quot;/&gt;&lt;/div&gt;
Slide text: Single file component pointing to its parts that enhance a router.
&lt;p name=&quot;7824&quot; id=&quot;7824&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Let’s take a look at a concrete example. We have our single file component here. We run a code generator on it and we extract this little route definition file from it. And that route file just says “Hey Router, here I am, please import me”. And obviously you can use this pattern for all kinds of other things. Maybe you are using GraphQL and your router should know about your data dependency, then you can just use the same pattern.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*Tg_CvUNzT9K0tbzIVC79kw.png&quot; data-width=&quot;2010&quot; data-height=&quot;1128&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*Tg_CvUNzT9K0tbzIVC79kw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*Tg_CvUNzT9K0tbzIVC79kw.png&quot;/&gt;&lt;/div&gt;
Slide text: The base bundle
&lt;p name=&quot;34c7&quot; id=&quot;34c7&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Unfortunately this is not all we need to know. There is my second favorite problem in computer science which I call the “&lt;em class=&quot;markup--em markup--p-em&quot;&gt;Base bundle pile of trash”&lt;/em&gt;. The base bundle in your graph of bundles in your application is the one bundle that will always get loaded–independent of how the user interacts with the application. So, it is particularly important, because if it is big, then everything further down will also be big. If it small, then dependent bundles at least have a chance of being small as well. A little anecdote: At some point I joined the Google Plus JavaScript infrastructure team, and I found out that their base bundle had 800KB of JavaScript. So, my warning to you is: If you want to be more successful than Google Plus, don’t have 800KB of JS in your base bundle. Unfortunately it is very easy to get to such a bad state.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*wW_u72nFdPiKjEINH4ubDg.png&quot; data-width=&quot;2012&quot; data-height=&quot;1126&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*wW_u72nFdPiKjEINH4ubDg.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*wW_u72nFdPiKjEINH4ubDg.png&quot;/&gt;&lt;/div&gt;
Slide text: Base bundle pointing to 3 different dependencies.
&lt;p name=&quot;e8e8&quot; id=&quot;e8e8&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Here is an example. Your base bundle needs to depend on the routes, because when you go from A to B, you need to already know the route for B, so it has to always be around. But what you really don’t want in the base bundle is any form of UI code, because depending on how a user enters your app, there might be different UI. So, for example the date picker should absolutely not be in your base bundle, and neither should the checkout flow. But how do we prevent that? Unfortunately imports are very fragile. You might innocently import that cool &lt;em class=&quot;markup--em markup--p-em&quot;&gt;util&lt;/em&gt; package, because it has a function to make random numbers. And now somebody says “I need a utility for self driving cars” and suddenly you import the machine learning algorithms for self driving cars into your base bundle. Things like that can happen very easily since imports are transitive, and so things tend to pile up over time.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*myk-tffGyQx74OIZT4n0mw.png&quot; data-width=&quot;2004&quot; data-height=&quot;1130&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*myk-tffGyQx74OIZT4n0mw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*myk-tffGyQx74OIZT4n0mw.png&quot;/&gt;&lt;/div&gt;
Slide text: Forbidden dependency tests.
&lt;p name=&quot;0f82&quot; id=&quot;0f82&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The solution we found for this are &lt;em class=&quot;markup--em markup--p-em&quot;&gt;forbidden dependency tests&lt;/em&gt;. Forbidden dependency tests are a way to assert that for example your base bundle does not depend on any UI.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*vDtioYTfzhCB9e7jc9A4pg.png&quot; data-width=&quot;2006&quot; data-height=&quot;1126&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*vDtioYTfzhCB9e7jc9A4pg.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*vDtioYTfzhCB9e7jc9A4pg.png&quot;/&gt;&lt;/div&gt;
Slide text: Assert that base bundle does not depend on React.Component
&lt;p name=&quot;1daa&quot; id=&quot;1daa&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Let’s take a look at a concrete example. In React every component needs to inherit from React.Component. So , if your goal is that no UI could ever be in the base bundle just add this one test that asserts that React.Component is not a transitive dependency of your base bundle.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*s5rDafWJi90dcrlEQSAepg.png&quot; data-width=&quot;2008&quot; data-height=&quot;1120&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*s5rDafWJi90dcrlEQSAepg.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*s5rDafWJi90dcrlEQSAepg.png&quot;/&gt;&lt;/div&gt;
Forbidden dependencies crossed out.
&lt;p name=&quot;4a91&quot; id=&quot;4a91&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Looking at the previous example again, you just get a test failure when someone wants to add the date picker. And these test failures are typically very easy to fix right then, because usually that person didn’t really mean to add the dependency–it just crept in through some transitive path. Compare this to when this dependency would have been around for 2 years because you didn’t have a test. In those cases it is typically extremely hard to refactor your code to get rid of the dependency.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*ONmcxDRRdY9DpR8QfwMj4g.png&quot; data-width=&quot;2006&quot; data-height=&quot;1120&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*ONmcxDRRdY9DpR8QfwMj4g.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*ONmcxDRRdY9DpR8QfwMj4g.png&quot;/&gt;&lt;/div&gt;
Slide text: The most natural path
&lt;p name=&quot;765f&quot; id=&quot;765f&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Ideally though, you find that most natural path.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*7XRIRO-_Y165Gn7Zff_fKQ.png&quot; data-width=&quot;2008&quot; data-height=&quot;1128&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*7XRIRO-_Y165Gn7Zff_fKQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*7XRIRO-_Y165Gn7Zff_fKQ.png&quot;/&gt;&lt;/div&gt;
Slide text: Most straightforward way must be the right way.
&lt;p name=&quot;27d5&quot; id=&quot;27d5&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;You want to get to a state where whatever the engineers on your team do, the most straightforward way is also the right way–so that they don’t get off the path, so that they naturally do the right thing.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*T6E-ExC2HWa0X--OiJ_vAA.png&quot; data-width=&quot;2012&quot; data-height=&quot;1124&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*T6E-ExC2HWa0X--OiJ_vAA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*T6E-ExC2HWa0X--OiJ_vAA.png&quot;/&gt;&lt;/div&gt;
Slide text: Otherwise add a test that ensure the right way,
&lt;p name=&quot;6cc9&quot; id=&quot;6cc9&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;This might not always be possible. In that case just add a test. But this is not something that many people feel empowered to do. But &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;please feel empowered to add tests to your application that ensure the major invariants of your infrastructure&lt;/strong&gt;. Tests are not only for testing that your math functions do the right thing. They are also for infrastructure and for the major design features of your application.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*y3COuLXS8b1vAQQESjp30Q.png&quot; data-width=&quot;2010&quot; data-height=&quot;1128&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*y3COuLXS8b1vAQQESjp30Q.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*y3COuLXS8b1vAQQESjp30Q.png&quot;/&gt;&lt;/div&gt;
Slide text: Avoid human judgement outside of application domain.
&lt;p name=&quot;ab16&quot; id=&quot;ab16&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Try to avoid human judgement whenever possible outside of the application domain. When working on an application we have to understand the business, but not every engineer in your organization can and will understand how code splitting works. And they don’t need to do that. Try to introduce these thing into your application in a way that is fine when not everybody understands them and keeps the complexity in their heads.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*CqeGbdnSFMRPtZWPIRZCvw.png&quot; data-width=&quot;2004&quot; data-height=&quot;1126&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*CqeGbdnSFMRPtZWPIRZCvw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*CqeGbdnSFMRPtZWPIRZCvw.png&quot;/&gt;&lt;/div&gt;
Slide text: Make it easy to delete code.
&lt;p name=&quot;86ce&quot; id=&quot;86ce&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;And really just make it easy to delete code. My talk is called “building very large JavaScript applications”. The best advice I can give: Don’t let your applications get very large. The best way to not get there is to delete stuff before it is too late.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*Mt_beSIamHND0E6NjBBetA.png&quot; data-width=&quot;2006&quot; data-height=&quot;1120&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*Mt_beSIamHND0E6NjBBetA.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*Mt_beSIamHND0E6NjBBetA.png&quot;/&gt;&lt;/div&gt;
Slide text: No abstraction is better than the wrong abstraction.
&lt;p name=&quot;9553&quot; id=&quot;9553&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;I want to address just one more point, which is that people sometimes say that having no abstractions at all is better than having the wrong abstractions. What this really means is that the cost of the wrong abstraction is very high, so be careful. I think this is sometimes misinterpreted. It does not mean that you should have no abstractions. It just means you have to be very careful.&lt;/p&gt;
&lt;blockquote name=&quot;d28d&quot; id=&quot;d28d&quot; class=&quot;graf graf--pullquote graf-after--p&quot; readability=&quot;5&quot;&gt;
&lt;p&gt;W&lt;em class=&quot;markup--em markup--pullquote-em&quot;&gt;e have to become good at finding the right abstractions&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*oNXlH0ththqRlPeRm2z0Sw.png&quot; data-width=&quot;2008&quot; data-height=&quot;1120&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*oNXlH0ththqRlPeRm2z0Sw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*oNXlH0ththqRlPeRm2z0Sw.png&quot;/&gt;&lt;/div&gt;
Slide text: Empathy and experience -&amp;gt; Right abstractions.
&lt;p name=&quot;1fe3&quot; id=&quot;1fe3&quot; class=&quot;graf graf--p graf-after--figure graf--trailing&quot;&gt;As I was saying at the start of the presentation: The way to get there is to use empathy and think with your engineers on your team about how they will use your APIs and how they will use your abstractions. Experience is how you flesh out that empathy over time. Put together, empathy and experience is what enables you to choose the right abstractions for your application&lt;/p&gt;
</description>
<pubDate>Fri, 20 Apr 2018 20:28:29 +0000</pubDate>
<dc:creator>kawera</dc:creator>
<og:title>Designing very large (JavaScript) applications – Malte Ubl – Medium</og:title>
<og:url>https://medium.com/@cramforce/designing-very-large-javascript-applications-6e013a3291a3</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*DqT7As1rm_M9cxyW1RIW6w.png</og:image>
<og:description>This is a mildly edited transcript of my JSConf Australia talk. Watch the whole talk on YouTube.</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://medium.com/@cramforce/designing-very-large-javascript-applications-6e013a3291a3</dc:identifier>
</item>
<item>
<title>Rethinking GPS: Engineering Next-Gen Location at Uber</title>
<link>https://ubere.ng/2qLlaFH</link>
<guid isPermaLink="true" >https://ubere.ng/2qLlaFH</guid>
<description>&lt;p&gt;&lt;span&gt;Location and navigation using&lt;/span&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Global_Positioning_System&quot;&gt;&lt;span&gt;global positioning systems&lt;/span&gt;&lt;/a&gt; &lt;span&gt;(GPS) is deeply embedded in our daily lives, and is particularly crucial to Uber’s services. To orchestrate quick, efficient pickups, our GPS technologies need to know the locations of matched riders and drivers, as well as provide navigation guidance from a driver’s current location to where the rider needs to be picked up, and then, to the rider’s chosen destination. For this process to work seamlessly, the location estimates for riders and drivers need to be as precise as possible.  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Since&lt;/span&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Global_Positioning_System&quot;&gt;&lt;span&gt;the (literal!) launch of GPS in 1973&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, we have advanced our understanding of the world, experienced exponential growth in the computational power available to us, and developed powerful algorithms to model uncertainty from fields like robotics. While our lives have become increasingly dependent on GPS, the fundamentals of how GPS works have not changed that much, which leads to significant performance limitations. In our opinion, it is time to rethink some of the starting assumptions that were true in 1973 regarding where and how we use GPS, as well as the computational power and additional information we can bring to bear to improve it.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;While GPS works well under clear skies, its location estimates can be wildly inaccurate (with a margin of error of 50 meters or more) when we need it the most: in densely populated and highly built-up urban areas, where many of our users are located. To overcome this challenge, we developed a software upgrade to GPS for Android which substantially improves location accuracy in urban environments via a client-server architecture that utilizes 3D maps and performs sophisticated probabilistic computations on GPS data available through&lt;/span&gt; &lt;a href=&quot;https://developer.android.com/guide/topics/sensors/gnss.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;Android’s GNSS APIs&lt;/span&gt;&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;In this article, we discuss why GPS can perform poorly in urban environments and outline how we fix it using advanced signal processing algorithms deployed at scale on our server infrastructure.&lt;/span&gt;&lt;/p&gt;
&lt;div id=&quot;attachment_1324&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;35&quot;&gt;&lt;a href=&quot;http://eng.uber.com/wp-content/uploads/2017/07/image3.gif&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img class=&quot;wp-image-1324 size-full&quot; src=&quot;https://eng.uber.com/wp-content/uploads/2017/07/image3.gif&quot; alt=&quot;&quot; width=&quot;1416&quot; height=&quot;980&quot;/&gt;&lt;/a&gt;
&lt;p class=&quot;wp-caption-text&quot;&gt;Figure 1: The above GIF offers a comparison of standard GPS (red) against our improved location estimate (blue) for a pickup from Uber HQ in San Francisco. Our estimated location closely follows the true path taken by the rider, while GPS shows very large excursions.&lt;/p&gt;
&lt;/div&gt;

&lt;h3&gt;&lt;span&gt;A bit of background on GPS/GNSS&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;Before discussing our approach in detail, let us do a quick recap of how GPS works in order to understand why it can be inaccurate in high-rise urban environments.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;GPS is a network of more than 30 satellites operated by the U.S. government, orbiting the earth at an altitude of about 20,000 kilometers. (Most cell phones these days can pick up similar Russian “&lt;/span&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/GLONASS&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;GLONASS&lt;/span&gt;&lt;/a&gt;&lt;span&gt;” satellites too.)  These satellites send out radio frequency signals that GPS receivers, such as those found in cell phones, can lock onto. Importantly, these satellites advertise the time at which they launch their signals.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;For each satellite whose signal the receiver processes, the difference between reception time and launch time (time-of-flight), multiplied by the speed of light, is called the&lt;/span&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Pseudorange&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;pseudorange&lt;/span&gt;&lt;/a&gt;&lt;em&gt;&lt;span&gt;.&lt;/span&gt;&lt;/em&gt; &lt;span&gt;If the satellite and receiver’s clocks are synchronized, and the signal travels along the straight line-of-sight path, then this would equal the actual distance to the satellite. However, the clocks are not synchronized, so the receiver needs to solve for four unknowns, its own 3D coordinates on the globe, and its clock bias. Thus, we need a minimum of four satellites (four equations) to solve for these four unknowns.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;If we ignore clock bias, we can intuitively interpret the location estimate performed by the GPS receiver by intersecting spheres centered at the satellites with the radius of each sphere given by the pseudorange. In practice, a GPS receiver processes signals from a significantly larger number of satellites (up to 20 GPS and GLONASS satellites are visible in an open field), and having more than the minimum number of equations provides extra robustness to noise, blockages, etc. &lt;/span&gt;&lt;span&gt;In addition to GPS and GLONASS, some new/future receivers can/will process signals from other satellite systems.  Other navigation satellite systems coming online are&lt;/span&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Galileo_(satellite_navigation)&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;Galileo&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, operated by the European Union,&lt;/span&gt; &lt;span&gt;IRNSS&lt;/span&gt; &lt;span&gt;in India, and&lt;/span&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/BeiDou_Navigation_Satellite_System&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;BeiDou&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, operated by China. The more general term&lt;/span&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Satellite_navigation&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;GNSS&lt;/span&gt;&lt;/a&gt; &lt;span&gt;(global navigation satellite systems) encompasses these systems. (We will use this term in the remainder of the article.)  &lt;/span&gt;&lt;/p&gt;
&lt;div id=&quot;attachment_1325&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;34&quot;&gt;&lt;img class=&quot;wp-image-1325&quot; src=&quot;https://eng.uber.com/wp-content/uploads/2017/07/image1-4-968x1024.png&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;635&quot; srcset=&quot;https://eng.uber.com/wp-content/uploads/2017/07/image1-4-968x1024.png 968w, https://eng.uber.com/wp-content/uploads/2017/07/image1-4-284x300.png 284w, https://eng.uber.com/wp-content/uploads/2017/07/image1-4-768x812.png 768w&quot; sizes=&quot;(max-width: 600px) 100vw, 600px&quot;/&gt;&lt;p class=&quot;wp-caption-text&quot;&gt;Figure 2: In this simplified interpretation of GPS receiver computation, spheres intersect at the center of known satellite locations.&lt;/p&gt;
&lt;/div&gt;

&lt;h3&gt;&lt;span&gt;Why GNSS location is inaccurate in urban environments&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;A major assumption behind GNSS-based positioning is that the receiver has a direct line-of-sight to each satellite whose pseudorange it is computing. This works seamlessly in open terrain but really breaks down in urban environments, as shown in Figure 3, below:&lt;/span&gt;&lt;/p&gt;
&lt;div id=&quot;attachment_3071&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;32&quot;&gt;&lt;a href=&quot;http://eng.uber.com/wp-content/uploads/2018/04/image9.jpg&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img class=&quot;wp-image-3071&quot; src=&quot;https://eng.uber.com/wp-content/uploads/2018/04/image9.jpg&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;338&quot; srcset=&quot;https://eng.uber.com/wp-content/uploads/2018/04/image9.jpg 1920w, https://eng.uber.com/wp-content/uploads/2018/04/image9-300x169.jpg 300w, https://eng.uber.com/wp-content/uploads/2018/04/image9-768x432.jpg 768w, https://eng.uber.com/wp-content/uploads/2018/04/image9-1024x576.jpg 1024w&quot; sizes=&quot;(max-width: 600px) 100vw, 600px&quot;/&gt;&lt;/a&gt;
&lt;p class=&quot;wp-caption-text&quot;&gt;Figure 3: Line-of-sight blockage and strong reflections can cause large GPS errors.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;span&gt;Buildings often block the lines of sight to satellites, so the receiver frequently processes signals corresponding to strong reflections off of other buildings. The significant inaccuracy (positive offsets) in pseudoranges resulting from this phenomenon can lead to errors in position estimates that can be 50 meters or more in urban canyons. Most of us who have wandered,  driven around, or requested an Uber in big cities have experienced these problems first hand.&lt;/span&gt;&lt;/p&gt;

&lt;h3&gt;&lt;span&gt;Satellite signal strengths to the rescue&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;Our approach to improving location accuracy makes a feature out of the very blockage of GNSS signals that causes trouble for standard receivers.  How? For Android phones, the LocationManager API provides not just the phone’s position estimate, but also the signal-to-noise ratio (SNR) for each GNSS satellite in view. If we put this “signal strength” information together with 3D maps, then we can obtain very valuable location information. Figure 4, below, shows a simplified version of how satellite SNRs and 3D maps can be used to infer which side of the street we are on:&lt;/span&gt;&lt;/p&gt;
&lt;div id=&quot;attachment_3072&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;35&quot;&gt;&lt;a href=&quot;http://eng.uber.com/wp-content/uploads/2018/04/image8.jpg&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img class=&quot;wp-image-3072&quot; src=&quot;https://eng.uber.com/wp-content/uploads/2018/04/image8.jpg&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;338&quot; srcset=&quot;https://eng.uber.com/wp-content/uploads/2018/04/image8.jpg 1920w, https://eng.uber.com/wp-content/uploads/2018/04/image8-300x169.jpg 300w, https://eng.uber.com/wp-content/uploads/2018/04/image8-768x432.jpg 768w, https://eng.uber.com/wp-content/uploads/2018/04/image8-1024x576.jpg 1024w&quot; sizes=&quot;(max-width: 600px) 100vw, 600px&quot;/&gt;&lt;/a&gt;
&lt;p class=&quot;wp-caption-text&quot;&gt;Figure 4: Satellite signal strengths, when combined with 3D maps, provide valuable location information.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;span&gt;Zooming into the details, our approach relies on putting the following intuition in a mathematical framework: if the SNR for a satellite is low, then the line-of-sight path is probably blocked or shadowed; if the SNR is high, then the LOS is probably clear. The qualifier “probably” is crucial here: even when the receiver is in a shadowed area, strong reflected signals can still reach it, and even if it is in a clear area, the received signal can be weak (because of destructive interference between LOS and reflected paths, a phenomenon referred to as&lt;/span&gt; &lt;a href=&quot;http://www.radio-electronics.com/info/propagation/multipath/multipath-fading.php&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;multipath fading&lt;/span&gt;&lt;/a&gt;&lt;span&gt;).  Also, in general, the 3D map is not entirely accurate, and certainly does not capture random blockages by large moving objects not in the map, like trucks. This adds additional uncertainty to the process.  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;&lt;span&gt;Probabilistic shadow matching using ray tracing&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;While the intuition on satellite signal strengths carrying useful location information is sound, it must be fleshed out within a probabilistic framework. For any possible location for the receiver, we can check whether the ray joining the location to the satellite is blocked using our 3D map. Now, using a model for the probability distribution of the SNR under LOS and shadowed conditions, we determine the likelihood of the SNR measured for that satellite. For example, if the location is shadowed, then the likelihood of a high SNR is low. The overall likelihood of a given location, based on the satellite SNRs, is the product of the likelihoods corresponding to the different satellites. By doing this over a grid of possible locations, we obtain a likelihood surface—or heat map—of possible receiver locations, based on satellite signal strengths alone. We call this procedure&lt;/span&gt; &lt;a href=&quot;http://www.insidegnss.com/node/4628&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;probabilistic shadow matching&lt;/span&gt;&lt;/a&gt;&lt;em&gt;&lt;span&gt;.&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;
&lt;div id=&quot;attachment_1328&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;33&quot;&gt;&lt;img class=&quot;wp-image-1328&quot; src=&quot;https://eng.uber.com/wp-content/uploads/2017/07/image8-2-1024x622.png&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;364&quot; srcset=&quot;https://eng.uber.com/wp-content/uploads/2017/07/image8-2-1024x622.png 1024w, https://eng.uber.com/wp-content/uploads/2017/07/image8-2-300x182.png 300w, https://eng.uber.com/wp-content/uploads/2017/07/image8-2-768x467.png 768w, https://eng.uber.com/wp-content/uploads/2017/07/image8-2.png 1508w&quot; sizes=&quot;(max-width: 600px) 100vw, 600px&quot;/&gt;&lt;p class=&quot;wp-caption-text&quot;&gt;Figure 5: Ray tracing from one possible location to each satellite for probabilistic shadow matching. This is done for thousands of hypothesized locations.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;span&gt;The likelihood surface, or heat map, from probabilistic shadow matching summarizes the information from satellite SNR measurements. However, as we see from Figure 6 below, this heat map can be pretty complicated. It can have many distinct, widely separated hotpots (local maxima) often corresponding to a given side of the street, but sometimes still in the wrong location (i.e., phantoms).  In order to narrow down our location estimate and to avoid locking onto the phantoms, we must now fuse this information with even more information.&lt;/span&gt;&lt;/p&gt;
&lt;div id=&quot;attachment_1329&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;38&quot;&gt;&lt;img class=&quot;wp-image-1329&quot; src=&quot;https://eng.uber.com/wp-content/uploads/2017/07/image9-2-1024x530.png&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;310&quot; srcset=&quot;https://eng.uber.com/wp-content/uploads/2017/07/image9-2-1024x530.png 1024w, https://eng.uber.com/wp-content/uploads/2017/07/image9-2-300x155.png 300w, https://eng.uber.com/wp-content/uploads/2017/07/image9-2-768x397.png 768w&quot; sizes=&quot;(max-width: 600px) 100vw, 600px&quot;/&gt;&lt;p class=&quot;wp-caption-text&quot;&gt;Figure 6. A location heat map computed based on satellite signal strengths can have many hotspots. In the above example, our improved location estimate (blue path, black uncertainty ellipse) follows ground truth (yellow path), whereas standard GPS (red path, gray uncertainty ellipse) is inaccurate.&lt;/p&gt;
&lt;/div&gt;
&lt;h4&gt;&lt;span&gt;Information fusion via particle filter&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;&lt;span&gt;For Android phones, the information we use in addition to satellite signal strengths is usually just the standard GNSS position fix, but can also be Android Fused locations, which may include WiFi-based positioning. Since this location can be very inaccurate, single time instant (one-shot) fusion of GNSS fix with shadow matching likelihoods typically leads to poor performance.  In order to take advantage of the information from satellite signal strengths, we trust GPS less in built-up areas (the gray GPS uncertainty ellipse in Figure 6 is a typical model that we use, while the black uncertainty ellipse for improved GPS is an output of our algorithm). We therefore use past measurements and constrain the location evolution over time using a motion model adapted to the application (e.g., pedestrian vs. vehicular motion). This is accomplished by using a&lt;/span&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Particle_filter&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;particle filter&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, which approximates the probability distribution of the receiver’s location at any given time by a set of weighted particles. In other words, we estimate where the phone is using thousands of hypothesized locations (i.e., particles).  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Over time, the probability weights and particle locations evolve based on the measurements and the motion model. Since the heat map from probabilistic shadow matching has so many local maxima and because the GNSS fix can have such large outliers, we cannot use standard techniques such as the&lt;/span&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Kalman_filter&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;Kalman filter&lt;/span&gt;&lt;/a&gt; &lt;span&gt;or the&lt;/span&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Extended_Kalman_filter&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;extended Kalman filter&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, which rely on the tracked probability distribution being well approximated by a bell-shaped&lt;/span&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Normal_distribution&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;Gaussian distribution&lt;/span&gt;&lt;/a&gt;&lt;span&gt;. The particle filter allows us to approximate arbitrary distributions, at the expense of higher complexity, and this is where our server infrastructure comes in.&lt;/span&gt;&lt;/p&gt;
&lt;div id=&quot;attachment_1330&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;36&quot;&gt;&lt;img class=&quot;wp-image-1330&quot; src=&quot;https://eng.uber.com/wp-content/uploads/2017/07/image5-3-1024x493.png&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;289&quot; srcset=&quot;https://eng.uber.com/wp-content/uploads/2017/07/image5-3-1024x493.png 1024w, https://eng.uber.com/wp-content/uploads/2017/07/image5-3-300x145.png 300w, https://eng.uber.com/wp-content/uploads/2017/07/image5-3-768x370.png 768w&quot; sizes=&quot;(max-width: 600px) 100vw, 600px&quot;/&gt;&lt;p class=&quot;wp-caption-text&quot;&gt;Figure 7: The location estimate obtained as the weighted centroid of the hotspot provided by the particle filter often corrects very large GPS errors. The uncertainty radius (white circle) for improved GPS is based on the spread of the particle set, and is often a more realistic measure than the small uncertainty radius (black circle) typically reported for raw GPS even when the actual position errors are large.&lt;/p&gt;
&lt;/div&gt;

&lt;h3&gt;&lt;span&gt;From signal processing to software at scale&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;The combination of particle filtering and ray tracing introduces complexity to the back-end server ecosystem, making for a very stateful service.&lt;/span&gt;&lt;/p&gt;
&lt;div id=&quot;attachment_1331&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;39&quot;&gt;&lt;img class=&quot;wp-image-1331&quot; src=&quot;https://eng.uber.com/wp-content/uploads/2017/07/image2-2-1024x707.png&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;415&quot; srcset=&quot;https://eng.uber.com/wp-content/uploads/2017/07/image2-2-1024x707.png 1024w, https://eng.uber.com/wp-content/uploads/2017/07/image2-2-300x207.png 300w, https://eng.uber.com/wp-content/uploads/2017/07/image2-2-768x531.png 768w&quot; sizes=&quot;(max-width: 600px) 100vw, 600px&quot;/&gt;&lt;p class=&quot;wp-caption-text&quot;&gt;Figure 8: Uber’s GPS improvement system is composed of a particle filter service, 3D map tile management service, a manager service, Uber HTTP API, and cloud storage, and integrates with other Uber services.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;span&gt;There are two kinds of state at play: per-user particle filter state and per-region 3D maps used for ray tracing. The use of particle filters necessitates a level of server affinity. Each new request to our service must be routed to the same back-end server for processing in order to update the correct particle filter. Additionally, due to the large size of 3D maps, each back-end server can only hold a few small sections of the 3D world in RAM.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Since each server can only hold a few square kilometers of map data, not all servers are capable of serving all users. Essentially, implementing the back-end systems for our solution necessitated the creation of a sticky session routing layer that takes server 3D map state into account. In addition to internal tests and performance evaluations, we also run spot checks on our own Android devices using an internal version of the Uber rider app, as illustrated in Figure 9, below:&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter wp-image-3074&quot; src=&quot;https://eng.uber.com/wp-content/uploads/2018/04/image4-1.png&quot; alt=&quot;&quot; width=&quot;300&quot; height=&quot;110&quot; srcset=&quot;https://eng.uber.com/wp-content/uploads/2018/04/image4-1.png 778w, https://eng.uber.com/wp-content/uploads/2018/04/image4-1-300x110.png 300w, https://eng.uber.com/wp-content/uploads/2018/04/image4-1-768x280.png 768w&quot; sizes=&quot;(max-width: 300px) 100vw, 300px&quot;/&gt;&lt;/p&gt;
&lt;div id=&quot;attachment_3073&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;33&quot;&gt;&lt;a href=&quot;http://eng.uber.com/wp-content/uploads/2018/04/image7.png&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img class=&quot;wp-image-3073&quot; src=&quot;https://eng.uber.com/wp-content/uploads/2018/04/image7.png&quot; alt=&quot;&quot; width=&quot;400&quot; height=&quot;711&quot; srcset=&quot;https://eng.uber.com/wp-content/uploads/2018/04/image7.png 1080w, https://eng.uber.com/wp-content/uploads/2018/04/image7-169x300.png 169w, https://eng.uber.com/wp-content/uploads/2018/04/image7-768x1365.png 768w, https://eng.uber.com/wp-content/uploads/2018/04/image7-576x1024.png 576w&quot; sizes=&quot;(max-width: 400px) 100vw, 400px&quot;/&gt;&lt;/a&gt;
&lt;p class=&quot;wp-caption-text&quot;&gt;Figure 9: Red dot/blue dot comparison on our internal version of the rider app allows Uber employees to spot check our solution anywhere in the world.&lt;/p&gt;
&lt;/div&gt;

&lt;h3&gt;&lt;span&gt;Moving forward&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;Accurate estimation of rider and driver location is a crucial requirement for fulfilling Uber’s mission of providing transportation as reliable as running water, everywhere, for everyone.&lt;/span&gt; &lt;span&gt;To meet our mission, the Sensing, Intelligence, and Research team is working on a variety of approaches for improving location with creative use of sensors and computation on mobile devices, coupled with the computational power of our server infrastructure. The combination of advanced signal processing, machine learning algorithms, and software at scale has huge potential, and we are always looking for talented and highly motivated individuals (&lt;/span&gt;&lt;a href=&quot;https://www.uber.com/careers/list/14345/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;software and algorithms engineers&lt;/span&gt;&lt;/a&gt;&lt;span&gt;,&lt;/span&gt; &lt;a href=&quot;https://www.uber.com/careers/list/13203/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;data visualization engineers&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href=&quot;https://www.uber.com/careers/list/37852/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;span&gt;machine learning engineers&lt;/span&gt;&lt;/a&gt;&lt;span&gt;) to join us to help realize this potential.&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;span&gt;Danny Iland, Andrew Irish, Upamanyu Madhow, &amp;amp; Brian Sandler are members of Uber’s Sensing, Inference and Research team. Danny, Andrew, and Upamanyu were part of the original group that led this research at the University of California, Santa Barbara. After spinning this work into a startup, they demonstrated server-based particle filtering for location improvement in San Francisco using a 3D map constructed from publicly available aerial LiDAR data. They joined Uber in July 2016.&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;



&lt;div id=&quot;sexy-author-bio&quot; class=&quot;danny-iland&quot; readability=&quot;8.0480769230769&quot;&gt;&lt;div id=&quot;sab-social-wrapper&quot;&gt;&lt;a id=&quot;sab-sablinkedin&quot; href=&quot;https://www.linkedin.com/in/daniel-iland-33b252b/&quot; target=&quot;_top&quot;&gt;&lt;img id=&quot;sig-sablinkedin&quot; alt=&quot;Danny Iland on Linkedin&quot; src=&quot;https://eng.uber.com/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sablinkedin.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;div id=&quot;sab-gravatar&quot;&gt;&lt;a href=&quot;https://eng.uber.com/author/danny-iland/&quot; target=&quot;_top&quot;&gt;&lt;img alt=&quot;Danny Iland&quot; src=&quot;https://eng.uber.com/wp-content/uploads/2018/04/up_8f7223e3-b7a5-432b-b56f-ff7197ba05bf-1.jpg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;p&gt;Danny Iland is a senior software engineer on Uber’s Sensing, Inference, and Research team.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sexy-author-bio&quot; class=&quot;andrew-irish&quot; readability=&quot;7.9811320754717&quot;&gt;&lt;div id=&quot;sab-social-wrapper&quot;&gt;&lt;a id=&quot;sab-sablinkedin&quot; href=&quot;https://www.linkedin.com/in/andrew-irish-565b6324/&quot; target=&quot;_top&quot;&gt;&lt;img id=&quot;sig-sablinkedin&quot; alt=&quot;Andrew Irish on Linkedin&quot; src=&quot;https://eng.uber.com/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sablinkedin.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;div id=&quot;sab-gravatar&quot;&gt;&lt;a href=&quot;https://eng.uber.com/author/andrew-irish/&quot; target=&quot;_top&quot;&gt;&lt;img alt=&quot;Andrew Irish&quot; src=&quot;https://eng.uber.com/wp-content/uploads/2018/04/up_aea689ce-7016-4311-b4ce-edd8ca585f9c.jpg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;p&gt;Andrew Irish is a senior software engineer on Uber’s Sensing, Inference, and Research team.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sexy-author-bio&quot; class=&quot;upamanyu-madhow&quot; readability=&quot;8.1455696202532&quot;&gt;&lt;div id=&quot;sab-social-wrapper&quot;&gt;&lt;a id=&quot;sab-sablinkedin&quot; href=&quot;https://www.linkedin.com/in/upamanyu-madhow-7a124512/&quot; target=&quot;_top&quot;&gt;&lt;img id=&quot;sig-sablinkedin&quot; alt=&quot;Upamanyu Madhow on Linkedin&quot; src=&quot;https://eng.uber.com/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sablinkedin.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;div id=&quot;sab-gravatar&quot;&gt;&lt;a href=&quot;https://eng.uber.com/author/upamanyu-madhow/&quot; target=&quot;_top&quot;&gt;&lt;img alt=&quot;Upamanyu Madhow&quot; src=&quot;https://eng.uber.com/wp-content/uploads/2018/04/bg_919763ee-15a3-45ca-a907-6ea7c99faab9-mpI9EDSTIR.jpg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;p&gt;Upamanyu Madhow is a researcher at Uber and a professor of Electrical and Computer Engineering at the University of California, Santa Barbara.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sexy-author-bio&quot; class=&quot;brian-sandler&quot; readability=&quot;9.2168674698795&quot;&gt;&lt;div id=&quot;sab-social-wrapper&quot;&gt;&lt;a id=&quot;sab-sablinkedin&quot; href=&quot;https://www.linkedin.com/in/sandlerbrian/&quot; target=&quot;_top&quot;&gt;&lt;img id=&quot;sig-sablinkedin&quot; alt=&quot;Brian Sandler on Linkedin&quot; src=&quot;https://eng.uber.com/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sablinkedin.png&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;div id=&quot;sab-gravatar&quot;&gt;&lt;a href=&quot;https://eng.uber.com/author/brian-sandler/&quot; target=&quot;_top&quot;&gt;&lt;img alt=&quot;Brian Sandler&quot; src=&quot;https://eng.uber.com/wp-content/uploads/2018/04/0.jpg&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;p&gt;Brian Sandler was a summer intern on Uber’s Sensing, Inference, and Research team and is currently a Ph.D student with the University of Pennsylvania.&lt;/p&gt;
&lt;/div&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;div class=&quot;post-meta&quot;&gt;
&lt;ul&gt;&lt;li&gt;Categories: &lt;a href=&quot;https://eng.uber.com/category/general-engineering/&quot; rel=&quot;category tag&quot;&gt;General Engineering&lt;/a&gt; &lt;span class=&quot;muted&quot;&gt;/&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Tags: &lt;a href=&quot;https://eng.uber.com/tag/3d-mapping/&quot; rel=&quot;tag&quot;&gt;3D mapping&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/android/&quot; rel=&quot;tag&quot;&gt;Android&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/beidou/&quot; rel=&quot;tag&quot;&gt;BeiDou&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/galileo/&quot; rel=&quot;tag&quot;&gt;Galileo&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/global-positioning-system/&quot; rel=&quot;tag&quot;&gt;Global Positioning System&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/glonass/&quot; rel=&quot;tag&quot;&gt;GLONASS&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/gps/&quot; rel=&quot;tag&quot;&gt;GPS&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/inference/&quot; rel=&quot;tag&quot;&gt;Inference&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/maps/&quot; rel=&quot;tag&quot;&gt;maps&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/particle-filter/&quot; rel=&quot;tag&quot;&gt;Particle Filter&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/probabilistic-shadow-matching/&quot; rel=&quot;tag&quot;&gt;Probabilistic Shadow Matching&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/ray-tracing/&quot; rel=&quot;tag&quot;&gt;Ray Tracing&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/research/&quot; rel=&quot;tag&quot;&gt;Research&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/sensing/&quot; rel=&quot;tag&quot;&gt;Sensing&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/signal-processing/&quot; rel=&quot;tag&quot;&gt;Signal Processing&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/uber-engineering/&quot; rel=&quot;tag&quot;&gt;Uber Engineering&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/uber-maps/&quot; rel=&quot;tag&quot;&gt;Uber Maps&lt;/a&gt;, &lt;a href=&quot;https://eng.uber.com/tag/ucsb/&quot; rel=&quot;tag&quot;&gt;UCSB&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;

</description>
<pubDate>Fri, 20 Apr 2018 18:27:40 +0000</pubDate>
<dc:creator>mkvorwerck</dc:creator>
<og:type>article</og:type>
<og:title>Rethinking GPS: Engineering Next-Gen Location at Uber</og:title>
<og:description>Uber’s Sensing, Inference, and Research team released a software upgrade for GPS on Android phones that significantly improves location accuracy in urban environments.</og:description>
<og:url>https://eng.uber.com/rethinking-gps/</og:url>
<og:image>http://eng.uber.com/wp-content/uploads/2018/04/Facebook.jpg</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://eng.uber.com/rethinking-gps/</dc:identifier>
</item>
</channel>
</rss>