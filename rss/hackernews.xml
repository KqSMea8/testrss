<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>AdamW and Super-convergence is now the fastest way to train neural nets</title>
<link>http://www.fast.ai/2018/07/02/adam-weight-decay/</link>
<guid isPermaLink="true" >http://www.fast.ai/2018/07/02/adam-weight-decay/</guid>
<description>&lt;span class=&quot;post-date&quot;&gt;Written: 02 Jul 2018 by &lt;em&gt;Sylvain Gugger and Jeremy Howard&lt;/em&gt;&lt;/span&gt;
&lt;p class=&quot;message&quot;&gt;&lt;em&gt;Note from Jeremy:&lt;/em&gt; Welcome to fast.ai’s first scholar-in-residence, &lt;a href=&quot;https://sgugger.github.io/&quot;&gt;Sylvain Gugger&lt;/a&gt;. What better way to introduce him than to publish the results of his first research project at fast.ai. We’ll be using the results of this research to change how we train models in the next version of our course and in our fastai library, as a result of which students and practitioners will be able to reliably train their models far faster than previous approaches.&lt;/p&gt;
&lt;h2 id=&quot;the-adam-roller-coaster&quot;&gt;The Adam roller-coaster&lt;/h2&gt;
&lt;p&gt;The journey of the Adam optimizer has been quite a roller coaster. First &lt;a href=&quot;https://arxiv.org/abs/1412.6980&quot;&gt;introduced&lt;/a&gt; in 2014, it is, at its heart, a simple and intuitive idea: why use the same learning rate for every parameter, when we know that some surely need to be moved further and faster than others? Since the square of recent gradients tells us how much signal we’re getting for each weight, we can just divide by that to ensure even the most sluggish weights get their chance to shine. Adam takes that idea, adds on the standard approach to momentum, and (with a little tweak to keep early batches from being biased) that’s it!&lt;/p&gt;
&lt;p&gt;When first released, the deep learning community was full of excitement after seeing charts like this one from the original paper:&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;400&quot; src=&quot;http://www.fast.ai/images/adam_charts.png&quot; alt=&quot;Comparison between Adam and other optimizers&quot;/&gt; Comparison between Adam and other optimizers
&lt;p&gt;200% speed up in training! “Overall, we found Adam to be robust and well-suited to a wide range of non-convex optimization problems in the field machine learning” concluded the paper. Ah yes, those were the days, over three years ago now, a life-time in deep-learning-years. But it started to become clear that all was not as we hoped. Few research articles used it to train their models, &lt;a href=&quot;https://arxiv.org/abs/1705.08292&quot;&gt;new studies&lt;/a&gt; began to clearly discourage to apply it and showed on several experiments that plain ole SGD with momentum was performing better. By the time the 2018 fast.ai course had come around, the decision was made to cut poor Adam from the early lessons.&lt;/p&gt;
&lt;p&gt;But at the end of 2017, Adam seemed to get a new lease of life. Ilya Loshchilov and Frank Hutter pointed out in &lt;a href=&quot;https://arxiv.org/abs/1711.05101&quot;&gt;their paper&lt;/a&gt; that the way weight decay is implemented in Adam in every library seems to be wrong, and proposed a simple way (which they call AdamW) to fix it. Although their results were slightly mixed, they did show some encouraging charts, such as this one:&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;600&quot; src=&quot;http://www.fast.ai/images/adamw_charts.png&quot; alt=&quot;Comparison between Adam and AdamW&quot;/&gt; Comparison between Adam and AdamW
&lt;p&gt;We expected to see the Adam enthusiasm return, since it seemed those first results could perhaps be found again. But that’s not what happened. Indeed, the only deep learning framework that implemented the fix was &lt;a href=&quot;https://github.com/fastai/fastai/&quot;&gt;fastai&lt;/a&gt;, using code written by Sylvain. Without broad framework availability, day-to-day practitioners were stuck with the old, “broken” Adam.&lt;/p&gt;
&lt;p&gt;But that’s not the only problem. More obstacles lay ahead. Two separate papers pointed out apparent problems with the convergence proof of poor Adam, although one of them claimed a fix (and won a “best paper” award at the prestigious ICLR conference), which they called &lt;em&gt;amsgrad&lt;/em&gt;. But if we’ve learned anything from this potted history of this most dramatic life (at least, dramatic by optimizer standards), it’s that nothing is as it seems. And indeed, PhD student Jeremy Bernstein &lt;a href=&quot;https://openreview.net/forum?id=ryQu7f-RZ&amp;amp;noteId=B1PDZUChG&quot;&gt;has pointed out&lt;/a&gt; that the claimed convergence problems are actually just signs of poorly chosen hyper-parameters, and that perhaps amsgrad won’t fix things anyway. Another PhD student, Filip Korzeniowski, showed some &lt;a href=&quot;https://fdlm.github.io/post/amsgrad/&quot;&gt;early results&lt;/a&gt; that seemed to support this discouraging view of amsgrad.&lt;/p&gt;
&lt;h2 id=&quot;getting-off-the-roller-coaster&quot;&gt;Getting off the roller-coaster&lt;/h2&gt;
&lt;p&gt;So for those of us that just want to train accurate models fast, what do we do? Let’s solve this debate the same way scientific debates have been solved for hundreds of years: with experiments! We’ll tell you all the details in just a moment, but first, here’s a summary of the results:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Properly tuned, Adam really works! We got new state of the art results (in terms of training time) on various tasks like
&lt;ul&gt;&lt;li&gt;training CIFAR10 to &amp;gt;94% accuracy in as few as 18 epochs with Test Time Augmentation or with 30 epochs without, as in the DAWNBench competition;&lt;/li&gt;
&lt;li&gt;fine-tuning Resnet50 to 90% accuracy on the Cars Stanford Dataset in just 60 epochs (previous reports to the same accuracy used 600);&lt;/li&gt;
&lt;li&gt;training from scratch an &lt;a href=&quot;https://arxiv.org/abs/1708.02182&quot;&gt;AWD LSTM or QRNN&lt;/a&gt; in 90 epochs (or 1 hour and a half on a single GPU) to state-of-the-art perplexity on Wikitext-2 (previous reports used 750 for LSTMs, 500 for QRNNs).&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;That means that we’ve seen (for the first time we’re aware of) &lt;a href=&quot;https://arxiv.org/abs/1708.07120&quot;&gt;super convergence&lt;/a&gt; using Adam! Super convergence is a phenomenon that occurs when training a neural net with high learning rates, growing for half the training. Before it was understood, training CIFAR10 to 94% accuracy took about 100 epochs.&lt;/li&gt;
&lt;li&gt;In contrast to previous work, we see Adam getting about as good accuracy as SGD+Momentum on every CNN image problem we’ve tried it on, as long as it’s properly tuned, and it’s nearly always a bit faster too.&lt;/li&gt;
&lt;li&gt;The suggestions that amsgrad are a poor “fix” are correct. We consistently found that amsgrad didn’t achieve any gain in accuracy (or other relevant metric) than plain Adam/AdamW.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;When you hear people saying that Adam doesn’t generalize as well as SGD+Momentum, you’ll nearly always find that they’re choosing poor hyper-parameters for their model. Adam generally requires more regularization than SGD, so be sure to adjust your regularization hyper-parameters when switching from SGD to Adam.&lt;/p&gt;
&lt;p&gt;Here’s an overview of the rest of this article:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;http://www.fast.ai/2018/07/02/adam-weight-decay/#adamw&quot;&gt;AdamW&lt;/a&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;http://www.fast.ai/2018/07/02/adam-weight-decay/#understanding-adamw-weight-decay-or-l2-regularization&quot;&gt;Understanding AdamW&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.fast.ai/2018/07/02/adam-weight-decay/#implementing-adamw&quot;&gt;Implementing AdamW&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.fast.ai/2018/07/02/adam-weight-decay/#results-of-adamw-experiments-does-it-work&quot;&gt;Results of AdamW experiments&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.fast.ai/2018/07/02/adam-weight-decay/#amsgrad&quot;&gt;amsgrad&lt;/a&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;http://www.fast.ai/2018/07/02/adam-weight-decay/#understanding-amsgrad&quot;&gt;Understanding amsgrad&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.fast.ai/2018/07/02/adam-weight-decay/#implementing-amsgrad&quot;&gt;Implementing amsgrad&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.fast.ai/2018/07/02/adam-weight-decay/#results-of-amsgrad-experiments-a-lot-of-noise-for-nothing&quot;&gt;Results of amsgrad experiments&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.fast.ai/2018/07/02/adam-weight-decay/#appendix-full-results&quot;&gt;Tables of full results&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;adamw&quot;&gt;AdamW&lt;/h2&gt;
&lt;h3 id=&quot;understanding-adamw-weight-decay-or-l2-regularization&quot;&gt;Understanding AdamW: Weight decay or L2 regularization?&lt;/h3&gt;
&lt;p&gt;L2 regularization is a classic method to reduce over-fitting, and consists in adding to the loss function the sum of the squares of all the weights of the model, multiplied by a given hyper-parameter (all equations in this article use python, numpy, and pytorch notation):&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;6&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;final_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all_weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;…where wd is the hyper-parameter to set. This is also called weight decay, because when applying vanilla SGD it’s equivalent to updating the weight like this:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;6&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;(Note that the derivative of &lt;em&gt;w&lt;sup&gt;2&lt;/sup&gt;&lt;/em&gt; with respect to &lt;em&gt;w&lt;/em&gt; is &lt;em&gt;2w&lt;/em&gt;.) In this equation we see how we subtract a little portion of the weight at each step, hence the name &lt;em&gt;decay&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;All libraries we have looked at use the first of these forms. (In practice, it is nearly always implemented by adding &lt;em&gt;wd*w&lt;/em&gt; to the gradients, rather than actually changing the loss function: we don’t want to add more computations by modifying the loss when there is an easier way.)&lt;/p&gt;
&lt;p&gt;So why make a distinction between those two concepts if they are the same thing? The answer is that they are only the same thing for vanilla SGD, but as soon as we add momentum, or use a more sophisticated optimizer like Adam, L2 regularization (first equation) and weight decay (second equation) become &lt;strong&gt;different&lt;/strong&gt;. In the rest of this article, when we talk about weight decay, we will always refer to this second formula (decay the weight by a little bit) and talk about L2 regularization if we want to mention the classic way.&lt;/p&gt;
&lt;p&gt;Let’s look at SGD with momentum for instance. Using L2 regularization consists in adding &lt;em&gt;wd*w&lt;/em&gt; to the gradients (as we saw earlier) but the gradients aren’t subtracted from the weights directly. First we compute a moving average:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;6&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;moving_avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;moving_avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;…and it’s this moving average that will be multiplied by the learning rate and subtracted from &lt;em&gt;w&lt;/em&gt;. So the part linked to the regularization that will be taken from &lt;em&gt;w&lt;/em&gt; is &lt;em&gt;lr* (1-alpha)*wd * w&lt;/em&gt; plus a combination of the previous weights that were already in &lt;em&gt;moving_avg&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;On the other hand, weight decay’s update will look like&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;6&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;moving_avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;moving_avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;moving_avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We can see that the part subtracted from w linked to regularization isn’t the same in the two methods. When using the Adam optimizer, it gets even more different: in the case of L2 regularization we add this &lt;em&gt;wd*w&lt;/em&gt; to the gradients then compute a moving average of the gradients and their squares before using both of them for the update. Whereas the weight decay method simply consists in doing the update, then subtract to each weight.&lt;/p&gt;
&lt;p&gt;Clearly those are two different approaches. And after experimenting with this, Ilya Loshchilov and Frank Hutter suggest in their article we should use weight decay with Adam, and not the L2 regularization that classic deep learning libraries implement.&lt;/p&gt;
&lt;h3 id=&quot;implementing-adamw&quot;&gt;Implementing AdamW&lt;/h3&gt;
&lt;p&gt;How can we do this? Very easily if you’re using the fastai library since its implemented inside. Specifically if you use the fit function, just add the argument use_wd_sched=True:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;7.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_wd_sched&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;If you prefer the new training API, you can use the argument wd_loss=False (for weight decay not computed in the loss) in each of your training phases:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;8&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;11&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;phases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TrainingPhase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wd_loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_opt_sched&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Here’s a quick summary of how we implemented this in fastai. Inside the step function of the optimizer, only the gradients are used to modify the parameters, the value of the parameters themselves isn’t used at all (except for the weight decay, but we will be dealing with that outside). We can then implement weight decay by simply doing it before the step of the optimizer. It still has to be done after the gradients are computed (otherwise it would impact the gradients values) so inside your training loop, you have to look for this spot.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;6&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#Do the weight decay here!&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Of course, the optimizer should have been set with wd=0 otherwise it will do some L2 regularization, which is exactly what we don’t want right now. Now in that spot, we have to loop over all the parameters and do our little weight decay update. Your parameters should all be inside the dictionary &lt;em&gt;param_groups&lt;/em&gt; of your optimizer, so the loop looks something like this:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;7&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;9&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param_groups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'params'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'lr'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&quot;results-of-adamw-experiments-does-it-work&quot;&gt;Results of AdamW experiments: does it work?&lt;/h3&gt;
&lt;p&gt;Our first tests on computer vision problems were very encouraging. Specifically, the accuracy we managed to get in 30 epochs (which is the necessary time for SGD to get to 94% accuracy with a &lt;a href=&quot;https://sgugger.github.io/the-1cycle-policy.html&quot;&gt;1cycle policy&lt;/a&gt;) with Adam and L2 regularization was at 93.96% on average, going over 94% one time out of two. We consistently reached values between 94% and 94.25% with Adam and weight decay. To do this, we found the optimal value for beta2 when using a 1cycle policy was 0.99. We treated the beta1 parameter as the momentum in SGD (meaning it goes from 0.95 to 0.85 as the learning rates grow, then goes back to 0.95 when the learning rates get lower).&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;500&quot; src=&quot;http://www.fast.ai/images/compare_acc.png&quot; alt=&quot;Accuracy with L2 regularization or weight decay&quot;/&gt; Accuracy with L2 regularization or weight decay
&lt;p&gt;Even more impressive, using Test Time Augmentation (i.e. taking the average of the predictions on one image of the test set and four data-augmented versions of it), we can get to those 94% accuracy in just 18 epochs (93.98% on average)! With plain Adam and L2 regularization, going over the 94% happened once every twenty tries.&lt;/p&gt;
&lt;p&gt;One thing to take into account in those comparisons is that changing the way we regularize changes the best values of weight decay or learning rate. In the tests we ran, the best learning rate with L2 regularization was 1e-6 (with a maximum learning rate of 1e-3) while 0.3 was the best value for weight decay (with a learning rate of 3e-3). The difference of orders of magnitude has been very consistent in all our tests, and comes primarily from the fact that L2 regularization gets effectively divided by the average norm of the gradients (which are pretty low) and that learning rates with Adam are pretty small (so the update of weight decay needs a stronger coefficient).&lt;/p&gt;
&lt;p&gt;So, weight decay is always better than L2 regularization with Adam then? We haven’t found a situation where it’s significantly worse, but for either a transfer-learning problem (e.g. fine-tuning Resnet50 on Stanford cars) or RNNs, it didn’t give better results.&lt;/p&gt;
&lt;h2 id=&quot;amsgrad&quot;&gt;amsgrad&lt;/h2&gt;
&lt;h3 id=&quot;understanding-amsgrad&quot;&gt;Understanding amsgrad&lt;/h3&gt;
&lt;p&gt;Amsgrad was introduced in &lt;a href=&quot;https://openreview.net/forum?id=ryQu7f-RZ&quot;&gt;a recent article&lt;/a&gt; by Sashank J. Reddi, Satyen Kale and Sanjiv Kumar. By analyzing the proof of convergence for the Adam optimizer, they spotted a mistake in the update rule that could cause the algorithm to converge to a sub-optimal point. They designed theoretical experiments that showed situations where Adam would fail and proposed a simple fix.&lt;/p&gt;
&lt;p&gt;To understand the error and the fix, let’s have a look at the update rule of Adam (if you need a refresher, &lt;a href=&quot;http://ruder.io/optimizing-gradient-descent/&quot;&gt;Sebastian got you covered&lt;/a&gt;):&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;6.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;avg_grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;avg_squared&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_squared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_squared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;We’ve just skipped the bias correction (useful for the beginning of training) to focus on the important point. The error in the proof of Adam the authors spotted is that it requires the quantity&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;lr / sqrt(avg_squared)
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;…which is the step we take in the direction of our average gradients, to be decreasing over training. Since the learning rate is often taken constant or decreasing (except for crazy people like us trying to obtain super-convergence), the fix the authors proposed was to force the &lt;em&gt;avg_squared&lt;/em&gt; quantity to be increasing by adding another variable to keep track of their maximums.&lt;/p&gt;
&lt;h3 id=&quot;implementing-amsgrad&quot;&gt;Implementing amsgrad&lt;/h3&gt;
&lt;p&gt;The associated article won an award at ICLR 2018 and gained such popularity that it’s already implemented in two of the main deep learning libraries, pytorch and Keras. There is little to do except turn the option on with &lt;em&gt;amsgrad=True&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This causes the weight update code from the previous section to be changed to something like this:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;7.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;avg_grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;avg_squared&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_squared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;max_squared&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_squared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_squared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_squared&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&quot;results-of-amsgrad-experiments-a-lot-of-noise-for-nothing&quot;&gt;Results of amsgrad experiments: a lot of noise for nothing&lt;/h3&gt;
&lt;p&gt;Amsgrad turns out to be very disappointing. In none of our experiments did we find that it helped the slightest bit, and even if it’s true that the minimum found by amsgrad is sometimes slightly lower (in terms of loss) than the one reached by Adam, the metrics (accuracy, f1 score…) always end up worse (see the tables in our introduction, or more examples &lt;a href=&quot;https://fdlm.github.io/post/amsgrad/&quot;&gt;here&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;The proof of convergence for the Adam optimizer in deep learning (since it’s for convex problems) and the mistake they found in it mattered for synthetic experiments that have nothing to do with real-life problems. Actual tests show that when those &lt;em&gt;avg_squared&lt;/em&gt; gradients want to decrease, it’s best for the final result to do so.&lt;/p&gt;
&lt;p&gt;This shows that even if the focus on theory can be useful to gain some new ideas, nothing replaces experiments (and lots of them!) to make sure these ideas actually help practitioners train better models.&lt;/p&gt;
&lt;h2 id=&quot;appendix-full-results&quot;&gt;Appendix: Full results&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Training of CIFAR10 from scratch (model is a wide resnet 22, average of the error on the test set with five models shown):&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Method&lt;/th&gt;
&lt;th&gt;Without amsgrad&lt;/th&gt;
&lt;th&gt;With amsgrad&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;AdamW&lt;/td&gt;
&lt;td&gt;5.66%&lt;/td&gt;
&lt;td&gt;6.31%&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Adam&lt;/td&gt;
&lt;td&gt;6.06%&lt;/td&gt;
&lt;td&gt;6.64%&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;em&gt;Fine-tuning Resnet50 on the Stanford Cars dataset using the standard head introduced by the fastai library (training the head for 20 epochs before unfreezing and training with differential learning rates for 40 epochs).:&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Method&lt;/th&gt;
&lt;th&gt;Without amsgrad&lt;/th&gt;
&lt;th&gt;With amsgrad&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;AdamW&lt;/td&gt;
&lt;td&gt;10.8%/9.5%&lt;/td&gt;
&lt;td&gt;10.1%/9.5%&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Adam&lt;/td&gt;
&lt;td&gt;10.4%/9%&lt;/td&gt;
&lt;td&gt;10.1%/9%&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;em&gt;Training an AWD LSTM with the hyper-parameters from the &lt;a href=&quot;https://github.com/salesforce/awd-lstm-lm&quot;&gt;github repo&lt;/a&gt; (results show the perplexity on the validation/test set, with or without cache pointer):&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Method&lt;/th&gt;
&lt;th&gt;Raw model&lt;/th&gt;
&lt;th&gt;With cache pointer&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Adam&lt;/td&gt;
&lt;td&gt;68.7/65.5&lt;/td&gt;
&lt;td&gt;52.9/50.9&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Adam + amsgrad&lt;/td&gt;
&lt;td&gt;69.4/66.5&lt;/td&gt;
&lt;td&gt;53.1/51.3&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;AdamW&lt;/td&gt;
&lt;td&gt;69.3/66&lt;/td&gt;
&lt;td&gt;54.1/51.9&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;AdamW + amsgrad&lt;/td&gt;
&lt;td&gt;72.7/69&lt;/td&gt;
&lt;td&gt;57/54.7&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;em&gt;And the same with QRNNs instead of LSTMs:&lt;/em&gt;&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Method&lt;/th&gt;
&lt;th&gt;Raw model&lt;/th&gt;
&lt;th&gt;With cache pointer&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Adam&lt;/td&gt;
&lt;td&gt;69.6/66.7&lt;/td&gt;
&lt;td&gt;53.6/51.7&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Adam + amsgrad&lt;/td&gt;
&lt;td&gt;71.5/68.4&lt;/td&gt;
&lt;td&gt;54.2/52.2&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;AdamW&lt;/td&gt;
&lt;td&gt;70.5/67.3&lt;/td&gt;
&lt;td&gt;55.5/53.3&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;AdamW + amsgrad&lt;/td&gt;
&lt;td&gt;74.3/70.9&lt;/td&gt;
&lt;td&gt;57.8/55.6&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;For this specific task, we used a modified version of the 1cycle policy, growing the learning rate faster, then having a long period of high constant learning rates before going down again.&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;400&quot; src=&quot;http://www.fast.ai/images/custom_cycle.png&quot; alt=&quot;Comparison between Adam and other optimizers&quot;/&gt; Comparison between Adam and other optimizers
&lt;p&gt;The values of all relevant hyper-parameters as well as the code used to produce these results are available &lt;a href=&quot;https://github.com/sgugger/Adam-experiments&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>Tue, 03 Jul 2018 16:57:40 +0000</pubDate>
<dc:creator>tim_sw</dc:creator>
<dc:language>en-us</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.fast.ai/2018/07/02/adam-weight-decay/</dc:identifier>
</item>
<item>
<title>Cities don&amp;#039;t have to offer huge subsidies to companies like Apple and Amazon</title>
<link>https://www.theguardian.com/cities/2018/jul/03/cities-need-to-stop-selling-out-to-big-tech-companies-theres-a-better-way</link>
<guid isPermaLink="true" >https://www.theguardian.com/cities/2018/jul/03/cities-need-to-stop-selling-out-to-big-tech-companies-theres-a-better-way</guid>
<description>&lt;p&gt;Every mayor and governor wants to attract hi-tech jobs. And why not? Depending on the nature of the facility, such jobs can be well-paid and strengthen a region’s economy.&lt;/p&gt;
&lt;p&gt;But too few elected officials have taken the time to learn how hi-tech companies start up, how they thrive, and how government can best assist them – without overspending on a few big deals.&lt;/p&gt;
&lt;a href=&quot;https://interactive.guim.co.uk/embed/series-embed/v1/index.html?vertical=news&amp;amp;series-name=Big%20tech%2C%20desperate%20cities&amp;amp;series-link=https%3A%2F%2Fwww.theguardian.com%2Fcities%2Fseries%2Fbig-tech-desperate-cities&amp;amp;description=Tax%20giveaways%20to%20tech%20firms%20%E2%80%8B%E2%80%8Bare%20%E2%80%8Bcalculated%E2%80%8B%20to%20lure%20them%20to%20cities%20%E2%80%93%20but%20are%20cities%20really%20getting%20a%20good%20deal%3F%20&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;Big tech, desperate cities&lt;/a&gt;
&lt;p&gt;Getting policy right is critical for high-tech success. It’s more complicated and volatile than the “old economy”: hi-tech firms are more susceptible to disruption. Product life cycles are typically much shorter. Skill sets are more specialised. Some facilities create very few permanent jobs, and some generate a lot of toxins.&lt;/p&gt;
&lt;p&gt;For all those reasons and more, using “old economy” incentives for “new economy” firms can be costly and counterproductive. The “lots of eggs in one basket” strategy is especially ill-suited. But many public leaders haven’t switched gears yet, often putting taxpayers at great risk, especially because some tech companies have become very aggressive about demanding big tax breaks. Companies with famous names are even more irresistible to politicians who want to look active on jobs.&lt;/p&gt;
&lt;p&gt;First, the too-many-eggs problem: hi-tech firms are prominent among recent tax-break “megadeals” awarded by cities and states. Tesla’s battery factory ($1.3bn from Nevada), Foxconn’s &lt;a href=&quot;https://www.theguardian.com/technology/2017/jul/29/foxconn-china-apple-wisconsin-trump&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;display-screen plant&lt;/a&gt; in Wisconsin ($4.8bn) and Apple’s data centre in Iowa ($214m) are typical.&lt;/p&gt;
&lt;aside class=&quot;element element-rich-link element--thumbnail element-rich-link--not-upgraded&quot; data-component=&quot;rich-link&quot; data-link-name=&quot;rich-link-3 | 1&quot;&gt;
&lt;/aside&gt;&lt;p&gt;The Apple centre, a cloud computing facility, will have only 50 permanent jobs, so the cost per job exceeds $4.2m. The &lt;a href=&quot;https://www.theguardian.com/technology/foxconn&quot; data-link-name=&quot;auto-linked-tag&quot; data-component=&quot;auto-linked-tag&quot; class=&quot;u-underline&quot;&gt;Foxconn&lt;/a&gt; deal, even by the state’s own official estimate, won’t break even for taxpayers for 25 years – an extremely risky time horizon given the likelihood of new technologies leapfrogging the company’s product much sooner. The Tesla deal was 14 times costlier than anything Nevada had done before.&lt;/p&gt;
&lt;p&gt;It doesn’t have to be this way. There are proven alternatives to this buffalo-hunting, trophy deal school of economic development that can reduce taxpayer risk, grow many more employers and intentionally build valuable relationships between promising firms and local public institutions.&lt;/p&gt;
&lt;h2&gt;Two proven alternatives&lt;/h2&gt;
&lt;p&gt;Here are two proven alternative strategies. The first could be called “back to basics”. A regional government inventories existing small- and medium-sized firms, the backbone of many local communities. Typically family-owned and located in micropolitan and rural areas, these firms are often neglected by policymakers and shortchanged by incentive programmes.&lt;/p&gt;

&lt;div class=&quot;u-responsive-ratio&quot;&gt;&lt;img class=&quot;gu-image&quot; itemprop=&quot;contentUrl&quot; alt=&quot;Foxconn chairman Terry Gou, left, and Wisconsin governor Scott Walker celebrate a deal to bring the tech company to the state in return for tax breaks worth $4.8bn.&quot; src=&quot;https://i.guim.co.uk/img/media/3112eb474b5ab2dc9c85231095458b3b490fb091/0_16_3184_1911/master/3184.jpg?w=300&amp;amp;q=55&amp;amp;auto=format&amp;amp;usm=12&amp;amp;fit=max&amp;amp;s=73811958c1f213d07f67dd6aad3e664a&quot;/&gt;&lt;/div&gt;

Foxconn chairman Terry Gou, left, and Wisconsin governor Scott Walker celebrate a deal to bring the tech company to the state in return for tax breaks worth $4.8bn. Photograph: Mike De Sisti/AP
&lt;p&gt;A regional government asks: which industry sectors are we already comparatively good at? Which of those sectors have the best futures? How can our public systems help those promising firms grow? Do they need export assistance? Customised training? Technology diffusion? More engineering-school graduates?&lt;/p&gt;
&lt;p&gt;There are some simple fixes that could go a long way.&lt;/p&gt;
&lt;p&gt;The second alternative takes this same approach and applies it to very young companies and to emerging technologies with more speculative prospects. This was North Carolina’s successful strategy from the 1950s until the mid-1990s. Making no big bets on any one company, the state invested in all levels of education, created its community college system and upgraded the state universities. It also focused on highway upgrades and other infrastructure investments.&lt;/p&gt;
&lt;aside class=&quot;element element-rich-link element--thumbnail element-rich-link--not-upgraded&quot; data-component=&quot;rich-link&quot; data-link-name=&quot;rich-link-3 | 2&quot;&gt;
&lt;/aside&gt;&lt;p&gt;The state followed up with targeted investments such as the &lt;a href=&quot;https://www.theguardian.com/us-news/northcarolina&quot; data-link-name=&quot;auto-linked-tag&quot; data-component=&quot;auto-linked-tag&quot; class=&quot;u-underline&quot;&gt;North Carolina&lt;/a&gt; Biotechnology Center, which especially benefited the Research Triangle Region. The centre wasn’t created for one company; its programmes provided an umbrella for a range of activities that promoted collaboration and commercialisation, such as offering small amounts of seed money to enable companies to test ideas, and convening diverse groups to respond to larger funding opportunities. Rather than defining biotechnology narrowly, it supported biomaterials, bioelectronics and biofuels.&lt;/p&gt;
&lt;p&gt;Though even North Carolina can stray from the wisdom of its history. Despite the Triangle’s steady success, the state would later abandon its patient approach and go buffalo hunting for hi-tech jobs. After secret negotiations and a one-day legislative session, in 2004 it gave &lt;a href=&quot;https://www.theguardian.com/technology/dell&quot; data-link-name=&quot;auto-linked-tag&quot; data-component=&quot;auto-linked-tag&quot; class=&quot;u-underline&quot;&gt;Dell&lt;/a&gt; a package worth almost a quarter of a billion dollars. Five years later, the plant, a so-called screwdriver shop that assembled components imported from Asia (ie its supply chain was not in-state), shut down.&lt;/p&gt;

&lt;div class=&quot;u-responsive-ratio&quot;&gt;&lt;img class=&quot;gu-image&quot; itemprop=&quot;contentUrl&quot; alt=&quot;The Tesla Gigafactory is being built in Nevada thanks to one of the recent tax-break “megadeals” awarded by cities and states&quot; src=&quot;https://i.guim.co.uk/img/media/95f4083d075fe4cad31ad3ab648a2e678968b46f/19_0_1743_1046/master/1743.jpg?w=300&amp;amp;q=55&amp;amp;auto=format&amp;amp;usm=12&amp;amp;fit=max&amp;amp;s=e76822b80d32e531105ae6eabe3bee3f&quot;/&gt;&lt;/div&gt;

The Tesla Gigafactory is being built in Nevada thanks to one of the recent tax-break “megadeals” awarded by cities and states Photograph: Teslarati.com
&lt;p&gt;When North Carolina got it right, it bolstered public systems to help young companies. Investments like these succeed because they jump-start what academics call the agglomeration economies that benefit local firms. That is, as clusters of small firms grow in an area, government assistance can help grow the scientific talent pool, the entrepreneurial skills base and other key inputs. Some companies won’t make it, while others will thrive and grow the whole industry – but taxpayers won’t lose on any one big bet.&lt;/p&gt;
&lt;p&gt;Austin, Texas, currently the hottest tech-led economy in the US, provides a model: there, local entrepreneurs became local champions, creating early incubators, reinvesting their gains and working with local government. &lt;a href=&quot;http://ic2.utexas.edu/about/mission-and-history/george-kozmetsky/&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;George Kozmetsky&lt;/a&gt; is perhaps Austin’s most famous champion: before his death in 2003, he helped develop more than 100 tech-based companies, including Dell and Teledyne Technologies. He also held business-school positions at the University of Texas for more than 35 years.&lt;/p&gt;
&lt;p&gt;The most important element for public officials and local champions is to have a long-term vision rooted in an informed analysis of local strengths and weaknesses and market potential. Informed by that analysis, incentives to individual firms may make sense, along with the investments in public goods intended to benefit many employers.&lt;/p&gt;
&lt;aside class=&quot;element element-rich-link element--thumbnail element-rich-link--not-upgraded&quot; data-component=&quot;rich-link&quot; data-link-name=&quot;rich-link-3 | 3&quot;&gt;
&lt;/aside&gt;&lt;p&gt;This is a strategy for the long term, but arguably a much safer and more effective use of government funds. Plus it uses the tax revenue of current local citizens for their own benefit.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Maryann Feldman is the Heninger distinguished professor in the Department of Public Policy at the University of North Carolina, and director at the Center for Innovative and Prosperous Economies at the Kenan Institute of Private Enterprise.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Greg LeRoy directs Good Jobs First, a nonprofit watchdog group on economic development incentives.&lt;/em&gt;&lt;/p&gt;


</description>
<pubDate>Tue, 03 Jul 2018 16:06:14 +0000</pubDate>
<dc:creator>pmoriarty</dc:creator>
<og:url>http://www.theguardian.com/cities/2018/jul/03/cities-need-to-stop-selling-out-to-big-tech-companies-theres-a-better-way</og:url>
<og:description>Fostering local hi-tech success doesn’t have to mean offering huge tax breaks to companies like Apple and Amazon. Here are some alternative strategies</og:description>
<og:image>https://i.guim.co.uk/img/media/e44c2da42a9213b1b60d6b7abcdbd4da9b66f374/0_399_6000_3600/master/6000.jpg?w=1200&amp;h=630&amp;q=55&amp;auto=format&amp;usm=12&amp;fit=crop&amp;crop=faces%2Centropy&amp;bm=normal&amp;ba=bottom%2Cleft&amp;blend64=aHR0cHM6Ly91cGxvYWRzLmd1aW0uY28udWsvMjAxOC8wMS8zMS9mYWNlYm9va19vcGluaW9ucy5wbmc&amp;s=d08fac43ca4ea2a56903218d6ac8cbaa</og:image>
<og:type>article</og:type>
<og:title>Cities need to stop selling out to big tech companies. There's a better way</og:title>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.theguardian.com/cities/2018/jul/03/cities-need-to-stop-selling-out-to-big-tech-companies-theres-a-better-way</dc:identifier>
</item>
<item>
<title>Google to developers: We take down your extension because we can</title>
<link>https://palant.de/2018/07/03/google-to-developers-we-take-down-your-extension-because-we-can</link>
<guid isPermaLink="true" >https://palant.de/2018/07/03/google-to-developers-we-take-down-your-extension-because-we-can</guid>
<description>&lt;p&gt;Today, I found this email from Google in my inbox:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We routinely review items in the Chrome Web Store for compliance with our Program policies to ensure a safe and trusted experience for our users. We recently found that your item, “Google search link fix,” with ID: cekfddagaicikmgoheekchngpadahmlf, did not comply with our Developer Program Policies. Your item did not comply with the following section of our policy:&lt;/p&gt;
&lt;p&gt;We may remove your item if it has a blank description field, or missing icons or screenshots, and appears to be suspicious. Your item is still published, but is at risk of being removed from the Web Store.&lt;/p&gt;
&lt;p&gt;Please make the above changes within 7 days in order to avoid removal.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Not sure why Google chose the wrong email address to contact me about this (the account is associated with another email address) but luckily this email found me. I opened the extension listing and the description is there, as is the icon. What’s missing is a screenshot, simply because creating one for an extension without a user interface isn’t trivial. No problem, spent a bit of time making something that will do to illustrate the principle.&lt;/p&gt;
&lt;p&gt;And then I got another mail from Google, exactly 2 hours 30 minutes after the first one:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We have not received an update from you on your Google Chrome item, “Google search link fix,” with ID: cekfddagaicikmgoheekchngpadahmlf, item before the expiry of the warning period specified in our earlier email. Because your item continues to not comply with our policies stated in the previous email, it has now been removed from the Google Chrome Web Store.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I guess, Mountain View must be moving at extreme speeds, which is why time goes by way faster over there — relativity theory in action. Unfortunately, communication at near-light speeds is also problematic, which is likely why there is no way to ask questions about their reasoning. The only option is resubmitting, but:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Important Note: Repeated or egregious policy violations in the Chrome Web Store may result in your developer account being suspended or could lead to a ban from using the Chrome Web Store platform.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In other words: if I don’t understand what’s wrong with my extension, then I better stay away from the resubmission button. Or maybe my update with the new screenshot simply didn’t reach them yet and all I have to do is wait?&lt;/p&gt;
&lt;p&gt;Anyway, dear users of my Google search link fix extension. If you happen to use Google Chrome, I sincerely recommend switching to Mozilla Firefox. No, not only because of this simple extension of course. But Addons.Mozilla.Org policies happen to be enforced in a transparent way, and appealing is always possible. Mozilla also has a good track record of keeping out malicious extensions, something that cannot be said about Chrome Web Store (&lt;a href=&quot;https://palant.de/2018/04/18/the-ticking-time-bomb-fake-ad-blockers-in-chrome-web-store&quot;&gt;a recent example&lt;/a&gt;).&lt;/p&gt;
</description>
<pubDate>Tue, 03 Jul 2018 13:21:16 +0000</pubDate>
<dc:creator>KwanEsq</dc:creator>
<dc:language>en-us</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://palant.de/2018/07/03/google-to-developers-we-take-down-your-extension-because-we-can</dc:identifier>
</item>
<item>
<title>Show HN: Termtosvg – Record terminal sessions as SVG animations</title>
<link>https://github.com/nbedos/termtosvg</link>
<guid isPermaLink="true" >https://github.com/nbedos/termtosvg</guid>
<description>&lt;h3&gt;README.md&lt;/h3&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://travis-ci.org/nbedos/termtosvg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/117a15a683e9f3156029fc3f5cb35800effa739f/68747470733a2f2f7472617669732d63692e6f72672f6e6265646f732f7465726d746f7376672e7376673f6272616e63683d6d6173746572&quot; alt=&quot;Build Status&quot; data-canonical-src=&quot;https://travis-ci.org/nbedos/termtosvg.svg?branch=master&quot;/&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;A Linux terminal recorder written in Python which renders your command line sessions as standalone SVG animations.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://camo.githubusercontent.com/394ba23a29d2fa3586954a81d6fd2a0ab8f478f8/68747470733a2f2f63646e2e7261776769742e636f6d2f6e6265646f732f7465726d746f7376672f302e332e302f6578616d706c65732f617765736f6d652e737667&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/394ba23a29d2fa3586954a81d6fd2a0ab8f478f8/68747470733a2f2f63646e2e7261776769742e636f6d2f6e6265646f732f7465726d746f7376672f302e332e302f6578616d706c65732f617765736f6d652e737667&quot; data-canonical-src=&quot;https://cdn.rawgit.com/nbedos/termtosvg/0.3.0/examples/awesome.svg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;More examples of recordings &lt;a href=&quot;https://github.com/nbedos/termtosvg/blob/0.3.0/examples/examples.md&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Motivation&lt;/h2&gt;
&lt;p&gt;I really like the clean look of SVG animations and I also wanted to see how this solution would hold out against other attempts at terminal recording such as &lt;a href=&quot;https://github.com/asciinema/asciinema&quot;&gt;asciinema&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;termtosvg is compatible with Python &amp;gt;= 3.5 and can be installed with pip:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;pip install termtosvg
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;Usage&lt;/h2&gt;
&lt;h3&gt;Basic usage&lt;/h3&gt;
&lt;p&gt;Start recording with:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ termtosvg
Recording started, enter &quot;exit&quot; command or Control-D to end
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;You are now in a subshell where you can type your commands as usual. Once you are done, exit the shell to end the recording:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ exit
Recording ended, file is /tmp/termtosvg_exp5nsr4.svg
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Finally, use your favorite web browser to play the animation:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ firefox /tmp/termtosvg_exp5nsr4.svg
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3&gt;Detailed usage&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;$ termtosvg --help
usage: termtosvg [output_file] [--font FONT] [--theme THEME] [--help] [--verbose]
Record a terminal session and render an SVG animation on the fly

positional arguments:
  output_file    optional filename of the SVG animation; if missing, a random
                 filename will be automatically generated

optional arguments:
  -h, --help     show this help message and exit
  --font FONT    font to specify in the CSS portion of the SVG animation
                 (DejaVu Sans Mono, Monaco...). If the font is not installed
                 on the viewer's machine, the browser will display a default
                 monospaced font instead.
  --theme THEME  color theme used to render the terminal session (circus,
                 classic-dark, classic-light, dracula, isotope, marrakesh,
                 material, monokai, solarized-dark, solarized-light, zenburn)
  -v, --verbose  increase log messages verbosity

See also 'termtosvg record --help' and 'termtosvg render --help'
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3&gt;Subcommands&lt;/h3&gt;
&lt;p&gt;Rendering the SVG animation while recording might sometimes slow the commands being executed a bit because of the CPU usage, so it is possible to proceed in two steps:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Record the terminal session to disk in asciicast v2 format&lt;/li&gt;
&lt;li&gt;Render the SVG animation using the recording on disk&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;The detailed usage of these two commands is available with &lt;code&gt;termtosvg record --help&lt;/code&gt; and &lt;code&gt;termtosvg render --help&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;Configuration&lt;/h3&gt;
&lt;p&gt;termtosvg configuration file is located at &lt;code&gt;~/.config/termtosvg/termtosvg.ini&lt;/code&gt; and will be created by termtosvg if it does not exist. The configuration file is self-documenting but here are the basics.&lt;/p&gt;
&lt;h4&gt;Global section&lt;/h4&gt;
&lt;p&gt;The 'global' section of the file specifies the font and color theme used.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[global]
font = DejaVu Sans Mono
theme = solarized-dark
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;These options can be overridden at the command line with the &lt;code&gt;--font&lt;/code&gt; and &lt;code&gt;--theme&lt;/code&gt; flags.&lt;/p&gt;
&lt;h4&gt;Color themes&lt;/h4&gt;
&lt;p&gt;All other sections of the file define color themes. For example here's the definition of the theme 'circus':&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[circus]
foreground = #a7a7a7
background = #191919
color0 = #191919
color1 = #dc657d
color2 = #84b97c
color3 = #c3ba63
color4 = #639ee4
color5 = #b888e2
color6 = #4bb1a7
color7 = #a7a7a7
color8 = #5f5a60
color9 = #4bb1a7
color10 = #202020
color11 = #303030
color12 = #505050
color13 = #808080
color14 = #b888e2
color15 = #ffffff
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Color themes can freely be added, removed or modified. Once a color theme has been added to the configuration it can be referred to in the global section of the configuration, or be used at the command line as a parameter to the &lt;code&gt;--theme&lt;/code&gt; flag.&lt;/p&gt;
&lt;h2&gt;Dependencies&lt;/h2&gt;
&lt;p&gt;termtosvg uses:&lt;/p&gt;
&lt;/article&gt;</description>
<pubDate>Tue, 03 Jul 2018 13:06:50 +0000</pubDate>
<dc:creator>nbe</dc:creator>
<og:image>https://avatars3.githubusercontent.com/u/33371440?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>nbedos/termtosvg</og:title>
<og:url>https://github.com/nbedos/termtosvg</og:url>
<og:description>termtosvg - Record terminal sessions as SVG animations</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/nbedos/termtosvg</dc:identifier>
</item>
<item>
<title>Italy Wikipedia shuts down in protest at proposed EU copyright law</title>
<link>https://www.bbc.com/news/world-europe-44696302</link>
<guid isPermaLink="true" >https://www.bbc.com/news/world-europe-44696302</guid>
<description>&lt;figure class=&quot;media-landscape has-caption full-width lead&quot;&gt;&lt;span class=&quot;image-and-copyright-container&quot;&gt;
                
                &lt;img class=&quot;js-image-replace&quot; alt=&quot;A woman stands with her back to the camera, in front of an enormous Wikipedia logo of various jigsaw pieces with different symbols forming a globe&quot; src=&quot;https://ichef.bbci.co.uk/news/320/cpsprodpb/158F7/production/_102311388_gettyimages-860967818.jpg&quot; width=&quot;976&quot; height=&quot;549&quot;/&gt;&lt;span class=&quot;off-screen&quot;&gt;Image copyright&lt;/span&gt;
                 &lt;span class=&quot;story-image-copyright&quot;&gt;Getty Images&lt;/span&gt;
                
            &lt;/span&gt;
            
            &lt;figcaption class=&quot;media-caption&quot;&gt;&lt;span class=&quot;off-screen&quot;&gt;Image caption&lt;/span&gt;
                &lt;span class=&quot;media-caption__text&quot;&gt;
                    Wikipedia's co-founder Jimmy Wales called the new rules a &quot;disastrous EU copyright directive&quot;
                &lt;/span&gt;
            &lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;story-body__introduction&quot;&gt;Italian Wikipedia blocked readers from its pages on Tuesday in protest over the future of EU online copyright law.&lt;/p&gt;&lt;p&gt;Critics say the rules, due to be voted on this week, could put an end to memes and remixes, and require platforms to pay for linking to news.&lt;/p&gt;&lt;p&gt;Instead of an encyclopaedia entry, visitors to any page on the Italian language Wikipedia were greeted with a statement about the upcoming vote. &lt;/p&gt;&lt;p&gt;The editors wrote that &quot;Wikipedia itself would be at risk of closing&quot;.&lt;/p&gt;&lt;p&gt;&quot;If the proposal is approved, it may be impossible to share a newspaper article on social networks or find it on a search engine,&quot; it said.&lt;/p&gt;&lt;p&gt;English-language users of the site were not cut off from its articles - but instead saw a large banner advert urging readers to contact their European representatives, or MEPs, ahead of the vote.&lt;/p&gt;&lt;ul class=&quot;story-body__unordered-list&quot;&gt;&lt;li class=&quot;story-body__list-item&quot;&gt;&lt;a href=&quot;https://www.bbc.com/news/technology-44546620&quot; class=&quot;story-body__link&quot;&gt;'Disastrous' copyright bill vote approved &lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;story-body__list-item&quot;&gt;&lt;a href=&quot;https://www.bbc.com/news/technology-44412025&quot; class=&quot;story-body__link&quot;&gt;Copyright law could put end to net memes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Wikipedia is one of the most visited sites on the internet, currently ranked fifth in the world by traffic ranking site Alexa.&lt;/p&gt;&lt;p&gt;The organisation has been a fierce opponent of the EU's proposed directive on copyright in the digital single market, calling it &quot;a serious threat to our mission&quot;.&lt;/p&gt;&lt;p&gt;Two particular parts of the new rules - articles 11 and 13 - have been the focus of much criticism online.&lt;/p&gt;&lt;p&gt;Article 13 has been the most controversial, requiring websites to enforce copyright, even on content uploaded by users.&lt;/p&gt;&lt;figure class=&quot;media-landscape has-caption full-width&quot;&gt;&lt;span class=&quot;image-and-copyright-container&quot;&gt;
                
                
                
                
                
                 &lt;span class=&quot;off-screen&quot;&gt;Image copyright&lt;/span&gt;
                 &lt;span class=&quot;story-image-copyright&quot;&gt;Wikipedia&lt;/span&gt;
                
            &lt;/span&gt;
            
            &lt;figcaption class=&quot;media-caption&quot;&gt;&lt;span class=&quot;off-screen&quot;&gt;Image caption&lt;/span&gt;
                &lt;span class=&quot;media-caption__text&quot;&gt;
                    Italians visiting Wikipedia on Monday found themselves locked out
                &lt;/span&gt;
            &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Critics believe this could mean that social media sites and others would have to check every piece of content uploaded - a task that would be impossible for humans.&lt;/p&gt;&lt;p&gt;Instead, it would require automated copyright checking systems, put in place by each company - a potentially expensive process.&lt;/p&gt;&lt;p&gt;Such systems have&lt;a href=&quot;https://www.bbc.co.uk/news/technology-42580523&quot; class=&quot;story-body__link&quot;&gt; a high error rate, and have already been controversial on platforms, like YouTube&lt;/a&gt;, where they have been implemented.&lt;/p&gt;&lt;p&gt;Such systems have been labelled &quot;censorship machines&quot; or an &quot;upload filter&quot; by critics of article 13.&lt;/p&gt;&lt;p&gt;It has also led to fears that popular memes, remixes, parodies and other material which use small amounts of copyrighted material could become a thing of the past.&lt;/p&gt;&lt;figure class=&quot;media-landscape no-caption full-width&quot;&gt;&lt;span class=&quot;image-and-copyright-container&quot;&gt;
                
                
                
                
                
            &lt;/span&gt;
            
        &lt;/figure&gt;&lt;p&gt;&lt;a href=&quot;http://www.consilium.europa.eu/media/35373/st09134-en18.pdf&quot; class=&quot;story-body__link-external&quot;&gt;The draft document&lt;/a&gt; does include a specific exemption for &quot;non-for-profit online encyclopaedias&quot;, but that has failed to allay fears.&lt;/p&gt;&lt;ul class=&quot;story-body__unordered-list&quot;&gt;&lt;li class=&quot;story-body__list-item&quot;&gt;&lt;a href=&quot;https://www.bbc.com/news/technology-44482381&quot; class=&quot;story-body__link&quot;&gt;Internet leaders oppose copyright reform&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;story-body__list-item&quot;&gt;&lt;a href=&quot;https://www.bbc.com/news/technology-42580523&quot; class=&quot;story-body__link&quot;&gt;White noise video hit by copyright claims&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Jimmy Wales, a founder of Wikipedia, was among &lt;a href=&quot;https://www.eff.org/files/2018/06/12/article13letter.pdf&quot; class=&quot;story-body__link-external&quot;&gt;dozens of leading technology figures who openly opposed the law&lt;/a&gt;, alongside Tim Berners-Lee, inventor of the World Wide Web.&lt;/p&gt;&lt;h2 class=&quot;story-body__crosshead&quot;&gt;A 'link tax'&lt;/h2&gt;&lt;p&gt;Article 11 of the proposed law requires online platforms to pay publishers a fee if they link to their news content.&lt;/p&gt;&lt;p&gt;The intent is to drive traffic to the home pages of news sites that, at the moment, have their work extensively linked to by huge organisations such as Google and Facebook. &lt;/p&gt;&lt;p&gt;Critics, though, have labelled it a &quot;link tax&quot; which would hand new, broad rights to large publishers and hurt smaller start-ups.&lt;/p&gt;&lt;p&gt;They also say the article fails to clearly define what constitutes a link and could be manipulated by governments to curb freedom of speech.&lt;/p&gt;&lt;p&gt;A collection of 169 &lt;a href=&quot;https://www.ivir.nl/academics-against-press-publishers-right/&quot; class=&quot;story-body__link-external&quot;&gt;European academics wrote that it was &quot;a bad piece of legislation&quot;&lt;/a&gt; which would &quot;impede the free flow of information that is of vital importance to democracy&quot;.&lt;/p&gt;&lt;ul class=&quot;story-body__unordered-list&quot;&gt;&lt;li class=&quot;story-body__list-item&quot;&gt;&lt;a href=&quot;https://www.bbc.com/news/technology-26187730&quot; class=&quot;story-body__link&quot;&gt;Linking to free web content is legal, EU court rules&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Axel Voss, a German MEP and key figure in creating the proposed law, defended it, saying the &quot;big platforms&quot; were behind a misinformation campaign.&lt;/p&gt;&lt;p&gt;&quot;We have, at the moment, an extreme imbalance in the whole copyright system,&quot; he said.&lt;/p&gt;&lt;p&gt;He said that creating links &quot;for a private purpose&quot; was explicitly excluded from the law, which would only affect commercial use.&lt;/p&gt;&lt;p&gt;Mr Voss also rubbished claims of an &quot;upload filter&quot;, saying the proposal would only affect 1%-5% of the internet.&lt;/p&gt;&lt;p&gt;He also said the rules would apply to &quot;only those that actually publish copyright protected content&quot; and earn money from it.&lt;/p&gt;&lt;p&gt;If the European Parliament and Council adopt the draft text, individual governments must then act to implement the directive in their national laws.&lt;/p&gt;&lt;p&gt;In the case of the UK, it would only become law if it comes into force before Brexit &quot;exit day&quot; - 29 March 2019.&lt;/p&gt;
            </description>
<pubDate>Tue, 03 Jul 2018 12:09:09 +0000</pubDate>
<dc:creator>mikece</dc:creator>
<og:title>Italy Wikipedia shuts down in EU protest</og:title>
<og:type>article</og:type>
<og:description>The pages go dark ahead of a vote on controversial new rules on website uploads and links.</og:description>
<og:url>https://www.bbc.co.uk/news/world-europe-44696302</og:url>
<og:image>https://ichef.bbci.co.uk/news/1024/branded_news/158F7/production/_102311388_gettyimages-860967818.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.bbc.com/news/world-europe-44696302</dc:identifier>
</item>
<item>
<title>PEP 572: Python assignment expressions has been accepted</title>
<link>https://groups.google.com/d/msg/dev-python/egS7A22oJgE/Ar6TfdrQCAAJ</link>
<guid isPermaLink="true" >https://groups.google.com/d/msg/dev-python/egS7A22oJgE/Ar6TfdrQCAAJ</guid>
<description>&lt;p&gt;On Wed, Jun 27, 2018 at 07:29:52PM -0500, Tim Peters wrote:&lt;br /&gt;[...]&lt;br /&gt;&amp;gt; For example, if the name is declared &quot;global&quot; in the outer scope, you'll&lt;br /&gt;&amp;gt; get a compile-time error if you try to declare it &quot;nonlocal&quot; in the&lt;br /&gt;&amp;gt; contained scope.  &quot;parentlocal&quot; adjusts its meaning accordingly, becoming a&lt;br /&gt;&amp;gt; synonym for &quot;global&quot; in that specific case.&lt;/p&gt;&lt;p&gt;&quot;Parentlocal&quot; is only a thing if we buy into the paradigm that inside&lt;br /&gt;comprehensions is a separate &quot;local&quot;. And *that* is only true under&lt;br /&gt;two circumstances:&lt;/p&gt;&lt;p&gt;- if you are utterly immersed in the implementation of comprehensions&lt;br /&gt;  as invisible, implicit functions;&lt;/p&gt;&lt;p&gt;- or if you start from the premise that comprehensions ought to&lt;br /&gt;  encapsulate not just the loop variable, but anything else as well.&lt;/p&gt;&lt;p&gt;But experimenting with locals() inside comprehensions shows that&lt;br /&gt;comprehension-scope *isn't* a well-defined thing. It already bleeds out&lt;br /&gt;of the comprehension, and so would some (but only some!) assignment&lt;br /&gt;expressions.&lt;/p&gt;&lt;p&gt;Instead, if we start from the premise that comprehensions (like any&lt;br /&gt;other expression) run in the current scope, then there is no need to&lt;br /&gt;invent a term &quot;parentlocal&quot;. There's just the usual LEGB scopes, plus&lt;br /&gt;class (which people usually forget).&lt;/p&gt;&lt;p&gt;With no sublocal scopes (a term we never even had prior to this PEP)&lt;br /&gt;assignments inside the comprehension are no more special than&lt;br /&gt;assignments inside any other expression. They bind in the current scope,&lt;br /&gt;same as always, and keep the sensible identity that these two&lt;br /&gt;expressions are exactly equivalent in their visible semantics:&lt;/p&gt;&lt;p&gt;    [x:=0, x:=1, x:=2]&lt;/p&gt;&lt;p&gt;    [x:=i for i in (0, 1, 2)]&lt;/p&gt;&lt;p&gt;including assignments.&lt;/p&gt;&lt;p&gt;What about the loop variable?&lt;/p&gt;&lt;p&gt;They ARE special, which is completely justified by the Zen:&lt;/p&gt;&lt;p&gt;Although practicality beats purity.&lt;/p&gt;&lt;p&gt;We can take a series of ever-more-detailed explanations, starting from&lt;br /&gt;the highest &quot;bird's eye&quot; view and gradually dropping further into the&lt;br /&gt;murky details of the implementation when, and if, required:&lt;/p&gt;&lt;p&gt;- assignment within comprehensions is no different from assignment&lt;br /&gt;  in any other expression, it occurs in the local scope;&lt;/p&gt;&lt;p&gt;- loop variables? they're a special case, for good reason, and are&lt;br /&gt;  encapsulated inside the comprehension;&lt;/p&gt;&lt;p&gt;- how? they're hidden in an implicit, invisible scope, same as .0&lt;br /&gt;  the implicit, invisible iterator object;&lt;/p&gt;&lt;p&gt;- oh, you didn't know about the .0 variable? well forget about it,&lt;br /&gt;  it's an undocumented implementation detail, just like the invisible,&lt;br /&gt;  implicit function used by comprehensions;&lt;/p&gt;&lt;p&gt;- oh, you didn't know about that either? read the source code.&lt;/p&gt;&lt;p&gt;Only the first two levels of explanation are part of Python the&lt;br /&gt;language. The rest is CPython implementation.&lt;/p&gt;&lt;p&gt;--&lt;br /&gt;Steve&lt;br /&gt;_______________________________________________&lt;br /&gt;Python-Dev mailing list&lt;br /&gt;&lt;a href=&quot;javascript:void(0);&quot; rel=&quot;nofollow&quot;&gt;Pytho...@python.org&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://mail.python.org/mailman/listinfo/python-dev&quot; rel=&quot;nofollow&quot;&gt;https://mail.python.org/mailman/listinfo/python-dev&lt;/a&gt;&lt;br /&gt;Unsubscribe: &lt;a href=&quot;https://mail.python.org/mailman/options/python-dev/guido%40python.org&quot; rel=&quot;nofollow&quot;&gt;https://mail.python.org/mailman/options/python-dev/guido%40python.org&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 03 Jul 2018 08:30:10 +0000</pubDate>
<dc:creator>est</dc:creator>
<og:title>Re: [Python-Dev] Informal educator feedback on PEP 572 (was Re: 2018 Python Language Summit coverage, last part)</og:title>
<og:type>website</og:type>
<og:url>https://groups.google.com/forum/#!msg/dev-python/egS7A22oJgE/Ar6TfdrQCAAJ</og:url>
<og:description>Posted by Guido van Rossum, Jul 2, 2018 11:21 AM</og:description>
<og:image>http://www.google.com/images/icons/product/groups-128.png</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://groups.google.com/forum/?_escaped_fragment_=msg/dev-python/egS7A22oJgE/Ar6TfdrQCAAJ</dc:identifier>
</item>
<item>
<title>Nancy Pearl’s Rule of 50 for dropping a bad book</title>
<link>https://www.theglobeandmail.com/arts/books-and-media/nancy-pearls-rule-of-50-for-dropping-a-bad-book/article565170/</link>
<guid isPermaLink="true" >https://www.theglobeandmail.com/arts/books-and-media/nancy-pearls-rule-of-50-for-dropping-a-bad-book/article565170/</guid>
<description>&lt;p class=&quot;c-article-body__text&quot;&gt;I was raised in a family in which the dictum &quot;Finish what you start&quot; was the 11th commandment. This stricture was applied in almost every conceivable situation, whether it was eating my father's lovingly (I'm sure) prepared soft-boiled eggs for breakfast (yuck!, way too runny for me), keeping up my elementary-school clarinet lessons long after the limits of my modest musical talent had been reached, or sticking it out at a college that, while it had been my first choice, had clearly proved to be the wrong one.&lt;/p&gt;
&lt;p class=&quot;c-article-body__text&quot;&gt;So it was only natural that when it came to reading, I simply took it for granted that virtue required that I slog through any book I started, whether it was William Thackeray's &lt;em&gt;Vanity Fair&lt;/em&gt; (a hated Grade 10 reading assignment) or Robert Heinlein's &lt;em&gt;Stranger in a Strange Land&lt;/em&gt; (I loved the beginning, but got bored with all the woo-woo philosophy about two-thirds of the way through).&lt;/p&gt;
&lt;p class=&quot;c-article-body__text&quot;&gt;Mine was also a family of readers, with a house full of books, and my childhood library was virtually a second home to me, so I certainly didn't lack for choices in my early reading life. But to my way of thinking back then, I had to finish the book I was reading, even if I already knew that I didn't especially like it, before I could start another one, one that I might love.&lt;/p&gt;
&lt;div class=&quot;u-wrapper pb-feature pb-layout-item pb-f-commercial-dfp-ads&quot; data-fn=&quot;&quot; id=&quot;&quot;&gt;
&lt;div class=&quot;&quot;&gt;
&lt;div id=&quot;c-ad--flex-gpt-1&quot; class=&quot;c-ad c-ad--inline c-ad--flex&quot; readability=&quot;6&quot;&gt;
&lt;div class=&quot;c-ad__wrapper&quot; readability=&quot;7&quot;&gt;
&lt;p class=&quot;c-ad__message&quot;&gt;Story continues below advertisement&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p class=&quot;c-article-body__text&quot;&gt;It wasn't until I became an adult, and a librarian, that I began to question my commitment to finishing each and every book that I began. Now that I really was living a major portion of my life in the library, I literally found myself surrounded by books, tempting me, calling to me from the shelves. How could I - in one lifetime - ever get through everything I wanted to read if I had to finish those books that I discovered to be (at least to me) boring, badly written or just plain bad?&lt;/p&gt;




&lt;p class=&quot;c-article-body__text&quot;&gt;It dawned on me that maybe, just maybe, I didn't have to finish every book I started. Gradually my attitude changed, but not without a struggle. I felt bad for the authors whose books I gave up on. Didn't they deserve a full chance to entice me into the world they'd created? I could hear their voices in my head, like the voice of my conscience, saying, &quot;Wait, wait, it gets better! You haven't gotten to the good part yet.&quot; Oh the guilt, the guilt!&lt;/p&gt;

&lt;p class=&quot;c-article-body__text&quot;&gt;But, little by little, I finally became comfortable with not finishing books that I wasn't enjoying. And then, during the weekly radio show I was doing at the time on KUOW-FM, Seattle's local National Public Radio, my Rule of 50 finally came into focus. We were taking call-ins, as we often did, and I was trying to explain to a caller why I thought it was a mistake to keep reading a book that you've stopped enjoying. The woman on the other end of the line said, &quot;But how many pages should I read before I can guiltlessly stop reading a book?&quot;&lt;/p&gt;
&lt;p class=&quot;c-article-body__text&quot;&gt;On the spur of the moment, with no particular psychological or literary theory in mind to justify it, I developed my Rule of 50:&lt;/p&gt;
&lt;p class=&quot;c-article-body__text&quot;&gt;Give a book 50 pages. When you get to the bottom of Page 50, ask yourself if you're really liking the book. If you are, of course, then great, keep on reading. But if you're not, then put it down and look for another. (Always keep in mind that there's nothing to stop you from going back to it later, whether that might be in six days or six years. Or 60 years. There is many a book that I couldn't get into the first time, or even two, that I tried to read it, and then, giving it one more chance, totally fell under its spell. The book obviously hadn't changed - but I had.)&lt;/p&gt;
&lt;p class=&quot;c-article-body__text&quot;&gt;And if, at the bottom of Page 50, all you're really interested in is who marries whom, or who the murderer is, then turn to the last page and find out. If it's not on the last page, turn to the penultimate page, or the antepenultimate page, or however far back you have to go to discover what you want to know. And rest assured that, despite the sophistication of computerized checkout and check-in technology at the modern library, there's no way that anyone there will be able to tell (even if they were interested) whether you've really read every page of the book you just returned.&lt;/p&gt;
&lt;p class=&quot;c-article-body__text&quot;&gt;This rule of 50 worked exceedingly well until I entered my own 50s. As I wended my way toward 60, and beyond, I could no longer avoid the realization that, while the reading time remaining in my life was growing shorter, the world of books that I wanted to read was, if anything, growing larger. In a flash of, if I do say so myself, brilliance, I realized that my Rule of 50 was incomplete. It needed an addendum. And here it is: When you are 51 years of age or older, subtract your age from 100, and the resulting number (which, of course, gets smaller every year) is the number of pages you should read before you can guiltlessly give up on a book. As the saying goes, &quot;Age has its privileges.&quot;&lt;/p&gt;
&lt;div class=&quot;u-wrapper pb-feature pb-layout-item pb-f-commercial-dfp-ads&quot; data-fn=&quot;&quot; id=&quot;&quot;&gt;
&lt;div class=&quot;&quot;&gt;
&lt;div id=&quot;c-ad--flex-gpt-2&quot; class=&quot;c-ad c-ad--inline c-ad--flex&quot; readability=&quot;6&quot;&gt;
&lt;div class=&quot;c-ad__wrapper&quot; readability=&quot;7&quot;&gt;
&lt;p class=&quot;c-ad__message&quot;&gt;Story continues below advertisement&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;js-ad-slimcut-wrapper&quot; class=&quot;c-ad c-ad--slimcut u-hidden&quot; readability=&quot;6&quot;&gt;
&lt;div class=&quot;c-ad__wrapper&quot; aria-hidden=&quot;true&quot; readability=&quot;7&quot;&gt;
&lt;p class=&quot;c-ad__message&quot;&gt;Story continues below advertisement&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;p class=&quot;c-article-body__text&quot;&gt;And the ultimate privilege of age, of course, is that when you turn 100, you are authorized (by the Rule of 50) to judge a book by its cover.&lt;/p&gt;
&lt;p class=&quot;c-article-body__text&quot;&gt;&lt;em&gt;Nancy Pearl is a librarian, critic, radio commentator and author of Book Lust. She is also the only librarian with her own action figure.&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 03 Jul 2018 07:51:49 +0000</pubDate>
<dc:creator>ingve</dc:creator>
<og:title>Nancy Pearl's Rule of 50 for dropping a bad book</og:title>
<og:url>https://www.theglobeandmail.com/arts/books-and-media/nancy-pearls-rule-of-50-for-dropping-a-bad-book/article565170/</og:url>
<og:description>A simple axiom from the only librarian in the world to have her own action figure</og:description>
<og:type>article</og:type>
<dc:language>en-CA</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.theglobeandmail.com/arts/books-and-media/nancy-pearls-rule-of-50-for-dropping-a-bad-book/article565170/</dc:identifier>
</item>
<item>
<title>The impact of the ‘open’ workspace on human collaboration</title>
<link>http://rstb.royalsocietypublishing.org/content/373/1753/20170239</link>
<guid isPermaLink="true" >http://rstb.royalsocietypublishing.org/content/373/1753/20170239</guid>
<description>&lt;div class=&quot;section abstract&quot; id=&quot;abstract-1&quot; readability=&quot;22&quot;&gt;
&lt;h2&gt;Abstract&lt;/h2&gt;
&lt;p id=&quot;p-3&quot;&gt;Organizations’ pursuit of increased workplace collaboration has led managers to transform traditional office spaces into ‘open’, transparency-enhancing architectures with fewer walls, doors and other spatial boundaries, yet there is scant direct empirical research on how human interaction patterns change as a result of these architectural changes. In two intervention-based field studies of corporate headquarters transitioning to more open office spaces, we empirically examined—using digital data from advanced wearable devices and from electronic communication servers—the effect of open office architectures on employees' face-to-face, email and instant messaging (IM) interaction patterns. Contrary to common belief, the volume of face-to-face interaction decreased significantly (approx. 70%) in both cases, with an associated increase in electronic interaction. In short, rather than prompting increasingly vibrant face-to-face collaboration, open architecture appeared to trigger a natural human response to socially withdraw from officemates and interact instead over email and IM. This is the first study to empirically measure both face-to-face and electronic interaction before and after the adoption of open office architecture. The results inform our understanding of the impact on human behaviour of workspaces that trend towards fewer spatial boundaries.&lt;/p&gt;
&lt;p id=&quot;p-4&quot;&gt;This article is part of the theme issue ‘Interdisciplinary approaches for uncovering the impacts of architecture on collective behaviour’.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;sec-1&quot; readability=&quot;107.32693783576&quot;&gt;
&lt;h2 class=&quot;&quot;&gt;1. Introduction&lt;/h2&gt;
&lt;p id=&quot;p-5&quot;&gt;Boundaries between ‘us’ and ‘them’ have long captured human interest. Yet even as social scientists continue to study the value of a vast array of boundaries [&lt;a id=&quot;xref-ref-1-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-1&quot;&gt;1&lt;/a&gt;], in an era in which the nature of work is changing [&lt;a id=&quot;xref-ref-2-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-2&quot;&gt;2&lt;/a&gt;–&lt;a id=&quot;xref-ref-4-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-4&quot;&gt;4&lt;/a&gt;], managers and organizational scholars have increasingly framed boundaries as barriers to interaction that ought to be spanned [&lt;a id=&quot;xref-ref-5-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-5&quot;&gt;5&lt;/a&gt;–&lt;a id=&quot;xref-ref-8-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-8&quot;&gt;8&lt;/a&gt;], permeated [&lt;a id=&quot;xref-ref-9-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-9&quot;&gt;9&lt;/a&gt;] or blurred [&lt;a id=&quot;xref-ref-10-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-10&quot;&gt;10&lt;/a&gt;] to increase collaboration. In the most physically salient and concrete example, ‘spatial boundaries’ [&lt;a id=&quot;xref-ref-11-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-11&quot;&gt;11&lt;/a&gt;] at work—such as office or cubicle walls—are being removed to create open ‘unbounded’ offices in order to stimulate greater collaboration and collective intelligence. Does it work?&lt;/p&gt;
&lt;p id=&quot;p-6&quot;&gt;Prior theory is divided—and empirical evidence mixed—on the effect that removing spatial boundaries has on human behaviour in the space previously within those boundaries (e.g. [&lt;a id=&quot;xref-ref-12-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-12&quot;&gt;12&lt;/a&gt;,&lt;a id=&quot;xref-ref-13-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-13&quot;&gt;13&lt;/a&gt;]). On the one hand, sociological theory presents a strong argument that removing spatial boundaries to bring more people into contact should &lt;em&gt;increase&lt;/em&gt; collaboration and collective intelligence. The notion that propinquity, or proximity, predicts social interaction [&lt;a id=&quot;xref-ref-14-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-14&quot;&gt;14&lt;/a&gt;]—driving the formation of social ties and therefore information exchange and collaboration—is one of the most robust findings in sociology [&lt;a id=&quot;xref-ref-15-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-15&quot;&gt;15&lt;/a&gt;,&lt;a id=&quot;xref-ref-16-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-16&quot;&gt;16&lt;/a&gt;]. It has been observed in contexts as diverse as the US Congress [&lt;a id=&quot;xref-ref-17-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-17&quot;&gt;17&lt;/a&gt;,&lt;a id=&quot;xref-ref-18-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-18&quot;&gt;18&lt;/a&gt;], nineteenth-century boarding houses [&lt;a id=&quot;xref-ref-19-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-19&quot;&gt;19&lt;/a&gt;], college dormitories [&lt;a id=&quot;xref-ref-14-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-14&quot;&gt;14&lt;/a&gt;], laboratories [&lt;a id=&quot;xref-ref-20-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-20&quot;&gt;20&lt;/a&gt;], co-working spaces [&lt;a id=&quot;xref-ref-21-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-21&quot;&gt;21&lt;/a&gt;] and corporate buildings [&lt;a id=&quot;xref-ref-22-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-22&quot;&gt;22&lt;/a&gt;]. When spatial boundaries—such as walls—are removed, individuals feel more physically proximate, which, such theory suggests, should lead to more interaction. Such interaction is a necessary foundation for collective intelligence—a form of distributed intelligence that arises from the social interaction of individuals [&lt;a id=&quot;xref-ref-23-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-23&quot;&gt;23&lt;/a&gt;] and that predicts, more so than the intelligence of individual members, a group's general ability to perform a wide variety of tasks [&lt;a id=&quot;xref-ref-24-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-24&quot;&gt;24&lt;/a&gt;–&lt;a id=&quot;xref-ref-26-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-26&quot;&gt;26&lt;/a&gt;]. Much like the swarm intelligence observed among cognitively simple agents such as social insects and other animals [&lt;a id=&quot;xref-ref-27-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-27&quot;&gt;27&lt;/a&gt;–&lt;a id=&quot;xref-ref-29-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-29&quot;&gt;29&lt;/a&gt;], collective intelligence for groups of humans requires interaction [&lt;a id=&quot;xref-ref-30-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-30&quot;&gt;30&lt;/a&gt;]. If greater propinquity drives greater interaction, it should generate greater collaboration and collective intelligence.&lt;/p&gt;
&lt;p id=&quot;p-7&quot;&gt;On the other hand, some organizational scholars, especially social psychologists and environmental psychologists, have shown that removing spatial boundaries can &lt;em&gt;decrease&lt;/em&gt; collaboration and collective intelligence. Spatial boundaries have long served a functional role at multiple levels of analysis, helping people make sense of their environment by modularizing it [&lt;a id=&quot;xref-ref-31-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-31&quot;&gt;31&lt;/a&gt;], clarifying who is watching and who is not, who has information and who does not, who belongs and who does not, who controls what and who does not, to whom one answers and to whom one does not [&lt;a id=&quot;xref-ref-32-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-32&quot;&gt;32&lt;/a&gt;]. This school of thought, like theories of organizational design and architecture [&lt;a id=&quot;xref-ref-29-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-29&quot;&gt;29&lt;/a&gt;], assumes that spatial boundaries built into workspace architecture support collaboration and collective intelligence by mitigating the effects of the cognitive constraints of the human beings working within them. Like social insects which swarm within functionally-determined zones ‘partitioned’ by spatial boundaries (e.g. hives, nests or schools) [&lt;a id=&quot;xref-ref-29-3&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-29&quot;&gt;29&lt;/a&gt;], human beings—despite their greater cognitive abilities—may also require boundaries to constrain their interactions, thereby reducing the potential for overload, distraction, bias, myopia and other symptoms of bounded rationality. Research as far back as the foundational Hawthorne Studies [&lt;a id=&quot;xref-ref-33-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-33&quot;&gt;33&lt;/a&gt;,&lt;a id=&quot;xref-ref-34-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-34&quot;&gt;34&lt;/a&gt;] shows that being walled off can therefore increase interaction within the separated group [&lt;a id=&quot;xref-ref-33-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-33&quot;&gt;33&lt;/a&gt;]. Similarly, subsequent workplace design research (for reviews, see [&lt;a id=&quot;xref-ref-35-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-35&quot;&gt;35&lt;/a&gt;–&lt;a id=&quot;xref-ref-38-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-38&quot;&gt;38&lt;/a&gt;])—though mixed in its findings—suggests that open offices can reduce certain conditions conducive to collaboration and collective intelligence, including employee satisfaction [&lt;a id=&quot;xref-ref-39-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-39&quot;&gt;39&lt;/a&gt;,&lt;a id=&quot;xref-ref-40-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-40&quot;&gt;40&lt;/a&gt;], focus [&lt;a id=&quot;xref-ref-41-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-41&quot;&gt;41&lt;/a&gt;–&lt;a id=&quot;xref-ref-44-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-44&quot;&gt;44&lt;/a&gt;], psychological privacy [&lt;a id=&quot;xref-ref-45-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-45&quot;&gt;45&lt;/a&gt;,&lt;a id=&quot;xref-ref-46-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-46&quot;&gt;46&lt;/a&gt;] and other affective and behavioural responses [&lt;a id=&quot;xref-ref-40-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-40&quot;&gt;40&lt;/a&gt;,&lt;a id=&quot;xref-ref-41-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-41&quot;&gt;41&lt;/a&gt;,&lt;a id=&quot;xref-ref-43-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-43&quot;&gt;43&lt;/a&gt;,&lt;a id=&quot;xref-ref-47-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-47&quot;&gt;47&lt;/a&gt;,&lt;a id=&quot;xref-ref-48-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-48&quot;&gt;48&lt;/a&gt;]. Such negative psychological effects of open offices conceivably may lead to less, not more, interaction between those within them [&lt;a id=&quot;xref-ref-49-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-49&quot;&gt;49&lt;/a&gt;], reducing collaboration and collective intelligence.&lt;/p&gt;
&lt;p id=&quot;p-8&quot;&gt;To our knowledge, no prior study has directly measured the effect on &lt;em&gt;actual interaction&lt;/em&gt; that results from removing spatial boundaries to create an open office environment. Past workplace design research, rather than directly and objectively measuring behaviours, has relied heavily on survey-based or activity-log methodologies, which provided self-reported measures, or on social observation studies, which provided an observer's subjective interpretation of human interactions. Several decades ago, when much of the workplace design research was conducted, measuring actual interaction patterns of individuals at work in both traditional and open office environments would have been prohibitively difficult, but new ‘people analytics’ technology has made it quite feasible.&lt;/p&gt;
&lt;p id=&quot;p-9&quot;&gt;Using two field studies of organizations transforming their office architecture by removing spatial boundaries to become more open, we empirically measure the effect on interaction, carefully tracking face-to-face (F2F) interaction before and after the transition with wearable sociometric devices [&lt;a id=&quot;xref-ref-50-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-50&quot;&gt;50&lt;/a&gt;,&lt;a id=&quot;xref-ref-51-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-51&quot;&gt;51&lt;/a&gt;] that avoid the imprecise and subjective survey-based self-reported measures typical of previous office collaboration studies [&lt;a id=&quot;xref-ref-52-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-52&quot;&gt;52&lt;/a&gt;,&lt;a id=&quot;xref-ref-53-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-53&quot;&gt;53&lt;/a&gt;]. We also measure two digital channels of interaction—email and instant messaging (IM) [&lt;a id=&quot;xref-ref-54-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-54&quot;&gt;54&lt;/a&gt;–&lt;a id=&quot;xref-ref-56-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-56&quot;&gt;56&lt;/a&gt;]—using information from the organizations' own servers.&lt;/p&gt;
&lt;p id=&quot;p-10&quot;&gt;In the first study, we focus on the most basic set of empirical questions: what is the effect of transitioning from cubicles to open workspaces on the overall &lt;em&gt;volume&lt;/em&gt; and &lt;em&gt;type&lt;/em&gt; of interaction, with what implications for organizational performance based on the company's own performance management system? In the second study, we replicate the first study's results and then consider two more-targeted empirical questions: how does spatial &lt;em&gt;distance&lt;/em&gt; between workstations moderate the effect of transitioning from cubicles to open workspaces and how do individual employee interaction &lt;em&gt;networks&lt;/em&gt;, both F2F and electronic, change differentially? While the first study considers interactions involving &lt;em&gt;individuals&lt;/em&gt;, the second considers interactions for &lt;em&gt;dyads&lt;/em&gt; (both sides of the interaction), allowing a more precise but limited investigation of the effects.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;sec-2&quot; readability=&quot;80.771535580524&quot;&gt;
&lt;h2 class=&quot;&quot;&gt;2. Study 1&lt;/h2&gt;
&lt;p id=&quot;p-11&quot;&gt;The first empirical study, a quasi-field experiment [&lt;a id=&quot;xref-ref-57-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-57&quot;&gt;57&lt;/a&gt;,&lt;a id=&quot;xref-ref-58-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-58&quot;&gt;58&lt;/a&gt;], was conducted at the global headquarters of OpenCo1,&lt;sup&gt;&lt;a id=&quot;xref-fn-2-1&quot; class=&quot;xref-fn&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#fn-2&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; a Fortune 500 multinational. In a so-called war on walls, OpenCo1 decided to use the latest open office workstation products to completely transform the wall-bounded workspaces in its headquarters so that one entire floor was open, transparent and boundaryless.&lt;/p&gt;
&lt;p id=&quot;p-12&quot;&gt;The redesign—which required people to move from assigned seats on their original floor to similarly assigned seats on a redesigned floor of the same size—affected employees in functions including technology, sales and pricing, human resources (HR), finance, and product development, as well as the top leadership. Of those people, a cluster of 52 (roughly 40%) agreed to participate in the experiment. A comparison of HR data for participants and nonparticipants provided no evidence of nonresponse bias. Because of the nature of office space, all employees moved from the old space to the redesigned space at the same time, so the experiment was structured with an interrupted time-series design [&lt;a id=&quot;xref-ref-58-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-58&quot;&gt;58&lt;/a&gt;].&lt;/p&gt;
&lt;p id=&quot;p-13&quot;&gt;To capture a full, data-rich picture of interaction patterns both before and after the boundaries were removed, participants were asked to wear a sensor, known as a sociometric badge [&lt;a id=&quot;xref-ref-59-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-59&quot;&gt;59&lt;/a&gt;], that recorded, in great detail, their F2F interactions: an infrared (IR) sensor captured whom they were facing (by making contact with the other person's IR sensor), microphones captured whether they were talking or listening (but not what was said), an accelerometer captured body movement and posture, and a Bluetooth sensor captured spatial location (&lt;a id=&quot;xref-fig-1-1&quot; class=&quot;xref-fig&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#F1&quot;&gt;figure 1&lt;/a&gt;). All sensors recorded time-stamped data in 10 ms intervals. Based on prior research using these sociometric badges [&lt;a id=&quot;xref-ref-50-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-50&quot;&gt;50&lt;/a&gt;], an F2F interaction was recorded when three conditions were met: two or more badges (i) were facing each other (with uninterrupted infrared line-of-sight), (ii) detected alternating speaking, and (iii) were within 10 m of each other. The interaction ended when any of the three criteria ceased to be true for more than 5 s. While these criteria were based on precedent from significant prior use of sociometric badges, sensitivity analysis showed the results to be robust to reasonable alternative assumptions (including shorter distances in 1 m increments, different lag times before concluding an interaction, and different speaking patterns). This F2F data was combined with email and IM data for the same time periods, collected from the company's servers, to create a full picture of these professionals' interactions before and after the redesign.&lt;/p&gt;
&lt;div id=&quot;F1&quot; class=&quot;fig pos-float odd&quot; readability=&quot;3.2777777777778&quot;&gt;
&lt;div class=&quot;highwire-figure&quot;&gt;
&lt;div class=&quot;fig-inline-img-wrapper&quot;&gt;
&lt;div class=&quot;fig-inline-img&quot;&gt;&lt;a href=&quot;http://rstb.royalsocietypublishing.org/content/royptb/373/1753/20170239/F1.large.jpg?width=800&amp;amp;height=600&amp;amp;carousel=1&quot; title=&quot;Sociometric badge. (Online version in colour.)&quot; class=&quot;highwire-fragment fragment-images colorbox-load&quot; rel=&quot;gallery-fragment-images-1164620834&quot; data-figure-caption=&quot;&amp;lt;div class=&amp;quot;highwire-markup&amp;quot;&amp;gt;Sociometric badge. (Online version in colour.)&amp;lt;/div&amp;gt;&quot; data-icon-position=&quot;&quot; data-hide-link-title=&quot;0&quot;&gt;&lt;span class=&quot;hw-responsive-img&quot;&gt;&lt;img class=&quot;highwire-fragment fragment-image lazyload&quot; alt=&quot;Figure 1.&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7&quot; data-src=&quot;http://rstb.royalsocietypublishing.org/content/royptb/373/1753/20170239/F1.medium.gif&quot; width=&quot;416&quot; height=&quot;440&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;highwire-fragment fragment-image&quot; alt=&quot;Figure 1.&quot; src=&quot;http://rstb.royalsocietypublishing.org/content/royptb/373/1753/20170239/F1.medium.gif&quot; width=&quot;416&quot; height=&quot;440&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/span&gt;&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div xmlns:xhtml=&quot;http://www.w3.org/1999/xhtml&quot; class=&quot;fig-caption&quot; readability=&quot;7&quot;&gt;&lt;span class=&quot;fig-label&quot;&gt;Figure 1.&lt;/span&gt;
&lt;p id=&quot;p-14&quot; class=&quot;first-child&quot;&gt;Sociometric badge. (Online version in colour.)&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;p id=&quot;p-15&quot;&gt;Data were collected in two phases: for 15 workdays (three weeks) before the redesign and, roughly three months later, for 15 workdays after the redesign. Three-week data collection windows were chosen as a balance between the organization's desire to minimize the burden of the research study on its employees and our need to control for the possibility of idiosyncratic daily and weekly variations in employee schedules. The three-month gap between phases was chosen for two reasons. First, work at OpenCo1's global headquarters followed quarterly cycles, so a three-month gap allowed us to conduct the two data-collection phases at the same point in the quarter. Second, it allowed just over two months of adjustment after the move, enough for people to have settled into their new environment but not so much that the work they did could have changed much.&lt;/p&gt;
&lt;p id=&quot;p-16&quot;&gt;The dataset included 96 778 F2F interactions, 84 026 emails (18 748 sent, 55 012 received, 9755 received by cc and 511 received by bcc) and 25 691 IMs (consisting of 221 426 words). The most straightforward and conservative empirical strategy for analysing the intervention was to simply aggregate and then compare pre-intervention and post-intervention volumes:&lt;span class=&quot;disp-formula&quot; id=&quot;disp-formula-1&quot;&gt;&lt;span class=&quot;highwire-responsive-lazyload&quot;&gt;&lt;img src=&quot;data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7&quot; class=&quot;highwire-embed lazyload&quot; alt=&quot;Embedded Image&quot; data-src=&quot;http://rstb.royalsocietypublishing.org/sites/default/files/highwire/royptb/373/1753/20170239/embed/graphic-2.gif&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;highwire-embed&quot; alt=&quot;Embedded Image&quot; src=&quot;http://rstb.royalsocietypublishing.org/sites/default/files/highwire/royptb/373/1753/20170239/embed/graphic-2.gif&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/span&gt; &lt;span class=&quot;disp-formula-label&quot;&gt;2.1&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p id=&quot;p-17&quot;&gt;&lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;it&lt;/sub&gt;, the dependent variable, is the amount of interaction—F2F or electronic—where ‘i’ is the individual in question and ‘t’ is the phase (pre- or post-redesign). Post&lt;sub&gt;it&lt;/sub&gt; is an indicator variable that equals 1 if the interaction occurred after the redesign. The main estimation used ordinary least-squares (OLS) regressions with person fixed effects, although all results were robust to the exclusion of person fixed effects. Standard errors were corrected for autocorrelation and clustered by individual [&lt;a id=&quot;xref-ref-60-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-60&quot;&gt;60&lt;/a&gt;]. If the redesign increased F2F interaction, we should see a positive and significant &lt;em&gt;β&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;— the coefficient reported in the ‘Post’ column of &lt;a id=&quot;xref-table-wrap-1-1&quot; class=&quot;xref-table&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#T1&quot;&gt;table 1&lt;/a&gt;—when &lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;it&lt;/sub&gt; is F2F interaction (the first row of &lt;a id=&quot;xref-table-wrap-1-2&quot; class=&quot;xref-table&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#T1&quot;&gt;table 1&lt;/a&gt;). More generally, in &lt;a id=&quot;xref-table-wrap-1-3&quot; class=&quot;xref-table&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#T1&quot;&gt;table 1&lt;/a&gt;, the effect on a particular kind of interaction due to the transition to more open architecture is reported in the ‘post’ column, where a negative number indicates reduced interaction and a positive number indicates increased interaction.&lt;/p&gt;
&lt;div id=&quot;T1&quot; class=&quot;table pos-float&quot; readability=&quot;8.2884615384615&quot;&gt;
&lt;div class=&quot;table-inline table-callout-links&quot;&gt;
&lt;div class=&quot;callout&quot;&gt;&lt;span&gt;View this table:&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;table-caption&quot; readability=&quot;12&quot;&gt;&lt;span class=&quot;table-label&quot;&gt;Table 1.&lt;/span&gt;
&lt;p id=&quot;p-18&quot; class=&quot;first-child&quot;&gt;Impact of open offices on interaction at OpenCo1. Models are OLS with person fixed effects and with standard errors clustered by individual in parentheses. Coefficients represent minutes of face-to-face (F2F) interaction, number of email messages or IM messages, or number of words in IM between a member of the study and all others at work during the period of the study. *&lt;em&gt;p&lt;/em&gt;&amp;lt;0.05; **&lt;em&gt;p&lt;/em&gt;&amp;lt;0.01; ***&lt;em&gt;p&lt;/em&gt;&amp;lt;0.001.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-3&quot; class=&quot;subsection&quot; readability=&quot;21.936231884058&quot;&gt;
&lt;h3&gt;(a) Study 1 results&lt;/h3&gt;
&lt;div id=&quot;sec-4&quot; class=&quot;subsection&quot; readability=&quot;28&quot;&gt;
&lt;h4&gt;(i) Volume of interaction&lt;/h4&gt;
&lt;p id=&quot;p-19&quot;&gt;Although OpenCo1's primary purpose in opening up the space had been to increase F2F interactions, the 52 participants now spent 72% &lt;em&gt;less&lt;/em&gt; time interacting F2F. Prior to the redesign, they accumulated 5266 min of interaction over 15 days, or roughly 5.8 h of F2F interaction per person per day. After the redesign, those same people accumulated only 1492 min of interaction over 15 days, or roughly 1.7 h per person per day.&lt;/p&gt;
&lt;p id=&quot;p-20&quot;&gt;Even though everyone on the floor could see everyone else all the time (or perhaps &lt;em&gt;because&lt;/em&gt; they could), virtual interaction replaced F2F interaction in the newly boundaryless space. After the redesign, participants collectively sent 56% (66) more emails to other participants over 15 days, received 20% (78) more emails from other participants, and were cc'd on 41% (27) more emails from other participants. (For the received and cc'd volumes, emails sent are counted once for each recipient.) Bcc: activity, which was low in volume and limited to a small subset of individuals, did not significantly change. IM message activity increased by 67% (99 more messages) and words sent by IM increased by 75% (850 more words). Thus—to restate more precisely—in boundaryless space, electronic interaction replaced F2F interaction.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-5&quot; class=&quot;subsection&quot; readability=&quot;15.875808538163&quot;&gt;
&lt;h4&gt;(ii) Performance outcome&lt;/h4&gt;
&lt;p id=&quot;p-21&quot;&gt;Should we be concerned about these effects? One indication of the meaningfulness of this shift in behaviour was its effect on performance. In an internal and confidential management review, OpenCo1 executives reported to us qualitatively that productivity, as defined by the metrics used by their internal performance management system, had declined after the redesign to eliminate spatial boundaries. Consistent with research on the impact of a decline in media richness on productivity [&lt;a id=&quot;xref-ref-54-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-54&quot;&gt;54&lt;/a&gt;,&lt;a id=&quot;xref-ref-55-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-55&quot;&gt;55&lt;/a&gt;] and on the particular challenges of email [&lt;a id=&quot;xref-ref-61-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-61&quot;&gt;61&lt;/a&gt;], it is not necessarily surprising that productivity declined due to a substitution of email for F2F interaction. What is surprising is that more open, transparent architecture prompted such a substitution.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;sec-6&quot; readability=&quot;65.48062477644&quot;&gt;
&lt;h2 class=&quot;&quot;&gt;3. Study 2&lt;/h2&gt;
&lt;p id=&quot;p-22&quot;&gt;Given the findings from Study 1, another organization was recruited to further this research. Our goal was to conduct a conceptual replication of the first study with a longer time window. This second empirical study was also a quasi-field experiment at a Fortune 500 multinational and was conducted at the global headquarters of OpenCo2.&lt;sup&gt;&lt;a id=&quot;xref-fn-3-1&quot; class=&quot;xref-fn&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#fn-3&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; At the time of the study, OpenCo2 was in the process of a multi-year headquarters redesign, which—as in Study 1—involved a transformation from assigned seats in cubicles to similarly assigned seats in an open office design, with large rooms of desks and monitors and no dividers between people's desks.&lt;/p&gt;
&lt;p id=&quot;p-23&quot;&gt;We again collected F2F data using sociometric badges and email data from company servers, this time for 100 employees from a single floor, which was roughly 45% of the employees on that floor. As in Study 1, data were collected in two phases: for eight weeks starting three months prior to the redesign of this particular floor and for eight weeks starting two months after the redesign. But for this study, we also collected detailed data on the participants; namely, three employee attributes—gender, team assignment and role—and one architectural attribute—desk location. In the first phase, desks were in cubicles, so seats were roughly 2 m apart and directly adjacent to one another. In the second phase, seats still lay roughly 2 m apart and directly adjacent to one another, but were grouped at undivided and unwalled tables of six to eight. Seat location allowed us to calculate the physical distance between dyads of employee workstations before and after the redesign, such that we could include physical distance, as well as the other employee attributes, as control variables. The OpenCo2 dataset included 63 363 min of F2F interaction and 25 553 emails, all generated by 1830 dyads—those with interaction—of the 100 employees involved. Mindful of Study 1's consistent results across multiple forms of electronic communication, Study 2 only collected email data to measure electronic interaction. The empirical strategy was similar:&lt;span class=&quot;disp-formula&quot; id=&quot;disp-formula-2&quot;&gt;&lt;span class=&quot;highwire-responsive-lazyload&quot;&gt;&lt;img src=&quot;data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7&quot; class=&quot;highwire-embed lazyload&quot; alt=&quot;Embedded Image&quot; data-src=&quot;http://rstb.royalsocietypublishing.org/sites/default/files/highwire/royptb/373/1753/20170239/embed/graphic-3.gif&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;highwire-embed&quot; alt=&quot;Embedded Image&quot; src=&quot;http://rstb.royalsocietypublishing.org/sites/default/files/highwire/royptb/373/1753/20170239/embed/graphic-3.gif&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/span&gt; &lt;span class=&quot;disp-formula-label&quot;&gt;3.1&lt;/span&gt;&lt;/span&gt;and&lt;span class=&quot;disp-formula&quot; id=&quot;disp-formula-3&quot;&gt;&lt;span class=&quot;highwire-responsive-lazyload&quot;&gt;&lt;img src=&quot;data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7&quot; class=&quot;highwire-embed lazyload&quot; alt=&quot;Embedded Image&quot; data-src=&quot;http://rstb.royalsocietypublishing.org/sites/default/files/highwire/royptb/373/1753/20170239/embed/graphic-4.gif&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;highwire-embed&quot; alt=&quot;Embedded Image&quot; src=&quot;http://rstb.royalsocietypublishing.org/sites/default/files/highwire/royptb/373/1753/20170239/embed/graphic-4.gif&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/span&gt; &lt;span class=&quot;disp-formula-label&quot;&gt;3.2&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p id=&quot;p-24&quot;&gt;In equation (3.1), as in equation (2.1), &lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;jt&lt;/sub&gt;, the dependent variable, is the amount of interaction, F2F or electronic. However, because the physical-distance control variable was dyadic, &lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;jt&lt;/sub&gt; must also be specific to a particular dyad ‘j’ (rather than to an individual ‘i’, as in Study 1). As in Study 1, ‘t’ refers to the phase (pre- or post-redesign). Post&lt;sub&gt;jt&lt;/sub&gt; is an indicator variable that equals 1 if the dyadic interaction occurred after the redesign. In equation (3.2), we investigate specific control variables—characteristics of each dyad—rather than just dyad fixed effects. Physical Distance&lt;sub&gt;jt&lt;/sub&gt; is the distance between the dyad's workstations, measured as the shortest walking path (in metres). Gender&lt;sub&gt;j&lt;/sub&gt;, Team&lt;sub&gt;j&lt;/sub&gt; and Role&lt;sub&gt;j&lt;/sub&gt; are indicator variables that equal 1 if the two individuals in the dyad were of the same gender, on the same team, or in the same role, and equal 0 otherwise. The main estimation used OLS regressions with either dyad fixed effects (2) or distance, gender, team and role controls (3). Standard errors of the coefficients were corrected for autocorrelation and clustered by dyad [&lt;a id=&quot;xref-ref-60-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-60&quot;&gt;60&lt;/a&gt;]. If the redesign increased F2F interaction, we should see a positive and significant &lt;em&gt;β&lt;/em&gt;&lt;sub&gt;1&lt;/sub&gt;—the coefficient reported in the ‘post’ row of &lt;a id=&quot;xref-table-wrap-2-1&quot; class=&quot;xref-table&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#T2&quot;&gt;table 2&lt;/a&gt;—when &lt;em&gt;Y&lt;/em&gt;&lt;sub&gt;it&lt;/sub&gt; is F2F interaction. More generally, in &lt;a id=&quot;xref-table-wrap-2-2&quot; class=&quot;xref-table&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#T2&quot;&gt;table 2&lt;/a&gt;, we report the effect of the transition to open architecture on particular types of interaction in the ‘post’ row, where a negative number indicates reduced interaction and a positive number indicates increased interaction. For the control variables, we report the coefficient for the entire sample without regard to whether the office architecture involved cubicles or open spaces, as our purpose in including those variables is to remove gender, team and role effects from the variable of interest, Post. For example, the significant and positive coefficient for Team means that those on the same team communicated more than those on different teams (for both cubicles and open spaces), and the significant and positive coefficient for Role means that those in the same role communicated more than those in different roles (for both cubicles and open spaces).&lt;/p&gt;
&lt;div id=&quot;T2&quot; class=&quot;table pos-float&quot; readability=&quot;9.2804621848739&quot;&gt;
&lt;div class=&quot;table-inline table-callout-links&quot;&gt;
&lt;div class=&quot;callout&quot;&gt;&lt;span&gt;View this table:&lt;/span&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;table-caption&quot; readability=&quot;14&quot;&gt;&lt;span class=&quot;table-label&quot;&gt;Table 2.&lt;/span&gt;
&lt;p id=&quot;p-25&quot; class=&quot;first-child&quot;&gt;Impact of open offices on interaction at OpenCo2. Models are OLS with standard errors clustered by dyad in parentheses. Models 1 and 3 include dyad fixed effects. In Models 1 and 2, coefficients represent minutes of F2F interaction between a particular dyad during the period of the study. In Models 3 and 4, coefficients represent number of emails between a particular dyad during the period of the study. *&lt;em&gt;p&lt;/em&gt;&amp;lt;0.05, **&lt;em&gt;p&lt;/em&gt;&amp;lt;0.01, ***&lt;em&gt;p&lt;/em&gt;&amp;lt;0.001.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-7&quot; class=&quot;subsection&quot; readability=&quot;36.133677167549&quot;&gt;
&lt;h3&gt;(a) Study 2 results&lt;/h3&gt;
&lt;div id=&quot;sec-8&quot; class=&quot;subsection&quot; readability=&quot;32&quot;&gt;
&lt;h4&gt;(i) Volume of interactions&lt;/h4&gt;
&lt;p id=&quot;p-26&quot;&gt;As a result of the redesign, 643 dyads decreased their F2F interaction and 141 dyads increased it. At the same time, 222 dyads decreased their email interaction and 374 dyads increased it. Like OpenCo1, OpenCo2 had hoped, by opening up the space, to increase F2F interactions, but the results did not bear this out. The 100 employees—or 1830 dyads—we tracked spent between 67% (Model 1, 12.79/17.99) and 71% (Model 2, 9.81/14.63) &lt;em&gt;less&lt;/em&gt; time interacting F2F. Instead, they emailed each other between 22% (Model 3, 1.24/5.75) and 50% (Model 4, 1.54/3.07) more.&lt;/p&gt;
&lt;p id=&quot;p-27&quot;&gt;As one might suspect, dyads on the same team or with the same role communicated more, both F2F and by email, relative to dyads on different teams or in different roles. Gender, in contrast, had no significant effect on the volume of either form of interaction. Physical distance did show a small inverse effect on F2F interaction (Model 2): the nearer the two workstations, the more F2F interaction. This effect was notable both for its small size relative to the size of the effect of the open office and for the fact that it was limited to F2F interaction (not email). We investigate this in further detail next.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;sec-9&quot; class=&quot;subsection&quot; readability=&quot;40.375370292002&quot;&gt;
&lt;h4&gt;(ii) The effect of physical distance on F2F versus email&lt;/h4&gt;
&lt;p id=&quot;p-28&quot;&gt;Model 2 of &lt;a id=&quot;xref-table-wrap-2-3&quot; class=&quot;xref-table&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#T2&quot;&gt;table 2&lt;/a&gt; shows that the effect of physical distance on F2F interaction is small—and the effect on email insignificant—relative to that of openness. The relatively small effect of distance on F2F interaction was surprising given that repeated studies have shown that people talk more to those who are physically closer to them [&lt;a id=&quot;xref-ref-62-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-62&quot;&gt;62&lt;/a&gt;,&lt;a id=&quot;xref-ref-63-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-63&quot;&gt;63&lt;/a&gt;]. When others are physically proximate, it is easier to be aware of them [&lt;a id=&quot;xref-ref-64-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-64&quot;&gt;64&lt;/a&gt;], start conversations with them [&lt;a id=&quot;xref-ref-64-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-64&quot;&gt;64&lt;/a&gt;,&lt;a id=&quot;xref-ref-65-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-65&quot;&gt;65&lt;/a&gt;], unexpectedly encounter or overhear them [&lt;a id=&quot;xref-ref-66-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-66&quot;&gt;66&lt;/a&gt;], and manage their impressions of our collaborative work behaviour [&lt;a id=&quot;xref-ref-67-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-67&quot;&gt;67&lt;/a&gt;]. Nonetheless, our review of these prior studies found none that directly measured interaction volumes, and thus perhaps—while present—the effect of distance on F2F interaction may be far more minimal than previously thought.&lt;/p&gt;
&lt;p id=&quot;p-29&quot;&gt;&lt;a id=&quot;xref-table-wrap-2-4&quot; class=&quot;xref-table&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#T2&quot;&gt;Table 2&lt;/a&gt;, however, does not allow us to compare the relative effects of physical distance on F2F interaction and on email interaction. To do so, we used a latent space model called the Latent Position Clustering Model [&lt;a id=&quot;xref-ref-68-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-68&quot;&gt;68&lt;/a&gt;] to take into account clustering and to control for other covariates. We find that physical distance affected F2F interaction twice as much as it did email interaction. As a robustness check, we used several machine learning algorithms, such as a Random Forest, to see if changes in F2F networks prompted by changes in physical distance predicted changes in email networks. Across all models, we find that F2F networks and email networks respond very differently to changes in the built environment, with changes in one type of network failing to predict changes in the other.&lt;/p&gt;
&lt;p id=&quot;p-30&quot;&gt;This variance between the adaptation of F2F and electronic networks in response to a change in physical space is an important finding for future research on collaboration and collective intelligence. In several notable cases, past research has relied on email alone [&lt;a id=&quot;xref-ref-69-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-69&quot;&gt;69&lt;/a&gt;,&lt;a id=&quot;xref-ref-70-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-70&quot;&gt;70&lt;/a&gt;] to study topics ranging from the Enron debacle to the relationship between office layout and interaction, basing claims about F2F interaction on findings from electronic interaction data. Our finding that changes in workplace design affect electronic and F2F interaction networks differently (and, on some measures, in opposite directions) should make future researchers wary of using one network as a proxy for the other.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;section&quot; id=&quot;sec-10&quot; readability=&quot;107.18926689027&quot;&gt;
&lt;h2 class=&quot;&quot;&gt;4. Discussion&lt;/h2&gt;
&lt;p id=&quot;p-31&quot;&gt;We began with a specific research question: does removing spatial boundaries at work to create open, unbounded offices increase interaction? Our two empirical field studies were consistent in their answer: open, unbounded offices reduce F2F interaction with a magnitude, in these contexts, of about 70%. Electronic interaction takes up at least some of the slack, increasing by roughly 20% to 50% (as measured by ‘To:’ received email).&lt;/p&gt;
&lt;p id=&quot;p-32&quot;&gt;Many organizations, like our two field sites, transform their office architectures into open spaces with the intention of creating more F2F interaction and thus a more vibrant work environment. What they often get—as captured by a steady stream of news articles professing the death of the open office [&lt;a id=&quot;xref-ref-71-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-71&quot;&gt;71&lt;/a&gt;–&lt;a id=&quot;xref-ref-73-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-73&quot;&gt;73&lt;/a&gt;]—is an open expanse of proximal employees choosing to isolate themselves as best they can (e.g. by wearing large headphones [&lt;a id=&quot;xref-ref-74-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-74&quot;&gt;74&lt;/a&gt;]) while appearing to be as busy as possible (since everyone can see them). Recent studies [&lt;a id=&quot;xref-ref-75-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-75&quot;&gt;75&lt;/a&gt;] and earlier research [&lt;a id=&quot;xref-ref-40-3&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-40&quot;&gt;40&lt;/a&gt;,&lt;a id=&quot;xref-ref-41-3&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-41&quot;&gt;41&lt;/a&gt;,&lt;a id=&quot;xref-ref-43-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-43&quot;&gt;43&lt;/a&gt;,&lt;a id=&quot;xref-ref-47-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-47&quot;&gt;47&lt;/a&gt;,&lt;a id=&quot;xref-ref-48-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-48&quot;&gt;48&lt;/a&gt;] have investigated the self-reported dissatisfaction of employees in open offices, but to our knowledge, we are the first to empirically study the direct behavioural impact of open office space on the volume of F2F and electronic interaction. Our results support three cautionary tales.&lt;/p&gt;
&lt;p id=&quot;p-33&quot;&gt;First, transitions to open office architecture do not necessarily promote open interaction. Consistent with the fundamental human desire for privacy [&lt;a id=&quot;xref-ref-76-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-76&quot;&gt;76&lt;/a&gt;] and prior evidence that privacy may increase productivity [&lt;a id=&quot;xref-ref-32-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-32&quot;&gt;32&lt;/a&gt;,&lt;a id=&quot;xref-ref-45-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-45&quot;&gt;45&lt;/a&gt;], when office architecture makes everyone more observable or ‘transparent’, it can dampen F2F interaction, as employees find other strategies to preserve their privacy; for example, by choosing a different channel through which to communicate [&lt;a id=&quot;xref-ref-39-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-39&quot;&gt;39&lt;/a&gt;]. Rather than have an F2F interaction in front of a large audience of peers, an employee might look around, see that a particular person is at his or her desk, and send an email.&lt;/p&gt;
&lt;p id=&quot;p-34&quot;&gt;The second caution relates to the impact of a transition to open office architecture on collective intelligence. We still have much to learn about how collective intelligence works [&lt;a id=&quot;xref-ref-77-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-77&quot;&gt;77&lt;/a&gt;], as we borrow from and distinguish parallel work on swarm intelligence among social insects and some other animals. While the earliest work assumed open spaces would promote collective intelligence among humans, our findings support more recent work that has begun to suggest otherwise. Kao &amp;amp; Couzin, in modelling the presence of multiple cues and the possibility of observing them, find that intermediate (rather than maximal) levels of cues produce higher levels of collective intelligence [&lt;a id=&quot;xref-ref-78-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-78&quot;&gt;78&lt;/a&gt;]. We see a close relationship between our finding that open, ‘transparent’ offices may be overstimulating and thus decrease organizational productivity and Kao &amp;amp; Couzin's demonstration that finitely bounded, and often small, group size maximizes decision accuracy in complex, realistic environments. Similarly, recent collective intelligence work suggests that, like our open offices, too much information from social data can be problematic, partly because of challenges focusing attention [&lt;a id=&quot;xref-ref-74-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-74&quot;&gt;74&lt;/a&gt;,&lt;a id=&quot;xref-ref-79-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-79&quot;&gt;79&lt;/a&gt;], but also for reasons that extend to more general functions of human cognition. For example, by connecting human cognition and collective intelligence with the behaviour of eusocial insects, Toyokawa &lt;em&gt;et al&lt;/em&gt;. found that richness in social information was detrimental to collective intelligence outcomes, with performance being best when social learning opportunities were constrained [&lt;a id=&quot;xref-ref-80-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-80&quot;&gt;80&lt;/a&gt;]. Similarly, in a study involving human subjects, Bernstein &lt;em&gt;et al&lt;/em&gt;. found that intermittent rather than constant social influence produced the best performance among humans collectively engaged in complex problem solving [&lt;a id=&quot;xref-ref-81-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-81&quot;&gt;81&lt;/a&gt;]. As we are reminded in Hight &amp;amp; Perry's article on collective intelligence and architectural design, ‘collective intelligence is not simply technical, but also explicitly social, political, and by extension, professional’ [&lt;a id=&quot;xref-ref-2-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-2&quot;&gt;2&lt;/a&gt;, p. 6]. Our findings empirically reinforce their caution that the relationship between architectural design and collective intelligence extends beyond technical considerations.&lt;/p&gt;
&lt;p id=&quot;p-35&quot;&gt;The third caution is that transitions to open office architecture can have different effects on different channels of interaction. In our studies, openness decreased F2F interaction with an associated increase in email interaction. In the digital age, employees can choose from multiple channels of interaction [&lt;a id=&quot;xref-ref-54-3&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-54&quot;&gt;54&lt;/a&gt;] and a change in office architecture may affect that choice.&lt;/p&gt;
&lt;p id=&quot;p-36&quot;&gt;Complementing prior research on media richness suggesting that substituting email for F2F interaction can lower productivity [&lt;a id=&quot;xref-ref-53-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-53&quot;&gt;53&lt;/a&gt;], our studies highlight two other consequences. First, because fundamentally different mechanisms drive F2F and email interaction, the physical propinquity that redesigned offices seek to achieve has a direct effect only on F2F interaction, not on email, yet drives interaction from F2F to email. Adopting open offices, therefore, appears to have the perverse outcome of reducing rather than increasing productive interaction. Second, F2F and email networks differ. Although prior studies have investigated one or the other [&lt;a id=&quot;xref-ref-56-2&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-56&quot;&gt;56&lt;/a&gt;,&lt;a id=&quot;xref-ref-82-1&quot; class=&quot;xref-bibr&quot; href=&quot;http://rstb.royalsocietypublishing.org/content/373/1753/20170239#ref-82&quot;&gt;82&lt;/a&gt;], none has empirically linked F2F and email network interaction to discern how good a proxy one is for the other. We find that they are poor proxies for each other. Therefore, an intervention that redirects interaction from one network to another, like the open office redesigns studied here, not only changes the channel of interaction, but also skews &lt;em&gt;whom&lt;/em&gt; a person interacts with. That can have profound consequences for how—and how productively—work gets done.&lt;/p&gt;
&lt;p id=&quot;p-37&quot;&gt;In summary, because the antecedents of human interaction at work go beyond proximity and visibility, the effects of open office architecture on collaboration are not as simple as previously thought. While it is possible to bring chemical substances together under specific conditions of temperature and pressure to form the desired compound, more factors seem to be at work in achieving a similar effect with humans. Until we understand those factors, we may be surprised to find a reduction in F2F collaboration at work even as we architect transparent, open spaces intended to increase it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section dataaccess&quot; id=&quot;sec-11&quot; readability=&quot;9&quot;&gt;
&lt;h2 class=&quot;&quot;&gt;Data accessibility&lt;/h2&gt;
&lt;p id=&quot;p-38&quot;&gt;We are unable to provide open access to our data owing to their sensitive nature and the nondisclosure and confidentiality agreements that surround them. Please contact the corresponding author for more information.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section aucontribute&quot; id=&quot;sec-12&quot; readability=&quot;8&quot;&gt;
&lt;h2 class=&quot;&quot;&gt;Authors' contributions&lt;/h2&gt;
&lt;p id=&quot;p-39&quot;&gt;E.S.B. carried out all work on Study 1 and drafted the manuscript. S.T. carried out all work on Study 2 and helped draft the manuscript. Both authors gave final approval for publication.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section competing&quot; id=&quot;sec-13&quot; readability=&quot;7&quot;&gt;
&lt;h2 class=&quot;&quot;&gt;Competing interests&lt;/h2&gt;
&lt;p id=&quot;p-40&quot;&gt;We declare we have no competing interests.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section funding&quot; id=&quot;sec-14&quot; readability=&quot;8&quot;&gt;
&lt;h2 class=&quot;&quot;&gt;Funding&lt;/h2&gt;
&lt;p id=&quot;p-41&quot;&gt;Funding for these studies was provided by the Division of Research and Faculty Development at the Harvard Business School.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;section ack&quot; id=&quot;ack-1&quot; readability=&quot;15&quot;&gt;
&lt;h2 class=&quot;&quot;&gt;Acknowledgements&lt;/h2&gt;
&lt;p id=&quot;p-42&quot;&gt;The authors thank Editor Steve Fiore and two anonymous reviewers for developmental, insightful and encouraging comments throughout the review process, as well as Senior Commissioning Editor Helen Eaton for her guidance. We also thank Ben Waber, Taemie Kim, Laura Freeman and the rest of the team at Humanyze, without whom we would have been unable to collect the unique datasets underlying these studies.&lt;/p&gt;
&lt;/div&gt;

&lt;ul class=&quot;history-list&quot;&gt;&lt;li xmlns:hwp=&quot;http://schema.highwire.org/Journal&quot; class=&quot;accepted&quot; hwp:start=&quot;2018-05-03&quot;&gt;&lt;span class=&quot;accepted-label&quot;&gt;Accepted&lt;/span&gt; May 3, 2018.&lt;/li&gt;
&lt;/ul&gt;&lt;ul class=&quot;copyright-statement&quot;&gt;&lt;li class=&quot;fn&quot; id=&quot;copyright-statement-1&quot;&gt;© 2018 The Authors.&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;license&quot; id=&quot;license-1&quot; readability=&quot;8.8597285067873&quot;&gt;
&lt;p id=&quot;p-2&quot;&gt;Published by the Royal Society under the terms of the Creative Commons Attribution License &lt;a href=&quot;http://creativecommons.org/licenses/by/4.0/&quot; rel=&quot;license&quot;&gt;http://creativecommons.org/licenses/by/4.0/&lt;/a&gt;, which permits unrestricted use, provided the original author and source are credited.&lt;/p&gt;
&lt;/div&gt;

</description>
<pubDate>Tue, 03 Jul 2018 07:22:05 +0000</pubDate>
<dc:creator>tosh</dc:creator>
<og:title>The impact of the ‘open’ workspace on human collaboration</og:title>
<og:url>http://rstb.royalsocietypublishing.org/content/373/1753/20170239</og:url>
<og:image>http://rstb.royalsocietypublishing.org/sites/default/files/highwire/royptb/373/1753.cover-source.jpg</og:image>
<og:description>Organizations’ pursuit of increased workplace collaboration has led managers to transform traditional office spaces into ‘open’, transparency-enhancing architectures with fewer walls, doors and other spatial boundaries, yet there is scant direct empirical research on how human interaction patterns change as a result of these architectural changes. In two intervention-based field studies of corporate headquarters transitioning to more open office spaces, we empirically examined—using digital data from advanced wearable devices and from electronic communication servers—the effect of open office architectures on employees' face-to-face, email and instant messaging (IM) interaction patterns. Contrary to common belief, the volume of face-to-face interaction decreased significantly (approx. 70%) in both cases, with an associated increase in electronic interaction. In short, rather than prompting increasingly vibrant face-to-face collaboration, open architecture appeared to trigger a natural human response to socially withdraw from officemates and interact instead over email and IM. This is the first study to empirically measure both face-to-face and electronic interaction before and after the adoption of open office architecture. The results inform our understanding of the impact on human behaviour of workspaces that trend towards fewer spatial boundaries. This article is part of the theme issue ‘Interdisciplinary approaches for uncovering the impacts of architecture on collective behaviour’.</og:description>
<og:type>article</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://rstb.royalsocietypublishing.org/content/373/1753/20170239</dc:identifier>
</item>
<item>
<title>“Stylish” browser extension steals all your internet history</title>
<link>https://robertheaton.com/2018/07/02/stylish-browser-extension-steals-your-internet-history/</link>
<guid isPermaLink="true" >https://robertheaton.com/2018/07/02/stylish-browser-extension-steals-your-internet-history/</guid>
<description>&lt;p&gt;02 Jul 2018&lt;/p&gt;
&lt;p&gt;Before it became a covert surveillance tool disguised as an outstanding browser extension, &lt;a href=&quot;https://userstyles.org&quot;&gt;Stylish&lt;/a&gt; really was an outstanding browser extension. It bestowed upon its users nothing less than the power to change the appearance of the internet. Its extensive bank of user-made skins gave bright websites a dark background, undid disliked UI changes, and added manga pictures to everything that wasn’t a manga picture already. I spent many wonderful hours in its simple CSS editor, &lt;a href=&quot;https://robertheaton.com/2016/08/08/hide-the-internet/&quot;&gt;hiding the distracting parts of the web&lt;/a&gt; whilst unknowingly being spied on. Facebook news feed - gone. Twitter news feed - gone. Personal browsing history - gone. Quality of life and unexplained ennui - up and down respectively.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://robertheaton.com/images/stylish-fb.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately, since January 2017, Stylish has been augmented with bonus spyware that records every single website that I and its 2 million other users visit. Stylish sends our complete browsing activity back to its servers, together with a unique identifier. This allows it’s new owner, &lt;a href=&quot;https://www.similarweb.com&quot;&gt;SimilarWeb&lt;/a&gt;, to connect all of an individual’s actions into a single profile. And for users like me who have created a Stylish account on &lt;a href=&quot;https://userstyles.org&quot;&gt;userstyles.org&lt;/a&gt;, this unique identifier can easily be linked to a login cookie. This means that not only does SimilarWeb own a copy of our complete browsing histories, they also own enough other data to theoretically tie these histories to email addresses and real-world identities.&lt;/p&gt;
&lt;p&gt;Stylish’s transition from visual Valhalla to privacy Chernobyl began when the original owner and creator of Stylish sold it in August 2016. In January 2017 the new owner sold it again, announcing that &lt;a href=&quot;https://forum.userstyles.org/discussion/53233/announcement-to-the-community&quot;&gt;“Stylish is now part of the SimilarWeb family”&lt;/a&gt;. The SimilarWeb family’s promotional literature lists “Market Solutions To See All Your Competitors’ Traffic” amongst its interests. I’m starting to feel like I might have become the product. I understand that it probably isn’t SimilarWeb company policy to threaten to show their users’ browsing history to their mothers and rabbis unless they hand over a big pile of cash. But it wasn’t Equifax company policy to lose all those Social Security Numbers either.&lt;/p&gt;

&lt;p&gt;The SimilarWeb Privacy Policy says that they only collect “non-personal” data, and I assume that this is technically true. But accidents happen. When you unwittingly entrust your personal data to a company like SimilarWeb, not only do you have to hope that they have no actively evil intentions (besides those listed on their pricing page). You also have to hope that they have good data access controls, no rogue employees, and strong enough security to prevent the theft of all their data (formerly your data). Worse, even the filching of a nominally anonymized list of URLs has significant privacy and security implications. De-anonymization using IP addresses and the specifics of a user’s browsing history is often straightforward. Who do &lt;em&gt;you&lt;/em&gt; think that person visiting &lt;code class=&quot;highlighter-rouge&quot;&gt;https://www.linkedin.com/in/robertjheaton/edit&lt;/code&gt; might be?&lt;/p&gt;
&lt;p&gt;Single URLs with no additional context can be very sensitive too. For example, some websites use URLs containing special authentication tokens to log their users in automatically when they click a link in an email. When a user clicks on a link like &lt;code class=&quot;highlighter-rouge&quot;&gt;mysocialnetwork.com/inbox?login_token=fsdj80d...etc...&lt;/code&gt;, the website uses the long, secret &lt;code class=&quot;highlighter-rouge&quot;&gt;login_token&lt;/code&gt; in the URL as an alternative password, and logs the user into their account. This is a risky but sometimes defensible practice that relies on login tokens staying secret and unguessable. However, since they are part of the URL, Stylish happily records them and sends them back to the SimilarWeb servers. Their databases presumably contain secondary login credentials for user accounts on any number of other services.&lt;/p&gt;
&lt;p&gt;Sensitive URLs crop up elsewhere too. My online medical provider shows me my medical documents using secret, 1000-character long URLs (generated by Amazon S3) that expire within a minute or so. For these pages, no login authentication beyond simply knowing the URL is required. Anyone who guessed the authentication token in the URL before it expired would be able to view and download my medical documents. In my opinion this is not best practice on the part of my online medical provider’s engineering team. But the real world is full of things that are not best practice, and no conventional attacker is actually going to be able to guess a 1000-character long URL within a minute. Stylish makes life easier for them by harvesting the whole thing and recording it in their database. Now this stupid advertising company also owns pointers to my medical records. I really hope they never get hacked.&lt;/p&gt;
&lt;p&gt;Most prevalently, many websites use URL tokens to allow users to reset a forgotten password. When a user clicks on the “Forgot Your Password?” button, the website sends them an email containing a special link. This link points to a long URL that looks something like &lt;code class=&quot;highlighter-rouge&quot;&gt;mysocialnetwork.com/password-reset?reset_token=a3dJ3...etc...&lt;/code&gt;. When the user clicks on it, the website reads the &lt;code class=&quot;highlighter-rouge&quot;&gt;reset_token&lt;/code&gt;, looks up the corresponding user, and allows them to safely reset their password. However, if an attacker were able to intercept these URLs and complete the password-reset process before the real user, they would gain total control over the account. Once again, Stylish hoovers up these password-reset URLs, taking its users’ privacy and security into its own hands.&lt;/p&gt;

&lt;p&gt;Even though Stylish’s new snooping functionality has been &lt;a href=&quot;https://www.bleepingcomputer.com/news/software/2-million-users-impacted-by-new-data-collection-policy-in-stylish-browser-add-on/&quot;&gt;public knowledge since the SimilarWeb announcement&lt;/a&gt;, I only discovered it last week whilst doing some unrelated work on a different website. It was like catching my favorite uncle picking his nose and eating it and stealing my passport. On the other hand, I never paid my uncle for any of the nice things he did for me, so what did I expect?&lt;/p&gt;
&lt;p&gt;Whilst looking at &lt;a href=&quot;https://portswigger.net/burp&quot;&gt;Burp Suite&lt;/a&gt;, I noticed a large number of strange-looking requests going to &lt;code class=&quot;highlighter-rouge&quot;&gt;api.userstyles.org&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://robertheaton.com/images/stylish-burp-1-3.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;HTTP requests that send a large blob of obfuscated data to a URL ending in &lt;code class=&quot;highlighter-rouge&quot;&gt;/stats&lt;/code&gt; are almost never good news for users. I noticed that the data blob contained only letters and numbers and ended in &lt;code class=&quot;highlighter-rouge&quot;&gt;%3D&lt;/code&gt;, the URL encoding for an &lt;code class=&quot;highlighter-rouge&quot;&gt;=&lt;/code&gt; sign. This made me suspect that the blob had been &lt;a href=&quot;https://en.wikipedia.org/wiki/Base64&quot;&gt;Base64 encoded&lt;/a&gt;. I tried Base64 decoding it:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://robertheaton.com/images/stylish-burp-2-2.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Still nonsense. But the decoded string also contained only letters and numbers, and also ended in an &lt;code class=&quot;highlighter-rouge&quot;&gt;=&lt;/code&gt; sign. I tried Base64 decoding it a second time:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://robertheaton.com/images/stylish-3-2.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Pyrrhic victory. When I looked at the contents of the decoded payload, I realized that Stylish was exfiltrating all my browsing data. I Googled “stylish spyware” and found lots of shops selling fashionable espionage gear. I also found plenty of articles confirming that &lt;a href=&quot;https://www.ghacks.net/2017/01/04/major-stylish-add-on-changes-in-regards-to-privacy/&quot;&gt;Stylish were up to no good&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I looked closer at the decoded payload and noted a unique tracking identifier. I remembered that I had signed up for a Stylish account in order to &lt;a href=&quot;https://robertheaton.com/2016/08/08/hide-the-internet/&quot;&gt;share some of my distraction-hiding skins with the world&lt;/a&gt;. I wondered whether my session cookie would get appended to Stylish’s tracking requests if I logged in to &lt;code class=&quot;highlighter-rouge&quot;&gt;userstyles.org&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Of course, it did. Stylish’s session cookie is scoped to &lt;code class=&quot;highlighter-rouge&quot;&gt;*.userstyles.org&lt;/code&gt;, so it gets sent to every &lt;code class=&quot;highlighter-rouge&quot;&gt;userstyles.org&lt;/code&gt; sub-domain as well. To Stylish’s very partial credit, the cookie is set to be very short-lived, and expires as soon as the browser is closed. This means that it is not appended to every tracking request - only the ones sent after the user logs in to &lt;code class=&quot;highlighter-rouge&quot;&gt;userstyles.org&lt;/code&gt; but before they next close the browser. However, it only takes one tracking request containing one session cookie to permanently associate a user account with a Stylish tracking identifier. This means that Stylish and SimilarWeb still have all the data they need to connect a real-world identity to a browsing history, should they or a hacker choose to.&lt;/p&gt;

&lt;p&gt;It’s not news that browser extensions can be a security nightmare. It’s not even enough to trust an extension’s current, benevolent owner. Even the benevolent have to make a buck eventually, and quiet sales to organizations like SimpleWeb are not uncommon. SimilarWeb claims that they need to track every single website Stylish’s users visit in order to recommend them styles for the current webpage. This is a solution in search of a flimsy justification. If this were all they were doing then they would only need to send themselves the current page’s domain, not the full URL. And it doesn’t even begin to explain why they also need to scrape and send themselves your actual Google search results from your browser window.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://robertheaton.com/images/stylish-google.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;There’s a check box in the Stylish control panel that claims to disable tracking, although SimilarWeb helpfully enable it by default. It does appear to work, at least until the next change to Stylish’s &lt;a href=&quot;https://userstyles.org/login/policy&quot;&gt;2,000-word privacy policy&lt;/a&gt; or 3,000-word Terms and Conditions. However, Stylish is no longer a well-meaning product with your best interests at heart. If you use and like Stylish, please uninstall it and switch to an alternative like &lt;a href=&quot;https://www.ghacks.net/2017/05/16/stylus-is-a-stylish-fork-without-analytics/&quot;&gt;Stylus&lt;/a&gt;, an offshoot from the good old version of Stylish that works in much the same way, minus the spyware.&lt;/p&gt;
&lt;section readability=&quot;4&quot;&gt;&lt;h3&gt;Get new essays sent to you&lt;/h3&gt;
&lt;p&gt;I publish new work on programming, security, and a few other topics several times a month.&lt;/p&gt;

&lt;/section&gt;&lt;section&gt;&lt;a href=&quot;https://twitter.com/intent/tweet/?text=&quot; browser=&quot;&quot; extension=&quot;&quot; steals=&quot;&quot; all=&quot;&quot; your=&quot;&quot; internet=&quot;&quot; history=&quot;&quot; by=&quot;&quot; target=&quot;_blank&quot; aria-label=&quot;Twitter&quot;&gt;Tweet&lt;/a&gt; / &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=robjheaton&amp;amp;region=follow_link&amp;amp;tw_p=followbutton&quot; target=&quot;_blank&quot; aria-label=&quot;Follow @RobJHeaton&quot;&gt;Follow @RobJHeaton&lt;/a&gt;    &lt;/section&gt;&lt;h3&gt;More posts on Online Tracking&lt;/h3&gt;
&lt;section class=&quot;navigation&quot;&gt;
&lt;/section&gt;</description>
<pubDate>Tue, 03 Jul 2018 05:37:22 +0000</pubDate>
<dc:creator>mbaye</dc:creator>
<og:image>https://robertheaton.com/images/stylish-prev2.png</og:image>
<og:url>http://robertheaton.com/2018/07/02/stylish-browser-extension-steals-your-internet-history/</og:url>
<og:type>article</og:type>
<og:title>&quot;Stylish&quot; browser extension steals all your internet history | Robert Heaton</og:title>
<og:description>Before it became a covert surveillance tool disguised as an outstanding browser extension, Stylish really was an outstanding browser extension. It bestowed upon its users nothing less than the power to change the appearance of the internet. Its extensive bank of user-made skins gave bright websites a dark background, undid disliked UI changes, and added manga pictures to everything that wasn’t a manga picture already. I spent many wonderful hours in its simple CSS editor, hiding the distracting parts of the web whilst unknowingly being spied on. Facebook news feed...</og:description>
<dc:format>text/html</dc:format>
<dc:identifier>https://robertheaton.com/2018/07/02/stylish-browser-extension-steals-your-internet-history/</dc:identifier>
</item>
<item>
<title>The Hidden Cost of Touchscreens</title>
<link>https://medium.com/@caseorganic/why-do-we-keep-building-cars-with-touchscreens-alt-the-hidden-lives-of-touchscreens-55faf92799bf</link>
<guid isPermaLink="true" >https://medium.com/@caseorganic/why-do-we-keep-building-cars-with-touchscreens-alt-the-hidden-lives-of-touchscreens-55faf92799bf</guid>
<description>&lt;p name=&quot;369c&quot; id=&quot;369c&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;In 2012 I tried out a brand new luxury vehicle at a automotive conference. It was a minimalist European model, and nothing seemed out of place — until I tried to use the in-car entertainment system. The whole thing was a monolithic rectangle of reflective, flat glass. The touchscreen software was bizarre and clunky. It took me five steps to pair my phone to the car, and I had to devote all my attention to the display just to figure it out. There were no physical buttons for the basics – like changing the volume or turning on the radio. I couldn’t imagine what it might be like to drive with it at night.&lt;/p&gt;
&lt;p name=&quot;79a6&quot; id=&quot;79a6&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;I expressed my frustration to the man sitting next to me. “I can’t believe the company let this thing on the road with this horrible display! It’s as if this entire system was tested in a lab under ideal conditions, but never once on the road with a single confused driver!”&lt;/p&gt;
&lt;p name=&quot;7d14&quot; id=&quot;7d14&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The man started laughing at my outburst. Then he apologized and gave me his card. As it turned out, he was the head of company.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*Zt2eaUYKum3vEH-VJgqJIw.png&quot; data-width=&quot;672&quot; data-height=&quot;518&quot; data-is-featured=&quot;true&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*Zt2eaUYKum3vEH-VJgqJIw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1200/1*Zt2eaUYKum3vEH-VJgqJIw.png&quot;/&gt;&lt;/div&gt;
Tesla’s 2012 touchscreen display (via &lt;a href=&quot;https://www.thecarconnection.com/overview/tesla_model-s_2012#image=100179523&quot; data-href=&quot;https://www.thecarconnection.com/overview/tesla_model-s_2012#image=100179523&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;Car Connection&lt;/a&gt;)
&lt;p name=&quot;d5f0&quot; id=&quot;d5f0&quot; class=&quot;graf graf--p graf--startsWithDoubleQuote graf-after--figure&quot;&gt;“The quality of the touchscreen is my fault”, he admitted, “we never tested it on the road”. Apparently the management was so convinced that the entertainment system’s blue-tinted, rectangular touchscreen interface was “the future” that the company didn’t even bother using it on the road before releasing it. After all, Tesla had recently debuted (to much acclaim), its first model which boasted a similar touchscreen system. Now that this new company’s own car was in mass production, it would take many years to undo the damage.&lt;/p&gt;
&lt;p name=&quot;5dda&quot; id=&quot;5dda&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Physical interfaces are crucial for automotive usability. Operations rely on a simple glance or muscle memory. Touchscreens, by contrast, force drivers to look. Because buttons are not fixed to specific locations, screens inhibit muscle memory and findability. Touchscreens compete for attention with the driving process, adding to the dangers of distracted driving.&lt;/p&gt;
&lt;blockquote name=&quot;46b1&quot; id=&quot;46b1&quot; class=&quot;graf graf--blockquote graf-after--p&quot; readability=&quot;11&quot;&gt;
&lt;p&gt;&lt;strong class=&quot;markup--strong markup--blockquote-strong&quot;&gt;&lt;em class=&quot;markup--em markup--blockquote-em&quot;&gt;Serious interfaces&lt;/em&gt; — &lt;em class=&quot;markup--em markup--blockquote-em&quot;&gt;those that are repeatedly used by a knowledgeable professional and/or in potentially hazardous situations, should not be touchscreen based. If a touchscreen must be used, it should be embedded alongside a set of fixed, physical buttons that support muscle memory and single actions.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p name=&quot;9523&quot; id=&quot;9523&quot; class=&quot;graf graf--p graf-after--blockquote&quot;&gt;What’s happening to in-car interfaces now? Five years later, we’re seeing some car models stick to physical buttons and dials, and that’s a great relief.&lt;/p&gt;
&lt;p name=&quot;07e5&quot; id=&quot;07e5&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Beyond safety considerations, there are productivity gains inherent in physical controls. When I worked in a mailroom during college, I processed packages with a very ugly keyboard-based system. I learned the machine in a single day and it quickly became part of me; the data density it could rapidly handle was enormous. In the same way that high school students bond with graphing calculators in Calculus class, we can become intertwined with these physical interfaces in a way that doesn’t force us to think when we use them. We work with them and they work with us. They could be considered one of Donna Haraway’s “companion species”.&lt;/p&gt;
&lt;p name=&quot;b288&quot; id=&quot;b288&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Touchscreens are not completely terrible. In the right cases, they’re incredibly useful. They’re already pervasive in service-related industries, but these screens usually have software that is glanceable, color-coded and professional. And they’re not meant to be used in moving vehicles!&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*6Ni7RxMyF4EGUSwU.&quot; data-width=&quot;669&quot; data-height=&quot;600&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*6Ni7RxMyF4EGUSwU.&quot; src=&quot;https://cdn-images-1.medium.com/max/1200/0*6Ni7RxMyF4EGUSwU.&quot;/&gt;&lt;/div&gt;
Example of an image-based touchscreen point of service system
&lt;p name=&quot;900f&quot; id=&quot;900f&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Touchscreen design could benefit from some basic design principles. Color-based interfaces take less time to parse when they are glanced at. Image-based interfaces take longer for the brain to process, and the lack of contrast can be confusing, because each item must be distinguished from adjacent items. When so many images look alike, service workers must rely on position and muscle memory for speedy use.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*4TqRT9A5CacQKdqM.&quot; data-width=&quot;500&quot; data-height=&quot;450&quot; src=&quot;https://cdn-images-1.medium.com/max/1200/0*4TqRT9A5CacQKdqM.&quot;/&gt;&lt;/div&gt;
Example POS system that is ugly but functional: High contrast, color-coded buttons take less time to mentally digest.
&lt;p name=&quot;c10f&quot; id=&quot;c10f&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;When I worked in food service and in the mailroom, the uglier touchscreens were always easier to work with. They were color coded with bright, contrasting colors, making the boundaries between numbers or items very obvious. I found that the colors reduced mistakes. I’d usually tap the right items after barely even glancing at the interface. After a while, I’d only check the screen for mistakes at the end of the process, before submitting an order or printing a receipt.&lt;/p&gt;
&lt;p name=&quot;b716&quot; id=&quot;b716&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Most touchscreen interfaces don’t use high contrast colors or locked, static buttons for basic functions. They bury actions under multiple buttons, and this leaves us dangerously hunting for the right button while trying to drive, or our frustrated passengers trying to help us get our phone connected via Bluetooth.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;0*QoUHjqw0vu3ypfYA.&quot; data-width=&quot;1200&quot; data-height=&quot;630&quot; data-action=&quot;zoom&quot; data-action-value=&quot;0*QoUHjqw0vu3ypfYA.&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/0*QoUHjqw0vu3ypfYA.&quot;/&gt;&lt;/div&gt;
&lt;p name=&quot;f680&quot; id=&quot;f680&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Square’s point of sale system is used by both customers and employees, and it’s important that the systems look good — but processing orders and mistakes can still be made if the images look too similar to one another. I know of some coffee shops that have replaced their product images with memes or high contrast cartoon characters. It’s a cute tactic that works for both employees and customers.&lt;/p&gt;
&lt;p name=&quot;2ab3&quot; id=&quot;2ab3&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Will we see a return to analog interfaces? I certainty hope so. While analog interfaces aren’t applicable to every situation, they do force designers to make permanent decisions. And because specific choices must be made for physical button placement, it’s harder to design an unusable analog interface. And design decisions must be final. Software interfaces can be quickly changed and deployed without the same process — and the world is filling up with nested, mystery-meat menus and confusing user flows.&lt;/p&gt;
&lt;p name=&quot;7098&quot; id=&quot;7098&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Last week, my neighborhood grocery store replaced all of its keypad-based machines with touchscreens. Now the grocers must take additional time to look up at the screen and tap through a few different pictures to select the correct items. In addition to the loss of productivity, the poorly-designed systems leave employees unhappy. I used to watch veteran supermarket workers deftly tap PLU codes for produce into a keypad. They bagged fruit with one hand while typing codes with the other. Their precision and memory was often a point of pride and mild honor. Now, there’s nothing left of that tiny speck of mastery. Worse, the new screens require different levels of focus, making it difficult for some workers to read the text. I’ve watched workers remove their glasses to peer at the display before tapping the right product image. I even found them apologizing — on behalf of the machine.&lt;/p&gt;
&lt;p name=&quot;be36&quot; id=&quot;be36&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;I asked a cashier if he thought he could find the same comfort with the touchscreen like he did with the physical machine.&lt;/p&gt;
&lt;p name=&quot;582b&quot; id=&quot;582b&quot; class=&quot;graf graf--p graf--startsWithDoubleQuote graf-after--p&quot;&gt;“Absolutely not,” he grumbled, “and when this one becomes tolerable, they’ll change the software on me.”&lt;/p&gt;
&lt;p name=&quot;4384&quot; id=&quot;4384&quot; class=&quot;graf graf--p graf-after--p graf--trailing&quot;&gt;These issues only hint at the troubles intrinsic in touchscreens. In a follow-up post, we’ll look at how they further enhance the social frictions we’re already seeing in the rise of automation.&lt;/p&gt;
</description>
<pubDate>Tue, 03 Jul 2018 04:06:01 +0000</pubDate>
<dc:creator>jepityr</dc:creator>
<og:title>The Hidden Cost of Touchscreens – Amber Case – Medium</og:title>
<og:url>https://medium.com/@caseorganic/why-do-we-keep-building-cars-with-touchscreens-alt-the-hidden-lives-of-touchscreens-55faf92799bf</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*Zt2eaUYKum3vEH-VJgqJIw.png</og:image>
<og:description>In 2012 I tried out a brand new luxury vehicle at a automotive conference. It was a minimalist European model, and nothing seemed out of…</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://medium.com/@caseorganic/why-do-we-keep-building-cars-with-touchscreens-alt-the-hidden-lives-of-touchscreens-55faf92799bf</dc:identifier>
</item>
</channel>
</rss>