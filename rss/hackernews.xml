<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>The Periodic Table of Data Structures [pdf]</title>
<link>https://stratos.seas.harvard.edu/files/stratos/files/periodictabledatastructures.pdf</link>
<guid isPermaLink="true" >https://stratos.seas.harvard.edu/files/stratos/files/periodictabledatastructures.pdf</guid>
<description>&lt;a href=&quot;https://stratos.seas.harvard.edu/files/stratos/files/periodictabledatastructures.pdf&quot;&gt;Download PDF&lt;/a&gt;</description>
<pubDate>Sat, 27 Oct 2018 06:02:19 +0000</pubDate>
<dc:creator>asplake</dc:creator>
<dc:format>application/pdf</dc:format>
<dc:identifier>https://stratos.seas.harvard.edu/files/stratos/files/periodictabledatastructures.pdf</dc:identifier>
</item>
<item>
<title>Some private equity firms are furious over a paper in a dermatology journal</title>
<link>https://www.nytimes.com/2018/10/26/health/private-equity-dermatology.html</link>
<guid isPermaLink="true" >https://www.nytimes.com/2018/10/26/health/private-equity-dermatology.html</guid>
<description>&lt;div class=&quot;css-18sbwfn StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot;&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Early this month, a respected medical journal published a research paper on its website that analyzed the effects of a business trend roiling the field of dermatology: the rapid entrance of private equity firms into the specialty by buying and running practices around the country.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Eight days later, after an outcry from private equity executives and dermatologists associated with private equity firms, the editor of the publication removed the paper from the site. No reason was given.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Furor over the publication and subsequent removal of the article has deepened a rift in the field over what some see as the “corporatization” of dermatology and other areas of medicine.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;&lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.nytimes.com/2017/11/20/health/dermatology-skin-cancer.html?module=inline&quot; title=&quot;&quot;&gt;&lt;strong class=&quot;css-8qgvsz euv7paa0&quot;&gt;&lt;em class=&quot;css-2fg4z9 ehxkw330&quot;&gt;[The once sleepy field of dermatology is booming these days. Read our story.]&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;The paper was published on the website of the Journal of the American Academy of Dermatology on Oct. 5, posted along with numerous other articles labeled “In Press Accepted Manuscript.” Most articles with this designation eventually appear in a print edition of the journal; some remain online.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;&lt;div class=&quot;css-18sbwfn StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot;&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Dr. Dirk Elston, the journal’s editor, said in an email that he replaced the article with a notice of “temporary removal” after receiving multiple calls and emails “expressing concerns about the accuracy of a few parts” of the article.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;On Wednesday, nearly two weeks after removing the article, Dr. Elston told the authors they had a choice: They could correct “factual errors” or retract the paper.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;The authors maintain that the article does not contain any factual errors and that several of the corrections requested had to do with protecting the reputation of the specialty and the leaders of the American Academy of Dermatology, the association that publishes the journal. Later on Wednesday, they submitted some revisions.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;The article had gone through the standard editorial process of academic journals, undergoing multiple revisions based on feedback from peer-reviewers selected by the journal, before being accepted for publication. It presents data to support a conclusion that private equity firms acquire “outlier” practices — that is, practices that perform an unusually high number of well-reimbursed procedures and bill high amounts to Medicare.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“It was interesting when we ran the numbers and we were counting how many practices with billing outliers were being acquired by private equity,” said Dr. Joseph Francis, a dermatologist in Florida who is a co-author on the paper. “With every revision of the paper, that number kept increasing. So it didn’t seem like an anomaly.”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-18sbwfn StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot;&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;He added, “It wasn’t clear whether these investors realized that the high billing might point to anything irregular. They might have just seen that this was a practice with booming business.”&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;The paper also notes that many practices backed by private equity firms have opened or acquired labs to process pathology specimens, potentially another source of profit.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Among those who objected to the article was Dr. George Hruza, the incoming president of the American Academy of Dermatology. Dr. Hruza, whose one-year term as president begins in March, is a dermatologist in Chesterfield, Mo. In 2016 he sold his own dermatology practice to United Skin Specialists, a firm that manages dermatology practices and is backed by private equity. He currently serves on the board of directors of United Skin Specialists, which he said is an unpaid position.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Dr. Hruza is not named in the journal article, but he said he is easily identified by the authors’ reference to his pending presidency of the academy, and to United Skin Specialists.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;In an interview, Dr. Hruza said he did not ask that the paper be taken down. He did, however, confirm that he expressed his concerns to Dr. Elston, the editor, after it was posted. Two days later, Dr. Elston removed the paper. A flurry of intense conversations ensued among Dr. Elston; Dr. Hruza; the current academy president, Dr. Suzanne Olbricht; a lawyer for the dermatology academy; and the paper’s authors.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1xdhyk6 e1vv25i80&quot;&gt;&lt;span class=&quot;css-1ly73wi e1afaoz0&quot;&gt;Image&lt;/span&gt;&lt;img alt=&quot;&quot; class=&quot;css-1m50asq&quot; src=&quot;https://static01.nyt.com/images/2018/10/25/science/00DERMATOLOGY2/00DERMATOLOGY2-articleLarge.jpg?quality=75&amp;amp;auto=webp&amp;amp;disable=upscale&quot; srcset=&quot;https://static01.nyt.com/images/2018/10/25/science/00DERMATOLOGY2/00DERMATOLOGY2-articleLarge.jpg?quality=90&amp;amp;auto=webp 600w,https://static01.nyt.com/images/2018/10/25/science/00DERMATOLOGY2/00DERMATOLOGY2-jumbo.jpg?quality=90&amp;amp;auto=webp 1024w,https://static01.nyt.com/images/2018/10/25/science/00DERMATOLOGY2/00DERMATOLOGY2-superJumbo.jpg?quality=90&amp;amp;auto=webp 2048w&quot; sizes=&quot;((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 60vw, 100vw&quot; itemprop=&quot;url&quot; itemid=&quot;https://static01.nyt.com/images/2018/10/25/science/00DERMATOLOGY2/00DERMATOLOGY2-articleLarge.jpg?quality=75&amp;amp;auto=webp&amp;amp;disable=upscale&quot;/&gt;&lt;/div&gt;
&lt;span class=&quot;css-1wp6toh e1olku6u0&quot;&gt;Dr. Sailesh Konda, left, and Dr. Joseph Francis, authors of a paper that has caused a stir in the field of dermatology.&lt;/span&gt;
&lt;div class=&quot;css-18sbwfn StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot;&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Specifically, Dr. Hruza said, he objected to one of the paper’s conclusions: Influential dermatology leaders are being recruited to work for and promote dermatology practices backed by private-equity firms.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-18sbwfn StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot;&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“Implying motivation is a stretch,” he said. Dr. Hruza has asked for specific wording changes to that section of the paper.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Among the changes the editor of the journal asked the authors to make was the removal of identifiable references to influential dermatologists, including Dr. Hruza.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Interference with a scientific paper from within the ranks of a medical society is highly unusual, say experts in the medical publishing field. The sudden disappearance of the paper has others in the medical publishing world scratching their heads.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“The process of science requires that people be allowed to publish their data as long as it has been reviewed by peers who find it accurate in that moment,” said Dr. Mitchell Katz, president and chief executive of NYC Health &amp;amp; Hospitals and Deputy Editor of the journal JAMA Internal Medicine.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;As for corrections, Dr. Katz added, “usually you would post a correct copy rather than removing a paper for days on end.”&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Dr. Elston said others who objected to the article included Dr. Darrell Rigel, a prominent dermatologist in New York who is a former president of the academy and whose practice is now owned by Schweiger Dermatology, a private equity-backed practice. Dr. Rigel did not respond to requests for comment.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Dermatologists account for one percent of physicians in the United States, but &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://jamanetwork.com/journals/jamadermatology/article-abstract/2664345&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;15 percent of recent private equity acquisitions of medical practices have involved dermatology practices.&lt;/a&gt; Other specialties that have attracted private equity investment include orthopedics, radiology, cardiology, urgent care, anesthesiology and ophthalmology.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-18sbwfn StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot;&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;One of the paper’s five supplemental tables lists 32 dermatology practices in the United States that have been formed or acquired by private equity firms. Many are large practices with dozens of physicians.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Shortly after the article disappeared from the journal’s website, a copy was posted to a Facebook group composed of some 3,500 dermatologists. Several participants in the Facebook group praised the article for shining a light on the effects of private equity on their specialty, and were outraged that the article had been withdrawn.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“If this were an article on psoriasis no one would be questioning it, but this was going to ruffle some feathers,” said Dr. Curtis Asbury, a dermatologist in Selbyville, Del., and an active participant in the Facebook group.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;The lead author of the paper was Dr. Sailesh Konda, an assistant clinical professor of dermatology at the University of Florida College of Medicine. Dr. Konda, 34, said he first grew interested in the topic when several of his trainees went to work for private equity-backed practices and told him of clinical environments that emphasized profits at the expense of patient care. He said that over the past year he had given 16 talks around the country to medical residents and dermatology societies about private equity. Dr. Francis has joined him for some of the sessions.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Dr. Konda said he and his co-authors spent a year working on the paper. After the paper went out for review, he said, “we received constructive feedback.” Most of the comments, he said, were about maintaining a neutral tone.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“We strived to not use any polemic words, which could be interpreted as bias,” he said. “We decided to just deal with the facts, which would speak for themselves.”&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;This week a lawyer for Advanced Dermatology and Cosmetic Surgery, which is backed by private equity and is the largest dermatology practice in the United States, called the general counsel at the University of Florida, where two of the authors are employed, demanding specific changes to the paper. The general counsel for the university declined to comment. Dr. Matt Leavitt, the chief executive of Advanced Dermatology, did not respond to requests for a comment.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Dr. Konda says he plans to continue his research into private equity. “I am passionate about this topic,” he said. “I realize we live in a capitalist society and money is a driving force behind many decisions regardless of the industry. However, I believe there has to be a balance between profit and patient care.”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;
</description>
<pubDate>Sat, 27 Oct 2018 00:56:09 +0000</pubDate>
<dc:creator>ItsMe000001</dc:creator>
<og:url>https://www.nytimes.com/2018/10/26/health/private-equity-dermatology.html</og:url>
<og:type>article</og:type>
<og:title>Why Private Equity Is Furious Over a Paper in a Dermatology Journal</og:title>
<og:image>https://static01.nyt.com/images/2018/10/27/business/27DERMATOLOGY1-print/00DERMATOLOGY1-facebookJumbo.jpg</og:image>
<og:description>The sudden, unexplained removal of a research paper on private equity firms buying dermatology practices has raised questions about corporate influence.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.nytimes.com/2018/10/26/health/private-equity-dermatology.html</dc:identifier>
</item>
<item>
<title>Texans say voting machines changing straight-ticket choices</title>
<link>https://apnews.com/a8825810d10441f2ad828e95d6851d55</link>
<guid isPermaLink="true" >https://apnews.com/a8825810d10441f2ad828e95d6851d55</guid>
<description>&lt;p&gt;AUSTIN, Texas (AP) — Some Texas voters are complaining that machines flipped their straight-ticket selections to the other party in key races during early voting, especially the much-watched Senate battle between Republican incumbent Ted Cruz and Democrat Beto O’Rourke.&lt;/p&gt;
&lt;p&gt;The secretary of state’s office said Friday that there have been reported issues with Hart eSlate voting machines, which are used in around 30 percent of counties statewide and feature a wheel for selecting candidates and buttons to move from screen to screen. But it says they are caused by voters themselves and often occur when they complete and submit ballots too quickly.&lt;/p&gt;

&lt;p&gt;“The Hart eSlate machines are not malfunctioning, the problems being reported are a result of user error — usually voters hitting a button or using the selection wheel before the screen is finished rendering,” said Sam Taylor, spokesman for the office of Secretary of State Rolando Pablos, who was appointed by Republican Gov. Greg Abbott.&lt;/p&gt;
&lt;p&gt;The machines are used in around 80 counties, including the state’s largest, Harris, which is home to Houston, as well as Travis, which includes Austin, and Tarrant, encompassing Fort Worth. Early voting in Texas began Monday and has featured strong turnout and long lines. It runs through Nov. 2, ahead of Election Day on Nov. 6.&lt;/p&gt;
&lt;p&gt;Many Hart eSlate machines used in Texas don’t provide receipts or other forms of paper trail to voters, but those casting ballots do see a screen that shows their choices before final submission — and can go back and make changes. Similar machines are used in parts of Indiana, Kentucky, Pennsylvania, Tennessee and Virginia, according to Verified Voting, a nonprofit group focused on ensuring the accuracy of elections.&lt;/p&gt;
&lt;p&gt;The machine’s manufacturer, Hart InterCivic, attributed the Texas issues to 16-year-old technology.&lt;/p&gt;
&lt;p&gt;“The same story has happened in multiple elections,” Steven Sockwell, the company’s vice president of marketing, said Friday. “There was no flipping then and there’s not any now.”&lt;/p&gt;
&lt;p&gt;Instead, Sockwell said, what typically happens in cases where someone believes his or her vote has been changed is a voter will select a straight-party ticket, then unintentionally change votes in individual races without realizing it.&lt;/p&gt;
&lt;p&gt;Still, in a statement to supporters, Cruz cited “multiple reports” of race selections changing and added “once you select the Republican party ticket, please be patient and do not select ‘next’ until the ballot has populated all of the selections.”&lt;/p&gt;

&lt;p&gt;An advisory to county clerks and elections administrators issued earlier this week by Keith Ingram, the secretary of state’s office’s director of elections, said, “We have heard from a number of people voting on Hart eSlate machines that when they voted straight ticket, it appeared to them that the machine had changed one or more of their selections to a candidate from a different party.”&lt;/p&gt;
&lt;p&gt;The Texas Democratic Party called the issue “a malfunction,” said it was causing Democrats to inadvertently vote for Cruz and accused the secretary of state’s office of not doing enough to warn voters of potential issues.&lt;/p&gt;
&lt;p&gt;Party chairman Gilberto Hinojosa said in a statement that “Texas’ Republican government blamed voters and did nothing.” He called for a statewide public service announcement to warn voters, training for poll workers on the issue and removal of “all malfunctioning machines.”&lt;/p&gt;
&lt;p&gt;Taylor said Friday that his office “has already trained election officials across the state” while also instructing “election administrators to post additional signage in multiple languages” and requiring county officials to keep “a detailed, meticulous log of any malfunctioning machines, and remove any machines that are malfunctioning.”&lt;/p&gt;
&lt;p&gt;Taylor also said his office “has no legal authority whatsoever to force any” voting machine vendors “to make upgrades if their voting systems are otherwise in compliance with federal and state law,” and that Hart eSlate’s system was certified in 2009. He said counties are responsible for purchasing their own new voting equipment.&lt;/p&gt;
&lt;p&gt;“We will continue to educate Texas voters using existing resources,” Taylor said, “and urge all Texans casting a ballot to take their time, slow down, and carefully review their ballot before casting one.”&lt;/p&gt;
&lt;p&gt;___&lt;/p&gt;
&lt;p&gt;Associated Press Writer Frank Bajak contributed to this report from Boston.&lt;/p&gt;
</description>
<pubDate>Fri, 26 Oct 2018 18:59:43 +0000</pubDate>
<dc:creator>threatofrain</dc:creator>
<og:title>Texans say voting machines changing straight-ticket choices</og:title>
<og:type>article</og:type>
<og:url>https://apnews.com/a8825810d10441f2ad828e95d6851d55</og:url>
<og:image>https://storage.googleapis.com/afs-prod/media/media:0a29fa8cc01c4cce8ae6a82b940548ad/3000.jpeg</og:image>
<og:description>AUSTIN, Texas (AP) — Some Texas voters are complaining that machines flipped their straight-ticket selections to the other party in key races during early voting, especially the much-watched Senate battle between Republican incumbent Ted Cruz and Democrat Beto O'Rourke. The secretary of state's office said Friday that there have been reported issues with Hart eSlate voting machines, which are used in around 30 percent of counties statewide and feature a wheel for selecting candidates and buttons to move from screen to screen. But it says they are caused by voters themselves and often occur when they complete and submit ballots too quickly.</og:description>
<dc:format>text/html</dc:format>
<dc:identifier>https://apnews.com/a8825810d10441f2ad828e95d6851d55</dc:identifier>
</item>
<item>
<title>Friendly Floatees</title>
<link>https://en.wikipedia.org/wiki/Friendly_Floatees</link>
<guid isPermaLink="true" >https://en.wikipedia.org/wiki/Friendly_Floatees</guid>
<description>&lt;a class=&quot;mw-jump-link&quot; href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#mw-head&quot;&gt;Jump to navigation&lt;/a&gt;
				&lt;a class=&quot;mw-jump-link&quot; href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#p-search&quot;&gt;Jump to search&lt;/a&gt;
				&lt;div id=&quot;mw-content-text&quot; lang=&quot;en&quot; dir=&quot;ltr&quot; class=&quot;mw-content-ltr&quot;&gt;&lt;div class=&quot;mw-parser-output&quot;&gt;
&lt;p class=&quot;mw-empty-elt&quot;&gt;
&lt;/p&gt;
&lt;div class=&quot;thumb tright&quot;&gt;&lt;div class=&quot;thumbinner&quot; style=&quot;width:362px;&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/File:Friendly_Floatees.png&quot; class=&quot;image&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Friendly_Floatees.png/360px-Friendly_Floatees.png&quot; width=&quot;360&quot; height=&quot;222&quot; class=&quot;thumbimage&quot; srcset=&quot;//upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Friendly_Floatees.png/540px-Friendly_Floatees.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Friendly_Floatees.png/720px-Friendly_Floatees.png 2x&quot; data-file-width=&quot;850&quot; data-file-height=&quot;523&quot;/&gt;&lt;/a&gt;  &lt;div class=&quot;thumbcaption&quot;&gt;Route taken by the Friendly Floatees initially lost in the Pacific Ocean in 1992.&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;thumb tright&quot;&gt;&lt;div class=&quot;thumbinner&quot; style=&quot;width:222px;&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/File:Curtis_Ebbesmeyer-2.JPG&quot; class=&quot;image&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Curtis_Ebbesmeyer-2.JPG/220px-Curtis_Ebbesmeyer-2.JPG&quot; width=&quot;220&quot; height=&quot;322&quot; class=&quot;thumbimage&quot; srcset=&quot;//upload.wikimedia.org/wikipedia/commons/f/fd/Curtis_Ebbesmeyer-2.JPG 1.5x&quot; data-file-width=&quot;292&quot; data-file-height=&quot;427&quot;/&gt;&lt;/a&gt;  &lt;div class=&quot;thumbcaption&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Oceanographer&quot; class=&quot;mw-redirect&quot; title=&quot;Oceanographer&quot;&gt;Oceanographer&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Curtis_Ebbesmeyer&quot; title=&quot;Curtis Ebbesmeyer&quot;&gt;Curtis Ebbesmeyer&lt;/a&gt; with &lt;a href=&quot;https://en.wikipedia.org/wiki/Flotsam&quot; class=&quot;mw-redirect&quot; title=&quot;Flotsam&quot;&gt;flotsam&lt;/a&gt; (including some Friendly Floatees) that he observes to monitor &lt;a href=&quot;https://en.wikipedia.org/wiki/Ocean_currents&quot; class=&quot;mw-redirect&quot; title=&quot;Ocean currents&quot;&gt;ocean currents&lt;/a&gt;.&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;b&gt;Friendly Floatees&lt;/b&gt; are plastic bath toys marketed by &lt;a href=&quot;https://en.wikipedia.org/w/index.php?title=The_First_Years,_Inc&amp;amp;action=edit&amp;amp;redlink=1&quot; class=&quot;new&quot; title=&quot;The First Years, Inc (page does not exist)&quot;&gt;The First Years, Inc&lt;/a&gt;. and made famous by the work of &lt;a href=&quot;https://en.wikipedia.org/wiki/Curtis_Ebbesmeyer&quot; title=&quot;Curtis Ebbesmeyer&quot;&gt;Curtis Ebbesmeyer&lt;/a&gt;, an oceanographer who models &lt;a href=&quot;https://en.wikipedia.org/wiki/Ocean_current&quot; title=&quot;Ocean current&quot;&gt;ocean currents&lt;/a&gt; on the basis of &lt;a href=&quot;https://en.wikipedia.org/wiki/Flotsam&quot; class=&quot;mw-redirect&quot; title=&quot;Flotsam&quot;&gt;flotsam&lt;/a&gt; movements. Ebbesmeyer studied the movements of a consignment of 29,000 Friendly Floatees—yellow ducks, red beavers, blue turtles and green frogs—which were washed into the Pacific Ocean in 1992. Some of the toys landed along Pacific Ocean shores, such as Hawaii. Others traveled over 17,000 miles, floating over the site where the &lt;i&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/RMS_Titanic&quot; title=&quot;RMS Titanic&quot;&gt;Titanic&lt;/a&gt;&lt;/i&gt; sank, and spent years frozen in Arctic ice to reach the &lt;a href=&quot;https://en.wikipedia.org/wiki/East_Coast_of_the_United_States&quot; title=&quot;East Coast of the United States&quot;&gt;Eastern Seaboard&lt;/a&gt;, British and Irish shores 15 years later in 2007.&lt;sup id=&quot;cite_ref-Mail-1000s_1-0&quot; class=&quot;reference&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_note-Mail-1000s-1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;


&lt;h2&gt;&lt;span class=&quot;mw-headline&quot; id=&quot;Oceanography&quot;&gt;Oceanography&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;A consignment of Friendly Floatee toys, manufactured in China for The First Years Inc., departed from &lt;a href=&quot;https://en.wikipedia.org/wiki/Hong_Kong&quot; title=&quot;Hong Kong&quot;&gt;Hong Kong&lt;/a&gt; on a &lt;a href=&quot;https://en.wikipedia.org/wiki/Container_ship&quot; title=&quot;Container ship&quot;&gt;container ship&lt;/a&gt;, the &lt;i&gt;Ever Laurel&lt;/i&gt;,&lt;sup id=&quot;cite_ref-2&quot; class=&quot;reference&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_note-2&quot;&gt;[2]&lt;/a&gt;&lt;/sup&gt; destined for &lt;a href=&quot;https://en.wikipedia.org/wiki/Tacoma,_Washington&quot; title=&quot;Tacoma, Washington&quot;&gt;Tacoma, Washington&lt;/a&gt;. On 10 January 1992, during a storm in the North Pacific Ocean close to the &lt;a href=&quot;https://en.wikipedia.org/wiki/International_Date_Line&quot; title=&quot;International Date Line&quot;&gt;International Date Line&lt;/a&gt;, twelve 40-foot (12-m) &lt;a href=&quot;https://en.wikipedia.org/wiki/Intermodal_container&quot; title=&quot;Intermodal container&quot;&gt;intermodal containers&lt;/a&gt; were washed overboard. One of these containers held 28,800 Floatees,&lt;sup id=&quot;cite_ref-Harper's_3-0&quot; class=&quot;reference&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_note-Harper's-3&quot;&gt;[3]&lt;/a&gt;&lt;/sup&gt; a child's bath toy which came in a number of forms: red &lt;a href=&quot;https://en.wikipedia.org/wiki/Beaver&quot; title=&quot;Beaver&quot;&gt;beavers&lt;/a&gt;, green frogs, blue turtles and yellow &lt;a href=&quot;https://en.wikipedia.org/wiki/Rubber_duck&quot; title=&quot;Rubber duck&quot;&gt;ducks&lt;/a&gt;. At some point, the container opened (possibly because it collided with other containers or the ship itself) and the Floatees were released. Although each toy was mounted in a plastic housing attached to a backing card, subsequent tests showed that the cardboard quickly degraded in sea water allowing the Floatees to escape. Unlike many bath toys, Friendly Floatees have no holes in them so they do not take on water.
&lt;/p&gt;&lt;p&gt;Seattle oceanographers Curtis Ebbesmeyer and James Ingraham, who were working on an ocean surface current model, began to track their progress. The mass release of 28,800 objects into the ocean at one time offered significant advantages over the standard method of releasing 500–1000 drift bottles. The recovery rate of objects from the Pacific Ocean is typically around 2%, so rather than the 10 to 20 recoveries typically seen with a drift bottle release, the two scientists expected numbers closer to 600. They were already tracking various other spills of flotsam, including 61,000 &lt;a href=&quot;https://en.wikipedia.org/wiki/Nike,_Inc.&quot; title=&quot;Nike, Inc.&quot;&gt;Nike&lt;/a&gt; running shoes that had been lost overboard in 1990.
&lt;/p&gt;&lt;p&gt;Ten months after the incident, the first Floatees began to wash up along the &lt;a href=&quot;https://en.wikipedia.org/wiki/Alaska&quot; title=&quot;Alaska&quot;&gt;Alaskan&lt;/a&gt; coast. The first discovery consisted of ten toys found by a &lt;a href=&quot;https://en.wikipedia.org/wiki/Beachcombing&quot; title=&quot;Beachcombing&quot;&gt;beachcomber&lt;/a&gt; near &lt;a href=&quot;https://en.wikipedia.org/wiki/Sitka,_Alaska&quot; title=&quot;Sitka, Alaska&quot;&gt;Sitka, Alaska&lt;/a&gt; on 16 November 1992, about 2,000 miles (3,200 km) from their starting point. Ebbesmeyer and Ingraham contacted beachcombers, coastal workers, and local residents to locate hundreds of the beached Floatees over a 530 mile (850 km) shoreline. Another beachcomber discovered twenty of the toys on 28 November 1992, and in total 400 were found along the eastern coast of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Gulf_of_Alaska&quot; title=&quot;Gulf of Alaska&quot;&gt;Gulf of Alaska&lt;/a&gt; in the period up to August 1993. This represented a 1.4% recovery rate. The landfalls were logged in Ingraham's computer model OSCUR (Ocean Surface Currents Simulation), which uses measurements of air pressure from 1967 onwards to calculate the direction of and speed of wind across the oceans, and the consequent surface currents. Ingraham's model was built to help fisheries but it is also used to predict flotsam movements or the likely locations of those lost at sea.
&lt;/p&gt;&lt;p&gt;Using the models they had developed, the oceanographers correctly predicted further landfalls of the toys in &lt;a href=&quot;https://en.wikipedia.org/wiki/Washington_(U.S._state)&quot; class=&quot;mw-redirect&quot; title=&quot;Washington (U.S. state)&quot;&gt;Washington state&lt;/a&gt; in 1996 and theorized that many of the remaining Floatees would have travelled to &lt;a href=&quot;https://en.wikipedia.org/wiki/Alaska&quot; title=&quot;Alaska&quot;&gt;Alaska&lt;/a&gt;, westward to Japan, back to Alaska, and then drifted northwards through the &lt;a href=&quot;https://en.wikipedia.org/wiki/Bering_Strait&quot; title=&quot;Bering Strait&quot;&gt;Bering Strait&lt;/a&gt; and become trapped in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Arctic&quot; title=&quot;Arctic&quot;&gt;Arctic&lt;/a&gt; pack ice. Moving slowly with the ice across the Pole, they predicted it would take five or six years for the toys to reach the North Atlantic where the ice would thaw and release them. Between July and December 2003, The First Years Inc. offered a $100 US &lt;a href=&quot;https://en.wikipedia.org/wiki/Savings_bond&quot; class=&quot;mw-redirect&quot; title=&quot;Savings bond&quot;&gt;savings bond&lt;/a&gt; reward to anybody who recovered a Floatee in &lt;a href=&quot;https://en.wikipedia.org/wiki/New_England&quot; title=&quot;New England&quot;&gt;New England&lt;/a&gt;, Canada or Iceland.&lt;sup id=&quot;cite_ref-Mail-1000s_1-1&quot; class=&quot;reference&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_note-Mail-1000s-1&quot;&gt;[1]&lt;/a&gt;&lt;/sup&gt; More of the toys were recovered in 2004 than in any of the preceding three years. However, still more of these toys were predicted to have headed eastward past Greenland and make landfall on the southwestern shores of the United Kingdom in 2007. In July 2007, a retired teacher found a plastic duck on the Devon coast, and British newspapers mistakenly announced that the Floatees had begun to arrive.&lt;sup id=&quot;cite_ref-4&quot; class=&quot;reference&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_note-4&quot;&gt;[4]&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&quot;cite_ref-5&quot; class=&quot;reference&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_note-5&quot;&gt;[5]&lt;/a&gt;&lt;/sup&gt; But the day after breaking the story, the Western Morning News, the local Devon newspaper, reported that Dr. Simon Boxall of the National Oceanography Centre in Southampton had examined the specimen and determined that the duck was not in fact a Floatee.&lt;sup id=&quot;cite_ref-6&quot; class=&quot;reference&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_note-6&quot;&gt;[6]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;Bleached by sun and seawater, the ducks and beavers had faded to white, but the turtles and frogs had kept their original colors.
&lt;/p&gt;
&lt;h2&gt;&lt;span class=&quot;mw-headline&quot; id=&quot;Legacy&quot;&gt;Legacy&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;At least two children's books have been inspired by the Floatees. In 1997, &lt;a href=&quot;https://en.wikipedia.org/wiki/Houghton_Mifflin_Harcourt&quot; title=&quot;Houghton Mifflin Harcourt&quot;&gt;Clarion Books&lt;/a&gt; published &lt;i&gt;Ducky&lt;/i&gt; (&lt;style data-mw-deduplicate=&quot;TemplateStyles:r861714446&quot;&gt;&lt;![CDATA[.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output q{quotes:&quot;\&quot;&quot;&quot;\&quot;&quot;&quot;'&quot;&quot;'&quot;}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-lock-free a{background:url(&quot;//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png&quot;)no-repeat;background-position:right .1em center}.mw-parser-output .cs1-lock-limited a,.mw-parser-output .cs1-lock-registration a{background:url(&quot;//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png&quot;)no-repeat;background-position:right .1em center}.mw-parser-output .cs1-lock-subscription a{background:url(&quot;//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png&quot;)no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}]]&gt;&lt;/style&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/International_Standard_Book_Number&quot; title=&quot;International Standard Book Number&quot;&gt;ISBN&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Special:BookSources/0-395-75185-3&quot; title=&quot;Special:BookSources/0-395-75185-3&quot;&gt;0-395-75185-3&lt;/a&gt;), written by &lt;a href=&quot;https://en.wikipedia.org/wiki/Eve_Bunting&quot; title=&quot;Eve Bunting&quot;&gt;Eve Bunting&lt;/a&gt; and illustrated by &lt;a href=&quot;https://en.wikipedia.org/wiki/Caldecott_Medal&quot; title=&quot;Caldecott Medal&quot;&gt;Caldecott Medal&lt;/a&gt; winner &lt;a href=&quot;https://en.wikipedia.org/wiki/David_Wisniewski&quot; title=&quot;David Wisniewski&quot;&gt;David Wisniewski&lt;/a&gt;. &lt;a href=&quot;https://en.wikipedia.org/wiki/Hans_Christian_Andersen_Award&quot; title=&quot;Hans Christian Andersen Award&quot;&gt;Hans Christian Andersen Award&lt;/a&gt; winner &lt;a href=&quot;https://en.wikipedia.org/wiki/Eric_Carle&quot; title=&quot;Eric Carle&quot;&gt;Eric Carle&lt;/a&gt; wrote &lt;i&gt;10 Little Rubber Ducks&lt;/i&gt; (Harper Collins 2005, &lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/International_Standard_Book_Number&quot; title=&quot;International Standard Book Number&quot;&gt;ISBN&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Special:BookSources/978-0-00-720242-3&quot; title=&quot;Special:BookSources/978-0-00-720242-3&quot;&gt;978-0-00-720242-3&lt;/a&gt;).&lt;sup id=&quot;cite_ref-ft_7-0&quot; class=&quot;reference&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_note-ft-7&quot;&gt;[7]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;In 2011, &lt;a href=&quot;https://en.wikipedia.org/wiki/Donovan_Hohn&quot; title=&quot;Donovan Hohn&quot;&gt;Donovan Hohn&lt;/a&gt; published &lt;i&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Moby-Duck&quot; title=&quot;Moby-Duck&quot;&gt;Moby-Duck: The True Story of 28,800 Bath Toys Lost at Sea and of the Beachcombers, Oceanographers, Environmentalists, and Fools, Including the Author, Who Went in Search of Them&lt;/a&gt;&lt;/i&gt; (Viking, &lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/International_Standard_Book_Number&quot; title=&quot;International Standard Book Number&quot;&gt;ISBN&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Special:BookSources/978-0-670-02219-9&quot; title=&quot;Special:BookSources/978-0-670-02219-9&quot;&gt;978-0-670-02219-9&lt;/a&gt;)&lt;sup id=&quot;cite_ref-8&quot; class=&quot;reference&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_note-8&quot;&gt;[8]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;On 20 June 2014, &lt;a href=&quot;https://en.wikipedia.org/wiki/The_Disney_Channel&quot; class=&quot;mw-redirect&quot; title=&quot;The Disney Channel&quot;&gt;The Disney Channel&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Disney_Junior&quot; title=&quot;Disney Junior&quot;&gt;Disney Junior&lt;/a&gt; aired &lt;i&gt;Lucky Duck&lt;/i&gt;, a Canadian-American animated tv movie that is loosely based on and inspired by the Friendly Floatees.&lt;sup id=&quot;cite_ref-9&quot; class=&quot;reference&quot;&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_note-9&quot;&gt;[9]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;p&gt;The toys themselves have become collector's items, fetching prices as high as $1,000.
&lt;/p&gt;
&lt;h2&gt;&lt;span class=&quot;mw-headline&quot; id=&quot;See_also&quot;&gt;See also&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Drifter_(floating_device)&quot; title=&quot;Drifter (floating device)&quot;&gt;Drifter (floating device)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Great_Pacific_garbage_patch&quot; title=&quot;Great Pacific garbage patch&quot;&gt;Great Pacific garbage patch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Marine_debris&quot; title=&quot;Marine debris&quot;&gt;Marine debris&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Message_in_a_bottle&quot; title=&quot;Message in a bottle&quot;&gt;Message in a bottle&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;span class=&quot;mw-headline&quot; id=&quot;Footnotes&quot;&gt;Footnotes&lt;/span&gt;&lt;/h2&gt;
&lt;div class=&quot;reflist&quot; style=&quot;list-style-type: decimal;&quot;&gt;
&lt;div class=&quot;mw-references-wrap&quot;&gt;&lt;ol class=&quot;references&quot;&gt;&lt;li id=&quot;cite_note-Mail-1000s-1&quot;&gt;&lt;span class=&quot;mw-cite-backlink&quot;&gt;^ &lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_ref-Mail-1000s_1-0&quot;&gt;&lt;sup&gt;&lt;i&gt;&lt;b&gt;a&lt;/b&gt;&lt;/i&gt;&lt;/sup&gt;&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_ref-Mail-1000s_1-1&quot;&gt;&lt;sup&gt;&lt;i&gt;&lt;b&gt;b&lt;/b&gt;&lt;/i&gt;&lt;/sup&gt;&lt;/a&gt;&lt;/span&gt; &lt;span class=&quot;reference-text&quot;&gt;&lt;cite class=&quot;citation news&quot;&gt;Clerkin, Ben (27 June 2007). &lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://www.dailymail.co.uk/news/article-464768/Thousands-rubber-ducks-land-British-shores-15-year-journey.html&quot;&gt;&quot;Thousands of rubber ducks to land on British shores after 15 year journey&quot;&lt;/a&gt;. &lt;a href=&quot;https://en.wikipedia.org/wiki/Daily_Mail&quot; title=&quot;Daily Mail&quot;&gt;Daily Mail&lt;/a&gt;&lt;span class=&quot;reference-accessdate&quot;&gt;. Retrieved &lt;span class=&quot;nowrap&quot;&gt;12 March&lt;/span&gt; 2018&lt;/span&gt;.&lt;/cite&gt;&lt;span title=&quot;ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;amp;rft.genre=article&amp;amp;rft.atitle=Thousands+of+rubber+ducks+to+land+on+British+shores+after+15+year+journey&amp;amp;rft.date=2007-06-27&amp;amp;rft.aulast=Clerkin&amp;amp;rft.aufirst=Ben&amp;amp;rft_id=http%3A%2F%2Fwww.dailymail.co.uk%2Fnews%2Farticle-464768%2FThousands-rubber-ducks-land-British-shores-15-year-journey.html&amp;amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFriendly+Floatees&quot; class=&quot;Z3988&quot;/&gt;&lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;/span&gt;
&lt;/li&gt;
&lt;li id=&quot;cite_note-2&quot;&gt;&lt;span class=&quot;mw-cite-backlink&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_ref-2&quot;&gt;^&lt;/a&gt;&lt;/b&gt;&lt;/span&gt; &lt;span class=&quot;reference-text&quot;&gt;&lt;cite class=&quot;citation book&quot;&gt;Hohn, Donovan (March 2011). &lt;i&gt;The True Story of 28,800 Bath Toys Lost at Sea and of the Beachcombers, Oceanographers, Environmentalists, and Fools, Including the Author, Who Went in Search of Them&lt;/i&gt;. &lt;a href=&quot;https://en.wikipedia.org/wiki/International_Standard_Book_Number&quot; title=&quot;International Standard Book Number&quot;&gt;ISBN&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Special:BookSources/9780670022199&quot; title=&quot;Special:BookSources/9780670022199&quot;&gt;9780670022199&lt;/a&gt;.&lt;/cite&gt;&lt;span title=&quot;ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;amp;rft.genre=book&amp;amp;rft.btitle=The+True+Story+of+28%2C800+Bath+Toys+Lost+at+Sea+and+of+the+Beachcombers%2C+Oceanographers%2C+Environmentalists%2C+and+Fools%2C+Including+the+Author%2C+Who+Went+in+Search+of+Them&amp;amp;rft.date=2011-03&amp;amp;rft.isbn=9780670022199&amp;amp;rft.aulast=Hohn&amp;amp;rft.aufirst=Donovan&amp;amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFriendly+Floatees&quot; class=&quot;Z3988&quot;/&gt;&lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;/span&gt;
&lt;/li&gt;
&lt;li id=&quot;cite_note-Harper's-3&quot;&gt;&lt;span class=&quot;mw-cite-backlink&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_ref-Harper's_3-0&quot;&gt;^&lt;/a&gt;&lt;/b&gt;&lt;/span&gt; &lt;span class=&quot;reference-text&quot;&gt;&lt;cite class=&quot;citation news&quot;&gt;Hohn, Donovan (January 2007). &lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://mysite.verizon.net/donovanhohn/Moby-Duck.html&quot;&gt;&quot;Moby-Duck: Or, The Synthetic Wilderness of Childhood&quot;&lt;/a&gt;. &lt;a href=&quot;https://en.wikipedia.org/wiki/Harper%27s_Magazine&quot; title=&quot;Harper's Magazine&quot;&gt;Harper's Magazine&lt;/a&gt;.&lt;/cite&gt;&lt;span title=&quot;ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;amp;rft.genre=article&amp;amp;rft.atitle=Moby-Duck%3A+Or%2C+The+Synthetic+Wilderness+of+Childhood&amp;amp;rft.date=2007-01&amp;amp;rft.aulast=Hohn&amp;amp;rft.aufirst=Donovan&amp;amp;rft_id=http%3A%2F%2Fmysite.verizon.net%2Fdonovanhohn%2FMoby-Duck.html&amp;amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFriendly+Floatees&quot; class=&quot;Z3988&quot;/&gt;&lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;/span&gt;
&lt;/li&gt;
&lt;li id=&quot;cite_note-4&quot;&gt;&lt;span class=&quot;mw-cite-backlink&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_ref-4&quot;&gt;^&lt;/a&gt;&lt;/b&gt;&lt;/span&gt; &lt;span class=&quot;reference-text&quot;&gt;&lt;cite class=&quot;citation news&quot;&gt;&lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://www.timesonline.co.uk/tol/news/uk/article2072458.ece&quot;&gt;&quot;First of the plastic duck invasion fleet makes landfall on the Devon coast&quot;&lt;/a&gt;. London: &lt;i&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/The_Times&quot; title=&quot;The Times&quot;&gt;The Times&lt;/a&gt;&lt;/i&gt;. 2000-07-14.&lt;/cite&gt;&lt;span title=&quot;ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;amp;rft.genre=article&amp;amp;rft.atitle=First+of+the+plastic+duck+invasion+fleet+makes+landfall+on+the+Devon+coast&amp;amp;rft.date=2000-07-14&amp;amp;rft_id=http%3A%2F%2Fwww.timesonline.co.uk%2Ftol%2Fnews%2Fuk%2Farticle2072458.ece&amp;amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFriendly+Floatees&quot; class=&quot;Z3988&quot;/&gt;&lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;/span&gt;
&lt;/li&gt;
&lt;li id=&quot;cite_note-5&quot;&gt;&lt;span class=&quot;mw-cite-backlink&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_ref-5&quot;&gt;^&lt;/a&gt;&lt;/b&gt;&lt;/span&gt; &lt;span class=&quot;reference-text&quot;&gt;&lt;cite class=&quot;citation news&quot;&gt;Coles, John (14 July 2007). &lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://www.thesun.co.uk/sol/homepage/news/article246146.ece&quot;&gt;&quot;The First of the Duck Armada&quot;&lt;/a&gt;. &lt;i&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/The_Sun_(United_Kingdom)&quot; title=&quot;The Sun (United Kingdom)&quot;&gt;The Sun&lt;/a&gt;&lt;/i&gt;.&lt;/cite&gt;&lt;span title=&quot;ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;amp;rft.genre=article&amp;amp;rft.jtitle=The+Sun&amp;amp;rft.atitle=The+First+of+the+Duck+Armada&amp;amp;rft.date=2007-07-14&amp;amp;rft.aulast=Coles&amp;amp;rft.aufirst=John&amp;amp;rft_id=http%3A%2F%2Fwww.thesun.co.uk%2Fsol%2Fhomepage%2Fnews%2Farticle246146.ece&amp;amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFriendly+Floatees&quot; class=&quot;Z3988&quot;/&gt;&lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;/span&gt;
&lt;/li&gt;
&lt;li id=&quot;cite_note-6&quot;&gt;&lt;span class=&quot;mw-cite-backlink&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_ref-6&quot;&gt;^&lt;/a&gt;&lt;/b&gt;&lt;/span&gt; &lt;span class=&quot;reference-text&quot;&gt;&lt;cite class=&quot;citation news&quot;&gt;&quot;Expert rules out toy duck as lost ocean adventurer&quot;. &lt;i&gt;Western Morning News&lt;/i&gt;. 14 July 2007.&lt;/cite&gt;&lt;span title=&quot;ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;amp;rft.genre=article&amp;amp;rft.atitle=Expert+rules+out+toy+duck+as+lost+ocean+adventurer&amp;amp;rft.date=2007-07-14&amp;amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFriendly+Floatees&quot; class=&quot;Z3988&quot;/&gt;&lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;/span&gt;
&lt;/li&gt;
&lt;li id=&quot;cite_note-ft-7&quot;&gt;&lt;span class=&quot;mw-cite-backlink&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_ref-ft_7-0&quot;&gt;^&lt;/a&gt;&lt;/b&gt;&lt;/span&gt; &lt;span class=&quot;reference-text&quot;&gt;&lt;cite class=&quot;citation news&quot;&gt;Wilkinson, Carl (17 February 2012). &lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://www.ft.com/cms/s/2/81ea32a4-5732-11e1-be25-00144feabdc0.html#axzz1n2AiRVJ0&quot;&gt;&quot;Ugly Ducklings&quot;&lt;/a&gt;. &lt;i&gt;Financial Times&lt;/i&gt;&lt;span class=&quot;reference-accessdate&quot;&gt;. Retrieved &lt;span class=&quot;nowrap&quot;&gt;21 February&lt;/span&gt; 2012&lt;/span&gt;.&lt;/cite&gt;&lt;span title=&quot;ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;amp;rft.genre=article&amp;amp;rft.jtitle=Financial+Times&amp;amp;rft.atitle=Ugly+Ducklings&amp;amp;rft.date=2012-02-17&amp;amp;rft.aulast=Wilkinson&amp;amp;rft.aufirst=Carl&amp;amp;rft_id=http%3A%2F%2Fwww.ft.com%2Fcms%2Fs%2F2%2F81ea32a4-5732-11e1-be25-00144feabdc0.html%23axzz1n2AiRVJ0&amp;amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFriendly+Floatees&quot; class=&quot;Z3988&quot;/&gt;&lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;/span&gt;
&lt;/li&gt;
&lt;li id=&quot;cite_note-8&quot;&gt;&lt;span class=&quot;mw-cite-backlink&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_ref-8&quot;&gt;^&lt;/a&gt;&lt;/b&gt;&lt;/span&gt; &lt;span class=&quot;reference-text&quot;&gt;&lt;cite class=&quot;citation news&quot;&gt;&lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;https://www.theguardian.com/books/2012/mar/30/moby-duck-toys-donovan-hohn&quot;&gt;&quot;Moby-Duck: The True Story of 28,800 Bath Toys Lost at Sea by Donovan Hohn&quot;&lt;/a&gt;. The Guardian. 30 March 2012.&lt;/cite&gt;&lt;span title=&quot;ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;amp;rft.genre=article&amp;amp;rft.atitle=Moby-Duck%3A+The+True+Story+of+28%2C800+Bath+Toys+Lost+at+Sea+by+Donovan+Hohn&amp;amp;rft.date=2012-03-30&amp;amp;rft_id=https%3A%2F%2Fwww.theguardian.com%2Fbooks%2F2012%2Fmar%2F30%2Fmoby-duck-toys-donovan-hohn&amp;amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFriendly+Floatees&quot; class=&quot;Z3988&quot;/&gt;&lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;/span&gt;
&lt;/li&gt;
&lt;li id=&quot;cite_note-9&quot;&gt;&lt;span class=&quot;mw-cite-backlink&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Friendly_Floatees#cite_ref-9&quot;&gt;^&lt;/a&gt;&lt;/b&gt;&lt;/span&gt; &lt;span class=&quot;reference-text&quot;&gt;&lt;cite class=&quot;citation web&quot;&gt;&lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://disneyjunior.com/lucky-duck&quot;&gt;&quot;Lucky Duck&quot;&lt;/a&gt;. &lt;a href=&quot;https://en.wikipedia.org/wiki/Disney_Junior&quot; title=&quot;Disney Junior&quot;&gt;Disney Junior&lt;/a&gt;&lt;span class=&quot;reference-accessdate&quot;&gt;. Retrieved &lt;span class=&quot;nowrap&quot;&gt;12 March&lt;/span&gt; 2018&lt;/span&gt;.&lt;/cite&gt;&lt;span title=&quot;ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;amp;rft.genre=unknown&amp;amp;rft.btitle=Lucky+Duck&amp;amp;rft.pub=Disney+Junior&amp;amp;rft_id=http%3A%2F%2Fdisneyjunior.com%2Flucky-duck&amp;amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFriendly+Floatees&quot; class=&quot;Z3988&quot;/&gt;&lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;/span&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;
&lt;style data-mw-deduplicate=&quot;TemplateStyles:r853264625&quot;&gt;&lt;![CDATA[.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents&gt;ul{list-style-type:none;margin-left:0}.mw-parser-output .refbegin-hanging-indents&gt;ul&gt;li,.mw-parser-output .refbegin-hanging-indents&gt;dl&gt;dd{margin-left:0;padding-left:3.2em;text-indent:-3.2em;list-style:none}.mw-parser-output .refbegin-100{font-size:100%}]]&gt;&lt;/style&gt;&lt;div class=&quot;refbegin&quot; style=&quot;&quot;&gt;
&lt;h2&gt;&lt;span class=&quot;mw-headline&quot; id=&quot;References&quot;&gt;References&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;Hohn, Donovan, &lt;i&gt;Moby-Duck: The True Story of 28,800 Bath Toys Lost at Sea and of the Beachcombers, Oceanographers, Environmentalists, and Fools, Including the Author, Who Went in Search of Them&lt;/i&gt;. Viking, New York, NY 2011, &lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/International_Standard_Book_Number&quot; title=&quot;International Standard Book Number&quot;&gt;ISBN&lt;/a&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Special:BookSources/978-0-670-02219-9&quot; title=&quot;Special:BookSources/978-0-670-02219-9&quot;&gt;978-0-670-02219-9&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;cite class=&quot;citation journal&quot;&gt;Curtis C. Ebbesmeyer and W. James Ingraham Jr. (October 1994). &lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;https://web.archive.org/web/20061005100806/http://www.agu.org/sci_soc/ducks.html&quot;&gt;&quot;Pacific Toy Spill Fuels Ocean Current Pathways Research&quot;&lt;/a&gt;. &lt;i&gt;Earth in Space&lt;/i&gt;. &lt;b&gt;7&lt;/b&gt; (2): 7–9, 14. Archived from &lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://www.agu.org/sci_soc/ducks.html&quot;&gt;the original&lt;/a&gt; on 5 October 2006&lt;span class=&quot;reference-accessdate&quot;&gt;. Retrieved &lt;span class=&quot;nowrap&quot;&gt;15 November&lt;/span&gt; 2006&lt;/span&gt;.&lt;/cite&gt;&lt;span title=&quot;ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;amp;rft.genre=article&amp;amp;rft.jtitle=Earth+in+Space&amp;amp;rft.atitle=Pacific+Toy+Spill+Fuels+Ocean+Current+Pathways+Research&amp;amp;rft.volume=7&amp;amp;rft.issue=2&amp;amp;rft.pages=7-9%2C+14&amp;amp;rft.date=1994-10&amp;amp;rft.au=Curtis+C.+Ebbesmeyer+and+W.+James+Ingraham+Jr.&amp;amp;rft_id=http%3A%2F%2Fwww.agu.org%2Fsci_soc%2Fducks.html&amp;amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFriendly+Floatees&quot; class=&quot;Z3988&quot;/&gt;&lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;/li&gt;
&lt;li&gt;&lt;cite class=&quot;citation web&quot;&gt;&lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;https://web.archive.org/web/20031001221100/http://www.thefirstyears.com/duckies.html&quot;&gt;&quot;Ducks embark on a scientific journey&quot;&lt;/a&gt;. The First Years Inc. 2003. Archived from &lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://www.thefirstyears.com/duckies.html&quot;&gt;the original&lt;/a&gt; on 1 October 2003&lt;span class=&quot;reference-accessdate&quot;&gt;. Retrieved &lt;span class=&quot;nowrap&quot;&gt;15 November&lt;/span&gt; 2006&lt;/span&gt;.&lt;/cite&gt;&lt;span title=&quot;ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;amp;rft.genre=unknown&amp;amp;rft.btitle=Ducks+embark+on+a+scientific+journey&amp;amp;rft.pub=The+First+Years+Inc.&amp;amp;rft.date=2003&amp;amp;rft_id=http%3A%2F%2Fwww.thefirstyears.com%2Fduckies.html&amp;amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFriendly+Floatees&quot; class=&quot;Z3988&quot;/&gt;&lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;/li&gt;
&lt;li&gt;&lt;cite class=&quot;citation news&quot;&gt;&lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://www.cbsnews.com/stories/2003/07/31/eveningnews/main566138.shtml&quot;&gt;&quot;Rubber Duckies Map The World&quot;&lt;/a&gt;. CBS News. 31 July 2003&lt;span class=&quot;reference-accessdate&quot;&gt;. Retrieved &lt;span class=&quot;nowrap&quot;&gt;15 November&lt;/span&gt; 2006&lt;/span&gt;.&lt;/cite&gt;&lt;span title=&quot;ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;amp;rft.genre=article&amp;amp;rft.atitle=Rubber+Duckies+Map+The+World&amp;amp;rft.date=2003-07-31&amp;amp;rft_id=http%3A%2F%2Fwww.cbsnews.com%2Fstories%2F2003%2F07%2F31%2Feveningnews%2Fmain566138.shtml&amp;amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFriendly+Floatees&quot; class=&quot;Z3988&quot;/&gt;&lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;/li&gt;
&lt;li&gt;&lt;cite class=&quot;citation web&quot;&gt;Ed Perry, Ed. (May 2005). &lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://www.seabean.com/newsletters/vol11-1.pdf&quot;&gt;&quot;The Drifting Seed newsletter&quot;&lt;/a&gt; &lt;span class=&quot;cs1-format&quot;&gt;(PDF)&lt;/span&gt;&lt;span class=&quot;reference-accessdate&quot;&gt;. Retrieved &lt;span class=&quot;nowrap&quot;&gt;15 November&lt;/span&gt; 2006&lt;/span&gt;.&lt;/cite&gt;&lt;span title=&quot;ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;amp;rft.genre=unknown&amp;amp;rft.btitle=The+Drifting+Seed+newsletter&amp;amp;rft.date=2005-05&amp;amp;rft.au=Ed+Perry%2C+Ed.&amp;amp;rft_id=http%3A%2F%2Fwww.seabean.com%2Fnewsletters%2Fvol11-1.pdf&amp;amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFriendly+Floatees&quot; class=&quot;Z3988&quot;/&gt;&lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;/li&gt;
&lt;li&gt;&lt;cite class=&quot;citation web&quot;&gt;Curtis C. Ebbesmeyer. &lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;https://web.archive.org/web/20061110180943/http://www.beachcombers.org/RubberDuckies.html&quot;&gt;&quot;Beachcombing Science from Bath Toys&quot;&lt;/a&gt;. Archived from &lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://www.beachcombers.org/RubberDuckies.html&quot;&gt;the original&lt;/a&gt; on 10 November 2006&lt;span class=&quot;reference-accessdate&quot;&gt;. Retrieved &lt;span class=&quot;nowrap&quot;&gt;15 November&lt;/span&gt; 2006&lt;/span&gt;.&lt;/cite&gt;&lt;span title=&quot;ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;amp;rft.genre=unknown&amp;amp;rft.btitle=Beachcombing+Science+from+Bath+Toys&amp;amp;rft.au=Curtis+C.+Ebbesmeyer&amp;amp;rft_id=http%3A%2F%2Fwww.beachcombers.org%2FRubberDuckies.html&amp;amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFriendly+Floatees&quot; class=&quot;Z3988&quot;/&gt;&lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;/li&gt;
&lt;li&gt;&lt;cite class=&quot;citation news&quot;&gt;Simon de Bruxelles (28 June 2007). &lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://www.timesonline.co.uk/tol/news/uk/article1996553.ece&quot;&gt;&quot;Plastic duck armada is heading for Britain after 15-year global voyage&quot;&lt;/a&gt;. &lt;i&gt;The Times&lt;/i&gt;. London&lt;span class=&quot;reference-accessdate&quot;&gt;. Retrieved &lt;span class=&quot;nowrap&quot;&gt;28 June&lt;/span&gt; 2007&lt;/span&gt;.&lt;/cite&gt;&lt;span title=&quot;ctx_ver=Z39.88-2004&amp;amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;amp;rft.genre=article&amp;amp;rft.jtitle=The+Times&amp;amp;rft.atitle=Plastic+duck+armada+is+heading+for+Britain+after+15-year+global+voyage&amp;amp;rft.date=2007-06-28&amp;amp;rft.au=Simon+de+Bruxelles&amp;amp;rft_id=http%3A%2F%2Fwww.timesonline.co.uk%2Ftol%2Fnews%2Fuk%2Farticle1996553.ece&amp;amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AFriendly+Floatees&quot; class=&quot;Z3988&quot;/&gt;&lt;link rel=&quot;mw-deduplicated-inline-style&quot; href=&quot;mw-data:TemplateStyles:r861714446&quot;/&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
&lt;h2&gt;&lt;span class=&quot;mw-headline&quot; id=&quot;External_links&quot;&gt;External links&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://www.islandnet.com/~see/weather/elements/shoes.htm&quot;&gt;Keith C. Heidorn, 'Of Shoes And Ships And Rubber Ducks And A Message In A Bottle'&lt;/a&gt;, &lt;i&gt;The Weather Doctor&lt;/i&gt; (17 March 1999).&lt;/li&gt;
&lt;li&gt;&lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://news.bbc.co.uk/1/hi/world/americas/3060579.stm&quot;&gt;Jane Standley, 'Ducks' odyssey nears end'&lt;/a&gt;, &lt;i&gt;BBC News&lt;/i&gt;, (12 July 2003).&lt;/li&gt;
&lt;li&gt;&lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://www.theage.com.au/articles/2003/08/06/1060064238597.html&quot;&gt;Duck ahoy&lt;/a&gt;, &lt;i&gt;The Age&lt;/i&gt;, (7 August 2003)&lt;/li&gt;
&lt;li&gt;Marsha Walton, &lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://cnn.at/2003/TECH/science/05/26/coolsc.oceansecrets/index.html&quot;&gt;'How Nikes, toys and hockey gear help ocean science'&lt;/a&gt;, CNN.com (26 May 2003).&lt;/li&gt;
&lt;li&gt;&lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://www.spiegel.de/reise/aktuell/0,1518,491506,00.html&quot;&gt;&quot;Journey of the Floatees&quot;&lt;/a&gt;, Spiegel magazine (1 July 2007)&lt;/li&gt;
&lt;li&gt;&lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;https://web.archive.org/web/20070927161150/http://www.rubaduck.com/news/rubber_duck_news-200302-duckies_around_the_world.htm&quot;&gt;&quot;Timeline of Rubber Duck Voyage&quot;&lt;/a&gt;, Rubaduck.com&lt;/li&gt;
&lt;li&gt;Donovan Hohn, &lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://www.harpers.org/archive/2007/01/0081345&quot;&gt;&quot;Moby-Duck: Or, The Synthetic Wilderness of Childhood,&quot;&lt;/a&gt; &lt;i&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Harper%27s_Magazine&quot; title=&quot;Harper's Magazine&quot;&gt;Harper's Magazine&lt;/a&gt;&lt;/i&gt;, January (2007), pp. 39–62.&lt;/li&gt;
&lt;li&gt;&lt;a rel=&quot;nofollow&quot; class=&quot;external text&quot; href=&quot;http://www.donovanhohn.com/Home.html&quot;&gt;Moby Duck: The True Story of 28,800 Bath Toys Lost at Sea and of the Beachcombers, Oceanographers, Environmentalists, and Fools, Including the Author, Who Went in Search of Them&lt;/a&gt; – follow up non-fiction book based on 2 years research after the Harper's Magazine article.&lt;/li&gt;&lt;/ul&gt;&lt;!-- 
NewPP limit report
Parsed by mw1331
Cached time: 20181026204506
Cache expiry: 1900800
Dynamic content: false
CPU time usage: 0.300 seconds
Real time usage: 0.380 seconds
Preprocessor visited node count: 1740/1000000
Preprocessor generated node count: 0/1500000
Post&amp;#8208;expand include size: 32341/2097152 bytes
Template argument size: 2065/2097152 bytes
Highest expansion depth: 12/40
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip post&amp;#8208;expand size: 38739/5000000 bytes
Number of Wikibase entities loaded: 0/400
Lua time usage: 0.127/10.000 seconds
Lua memory usage: 4.84 MB/50 MB
--&gt;&lt;!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  335.074      1 -total
 27.75%   92.973      1 Template:Reflist
 22.50%   75.405      1 Template:More_footnotes
 21.60%   72.362      9 Template:Cite_news
 18.72%   62.710      4 Template:ISBN
 11.83%   39.625      1 Template:Ambox
 10.96%   36.710      4 Template:Catalog_lookup_link
  8.32%   27.867      1 Template:Clarify
  7.36%   24.653      1 Template:Fix-span
  5.49%   18.380      4 Template:Cite_web
--&gt;&lt;!-- Saved in parser cache with key enwiki:pcache:idhash:6264793-0!canonical and timestamp 20181026204506 and revision id 865888318
 --&gt;&lt;/div&gt;&lt;noscript&gt;&lt;img src=&quot;https://en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1&quot; alt=&quot;&quot; title=&quot;&quot; width=&quot;1&quot; height=&quot;1&quot; style=&quot;border: none; position: absolute;&quot;/&gt;&lt;/noscript&gt;&lt;/div&gt;					&lt;div class=&quot;printfooter&quot;&gt;
						Retrieved from &quot;&lt;a dir=&quot;ltr&quot; href=&quot;https://en.wikipedia.org/w/index.php?title=Friendly_Floatees&amp;amp;oldid=865888318&quot;&gt;https://en.wikipedia.org/w/index.php?title=Friendly_Floatees&amp;amp;oldid=865888318&lt;/a&gt;&quot;					&lt;/div&gt;
								&lt;div class=&quot;visualClear&quot;/&gt;
							</description>
<pubDate>Fri, 26 Oct 2018 18:41:06 +0000</pubDate>
<dc:creator>Tomte</dc:creator>
<og:image>https://upload.wikimedia.org/wikipedia/commons/1/1f/Friendly_Floatees.png</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://en.wikipedia.org/wiki/Friendly_Floatees</dc:identifier>
</item>
<item>
<title>Visualizing quaternions: An explorable video series</title>
<link>https://eater.net/quaternions</link>
<guid isPermaLink="true" >https://eater.net/quaternions</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://eater.net/quaternions&quot;&gt;https://eater.net/quaternions&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=18310788&quot;&gt;https://news.ycombinator.com/item?id=18310788&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 255&lt;/p&gt;
&lt;p&gt;# Comments: 26&lt;/p&gt;
</description>
<pubDate>Fri, 26 Oct 2018 16:33:08 +0000</pubDate>
<dc:creator>beneater</dc:creator>
<og:url>https://eater.net/quaternions</og:url>
<og:type>website</og:type>
<og:title>Visualizing quaternions, an explorable video series</og:title>
<og:image>https://eater.net/media/intro.jpg</og:image>
<og:description>Explaining how quaternions, a four-dimensional number system, describe 3d rotation.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://eater.net/quaternions</dc:identifier>
</item>
<item>
<title>One Windows Kernel</title>
<link>https://techcommunity.microsoft.com/t5/Windows-Kernel-Internals/One-Windows-Kernel/ba-p/267142</link>
<guid isPermaLink="true" >https://techcommunity.microsoft.com/t5/Windows-Kernel-Internals/One-Windows-Kernel/ba-p/267142</guid>
<description>&lt;p&gt;Windows is one of the most versatile and flexible operating systems out there, running on a variety of machine architectures and available in multiple SKUs. It currently supports x86, x64, ARM and ARM64 architectures. Windows used to support Itanium, PowerPC, DEC Alpha, and MIPS (&lt;span&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Windows_NT&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;wiki entry&lt;/a&gt;&lt;/span&gt;). In addition, Windows supports a variety of SKUs that run in a multitude of environments; from data centers, laptops, Xbox, phones to embedded IOT devices such as ATM machines.&lt;/p&gt;

&lt;p&gt;The most amazing aspect of all this is that the core of Windows, its kernel, remains virtually unchanged on all these architectures and SKUs. The Windows kernel scales dynamically depending on the architecture and the processor that it’s run on to exploit the full power of the hardware. There is of course some architecture specific code in the Windows kernel, however this is kept to a minimum to allow Windows to run on a variety of architectures.&lt;/p&gt;

&lt;p&gt;In this blog post, I will talk about the evolution of the core pieces of the Windows kernel that allows it to transparently scale across a low power NVidia Tegra chip on the &lt;span&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Surface_2&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Surface RT&lt;/a&gt;&lt;/span&gt; from 2012, to the giant &lt;span&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;behemoths&lt;/a&gt;&lt;/span&gt; that power Azure data centers today.&lt;/p&gt;

&lt;p&gt;This is a picture of Windows taskmgr running on a pre-release Windows DataCenter class machine with 896 cores supporting 1792 logical processors and 2TB of RAM!&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;lia-inline-image-display-wrapper lia-image-align-inline&quot;&gt;&lt;img src=&quot;https://gxcuf89792.i.lithium.com/t5/image/serverpage/image-id/55551i89F6A2C912C5C448/image-size/large?v=1.0&amp;amp;px=999&quot; alt=&quot;TaskMgr.png&quot; title=&quot;TaskMgr.png&quot; li-image-url=&quot;https://gxcuf89792.i.lithium.com/t5/image/serverpage/image-id/55551i89F6A2C912C5C448?v=1.0&quot; li-image-display-id=&quot;'55551i89F6A2C912C5C448'&quot; li-message-uid=&quot;'267142'&quot; li-messages-message-image=&quot;true&quot; li-bindable=&quot;&quot; class=&quot;lia-media-image&quot; tabindex=&quot;0&quot; li-bypass-lightbox-when-linked=&quot;true&quot; li-use-hover-links=&quot;false&quot;/&gt;&lt;span class=&quot;lia-inline-image-caption&quot; onclick=&quot;event.preventDefault();&quot;&gt;Task Manager showing 1792 logical processors&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Before we talk about the details of the Windows kernel, I am going to take a small detour to talk about something called Windows refactoring. Windows refactoring plays a key part in increasing the reuse of Windows components across different SKUs, and platforms (e.g. client, server and phone). The basic idea of Windows refactoring is to allow the same DLL to be reused in different SKUs but support minor modifications tailored to the SKU without renaming the DLL and breaking apps.&lt;/p&gt;

&lt;p&gt;The base technology used for Windows refactoring are a lightly documented technology (entirely by design) called &lt;span&gt;&lt;a href=&quot;http://msdn.microsoft.com/en-us/library/windows/desktop/Hh802935(v=vs.85).aspx&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;API sets&lt;/a&gt;&lt;/span&gt;. API sets are a mechanism that allows Windows to decouple the DLL from where its implementation is located. For example, API sets allow win32 apps to continue to use kernel32.dll but, the implementation of all the APIs are in a different DLL. These implementation DLLs can also be different depending on your SKU. You can see API sets in action if you launch dependency walker on a traditional Windows DLL; e.g. kernel32.dll.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;lia-inline-image-display-wrapper lia-image-align-inline&quot;&gt;&lt;img src=&quot;https://gxcuf89792.i.lithium.com/t5/image/serverpage/image-id/55556i8BF228D9318A85CC/image-size/large?v=1.0&amp;amp;px=999&quot; alt=&quot;depends.png&quot; title=&quot;depends.png&quot; li-image-url=&quot;https://gxcuf89792.i.lithium.com/t5/image/serverpage/image-id/55556i8BF228D9318A85CC?v=1.0&quot; li-image-display-id=&quot;'55556i8BF228D9318A85CC'&quot; li-message-uid=&quot;'267142'&quot; li-messages-message-image=&quot;true&quot; li-bindable=&quot;&quot; class=&quot;lia-media-image&quot; tabindex=&quot;0&quot; li-bypass-lightbox-when-linked=&quot;true&quot; li-use-hover-links=&quot;false&quot;/&gt;&lt;span class=&quot;lia-inline-image-caption&quot; onclick=&quot;event.preventDefault();&quot;&gt;Dependency walker&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;With that detour into how Windows is built to maximize code reuse and sharing, let’s go into the technical depths of the kernel starting with the scheduler which is key to the scaling of Windows.&lt;/p&gt;


&lt;p&gt;Windows NT is like a &lt;a href=&quot;https://en.wikipedia.org/wiki/Microkernel&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;microkernel&lt;/a&gt; in the sense that it has a core Kernel (KE) that does very little and uses the Executive layer (Ex) to perform all the higher-level policy. Note that EX is still kernel mode, so it's not a true microkernel. The kernel is responsible for thread dispatching, multiprocessor synchronization, hardware exception handling, and the implementation of low-level machine dependent functions. The EX layer contains various subsystems which provide the bulk of the functionality traditionally thought of as kernel such as IO, Object Manager, Memory Manager, Process Subsystem, etc.&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;lia-inline-image-display-wrapper lia-image-align-inline&quot;&gt;&lt;img src=&quot;https://gxcuf89792.i.lithium.com/t5/image/serverpage/image-id/55558i85CBB1B2E72B3E88/image-size/large?v=1.0&amp;amp;px=999&quot; alt=&quot;arch.png&quot; title=&quot;arch.png&quot; li-image-url=&quot;https://gxcuf89792.i.lithium.com/t5/image/serverpage/image-id/55558i85CBB1B2E72B3E88?v=1.0&quot; li-image-display-id=&quot;'55558i85CBB1B2E72B3E88'&quot; li-message-uid=&quot;'267142'&quot; li-messages-message-image=&quot;true&quot; li-bindable=&quot;&quot; class=&quot;lia-media-image&quot; tabindex=&quot;0&quot; li-bypass-lightbox-when-linked=&quot;true&quot; li-use-hover-links=&quot;false&quot;/&gt;&lt;/span&gt; &lt;/p&gt;

&lt;p&gt;To get a better idea of the size of the components, here is a rough breakdown on the number of lines of code in a few key directories in the Windows kernel source tree (counting comments). There is a lot more to the Kernel not shown in this table. &lt;/p&gt;

&lt;table width=&quot;395&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td width=&quot;171&quot;&gt;
&lt;p&gt;&lt;strong&gt;Kernel subsystems&lt;/strong&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;223&quot;&gt;
&lt;p&gt;&lt;strong&gt;Lines of code&lt;/strong&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td width=&quot;171&quot;&gt;
&lt;p&gt;&lt;strong&gt;Memory Manager&lt;/strong&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;223&quot;&gt;
&lt;p&gt;501, 000&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td width=&quot;171&quot;&gt;
&lt;p&gt;&lt;strong&gt;Registry&lt;/strong&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;223&quot;&gt;
&lt;p&gt;211,000&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td width=&quot;171&quot;&gt;
&lt;p&gt;&lt;strong&gt;Power&lt;/strong&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;223&quot;&gt;
&lt;p&gt;238,000&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td width=&quot;171&quot;&gt;
&lt;p&gt;&lt;strong&gt;Executive&lt;/strong&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;223&quot;&gt;
&lt;p&gt;157,000&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td width=&quot;171&quot;&gt;
&lt;p&gt;&lt;strong&gt;Security&lt;/strong&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;223&quot;&gt;
&lt;p&gt;135,000&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td width=&quot;171&quot;&gt;
&lt;p&gt;&lt;strong&gt;Kernel&lt;/strong&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;223&quot;&gt;
&lt;p&gt;339,000&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td width=&quot;171&quot;&gt;
&lt;p&gt;&lt;strong&gt;Process sub-system&lt;/strong&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;223&quot;&gt;
&lt;p&gt;116,000&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;For more information on the architecture of Windows, the “&lt;a href=&quot;https://docs.microsoft.com/en-us/sysinternals/learn/windows-internals&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Windows Internals&lt;/a&gt;” series of books are a good reference.&lt;/p&gt;


&lt;p&gt;With that background, let's talk a little bit about the scheduler, its evolution and how Windows kernel can scale across so many different architectures with so many processors.&lt;/p&gt;

&lt;p&gt;A thread is the basic unit that runs program code and it is this unit that is scheduled by the Window scheduler. The Windows scheduler uses the thread priority to decide which thread to run and in theory the highest priority thread on the system always gets to run even if that entails preempting a lower priority thread.&lt;/p&gt;

&lt;p&gt;As a thread runs and experiences quantum end (minimum amount of time a thread gets to run), its dynamic priority decays, so that a high priority CPU bound thread doesn’t run forever starving everyone else. When another waiting thread is awakened to run, it is given a priority boost based on the importance of the event that caused the wait to be satisfied (e.g. a large boost is for a foreground UI thread vs. a smaller one for completing disk I/O). A thread therefore runs at a high priority as long as it’s interactive. When it becomes CPU (compute) bound, its priority decays, and it is considered only after other, higher priority threads get their time on the CPU. In addition, the kernel arbitrarily boosts the priority of ready threads that haven't received any processor time for a given period of time to prevent starvation and correct priority inversions.&lt;/p&gt;

&lt;p&gt;The Windows scheduler initially had a single ready queue from where it picked up the next highest priority thread to run on the processor. However, as Windows started supporting more and more processors the single ready queue turned out to be a bottleneck and around &lt;strong&gt;Windows Server 2003,&lt;/strong&gt; the scheduler changed to one ready queue per processor. As Windows moved to multiple per processor queues, it avoided having a single global lock protecting all the queues and allowed the scheduler to make locally optimum decisions. This means that any point the single highest priority thread in the system runs but that doesn’t necessarily mean that the top N (N is number of cores) priority threads on the system are running. This proved to be good enough until Windows started moving to low power CPUs, e.g. in laptops and tablets. On these systems, not running a high priority thread (such as the foreground UI thread) caused the system to have noticeable glitches in UI. And so, in &lt;strong&gt;Windows 8.1&lt;/strong&gt;, the scheduler changed to a hybrid model with per processor ready queues for affinitized (tied to a processor) work and shared ready queues between processors. This did not cause a noticeable impact on performance because of other architectural changes in the scheduler such as the dispatcher database lock refactoring which we will talk about later.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Windows 7&lt;/strong&gt; introduced something called the Dynamic Fair Share Scheduler; this feature was introduced primarily for terminal servers. The problem that this feature tried to solve was that one terminal server session which had a CPU intensive workload could impact the threads in other terminal server sessions. Since the scheduler didn’t consider sessions and simply used the priority as the key to schedule threads, users in different sessions could impact the user experience of others by starving their threads. It also unfairly advantages the sessions (users) who has a lot of threads because the sessions with more threads get more opportunity to be scheduled and received CPU time. This feature tried to add policy to the scheduler such that each session was treated fairly and roughly the same amount of CPU was available to each session. &lt;span&gt;Similar functionality is available in Linux as well, with its &lt;a href=&quot;https://en.wikipedia.org/wiki/Completely_Fair_Scheduler&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Completely Fair Scheduler&lt;/a&gt;&lt;/span&gt;. In &lt;strong&gt;Windows 8&lt;/strong&gt;, this concept was generalized as a scheduler group and added to the Windows Scheduler with each session in an independent scheduler group. In addition to the thread priority, the scheduler uses the scheduler groups as a second level index to decide which thread should run next. In a terminal server, all the scheduler groups are weighted equally and hence all sessions (scheduler groups) receive the same amount of CPU regardless of the number or priorities of the threads in the scheduler groups. In addition to its utility in a terminal server session, scheduler groups are also used to have fine grained control on a process at runtime. In Windows 8, &lt;strong&gt;Job objects&lt;/strong&gt; were enhanced to support &lt;span&gt;&lt;a href=&quot;http://msdn.microsoft.com/en-us/library/windows/desktop/hh448384(v=vs.85).aspx&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;CPU rate control&lt;/a&gt;&lt;/span&gt;. Using the CPU rate control APIs, one can decide how much CPU a process can use, whether it should be a hard cap or a soft cap and receive notifications when a process meets those CPU limits. This is like the resource controls features available in &lt;span&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Cgroups&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;cgroups&lt;/a&gt;&lt;/span&gt; on Linux.&lt;/p&gt;

&lt;p&gt;Starting with &lt;strong&gt;Windows 7&lt;/strong&gt;, Windows Server started supporting greater than &lt;span&gt;&lt;a href=&quot;http://msdn.microsoft.com/en-us/library/windows/hardware/gg463349.aspx&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;64 logical processors&lt;/a&gt;&lt;/span&gt; in a single machine. To add support for so many processors, Windows internally introduced a new entity called “processor group”. A group is a static set of up to 64 logical processors that is treated as a single scheduling entity.  The kernel determines at boot time which processor belongs to which group and for machines with less than 64 cores, with the overhead of the group structure indirection is mostly not noticeable. While a single process can span groups (such as a SQL server instance), and individual thread could only execute within a single scheduling group at a time.&lt;/p&gt;

&lt;p&gt;However, on machines with greater than 64 cores, Windows started showing some bottlenecks that prevented high performance applications such as SQL server from scaling their performance linearly with the number of processor cores. Thus, even if you added more cores and memory, the benchmarks wouldn’t show much increase in performance. And one of the main problems that caused this lack of performance was the contention around the Dispatcher database lock. The dispatcher database lock protected access to those objects that needed to be dispatched; i.e. scheduled. Examples of objects that were protected by this lock included threads, timers, I/O completion ports, and other waitable kernel objects (events, semaphores, mutants, etc.). Thus, in Windows 7 due to the impetus provided by the greater than 64 processor support, work was done to eliminate the dispatcher database lock and replace it with fine grained locks such as per object locks. This allowed benchmarks such as the SQL &lt;span&gt;&lt;a href=&quot;http://www.tpc.org/tpcc/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;TPC-C&lt;/a&gt;&lt;/span&gt; to show a &lt;strong&gt;290%&lt;/strong&gt; improvement when compared to Windows 7 with a dispatcher database lock on certain machine configurations. This was one of the biggest performance boosts seen in Windows history, due to a single feature.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Windows 10&lt;/strong&gt; brought us another innovation in the scheduler space with &lt;span&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/windows/desktop/ProcThread/cpu-sets&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;CPU Sets&lt;/a&gt;&lt;/span&gt;. CPU Sets allow a process to partition the system such that its process can take over a group of processors and not allow any other process or system to run their threads on those processors. Windows Kernel even steers Interrupts from devices away from the processors that are part of your CPU set. This ensures that even devices cannot target their code on the processors which have been partitioned off by CPU sets for your app or process. Think of this as a low-tech Virtual Machine. As you can imagine this is a powerful capability and hence there are a lot of safeguards built-in to prevent an app developer from making the wrong choice within the API. CPU sets functionality are used by the customer when they use &lt;span&gt;&lt;a href=&quot;https://www.windowscentral.com/windows-10-game-mode&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Game Mode&lt;/a&gt;&lt;/span&gt; to run their games.&lt;/p&gt;

&lt;p&gt;Finally, this brings us to &lt;strong&gt;ARM64&lt;/strong&gt; support with &lt;span&gt;&lt;a href=&quot;https://channel9.msdn.com/Events/Build/2018/BRK2438&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Windows 10 on ARM&lt;/a&gt;&lt;/span&gt;.  The ARM architecture supports a &lt;span&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/ARM_big.LITTLE&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;big.LITTLE&lt;/a&gt;&lt;/span&gt; architecture, big.LITTLE is a heterogenous architecture where the “big” core runs fast, consuming more power and the “LITTLE” core runs slow consuming less power. The idea here is that you run unimportant tasks on the little core saving battery. To support big.LITTLE architecture and provide great battery life on Windows 10 on ARM, the Windows scheduler added support for &lt;strong&gt;heterogenous scheduling&lt;/strong&gt; which took into account the app intent for scheduling on big.LITTLE architectures.&lt;/p&gt;

&lt;p&gt;By app intent, I mean Windows tries to provide a quality of service for apps by tracking threads which are running in the foreground (or starved of CPU) and ensuring those threads always run on the big core. Whereas the background tasks, services, and other ancillary threads in the system run on the little cores. (As an aside, you can also &lt;span&gt;&lt;a href=&quot;https://docs.microsoft.com/en-us/windows/desktop/api/processthreadsapi/nf-processthreadsapi-setthreadinformation&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;programmatically&lt;/a&gt;&lt;/span&gt; mark your thread as unimportant which will make it run on the LITTLE core.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Work on Behalf:&lt;/strong&gt; In Windows, a lot of work for the foreground is done by other services running in the background. E.g. In Outlook, when you search for a mail, the search is conducted by a background service (Indexer). If we simply, run all the services on the little core, then the experience and performance of the foreground app will be affected. To ensure, that these scenarios are not slow on big.LITTLE architectures, Windows actually tracks when an app calls into another process to do work on its behalf. When this happens, we donate the foreground priority to the service thread and force run the thread in the service on the big core.&lt;/p&gt;

&lt;p&gt;That concludes our first (huge?) One Windows Kernel post, giving you an overview of the Windows Kernel Scheduler. We will have more similarly technical posts about the internals of the Windows Kernel. &lt;/p&gt;

&lt;p&gt;Hari Pulapaka&lt;/p&gt;
&lt;p&gt;(Windows Kernel Team)&lt;/p&gt;
</description>
<pubDate>Fri, 26 Oct 2018 15:18:47 +0000</pubDate>
<dc:creator>MikusR</dc:creator>
<og:image>https://gxcuf89792.i.lithium.com/t5/image/serverpage/image-id/55551i89F6A2C912C5C448?v=1.0</og:image>
<og:type>article</og:type>
<og:description>Windows is one of the most versatile and flexible operating systems out there, running on a variety of machine architectures and available in multiple SKUs. It currently supports x86, x64, ARM and ARM64 architectures. Windows used to support Itanium, PowerPC, DEC Alpha, and MIPS (wiki entry). In add...</og:description>
<og:title>One Windows Kernel</og:title>
<og:url>https://techcommunity.microsoft.com/t5/Windows-Kernel-Internals/One-Windows-Kernel/ba-p/267142</og:url>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://techcommunity.microsoft.com/t5/Windows-Kernel-Internals/One-Windows-Kernel/ba-p/267142</dc:identifier>
</item>
<item>
<title>The Architecture of Git (2012)</title>
<link>http://aosabook.org/en/git.html</link>
<guid isPermaLink="true" >http://aosabook.org/en/git.html</guid>
<description>&lt;section readability=&quot;11&quot;&gt;&lt;h2&gt;6.1. Git in a Nutshell&lt;/h2&gt;
&lt;p&gt;Git enables the maintenance of a digital body of work (often, but not limited to, code) by many collaborators using a peer-to-peer network of repositories. It supports distributed workflows, allowing a body of work to either eventually converge or temporarily diverge.&lt;/p&gt;
&lt;p&gt;This chapter will show how various aspects of Git work under the covers to enable this, and how it differs from other version control systems (VCSs).&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;72.829538820782&quot;&gt;&lt;h2&gt;6.2. Git's Origin&lt;/h2&gt;
&lt;p&gt;To understand Git's design philosophy better it is helpful to understand the circumstances in which the Git project was started in the Linux Kernel Community.&lt;/p&gt;
&lt;p&gt;The Linux kernel was unusual, compared to most commercial software projects at that time, because of the large number of committers and the high variance of contributor involvement and knowledge of the existing codebase. The kernel had been maintained via tarballs and patches for years, and the core development community struggled to find a VCS that satisfied most of their needs.&lt;/p&gt;
&lt;p&gt;Git is an open source project that was born out of those needs and frustrations in 2005. At that time the Linux kernel codebase was managed across two VCSs, BitKeeper and CVS, by different core developers. BitKeeper offered a different view of VCS history lineage than that offered by the popular open source VCSs at this time.&lt;/p&gt;
&lt;p&gt;Days after BitMover, the maker of BitKeeper, announced it would revoke the licenses of some core Linux kernel developers, Linus Torvalds began development, in haste, of what was to become Git. He began by writing a collection of scripts to help him manage email patches to apply one after the other. The aim of this initial collection of scripts was to be able to abort merges quickly so the maintainer could modify the codebase mid-patch-stream to manually merge, then continue merging subsequent patches.&lt;/p&gt;
&lt;p&gt;From the outset, Torvalds had one philosophical goal for Git—to be the anti-CVS—plus three usability design goals:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Support distributed workflows similar to those enabled by BitKeeper&lt;/li&gt;
&lt;li&gt;Offer safeguards against content corruption&lt;/li&gt;
&lt;li&gt;Offer high performance&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;These design goals have been accomplished and maintained, to a degree, as I will attempt to show by dissecting Git's use of directed acyclic graphs (DAGs) for content storage, reference pointers for heads, object model representation, and remote protocol; and finally how Git tracks the merging of trees.&lt;/p&gt;
&lt;p&gt;Despite BitKeeper influencing the original design of Git, it is implemented in fundamentally different ways and allows even more distributed plus local-only workflows, which were not possible with BitKeeper. &lt;a href=&quot;http://www.monotone.ca/&quot;&gt;Monotone&lt;/a&gt;, an open source distributed VCS started in 2003, was likely another inspiration during Git's early development.&lt;/p&gt;
&lt;p&gt;Distributed version control systems offer great workflow flexibility, often at the expense of simplicity. Specific benefits of a distributed model include:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Providing the ability for collaborators to work offline and commit incrementally.&lt;/li&gt;
&lt;li&gt;Allowing a collaborator to determine when his/her work is ready to share.&lt;/li&gt;
&lt;li&gt;Offering the collaborator access to the repository history when offline.&lt;/li&gt;
&lt;li&gt;Allowing the managed work to be published to multiple repositories, potentially with different branches or granularity of changes visible.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Around the time the Git project started, three other open source distributed VCS projects were initiated. (One of them, Mercurial, is discussed in Volume 1 of &lt;em&gt;The Architecture of Open Source Applications&lt;/em&gt;.) All of these dVCS tools offer slightly different ways to enable highly flexible workflows, which centralized VCSs before them were not capable of handling directly. Note: Subversion has an extension named SVK maintained by different developers to support server-to-server synchronization.&lt;/p&gt;
&lt;p&gt;Today popular and actively maintained open source dVCS projects include Bazaar, Darcs, Fossil, Git, Mercurial, and Veracity.&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;75.5&quot;&gt;&lt;h2&gt;6.3. Version Control System Design&lt;/h2&gt;
&lt;p&gt;Now is a good time to take a step back and look at the alternative VCS solutions to Git. Understanding their differences will allow us to explore the architectural choices faced while developing Git.&lt;/p&gt;
&lt;p&gt;A version control system usually has three core functional requirements, namely:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Storing content&lt;/li&gt;
&lt;li&gt;Tracking changes to the content (history including merge metadata)&lt;/li&gt;
&lt;li&gt;Distributing the content and history with collaborators&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Note: The third requirement above is not a functional requirement for all VCSs.&lt;/p&gt;
&lt;section readability=&quot;10&quot;&gt;&lt;h3&gt;Content Storage&lt;/h3&gt;
&lt;p&gt;The most common design choices for storing content in the VCS world are with a delta-based changeset, or with directed acyclic graph (DAG) content representation.&lt;/p&gt;
&lt;p&gt;Delta-based changesets encapsulate the differences between two versions of the flattened content, plus some metadata. Representing content as a directed acyclic graph involves objects forming a hierarchy which mirrors the content's filesystem tree as a snapshot of the commit (reusing the unchanged objects inside the tree where possible). Git stores content as a directed acyclic graph using different types of objects. The &quot;Object Database&quot; section later in this chapter describes the different types of objects that can form DAGs inside the Git repository.&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;20&quot;&gt;&lt;h3&gt;Commit and Merge Histories&lt;/h3&gt;
On the history and change-tracking front most VCS software uses one of the following approaches:
&lt;ul&gt;&lt;li&gt;Linear history&lt;/li&gt;
&lt;li&gt;Directed acyclic graph for history&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Again Git uses a DAG, this time to store its history. Each commit contains metadata about its ancestors; a commit in Git can have zero or many (theoretically unlimited) parent commits. For example, the first commit in a Git repository would have zero parents, while the result of a three-way merge would have three parents.&lt;/p&gt;
&lt;p&gt;Another primary difference between Git and Subversion and its linear history ancestors is its ability to directly support branching that will record most merge history cases.&lt;/p&gt;
&lt;img src=&quot;http://aosabook.org/images/git/dag-example.png&quot;/&gt; Figure 6.1: Example of a DAG representation in Git
&lt;p&gt;Git enables full branching capability using directed acyclic graphs to store content. The history of a file is linked all the way up its directory structure (via nodes representing directories) to the root directory, which is then linked to a commit node. This commit node, in turn, can have one or more parents. This affords Git two properties that allow us to reason about history and content in more definite ways than the family of VCSs derived from RCS do, namely:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;When a content (i.e., file or directory) node in the graph has the same reference identity (the SHA in Git) as that in a different commit, the two nodes are guaranteed to contain the same content, allowing Git to short-circuit content diffing efficiently.&lt;/li&gt;
&lt;li&gt;When merging two branches we are merging the content of two nodes in a DAG. The DAG allows Git to &quot;efficiently&quot; (as compared to the RCS family of VCS) determine common ancestors.&lt;/li&gt;
&lt;/ul&gt;&lt;/section&gt;&lt;section readability=&quot;3&quot;&gt;&lt;h3&gt;Distribution&lt;/h3&gt;
&lt;p&gt;VCS solutions have handled content distribution of a working copy to collaborators on a project in one of three ways:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Local-only: for VCS solutions that do not have the third functional requirement above.&lt;/li&gt;
&lt;li&gt;Central server: where all changes to the repository must transact via one specific repository for it to be recorded in history at all.&lt;/li&gt;
&lt;li&gt;Distributed model: where there will often be publicly accessible repositories for collaborators to &quot;push&quot; to, but commits can be made locally and pushed to these public nodes later, allowing offline work.&lt;/li&gt;
&lt;/ul&gt;&lt;/section&gt;&lt;p&gt;To demonstrate the benefits and limitations of each major design choice, we will consider a Subversion repository and a Git repository (on a server), with equivalent content (i.e., the HEAD of the default branch in the Git repository has the same content as the Subversion repository's latest revision on trunk). A developer, named Alex, has a local checkout of the Subversion repository and a local clone of the Git repository.&lt;/p&gt;
&lt;p&gt;Let us say Alex makes a change to a 1 MB file in the local Subversion checkout, then commits the change. Locally, the checkout of the file mimics the latest change and local metadata is updated. During Alex's commit in the centralized Subversion repository, a diff is generated between the previous snapshot of the files and the new changes, and this diff is stored in the repository.&lt;/p&gt;
&lt;p&gt;Contrast this with the way Git works. When Alex makes the same modification to the equivalent file in the local Git clone, the change will be recorded locally first, then Alex can &quot;push&quot; the local pending commits to a public repository so the work can be shared with other collaborators on the project. The content changes are stored identically for each Git repository that the commit exists in. Upon the local commit (the simplest case), the local Git repository will create a new object representing a file for the changed file (with all its content inside). For each directory above the changed file (plus the repository root directory), a new tree object is created with a new identifier. A DAG is created starting from the newly created root tree object pointing to blobs (reusing existing blob references where the files content has not changed in this commit) and referencing the newly created blob in place of that file's previous blob object in the previous tree hierarchy. (A &lt;em&gt;blob&lt;/em&gt; represents a file stored in the repository.)&lt;/p&gt;
&lt;p&gt;At this point the commit is still local to the current Git clone on Alex's local device. When Alex &quot;pushes&quot; the commit to a publicly accessible Git repository this commit gets sent to that repository. After the public repository verifies that the commit can apply to the branch, the same objects are stored in the public repository as were originally created in the local Git repository.&lt;/p&gt;
&lt;p&gt;There are a lot more moving parts in the Git scenario, both under the covers and for the user, requiring them to explicitly express intent to share changes with the remote repository separately from tracking the change as a commit locally. However, both levels of added complexity offer the team greater flexibility in terms of their workflow and publishing capabilities, as described in the &quot;Git's Origin&quot; section above.&lt;/p&gt;
&lt;p&gt;In the Subversion scenario, the collaborator did not have to remember to push to the public remote repository when ready for others to view the changes made. When a small modification to a larger file is sent to the central Subversion repository the delta stored is much more efficient than storing the complete file contents for each version. However, as we will see later, there is a workaround for this that Git takes advantage of in certain scenarios.&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;28&quot;&gt;&lt;h2&gt;6.4. The Toolkit&lt;/h2&gt;
&lt;p&gt;Today the Git ecosystem includes many command-line and UI tools on a number of operating systems (including Windows, which was originally barely supported). Most of these tools are mostly built on top of the Git core toolkit.&lt;/p&gt;
&lt;p&gt;Due to the way Git was originally written by Linus, and its inception within the Linux community, it was written with a toolkit design philosophy very much in the Unix tradition of command line tools.&lt;/p&gt;
&lt;p&gt;The Git toolkit is divided into two parts: the plumbing and the porcelain. The plumbing consists of low-level commands that enable basic content tracking and the manipulation of directed acyclic graphs (DAG). The porcelain is the smaller subset of &lt;code&gt;git&lt;/code&gt; commands that most Git end users are likely to need to use for maintaining repositories and communicating between repositories for collaboration.&lt;/p&gt;
&lt;p&gt;While the toolkit design has provided enough commands to offer fine-grained access to functionality for many scripters, application developers complained about the lack of a linkable library for Git. Since the Git binary calls &lt;code&gt;die()&lt;/code&gt;, it is not reentrant and GUIs, web interfaces or longer running services would have to fork/exec a call to the Git binary, which can be slow.&lt;/p&gt;
&lt;p&gt;Work is being done to improve the situation for application developers; see the &quot;Current And Future Work&quot; section for more information.&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;79&quot;&gt;&lt;h2&gt;6.5. The Repository, Index and Working Areas&lt;/h2&gt;
&lt;p&gt;Let's get our hands dirty and dive into using Git locally, if only to understand a few fundamental concepts.&lt;/p&gt;
&lt;p&gt;First to create a new initialized Git repository on our local filesystem (using a Unix inspired operating system) we can do:&lt;/p&gt;
&lt;pre&gt;
  $ mkdir testgit
  $ cd testgit
  $ git init
&lt;/pre&gt;
&lt;p&gt;Now we have an empty, but initialized, Git repository sitting in our testgit directory. We can branch, commit, tag and even communicate with other local and remote Git repositories. Even communication with other types of VCS repositories is possible with just a handful of &lt;code&gt;git&lt;/code&gt; commands.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;git init&lt;/code&gt; command creates a .git subdirectory inside of testgit. Let's have a peek inside it:&lt;/p&gt;
&lt;pre&gt;
tree .git/
.git/
|-- HEAD
|-- config
|-- description
|-- hooks
|   |-- applypatch-msg.sample
|   |-- commit-msg.sample
|   |-- post-commit.sample
|   |-- post-receive.sample
|   |-- post-update.sample
|   |-- pre-applypatch.sample
|   |-- pre-commit.sample
|   |-- pre-rebase.sample
|   |-- prepare-commit-msg.sample
|   |-- update.sample
|-- info
|   |-- exclude
|-- objects
|   |-- info
|   |-- pack
|-- refs
    |-- heads
    |-- tags
&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;.git&lt;/code&gt; directory above is, by default, a subdirectory of the root working directory, &lt;code&gt;testgit&lt;/code&gt;. It contains a few different types of files and directories:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;em&gt;Configuration&lt;/em&gt;: the &lt;code&gt;.git/config&lt;/code&gt;, &lt;code&gt;.git/description&lt;/code&gt; and &lt;code&gt;.git/info/exclude&lt;/code&gt; files essentially help configure the local repository.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Hooks&lt;/em&gt;: the &lt;code&gt;.git/hooks&lt;/code&gt; directory contains scripts that can be run on certain lifecycle events of the repository.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Staging Area&lt;/em&gt;: the &lt;code&gt;.git/index&lt;/code&gt; file (which is not yet present in our tree listing above) will provide a staging area for our working directory.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Object Database&lt;/em&gt;: the &lt;code&gt;.git/objects&lt;/code&gt; directory is the default Git object database, which contains all content or pointers to local content. All objects are immutable once created.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;References&lt;/em&gt;: the &lt;code&gt;.git/refs&lt;/code&gt; directory is the default location for storing reference pointers for both local and remote branches, tags and heads. A reference is a pointer to an object, usually of type &lt;code&gt;tag&lt;/code&gt; or &lt;code&gt;commit&lt;/code&gt;. References are managed outside of the Object Database to allow the references to change where they point to as the repository evolves. Special cases of references may point to other references, e.g. &lt;code&gt;HEAD&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The &lt;code&gt;.git&lt;/code&gt; directory is the actual repository. The directory that contains the working set of files is the &lt;em&gt;working directory&lt;/em&gt;, which is typically the parent of the &lt;code&gt;.git&lt;/code&gt; directory (or &lt;em&gt;repository&lt;/em&gt;). If you were creating a Git remote repository that would not have a working directory, you could initialize it using the &lt;code&gt;git init --bare&lt;/code&gt; command. This would create just the pared-down repository files at the root, instead of creating the repository as a subdirectory under the working tree.&lt;/p&gt;
&lt;p&gt;Another file of great importance is the &lt;em&gt;Git index&lt;/em&gt;: &lt;code&gt;.git/index&lt;/code&gt;. It provides the staging area between the local working directory and the local repository. The index is used to stage specific changes within one file (or more), to be committed all together. Even if you make changes related to various types of features, the commits can be made with like changes together, to more logically describe them in the commit message. To selectively stage specific changes in a file or set of files you can using &lt;code&gt;git add -p&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The Git index, by default, is stored as a single file inside the repository directory. The paths to these three areas can be customized using environment variables.&lt;/p&gt;
&lt;p&gt;It is helpful to understand the interactions that take place between these three areas (the repository, index and working areas) during the execution of a few core Git commands:&lt;/p&gt;
&lt;ul readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;2&quot;&gt;&lt;code&gt;git checkout [branch]&lt;/code&gt;
&lt;p&gt;This will move the HEAD reference of the local repository to branch reference path (e.g. &lt;code&gt;refs/heads/master&lt;/code&gt;), populate the index with this head data and refresh the working directory to represent the tree at that head.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;&lt;code&gt;git add [files]&lt;/code&gt;
&lt;p&gt;This will cross reference the checksums of the &lt;em&gt;files&lt;/em&gt; specified with the corresponding entries in the Git index to see if the index for staged files needs updating with the working directory's version. Nothing changes in the Git directory (or repository).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Let us explore what this means more concretely by inspecting the contents of files under the &lt;code&gt;.git&lt;/code&gt; directory (or repository).&lt;/p&gt;
&lt;pre&gt;
  $ GIT_DIR=$PWD/.git
  $ cat $GIT_DIR/HEAD

  ref: refs/heads/master

  $ MY_CURRENT_BRANCH=$(cat .git/HEAD | sed 's/ref: //g')
  $ cat $GIT_DIR/$MY_CURRENT_BRANCH

  cat: .git/refs/heads/master: No such file or directory
&lt;/pre&gt;
&lt;p&gt;We get an error because, before making any commits to a Git repository at all, no branches exist except the default branch in Git which is &lt;code&gt;master&lt;/code&gt;, whether it exists yet or not.&lt;/p&gt;
&lt;p&gt;Now if we make a new commit, the master branch is created by default for this commit. Let us do this (continuing in the same shell, retaining history and context):&lt;/p&gt;
&lt;pre&gt;
  $ git commit -m &quot;Initial empty commit&quot; --allow-empty
  $ git branch

  * master

  $ cat $GIT_DIR/$MY_CURRENT_BRANCH

  3bce5b130b17b7ce2f98d17b2998e32b1bc29d68

  $ git cat-file -p $(cat $GIT_DIR/$MY_CURRENT_BRANCH)
&lt;/pre&gt;
&lt;p&gt;What we are starting to see here is the content representation inside Git's object database.&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;20&quot;&gt;&lt;h2&gt;6.6. The Object Database&lt;/h2&gt;
&lt;img src=&quot;http://aosabook.org/images/git/object-hierarchy.png&quot;/&gt; Figure 6.2: Git objects
&lt;p&gt;Git has four basic primitive objects that every type of content in the local repository is built around. Each object type has the following attributes: &lt;em&gt;type&lt;/em&gt;, &lt;em&gt;size&lt;/em&gt; and &lt;em&gt;content&lt;/em&gt;. The primitive object types are:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;em&gt;Tree&lt;/em&gt;: an element in a tree can be another tree or a blob, when representing a content directory.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Blob&lt;/em&gt;: a blob represents a file stored in the repository.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Commit&lt;/em&gt;: a commit points to a tree representing the top-level directory for that commit as well as parent commits and standard attributes.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Tag&lt;/em&gt;: a tag has a name and points to a commit at the point in the repository history that the tag represents.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;All object primitives are referenced by a SHA, a 40-digit object identity, which has the following properties:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;If two objects are identical they will have the same SHA.&lt;/li&gt;
&lt;li&gt;if two objects are different they will have different SHAs.&lt;/li&gt;
&lt;li&gt;If an object was only copied partially or another form of data corruption occurred, recalculating the SHA of the current object will identify such corruption.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The first two properties of the SHA, relating to identity of the objects, is most useful in enabling Git's distributed model (the second goal of Git). The latter property enables some safeguards against corruption (the third goal of Git).&lt;/p&gt;
&lt;p&gt;Despite the desirable results of using DAG-based storage for content storage and merge histories, for many repositories delta storage will be more space-efficient than using &lt;em&gt;loose&lt;/em&gt; DAG objects.&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;23&quot;&gt;&lt;h2&gt;6.7. Storage and Compression Techniques&lt;/h2&gt;
&lt;p&gt;Git tackles the storage space problem by packing objects in a compressed format, using an index file which points to offsets to locate specific objects in the corresponding &lt;em&gt;packed&lt;/em&gt; file.&lt;/p&gt;
&lt;img src=&quot;http://aosabook.org/images/git/packed-format.png&quot;/&gt; Figure 6.3: Diagram of a pack file with corresponding index file
&lt;p&gt;We can count the number of loose (or unpacked) objects in the local Git repository using &lt;code&gt;git count-objects&lt;/code&gt;. Now we can have Git pack loose objects in the object database, remove loose objects already packed, and find redundant pack files with Git plumbing commands if desired.&lt;/p&gt;
&lt;p&gt;The pack file format in Git has evolved, with the initial format storing CRC checksums for the pack file and index file in the index file itself. However, this meant there was the possibility of undetectable corruption in the compressed data since the repacking phase did not involve any further checks. Version 2 of the pack file format overcomes this problem by including the CRC checksums of each compressed object in the pack index file. Version 2 also allows packfiles larger than 4 GB, which the initial format did not support. As a way to quickly detect pack file corruption the end of the pack file contains a 20-byte SHA1 sum of the ordered list of all the SHAs in that file. The emphasis of the newer pack file format is on helping fulfill Git's second usability design goal of safeguarding against data corruption.&lt;/p&gt;
&lt;p&gt;For remote communication Git calculates the commits and content that need to be sent over the wire to synchronize repositories (or just a branch), and generates the pack file format on the fly to send back using the desired protocol of the client.&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;43&quot;&gt;&lt;h2&gt;6.8. Merge Histories&lt;/h2&gt;
&lt;p&gt;As mentioned previously, Git differs fundamentally in merge history approach than the RCS family of VCSs. Subversion, for example, represents file or tree history in a linear progression; whatever has a higher revision number will supercede anything before it. Branching is not supported directly, only through an unenforced directory structure within the repository.&lt;/p&gt;
&lt;img src=&quot;http://aosabook.org/images/git/merge-history.png&quot;/&gt; Figure 6.4: Diagram showing merge history lineage
&lt;p&gt;Let us first use an example to show how this can be problematic when maintaining multiple branches of a work. Then we will look at a scenario to show its limitations.&lt;/p&gt;
&lt;p&gt;When working on a &quot;branch&quot; in Subversion at the typical root &lt;code&gt;branches/branch-name&lt;/code&gt;, we are working on directory subtree adjacent to the &lt;code&gt;trunk&lt;/code&gt; (typically where the live or &lt;em&gt;master&lt;/em&gt; equivalent code resides within). Let us say this branch is to represent parallel development of the &lt;code&gt;trunk&lt;/code&gt; tree.&lt;/p&gt;
&lt;p&gt;For example, we might be rewriting a codebase to use a different database. Part of the way through our rewrite we wish to merge in upstream changes from another branch subtree (not trunk). We merge in these changes, manually if necessary, and proceed with our rewrite. Later that day we finish our database vendor migration code changes on our &lt;code&gt;branches/branch-name&lt;/code&gt; branch and merge our changes into &lt;code&gt;trunk&lt;/code&gt;. The problem with the way linear-history VCSs like Subversion handle this is that there is no way to know that the changesets from the other branch are now contained within the trunk.&lt;/p&gt;
&lt;p&gt;DAG-based merge history VCSs, like Git, handle this case reasonably well. Assuming the other branch does not contain commits that have not been merged into our database vendor migration branch (say, &lt;code&gt;db-migration&lt;/code&gt; in our Git repository), we can determine—from the commit object parent relationships—that a commit on the &lt;code&gt;db-migration&lt;/code&gt; branch contained the &lt;em&gt;tip&lt;/em&gt; (or HEAD) of the other upstream branch. Note that a commit object can have zero or more (bounded by only the abilities of the merger) parents. Therefore the merge commit on the &lt;code&gt;db-migration&lt;/code&gt; branch &lt;em&gt;knows&lt;/em&gt; it merged in the current HEAD of the current branch and the HEAD of the other upstream branch through the SHA hashes of the parents. The same is true of the merge commit in the &lt;code&gt;master&lt;/code&gt; (the &lt;code&gt;trunk&lt;/code&gt; equivalent in Git).&lt;/p&gt;
&lt;p&gt;A question that is hard to answer definitively using DAG-based (and linear-based) merge histories is which commits are contained within each branch. For example, in the above scenario we assumed we merged into each branch all the changes from both branches. This may not be the case.&lt;/p&gt;
&lt;p&gt;For simpler cases Git has the ability to cherry pick commits from other branches in to the current branch, assuming the commit can cleanly be applied to the branch.&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;40.162259615385&quot;&gt;&lt;h2&gt;6.9. What's Next?&lt;/h2&gt;
&lt;p&gt;As mentioned previously, Git core as we know it today is based on a toolkit design philosophy from the Unix world, which is very handy for scripting but less useful for embedding inside or linking with longer running applications or services. While there is Git support in many popular Integrated Development Environments today, adding this support and maintaining it has been more challenging than integrating support for VCSs that provide an easy-to-link-and-share library for multiple platforms.&lt;/p&gt;
&lt;p&gt;To combat this, Shawn Pearce (of Google's Open Source Programs Office) spearheaded an effort to create a linkable Git library with more permissive licensing that did not inhibit use of the library. This was called &lt;a href=&quot;https://github.com/libgit2/libgit2&quot;&gt;libgit2&lt;/a&gt;. It did not find much traction until a student named Vincent Marti chose it for his Google Summer of Code project last year. Since then Vincent and Github engineers have continued contributing to the libgit2 project, and created bindings for numerous other popular languages such as Ruby, Python, PHP, .NET languages, Lua, and Objective-C.&lt;/p&gt;
&lt;p&gt;Shawn Pearce also started a BSD-licensed pure Java library called &lt;a href=&quot;https://github.com/eclipse/jgit&quot;&gt;JGit&lt;/a&gt; that supports many common operations on Git repositories. It is now maintained by the Eclipse Foundation for use in the Eclipse IDE Git integration.&lt;/p&gt;
&lt;p&gt;Other interesting and experimental open source endeavours outside of the Git core project are a number of implementations using alternative datastores as backends for the Git object database such as:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/spearce/jgit_cassandra&quot;&gt;jgit_cassandra&lt;/a&gt;, which offers Git object persistence using Apache Cassandra, a hybrid datastore using Dynamo-style distribution with BigTable column family data model semantics.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/spearce/jgit_hbase&quot;&gt;jgit_hbase&lt;/a&gt;, which enables read and write operations to Git objects stored in HBase, a distributed key-value datastore.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/libgit2/libgit2-backends&quot;&gt;libgit2-backends&lt;/a&gt;, which emerged from the libgit2 effort to create Git object database backends for multiple popular datastores such as Memcached, Redis, SQLite, and MySQL.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;All of these open source projects are maintained independently of the Git core project.&lt;/p&gt;
&lt;p&gt;As you can see, today there are a large number of ways to use the Git format. The face of Git is no longer just the toolkit command line interface of the Git Core project; rather it is the repository format and protocol to share between repositories.&lt;/p&gt;
&lt;p&gt;As of this writing, most of these projects, according to their developers, have not reached a stable release, so work in the area still needs to be done but the future of Git appears bright.&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;30&quot;&gt;&lt;h2&gt;6.10. Lessons Learned&lt;/h2&gt;
&lt;p&gt;In software, every design decision is ultimately a trade-off. As a power user of Git for version control and as someone who has developed software around the Git object database model, I have a deep fondness for Git in its present form. Therefore, these lessons learned are more of a reflection of common recurring complaints about Git that are due to design decisions and focus of the Git core developers.&lt;/p&gt;
&lt;p&gt;One of the most common complaints by developers and managers who evaluate Git has been the lack of IDE integration on par with other VCS tools. The toolkit design of Git has made this more challenging than integrating other modern VCS tools into IDEs and related tools.&lt;/p&gt;
&lt;p&gt;Earlier in Git's history some of the commands were implemented as shell scripts. These shell script command implementations made Git less portable, especially to Windows. I am sure the Git core developers did not lose sleep over this fact, but it has negatively impacted adoption of Git in larger organizations due to portability issues that were prevalent in the early days of Git's development. Today a project named Git for Windows has been started by volunteers to ensure new versions of Git are ported to Windows in a timely manner.&lt;/p&gt;
&lt;p&gt;An indirect consequence of designing Git around a toolkit design with a lot of plumbing commands is that new users get lost quickly; from confusion about all the available subcommands to not being able to understand error messages because a low level plumbing task failed, there are many places for new users to go astray. This has made adopting Git harder for some developer teams.&lt;/p&gt;
&lt;p&gt;Even with these complaints about Git, I am excited about the possibilities of future development on the Git Core project, plus all the related open source projects that have been launched from it.&lt;/p&gt;
&lt;/section&gt;</description>
<pubDate>Fri, 26 Oct 2018 14:39:34 +0000</pubDate>
<dc:creator>wheresvic1</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://aosabook.org/en/git.html</dc:identifier>
</item>
<item>
<title>Heavy multitaskers have reduced memory</title>
<link>https://news.stanford.edu/2018/10/25/decade-data-reveals-heavy-multitaskers-reduced-memory-psychologist-says/</link>
<guid isPermaLink="true" >https://news.stanford.edu/2018/10/25/decade-data-reveals-heavy-multitaskers-reduced-memory-psychologist-says/</guid>
<description>&lt;p&gt;The smartphones that are now ubiquitous were just gaining popularity when &lt;a href=&quot;https://profiles.stanford.edu/anthony-wagner&quot;&gt;Anthony Wagner&lt;/a&gt; became interested in the research of his Stanford colleague, Clifford Nass, on the effects of media multitasking and attention. Though Wagner, a professor of psychology at Stanford University and director of the &lt;a href=&quot;https://memorylab.stanford.edu/&quot;&gt;Stanford Memory Laboratory&lt;/a&gt;, wasn’t convinced by the early data, he recommended some cognitive tests for Nass to use in subsequent experiments. More than 11 years later, Wagner was intrigued enough to write a review on past research findings, published in &lt;em&gt;Proceedings of the National Academy of Sciences&lt;/em&gt;, and contribute some of his own.&lt;/p&gt;
&lt;div class=&quot;pull-right pull-right-wide&quot; readability=&quot;8&quot;&gt;&lt;img class=&quot;wp-image-24130 size-full img-responsive&quot; src=&quot;https://news-media.stanford.edu/wp-content/uploads/2018/10/24142623/multitasking.jpg&quot; alt=&quot;Woman holding phone in one hand, tablet in another, at a laptop computer.&quot; srcset=&quot;https://news-media.stanford.edu/wp-content/uploads/2018/10/24142623/multitasking.jpg 1500w, https://news-media.stanford.edu/wp-content/uploads/2018/10/24142623/multitasking-555x370.jpg 555w, https://news-media.stanford.edu/wp-content/uploads/2018/10/24142623/multitasking-795x530.jpg 795w, https://news-media.stanford.edu/wp-content/uploads/2018/10/24142623/multitasking-960x640.jpg 960w, https://news-media.stanford.edu/wp-content/uploads/2018/10/24142623/multitasking-705x470.jpg 705w, https://news-media.stanford.edu/wp-content/uploads/2018/10/24142623/multitasking-345x230.jpg 345w, https://news-media.stanford.edu/wp-content/uploads/2018/10/24142623/multitasking-375x250.jpg 375w&quot; sizes=&quot;(max-width: 1500px) 100vw, 1500px&quot;/&gt;&lt;p class=&quot;media-caption&quot;&gt;A decade’s worth of research has shown that people who frequently use many types of media at once performed significantly worse on simple memory tasks. &lt;span class=&quot;media-attrib&quot;&gt;(Image credit: Getty Images)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The &lt;a href=&quot;http://www.pnas.org/content/early/2018/09/26/1611612115.short&quot;&gt;paper&lt;/a&gt;, co-authored with neuroscientist Melina Uncapher of the University of California, San Francisco, summarizes a decade’s worth of research on the relationship between media multitasking and various domains of cognition, including working memory and attention. In doing that analysis, Wagner noticed a trend emerging in the literature: People who frequently use many types of media at once, or heavy media multitaskers, performed significantly worse on simple memory tasks.&lt;/p&gt;
&lt;p&gt;Wagner spoke with &lt;em&gt;Stanford Report&lt;/em&gt; to explain the findings from his review on media multitasking and cognition, and discuss why it’s premature to determine the impact of these results.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How did you become interested in researching media multitasking and memory?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I was brought into a collaboration with Cliff Nass, a Stanford faculty member in communication who passed away a few years ago, and his master’s student, Eyal Ophir. They had this question: With the explosion of media technologies that has resulted in there being multiple simultaneous channels available that we can switch between, how might this relate to human cognition? Eyal and Cliff would come chat with me about their early findings and – I have to say – I thought it was complete hooey. I was skeptical. But, after a few experiments, the data were increasingly pointing to a link between media multitasking and attention. Their findings struck me as potentially important given the way we’re living as humans in this attention economy. Years later, as a memory scientist my interests continued to grow. Given that attention and cognitive control are so fundamental for memory, I wanted to see if there was a relationship between media multitasking and memory.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How do you define media multitasking, and can you give hypothetical examples of people that would be “heavy” and “light” media multitaskers?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Well, we don’t multitask. We task switch. The word “multitasking” implies that you can do two or more things at once, but in reality our brains only allow us to do one thing at a time and we have to switch back and forth.&lt;/p&gt;
&lt;p&gt;Heavy media multitaskers have many media channels open at once and they switch between them. A heavy media multitasker might be writing an academic paper on their laptop, occasionally checking the Stanford basketball game on TV, responding to texts and Facebook messages, then getting back to writing – but then an email pops up and they check it. A light media multitasker would only be writing the academic paper or may only switch between a couple of media. They may turn off Wi-Fi, put away their phone or change their settings so they only get notified every hour. Those are some extreme examples, but they provide a sense of how people differ in their media use. Moreover, because our media landscape has continued to accelerate and change, those who are considered a heavy or light media multitasker today may not be the same as those a decade ago.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How do scientists assess someone’s memory?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There are many forms of memory, and thus many ways of probing memory in the lab. For working memory – the ability to keep a limited amount of information active in mind – we often use simple short-delay memory tasks. For example, in one test we show a set of oriented blue rectangles, then remove them from the screen and ask the subject to retain that information in mind. Then we’ll show them another set of rectangles and ask if any have changed orientation. To measure memory capacity, we do this task with a different number of rectangles and determine how performance changes with increasing memory loads. To measure the ability to filter out distraction, sometimes we add distractors, like red rectangles that the subjects are told to ignore.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What overall trends did you notice when you were looking through the literature to write this review?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In about half of the studies, the heavy media multitaskers are significantly underperforming on tasks of working memory and sustained attention. The other half are null results; there’s no significant difference. It strikes me as pretty clear that there is a negative relationship between media multitasking and memory performance – that high media multitasking is associated with poor performance on cognitive memory tasks. There’s not a single published paper that shows a significant positive relationship between working memory capacity and multitasking.&lt;/p&gt;
&lt;p&gt;In the review we noticed an interesting potential emerging story. One possibility is that reduced working memory occurs in heavy media multitaskers because they have a higher probability of experiencing lapses of attention. When demands are low, they underperform. But, when the task demands are high, such as when the working memory tasks are harder, there’s no difference between the heavy and light media multitaskers. This observation, combined with the negative relationship between multitasking and performance on sustained attention tasks, prompted us to start looking at intrasubject variability and moment-to-moment fluctuations in a person’s ability to use task goals to direct attention in a sustained manner.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How do these findings affect how people should engage with media, or should they at all?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I would never tell anyone that the data unambiguously show that media multitasking causes a change in attention and memory. That would be premature. It’s too early to definitively determine cause and effect.&lt;/p&gt;
&lt;p&gt;One could choose to be cautious, however. Many of us have felt like our technology and media are controlling us – that email chime or text tone demands our attention. But we can control that by adopting approaches that minimize habitual multitasking; we can decide to be more thoughtful and reflective users of media.&lt;/p&gt;
&lt;p&gt;That said, multitasking isn’t efficient. We know there are costs of task switching. So that might be an argument to do less media multitasking – at least when working on a project that matters academically or professionally. If you’re multitasking while doing something significant, like an academic paper or work project, you’ll be slower to complete it and you might be less successful.&lt;/p&gt;
</description>
<pubDate>Fri, 26 Oct 2018 14:05:37 +0000</pubDate>
<dc:creator>cabinguy</dc:creator>
<og:type>article</og:type>
<og:title>Heavy multitaskers have reduced memory</og:title>
<og:description>People who frequently engage with multiple types of media at once performed worse on simple memory tasks, according to the last decade of research. However, it’s still too soon to determine cause and effect, says psychology Professor Anthony Wagner.</og:description>
<og:url>https://news.stanford.edu/2018/10/25/decade-data-reveals-heavy-multitaskers-reduced-memory-psychologist-says/</og:url>
<og:image>https://news-media.stanford.edu/wp-content/uploads/2018/10/24142623/multitasking.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://news.stanford.edu/2018/10/25/decade-data-reveals-heavy-multitaskers-reduced-memory-psychologist-says/</dc:identifier>
</item>
<item>
<title>A Dark Consensus About Screens and Kids Begins to Emerge in Silicon Valley</title>
<link>https://www.nytimes.com/2018/10/26/style/phones-children-silicon-valley.html</link>
<guid isPermaLink="true" >https://www.nytimes.com/2018/10/26/style/phones-children-silicon-valley.html</guid>
<description>&lt;div class=&quot;css-18sbwfn StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot;&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;SAN FRANCISCO — The people who are closest to a thing are often the most wary of it. Technologists know how phones really work, and many have decided &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.nytimes.com/2018/10/26/style/silicon-valley-nannies.html?module=inline&quot; title=&quot;&quot;&gt;they don’t want their own children anywhere near them&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;A wariness that has been slowly brewing is turning into a regionwide consensus: The benefits of screens as a learning tool are overblown, and the risks for addiction and stunting development seem high. The debate in Silicon Valley now is about how much exposure to phones is O.K.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“Doing no screen time is almost easier than doing a little,” said Kristin Stecher, a former social computing researcher married to a Facebook engineer. “If my kids do get it at all, they just want it more.”&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Ms. Stecher, 37, and her husband, Rushabh Doshi, researched screen time and came to a simple conclusion: they wanted almost none of it in their house. Their daughters, ages 5 and 3, have no screen time “budget,” no regular hours they are allowed to be on screens. The only time a screen can be used is during the travel portion of a long car ride (the four-hour drive to Tahoe counts) or during a plane trip.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;&lt;div class=&quot;css-18sbwfn StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot;&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Recently she has softened this approach. Every Friday evening the family watches one movie.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;There is a looming issue Ms. Stecher sees in the future: Her husband, who is 39, loves video games and thinks they can be educational and entertaining. She does not.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“We’ll cross that when we come to it,” said Ms. Stecher, who is due soon with a boy.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Some of the people who built video programs are now horrified by how many places a child can now watch a video.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Asked about limiting screen time for children, Hunter Walk, a venture capitalist who for years directed product for YouTube at Google, sent a photo of a potty training toilet with an iPad attached and wrote: “Hashtag ‘products we didn’t buy.’”&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Athena Chavarria, who worked as an executive assistant at Facebook and is now at Mark Zuckerberg’s philanthropic arm, the Chan Zuckerberg Initiative, said: “I am convinced the devil lives in our phones and is wreaking havoc on our children.”&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Ms. Chavarria did not let her children have cellphones until high school, and even now bans phone use in the car and severely limits it at home.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-18sbwfn StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot;&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;She said she lives by the mantra that the last child in the class to get a phone wins. Her daughter did not get a phone until she started ninth grade.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“Other parents are like, ‘Aren’t you worried you don’t know where your kids are when you can’t find them?’” Ms. Chavarria said. “And I’m like, ‘No, I do not need to know where my kids are every second of the day.’”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-1ur45q4 e5d2tgl3&quot;&gt;
&lt;div class=&quot;css-1ukm2ij e5d2tgl0&quot;&gt;More about kids and screens&lt;/div&gt;
&lt;div class=&quot;css-15g2oxy e5d2tgl2&quot;&gt;
&lt;div class=&quot;css-1s7gosn ezm5mny6&quot;&gt;
&lt;div class=&quot;css-i9gxme ezm5mny4&quot;&gt;
&lt;div class=&quot;css-oyr3ly ezm5mny2&quot;&gt;Silicon Valley Nannies Are Phone Police for Kids&lt;/div&gt;
&lt;div class=&quot;css-14shocx ezm5mny3&quot;&gt;Child care contracts now demand that nannies hide phones, tablets, computers and TVs from their charges.&lt;/div&gt;
&lt;time class=&quot;css-tnzxe9 eqgapgq0&quot; datetime=&quot;2018-10-26&quot;&gt;Oct. 26, 2018&lt;/time&gt;&lt;/div&gt;
&lt;div class=&quot;css-wexrmg ezm5mny0&quot;&gt;&lt;img src=&quot;https://static01.nyt.com/images/2018/10/26/style/26SiliconNannies-1/26SiliconNannies-threeByTwoSmallAt2X.jpg&quot; class=&quot;css-1g9kf2h ezm5mny1&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;css-1s7gosn ezm5mny6&quot;&gt;
&lt;div class=&quot;css-i9gxme ezm5mny4&quot;&gt;
&lt;div class=&quot;css-oyr3ly ezm5mny2&quot;&gt;The Digital Gap Between Rich and Poor Kids Is Not What We Expected&lt;/div&gt;
&lt;div class=&quot;css-14shocx ezm5mny3&quot;&gt;America’s public schools are still touting devices with screens — even offering digital-only preschools. The rich are banning screens from class altogether.&lt;/div&gt;
&lt;time class=&quot;css-tnzxe9 eqgapgq0&quot; datetime=&quot;2018-10-26&quot;&gt;Oct. 26, 2018&lt;/time&gt;&lt;/div&gt;
&lt;div class=&quot;css-wexrmg ezm5mny0&quot;&gt;&lt;img src=&quot;https://static01.nyt.com/images/2018/10/26/style/26DigitalDivide-PROMO/26DigitalDivide-PROMO-threeByTwoSmallAt2X.jpg&quot; class=&quot;css-1g9kf2h ezm5mny1&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;css-18sbwfn StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot;&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;For longtime tech leaders, watching how the tools they built affect their children has felt like a reckoning on their life and work.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Among those is Chris Anderson, the former editor of Wired and now the chief executive of a robotics and drone company. He is also the founder of &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://geekdad.com/&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;GeekDad.com&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“On the scale between candy and crack cocaine, it’s closer to crack cocaine,” Mr. Anderson said of screens.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-18sbwfn StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot;&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Technologists building these products and writers observing the tech revolution were naïve, he said.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“We thought we could control it,” Mr. Anderson said. “And this is beyond our power to control. This is going straight to the pleasure centers of the developing brain. This is beyond our capacity as regular parents to understand.”&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;He has five children and 12 tech rules. They include: no phones until the summer before high school, no screens in bedrooms, network-level content blocking, no social media until age 13, no iPads at all and screen time schedules enforced by Google Wifi that he controls from his phone. Bad behavior? The child goes offline for 24 hours.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“I didn’t know what we were doing to their brains until I started to observe the symptoms and the consequences,” Mr. Anderson said.&lt;/p&gt;
&lt;div class=&quot;css-zgakxe e1vv25i80&quot;&gt;&lt;span class=&quot;css-1ly73wi e1afaoz0&quot;&gt;Image&lt;/span&gt;&lt;img alt=&quot;&quot; class=&quot;css-1m50asq&quot; src=&quot;https://static01.nyt.com/images/2018/10/11/style/oakImage-1539293138789/oakImage-1539293138789-articleLarge.png?quality=75&amp;amp;auto=webp&amp;amp;disable=upscale&quot; srcset=&quot;https://static01.nyt.com/images/2018/10/11/style/oakImage-1539293138789/oakImage-1539293138789-articleLarge.png?quality=90&amp;amp;auto=webp 600w,https://static01.nyt.com/images/2018/10/11/style/oakImage-1539293138789/oakImage-1539293138789-jumbo.png?quality=90&amp;amp;auto=webp 576w,https://static01.nyt.com/images/2018/10/11/style/oakImage-1539293138789/oakImage-1539293138789-superJumbo.png?quality=90&amp;amp;auto=webp 1080w&quot; sizes=&quot;50vw&quot; itemprop=&quot;url&quot; itemid=&quot;https://static01.nyt.com/images/2018/10/11/style/oakImage-1539293138789/oakImage-1539293138789-articleLarge.png?quality=75&amp;amp;auto=webp&amp;amp;disable=upscale&quot;/&gt;&lt;/div&gt;
&lt;span class=&quot;css-1wp6toh e1olku6u0&quot;&gt;A view of the Anderson family schedule.&lt;/span&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“This is scar tissue talking. We’ve made every mistake in the book, and I think we got it wrong with some of my kids,” Mr. Anderson said. “We glimpsed into the chasm of addiction, and there were some lost years, which we feel bad about.”&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-18sbwfn StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot;&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;His children attended private elementary school, where he saw the administration introduce iPads and smart whiteboards, only to “descend into chaos and then pull back from it all.”&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;This idea that Silicon Valley parents are wary about tech is not new. The godfathers of tech expressed these concerns years ago, and concern has been loudest from the top.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Tim Cook, the C.E.O. of Apple, &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.theguardian.com/technology/2018/jan/19/tim-cook-i-dont-want-my-nephew-on-a-social-network&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;said earlier this year&lt;/a&gt; that he would not let his nephew join social networks. Bill Gates banned cellphones until his children were teenagers, and Melinda Gates wrote that &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.washingtonpost.com/news/parenting/wp/2017/08/24/melinda-gates-i-spent-my-career-in-technology-i-wasnt-prepared-for-its-effect-on-my-kids/?utm_term=.a462ac452c51&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;she wished they had waited even longer&lt;/a&gt;. Steve Jobs &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.nytimes.com/2014/09/11/fashion/steve-jobs-apple-was-a-low-tech-parent.html?module=inline&quot; title=&quot;&quot;&gt;would not let his young children near iPads&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;But in the last year, a fleet of high-profile Silicon Valley defectors have been sounding alarms in increasingly dire terms about what these gadgets do to the human brain. Suddenly rank-and-file Silicon Valley workers are obsessed. No-tech homes are cropping up across the region. &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.nytimes.com/2018/10/26/style/silicon-valley-nannies.html?module=inline&quot; title=&quot;&quot;&gt;Nannies are being asked to sign no-phone&lt;/a&gt; &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.nytimes.com/2018/10/26/style/silicon-valley-nannies.html?module=inline&quot; title=&quot;&quot;&gt;contracts&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Those who have exposed their children to screens try to talk them out of addiction by explaining how the tech works.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;John Lilly, a Silicon Valley-based venture capitalist with Greylock Partners and the former C.E.O. of Mozilla, said he tries to help his 13-year-old son understand that he is being manipulated by those who built the technology.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-18sbwfn StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot;&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“I try to tell him somebody wrote code to make you feel this way — I’m trying to help him understand how things are made, the values that are going into things and what people are doing to create that feeling,” Mr. Lilly said. “And he’s like, ‘I just want to spend my 20 bucks to get my Fortnite skins.’”&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;And there are those in tech who disagree that screens are dangerous. Jason Toff, 32, who ran the video platform Vine and now works for Google, lets his 3-year-old play on an iPad, which he believes is no better or worse than a book. This opinion is unpopular enough with his fellow tech workers that he feels there is now “a stigma.”&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“One reaction I got just yesterday was, ‘Doesn’t it worry you that all the major tech execs are limiting screen time?’” Mr. Toff said. “And I was like, ‘Maybe it should, but I guess I’ve always been skeptical of norms.’ People are just scared of the unknown.”&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“It’s contrarian,” Mr. Toff said. “But I feel like I’m speaking for a lot of parents that are afraid of speaking out loud for fear of judgment.”&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;He said he thinks back to his own childhood growing up watching a lot of TV. “I think I turned out O.K.,” Mr. Toff said.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Other Silicon Valley parents say there are ways to make some limited screen time slightly less toxic.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;css-18sbwfn StoryBodyCompanionColumn&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot;&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;Renee DiResta, a security researcher on the board of the Center for Humane Tech, won’t allow passive screen time, but will allow short amounts of time on challenging games.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;She wants her 2- and 4-year-old children to learn how to code young, so she embraces their awareness of gadgets. But she distinguishes between these types of screen use. Playing a building game is allowed, but watching a YouTube video is not, unless it is as a family.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;And Frank Barbieri, a San Francisco-based executive at the start-up PebblePost that tracks online activity to send direct mail advertising, tries to limit his 5-year-old daughter’s screen time to Italian language content.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“We have friends who are screen abolitionists, and we have friends who are screen liberalists,” Mr. Barbieri said.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;He had read studies on how learning a second language at a young age is good for the developing mind, so his daughter watches Italian-language movies and TV shows.&lt;/p&gt;
&lt;p class=&quot;css-1xl4flh e2kc3sl0&quot;&gt;“For us, honestly, me and my wife were like, ‘Where would we like to visit?’” Mr. Barbieri said.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;
</description>
<pubDate>Fri, 26 Oct 2018 14:05:18 +0000</pubDate>
<dc:creator>extraterra</dc:creator>
<og:url>https://www.nytimes.com/2018/10/26/style/phones-children-silicon-valley.html</og:url>
<og:type>article</og:type>
<og:title>A Dark Consensus About Screens and Kids Begins to Emerge in Silicon Valley</og:title>
<og:image>https://static01.nyt.com/images/2018/10/28/fashion/26NoTech-1/26NoTech-1-facebookJumbo-v2.jpg</og:image>
<og:description>“I am convinced the devil lives in our phones.”</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.nytimes.com/2018/10/26/style/phones-children-silicon-valley.html</dc:identifier>
</item>
<item>
<title>Generating custom photo-realistic faces using AI</title>
<link>https://blog.insightdatascience.com/generating-custom-photo-realistic-faces-using-ai-d170b1b59255</link>
<guid isPermaLink="true" >https://blog.insightdatascience.com/generating-custom-photo-realistic-faces-using-ai-d170b1b59255</guid>
<description>&lt;p name=&quot;604f&quot; id=&quot;604f&quot; class=&quot;graf graf--p graf--leading&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;All the code and online demo are available at the&lt;/em&gt; &lt;a href=&quot;https://github.com/SummitKwan/transparent_latent_gan&quot; data-href=&quot;https://github.com/SummitKwan/transparent_latent_gan&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;project page&lt;/em&gt;&lt;/a&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;h3 name=&quot;f1b3&quot; id=&quot;f1b3&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Teaching computers to draw photos according to descriptions&lt;/h3&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*lCAeDPpTkfvDqzZXiQoc1g.png&quot; data-width=&quot;705&quot; data-height=&quot;212&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*lCAeDPpTkfvDqzZXiQoc1g.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*lCAeDPpTkfvDqzZXiQoc1g.png&quot;/&gt;&lt;/div&gt;
Discriminative vs. generative tasks
&lt;p name=&quot;0f24&quot; id=&quot;0f24&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;Describing&lt;/em&gt; an image is easy for humans, and we are able to do it from a very young age. In machine learning, this task is a &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;discriminative&lt;/strong&gt; classification/regression problem, i.e. predicting feature labels from input images. Recent advancements in ML/AI techniques, especially deep learning models, are beginning to excel in these tasks, sometimes reaching or exceeding human performance, as is demonstrated in scenarios like visual object recognition (e.g. from AlexNet to ResNet on ImageNet classification) and object detection/segmentation (e.g. from RCNN to YOLO on COCO dataset), etc.&lt;/p&gt;
&lt;p name=&quot;b375&quot; id=&quot;b375&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;However, the other way around, g&lt;em class=&quot;markup--em markup--p-em&quot;&gt;enerating&lt;/em&gt; realistic images based on descriptions, is much harder, and takes years of graphic design training. In machine learning this is a &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;generative&lt;/strong&gt; task, which is also much more challenging than discriminative tasks, as a generative model has to produce much richer information (like a full image at some level of detail and variation) based on a smaller seed input.&lt;/p&gt;
&lt;p name=&quot;85ec&quot; id=&quot;85ec&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Despite the difficulty in creating such types of applications, &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;generative models&lt;/strong&gt; (with some control) can be extremely useful in many cases:&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li name=&quot;1d9e&quot; id=&quot;1d9e&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Content creation&lt;/strong&gt;: Imagine if an advertisement company could automatically generate attractive product images that match the content and style of the webpage where these images are inserted; a fashion designer could get inspiration by asking an algorithm to produce 20 examples of shoe designs that are related to “leisure”, “canvas”, “summer” and “passionate”; and a new game could allow players to create realistic avatars based simple descriptions.&lt;/li&gt;
&lt;li name=&quot;8d4c&quot; id=&quot;8d4c&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Content-aware smart editing&lt;/strong&gt;: We could allow a photographer to change the facial expression, amount of wrinkles and hair style of a profile photo with several clicks; and a Hollywood studio artist could transform the footage shot on a cloudy evening to look like it was shot on a sunny morning, with sunshine shedding light from the left side of the screen.&lt;/li&gt;
&lt;li name=&quot;8875&quot; id=&quot;8875&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Data augmentation&lt;/strong&gt;: An autonomous driving car company could synthesize realistic videos of a particular type of accident scenario to augment the training dataset; and a credit card company could synthesize data of a particular type of fraud data that is underrepresented in the dataset to improve their fraud detection system.&lt;/li&gt;
&lt;/ul&gt;&lt;p name=&quot;5032&quot; id=&quot;5032&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;In this post, we will describe our recent work called &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Transparent Latent-space GAN (TL-GAN)&lt;/strong&gt;, which extends current cutting edge models to provide a new interface. We are currently working on a paper, that will have more technical details.&lt;/p&gt;
&lt;h3 name=&quot;261d&quot; id=&quot;261d&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Overview of generative models&lt;/h3&gt;
&lt;p name=&quot;5d9b&quot; id=&quot;5d9b&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;The deep learning community is making rapid progress on generative models. Among them are three promising types of models: &lt;a href=&quot;https://arxiv.org/abs/1601.06759&quot; data-href=&quot;https://arxiv.org/abs/1601.06759&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;autoregressive models&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1312.6114&quot; data-href=&quot;https://arxiv.org/abs/1312.6114&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;variational autoencoders (VAE)&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/abs/1406.2661&quot; data-href=&quot;https://arxiv.org/abs/1406.2661&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;generative adversarial networks (GAN)&lt;/a&gt;, illustrated as the figure below. If you are interested in the details, please check out this awesome OpenAI blog &lt;a href=&quot;https://blog.openai.com/generative-models/&quot; data-href=&quot;https://blog.openai.com/generative-models/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*JFg3SRN0Uf-A7YWajQ6HOw.png&quot; data-width=&quot;1632&quot; data-height=&quot;509&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*JFg3SRN0Uf-A7YWajQ6HOw.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*JFg3SRN0Uf-A7YWajQ6HOw.png&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;Figure: comparison of generator networks. Image from&lt;/em&gt; &lt;a href=&quot;https://wiki.math.uwaterloo.ca/statwiki/index.php?title=STAT946F17/Conditional_Image_Generation_with_PixelCNN_Decoders&quot; data-href=&quot;https://wiki.math.uwaterloo.ca/statwiki/index.php?title=STAT946F17/Conditional_Image_Generation_with_PixelCNN_Decoders&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;University of Waterloo STAT946F17 course&lt;/em&gt;&lt;/a&gt;
&lt;p name=&quot;ef16&quot; id=&quot;ef16&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;So far, GANs produce images of the &lt;a href=&quot;https://blog.openai.com/generative-models/&quot; data-href=&quot;https://blog.openai.com/generative-models/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;highest quality&lt;/a&gt; (photo-realistic and diverse, with convincing details in high resolution). Look at the stunning images generated by Nvidia’s recent work with pg-GAN (&lt;a href=&quot;https://github.com/tkarras/progressive_growing_of_gans&quot; data-href=&quot;https://github.com/tkarras/progressive_growing_of_gans&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;progressively-growing GAN&lt;/a&gt;). For this reason, this blog post will focus on GAN models.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*F1HFYYfHgkjaEcGPrW5FDw.png&quot; data-width=&quot;700&quot; data-height=&quot;350&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*F1HFYYfHgkjaEcGPrW5FDw.png&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;Figure: synthetic images generated by&lt;/em&gt; &lt;a href=&quot;https://github.com/tkarras/progressive_growing_of_gans&quot; data-href=&quot;https://github.com/tkarras/progressive_growing_of_gans&quot; class=&quot;markup--anchor markup--figure-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;pg-GAN&lt;/em&gt;&lt;/a&gt; &lt;em class=&quot;markup--em markup--figure-em&quot;&gt;from Nvidia. None of these images are real!&lt;/em&gt;
&lt;h3 name=&quot;1ab2&quot; id=&quot;1ab2&quot; class=&quot;graf graf--h3 graf-after--figure&quot;&gt;Controlling the output of GAN models&lt;/h3&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*lzQ-xViUbiJSA0Ytu9YTQQ.png&quot; data-width=&quot;899&quot; data-height=&quot;430&quot; data-is-featured=&quot;true&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*lzQ-xViUbiJSA0Ytu9YTQQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*lzQ-xViUbiJSA0Ytu9YTQQ.png&quot;/&gt;&lt;/div&gt;
Figure: random image generation vs. controlled image generation
&lt;p name=&quot;09f4&quot; id=&quot;09f4&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The &lt;a href=&quot;https://arxiv.org/abs/1406.2661&quot; data-href=&quot;https://arxiv.org/abs/1406.2661&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;original version of GAN&lt;/a&gt; and many popular successors (like &lt;a href=&quot;https://arxiv.org/abs/1511.06434&quot; data-href=&quot;https://arxiv.org/abs/1511.06434&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;DC-GAN&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/abs/1710.10196&quot; data-href=&quot;https://arxiv.org/abs/1710.10196&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;pg-GAN&lt;/a&gt;) are &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;unsupervised&lt;/strong&gt; learning models. After training, the generator network takes random noise as input and produces a photo-realistic image that is barely distinguishable from the training dataset. However, we cannot further control the features of the generated images. In most applications (such as the scenarios described in the first section), users would like to generate samples with &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;custom features&lt;/strong&gt; (like age, hair color, facial expression, etc), and ideally, tuning each feature continuously.&lt;/p&gt;
&lt;p name=&quot;af59&quot; id=&quot;af59&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;To achieve controlled synthesis, numerous variants of GAN have been created. They can be roughly divided into two types: style-transfer networks and conditional generators.&lt;/p&gt;
&lt;h4 name=&quot;a761&quot; id=&quot;a761&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;Style-transfer networks&lt;/h4&gt;
&lt;p name=&quot;986e&quot; id=&quot;986e&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;Style-transfer networks, represented by &lt;a href=&quot;https://junyanz.github.io/CycleGAN/&quot; data-href=&quot;https://junyanz.github.io/CycleGAN/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;CycleGAN&lt;/a&gt; and &lt;a href=&quot;https://phillipi.github.io/pix2pix/&quot; data-href=&quot;https://phillipi.github.io/pix2pix/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;pix2pix&lt;/a&gt;, are models trained to translate image from one domain to another (e.g. from horse to zebra, from sketch to colored images). As a result, we cannot continuously tune one feature gradually between two discrete states (eg. add slightly more beard on the face). Also, one network is dedicated to one type of transfer, so it requires ten different neural networks to tune 10 features.&lt;/p&gt;
&lt;h4 name=&quot;1595&quot; id=&quot;1595&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;Conditional generators&lt;/h4&gt;
&lt;p name=&quot;211a&quot; id=&quot;211a&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;Conditional generators, represented by &lt;a href=&quot;https://arxiv.org/abs/1411.1784&quot; data-href=&quot;https://arxiv.org/abs/1411.1784&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;conditional GAN&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1610.09585&quot; data-href=&quot;https://arxiv.org/abs/1610.09585&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;AC-GAN&lt;/a&gt;, and &lt;a href=&quot;https://github.com/hanzhanggit/StackGAN&quot; data-href=&quot;https://github.com/hanzhanggit/StackGAN&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Stack-GAN&lt;/a&gt;, are models that jointly learn images with feature labels during training time, enabling the image generation to be conditioned on custom features. Therefore, when you want to add new tunable features to the generation process, you have to retrain the whole GAN model, which takes an enormous amount of computing resources and time (e.g. days to weeks on a single K80 GPU with the perfect set of hyper-parameters). In addition, you have to rely on a single dataset that contains all the custom feature labels to perform the training, instead of leveraging different labels from multiple datasets.&lt;/p&gt;
&lt;p name=&quot;3131&quot; id=&quot;3131&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Our model, which we call &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Transparent Latent-space GAN&lt;/strong&gt; (TL-GAN), addresses these problems of existing methods by approaching controlled generation task from a novel angle. It offers users the ability to &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;gradually tune one or multiple features using a single network&lt;/strong&gt;. Besides, adding new tunable features can be done very efficiently in less than one hour.&lt;/p&gt;
&lt;h3 name=&quot;29f4&quot; id=&quot;29f4&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;TL-GAN: a novel and efficient approach for controlled synthesis and editing&lt;/h3&gt;
&lt;h4 name=&quot;c19d&quot; id=&quot;c19d&quot; class=&quot;graf graf--h4 graf-after--h3&quot;&gt;Making the mysterious latent space transparent&lt;/h4&gt;
&lt;p name=&quot;77c6&quot; id=&quot;77c6&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;We will leverage NVIDIA’s &lt;a href=&quot;https://arxiv.org/abs/1710.10196&quot; data-href=&quot;https://arxiv.org/abs/1710.10196&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;pg-GAN&lt;/a&gt;, the model that generates the photo-realistic high resolution face images as shown in the the previous section. All the features of a generated 1024px*1024px image are determined solely by a 512-dimentional noise vector in the latent space (as a low-dimensional representation of the image content). Therefore, &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;if we could understand what the latent space represents (i.e., making it transparent), we could completely control the generation process&lt;/strong&gt;.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*ChmB0i6NQGCpCyseOULISw.png&quot; data-width=&quot;700&quot; data-height=&quot;375&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*ChmB0i6NQGCpCyseOULISw.png&quot;/&gt;&lt;/div&gt;
Motivation of TL-GAN: understand latent space to control generation process
&lt;p name=&quot;75d2&quot; id=&quot;75d2&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;By experimenting with the pre-trained pg-GAN, I found that the latent space actually has two good properties:&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li name=&quot;230d&quot; id=&quot;230d&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;It is well populated, meaning that most points in the space will generate reasonable images&lt;/li&gt;
&lt;li name=&quot;fbe8&quot; id=&quot;fbe8&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;It is quite continuous, meaning the interpolation between two points in the latent space usually leads to a smooth transition of corresponding images.&lt;/li&gt;
&lt;/ul&gt;&lt;p name=&quot;7074&quot; id=&quot;7074&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;With this in mind, my intuition was that it is possible to find directions in the latent space that are predictive of features that we care about (eg. male-female). If so, we can use unit vectors of these directions as the feature axes for controlling the generation process (more male-like or more female-like).&lt;/p&gt;
&lt;h4 name=&quot;3ed5&quot; id=&quot;3ed5&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;Approach: uncovering the feature axes&lt;/h4&gt;
&lt;p name=&quot;2e36&quot; id=&quot;2e36&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;To find these feature axes in the latent space, we will &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;build a link between a latent vector &lt;em class=&quot;markup--em markup--p-em&quot;&gt;z&lt;/em&gt; and the feature labels &lt;em class=&quot;markup--em markup--p-em&quot;&gt;y&lt;/em&gt;&lt;/strong&gt; through supervised learning methods trained on paired &lt;em class=&quot;markup--em markup--p-em&quot;&gt;(z,y)&lt;/em&gt; data. Now the problem becomes how to get such paired data, since existing datasets only contain images &lt;em class=&quot;markup--em markup--p-em&quot;&gt;x&lt;/em&gt; and their corresponding feature labels &lt;em class=&quot;markup--em markup--p-em&quot;&gt;y&lt;/em&gt;.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*-VLgZiCEkwPROEtZaWxb4w.png&quot; data-width=&quot;960&quot; data-height=&quot;540&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*-VLgZiCEkwPROEtZaWxb4w.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*-VLgZiCEkwPROEtZaWxb4w.png&quot;/&gt;&lt;/div&gt;
Figure: approaches to link latent vector z with feature label y
&lt;p name=&quot;2738&quot; id=&quot;2738&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Potential approaches:&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote name=&quot;1467&quot; id=&quot;1467&quot; class=&quot;graf graf--blockquote graf-after--p&quot; readability=&quot;9&quot;&gt;
&lt;p&gt;One potential approach is to compute the corresponding latent vectors &lt;em class=&quot;markup--em markup--blockquote-em&quot;&gt;z&lt;/em&gt; of images &lt;em class=&quot;markup--em markup--blockquote-em&quot;&gt;x_real&lt;/em&gt; from an existing dataset labeled with features of interest &lt;em class=&quot;markup--em markup--blockquote-em&quot;&gt;y_real&lt;/em&gt;. However, the GAN network does not offer an easy way to compute &lt;em class=&quot;markup--em markup--blockquote-em&quot;&gt;z_encode=G^(−1)(x_real)&lt;/em&gt;, making this idea difficult to implement.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote name=&quot;cb9e&quot; id=&quot;cb9e&quot; class=&quot;graf graf--blockquote graf-after--blockquote&quot; readability=&quot;8&quot;&gt;
&lt;p&gt;A second potential approach is to generate synthetic images &lt;em class=&quot;markup--em markup--blockquote-em&quot;&gt;x_gen&lt;/em&gt; using GAN from a random latent vector &lt;em class=&quot;markup--em markup--blockquote-em&quot;&gt;z&lt;/em&gt; as &lt;em class=&quot;markup--em markup--blockquote-em&quot;&gt;x_gen=G(z)&lt;/em&gt;. The problem here is that the synthetic images are unlabeled, and we can not easily leverage the available labeled dataset.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p name=&quot;baf7&quot; id=&quot;baf7&quot; class=&quot;graf graf--p graf-after--blockquote&quot;&gt;To solve this problem, the key innovation of our TL-GAN model is to &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;train a separate feature extractor&lt;/strong&gt; (a classifier for discrete label or regressor for continuous label) model &lt;em class=&quot;markup--em markup--p-em&quot;&gt;y=F(x)&lt;/em&gt; using an existing labelled image dataset &lt;em class=&quot;markup--em markup--p-em&quot;&gt;(x_real, y_real)&lt;/em&gt;, and then couple the trained GAN generator G with the feature extractor network F. Once this is done, we can predict the feature labels &lt;em class=&quot;markup--em markup--p-em&quot;&gt;y_pred&lt;/em&gt; of the synthetic images &lt;em class=&quot;markup--em markup--p-em&quot;&gt;x_gen&lt;/em&gt; using the trained feature extractor network, and thus establish the link between z and y through synthetic images as &lt;em class=&quot;markup--em markup--p-em&quot;&gt;x_gen=G(z)&lt;/em&gt; and &lt;em class=&quot;markup--em markup--p-em&quot;&gt;y_pred=F(x_gen)&lt;/em&gt;.&lt;/p&gt;
&lt;p name=&quot;8665&quot; id=&quot;8665&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Now that we have the paired latent vector and features, we can train a regressor model &lt;em class=&quot;markup--em markup--p-em&quot;&gt;y=A(z)&lt;/em&gt; to uncover all feature axes for controlling the image generation process.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*l6ug8cLOpd_TtxxgWlnw1Q.png&quot; data-width=&quot;1180&quot; data-height=&quot;479&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*l6ug8cLOpd_TtxxgWlnw1Q.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*l6ug8cLOpd_TtxxgWlnw1Q.png&quot;/&gt;&lt;/div&gt;
Figure: architecture of our TL-GAN model
&lt;p name=&quot;bdf0&quot; id=&quot;bdf0&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;The above figure shows the architecture of the TL-GAN model, which contains five steps:&lt;/p&gt;
&lt;ol class=&quot;postList&quot;&gt;&lt;li name=&quot;2da9&quot; id=&quot;2da9&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Learning the distribution:&lt;/strong&gt; Choose a well-trained GAN model and take the generator network. I chose the well-trained pg-GAN (provided by Nvidia), which offers the best face generation quality.&lt;/li&gt;
&lt;li name=&quot;ca62&quot; id=&quot;ca62&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Classification:&lt;/strong&gt; Choose a pre-trained feature extractor model (could be a convolutional neural network or other computer vision models), or train your own feature extractor network using a labelled dataset. I trained a simple convolutional neural network on the CelebA dataset (which contains 30,000+ face images with 40 labels each).&lt;/li&gt;
&lt;li name=&quot;e5da&quot; id=&quot;e5da&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Generation:&lt;/strong&gt; Generate a number of random latent vectors, pass through the trained GAN generator to produce synthetic images, then use a trained feature extractor to produce features for every image.&lt;/li&gt;
&lt;li name=&quot;f2cc&quot; id=&quot;f2cc&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Correlation:&lt;/strong&gt; Use a Generalized Linear Model (GLM) to perform regression between latent vectors and features. &lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;The regression slope becomes the feature axes.&lt;/strong&gt;&lt;/li&gt;
&lt;li name=&quot;6a3b&quot; id=&quot;6a3b&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;&lt;strong class=&quot;markup--strong markup--li-strong&quot;&gt;Exploration:&lt;/strong&gt; Start from one latent vector, move it along one or more feature axes, and examine how this affects the generated images.&lt;/li&gt;
&lt;/ol&gt;&lt;p name=&quot;19d4&quot; id=&quot;19d4&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;I made this process very efficient; once we have a pre-trained GAN model, identifying feature axes &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;only takes one hour&lt;/strong&gt; on a single-GPU machine. This is achieved by several engineering tricks including transfer learning, downsampling image size, pre-cache synthetic images, etc.&lt;/p&gt;
&lt;h3 name=&quot;7c7b&quot; id=&quot;7c7b&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Results&lt;/h3&gt;
&lt;p name=&quot;7304&quot; id=&quot;7304&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Let us see how this simple idea works.&lt;/p&gt;
&lt;h4 name=&quot;5994&quot; id=&quot;5994&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;Moving latent vector along feature axes&lt;/h4&gt;
&lt;p name=&quot;2be7&quot; id=&quot;2be7&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;First, I tested whether the discovered feature axes can be used to control the corresponding feature of the generated image. To do this, I generated a random vector &lt;em class=&quot;markup--em markup--p-em&quot;&gt;z_0&lt;/em&gt; in the latent space of GAN, and produced a synthetic image &lt;em class=&quot;markup--em markup--p-em&quot;&gt;x_0&lt;/em&gt; by passing it through the generator network &lt;em class=&quot;markup--em markup--p-em&quot;&gt;x_0=G(z_0)&lt;/em&gt;. Next, I moved the latent vector along one feature axis &lt;em class=&quot;markup--em markup--p-em&quot;&gt;u&lt;/em&gt; (a unit vector in the latent space, say, corresponding to the gender of the face) by distance &lt;em class=&quot;markup--em markup--p-em&quot;&gt;λ&lt;/em&gt;, to a new location &lt;em class=&quot;markup--em markup--p-em&quot;&gt;x_1=x_0+λu&lt;/em&gt;, and generated a new image &lt;em class=&quot;markup--em markup--p-em&quot;&gt;x1=G(z1)&lt;/em&gt;. Ideally, the corresponding feature of the new image would be modified toward the expected direction.&lt;/p&gt;
&lt;p name=&quot;f52d&quot; id=&quot;f52d&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;The results of moving the latent space vector along several example feature axes (gender, age, etc) are shown below. This works surprisingly well! We can &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;smoothly morph&lt;/strong&gt; the image between male ←→ female, young←→old, etc.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*ow2h4j_v8jdnIJZzLcktlQ.png&quot; data-width=&quot;1176&quot; data-height=&quot;869&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*ow2h4j_v8jdnIJZzLcktlQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*ow2h4j_v8jdnIJZzLcktlQ.png&quot;/&gt;&lt;/div&gt;
Figure: Initial result of moving latent vector along example entangled feature axes
&lt;h4 name=&quot;431c&quot; id=&quot;431c&quot; class=&quot;graf graf--h4 graf-after--figure&quot;&gt;Disentangling correlated feature axes&lt;/h4&gt;
&lt;p name=&quot;0068&quot; id=&quot;0068&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;The examples above shows a shortcoming of the initial method, i.e., the &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;entangled feature axes&lt;/strong&gt;. For instance, when I intended to reduce the amount of beard, the generated faces became more female-like, which is not what a user would expect. This problem is due to the fact that the gender feature and the beard feature are by nature &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;correlated&lt;/strong&gt;, modifying one leading to the corollary change of the other. Similar things happened to other features like hairline and wavy hair. As is illustrated in the figure below, the original beard axis is not perpendicular to the gender axis in the latent space.&lt;/p&gt;
&lt;p name=&quot;1501&quot; id=&quot;1501&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;To solve this problem, I used straight-forward linear algebra tricks. Specifically, I projected the beard axis to a new direction that is orthogonal to the gender axis, which effectively removes their correlation, and thus could potentially disentangle these two features of generated face images.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*0RPW3Rvqy_uDAoUpVzhfOA.png&quot; data-width=&quot;660&quot; data-height=&quot;390&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*0RPW3Rvqy_uDAoUpVzhfOA.png&quot;/&gt;&lt;/div&gt;
Figure: disentangle correlated feature axes using linear algebra tricks
&lt;p name=&quot;b367&quot; id=&quot;b367&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;I applied this feature disentangling method to the same example face. This time I used gender axis and age axis as reference features, projected all other feature axes so that they became orthogonal to gender and age, and examined the generated images when the latent vector moved along the newly generated feature axes (shown in the figure below). As we expected, the features including hairline, wavy hair and beard now modify the gender of face anymore, which behaves as expected.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*3OlC0FsszJlkL9uYDV5haQ.png&quot; data-width=&quot;1176&quot; data-height=&quot;869&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*3OlC0FsszJlkL9uYDV5haQ.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*3OlC0FsszJlkL9uYDV5haQ.png&quot;/&gt;&lt;/div&gt;
Figure: Improved result of moving latent vector along example disentangled feature axes
&lt;h4 name=&quot;46d1&quot; id=&quot;46d1&quot; class=&quot;graf graf--h4 graf-after--figure&quot;&gt;Flexible interactive editing&lt;/h4&gt;
&lt;p name=&quot;a451&quot; id=&quot;a451&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;To see how flexibly our TL-GAN model can control the image generation process, I built an interactive GUI to explore the effect of gradually tuning feature values along different feature axes, as shown below:&lt;/p&gt;

Video: interactive editing of face images using TL-GAN
&lt;p name=&quot;86a0&quot; id=&quot;86a0&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Again, the model works surprisingly well when I use the features axes to control the generated images!&lt;/p&gt;
&lt;h3 name=&quot;c7eb&quot; id=&quot;c7eb&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Recap&lt;/h3&gt;
&lt;p name=&quot;a855&quot; id=&quot;a855&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;This project provides a novel method to control the generation process of an unsupervised generative model like GAN (generative adversarial network). Using an already well-trained GAN generator (Nvidia’s pg-GAN), I made its latent space transparent by discovering the meaningful feature axes in it. When a vector moves along a feature axis in the latent space, the corresponding image morphs over this feature, which enables controllable synthesis and edit.&lt;/p&gt;
&lt;p name=&quot;656c&quot; id=&quot;656c&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This method has clear advantages:&lt;/p&gt;
&lt;ol class=&quot;postList&quot;&gt;&lt;li name=&quot;d361&quot; id=&quot;d361&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;Efficiency: To add a new feature tuner for the generator, you do not need to re-train the GAN model, thus it only takes &amp;lt;1h to add 40 feature tuners with our method.&lt;/li&gt;
&lt;li name=&quot;6efb&quot; id=&quot;6efb&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;Flexibility: You can use any feature extractor trained on any dataset to add more feature tuners to the well-trained GAN.&lt;/li&gt;
&lt;/ol&gt;&lt;h4 name=&quot;b380&quot; id=&quot;b380&quot; class=&quot;graf graf--h4 graf-after--li&quot;&gt;A word about ethics&lt;/h4&gt;
&lt;p name=&quot;5fb8&quot; id=&quot;5fb8&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;This work allows us to have fine grained control over image generation, but it still relies heavily on the features of our dataset. Training on photos of celebrities of Hollywood means that our model will be very good at generating photos of a predominantly white and attractive demographic. In turn, this would lead to users only being able to generate these specific kind of faces which are only representative of a small subset of people. If we were to deploy this as an application, we would want to make sure that we have augmented our initial dataset to take into account the diversity of our users.&lt;/p&gt;
&lt;p name=&quot;5609&quot; id=&quot;5609&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;In addition, while this tool could be a huge creative help, we should ask ourselves how this model could be used for nefarious purposes. If we can generate realistic looking faces of any type, what are the implications for our ability to trust in what we see. These sort of issues are important to tackle today. As we have seen with the recent applications of &lt;a href=&quot;https://en.wikipedia.org/wiki/Deepfake&quot; data-href=&quot;https://en.wikipedia.org/wiki/Deepfake&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;deepfakes&lt;/a&gt;, the capability of AI methods is increasing at a fast pace, so it is vital for us to start conversations about how to best deploy them.&lt;/p&gt;
&lt;h3 name=&quot;1472&quot; id=&quot;1472&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Online demo and code&lt;/h3&gt;
&lt;p name=&quot;1cc4&quot; id=&quot;1cc4&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;All the code and online demo of this work are available at &lt;a href=&quot;https://github.com/SummitKwan/transparent_latent_gan&quot; data-href=&quot;https://github.com/SummitKwan/transparent_latent_gan&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;this Github project page&lt;/a&gt;.&lt;/p&gt;
&lt;h4 name=&quot;08b7&quot; id=&quot;08b7&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;If you want to play with the model in your web-browser&lt;/h4&gt;
&lt;p name=&quot;27e4&quot; id=&quot;27e4&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;You do not have to download any code, model or data. Just follow the instructions on &lt;a href=&quot;https://github.com/SummitKwan/transparent_latent_gan#1-instructions-on-the-online-demo&quot; data-href=&quot;https://github.com/SummitKwan/transparent_latent_gan#1-instructions-on-the-online-demo&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;this section&lt;/a&gt; of the GitHub README page. You can tweak faces in your web-browser as is demonstrated in the the above Video.&lt;/p&gt;
&lt;h4 name=&quot;58b3&quot; id=&quot;58b3&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;If you want to try my code&lt;/h4&gt;
&lt;p name=&quot;fb1e&quot; id=&quot;fb1e&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;Just follow the README page of the GitHub repository. The code is built on Anaconda Python 3.6 with Tensorflow and Keras.&lt;/p&gt;
&lt;h4 name=&quot;dcbd&quot; id=&quot;dcbd&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;If you want to contribute&lt;/h4&gt;
&lt;p name=&quot;a7c9&quot; id=&quot;a7c9&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;You are very welcome! Feel free to submit a Pull Request or file an issue on Github&lt;/p&gt;
&lt;h4 name=&quot;dab4&quot; id=&quot;dab4&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--h4-strong&quot;&gt;About me&lt;/strong&gt;&lt;/h4&gt;
&lt;p name=&quot;9bf0&quot; id=&quot;9bf0&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;I recently finished PhD in computational and cognitive neuroscience from Brown University, with a concurrent master degree in computer science focusing on machine learning. In the past, I studied how neurons in the brain collectively process information to achieve high-level functions like visual perception. I am enthusiastic about the algorithmic approach to understand, mimic, and implement intelligence, as well as apply them to solve challenging real-world problems. I am actively looking for ML/AI researcher positions in the tech industry.&lt;/p&gt;
&lt;h4 name=&quot;af04&quot; id=&quot;af04&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;Acknowledgements&lt;/h4&gt;
&lt;p name=&quot;0388&quot; id=&quot;0388&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;This work was done as the project for the &lt;a href=&quot;https://www.insightdata.ai/&quot; data-href=&quot;https://www.insightdata.ai/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Insight AI fellow program&lt;/a&gt; over three weeks. I give my thanks to the program director &lt;a href=&quot;https://twitter.com/EmmanuelAmeisen&quot; data-href=&quot;https://twitter.com/EmmanuelAmeisen&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Emmanuel Ameisen&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/mrubash1&quot; data-href=&quot;https://twitter.com/mrubash1&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Matt Rubashkin&lt;/a&gt; for their general guidance, especially &lt;a href=&quot;https://twitter.com/EmmanuelAmeisen&quot; data-href=&quot;https://twitter.com/EmmanuelAmeisen&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Emmanuel Ameisen&lt;/a&gt; for his suggestions and editing work on this blog post. I also give my thanks to all Insight staff for providing a great learning environment, and to Insight AI fellows from whom I learned a lot. Special thanks to &lt;a href=&quot;https://www.linkedin.com/in/ruobing-xia/&quot; data-href=&quot;https://www.linkedin.com/in/ruobing-xia/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Ruobing Xia&lt;/a&gt; for providing numerous inspirations as I decided on project directions, and for the enormous help structuring and editing this blog post.&lt;/p&gt;
&lt;p name=&quot;f25d&quot; id=&quot;f25d&quot; class=&quot;graf graf--p graf-after--p graf--trailing&quot;&gt;This passage was originally posted on my personal &lt;a href=&quot;http://summit.metaneuro.com/index.php/2018/10/10/draw-as-you-can-tell-controlled-image-synthesis-an/&quot; data-href=&quot;http://summit.metaneuro.com/index.php/2018/10/10/draw-as-you-can-tell-controlled-image-synthesis-an/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;blog&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>Fri, 26 Oct 2018 13:26:19 +0000</pubDate>
<dc:creator>homarp</dc:creator>
<og:title>Generating custom photo-realistic faces using AI – Insight Data</og:title>
<og:url>https://blog.insightdatascience.com/generating-custom-photo-realistic-faces-using-ai-d170b1b59255</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*lzQ-xViUbiJSA0Ytu9YTQQ.png</og:image>
<og:description>Controlled image synthesis and editing using a novel TL-GAN model</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.insightdatascience.com/generating-custom-photo-realistic-faces-using-ai-d170b1b59255?gi=e16ceb3fdcfc</dc:identifier>
</item>
</channel>
</rss>