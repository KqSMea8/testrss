<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Statistics, Fast and Slow</title>
<link>http://timharford.com/2018/05/statistics-fast-and-slow/</link>
<guid isPermaLink="true" >http://timharford.com/2018/05/statistics-fast-and-slow/</guid>
<description>&lt;a href=&quot;http://timharford.com/articles/undercovereconomist/&quot; title=&quot;Undercover Economist&quot;&gt;&lt;img class=&quot;article-perm&quot; src=&quot;http://timharford.com/wp-content/themes/timharford-v4/img//icon-ue.png&quot; width=&quot;36&quot; height=&quot;36&quot; alt=&quot;Undercover Economist&quot; title=&quot;Undercover Economist&quot;/&gt;&lt;/a&gt;&lt;h2&gt;Statistics, Fast and Slow&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Written for and first published in the &lt;a href=&quot;https://www.ft.com/content/6fac587c-3e3c-11e8-b9f9-de94fa33a81e&quot;&gt;Financial Times&lt;/a&gt; on 13 April 2018.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;One way to understand China is to look at the statistics. Real income per person has increased nearly tenfold since 1990. Since the early 1980s, the number of extremely poor people in China has fallen by more than three-quarters of a billion people, more than half the population of the country. China consumed more cement in a recent three-year period than the US used in the entire 20th century.&lt;/p&gt;
&lt;p&gt;Even on paper, it is the most dramatic explosion of economic activity in human history. Seeing it with your own eyes is another experience entirely.&lt;/p&gt;
&lt;p&gt;Nothing in the statistics truly prepared me for a journey across Guangdong, the southern province of China that has been at the forefront of this growth. Start at Hong Kong — the ultimate high-rise city — and walk into its mainland twin, Shenzhen. Then in the shadow of the Ping An skyscraper, which dwarfs the Empire State building, catch a bullet train across the province.&lt;/p&gt;
&lt;p&gt;Where London might have a single big block like Trellick Tower, Shenzhen will have a cluster of a dozen identical monoliths, crammed with apartments. Next to that cluster, another dozen of a different design. Then another, and another. Here and there, in the distance across the haze, would be a Manhattan-esque cluster of skyscrapers. The towers marched on and on, all the way — or so it seemed to me — to the city of Guangzhou: 45 minutes or so of high-speed travel through what seemed an infinite vista of concrete.&lt;/p&gt;
&lt;p&gt;That night, tucked into bed in the picture-postcard landscape of Yangshuo, I couldn’t sleep. The endless tower blocks scrolled through my mind. What if we had lost our six-year-old son in the middle of Guangdong? So many people. So much concrete.&lt;/p&gt;
&lt;p&gt;There was nothing in this experience to contradict the economic data; in fact, the two perspectives on China’s growth were perfectly complementary. But they felt very different. To borrow the terminology made famous by Daniel Kahneman’s book &lt;em&gt;Thinking, Fast and Slow&lt;/em&gt;, (&lt;a href=&quot;https://amzn.to/2EF0tQB&quot;&gt;UK&lt;/a&gt;) (&lt;a href=&quot;https://amzn.to/2v6fhrK&quot;&gt;US&lt;/a&gt;) the statistics spoke to my mental “system 2” — the deliberate, effortful processing of logical or mathematical information. The train journey tapped into “system 1”, a swift and automatic forming of impressions, making of comparisons and recognising of dangers. This was statistics, fast and slow.&lt;/p&gt;
&lt;p&gt;Some will be tempted to dismiss the statistics as irrelevant book-learning, and declare that only personal experience matters. There is certainly something in that, especially when a situation is fast-moving or contains soft, hard-to-quantify details. As the Nobel laureate economist Friedrich Hayek remarked, the “knowledge of the particular circumstances of time and place” is important and often neglected.&lt;/p&gt;
&lt;p&gt;HR McMaster — who before he was US president Donald Trump’s former national security adviser, was a counterinsurgency pioneer in Iraq — had a similar concern. He once told me the army used to wrongly believe that “situational understanding could be delivered on a computer screen”. It would be convenient if that was possible, but as Gen McMaster and his colleagues learnt the hard way, it is not. Sometimes you have to be there to understand.&lt;/p&gt;
&lt;p&gt;But while there is a lot to be said for the rich and vivid lessons of personal experience, they have an obvious limitation: we cannot be everywhere and see everything. And what we do see may be as unrepresentative as the sloppiest of surveys. My trip to China took in tourist spots and high-speed rail links. As a result, I formed an indelible impression of a very particular slice of China.&lt;/p&gt;
&lt;p&gt;The skew in our personal experience affects us when at home almost as much as when travelling. We are surprised when an election goes against us: all our friends agreed with us, so why did the nation vote otherwise? Newspapers and television carry tales of lottery wins and fairytale romances, terrorist atrocities or gruesome assaults by strangers. None of these stories reflect everyday life; all of them are viscerally memorable and seem to take place in our living rooms.&lt;/p&gt;
&lt;p&gt;And there are more subtle ways in which personal experience can mislead. For example, most of us who ride on London buses will attest that they are packed. Yet the average occupancy of a London bus is just 17 people. How so? Most people witness the full buses — that is why they are full — while empty buses are observed only by their drivers.&lt;/p&gt;
&lt;p&gt;It is not quite fair to say that our fast-and-loose “system 1” impression is a lie. It really is true that most people travel on busy buses. But if we want to understand emissions per passenger, we need a statistical perspective.&lt;/p&gt;
&lt;p&gt;A new book by the late Hans Rosling and his family, &lt;em&gt;Factfulness&lt;/em&gt; (&lt;a href=&quot;https://amzn.to/2qvmex1&quot;&gt;UK&lt;/a&gt;) (&lt;a href=&quot;https://amzn.to/2GV8iHN&quot;&gt;US&lt;/a&gt;), advocates the merits of understanding the world both through the data and through personal experience — not of news stories or tourist traps, but of the everyday lives being lived all over the world. “Numbers will never tell the full story of what life on Earth is all about,” wrote Rosling, despite being the world’s most famous statistical guru. But the story they do tell matters. In statistics, as elsewhere, hard logic and personal impressions work best when they reinforce and correct each other.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;My book “Messy: How To Be Creative and Resilient in a Tidy-Minded World” is now available in paperback both in the &lt;a href=&quot;http://amzn.to/2Gasthh&quot;&gt;US&lt;/a&gt; and the &lt;a href=&quot;http://amzn.to/2FthX3H&quot;&gt;UK&lt;/a&gt; – or through your local bookshop.&lt;/em&gt;&lt;/p&gt;

&lt;div class=&quot;sharedaddy sd-sharing-enabled&quot;&gt;
&lt;div class=&quot;robots-nocontent sd-block sd-social sd-social-icon sd-sharing&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Share this:&lt;/h3&gt;

&lt;/div&gt;
&lt;/div&gt;

</description>
<pubDate>Wed, 16 May 2018 20:38:46 +0000</pubDate>
<dc:creator>khc</dc:creator>
<og:type>article</og:type>
<og:title>Statistics, Fast and Slow</og:title>
<og:url>http://timharford.com/2018/05/statistics-fast-and-slow/</og:url>
<og:description>Written for and first published in the Financial Times on 13 April 2018. One way to understand China is to look at the statistics. Real income per person has increased nearly tenfold since 1990. Si…</og:description>
<og:image>https://s0.wp.com/i/blank.jpg</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://timharford.com/2018/05/statistics-fast-and-slow/</dc:identifier>
</item>
<item>
<title>Senate votes to reinstate net neutrality</title>
<link>https://www.theverge.com/2018/5/16/17357592/net-neutrality-senate-vote-cra-reinstate-fcc-rules</link>
<guid isPermaLink="true" >https://www.theverge.com/2018/5/16/17357592/net-neutrality-senate-vote-cra-reinstate-fcc-rules</guid>
<description>&lt;p id=&quot;15Fqhn&quot;&gt;The Senate has voted to save net neutrality, but don’t get your hopes up: there’s still a long, likely impossible journey ahead if the policy is to be saved in the immediate future.&lt;/p&gt;
&lt;p id=&quot;U729tV&quot;&gt;In a 52–47 vote today, senators voted to overturn the Federal Communication Commission’s Restoring Internet Freedom Order, which took net neutrality rules off the books. They were able to do so &lt;a href=&quot;https://www.theverge.com/2018/5/3/17314404/net-neutrality-cra-congressional-review-act-markey-senate&quot;&gt;using the Congressional Review Act, or CRA&lt;/a&gt;, which allows Congress to reverse recent decisions by government agencies. Republican control of Congress means that such a measure wouldn’t normally even make it up for a vote; but the CRA allows senators to force a vote by obtaining 30 signatures.&lt;/p&gt;
&lt;p id=&quot;gaB3BR&quot;&gt;All 49 Democrats voted in favor, as well as Republican Senators Susan Collins, of Maine; John Kennedy, of Louisiana; and Lisa Murkowski, of Alaska.&lt;/p&gt;
&lt;div class=&quot;c-float-right&quot;&gt;
&lt;aside id=&quot;vPlfiO&quot;&gt;&lt;q&gt;The House needs a full majority to force a vote; then there’s Trump&lt;/q&gt;&lt;/aside&gt;&lt;/div&gt;
&lt;p id=&quot;nrk6sD&quot;&gt;While advocates have argued that this is a step toward reinstating net neutrality, it’s really a long-shot attempt that seems to be meant more to get the issue back on voters’ minds — and to force politicians to take a position ahead of what’s expected to be a tumultuous midterm election.&lt;/p&gt;
&lt;p id=&quot;XR2gWL&quot;&gt;In order for net neutrality to actually be reinstated, two more things have to happen. First, the House has to use the CRA to overturn the policy as well. That’s even harder. Instead of 30 signatures, net neutrality supporters have to collect signatures from a full majority of House members. Even if they get every single Democrat on board — and they don’t have that yet — they’d still need the support of 22 Republicans. And finally, if that happened and they all voted to reverse the policy, it’d still have to get signed by President Trump, who is not a fan of the policy.&lt;/p&gt;
&lt;p id=&quot;pn0wQd&quot;&gt;While it’s obviously an uphill battle, net neutrality advocates seem to be holding out hope that they could actually get through the House, too. There’s a degree of bipartisan agreement that something needs to be done on net neutrality. And with midterms coming up, representatives in challenging districts may be more inclined to support the popular, consumer-friendly policy. As for Trump, well, you never know exactly how he’s going to wake up each day, or so the argument goes.&lt;/p&gt;
&lt;p id=&quot;cJkDhk&quot;&gt;In reality, this is more about setting up whatever comes next for net neutrality, likely a few years down the line. The general consensus at this point is that net neutrality is now out of the FCC’s hands, and that Congress will have to act to reinstate some of its outgoing rules. It’s not at all clear how soon that’ll happen, but forcing Congress to take a vote helps to clarify the playing field and make sure it’s something legislators are thinking about.&lt;/p&gt;
</description>
<pubDate>Wed, 16 May 2018 20:06:03 +0000</pubDate>
<dc:creator>kposehn</dc:creator>
<og:description>Next stop, the House</og:description>
<og:image>https://cdn.vox-cdn.com/thumbor/P2hEoHE1iBY_6bGnCX4bnQRAHTI=/0x648:5184x3362/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/10845751/951573798.jpg.jpg</og:image>
<og:title>Senate votes to reinstate net neutrality — but it has a long way to go</og:title>
<og:type>article</og:type>
<og:url>https://www.theverge.com/2018/5/16/17357592/net-neutrality-senate-vote-cra-reinstate-fcc-rules</og:url>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.theverge.com/2018/5/16/17357592/net-neutrality-senate-vote-cra-reinstate-fcc-rules</dc:identifier>
</item>
<item>
<title>The Entire Economy Is MoviePass Now</title>
<link>https://www.nytimes.com/2018/05/16/technology/moviepass-economy-startups.html</link>
<guid isPermaLink="true" >https://www.nytimes.com/2018/05/16/technology/moviepass-economy-startups.html</guid>
<description>&lt;p class=&quot;css-1cy1v93 e2kc3sl0&quot;&gt;Perhaps the buzziest money-loser of the year is MoviePass, which has upended the film industry by essentially giving away millions of free movie tickets. Until recently, MoviePass members could pay $9.95 for a monthly subscription that allowed them to watch up to one movie per day in theaters, with MoviePass paying the face value of the ticket on a preloaded debit card. Since the average cost of a movie ticket in the United States is around $9, going to just two movies per month resulted in a good deal for the customer, and a loss for the company. (MoviePass has started &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.theverge.com/2018/4/27/17291242/moviepass-unlimited-movie-deal-repeat-viewings-theater-blackouts&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;placing more restrictions&lt;/a&gt; on which films its customers can see, perhaps in an effort to trim costs.)&lt;/p&gt;
&lt;p class=&quot;css-1cy1v93 e2kc3sl0&quot;&gt;MoviePass’s business model — which &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://slate.com/business/2018/05/moviepass-appears-to-be-running-very-low-on-money.html&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;Slate described&lt;/a&gt; as “creatively lighting money aflame in order to subsidize the movie-going habits of some 3 million customers” — has turbocharged its growth. And the company maintains that it can make money by striking revenue-sharing deals with theater chains, or charging movie studios to advertise inside its app.&lt;/p&gt;
&lt;p class=&quot;css-1cy1v93 e2kc3sl0&quot;&gt;But investors aren’t convinced. Shares of MoviePass’s parent company, Helios and Matheson Analytics, have fallen more than 90 percent since October, and the company recently reported that it has been burning through its cash reserves, spending an average of $21.7 million per month with just $15.5 million left in the bank at the end of April. On Tuesday, Helios reported that MoviePass lost $98.3 million in the first quarter, despite adding more than a million net subscribers.&lt;/p&gt;
&lt;p class=&quot;css-1cy1v93 e2kc3sl0&quot;&gt;Mitch Lowe, the chief executive of MoviePass, told me in a phone interview this week that the company’s financial troubles have been exaggerated. The company has access to a $300 million equity line of credit that will keep it solvent, he said, and blamed the company’s competitors, such as large theater chains, for sowing the seeds of doubt.&lt;/p&gt;
&lt;p class=&quot;css-1cy1v93 e2kc3sl0&quot;&gt;“They smell blood in the water, so they’re spreading rumors and hypotheses,” he said.&lt;/p&gt;
&lt;p class=&quot;css-1cy1v93 e2kc3sl0&quot;&gt;Ultimately, companies like MoviePass illustrate the perilous tightrope many growing businesses must walk. Spend too little on acquiring new customers and drawing business away from your competitors, and you won’t make it off the ground. Give too many freebies away, and you risk running out of cash before you’re big enough to cash in.&lt;/p&gt;
&lt;p class=&quot;css-1cy1v93 e2kc3sl0&quot;&gt;“Pricing can be strategic,” said Kara Nortman, a partner at Upfront Ventures, which invests in technology companies. “If you can attract a lot of consumers to your product or service, it gives you a lot more power with incumbents who are limiting your growth.”&lt;/p&gt;
&lt;p class=&quot;css-1cy1v93 e2kc3sl0&quot;&gt;The king of money-losers, of course, is Amazon, which went years without turning a profit. Instead, it plowed billions of dollars back into its business, building out its e-commerce infrastructure and jump-starting side efforts like Amazon Web Services and Amazon Prime Video. Those years of investments paid off, and Amazon is now the second most valuable company in the world, with $1.6 billion in profit last quarter alone.&lt;/p&gt;
&lt;p class=&quot;css-1cy1v93 e2kc3sl0&quot;&gt;Not every company can repeat Amazon’s success. Just ask any of the dozens of “Uber for X” start-ups that raised millions of dollars to disrupt industries like laundry, parking and grocery delivery by offering cut-rate promotional deals, only to &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://www.nytimes.com/2016/03/24/technology/the-uber-model-it-turns-out-doesnt-translate.html&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;run out of capital&lt;/a&gt; before customers latched on. Or consider crash-and-burn cases like Beepi, a used car marketplace that blew through nearly $150 million in venture capital before &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://techcrunch.com/2016/12/07/used-car-marketplace-beepi-shuts-down-outside-of-ca-merges-with-stealth-fair-com/&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;shutting down in 2016&lt;/a&gt;. (Happily, not before &lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://splinternews.com/i-bought-a-car-from-the-uber-for-used-cars-start-up-1793845289&quot; title=&quot;&quot; target=&quot;_blank&quot;&gt;I bought a car through the service&lt;/a&gt; for thousands of dollars less than its market value. Thanks, venture capitalists!)&lt;/p&gt;
</description>
<pubDate>Wed, 16 May 2018 19:16:55 +0000</pubDate>
<dc:creator>jds375</dc:creator>
<og:url>https://www.nytimes.com/2018/05/16/technology/moviepass-economy-startups.html</og:url>
<og:type>article</og:type>
<og:title>The Entire Economy Is MoviePass Now. Enjoy It While You Can.</og:title>
<og:image>https://static01.nyt.com/images/2018/05/17/business/17Roose.print/merlin_138197655_676241b8-67e3-4499-b081-510bac0cfcca-facebookJumbo.jpg</og:image>
<og:description>Inspired by Silicon Valley’s hyper-growth, companies elsewhere are burning cash in hopes of being the next big thing.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.nytimes.com/2018/05/16/technology/moviepass-economy-startups.html</dc:identifier>
</item>
<item>
<title>HoweyCoins – An educational tool to alert investors to possible fraud</title>
<link>https://www.howeycoins.com/index.html</link>
<guid isPermaLink="true" >https://www.howeycoins.com/index.html</guid>
<description>&lt;h3&gt;INVESTMENT LADDER&lt;/h3&gt;
&lt;p class=&quot;lead mb-0&quot;&gt;Investors can purchase HoweyCoins with any major credit card, widely-circulated coin, or with TravExcoins, our exclusive e-commerce partner in the travel and luxury goods investment area. Investment Discounting Ladder:&lt;/p&gt;
&lt;p class=&quot;lead mb-0&quot;&gt;HoweyCoins platform stands as one of the largest cryptocurrency platforms ever built. Recent market surveys expect the luxury travel industry to set a world-record high of over $1.5 trillion this year. The vast majority of these business and vacation transactions require processing, centralized currency and, most importantly, nickel and dime fees that add up to literally billions. HoweyCoins utilize the latest crypto-technology to allow travelers to purchase all segments without these limitations, allowing HoweyCoin users to buy, sell, and trade in a frictionless environment – where they use HoweyCoins to purchase travel OR as a government-backed, freely tradable investment – or both!&lt;/p&gt;
</description>
<pubDate>Wed, 16 May 2018 18:44:23 +0000</pubDate>
<dc:creator>ChrisArchitect</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.howeycoins.com/index.html</dc:identifier>
</item>
<item>
<title>A pure JavaScript implementation of Git for Node and browsers</title>
<link>https://github.com/isomorphic-git/isomorphic-git</link>
<guid isPermaLink="true" >https://github.com/isomorphic-git/isomorphic-git</guid>
<description>&lt;h3&gt;README.md&lt;/h3&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://travis-ci.org/isomorphic-git/isomorphic-git&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/d5114a50b7a1a8be9295458ed4aa76e6172fb8c7/68747470733a2f2f7472617669732d63692e6f72672f69736f6d6f72706869632d6769742f69736f6d6f72706869632d6769742e7376673f6272616e63683d6d6173746572&quot; alt=&quot;Build Status&quot; data-canonical-src=&quot;https://travis-ci.org/isomorphic-git/isomorphic-git.svg?branch=master&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://codecov.io/gh/isomorphic-git/isomorphic-git&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/f2b20974450dda718f9fd28e0417fe95d6ba2106/68747470733a2f2f636f6465636f762e696f2f67682f69736f6d6f72706869632d6769742f69736f6d6f72706869632d6769742f6272616e63682f6d61737465722f67726170682f62616467652e737667&quot; alt=&quot;codecov&quot; data-canonical-src=&quot;https://codecov.io/gh/isomorphic-git/isomorphic-git/branch/master/graph/badge.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://david-dm.org/isomorphic-git/isomorphic-git&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/5a4179656cefb7f4b99b4867d3e774a8c7e82b21/68747470733a2f2f64617669642d646d2e6f72672f69736f6d6f72706869632d6769742f69736f6d6f72706869632d6769742f7374617475732e737667&quot; alt=&quot;dependencies&quot; data-canonical-src=&quot;https://david-dm.org/isomorphic-git/isomorphic-git/status.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://snyk.io/test/github/isomorphic-git/isomorphic-git&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/7a723bd92222f06489c7b9b7bb36b545c67e2694/68747470733a2f2f736e796b2e696f2f746573742f6769746875622f69736f6d6f72706869632d6769742f69736f6d6f72706869632d6769742f62616467652e737667&quot; alt=&quot;Known Vulnerabilities&quot; data-canonical-src=&quot;https://snyk.io/test/github/isomorphic-git/isomorphic-git/badge.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://app.fossa.io/projects/git%2Bgithub.com%2Fisomorphic-git%2Fisomorphic-git?ref=badge_shield&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/02a9794c081a800e8412a14d9d37e551d6447058/68747470733a2f2f6170702e666f7373612e696f2f6170692f70726f6a656374732f6769742532426769746875622e636f6d25324669736f6d6f72706869632d67697425324669736f6d6f72706869632d6769742e7376673f747970653d736869656c64&quot; alt=&quot;FOSSA Status&quot; data-canonical-src=&quot;https://app.fossa.io/api/projects/git%2Bgithub.com%2Fisomorphic-git%2Fisomorphic-git.svg?type=shield&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://gitter.im/isomorphic-git/Lobby&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/3e5db20c15e1adc5ce03d261238a2f930897c7cd/68747470733a2f2f6261646765732e6769747465722e696d2f69736f6d6f72706869632d6769742e706e67&quot; alt=&quot;Gitter chat&quot; data-canonical-src=&quot;https://badges.gitter.im/isomorphic-git.png&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/isomorphic-git/isomorphic-git#backers&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/08cd680b82360fb8b5b7cd160d7c0a187bef4a5a/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f69736f6d6f72706869632d6769742f6261636b6572732f62616467652e737667&quot; alt=&quot;Backers on Open Collective&quot; data-canonical-src=&quot;https://opencollective.com/isomorphic-git/backers/badge.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/isomorphic-git/isomorphic-git#sponsors&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/ac525642157e2c77cfdd552237744d883e16b4e8/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f69736f6d6f72706869632d6769742f73706f6e736f72732f62616467652e737667&quot; alt=&quot;Sponsors on Open Collective&quot; data-canonical-src=&quot;https://opencollective.com/isomorphic-git/sponsors/badge.svg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A pure JavaScript implementation of git for node and browsers!&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://saucelabs.com/u/_wmhilton&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/eaf24e6deb96ffac07566e476240daf71c8a3056/68747470733a2f2f6261646765732e6865726f6b756170702e636f6d2f62726f77736572733f676f6f676c656368726f6d653d2b36362666697265666f783d3630266d6963726f736f6674656467653d3137267361666172693d313126616e64726f69643d372e31266970686f6e653d31312e32&quot; alt=&quot;Sauce Labs Test Status (for master branch)&quot; data-canonical-src=&quot;https://badges.herokuapp.com/browsers?googlechrome=+66&amp;amp;firefox=60&amp;amp;microsoftedge=17&amp;amp;safari=11&amp;amp;android=7.1&amp;amp;iphone=11.2&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;isomorphic-git&lt;/code&gt; is a pure JavaScript implementation of git that works in node and browser environments (including WebWorkers and ServiceWorkers). This means it can be used to read and write to to git repositories, as well as fetch from and push to git remotes like Github.&lt;/p&gt;
&lt;p&gt;Isomorphic-git aims for 100% interoperability with the canonical git implementation. This means it does all its operations by modifying files in a &quot;.git&quot; directory just like the git you are used to. The included &lt;code&gt;isogit&lt;/code&gt; CLI can operate on git repositories on your desktop or server.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;isomorphic-git&lt;/code&gt; aims to be a complete solution with no assembly required. I've tried carefully to design the API so it is easy to use all the features, without paying a penalty in bundle size. By providing functionality as separate functions instead of an object oriented API, code bundlers like Webpack will only include the functionality your application actually uses. (Or at least that's the goal.)&lt;/p&gt;
&lt;p&gt;I am working on adding type definitions so you can enjoy static type-checking and intelligent code completion in editors like &lt;a href=&quot;https://codesandbox.io&quot; rel=&quot;nofollow&quot;&gt;CodeSandbox&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;The &quot;isomorphic&quot; in &lt;code&gt;isomorphic-git&lt;/code&gt; means it works equally well on the server or the browser. That's tricky to do since git uses the file system, and browsers don't have an &lt;code&gt;fs&lt;/code&gt; module. So rather than relying on the &lt;code&gt;fs&lt;/code&gt; module, &lt;code&gt;isomorphic-git&lt;/code&gt; is BYOFS (Bring Your Own File System). When creating a new Git object, you pass it the &lt;code&gt;fs&lt;/code&gt; module to use.&lt;/p&gt;
&lt;p&gt;If you're only using &lt;code&gt;isomorphic-git&lt;/code&gt; in Node, you can just use the native &lt;code&gt;fs&lt;/code&gt; module.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-js&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;isomorphic-git&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;);
&lt;span class=&quot;pl-k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;fs&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;require&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;fs&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;);
&lt;span class=&quot;pl-smi&quot;&gt;git&lt;/span&gt;.&lt;span class=&quot;pl-en&quot;&gt;listFiles&lt;/span&gt;({fs, dir&lt;span class=&quot;pl-k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;__dirname&lt;/span&gt;});
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you're writing code for the browser though, you'll need something that emulates the &lt;code&gt;fs&lt;/code&gt; API. At the time of writing, the most complete option is &lt;a href=&quot;https://github.com/jvilk/BrowserFS&quot;&gt;BrowserFS&lt;/a&gt;. It has a few more steps involved to set up than in Node, as seen below:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-text-html-basic&quot;&gt;
&lt;pre&gt;
&amp;lt;&lt;span class=&quot;pl-ent&quot;&gt;script&lt;/span&gt; &lt;span class=&quot;pl-e&quot;&gt;src&lt;/span&gt;=&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;https://unpkg.com/browserfs&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span class=&quot;pl-ent&quot;&gt;script&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span class=&quot;pl-ent&quot;&gt;script&lt;/span&gt; &lt;span class=&quot;pl-e&quot;&gt;src&lt;/span&gt;=&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;https://unpkg.com/isomorphic-git&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span class=&quot;pl-ent&quot;&gt;script&lt;/span&gt;&amp;gt;
&amp;lt;&lt;span class=&quot;pl-ent&quot;&gt;script&lt;/span&gt;&amp;gt;
&lt;span class=&quot;pl-s1&quot;&gt;&lt;span class=&quot;pl-smi&quot;&gt;BrowserFS&lt;/span&gt;.&lt;span class=&quot;pl-en&quot;&gt;configure&lt;/span&gt;({ fs&lt;span class=&quot;pl-k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;IndexedDB&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;, options&lt;span class=&quot;pl-k&quot;&gt;:&lt;/span&gt; {} }, &lt;span class=&quot;pl-k&quot;&gt;function&lt;/span&gt; (&lt;span class=&quot;pl-smi&quot;&gt;err&lt;/span&gt;) {&lt;/span&gt;
&lt;span class=&quot;pl-s1&quot;&gt;  &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; (err) &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;console&lt;/span&gt;.&lt;span class=&quot;pl-c1&quot;&gt;log&lt;/span&gt;(err);&lt;/span&gt;
&lt;span class=&quot;pl-s1&quot;&gt;  &lt;span class=&quot;pl-c1&quot;&gt;window&lt;/span&gt;.&lt;span class=&quot;pl-smi&quot;&gt;fs&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;pl-smi&quot;&gt;BrowserFS&lt;/span&gt;.&lt;span class=&quot;pl-en&quot;&gt;BFSRequire&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;fs&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;);&lt;/span&gt;
&lt;span class=&quot;pl-s1&quot;&gt;  &lt;span class=&quot;pl-smi&quot;&gt;git&lt;/span&gt;.&lt;span class=&quot;pl-en&quot;&gt;listFiles&lt;/span&gt;({fs&lt;span class=&quot;pl-k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;window&lt;/span&gt;.&lt;span class=&quot;pl-smi&quot;&gt;fs&lt;/span&gt;, dir&lt;span class=&quot;pl-k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;/&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;});&lt;/span&gt;
&lt;span class=&quot;pl-s1&quot;&gt;});&lt;/span&gt;
&lt;span class=&quot;pl-s1&quot;&gt;&amp;lt;&lt;/span&gt;/&lt;span class=&quot;pl-ent&quot;&gt;script&lt;/span&gt;&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Besides IndexedDB, BrowserFS supports many different backends with different performance characteristics, as well as advanced configurations such as: multiple mounting points, and overlaying a writeable filesystems on top of a read-only filesystem. You don't need to know about all these features, but familiarizing yourself with the different options may be necessary if you hit a storage limit or performance bottleneck in the IndexedDB backend I suggested above.&lt;/p&gt;
&lt;h3&gt;CORS support&lt;/h3&gt;
&lt;p&gt;Unfortunately, due to the same-origin policy by default &lt;code&gt;isomorphic-git&lt;/code&gt; can only clone from the same origin as the webpage it is running on. This is terribly inconvenient, as it means for all practical purposes cloning and pushing repos must be done through a &lt;a href=&quot;https://cors-buster-jfpactjnem.now.sh/&quot; rel=&quot;nofollow&quot;&gt;proxy&lt;/a&gt;. However, I am &quot;being the change you want to see in the world&quot; by making PRs to all the major git repository hosting services.&lt;/p&gt;
&lt;p&gt;It is literally just two lines of code to add the CORS headers!! Easy stuff. Surely it will happen.&lt;/p&gt;
&lt;h3&gt;Using as an npm module&lt;/h3&gt;
&lt;p&gt;You can install it from npm.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;npm install --save isomorphic-git
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;In the package.json you'll see there are actually 4 different versions:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-json&quot;&gt;
&lt;pre&gt;
  &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;main&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;dist/for-node/&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;,
  &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;browser&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;dist/for-browserify/&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;,
  &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;module&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;dist/for-future/&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;,
  &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;unpkg&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;: &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;dist/bundle.umd.min.js&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;,
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This probably deserves a brief explanation.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;the &quot;main&quot; version is for node.&lt;/li&gt;
&lt;li&gt;the &quot;browser&quot; version is for browserify.&lt;/li&gt;
&lt;li&gt;the &quot;module&quot; version is for native ES6 module loaders when they arrive.&lt;/li&gt;
&lt;li&gt;the &quot;unpkg&quot; version is the UMD build.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;For more details about each build see &lt;a href=&quot;https://github.com/isomorphic-git/isomorphic-git/blob/master/dist/README.md&quot;&gt;./dist/README.md&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;code&gt;isogit&lt;/code&gt; CLI&lt;/h3&gt;
&lt;p&gt;Isomorphic-git comes with a simple CLI tool, named &lt;code&gt;isogit&lt;/code&gt; because &lt;code&gt;isomorphic-git&lt;/code&gt; is a lot to type. It is really just a thin shell that translates command line arguments into the equivalent JS API commands. So you should be able to run &lt;em&gt;any&lt;/em&gt; current or future isomorphic-git commands using the CLI.&lt;/p&gt;
&lt;p&gt;It always starts with an the assumption that the current working directory is a git root. E.g. &lt;code&gt;repo = new Git({fs, dir: '.'})&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It uses &lt;code&gt;minimisted&lt;/code&gt; to parse command line options.&lt;/p&gt;
&lt;p&gt;TODO: Document this more. Also write some tests? IDK the CLI is more of a lark for testing really.&lt;/p&gt;
&lt;h2&gt;Supported Git commands&lt;/h2&gt;
&lt;p&gt;I may continue to make changes to the API until the 1.0 release, after which I promise not to make any breaking changes.&lt;/p&gt;
&lt;h3&gt;commands&lt;/h3&gt;
&lt;h3&gt;utils&lt;/h3&gt;
&lt;h2&gt;Internal code architecture&lt;/h2&gt;
&lt;p&gt;I have written this library as a series of layers that build upon one another and should tree-shake very well:&lt;/p&gt;
&lt;h3&gt;Commands&lt;/h3&gt;
&lt;p&gt;Each command is available as its own file, so you are able to import individual commands if you only need a few in order to optimize your bundle size.&lt;/p&gt;
&lt;h3&gt;Managers&lt;/h3&gt;
&lt;p&gt;Managers are a level above models. They take care of implementation performance details like&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;batching reads to and from the file system&lt;/li&gt;
&lt;li&gt;in-process concurrency locks&lt;/li&gt;
&lt;li&gt;lockfiles&lt;/li&gt;
&lt;li&gt;caching files and invalidating cached results&lt;/li&gt;
&lt;li&gt;reusing objects&lt;/li&gt;
&lt;li&gt;object memory pools&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;Models and Utils&lt;/h3&gt;
&lt;p&gt;Models and utils are the lowest level building blocks. Models generally have very few or no dependencies except for &lt;code&gt;'buffer'&lt;/code&gt;. This makes them portable to many different environments so they can be a useful lowest common denominator.&lt;/p&gt;
&lt;p&gt;Utils are basically miscellaneous functions. Some are convenience wrappers for common filesystem operations.&lt;/p&gt;
&lt;h2&gt;Who is using isomorphic-git?&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://nde.now.sh&quot; rel=&quot;nofollow&quot;&gt;nde&lt;/a&gt; - a futuristic next-generation web IDE&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://git-app-manager-tcibxepsta.now.sh&quot; rel=&quot;nofollow&quot;&gt;git-app-manager&lt;/a&gt; - install &quot;unhosted&quot; websites locally by git cloning them&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Similar projects&lt;/h2&gt;
&lt;h2&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;Isomorphic-git would not have been possible without the pioneering work by @creationix and @chrisdickinson. Git is a tricky binary mess, and without their examples (and their modules!) I would not have been able to come even close to finishing this. They are geniuses ahead of their time.&lt;/p&gt;
&lt;h2&gt;Contributors&lt;/h2&gt;
&lt;p&gt;Thanks goes to these wonderful people (&lt;a href=&quot;https://github.com/kentcdodds/all-contributors#emoji-key&quot;&gt;emoji key&lt;/a&gt;):&lt;/p&gt;
&lt;p&gt;This project follows the &lt;a href=&quot;https://github.com/kentcdodds/all-contributors&quot;&gt;all-contributors&lt;/a&gt; specification. Contributions of any kind welcome!&lt;/p&gt;
&lt;h3&gt;Backers&lt;/h3&gt;
&lt;p&gt;Thank you to all our backers! 🙏 [&lt;a href=&quot;https://opencollective.com/isomorphic-git#backer&quot; rel=&quot;nofollow&quot;&gt;Become a backer&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://opencollective.com/isomorphic-git#backers&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/6dce226c74a8d902548e23a5f1b7296ec5555ac9/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f69736f6d6f72706869632d6769742f6261636b6572732e7376673f77696474683d383930&quot; data-canonical-src=&quot;https://opencollective.com/isomorphic-git/backers.svg?width=890&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Sponsors&lt;/h3&gt;
&lt;p&gt;Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [&lt;a href=&quot;https://opencollective.com/isomorphic-git#sponsor&quot; rel=&quot;nofollow&quot;&gt;Become a sponsor&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://opencollective.com/isomorphic-git/sponsor/0/website&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/9025879c6c50d6e16d29e8008c7a1fca756fafd6/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f69736f6d6f72706869632d6769742f73706f6e736f722f302f6176617461722e737667&quot; data-canonical-src=&quot;https://opencollective.com/isomorphic-git/sponsor/0/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/isomorphic-git/sponsor/1/website&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/0e6d500943a48d424e370528b43acb778e43b34a/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f69736f6d6f72706869632d6769742f73706f6e736f722f312f6176617461722e737667&quot; data-canonical-src=&quot;https://opencollective.com/isomorphic-git/sponsor/1/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/isomorphic-git/sponsor/2/website&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/985dedc2f73319404e8cb7ce706e1d6deb4f0e32/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f69736f6d6f72706869632d6769742f73706f6e736f722f322f6176617461722e737667&quot; data-canonical-src=&quot;https://opencollective.com/isomorphic-git/sponsor/2/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/isomorphic-git/sponsor/3/website&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/dc29207002db0a8187aab77469ab78d8c92c9908/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f69736f6d6f72706869632d6769742f73706f6e736f722f332f6176617461722e737667&quot; data-canonical-src=&quot;https://opencollective.com/isomorphic-git/sponsor/3/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/isomorphic-git/sponsor/4/website&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/5b9ac4cec1d96264d7ab26791e2f593e354dcf9d/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f69736f6d6f72706869632d6769742f73706f6e736f722f342f6176617461722e737667&quot; data-canonical-src=&quot;https://opencollective.com/isomorphic-git/sponsor/4/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/isomorphic-git/sponsor/5/website&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/e7302cae61dc27926da1f619ef2cfae38af323de/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f69736f6d6f72706869632d6769742f73706f6e736f722f352f6176617461722e737667&quot; data-canonical-src=&quot;https://opencollective.com/isomorphic-git/sponsor/5/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/isomorphic-git/sponsor/6/website&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/5a3148307ab91c8a755a14814cca4b2850a129f9/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f69736f6d6f72706869632d6769742f73706f6e736f722f362f6176617461722e737667&quot; data-canonical-src=&quot;https://opencollective.com/isomorphic-git/sponsor/6/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/isomorphic-git/sponsor/7/website&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/c0a8c053134345f54bedb347871b0d845b952737/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f69736f6d6f72706869632d6769742f73706f6e736f722f372f6176617461722e737667&quot; data-canonical-src=&quot;https://opencollective.com/isomorphic-git/sponsor/7/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/isomorphic-git/sponsor/8/website&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/935ba05939c417a42da6412592f5341742541ebe/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f69736f6d6f72706869632d6769742f73706f6e736f722f382f6176617461722e737667&quot; data-canonical-src=&quot;https://opencollective.com/isomorphic-git/sponsor/8/avatar.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://opencollective.com/isomorphic-git/sponsor/9/website&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/1f6ee450adc928c3534707ac664bc2fa87296cf6/68747470733a2f2f6f70656e636f6c6c6563746976652e636f6d2f69736f6d6f72706869632d6769742f73706f6e736f722f392f6176617461722e737667&quot; data-canonical-src=&quot;https://opencollective.com/isomorphic-git/sponsor/9/avatar.svg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;License&lt;/h2&gt;
&lt;p&gt;This work is released under &lt;a href=&quot;https://opensource.org/licenses/MIT&quot; rel=&quot;nofollow&quot;&gt;The MIT License&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://app.fossa.io/projects/git%2Bgithub.com%2Fisomorphic-git%2Fisomorphic-git?ref=badge_large&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/aba5d36805f447dbf686529da93befc191345c2d/68747470733a2f2f6170702e666f7373612e696f2f6170692f70726f6a656374732f6769742532426769746875622e636f6d25324669736f6d6f72706869632d67697425324669736f6d6f72706869632d6769742e7376673f747970653d6c61726765&quot; alt=&quot;FOSSA Status&quot; data-canonical-src=&quot;https://app.fossa.io/api/projects/git%2Bgithub.com%2Fisomorphic-git%2Fisomorphic-git.svg?type=large&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;</description>
<pubDate>Wed, 16 May 2018 16:36:35 +0000</pubDate>
<dc:creator>axiomdata316</dc:creator>
<og:image>https://avatars0.githubusercontent.com/u/34904042?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>isomorphic-git/isomorphic-git</og:title>
<og:url>https://github.com/isomorphic-git/isomorphic-git</og:url>
<og:description>isomorphic-git - A pure JavaScript implementation of git for node and browsers!</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/isomorphic-git/isomorphic-git</dc:identifier>
</item>
<item>
<title>AI and Compute</title>
<link>https://blog.openai.com/ai-and-compute/?</link>
<guid isPermaLink="true" >https://blog.openai.com/ai-and-compute/?</guid>
<description>&lt;p&gt;We're releasing an analysis showing that since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.5 month-doubling time (by comparison, Moore's Law &lt;a href=&quot;https://www.nature.com/articles/s41928-017-0005-9&quot;&gt;had&lt;/a&gt; an 18-month doubling period). Since 2012, this metric has grown by more than 300,000x (an 18-month doubling period would yield only a 12x increase). Improvements in compute have been a key component of AI progress, so as long as this trend continues, it's worth preparing for the implications of systems far outside today's capabilities.&lt;/p&gt;&lt;div id=&quot;log&quot;&gt;&lt;img src=&quot;https://blog.openai.com/content/images/2018/05/compute_diagram-log@2x-3.png&quot;/&gt;&lt;/div&gt;
&lt;div id=&quot;linear&quot;&gt;&lt;img src=&quot;https://blog.openai.com/content/images/2018/05/compute_diagram-linear@2x-5.png&quot;/&gt;&lt;/div&gt;
&lt;p&gt;&lt;input type=&quot;radio&quot; class=&quot;switch-input&quot; name=&quot;view1&quot; value=&quot;log-scale&quot; id=&quot;log-scale&quot; onclick=&quot;toggle('log')&quot; checked=&quot;checked&quot;/&gt;&lt;label for=&quot;log-scale&quot; class=&quot;switch-label switch-label-off&quot;&gt;Log Scale&lt;/label&gt; &lt;input type=&quot;radio&quot; class=&quot;switch-input&quot; name=&quot;view1&quot; value=&quot;linear-scale&quot; id=&quot;linear-scale&quot; onclick=&quot;toggle('linear')&quot;/&gt;&lt;label for=&quot;linear-scale&quot; class=&quot;switch-label switch-label-on&quot;&gt;Linear Scale&lt;/label&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The chart shows the total amount of compute, in petaflop/s-days, that was used to train selected results that are relatively well known, used a lot of compute for their time, and gave enough information to estimate the compute used. A petaflop/s-day (pfs-day) consists of performing 10&lt;sup&gt;15&lt;/sup&gt; neural net operations per second for one day, or a total of about 10&lt;sup&gt;20&lt;/sup&gt; operations. The compute-time product serves as a mental convenience, similar to kW-hr for energy. We don’t measure peak theoretical FLOPS of the hardware but instead try to estimate the number of actual operations performed. We count adds and multiplies as separate operations, we count any add or multiply as a single operation regardless of numerical precision (making “FLOP” a slight misnomer), and we ignore &lt;a href=&quot;http://web.engr.oregonstate.edu/~tgd/publications/mcs-ensembles.pdf&quot;&gt;ensemble models&lt;/a&gt;. Example calculations that went into this graph are provided in this &lt;a href=&quot;https://blog.openai.com/ai-and-compute/?#appendixmethods&quot;&gt;appendix&lt;/a&gt;. Doubling time for line of best fit shown is 3.43 months.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Three factors drive the advance of AI: algorithmic innovation, data (which can be either supervised data or interactive environments), and the amount of compute available for training. Algorithmic innovation and data are difficult to track, but compute is unusually quantifiable, providing an opportunity to measure one input to AI progress. Of course, the use of massive compute sometimes just exposes the shortcomings of our current algorithms. But at least within many current domains, more compute seems to lead &lt;a href=&quot;https://arxiv.org/abs/1712.00409&quot;&gt;predictably to better performance&lt;/a&gt;, and is often complementary to algorithmic advances.&lt;/p&gt;
&lt;p&gt;For this analysis, we believe the relevant number is not the speed of a single GPU, nor the capacity of the biggest datacenter, but the amount of compute that is used to train a single model — this is the number most likely to correlate to how powerful our best models are. Compute per model differs greatly from total bulk compute because &lt;a href=&quot;http://learningsys.org/nips17/assets/slides/dean-nips17.pdf&quot;&gt;limits on parallelism&lt;/a&gt; (both hardware and algorithmic) have constrained how big a model can be or how much it can be usefully trained. Of course, important breakthroughs are still made with &lt;a href=&quot;https://blog.openai.com/ai-and-compute/?#appendixrecentnovelresultsthatusedmodestamountsofcompute&quot;&gt;modest amounts&lt;/a&gt; of compute — this analysis just covers compute capability.&lt;/p&gt;
&lt;p&gt;The trend represents an increase by roughly a factor of 10 each year. It’s been partly driven by custom hardware that allows more operations to be performed per second for a given price (GPUs and TPUs), but it’s been primarily propelled by researchers repeatedly finding ways to use more chips in parallel and being willing to pay the economic cost of doing so.&lt;/p&gt;

&lt;p&gt;Looking at the graph we can roughly see four distinct eras:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Before 2012: It was uncommon to use GPUs for ML, making any of the results in the graph difficult to achieve.&lt;/li&gt;
&lt;li&gt;2012 to 2014: Infrastructure to train on many GPUs was uncommon, so most results used 1-8 GPUs rated at 1-2 TFLOPS for a total of 0.001-0.1 pfs-days.&lt;/li&gt;
&lt;li&gt;2014 to 2016: Large-scale results used 10-100 GPUs rated at 5-10 TFLOPS, resulting in 0.1-10 pfs-days. Diminishing returns on data parallelism meant that larger training runs had limited value.&lt;/li&gt;
&lt;li&gt;2016 to 2017: Approaches that allow greater algorithmic parallelism such as &lt;a href=&quot;https://arxiv.org/abs/1711.04325&quot;&gt;huge batch sizes&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1611.01578&quot;&gt;architecture search&lt;/a&gt;, and &lt;a href=&quot;https://arxiv.org/pdf/1705.08439.pdf&quot;&gt;expert iteration&lt;/a&gt;, along with specialized hardware such as TPU’s and faster interconnects, have greatly increased these limits, at least for some applications.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;AlphaGoZero/AlphaZero is the most visible public example of massive algorithmic parallelism, but many other applications at this scale are now algorithmically possible, and may already be happening in a production context.&lt;/p&gt;

&lt;p&gt;We see multiple reasons to believe that the trend in the graph could continue. Many &lt;a href=&quot;https://www.nytimes.com/2018/01/14/technology/artificial-intelligence-chip-start-ups.html&quot;&gt;hardware startups&lt;/a&gt; are developing AI-specific chips, some of which claim they will achieve a substantial increase in FLOPS/Watt (which is correlated to FLOPS/$) over the next 1-2 years. There may also be gains from simply reconfiguring hardware to do the same number of operations for &lt;a href=&quot;http://www.fast.ai/2018/04/30/dawnbench-fastai/&quot;&gt;less economic cost&lt;/a&gt;. On the parallelism side, many of the recent algorithmic innovations described above could in principle be combined multiplicatively — for example, architecture search and massively parallel SGD.&lt;/p&gt;
&lt;p&gt;On the other hand, cost will eventually limit the parallelism side of the trend and physics will limit the chip efficiency side. We believe the largest training runs today employ hardware that cost in the single digit millions of dollars to purchase (although the amortized cost is much lower). But the majority of neural net compute today is still spent on inference (deployment), not training, meaning companies can repurpose or afford to purchase much larger fleets of chips for training. Therefore, if sufficient economic incentive exists, we could see even more massively parallel training runs, and thus the continuation of this trend for several more years. The world’s total hardware budget is &lt;a href=&quot;https://www.statista.com/statistics/422802/hardware-spending-forecast-worldwide/&quot;&gt;1 trillion dollars&lt;/a&gt; a year, so absolute limits remain far away. Overall, given the data above, the precedent for exponential trends in computing, work on ML specific hardware, and the economic incentives at play, we think it’d be a mistake to be confident this trend won’t continue in the short term.&lt;/p&gt;
&lt;p&gt;Past trends are not sufficient to predict how long the trend will continue into the future, or what will happen while it continues. But even the reasonable potential for rapid increases in capabilities means it is critical to start addressing both &lt;a href=&quot;https://blog.openai.com/concrete-ai-safety-problems/&quot;&gt;safety&lt;/a&gt; and &lt;a href=&quot;https://blog.openai.com/preparing-for-malicious-uses-of-ai/&quot;&gt;malicious use of AI&lt;/a&gt; today. Foresight is essential to &lt;a href=&quot;https://oversight.house.gov/wp-content/uploads/2018/04/Clark-OpenAI-Statement-AI-III-4-18.pdf&quot;&gt;responsible policymaking&lt;/a&gt; and responsible technological development, and we must get out ahead of these trends rather than belatedly reacting to them.&lt;/p&gt;
&lt;p&gt;(If you'd like to help make sure that &lt;a href=&quot;https://blog.openai.com/openai-charter/&quot;&gt;AI progress benefits all of humanity&lt;/a&gt;, &lt;a href=&quot;https://openai.com/jobs/&quot;&gt;join us&lt;/a&gt; at OpenAI. Our research and engineering roles range from &lt;a href=&quot;https://jobs.lever.co/openai/588c1d80-4632-4d5c-a535-9f2c8c80c501&quot;&gt;machine learning researchers&lt;/a&gt; to &lt;a href=&quot;https://jobs.lever.co/openai/638c06a8-4058-4c3d-9aef-6ee0528fb3bf&quot;&gt;policy researchers&lt;/a&gt; to &lt;a href=&quot;https://jobs.lever.co/openai/f163bf64-278e-417b-ad2e-5e508a29eb71&quot;&gt;infrastructure engineers&lt;/a&gt;.)&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;Two methodologies were used to generate these data points. When we had enough information, we directly counted the number of FLOPs (adds and multiplies) in the described architecture per training example and multiplied by the total number of forward and backward passes during training. When we didn’t have enough information to directly count FLOPs, we looked GPU training time and total number of GPUs used and assumed a utilization efficiency (usually 0.33). For the majority of the papers we were able to use the first method, but for a significant minority we relied on the second, and we computed both whenever possible as a consistency check. In the majority of cases we also confirmed with the authors. The calculations are not intended to be precise but we aim to be correct within a factor 2-3. We provide some example calculations below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example of Method 1: Counting operations in the model&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This method is particularly easy to use when the authors give the number of operations used in a forward pass, as in the &lt;a href=&quot;https://arxiv.org/abs/1512.03385&quot;&gt;Resnet paper&lt;/a&gt; (the Resnet-151 model in particular):&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;(add-multiplies per forward pass) * (2 FLOPs/add-multiply) * (3 for forward and backward pass) * (number of examples in dataset) * (number of epochs)
= (11.4 * 10^9) * 2 * 3 * (1.2 * 10^6 images) * 128
= 10,000 PF = 0.117 pfs-days
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Operations can also be counted programmatically for a known model architecture in some deep learning frameworks, or we can simply count operations manually. If a paper gives enough information to make this calculation, it will be quite accurate, but in some cases papers don’t contain all the necessary information and authors aren’t able to reveal it publicly.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example of Method 2: GPU Time&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If we can’t count operations directly, we can instead look at how many GPUs were trained for how long, and use reasonable guesses at GPU utilization to try to estimate the number of operations performed. We emphasize that here we are not counting peak theoretical FLOPS, but using an assumed fraction of theoretical FLOPS to try to guess at actual FLOPS. We typically assume a 33% utilization for GPUs and a 17% utilization for CPU’s, based on our own experience, except where we have more specific information (e.g. we spoke to the author or the work was done at OpenAI).&lt;/p&gt;
&lt;p&gt;As an example, in the &lt;a href=&quot;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&quot;&gt;AlexNet paper&lt;/a&gt; it’s stated that “our network takes between five and six days to train on two GTX 580 3GB GPUs”. Under our assumptions this implies a total compute of:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Number of GPUs * (peta-flops/GTX580) * days trained * estimated utilization
= 2 * (1.58 * 10 ^ -3 PF) * 5.5 * 0.33
= 500 PF = 0.0058 pfs-days 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;This method is more approximate and can easily be off by a factor of 2 or occasionally more; our aim is only to estimate the order of magnitude. In practice when both methods are available they often line up quite well (for AlexNet we can also directly count the operations, which gives us 0.0054 pfs-days vs 0.0058 with the GPU time method).&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;1.2M images * 90 epochs * 0.75 GFLOPS * (2 add-multiply) * (3 backward pass) 
= 470 PF = 0.0054 pfs-days
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Selected Additional Calculations&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1207.0580&quot;&gt;Dropout&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Method 2:

1 GPU * 4 days * 1.54 TFLOPS/GTX 580 * 0.33 utilization 
= 184 PF = 0.0021 pfs-days
&lt;/code&gt;
&lt;/pre&gt;
&lt;hr class=&quot;appendix&quot;/&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1311.2901&quot;&gt;Visualizing and Understanding Conv Nets&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Method 2:

1 GPU * 12 days * 1.54 TFLOPS/GTX 580 * 0.33 utilization 
= 532 PF = 0.0062 pfs-days
&lt;/code&gt;
&lt;/pre&gt;
&lt;hr class=&quot;appendix&quot;/&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1312.5602&quot;&gt;DQN&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Method 1:

Network is 84x84x3 input, 16, 8x8, stride 4, 32 4x4 stride 2, 256 fully connected
First layer: 20*20*3*16*8*8 = 1.23M add-multiplies
Second layer: 9*9*16*32*4*4 = 0.66M add-multiplies
Third layer: 9*9*32*256 = 0.66M add-mutliplies
Total ~ 2.55M add-multiplies
2.5 MFLOPs * 5M updates * 32 batch size * 2 multiply-add * 3 backward pass
= 2.3 PF = 2.7e-5 pfs-days
&lt;/code&gt;
&lt;/pre&gt;
&lt;hr class=&quot;appendix&quot;/&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1409.3215&quot;&gt;Seq2Seq&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Method 1:

(348M + 304M) words * 0.380 GF * 2 add-multiply * 3 backprop * 7.5 epoch
= 7,300 PF = 0.085 pfs-days
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;Method 2:

10 days * 8 GPU’s * 3.5 TFLOPS/ K20 GPU * 0.33 utilization 
= 8,100 PF = 0.093 pfs-days
&lt;/code&gt;
&lt;/pre&gt;
&lt;hr class=&quot;appendix&quot;/&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/pdf/1409.1556.pdf&quot;&gt;VGG&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Method 1:

1.2 M images * 74 epochs * 16 GFLOPS * 2 add-multiply * 3 backward pass 
= 8524 PF = 0.098 pfs-days
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;Method 2:

4 Titan Black GPU’s * 15 days * 5.1 TFLOPS/GPU * 0.33 utilization 
= 10,000 PF = 0.12 pfs-days
&lt;/code&gt;
&lt;/pre&gt;
&lt;hr class=&quot;appendix&quot;/&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.02595&quot;&gt;DeepSpeech2&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Method 1:

1 timestep = (1280 hidden units)^2 * (7 RNN layers * 4 matrices for bidirectional + 2 DNN layers) * (2 for doubling parameters from 36M to 72M) = 98 MFLOPs
20 epochs * 12,000 hours * 3600 seconds/hour * 50 samples/sec * 98 MFLOPs * 3 add-multiply * 2 backprop 
= 26,000 PF = 0.30 pfs-days
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;Method 2:

16 TitanX GPU’s * 5 days * 6 TFLOPS/GPU * 0.50 utilization 
= 21,000 PF = 0.25 pfs-days
&lt;/code&gt;
&lt;/pre&gt;
&lt;hr class=&quot;appendix&quot;/&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.02357&quot;&gt;Xception&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Method 2:

60 K80 GPU’s * 30 days * 8.5 TFLOPS/GPU * 0.33 utilization 
= 4.5e5 PF = 5.0 pfs-days
&lt;/code&gt;
&lt;/pre&gt;
&lt;hr class=&quot;appendix&quot;/&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1611.01578&quot;&gt;Neural Architecture Search&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Method 1:

50 epochs * 50,000 images * 10.0 GFLOPSs * 12800 networks * 2 add-multiply * 3 backward pass 
= 1.9e6 PF = 22 pfs-days
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;Method 2:

800 K40’s * 28 days * 4.2 TFLOPS/GPU * 0.33 utilization 
= 2.8e6 PF = 31 pfs-days
Details given in a [later paper](https://arxiv.org/pdf/1707.07012.pdf).
&lt;/code&gt;
&lt;/pre&gt;
&lt;hr class=&quot;appendix&quot;/&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1609.08144&quot;&gt;Neural Machine Translation&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Method 2:

sqrt(10 * 100) factor added because production model used 2-3 orders of magnitude more data, but only 1 epoch rather than 10.
96 K80 GPU’s * 9 days * 8.5 TFLOPS * 0.33 utilization * sqrt(10 * 100)  
= 6.9e6 PF = 79 pfs-days
&lt;/code&gt;
&lt;/pre&gt;
&lt;hr class=&quot;appendix&quot;/&gt;
&lt;p&gt;Massive compute is certainly not a requirement to produce important results. Many recent noteworthy results have used only modest amounts of compute. Here are some examples of results using modest compute that gave enough information to estimate their compute. We didn’t use multiple methods to estimate the compute for these models, and for upper bounds we made conservative estimates around any missing information, so they have more overall uncertainty. They aren’t material to our quantitative analysis, but we still think they are interesting and worth sharing:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;Attention is all you need:&lt;/a&gt; 0.089 pfs-days (6/2017)&lt;br/&gt;&lt;a href=&quot;https://arxiv.org/abs/1412.6980&quot;&gt;Adam Optimizer:&lt;/a&gt; less than 0.0007 pfs-days (12/2014)&lt;br/&gt;&lt;a href=&quot;https://arxiv.org/abs/1409.0473&quot;&gt;Learning to Align and Translate:&lt;/a&gt; 0.018 pfs-days (09/2014)&lt;br/&gt;&lt;a href=&quot;https://arxiv.org/abs/1406.2661&quot;&gt;GANs:&lt;/a&gt; less than 0.006 pfs-days (6/2014)&lt;br/&gt;&lt;a href=&quot;https://arxiv.org/abs/1310.4546&quot;&gt;Word2Vec:&lt;/a&gt; less than 0.00045 pfs-days (10/2013)&lt;br/&gt;&lt;a href=&quot;https://arxiv.org/abs/1312.6114&quot;&gt;Variational Auto Encoders:&lt;/a&gt; less than 0.0000055 pfs-days (12/2013)&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;em&gt;The authors thank Katja Grace, Geoffrey Irving, Jack Clark, Thomas Anthony, and Michael Page for assistance with this post.&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 16 May 2018 16:29:41 +0000</pubDate>
<dc:creator>gdb</dc:creator>
<og:type>article</og:type>
<og:title>AI and Compute</og:title>
<og:description>Since 2012, the amount of compute used in the largest AI training runs has been increasing exponentially with a 3.5 month doubling time (by comparison, Moore's Law had an 18 month doubling period).</og:description>
<og:url>https://blog.openai.com/ai-and-compute/</og:url>
<og:image>https://blog.openai.com/content/images/2018/05/compute_diagram@2x-1.png</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.openai.com/ai-and-compute/?</dc:identifier>
</item>
<item>
<title>Salesforce CEO Benioff calls for national privacy law</title>
<link>https://www.salesforce.com/company/news-press/stories/2018/5/051618/</link>
<guid isPermaLink="true" >https://www.salesforce.com/company/news-press/stories/2018/5/051618/</guid>
<description>&lt;p&gt;&lt;em&gt;                    Watch Salesforce Chairman and CEO Marc Benioff's appearance on CBS This Morning.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Speaking on &lt;a href=&quot;https://www.cbsnews.com/video/salesforce-ceo-marc-benioff-calls-for-national-privacy-law/&quot;&gt;CBS This Morning&lt;/a&gt; today with Gayle King, Norah O'Donnell and John Dickerson, Salesforce Chairman and CEO Marc Benioff called for a national privacy law.&lt;/p&gt;
&lt;p&gt;“You can see that our industry is going through a very significant crisis of trust. We've seen that over the last year with Uber and Facebook and other companies,” Benioff said. “In some ways, you could say that Facebook has become the new cigarettes in our industry. That is, it's a technology that is addictive, it may not be that great for you and it might be something you don't want to go back to. Maybe it's time for the government to step in and regulate not just that product but our industry.”&lt;/p&gt;
&lt;p&gt;“We really need in this country a national privacy law,” he said. “You can see it's going into effect in Europe with GDPR. That means in Europe your data belongs to you, but in the United States, your data belongs to all these companies that are collecting it, and they can do with it basically whatever they want. That's a shift we have to make. You can see that's about to happen in California where I am from. There is a statewide privacy law that is moving its way to voters. But what we need is a national privacy law. It's not just going to protect the tech industry, it's going to protect all the consumers, and ultimately our kids, which is really what this is all about. We know that all these companies are looking to bring kids into their social networks as well.”&lt;/p&gt;
&lt;p&gt;Benioff also called for regulations to address advances in artificial intelligence. &quot;I see huge advancements that are happening every day in our industry. You could see that last week with Google Duplex. It was the most amazing AI technology I've seen. It's indistinguishable from a human being when you are talking to it. Many people in the computer industry feel that it passed the Turing Test—that means 'is that a human or a computer.' If we are at that point we have to have better regulations and controls. The Europeans understand that. It's time for Americans to understand that too.”&lt;/p&gt;
&lt;p&gt;A national privacy law would require that companies disclose how they collect your information, use your information, and offer a right-to-be-forgotten, Benioff explained. “If you want to delete your information, you could hit that button and be sure your data is gone forever.”&lt;/p&gt;
&lt;p&gt;Benioff also discussed gender equality and the role of chief executives. “CEOs need to be held accountable for making sure that they are equally paying men and women,” he said. “It's also about preventing sexual harassment. You can't have gender equality without knowing you have psychological safety in your workplace.”&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Related Stories:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.salesforce.com/company/news-press/stories/2018/5/051418/&quot;&gt;Salesforce's GDPR Journey&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.salesforce.com/company/news-press/stories/2018/5/051418-a/&quot;&gt;Q&amp;amp;A: Salesforce's Data Protection Officer on Trust, GDPR and How Privacy Found Her&lt;/a&gt;&lt;/p&gt;


</description>
<pubDate>Wed, 16 May 2018 16:28:19 +0000</pubDate>
<dc:creator>jeffthechimp</dc:creator>
<og:url>https://www.salesforce.com/company/news-press/stories/2018/5/051618/</og:url>
<og:type>website</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.salesforce.com/company/news-press/stories/2018/5/051618/</dc:identifier>
</item>
<item>
<title>The sad state of sysadmin in the age of containers (2015)</title>
<link>https://www.vitavonni.de/blog/201503/2015031201-the-sad-state-of-sysadmin-in-the-age-of-containers.html</link>
<guid isPermaLink="true" >https://www.vitavonni.de/blog/201503/2015031201-the-sad-state-of-sysadmin-in-the-age-of-containers.html</guid>
<description>&lt;p&gt;System administration is in a sad state. It in a mess.&lt;/p&gt;
&lt;p&gt;I’m not complaining about old-school sysadmins. They know how to keep systems running, manage update and upgrade paths.&lt;/p&gt;
&lt;p&gt;This rant is about containers, prebuilt VMs, and the incredible mess they cause because their concept lacks notions of “trust” and “upgrades”.&lt;/p&gt;
&lt;p&gt;Consider for example Hadoop. &lt;strong&gt;Nobody seems to know how to build Hadoop from scratch.&lt;/strong&gt; It’s an incredible mess of dependencies, version requirements and build tools.&lt;/p&gt;
&lt;p&gt;None of these “fancy” tools still builds by a traditional &lt;code class=&quot;highlighter-rouge&quot;&gt;make&lt;/code&gt; command. Every tool has to come up with their own, incomptaible, and non-portable “method of the day” of building.&lt;/p&gt;
&lt;p&gt;And since nobody is still able to compile things from scratch, &lt;strong&gt;everybody just downloads precompiled binaries from random websites&lt;/strong&gt;. Often &lt;strong&gt;without any authentication or signature&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;NSA and virus heaven. &lt;strong&gt;You don’t need to exploit any security hole anymore.&lt;/strong&gt; Just make an “app” or “VM” or “Docker” image, and have people load your malicious binary to their network.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://wiki.debian.org/Hadoop&quot;&gt;Hadoop Wiki Page&lt;/a&gt; of Debian is a typical example. Essentially, people have given up in 2010 to be able build Hadoop from source for Debian and offer nice packages.&lt;/p&gt;
&lt;p&gt;To build Apache Bigtop, you apparently first have to install puppet3. Let it download magic data from the internet. Then it tries to run &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo puppet&lt;/code&gt; to enable the NSA backdoors (for example, it will download and install an outdated precompiled JDK, because it considers you too stupid to install Java.) And then hope the gradle build doesn’t throw a 200 line useless backtrace.&lt;/p&gt;
&lt;p&gt;I am not joking. It will try to execute commands such as e.g.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;/bin/bash -c &quot;wget http://www.scala-lang.org/files/archive/scala-2.10.3.deb ; dpkg -x ./scala-2.10.3.deb /&quot;&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note that it doesn’t even &lt;em&gt;install&lt;/em&gt; the package properly, but extracts it to your root directory. The download does not check any signature, not even SSL certificates. (Source: &lt;a href=&quot;https://github.com/apache/bigtop/blob/master/bigtop_toolchain/manifests/scala.pp&quot;&gt;Bigtop puppet manifests&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Even if your build would work, it will involve Maven downloading unsigned binary code from the internet, and use that for building.&lt;/p&gt;
&lt;p&gt;Instead of writing clean, modular architecture, everything these days morphs into a huge mess of interlocked dependencies. Last I checked, the Hadoop classpath was already over 100 jars. I bet it is now 150, without even using any of the HBaseGiraphFlumeCrunchPigHiveMahoutSolrSparkElasticsearch (or any other of the Apache chaos) mess yet.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stack&lt;/strong&gt; is the new term for “I have no idea what I’m actually using”.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Maven&lt;/strong&gt;, &lt;strong&gt;ivy&lt;/strong&gt; and &lt;strong&gt;sbt&lt;/strong&gt; are the go-to tools for having your system download unsigned binary data from the internet and run it on your computer.&lt;/p&gt;
&lt;p&gt;And with containers, this mess gets even worse.&lt;/p&gt;
&lt;p&gt;Ever tried to &lt;strong&gt;security update&lt;/strong&gt; a container?&lt;/p&gt;
&lt;p&gt;Essentially, the Docker approach boils down to downloading an unsigned binary, running it, and hoping it doesn’t contain any backdoor into your companies network.&lt;/p&gt;
&lt;p&gt;Feels like downloading Windows shareware in the 90s to me.&lt;/p&gt;
&lt;p&gt;When will the first docker image appear which contains the Ask toolbar? The first internet worm spreading via flawed docker images?&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;Back then, years ago, Linux distributions were trying to provide you with a safe operating system. With signed packages, built from a web of trust. Some even work on reproducible builds.&lt;/p&gt;
&lt;p&gt;But then, everything got Windows-ized. “Apps” were the rage, which you download and run, without being concerned about security, or the ability to upgrade the application to the next version. Because “you only live once”.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; it was pointed out that this started way before Docker: »&lt;em&gt;Docker is the new ‘&lt;code class=&quot;highlighter-rouge&quot;&gt;curl | sudo bash&lt;/code&gt;‘&lt;/em&gt;«. That’s right, but it’s now pretty much mainstream to download and run untrusted software in your “datacenter”. That is bad, really bad. Before, admins would try hard to prevent security holes, now they call themselves “devops” and happily introduce them to the network themselves!&lt;/p&gt;
</description>
<pubDate>Wed, 16 May 2018 16:00:57 +0000</pubDate>
<dc:creator>xg15</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.vitavonni.de/blog/201503/2015031201-the-sad-state-of-sysadmin-in-the-age-of-containers.html</dc:identifier>
</item>
<item>
<title>How a domain registrar can kill your business</title>
<link>https://www.uptimechecker.io/blog/how-domain-registrar-can-kill-your-business</link>
<guid isPermaLink="true" >https://www.uptimechecker.io/blog/how-domain-registrar-can-kill-your-business</guid>
<description>&lt;p&gt;In this post we will write about recent domain incident we suffered, who is responsible and what we did to minimize the damage.&lt;/p&gt;&lt;div readability=&quot;216.25326909842&quot;&gt;
&lt;p&gt;So, in the morning of May 3rd, I noticed &lt;strong&gt;uptimechecker.io&lt;/strong&gt; becomes unreachable at moments, then available again, then down again, and so on. It all reminded of DNS problems, but I didn't have idea how big the problem will become.&lt;/p&gt;
&lt;h3&gt;Horror started when we contacted our Registrar support&lt;/h3&gt;
&lt;p&gt;I knew our domain should be renewed about these dates, and we were already &lt;strong&gt;billed&lt;/strong&gt; for this renewal. Our domain registrar is &lt;a href=&quot;https://www.domain.com&quot;&gt;domain.com&lt;/a&gt;, so I logged in to our &lt;strong&gt;domain.com&lt;/strong&gt; dashboard to check if everything is OK, but domain &lt;strong&gt;was not renewed&lt;/strong&gt; and domain details were reading &lt;strong&gt;2 days&lt;/strong&gt; until expiry.&lt;/p&gt;
&lt;p&gt;I contacted &lt;strong&gt;domain.com&lt;/strong&gt; support immediately, their chat agent responded immediately, &lt;strong&gt;confirmed we were billed&lt;/strong&gt; for domain and that domain is &lt;strong&gt;not renewed&lt;/strong&gt;, and he created support ticket for the issue. This is the start of &lt;strong&gt;horror story&lt;/strong&gt; with domain.com support.&lt;/p&gt;
&lt;p&gt;I was regularly checking the ticket, but nothing happened, and after 4 hours I noticed nameservers for uptimechecker.io were reverted to default values (not serving anything). UptimeChecker.io was &lt;strong&gt;completely down&lt;/strong&gt; for all users.&lt;/p&gt;
&lt;p&gt;I tried to set nameservers to correct values, but Control panel returned error: &lt;strong&gt;uptimechekcer.io is not managed here&lt;/strong&gt;!&lt;/p&gt;
&lt;p&gt;I updated the ticket, said it is &lt;strong&gt;urgent&lt;/strong&gt; because our &lt;strong&gt;users cannot access the service&lt;/strong&gt;. I didn't got response for the next 8 hours, and after that, this was response:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Hello,&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Thank you for contacting Support.&lt;/p&gt;&lt;p&gt;I apologize for any inconvenience this has caused you. We can understand your concern about the domain renewal issue. I will need to hand this ticket over to one of our senior registrar specialists to further assist you on 'uptimechecker.io' domain renewal issue. You should be hearing from them within 24-48 hours.&lt;/p&gt;&lt;p&gt;If you have any further questions, please chat with us at https://www1.domain.com/chat/ .&lt;/p&gt;&lt;p&gt;Sincerely,&lt;/p&gt;&lt;p&gt;Sachin K&lt;br/&gt;Domain Registrar Specialist&lt;/p&gt;
&lt;p&gt;So, our &lt;strong&gt;domain is not working&lt;/strong&gt;, no one can access the service, obviously &lt;strong&gt;domain.com&lt;/strong&gt; is responsible for the incident because they failed to renew the domain, but they said please wait &lt;strong&gt;24-48 hours&lt;/strong&gt;!? That is the time we started panicking, because it looked like no one at &lt;strong&gt;domain.com&lt;/strong&gt; is really caring about the issue, and we were not able to do anything to recover the service by ourselves, since we were &lt;strong&gt;completely cut off&lt;/strong&gt; of our domain because nameservers were set to incorrect values and there were no way we can update them.&lt;/p&gt;
&lt;p&gt;It turned to be even worse than this, they didn't answer anything for next &lt;strong&gt;four days&lt;/strong&gt;. I was contacting live chat support &lt;strong&gt;every day&lt;/strong&gt;, in first days two times per day, and every time &lt;strong&gt;chat agent assured me&lt;/strong&gt; someone is working on the ticket, and that ticket will be updated shortly, they sometimes said in next &lt;strong&gt;6 hours&lt;/strong&gt;, or next &lt;strong&gt;24 hours&lt;/strong&gt;. So yeah, it may sound crazy, but that is true, and they lied to us constantly every day. And we were completely blind what was happening and when we can expect the resolution.&lt;/p&gt;
&lt;h3&gt;Recovery plan&lt;/h3&gt;
&lt;p&gt;Since we were &lt;strong&gt;completely locked out of control&lt;/strong&gt; of our primary domain, only way to do something on our side was to purchase another domain, change all of our systems to work with the new domain, and to inform our users about it. This is pretty radical, so I wanted to avoid this if possible, but no one from &lt;strong&gt;domain.com&lt;/strong&gt; gave us an answer when we can expect the service to be online again.&lt;/p&gt;
&lt;p&gt;Finally, on Sunday (four days after incident started) I concluded that we really cannot rely on them, and I purchased the new domain: &lt;strong&gt;uptimechecker.org&lt;/strong&gt; and started the migration process. Everything was ready for the switch on Monday, so I contacted live chat support one more time, and got the same answer: someone will update your ticket today. They really updated the ticket with this bizarre answer:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Hello,&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Thank you for your recent contact and concerns in regards toward your domain name. We are currently reaching out to our registrar members, to ensure your domain name is renewed. Unlike common domain names like .com or .nets. .IO's are managed by a specific organization, that manages only .IO domain names. They must receive notification to renew the domain name prior to three days before the domain name expires. Unfortunately, our automatic renewal system is not compatible to renew the .IO domain names. Therefor, we are reaching out to our registrar members to reach to the registry to redeem the domain name. We do apologize for the delay in your resolution. Once I have received a confirmation on your domain renewal, I will notify you. If you have any questions or concerns please feel free to contact us.&lt;/p&gt;&lt;p&gt;Regards,&lt;br/&gt;Danny G.&lt;br/&gt;Domain Registrar Specialist.&lt;/p&gt;
&lt;p&gt;So, basically, they admitted this is their fault, and their systems cannot do it properly, but they &lt;strong&gt;can create invoice and take money&lt;/strong&gt;, and not even inform the user about any problems!? Also, in that update, &lt;strong&gt;they didn't&lt;/strong&gt; give us &lt;strong&gt;any time estimate&lt;/strong&gt; when we can expect the resolution. I asked for that information each day over live chat, always getting response: your ticket will be updated in the next 6 hours, or sometimes, in next 24 hours. It is &lt;strong&gt;still not updated&lt;/strong&gt;, it is now &lt;strong&gt;8 days&lt;/strong&gt; after the last update.&lt;/p&gt;
&lt;p&gt;After that update, I decided it is time to inform all our users about migration to the new domain: &lt;strong&gt;uptimechecker.org&lt;/strong&gt;. This was all we could do, and we would do that even earlier, but we hoped urgent problem like this will be handled earlier by &lt;strong&gt;domain.com&lt;/strong&gt;, however, we were terribly wrong.&lt;/p&gt;
&lt;p&gt;One week after the migration, &lt;strong&gt;uptimechecker.io&lt;/strong&gt; started working again (we still don't have control over our domain, but somehow DNS servers are reverted to correct values). They still didn't updated the ticket, we don't know how they fixed this, is it going to work permanently, or this is only temporary fix - again, &lt;strong&gt;zero information&lt;/strong&gt; from them. I contacted live support again, they said it works now because &quot;they are working on the issue&quot;, and that specialist will update ticket - and guess what, they didn't.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;I know this all sounds unbelievable, and if someone told me such story probably I would not believe also, so, at the end of this post, you can find &lt;strong&gt;full text of this ticket&lt;/strong&gt;. Sadly, all said in this post is &lt;strong&gt;true&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;While we are still waiting to regain control of our domain, UptimeChecker will continue to work both on uptimechecker.org and uptimechecker.io. To avoid situations like this to happen in the future, we will transfer all our domains out of &lt;strong&gt;domain.com&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So, to conclude, be aware of your Domain registrar, and be careful who you work with, because domain problem like this is one of the worst thing can happen to your business:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;You can't do anything to fix the issue&lt;/li&gt;
&lt;li&gt;Your users cannot access the service at all&lt;/li&gt;
&lt;li&gt;They can't event send you email to ask about the problem: (email address cannot be resolved also)&lt;/li&gt;
&lt;li&gt;Your ranks on Google will be destroyed (uptimechecker.io was completely removed from Google search results)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;We value our users, and we are really sorry this happened, but it was out of our control. We apologize one more time to all of you, we did only thing we could to minimize the impact of the problem, and we hope you will stay with us :)&lt;/p&gt;
&lt;p&gt;If you are new to UptimeChecker, you can &lt;a href=&quot;https://www.uptimechecker.io/accounts/create-account&quot;&gt;try our service&lt;/a&gt; with all features totally free for 14 days! And if you become our user, we promise we will never let you down like our registrar did with us!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Here you can find whole ticket, without any modifications:&lt;/strong&gt; &lt;img src=&quot;https://www.uptimechecker.io/Content/images/blog/domain_com_ticket.png&quot;/&gt;&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Wed, 16 May 2018 15:47:54 +0000</pubDate>
<dc:creator>richeyrw</dc:creator>
<og:title>Be aware: How domain registrar can kill your business</og:title>
<og:type>article</og:type>
<og:image>https://www.uptimechecker.io/Content/images/blog/alert_sign.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.uptimechecker.io/blog/how-domain-registrar-can-kill-your-business</dc:identifier>
</item>
<item>
<title>Browser extension that strips Google Analytics tokens from URL query strings</title>
<link>https://github.com/jparise/chrome-utm-stripper</link>
<guid isPermaLink="true" >https://github.com/jparise/chrome-utm-stripper</guid>
<description>&lt;h3&gt;README.md&lt;/h3&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;
&lt;p&gt;This is a Chrome and Firefox browser extension that strips Google Analytics (i.e. &lt;a href=&quot;https://support.google.com/urchin/answer/28307?hl=en&quot; rel=&quot;nofollow&quot;&gt;Urchin Tracking Monitor&lt;/a&gt;) tokens from URL query strings. This is done &lt;em&gt;before&lt;/em&gt; the web request is made and results in both more private browsing as well as more aesthetically-pleasing URLs.&lt;/p&gt;
&lt;p&gt;Install from the &lt;a href=&quot;https://chrome.google.com/webstore/detail/kcpnkledgcbobhkgimpbmejgockkplob&quot; rel=&quot;nofollow&quot;&gt;Chrome Web Store&lt;/a&gt; or &lt;a href=&quot;https://addons.mozilla.org/addon/utm-tracking-token-stripper/&quot; rel=&quot;nofollow&quot;&gt;Firefox Add-ons&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The following &lt;a href=&quot;http://www.google.com/support/analytics/bin/answer.py?answer=55578&quot; rel=&quot;nofollow&quot;&gt;Google Analytics query string parameters&lt;/a&gt; are stripped:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;utm_source&lt;/li&gt;
&lt;li&gt;utm_medium&lt;/li&gt;
&lt;li&gt;utm_term&lt;/li&gt;
&lt;li&gt;utm_campaign&lt;/li&gt;
&lt;li&gt;utm_content&lt;/li&gt;
&lt;li&gt;utm_cid&lt;/li&gt;
&lt;li&gt;utm_reader&lt;/li&gt;
&lt;li&gt;utm_name&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;This extension requires these &lt;a href=&quot;https://developer.chrome.com/extensions/declare_permissions&quot; rel=&quot;nofollow&quot;&gt;permissions&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;webRequest&lt;/code&gt;, to use the &lt;a href=&quot;https://developer.chrome.com/extensions/webRequest&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;chrome.webRequest&lt;/code&gt; API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;webRequestBlocking&lt;/code&gt;, to use &lt;code&gt;chrome.webRequest&lt;/code&gt; in a blocking fashion&lt;/li&gt;
&lt;li&gt;&lt;code&gt;http://*/*?*&lt;/code&gt;, to filter http URLs&lt;/li&gt;
&lt;li&gt;&lt;code&gt;https://*/*?*&lt;/code&gt;, to filter https URLs&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;a href=&quot;http://www.openclipart.org/detail/69997&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://github.com/jparise/chrome-utm-stripper/raw/master/icon-128.png&quot; alt=&quot;Urchin Logo&quot; title=&quot;Urchin Logo&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.openclipart.org/detail/69997&quot; rel=&quot;nofollow&quot;&gt;Urchin Logo&lt;/a&gt; by Jordan Irwin / Deluge.&lt;/p&gt;
&lt;/article&gt;</description>
<pubDate>Wed, 16 May 2018 15:35:29 +0000</pubDate>
<dc:creator>falcon620</dc:creator>
<og:image>https://avatars2.githubusercontent.com/u/10311?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>jparise/chrome-utm-stripper</og:title>
<og:url>https://github.com/jparise/chrome-utm-stripper</og:url>
<og:description>chrome-utm-stripper - Browser extension that strips Google Analytics (UTM) tokens from URL query strings</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/jparise/chrome-utm-stripper</dc:identifier>
</item>
</channel>
</rss>