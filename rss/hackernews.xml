<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>The Super-Rich Are Stockpiling Wealth in Black-Box Charities</title>
<link>https://www.bloomberg.com/news/articles/2018-10-03/the-super-rich-are-stockpiling-wealth-in-black-box-charities</link>
<guid isPermaLink="true" >https://www.bloomberg.com/news/articles/2018-10-03/the-super-rich-are-stockpiling-wealth-in-black-box-charities</guid>
<description>[unable to retrieve full-text content]
&lt;p&gt;Article URL: &lt;a href=&quot;https://www.bloomberg.com/news/articles/2018-10-03/the-super-rich-are-stockpiling-wealth-in-black-box-charities&quot;&gt;https://www.bloomberg.com/news/articles/2018-10-03/the-super-rich-are-stockpiling-wealth-in-black-box-charities&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=18129571&quot;&gt;https://news.ycombinator.com/item?id=18129571&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Points: 203&lt;/p&gt;
&lt;p&gt;# Comments: 183&lt;/p&gt;
</description>
<pubDate>Wed, 03 Oct 2018 12:38:30 +0000</pubDate>
<dc:creator>petethomas</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.bloomberg.com/tosv2.html?vid=&amp;uuid=925b8970-c725-11e8-9fdd-dd13d01d387c&amp;url=L25ld3MvYXJ0aWNsZXMvMjAxOC0xMC0wMy90aGUtc3VwZXItcmljaC1hcmUtc3RvY2twaWxpbmctd2VhbHRoLWluLWJsYWNrLWJveC1jaGFyaXRpZXM=</dc:identifier>
</item>
<item>
<title>Why I’m Worried About Google</title>
<link>https://slate.com/technology/2018/10/google-is-losing-users-trust.html</link>
<guid isPermaLink="true" >https://slate.com/technology/2018/10/google-is-losing-users-trust.html</guid>
<description>&lt;div class=&quot;lazy-container&quot;&gt;&lt;img class=&quot;image__src&quot; data-normal=&quot;https://compote.slate.com/images/f24d6acd-5773-4a50-8b80-e40bd3f78b9a.jpeg?width=780&amp;amp;height=520&amp;amp;rect=1400x933&amp;amp;offset=0x0&quot; data-retina=&quot;https://compote.slate.com/images/f24d6acd-5773-4a50-8b80-e40bd3f78b9a.jpeg?width=780&amp;amp;height=520&amp;amp;rect=1400x933&amp;amp;offset=0x0&quot; data-srcset=&quot;https://compote.slate.com/images/f24d6acd-5773-4a50-8b80-e40bd3f78b9a.jpeg?width=780&amp;amp;height=520&amp;amp;rect=1400x933&amp;amp;offset=0x0 1x, https://compote.slate.com/images/f24d6acd-5773-4a50-8b80-e40bd3f78b9a.jpeg?width=780&amp;amp;height=520&amp;amp;rect=1400x933&amp;amp;offset=0x0 2x&quot; alt=&quot;Google logo with the O's looking like spying eyes.&quot;/&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img src=&quot;https://compote.slate.com/images/f24d6acd-5773-4a50-8b80-e40bd3f78b9a.jpeg?width=780&amp;amp;height=520&amp;amp;rect=1400x933&amp;amp;offset=0x0&quot; alt=&quot;Google logo with the O's looking like spying eyes.&quot; srcset=&quot;https://compote.slate.com/images/f24d6acd-5773-4a50-8b80-e40bd3f78b9a.jpeg?width=780&amp;amp;height=520&amp;amp;rect=1400x933&amp;amp;offset=0x0 1x, https://compote.slate.com/images/f24d6acd-5773-4a50-8b80-e40bd3f78b9a.jpeg?width=780&amp;amp;height=520&amp;amp;rect=1400x933&amp;amp;offset=0x0 2x&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/div&gt;

&lt;p&gt;Photo illustration by Slate. Photo by korionov/iStock.&lt;/p&gt;
&lt;aside data-uri=&quot;slate.com/_components/partner-branding/instances/cjms78ji5000d3h5tgmft712u@published&quot; class=&quot;partner-branding futureTense&quot; data-editable=&quot;partnerBranding&quot; readability=&quot;1.2876712328767&quot;&gt;
&lt;div class=&quot;partner-branding__logo&quot;&gt;&lt;img src=&quot;https://slate.com/media/components/partner-branding/partner-logo-future-tense.png&quot; alt=&quot;Future Tense&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;partner-branding__text&quot; readability=&quot;21.890410958904&quot;&gt;&lt;a href=&quot;http://www.slate.com/articles/technology/future_tense/2012/03/future_tense_emerging_technologies_society_and_policy_.html&quot;&gt;Future Tense&lt;/a&gt; is a partnership of &lt;a href=&quot;https://slate.com&quot;&gt;Slate&lt;/a&gt;, &lt;a href=&quot;https://www.newamerica.org/&quot;&gt;New America&lt;/a&gt;, and &lt;a href=&quot;http://www.asu.edu/?feature=research&quot;&gt;Arizona State University&lt;/a&gt; that examines emerging technologies, public policy, and society.&lt;/div&gt;
&lt;/aside&gt;&lt;aside data-uri=&quot;slate.com/_components/in-article-recirc/instances/cjms76z61000nnrkzfra9ffl5@published&quot; class=&quot;in-article-recirc&quot; data-editable=&quot;settings&quot; data-via=&quot;article-inline_recirc-tag-privacy&quot;&gt;
&lt;ol class=&quot;in-article-recirc__list&quot;&gt;&lt;li class=&quot;in-article-recirc__item&quot;&gt;&lt;a href=&quot;https://slate.com/technology/2018/09/data-brokers-senate-hearing-privacy.html&quot; class=&quot;in-article-recirc__link&quot;&gt;We’re Finally Having a Real Conversation About Privacy. Why Aren’t We Looking Closely at Data Brokers?&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;in-article-recirc__item&quot;&gt;&lt;a href=&quot;https://slate.com/technology/2018/08/google-mastercard-data-track-offline-purchases.html&quot; class=&quot;in-article-recirc__link&quot;&gt;Report: Google Tracks What You Buy Offline Using Data from Mastercard&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;in-article-recirc__item&quot;&gt;&lt;a href=&quot;https://slate.com/technology/2018/08/how-australias-my-health-record-program-became-opt-out-violating-citizens-privacy.html&quot; class=&quot;in-article-recirc__link&quot;&gt;Australia’s Digital Health Records Program Went From Opt-In to Opt-Out. Chaos Ensued.&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;in-article-recirc__item&quot;&gt;&lt;a href=&quot;https://slate.com/technology/2018/08/facebook-and-googles-plan-for-a-new-federal-privacy-law-is-really-about-protecting-themselves.html&quot; class=&quot;in-article-recirc__link&quot;&gt;Big Tech’s Push for a New Privacy Law Is Really About Protecting Itself&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/aside&gt;&lt;p class=&quot;slate-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;slate.com/_components/slate-paragraph/instances/cjms76z61000onrkz4ju2jxwp@published&quot; data-word-count=&quot;68&quot;&gt;A couple of weeks ago, I noticed something strange was happening to my Google Chrome web browser. Where Chrome had always allowed me to browse the internet as an anonymous user, suddenly my browser had signed itself into my Google account. A bit of investigation (and a visit to a nerd forum) pointed me to the cause: &lt;a href=&quot;https://blog.cryptographyengineering.com/2018/09/23/why-im-leaving-chrome/&quot;&gt;Chrome had logged itself in&lt;/a&gt; after I visited my Gmail account.&lt;/p&gt;
&lt;p class=&quot;slate-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;slate.com/_components/slate-paragraph/instances/cjms78xq2000u3h5tcejqgwgb@published&quot; data-word-count=&quot;159&quot;&gt;The change in Chrome’s behavior, it turns out, was not a bug. It’s part of a new technical “feature” in the browser called “identity consistency between browser and cookie jar.” Despite the gritty technical name of the feature, it represents a truly fundamental change in the way Chrome works. For the first 10 years of Chrome’s existence, Chrome was simply a typical web browser. You had the option to sign the browser into Google—and thus take advantage of Google’s many data-sharing and cloud-synchronization options—but you never had to. In the stroke of an update, the sign-in became mandatory: If you happened to visit a Google property, the browser would attach itself to your Google account. To Google’s credit, it recognizes the privacy implications of this change, and simply signing the browser into Google does not immediately send your data to Google’s servers. But it brings users within an accidental click of sharing their bookmarks and browsing history with Google.&lt;/p&gt;



&lt;p class=&quot;slate-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;slate.com/_components/slate-paragraph/instances/cjms78xpt000t3h5t3c755piy@published&quot; data-word-count=&quot;91&quot;&gt;After I &lt;a href=&quot;https://blog.cryptographyengineering.com/2018/09/23/why-im-leaving-chrome/&quot;&gt;wrote about&lt;/a&gt; the change, I was taken aback by the tech community’s vociferous &lt;a href=&quot;https://news.ycombinator.com/item?id=18052923&quot;&gt;response&lt;/a&gt;. It seems that many technical professionals feel the same way I do: that their web browser should be just a web browser, rather than an arm of Google’s online juggernaut. The tech backlash even caused Google to back down, sort of. It &lt;a href=&quot;https://www.blog.google/products/chrome/product-updates-based-your-feedback/&quot;&gt;announced&lt;/a&gt; a forthcoming update last Wednesday: Chrome’s auto-sign-in feature will still be the default behavior of Chrome. But you’ll be able to turn it off through an optional switch buried in Chrome’s settings.&lt;/p&gt;
&lt;p class=&quot;slate-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;slate.com/_components/slate-paragraph/instances/cjms78xp0000p3h5tkglvarlh@published&quot; data-word-count=&quot;104&quot;&gt;This pattern of behavior by tech companies is so routine that we take it for granted. Let’s call it “pulling a Facebook” in honor of the many times that Facebook has “accidentally” &lt;a href=&quot;https://www.nytimes.com/2018/06/07/technology/facebook-privacy-bug.html&quot;&gt;relaxed&lt;/a&gt; &lt;a href=&quot;https://www.theguardian.com/technology/2016/jun/29/facebook-privacy-secret-profile-exposed&quot;&gt;the&lt;/a&gt; &lt;a href=&quot;https://www.forbes.com/sites/thomasbrewster/2016/06/29/facebook-location-tracking-friend-games/#2dcfebff35f9&quot;&gt;privacy&lt;/a&gt; &lt;a href=&quot;https://gizmodo.com/facebook-is-giving-advertisers-access-to-your-shadow-co-1828476051&quot;&gt;settings&lt;/a&gt; for user profile data, and then—following a bout of bad press coverage—apologized and quietly &lt;a href=&quot;https://www.consumerreports.org/privacy/facebook-changes-settings-after-cr-investigation/&quot;&gt;reversed course&lt;/a&gt;. A key feature of these episodes is that management rarely takes the blame: It’s usually laid at the feet of some anonymous engineer moving fast and breaking things. Maybe it’s just a coincidence that these changes consistently err in the direction of increasing “user engagement” and never make your experience more private.&lt;/p&gt;





&lt;p class=&quot;slate-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;slate.com/_components/slate-paragraph/instances/cjms78xpc000r3h5twvtcomyi@published&quot; data-word-count=&quot;109&quot;&gt;What’s new here, and is a very recent development indeed, is that we’re finally starting to see that this approach has costs. For example, it now seems like Facebook executives spend an awful lot of time &lt;a href=&quot;https://www.washingtonpost.com/news/the-switch/wp/2018/04/11/zuckerberg-facebook-hearing-congress-house-testimony/?noredirect=on&quot;&gt;answering questions&lt;/a&gt; &lt;a href=&quot;https://www.cnet.com/g00/news/heres-what-facebooks-twitters-apology-tour-to-congress-looked-like-up-close/?i10c.encReferrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8%3D&amp;amp;i10c.ua=1&amp;amp;i10c.dv=14&quot;&gt;in front of Congress&lt;/a&gt;. In 2017, when Facebook announced it had handed more than 80 million user profiles to the sketchy election strategy firm &lt;a href=&quot;https://www.theguardian.com/commentisfree/2018/apr/16/how-many-people-data-cambridge-analytica-facebook&quot;&gt;Cambridge Analytica&lt;/a&gt;, Facebook received surprisingly little sympathy and a notable stock drop. Losing the trust of your users, we’re learning, does not immediately make them flee your business. But it does matter. It’s just that the consequences are cumulative, like spending too much time in the sun.&lt;/p&gt;
&lt;p class=&quot;slate-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;slate.com/_components/slate-paragraph/instances/cjms78xp6000q3h5tafza75j5@published&quot; data-word-count=&quot;75&quot;&gt;It’s this background that makes Google’s recent changes to Chrome so surprising. Google is the one major Silicon Valley firm that has avoided much of the tech backlash that’s spattering its peers. While the idea that Google is doing &lt;em&gt;better&lt;/em&gt; than those companies might seem strange—Google is one of the biggest data collectors in the world, after all—I would argue that to a large extent, this is because Google has invested massively building user trust.&lt;/p&gt;

&lt;p class=&quot;slate-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;slate.com/_components/slate-paragraph/instances/cjms78xpk000s3h5tj7m9m5jv@published&quot; data-word-count=&quot;147&quot;&gt;This investment takes various forms. First, Google has &lt;a href=&quot;https://cloud.google.com/security/infrastructure/design/&quot;&gt;invested&lt;/a&gt; &lt;a href=&quot;https://www.sslsupportdesk.com/google-makes-certificate-transparency-mandatory-chrome/&quot;&gt;relentlessly&lt;/a&gt; in securing its infrastructure: When it was hacked (allegedly by China) in 2010, the company not only &lt;a href=&quot;https://www.businessinsider.com/google-pulls-out-of-china-2010-3&quot;&gt;pulled out&lt;/a&gt; of China, but it poured resources into hardening its systems, and even moved its security team into a dedicated building at the edge of their Mountain View campus to thwart physical espionage. Google security engineers brag that they can go toe-to-toe with nation-states, and they back this up by providing &lt;a href=&quot;https://www.zdnet.com/article/google-well-warn-you-if-government-hackers-are-attacking-your-company-email/&quot;&gt;nation-state hacking warnings&lt;/a&gt; to at-risk users like &lt;a href=&quot;https://arstechnica.com/information-technology/2016/11/google-warns-journalists-and-professors-your-account-is-under-attack/&quot;&gt;journalists, politicians, and professors&lt;/a&gt;. On the privacy front, Google is the king of targeted advertising, but it largely avoids controversial and upsetting privacy changes like the ones that plague Facebook. Sure, it collects gobs of data, but it’s generally been upfront about what it takes and what it doesn’t. And &lt;a href=&quot;https://www.nytimes.com/2018/09/28/technology/facebook-hack-data-breach.html&quot;&gt;unlike Facebook&lt;/a&gt;, the company almost never loses your data to hackers.&lt;/p&gt;

&lt;p class=&quot;slate-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;slate.com/_components/slate-paragraph/instances/cjms78xr700123h5tawxe03vd@published&quot; data-word-count=&quot;102&quot;&gt;This pro-security strategy has produced tangible benefits for Google. Even when invisible to the average person, it’s helped to build trust with highly technical users who generally serve as ambassadors and an informal “IT help-desk” for everyone else. More critically, it’s allowed Google the breathing room to quietly improve its data collection and advertising businesses without the embarrassing congressional testimony and distractions of a Cambridge Analytica. Of course, the fact that Google is so ubiquitous means that it can afford to be magnanimous: There’s no need to push the privacy envelope with users when you’re already getting so much of their data.&lt;/p&gt;



&lt;p&gt;&lt;span class=&quot;pull-quote__text&quot; data-editable=&quot;quote&quot;&gt;I fear Google is well on the way to becoming a different kind of&lt;span class=&quot;widont&quot;&gt; &lt;/span&gt;company.&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;slate-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;slate.com/_components/slate-paragraph/instances/cjms78xr1000y3h5tb55tv9h8@published&quot; data-word-count=&quot;163&quot;&gt;But the recent Chrome changes indicate that Google is not immune to the same pressures that apply to other companies. And while the Chrome update may be only a small sign of that pressure, it’s hardly the most troubling one. For example, Google recently inked a &lt;a href=&quot;https://www.bloomberg.com/news/articles/2018-08-30/google-and-mastercard-cut-a-secret-ad-deal-to-track-retail-sales&quot;&gt;secret deal with Mastercard&lt;/a&gt; to link your credit card transaction information to your web browsing. We can only guess at what it hopes to do with this data. And of course, this summer, the Intercept &lt;a href=&quot;https://theintercept.com/2018/08/01/google-china-search-engine-censorship/&quot;&gt;leaked an internal memo&lt;/a&gt; showing that Google is even considering a move back into China, building a custom search engine code-named “Dragonfly” that will systematically track Chinese users, while providing censored search results that remove results for terms like “human rights.” Google has for its part claimed that the project was only “exploratory,” though this explanation &lt;a href=&quot;https://theintercept.com/2018/09/21/google-suppresses-memo-revealing-plans-to-closely-track-search-users-in-china/&quot;&gt;is disputed&lt;/a&gt;. It’s hard to see Google retaining a strong reputation for privacy if it deploys systems like this to a large fraction of the world.&lt;/p&gt;




&lt;p class=&quot;slate-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;slate.com/_components/slate-paragraph/instances/cjms78xqv000v3h5tk5ud0tw4@published&quot; data-word-count=&quot;83&quot;&gt;In short, I fear Google is well on the way to becoming a different kind of company, and it worries me. This is not because I inherently love Google—it’s a profit-making entity, and its shareholders will always come before me. But I worry that it is increasingly trading away my trust for short-term benefits. Even worse, this course change indicates that companies’ self-interest in maintaining user trust may not be a match for the business pressures that drive them to become more intrusive.&lt;/p&gt;
&lt;p class=&quot;slate-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;slate.com/_components/slate-paragraph/instances/cjms78xr0000x3h5tiz72ur89@published&quot; data-word-count=&quot;70&quot;&gt;Of course, some might say that I’m a fool for ever relying on Google products, that I deserve whatever I get for becoming enmeshed in the Google ecosystem. The more extreme version of the argument holds that people who expect privacy must avoid tools like Chrome and Facebook altogether, as though privacy is a value we should all suffer for—and one that is the exclusive right of the technical elite.&lt;/p&gt;

&lt;p class=&quot;slate-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;slate.com/_components/slate-paragraph/instances/cjms78xqw000w3h5tc4vqw4wr@published&quot; data-word-count=&quot;54&quot;&gt;I reject this argument. It’s entirely possible for a company like Google to make good, usable products that strike a balance between privacy and profit. It’s just that without some countervailing pressure forcing Google to hold up their end of the bargain, it’s going to be increasingly hard for Google executives to justify it.&lt;/p&gt;

&lt;p class=&quot;slate-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;slate.com/_components/slate-paragraph/instances/cjms78xr300103h5ttob2h57e@published&quot; data-word-count=&quot;28&quot;&gt;In the end, this is why I’m moving away from the Google ecosystem. If nothing else works, then at least I can vote with my feet—or my fingertips.&lt;/p&gt;
&lt;p class=&quot;slate-paragraph&quot; data-editable=&quot;text&quot; data-uri=&quot;slate.com/_components/slate-paragraph/instances/cjms78xr400113h5t2nn4pggl@published&quot; data-word-count=&quot;15&quot;&gt;&lt;em&gt;Disclosures: From 2014–15, Matthew Green received a grant from Google’s Advanced Technologies and Projects division.&lt;/em&gt;&lt;/p&gt;
&lt;p class=&quot;slate-paragraph slate-paragraph--tombstone&quot; data-editable=&quot;text&quot; data-uri=&quot;slate.com/_components/slate-paragraph/instances/cjms78xr800133h5tyfal07y2@published&quot; data-word-count=&quot;75&quot;&gt;&lt;em&gt;Slate is a partner with New America and Arizona State University in Future Tense. Google has donated money to New America, a think tank, as has former Google executive chairman and CEO Eric Schmidt, who also once served as chair of New America’s board. In August 2017, a former New America employee who was critical of Google alleged that he was fired because Schmidt, held undue influence at the organization, a charge New America denied.&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 03 Oct 2018 12:09:52 +0000</pubDate>
<dc:creator>DyslexicAtheist</dc:creator>
<og:title>Why One Tech Security Expert Is Increasingly Worried About Google</og:title>
<og:url>https://slate.com/technology/2018/10/google-is-losing-users-trust.html</og:url>
<og:description>I worry Google is trading away my trust for a short-term benefit.</og:description>
<og:image>https://compote.slate.com/images/f24d6acd-5773-4a50-8b80-e40bd3f78b9a.jpeg?width=780&amp;height=520&amp;rect=1400x933&amp;offset=0x0</og:image>
<og:type>article</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://slate.com/technology/2018/10/google-is-losing-users-trust.html</dc:identifier>
</item>
<item>
<title>It doesn&amp;#039;t have to be crazy at work</title>
<link>https://basecamp.com/books/calm</link>
<guid isPermaLink="true" >https://basecamp.com/books/calm</guid>
<description>&lt;a class=&quot;calm__mock grid__item grid__item--max&quot; href=&quot;https://www.barnesandnoble.com/w/it-doesnt-have-to-be-crazy-at-work-jason-fried/1128018111?ean=9780062874788&quot; target=&quot;_blank&quot;&gt;&lt;img srcset=&quot;/assets/books/calm-mock-0f4b60974b3db713605e015693fc4523ff0c409cfa28f4b35de4ca459ec3c150.jpg 1x, /assets/books/calm-mock@2x-17927ec974d5b776fd4e5df66d873fc85a00ab68e82536e90fc9eff62c87c133.jpg 2x&quot; src=&quot;https://basecamp.com/assets/books/calm-mock-0f4b60974b3db713605e015693fc4523ff0c409cfa28f4b35de4ca459ec3c150.jpg&quot; alt=&quot;It doesn't have to be crazy at work&quot;/&gt;&lt;/a&gt;&lt;p class=&quot;intro centered&quot;&gt;By Jason Fried and David Heinemeier Hansson&lt;/p&gt;
&lt;hr class=&quot;push--top push_double--bottom&quot;/&gt;&lt;p class=&quot;centered grid__item grid__item--xlarge&quot;&gt;&lt;a class=&quot;book-purchase&quot; href=&quot;https://www.amazon.com/Doesnt-Have-Be-Crazy-Work/dp/0062874780/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://basecamp.com/assets/books/amazon-cbf96dacc6b6a01cffdea4feb224118d2bbd5e213db6fb4c1276757d7814ce56.jpg&quot; width=&quot;117&quot; height=&quot;52&quot; alt=&quot;Amazon.com&quot;/&gt;&lt;/a&gt;  &lt;a class=&quot;book-purchase&quot; href=&quot;https://www.barnesandnoble.com/w/it-doesnt-have-to-be-crazy-at-work-jason-fried/1128018111&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://basecamp.com/assets/books/bn-abeaad794f37b535df1c08d79d731de6673be473e33d3f2c5832577496a7601e.jpg&quot; width=&quot;117&quot; height=&quot;52&quot; alt=&quot;Barnes and Noble&quot;/&gt;&lt;/a&gt;  &lt;a class=&quot;book-purchase&quot; href=&quot;https://itunes.apple.com/us/book/it-doesnt-have-to-be-crazy-at-work/id1350572012&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://basecamp.com/assets/books/ibooks-3b7fccd2ef650862db075714ad323fb9198d2229dec8468ba0007b9e61594b17.jpg&quot; width=&quot;117&quot; height=&quot;52&quot; alt=&quot;iBooks&quot;/&gt;&lt;/a&gt;  &lt;a class=&quot;book-purchase&quot; href=&quot;https://www.indiebound.org/book/9780062874788&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://basecamp.com/assets/books/indie-66afa860201176112fb9c99121761b3b1d1ac1ebd4af0e62b0740db62f326fe6.jpg&quot; width=&quot;117&quot; height=&quot;52&quot; alt=&quot;indiebound&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;small grid__item grid__item--small centered&quot;&gt;&lt;strong&gt;In the UK, Australia, or New Zealand? “It Doesn't Have to Be Crazy at Work” comes out October 4th.&lt;/strong&gt;&lt;/p&gt;
&lt;hr class=&quot;push--top push_double--bottom&quot;/&gt;&lt;p&gt;&lt;strong&gt;“It’s crazy at work.”&lt;/strong&gt; How often have you heard that? Or said it yourself? Probably too often.&lt;/p&gt;
&lt;p&gt;For many, “it’s crazy at work” has become their normal. But why's that?&lt;/p&gt;
&lt;p&gt;At the root is an onslaught of physical and virtual real-time distractions slicing work days into a series of fleeting work moments.&lt;/p&gt;
&lt;p&gt;Tie that together with a trend of over-collaboration, plus an unhealthy obsession with growth at any cost, and you’ve got the building blocks for an anxious, crazy mess.&lt;/p&gt;
&lt;p&gt;It’s no wonder people are working longer, earlier, later, on weekends, and whenever they have a spare moment. People can’t get work done at work anymore.&lt;/p&gt;
&lt;p&gt;Work claws away at life. Life has become work’s leftovers. The doggy bag. The remnants. The scraps.&lt;/p&gt;
&lt;p&gt;That’s just not OK. It’s unacceptable.&lt;/p&gt;
&lt;p&gt;What’s worse is that long hours, excessive busyness, and lack of sleep have become a badge of honor for many people these days. Sustained exhaustion is not a badge of honor, it’s a mark of stupidity. Companies that force their crew into this bargain are cooking up dumb at their employees’ expense.&lt;/p&gt;
&lt;p&gt;And it’s not just about organizations — individuals, contractors, and solopreneurs are burning themselves out the very same way.&lt;/p&gt;
&lt;p&gt;You’d think with all the hours people are putting in, and all the promises of tech’s flavor of the month, the load would be lessening. It’s not. It’s getting heavier.&lt;/p&gt;
&lt;p&gt;But the thing is, there’s not more work to be done all of the sudden. The problem is there’s hardly any uninterrupted, dedicated time to do it.&lt;/p&gt;
&lt;p&gt;Working more but getting less done? It doesn’t add up. But it does — it adds up to a majority of time wasted on things that don’t matter.&lt;/p&gt;
&lt;p&gt;Many modern companies seem to be great at one thing: wasting. Wasting time, attention, money, energy.&lt;/p&gt;
&lt;p&gt;Out of the 60, 70, 80 hours a week many are expected to pour into work, how many of those hours are really spent on the work itself? And how many are tossed away in meetings, lost to distraction, and withered away by inefficient business practices? The bulk.&lt;/p&gt;
&lt;p&gt;The answer isn’t more hours, it’s less bullshit. Less waste, not more production. And far fewer things that induce distraction, always-on anxiety, and stress.&lt;/p&gt;
&lt;p&gt;Stress is an infection passed down from organization to employee, from employee to employee, and then from employee to customer. And it’s becoming resistant to traditional treatments. The same old medicine is only making it worse.&lt;/p&gt;
&lt;p&gt;And remember, stress can not be contained. It never stops at the edge of work. It always bleeds into life. It infects your relationships with your friends, your family, your kids.&lt;/p&gt;
&lt;p&gt;The promises keep coming. More time management hacks. More ways to communicate. More information spread across separate platforms and disparate places. New demands to pay attention to more and more real-time conversations happening all the time at work. Faster and faster, for what? Panaceas left and right. Snake oil.&lt;/p&gt;
&lt;p&gt;On-demand is for movies, TV shows, and podcasts, not for you. Your time isn’t an episode recalled when someone wants it at 10pm on a Saturday night, or every few minutes in the collection of conveyor belt chat room conversations you’re supposed to be following all day long.&lt;/p&gt;
&lt;p&gt;If it’s constantly crazy at work, we have two words for you: Fuck that. And two more: Enough already.&lt;/p&gt;
&lt;p&gt;At the heart of it all is an unhealthy obsession with rapid growth. Towering, unrealistic expectations drag people down.&lt;/p&gt;
&lt;p&gt;It’s time for companies to stop asking their employees to breathlessly chase ever-higher, ever-more artificial targets set by ego, not need. It’s time to stop celebrating this way of working.&lt;/p&gt;
&lt;p&gt;Over the last 18 years we’ve been working at making Basecamp a calm company. One that isn’t fueled by stress, or ASAP, or rushing, or late nights, or all-nighter crunches, or impossible promises, or high turnover, or over-collaboration, or consistently missed deadlines, or projects that never seem to end, or manufactured busywork, or incorrect assumptions that lead to systemic institutional anxiety.&lt;/p&gt;
&lt;p&gt;No growth-at-all-costs. No constant, churning false busyness. No ego-driven decisions. No keeping up with the Joneses Corporation. No hair on fire.&lt;/p&gt;
&lt;p&gt;And yet we’ve been profitable every year since the beginning. We’ve kept our company intentionally small — we believe small is a key to calm.&lt;/p&gt;
&lt;p&gt;As a tech company we’re supposed to be playing the hustle game in Silicon Valley, but we’re blissfully far away in Chicago with employees working remotely in 30 different towns around the world.&lt;/p&gt;
&lt;p&gt;We each put in about 40 hours a week most of the year, and just 32-hour four-day weeks in the summer. We send people on month-long sabbaticals every three years. We not only pay for people’s vacation time, but we pay for the actual vacation too.&lt;/p&gt;
&lt;p&gt;No, not 9pm Wednesday night. It can wait until 9am Thursday morning. No, not Sunday. Monday.&lt;/p&gt;
&lt;p&gt;Walk into our office and it feels more like a library and less like a chaotic kitchen. Noise and movement are not indicator of activity and progress — they’re just indicators of noise and movement.&lt;/p&gt;
&lt;p&gt;We’re in one of the most competitive industries in the world. An industry dominated by giants and frequent upstarts backed by hundreds of millions of dollars in VC money. We’ve taken zero. Where does our money come from? Our customers. They buy what we’re selling and we treat them exceptionally well. Call us old fashioned.&lt;/p&gt;
&lt;p&gt;Our benefits are focused on getting people out of the office, not enticing them to stay longer. Fresh fruits and veggies are delivered to people’s houses, not the kitchen at work. Want to learn to play the guitar in your own time? We’ll gladly support you and pay for that too.&lt;/p&gt;
&lt;p&gt;We’ll pay for you to get a massage, but we won’t bring the masseuse to the office. Loosening up for 60 minutes only to tense back up hunched over your desk is faux relaxation. No “stay here” signals. Everything’s about wrapping up your reasonable day, going home, and living your life.&lt;/p&gt;
&lt;p&gt;Are there occasionally stressful moments? Sure — such is life. Is every day peachy? Of course not — we’d be lying if we said it was. But we do our best to make sure those are the exceptions. On balance we’re calm — by choice, by practice. We’re intentional about it. We’ve made different decisions than the rest.&lt;/p&gt;
&lt;p&gt;We’ve designed our company differently. We’re here to tell you about it, and show you how you can do it. There’s a path. You’ve got to want it, but if you do you’ll realize it’s much nicer over here. You can have a calm company too.&lt;/p&gt;
&lt;p&gt;This book points out the diseases plaguing modern workplace and work methods. It calls out false cures, and pushes back against ritualistic time-sucks that have infected the way people work these days. We have a prescription to make it better.&lt;/p&gt;
&lt;p&gt;Chaos should not be the natural state at work. Anxiety isn’t a prerequisite for progress. Sitting in meetings all day isn’t required for success. These are all perversions of work — side effects of broken models and follow-the-lemming-off-the-cliff worst practices. Step aside and let the suckers jump.&lt;/p&gt;
&lt;p&gt;Calm is profitability.&lt;br/&gt;Calm is protecting people’s time and attention.&lt;br/&gt;Calm is reasonable expectations.&lt;br/&gt;Calm is about 40 hours of work a week.&lt;br/&gt;Calm is ample time off.&lt;br/&gt;Calm is smaller.&lt;br/&gt;Calm is a visible horizon.&lt;br/&gt;Calm is meetings as a last resort.&lt;br/&gt;Calm is contextual communication.&lt;br/&gt;Calm is asynchronous first, real-time second.&lt;br/&gt;Calm is more independence, less interdependence.&lt;br/&gt;Calm is about sustainable practices that can run for the long-term.&lt;/p&gt;
&lt;p&gt;By the end of the book you’ll understand it all.&lt;/p&gt;
&lt;hr class=&quot;push_double--top push_double--bottom&quot;/&gt;&lt;p class=&quot;centered grid__item grid__item--xlarge&quot;&gt;&lt;a class=&quot;book-purchase&quot; href=&quot;https://www.amazon.com/Doesnt-Have-Be-Crazy-Work/dp/0062874780/&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://basecamp.com/assets/books/amazon-cbf96dacc6b6a01cffdea4feb224118d2bbd5e213db6fb4c1276757d7814ce56.jpg&quot; width=&quot;117&quot; height=&quot;52&quot; alt=&quot;Amazon.com&quot;/&gt;&lt;/a&gt;  &lt;a class=&quot;book-purchase&quot; href=&quot;https://www.barnesandnoble.com/w/it-doesnt-have-to-be-crazy-at-work-jason-fried/1128018111&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://basecamp.com/assets/books/bn-abeaad794f37b535df1c08d79d731de6673be473e33d3f2c5832577496a7601e.jpg&quot; width=&quot;117&quot; height=&quot;52&quot; alt=&quot;Barnes and Noble&quot;/&gt;&lt;/a&gt;  &lt;a class=&quot;book-purchase&quot; href=&quot;https://itunes.apple.com/us/book/it-doesnt-have-to-be-crazy-at-work/id1350572012&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://basecamp.com/assets/books/ibooks-3b7fccd2ef650862db075714ad323fb9198d2229dec8468ba0007b9e61594b17.jpg&quot; width=&quot;117&quot; height=&quot;52&quot; alt=&quot;iBooks&quot;/&gt;&lt;/a&gt;  &lt;a class=&quot;book-purchase&quot; href=&quot;https://www.indiebound.org/book/9780062874788&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://basecamp.com/assets/books/indie-66afa860201176112fb9c99121761b3b1d1ac1ebd4af0e62b0740db62f326fe6.jpg&quot; width=&quot;117&quot; height=&quot;52&quot; alt=&quot;indiebound&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;hr class=&quot;push--top push_double--bottom&quot;/&gt;&lt;h2 class=&quot;subheading centered&quot;&gt;Full list of essays included in the book&lt;/h2&gt;
&lt;div class=&quot;toc grid__item grid__item--xlarge&quot;&gt;
&lt;div class=&quot;toc__column&quot;&gt;
&lt;h3&gt;First&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;It’s crazy at work&lt;/li&gt;
&lt;li&gt;A quick bit about us&lt;/li&gt;
&lt;li&gt;Your company is a product&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;Curb Your Ambition&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Bury the hustle&lt;/li&gt;
&lt;li&gt;Happy pacifists&lt;/li&gt;
&lt;li&gt;Our goal: No goals&lt;/li&gt;
&lt;li&gt;Don’t change the world&lt;/li&gt;
&lt;li&gt;Make it up as you go&lt;/li&gt;
&lt;li&gt;Comfy’s cool&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;Defend Your Time&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;8’s enough, 40’s plenty&lt;/li&gt;
&lt;li&gt;Protectionism&lt;/li&gt;
&lt;li&gt;The quality of an hour&lt;/li&gt;
&lt;li&gt;Effective &amp;gt; Productive&lt;/li&gt;
&lt;li&gt;The outwork myth&lt;/li&gt;
&lt;li&gt;Work doesn’t happen at work&lt;/li&gt;
&lt;li&gt;Office hours&lt;/li&gt;
&lt;li&gt;Calendar Tetris&lt;/li&gt;
&lt;li&gt;The presence prison&lt;/li&gt;
&lt;li&gt;I’ll get back to you whenever&lt;/li&gt;
&lt;li&gt;FOMO? JOMO!&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;div class=&quot;toc__column&quot;&gt;
&lt;h3&gt;Feed Your Culture&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;We’re not family&lt;/li&gt;
&lt;li&gt;They’ll do as you do&lt;/li&gt;
&lt;li&gt;The trust battery&lt;/li&gt;
&lt;li&gt;Don’t be the last to know&lt;/li&gt;
&lt;li&gt;The owner’s word weighs a ton&lt;/li&gt;
&lt;li&gt;Low-hanging fruit can still be out of reach&lt;/li&gt;
&lt;li&gt;Don’t cheat sleep&lt;/li&gt;
&lt;li&gt;Out of whack&lt;/li&gt;
&lt;li&gt;Hire the work, not the résum&lt;/li&gt;
&lt;li&gt;Nobody hits the ground running&lt;/li&gt;
&lt;li&gt;Ignore the talent war&lt;/li&gt;
&lt;li&gt;Don’t negotiate salaries&lt;/li&gt;
&lt;li&gt;Benefits who?&lt;/li&gt;
&lt;li&gt;Library rules&lt;/li&gt;
&lt;li&gt;No fakecations&lt;/li&gt;
&lt;li&gt;Calm goodbyes&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;Dissect Your Process&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;The wrong time for real-time&lt;/li&gt;
&lt;li&gt;Dreadlines&lt;/li&gt;
&lt;li&gt;Don’t be a knee-jerk&lt;/li&gt;
&lt;li&gt;Watch out for 12-day weeks&lt;/li&gt;
&lt;li&gt;The new normal&lt;/li&gt;
&lt;li&gt;Bad habits beat good intentions&lt;/li&gt;
&lt;li&gt;Independencies&lt;/li&gt;
&lt;li&gt;Commitment, not consensus&lt;/li&gt;
&lt;li&gt;Compromise on quality&lt;/li&gt;
&lt;li&gt;Narrow as you go&lt;/li&gt;
&lt;li&gt;Why not nothing?&lt;/li&gt;
&lt;li&gt;It’s enough&lt;/li&gt;
&lt;li&gt;Worst practices&lt;/li&gt;
&lt;li&gt;Whatever it doesn’t take&lt;/li&gt;
&lt;li&gt;Have less to do&lt;/li&gt;
&lt;li&gt;Three’s company&lt;/li&gt;
&lt;li&gt;Stick with it&lt;/li&gt;
&lt;li&gt;Know no&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;div class=&quot;toc__column&quot;&gt;
&lt;h3&gt;Mind Your Business&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Risk without putting yourself at risk&lt;/li&gt;
&lt;li&gt;Season’s greetings&lt;/li&gt;
&lt;li&gt;Calm’s in the black&lt;/li&gt;
&lt;li&gt;Priced to lose&lt;/li&gt;
&lt;li&gt;Launch and learn&lt;/li&gt;
&lt;li&gt;Promise not to promise&lt;/li&gt;
&lt;li&gt;Copycats&lt;/li&gt;
&lt;li&gt;Change control&lt;/li&gt;
&lt;li&gt;Startups are easy, stayups are hard&lt;/li&gt;
&lt;li&gt;No big deal or the end of the world?&lt;/li&gt;
&lt;li&gt;The good old days&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;Last&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Choose calm&lt;/li&gt;
&lt;li&gt;Bibliography&lt;/li&gt;
&lt;li&gt;Resources&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;hr class=&quot;sketch-rule grid__item grid__item--xlarge&quot;/&gt;&lt;h2 class=&quot;subheading centered&quot;&gt;Other books by Basecamp&lt;/h2&gt;
&lt;section class=&quot;more-books grid__item grid__item--large&quot; readability=&quot;2&quot;&gt;
&lt;div class=&quot;book-cover book-cover--dark&quot;&gt;&lt;img srcset=&quot;/assets/books/rework/rework-cover-b85a1d26aa5bd83ced57049343640945ec42938415b067241c07f19040473c4c.png 1x, /assets/books/rework/rework-cover@2x-80707c3ae753c88f9b303ffa0c5890cc8afcb4d7eed55a818c3ab200ce1e444b.png 2x&quot; src=&quot;https://basecamp.com/assets/books/rework/rework-cover-b85a1d26aa5bd83ced57049343640945ec42938415b067241c07f19040473c4c.png&quot; alt=&quot;REWORK cover&quot;/&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;REWORK&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;book-cover&quot;&gt;&lt;img srcset=&quot;/assets/books/remote/remote-cover-aadeb20bf72bc28d49a49d2433e731d36c8a255f9d496880a5224e1ce0006577.png 1x, /assets/books/remote/remote-cover@2x-65bfebc02dc31ce63e7f5e1ee9f652afd72f10356ec724fe793fed47e1de8c2a.png 2x&quot; src=&quot;https://basecamp.com/assets/books/remote/remote-cover-aadeb20bf72bc28d49a49d2433e731d36c8a255f9d496880a5224e1ce0006577.png&quot; alt=&quot;REMOTE cover&quot;/&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;REMOTE: Office Not Required&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;book-cover book-cover--dark&quot;&gt;&lt;img srcset=&quot;/assets/books/getting-real-cover-56d90c4d62fc6aa1e8a333b339cc7272a18afbda0089bebdb1c0bbc54f887a39.png 1x, /assets/books/getting-real-cover@2x-c27a48c78884144aba3d1c20b8367634996653bfae904326e8f688281db4b3b4.png 2x&quot; src=&quot;https://basecamp.com/assets/books/getting-real-cover-56d90c4d62fc6aa1e8a333b339cc7272a18afbda0089bebdb1c0bbc54f887a39.png&quot; alt=&quot;Getting Real cover&quot;/&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Getting Real&lt;/strong&gt;&lt;/p&gt;
&lt;/section&gt;</description>
<pubDate>Wed, 03 Oct 2018 06:32:00 +0000</pubDate>
<dc:creator>kristianp</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://basecamp.com/books/calm</dc:identifier>
</item>
<item>
<title>Intel ME Manufacturing Mode: obscured dangers and MacBook vulnerability</title>
<link>http://blog.ptsecurity.com/2018/10/intel-me-manufacturing-mode-macbook.html</link>
<guid isPermaLink="true" >http://blog.ptsecurity.com/2018/10/intel-me-manufacturing-mode-macbook.html</guid>
<description>&lt;div dir=&quot;ltr&quot; trbidi=&quot;on&quot;&gt;

&lt;div class=&quot;separator&quot;&gt;&lt;a href=&quot;https://1.bp.blogspot.com/--goW46T1rD4/W7NbLrHLJtI/AAAAAAAAHUU/kuU0B6lmZS80LYSwDk7AJ899gS6-NDBwgCLcBGAs/s1600/Untitled.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;662&quot; data-original-width=&quot;799&quot; height=&quot;530&quot; src=&quot;https://1.bp.blogspot.com/--goW46T1rD4/W7NbLrHLJtI/AAAAAAAAHUU/kuU0B6lmZS80LYSwDk7AJ899gS6-NDBwgCLcBGAs/s640/Untitled.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;br/&gt;The weakness of &quot;security through obscurity&quot; is so well known as to be obvious. Yet major hardware manufacturers, citing the need to protect intellectual property, often require a non-disclosure agreement (NDA) before allowing access to technical documentation. The situation has become even more difficult with the growing intricacy of chip designs and integration of proprietary firmware. Such obstacles make it nearly impossible for independent researchers to analyze the security of these platforms. As a result, both ordinary users and hardware manufacturers lose out.&lt;p&gt;One example is Intel Management Engine (Intel ME), including its server (Intel SPS) and mobile (Intel TXE) versions (for background on Intel ME, we recommend consulting  [&lt;a href=&quot;https://github.com/ptresearch/me-disablement/blob/master/How%20to%20become%20the%20sole%20owner%20of%20your%20PC.pdf&quot;&gt;5&lt;/a&gt;] and [&lt;a href=&quot;http://blog.ptsecurity.com/2017/08/disabling-intel-me.html&quot;&gt;6&lt;/a&gt;]). In this article, we will describe how undocumented commands (although &quot;undocumented&quot; applies to practically everything about Intel ME) enable overwriting SPI flash memory and implementing the doomsday scenario: local exploitation of an ME vulnerability (INTEL-SA-00086). At the root of this problem is an undocumented Intel ME mode, specifically, Manufacturing Mode.&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;What is Manufacturing Mode?&lt;/h2&gt;
Intel ME Manufacturing Mode is intended for configuration and testing of the end platform during manufacturing, and as such should be disabled (closed) before sale and shipment to users. However, this mode and its potential risks are not described anywhere in Intel's public documentation. Ordinary users do not have the ability to disable this mode, since the relevant utility (part of Intel ME System Tools) is not officially available. As a result, there is no software that can protect, or even notify, the user if this mode is enabled for whatever reason. Even Chipsec [&lt;a href=&quot;https://github.com/chipsec/chipsec&quot;&gt;2&lt;/a&gt;], a utility specially designed to identify configuration errors in the chipset and CPU at the level of UEFI firmware (such as incorrect configuration of access rights for SPI flash regions), does not know anything about Intel Manufacturing Mode.&lt;p&gt;This mode allows configuring critical platform settings stored in one-time-programmable memory (FUSEs). These settings include those for BootGuard (the mode, policy, and hash for the digital signing key for the ACM and UEFI modules). Some of them are referred to as FPFs (Field Programmable Fuses). For a list of FPFs that can be written to FUSEs (a list that is incomplete, since a number of FPFs cannot be set directly), you can use the FPT (Flash Programming Tool) utility from Intel ME System Tools.&lt;/p&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-j1v2mVX11D0/W7NWldBmLyI/AAAAAAAAHSk/ocwJfsWEalUNukLZcVgAtMHN2Y0tAas_ACLcBGAs/s1600/me_1.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;427&quot; data-original-width=&quot;800&quot; height=&quot;340&quot; src=&quot;https://2.bp.blogspot.com/-j1v2mVX11D0/W7NWldBmLyI/AAAAAAAAHSk/ocwJfsWEalUNukLZcVgAtMHN2Y0tAas_ACLcBGAs/s640/me_1.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 1. Output of the -FPFs option in FPT&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
FPFs account for only a part of the FUSE array: instead, most are used by Intel to store platform parameters. Part of this space is called IP FUSEs, used to store the settings of IP (Intelligent Property, hardware logic blocks) units. Thus, the DFx Aggregator special device stores in FUSEs a sign of whether the platform is for testing or mass production.&lt;p&gt;In addition to FPFs, in Manufacturing Mode the hardware manufacturer can specify settings for Intel ME, which are stored in the Intel ME internal file system (MFS) on SPI flash memory. These parameters can be changed by reprogramming the SPI flash. The parameters are known as CVARs (Configurable NVARs, Named Variables).&lt;/p&gt;&lt;p&gt;Setting CVARs is the responsibility of the Intel ME module named mca_server. MCA is short for &quot;Manufacture-Line Configuration Architecture,&quot; which is the general name for the process of configuring the platform during manufacturing. CVARs, just like FPFs, can be set and read via FPT.&lt;/p&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-Es7yvJ_KnIo/W7NW2fulmqI/AAAAAAAAHSs/2iyy1ERozUwSmetcloMbzwD4Uwf30QulQCLcBGAs/s1600/me2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;427&quot; data-original-width=&quot;800&quot; height=&quot;340&quot; src=&quot;https://2.bp.blogspot.com/-Es7yvJ_KnIo/W7NW2fulmqI/AAAAAAAAHSs/2iyy1ERozUwSmetcloMbzwD4Uwf30QulQCLcBGAs/s640/me2.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 2. List of CVARs output by FPT for the Broxton P platform&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
The list of CVARs depends on the platform and version of Intel ME. For chipsets supporting Intel AMT, one of the CVARs is the password for entering MEBx (ME BIOS Extension).&lt;p&gt;Setting FPFs, or almost any CVARs, requires that Intel ME be in Manufacturing Mode. The process of assigning FPFs consists of two steps: setting the values for FPFs (which are saved to temporary memory) and committing the FPF values to the FUSEs. The first step is possible only in Manufacturing Mode, but the actual &quot;burn&quot; occurs automatically after Manufacturing Mode is closed if, while in that mode, the manufacturer set FPF values and the corresponding range in the FUSE array has never been written to before. &lt;strong&gt;So, if a system is in Manufacturing Mode, the FPFs have likely never been initialized&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;A sign of Manufacturing Mode having been closed is stored in the file /home/mca/eom on MFS. When the SPI flash is overwritten by firmware with the basic file system (just after build by FIT [9]), the platform can once again function in Manufacturing Mode, although overwriting FUSEs is no longer possible.&lt;/p&gt;&lt;h2&gt;OEM public key&lt;/h2&gt;
Accordingly, the procedure for configuring Intel platforms is rather complicated and consists of multiple steps. Any error or deviation from this procedure by hardware manufacturers places the platform at serious risk. Even if Manufacturing Mode has been closed, a manufacturer may not have set FPFs, which allows attackers to do so themselves by writing their own values for example instead of the key for signing the start code of the BootGuard (AСM) and UEFI modules. In this case, the platform would load only with the attacker's malicious code—and persistently so. This would lead to irreversible hardware compromise, since the attacker's key is written to permanent memory, from which it can never be removed (for details of this attack, see &quot;Safeguarding rootkits: Intel BootGuard&quot; by Alexander Ermolov [&lt;a href=&quot;https://2016.zeronights.ru/wp-content/uploads/2017/03/Intel-BootGuard.pdf&quot;&gt;8&lt;/a&gt;]).&lt;p&gt;On newer systems (Apollo Lake, Gemini Lake, Cannon Point) FPFs store not just the key for BootGuard, but the OEM's public key (strictly speaking, the SHA256 hash for the RSA OEM public key), which underpins several ME security mechanisms. For example, the special section of SPI flash named Signed Master Image Profile (SMIP) stores manufacturer-specified PCH Straps (PCH hardware configuration). This section is signed using a key whose SHA256 hash is stored in a special file (partition) on SPI flash. This file name is oem.key in the FTPR partition (OEMP.man in OEMP partition for Cannon Point PCH) and contains various OEM-provided public keys for signing all sorts of data. In the following figure, you can see a full list of the sets of data signed by the manufacturer, each with a unique key, for the Cannon Point platform:&lt;/p&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-ns9k6911YjM/W7NXBanvV_I/AAAAAAAAHSw/iNUgwNS4NfgovEZQEjeWS5PlBskq2X5TQCLcBGAs/s1600/me3.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;251&quot; data-original-width=&quot;800&quot; height=&quot;200&quot; src=&quot;https://3.bp.blogspot.com/-ns9k6911YjM/W7NXBanvV_I/AAAAAAAAHSw/iNUgwNS4NfgovEZQEjeWS5PlBskq2X5TQCLcBGAs/s640/me3.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 3. List of OEM-signed data for the CNP platform&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
The oem.key file itself is signed with an OEM root key, whose public key’s hash should be written in the FPFs.&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-5viOEY2M7hQ/W7NXS5CKRAI/AAAAAAAAHS8/0s99ouiE0EkhLartbWoxdey92Sw4ZBslACLcBGAs/s1600/me5.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;471&quot; data-original-width=&quot;800&quot; height=&quot;376&quot; src=&quot;https://3.bp.blogspot.com/-5viOEY2M7hQ/W7NXS5CKRAI/AAAAAAAAHS8/0s99ouiE0EkhLartbWoxdey92Sw4ZBslACLcBGAs/s640/me5.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 4. OEM signing&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
Therefore, having compromised the OEM root key, an attacker can compromise all previously mentioned data, which is much worse than the Boot Guard–only takeover possible on older platforms.&lt;h2&gt;Bypassing block on writing to the ME region&lt;/h2&gt;
Until recently (prior to Intel Apollo Lake), Intel ME was located in a separate SPI region that had independent access rights for the CPU, GBE, and ME. So as long as access attributes were correctly configured, it was impossible to read or write to ME from the CPU (main system) side. However, current SPI controllers for Intel chipsets have a special mechanism called Master Grant. This mechanism assigns a strictly defined portion of SPI flash to each SPI master. A master controls its particular region, regardless of the access rights indicated in the SPI descriptor. Each master can provide access (read or write) for its region (but only its own region!) to any other master it wishes.&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-K8by8Iixh7c/W7NZYHAa7sI/AAAAAAAAHTo/tawOkbMg3bQujrcmX2bSwdScNJ8LZiW3gCEwYBhgL/s1600/Untitled2.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;911&quot; data-original-width=&quot;800&quot; height=&quot;640&quot; src=&quot;https://3.bp.blogspot.com/-K8by8Iixh7c/W7NZYHAa7sI/AAAAAAAAHTo/tawOkbMg3bQujrcmX2bSwdScNJ8LZiW3gCEwYBhgL/s640/Untitled2.png&quot; width=&quot;562&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;/&gt;
&lt;td class=&quot;tr-caption&quot;&gt;&lt;span&gt;                             Figure 5. Excerpt from Intel documentation describing SPI Master Grant&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
What this means is that even if the SPI descriptor forbids host access to an SPI region of ME, it is possible for ME to still provide access. In our view, this change was likely intended to enable updating Intel ME in a way that bypasses the standard process.&lt;h2&gt;Host ME Region Flash Protection Override&lt;/h2&gt;
Intel ME implements a special HECI command that allows opening write access to ME SPI region on the CPU side. The command is called HMR FPO (Host ME Region Flash Protection Override). We have detailed this command at length previously [5]. There are some things worth knowing about it.&lt;p&gt;After receiving the HMR FPO command, Intel ME opens access to the region &lt;strong&gt;only after&lt;/strong&gt; a reset. Intel МЕ itself also includes security measures: the command is accepted only when the UEFI BIOS is owner of the platform boot process, prior to End Of Post (EOP). EOP is a different HECI command that sends the UEFI to ME before handing off control to the operating system (ExitBootServices). Sometimes, BIOS Setup contains an option for sending the HMRFPO command prior to EOP.&lt;/p&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-3PL5yWQnua0/W7NZHnxdjqI/AAAAAAAAHTc/RP8kZicDlq4ei1ova_Ng44TIBjMeW52VgCLcBGAs/s1600/me7.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;451&quot; data-original-width=&quot;800&quot; height=&quot;360&quot; src=&quot;https://2.bp.blogspot.com/-3PL5yWQnua0/W7NZHnxdjqI/AAAAAAAAHTc/RP8kZicDlq4ei1ova_Ng44TIBjMeW52VgCLcBGAs/s640/me7.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 6. Opening the ME region in the BIOS&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
After receiving EOP, Intel ME ignores HMR FPO and returns the corresponding error status. &lt;strong&gt;But this occurs only after Manufacturing Mode has been closed&lt;/strong&gt;. Therefore, in Manufacturing Mode, Intel ME accepts HMR FPO &lt;strong&gt;at any time, regardless of the presence (or absence) of End Of Post&lt;/strong&gt;. If the manufacturer has failed to close Manufacturing Mode, an attacker can alter Intel ME at any time (of course, administrator rights are needed, but even the OS kernel initially cannot re-flash Intel ME). At this stage, the attacker can re-flash the ME image, such as to exploit vulnerability INTEL-SA-00086. A reset is then needed to run the modified firmware, but this is no problem on nearly any platform, with the exception of the Apple MacBook. Apple's computers contain an additional check in the UEFI, which runs when the UEFI is launched and blocks startup of the system if the ME region has been opened with HMRFPO. However, as we will show here, this mechanism can be easily bypassed if Intel ME is in Manufacturing Mode.&lt;h2&gt;Resetting ME without resetting the main CPU&lt;/h2&gt;
Today's computers can be restarted in several different ways: the documented versions include a global reset and reset of the main CPU only (without resetting ME). But, if there is a way to reset ME &lt;strong&gt;without&lt;/strong&gt; resetting the main CPU (by running the HMRFPO command in advance as well), access to the region opens up and the main system continues to function.&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-cvWjU06Js1c/W7NZWUwuJ4I/AAAAAAAAHTg/IGorljX6LQkLeIHmO8d0N_SrxLb7u8_MQCLcBGAs/s1600/Untitled3.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;953&quot; data-original-width=&quot;800&quot; height=&quot;640&quot; src=&quot;https://2.bp.blogspot.com/-cvWjU06Js1c/W7NZWUwuJ4I/AAAAAAAAHTg/IGorljX6LQkLeIHmO8d0N_SrxLb7u8_MQCLcBGAs/s640/Untitled3.png&quot; width=&quot;536&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 7. Reset types&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br/&gt;
Having investigated the internal ME modules, we discovered that there is a HECI command (&quot;80 06 00 07 00 00 0b 00 00 00 03 00&quot;, see more about sending commands in [&lt;a href=&quot;https://github.com/ptresearch/me-disablement/blob/master/How%20to%20become%20the%20sole%20owner%20of%20your%20PC.pdf&quot;&gt;5&lt;/a&gt;]) for a reset of only (!!!) Intel ME. In Manufacturing Mode, this command can be sent at any time, even after EOP:&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-xka32IAC5lQ/W7NZ3C0z2hI/AAAAAAAAHT0/M146BP0SFzwwvcytch1AbjbOzFpSEr1eQCLcBGAs/s1600/me8.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;651&quot; data-original-width=&quot;800&quot; height=&quot;520&quot; src=&quot;https://3.bp.blogspot.com/-xka32IAC5lQ/W7NZ3C0z2hI/AAAAAAAAHT0/M146BP0SFzwwvcytch1AbjbOzFpSEr1eQCLcBGAs/s640/me8.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 8. Disassembler listing for the function responsible for handling HECI ME reset commands&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;strong&gt;Therefore, an attacker who sends these two HECI commands opens the ME region and can write arbitrary data there, without having to reset the platform as a whole&lt;/strong&gt;. And it doesn't even matter what the SPI descriptor contains—correctly set protection attributes for SPI regions will not protect ME from modifications if the system is running in Manufacturing Mode.&lt;h2&gt;Exploitation case: vulnerability &lt;a href=&quot;https://support.apple.com/hr-hr/HT208849&quot;&gt;CVE-2018-4251&lt;/a&gt;&lt;/h2&gt;
We analyzed several platforms from a number of manufacturers, including Lenovo and Apple MacBook Prо laptops. The Yoga and ThinkPad computers we examined did NOT have any issues related to Manufacturing Mode. But we found that &lt;strong&gt;Apple laptops on Intel chipsets are running in Manufacturing Mode&lt;/strong&gt;. After this information was reported to Apple, the vulnerability (CVE-2018-4251) was patched in macOS High Sierra update 10.13.5.&lt;h2&gt;Local exploitation of INTEL-SA-00086&lt;/h2&gt;
By exploiting CVE-2018-4251, an attacker could write old versions of Intel ME (such as versions containing vulnerability INTEL-SA-00086) to memory without needing an SPI programmer or access to the HDA_SDO bridge—in other words, without physical access to the computer. Thus, a local vector is possible for exploitation of INTEL-SA-00086, which enables running arbitrary code in ME.&lt;br/&gt;Notably, in the notes for the INTEL-SA-00086 security bulletin, Intel does not mention enabled Manufacturing Mode as a method for local exploitation in the absence of physical access. Instead, the company incorrectly claims that local exploitation is possible only if access settings for SPI regions have been misconfigured. So to keep users safe, we decided to describe how to check the status of Manufacturing Mode and how to disable it.&lt;h2&gt;What can users do?&lt;/h2&gt;
Intel System Tools includes MEInfo (and, for mobile and server platforms respectively, TXEInfo and SPSInfo) in order to allow obtaining thorough diagnostic information about the current state of ME and the platform overall. We demonstrated this utility in previous research about the undocumented HAP (High Assurance Platform) mode and how to disable ME [&lt;a href=&quot;http://blog.ptsecurity.com/2017/08/disabling-intel-me.html&quot;&gt;6&lt;/a&gt;]. The utility, when called with the -FWSTS flag, displays a detailed description of status HECI registers and the current status of Manufacturing Mode (when the fourth bit of the FWSTS status register is set, Manufacturing Mode is active).&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-sOIY2NZm250/W7NaNdyWEuI/AAAAAAAAHT8/RAnnC_0HcC0gEWXnMguRVhwYetJSpe1JQCLcBGAs/s1600/me9.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;418&quot; data-original-width=&quot;800&quot; height=&quot;334&quot; src=&quot;https://3.bp.blogspot.com/-sOIY2NZm250/W7NaNdyWEuI/AAAAAAAAHT8/RAnnC_0HcC0gEWXnMguRVhwYetJSpe1JQCLcBGAs/s640/me9.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 9. Example of MEInfo output&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
We also created a program [&lt;a href=&quot;https://github.com/ptresearch/mmdetect&quot;&gt;7&lt;/a&gt;] for checking the status of Manufacturing Mode if the user for whatever reason does not have access to Intel ME System Tools. Here is what the script shows on affected systems:&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://3.bp.blogspot.com/-3JF-WAlHrPQ/W7NaTD0BbaI/AAAAAAAAHUA/8gWtAVS47hYCTeBTSuQGJULIDj0wYXdCwCLcBGAs/s1600/me10.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;387&quot; data-original-width=&quot;800&quot; height=&quot;308&quot; src=&quot;https://3.bp.blogspot.com/-3JF-WAlHrPQ/W7NaTD0BbaI/AAAAAAAAHUA/8gWtAVS47hYCTeBTSuQGJULIDj0wYXdCwCLcBGAs/s640/me10.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 10. mmdetect script&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
So one logical question is, how can users close Manufacturing Mode themselves if the manufacturer has failed to do so? To disable Manufacturing Mode, FPT has a special option (-CLOSEMNF) that in addition to its main purpose also allows setting the recommended access rights for SPI flash regions in the descriptor.&lt;p&gt;Here is what happens when we enter -CLOSEMNF:&lt;/p&gt;&lt;table align=&quot;center&quot; cellpadding=&quot;0&quot; cellspacing=&quot;0&quot; class=&quot;tr-caption-container&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://1.bp.blogspot.com/-z068cBRhBd0/W7Nai3fV_FI/AAAAAAAAHUI/ou5TwX7PEBowGv6AJu85Qriqciixb0JrQCLcBGAs/s1600/me11.png&quot; imageanchor=&quot;1&quot;&gt;&lt;img border=&quot;0&quot; data-original-height=&quot;418&quot; data-original-width=&quot;800&quot; height=&quot;334&quot; src=&quot;https://1.bp.blogspot.com/-z068cBRhBd0/W7Nai3fV_FI/AAAAAAAAHUI/ou5TwX7PEBowGv6AJu85Qriqciixb0JrQCLcBGAs/s640/me11.png&quot; width=&quot;640&quot;/&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td class=&quot;tr-caption&quot;&gt;Figure 11. Process of closing Manufacturing Mode with FPT&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;br/&gt;In this example, we used the NO parameter for -CLOSEMNF to avoid resetting the platform, as would otherwise happen by default immediately after closing Manufacturing Mode.&lt;h2&gt;Conclusion&lt;/h2&gt;
Our research shows that Intel ME has a Manufacturing Mode problem, and that even giant manufacturers such as Apple are not immune to configuration mistakes on Intel platforms. Worse still, there is no public information on the topic, leaving end users in the dark about weaknesses that could result in data theft, persistent irremovable rootkits, and even &quot;bricking&quot; of hardware.&lt;br/&gt;We also suspect that the ability to reset ME without resetting the main CPU may lead to yet additional security issues, due to the states of the BIOS/UEFI and ME falling out of sync.&lt;p&gt;[1] &lt;a href=&quot;https://www.intel.com/content/www/us/en/security-center/advisory/intel-sa-00086.html&quot;&gt;Intel Management Engine Critical Firmware Update, Intel-SA-00086&lt;/a&gt;&lt;br/&gt;[2] &lt;a href=&quot;https://github.com/chipsec/chipsec&quot;&gt;GitHub - chipsec/chipsec: Platform Security Assessment Framework&lt;/a&gt;&lt;br/&gt;[4] &lt;a href=&quot;https://www.coreboot.org/&quot;&gt;Fast, secure and flexible OpenSource firmware, Coreboot&lt;/a&gt;&lt;br/&gt;[5] &lt;a href=&quot;https://github.com/ptresearch/me-disablement/blob/master/How%20to%20become%20the%20sole%20owner%20of%20your%20PC.pdf&quot;&gt;Mark Ermolov, Maxim Goryachy, How to Become the Sole Owner of Your PC, PHDays VI, 2016&lt;/a&gt;&lt;br/&gt;[6] &lt;a href=&quot;http://blog.ptsecurity.com/2017/08/disabling-intel-me.html&quot;&gt;Mark Ermolov, Maxim Goryachy, Disabling Intel ME 11 via undocumented mode, Positive Technologies blog&lt;/a&gt;&lt;br/&gt;[7] &lt;a href=&quot;https://github.com/ptresearch/mmdetect&quot;&gt;Intel ME Manufacturing Mode Detection Tools&lt;/a&gt;&lt;br/&gt;[8] &lt;a href=&quot;https://2016.zeronights.ru/wp-content/uploads/2017/03/Intel-BootGuard.pdf%22&quot;&gt;Safeguarding rootkits: Intel BootGuard, Alexander Ermolov&lt;/a&gt;&lt;br/&gt;[9] &lt;a href=&quot;https://www.blackhat.com/docs/eu-17/materials/eu-17-Sklyarov-Intel-ME-Flash-File-System-Explained.pdf&quot;&gt;Dmitry Sklyarov. Intel ME: Flash File System. Explained&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Authors&lt;/strong&gt;: Maxim Goryachy, Mark Ermolov&lt;/p&gt;&lt;/div&gt;

</description>
<pubDate>Tue, 02 Oct 2018 22:44:05 +0000</pubDate>
<dc:creator>tomxor</dc:creator>
<og:url>http://blog.ptsecurity.com/2018/10/intel-me-manufacturing-mode-macbook.html</og:url>
<og:title>Intel ME Manufacturing Mode: obscured dangers and their relationship to Apple MacBook vulnerability CVE-2018-4251</og:title>
<og:description>The weakness of &quot;security through obscurity&quot; is so well known as to be obvious. Yet major hardware manufacturers, citing the need to p...</og:description>
<og:image>https://1.bp.blogspot.com/--goW46T1rD4/W7NbLrHLJtI/AAAAAAAAHUU/kuU0B6lmZS80LYSwDk7AJ899gS6-NDBwgCLcBGAs/w1200-h630-p-k-no-nu/Untitled.png</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>http://blog.ptsecurity.com/2018/10/intel-me-manufacturing-mode-macbook.html</dc:identifier>
</item>
<item>
<title>In Praise of Mediocrity</title>
<link>https://www.nytimes.com/2018/09/29/opinion/sunday/in-praise-of-mediocrity.html</link>
<guid isPermaLink="true" >https://www.nytimes.com/2018/09/29/opinion/sunday/in-praise-of-mediocrity.html</guid>
<description>&lt;div readability=&quot;50&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot; readability=&quot;45&quot;&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;I’m a little surprised by how many people tell me they have no hobbies. It may seem a small thing, but — at the risk of sounding grandiose — I see it as a sign of a civilization in decline. The idea of leisure, after all, is a hard-won achievement; it presupposes that we have overcome the exigencies of brute survival. Yet here in the United States, the wealthiest country in history, we seem to have forgotten the importance of doing things solely because we enjoy them.&lt;/p&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;Yes, I know: We are all so very busy. Between work and family and social obligations, where are we supposed to find the time?&lt;/p&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;But there’s a deeper reason, I’ve come to think, that so many people don’t have hobbies: We’re afraid of being bad at them. Or rather, we are intimidated by the expectation — itself a hallmark of our intensely public, performative age — that we must actually be skilled at what we do in our free time. Our “hobbies,” if that’s even the word for them anymore, have become too serious, too demanding, too much an occasion to become anxious about whether you are really the person you claim to be.&lt;/p&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;If you’re a jogger, it is no longer enough to cruise around the block; you’re training for the next marathon. If you’re a painter, you are no longer passing a pleasant afternoon, just you, your watercolors and your water lilies; you are trying to land a gallery show or at least garner a respectable social media following. When your identity is linked to your hobby — you’re a yogi, a surfer, a rock climber — you’d better be good at it, or else who are you?&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;&lt;div readability=&quot;35.5&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot; readability=&quot;16&quot;&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;Lost here is the gentle pursuit of a modest competence, the doing of something just because you enjoy it, not because you are good at it. Hobbies, let me remind you, are supposed to be something different from work. But alien values like “the pursuit of excellence” have crept into and corrupted what was once the realm of leisure, leaving little room for the true amateur. The population of our country now seems divided between the semipro hobbyists (some as devoted as Olympic athletes) and those who retreat into the passive, screeny leisure that is the signature of our technological moment.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;&lt;div readability=&quot;45&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot; readability=&quot;35&quot;&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;I don’t deny that you can derive a lot of meaning from pursuing an activity at the highest level. I would never begrudge someone a lifetime devotion to a passion or an inborn talent. There are depths of experience that come with mastery. But there is also a real and pure joy, a sweet, childlike delight, that comes from just learning and trying to get better. Looking back, you will find that the best years of, say, scuba-diving or doing carpentry were those you spent on the learning curve, when there was exaltation in the mere act of doing.&lt;/p&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;In a way that we rarely appreciate, the demands of excellence are at war with what we call freedom. For to permit yourself to do only that which you are good at is to be trapped in a cage whose bars are not steel but self-judgment. Especially when it comes to physical pursuits, but also with many other endeavors, most of us will be truly excellent only at whatever we started doing in our teens. What if you decide in your 40s, as I have, that you want to learn to surf? What if you decide in your 60s that you want to learn to speak Italian? The expectation of excellence can be stultifying.&lt;/p&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;Liberty and equality are supposed to make possible the pursuit of happiness. It would be unfortunate if we were to protect the means only to neglect the end. A democracy, when it is working correctly, allows men and women to develop into free people; but it falls to us as individuals to use that opportunity to find purpose, joy and contentment.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;&lt;div readability=&quot;36.399188092016&quot;&gt;
&lt;div class=&quot;css-4w7y5l&quot; readability=&quot;18.69147496617&quot;&gt;
&lt;p class=&quot;css-xhhu0i e2kc3sl0&quot;&gt;Lest this sound suspiciously like an elaborate plea for people to take more time off from work — well, yes. Though I’d like to put the suggestion more grandly: The promise of our civilization, the point of all our labor and technological progress, is to free us from the struggle for survival and to make room for higher pursuits. But demanding excellence in all that we do can undermine that; it can threaten and even destroy freedom. It steals from us one of life’s greatest rewards — the simple pleasure of doing something you merely, but truly, enjoy.&lt;/p&gt;
&lt;p class=&quot;css-fdlzs e1kwarht0&quot;&gt;Tim Wu (&lt;a class=&quot;css-1g7m0tk&quot; href=&quot;https://twitter.com/superwuster&quot; title=&quot;&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;@superwuster&lt;/a&gt;) is a law professor at Columbia, the author of “The Attention Merchants: The Epic Struggle to Get Inside Our Heads” and a contributing opinion writer.&lt;/p&gt;
&lt;/div&gt;
&lt;aside class=&quot;css-14jsv4e&quot;/&gt;&lt;/div&gt;</description>
<pubDate>Tue, 02 Oct 2018 20:29:13 +0000</pubDate>
<dc:creator>anarbadalov</dc:creator>
<og:url>https://www.nytimes.com/2018/09/29/opinion/sunday/in-praise-of-mediocrity.html</og:url>
<og:type>article</og:type>
<og:title>Opinion | In Praise of Mediocrity</og:title>
<og:image>https://static01.nyt.com/images/2018/10/01/opinion/sunday/30wu/30wu-facebookJumbo.jpg</og:image>
<og:description>The pursuit of excellence has infiltrated and corrupted the world of leisure.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.nytimes.com/2018/09/29/opinion/sunday/in-praise-of-mediocrity.html</dc:identifier>
</item>
<item>
<title>Announcing flicker-free boot for Fedora 29</title>
<link>https://hansdegoede.livejournal.com/19224.html</link>
<guid isPermaLink="true" >https://hansdegoede.livejournal.com/19224.html</guid>
<description>A big project I've been working on recently for Fedora Workstation is what we call flickerfree boot. The idea here is that the firmware lights up the display in its native mode and no further modesets are done after that. Likewise there are also no unnecessary jarring graphical transitions.&lt;p&gt;Basically the machine boots up in UEFI mode, shows its vendor logo and then the screen keeps showing the vendor logo all the way to a smooth fade into the gdm screen. &lt;a href=&quot;https://fedorapeople.org/~jwrdegoede/flickerfree-videos/workstation-normal.webm&quot; rel=&quot;nofollow&quot;&gt;Here&lt;/a&gt; is a &lt;a href=&quot;https://fedorapeople.org/~jwrdegoede/flickerfree-videos/workstation-normal.webm&quot; rel=&quot;nofollow&quot;&gt;video&lt;/a&gt; of my main workstation booting this way.&lt;/p&gt;&lt;p&gt;Part of this effort is the &lt;a href=&quot;https://fedoraproject.org/wiki/Changes/HiddenGrubMenu&quot; rel=&quot;nofollow&quot;&gt;hidden grub menu change&lt;/a&gt; for Fedora 29. I'm happy to announce that most of the other flickerfree changes have also landed for Fedora 29:&lt;br/&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;There have been changes to shim and grub to not mess with the EFI framebuffer, leaving the vendor logo intact, when they don't have anything to display (so when grub is hidden)&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;There have been changes to the kernel to properly inherit the EFI framebuffer when using Intel integrated graphics, and to delay switching the display to the framebuffer-console until the first kernel message is printed. Together with changes to make &lt;em&gt;&quot;quiet&quot;&lt;/em&gt; really quiet (except for oopses/panics) this means that the kernel now also leaves the EFI framebuffer with the logo intact if quiet is used.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;There have been changes to plymouth to allow pressing ESC as soon as plymouth loads to get detailed boot messages.&lt;br/&gt;&lt;/li&gt;
&lt;/ol&gt;
With all these changes in place it is possible to get a fully flickerfree boot today, as the &lt;a href=&quot;https://fedorapeople.org/~jwrdegoede/flickerfree-videos/workstation-normal.webm&quot; rel=&quot;nofollow&quot;&gt;video of my workstation&lt;/a&gt; shows. This video is made with a stock Fedora 29 with 2 small kernel commandline tweaks:
&lt;ol&gt;&lt;li&gt;&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Add &lt;em&gt;&quot;i915.fastboot=1&quot;&lt;/em&gt; to the kernel commandline, this removes the first and last modeset during the boot when using the i915 driver.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Add &lt;em&gt;&quot;plymouth.splash-delay=20&quot;&lt;/em&gt; to the kernel commandline. Normally plymouth waits 5 seconds before showing the charging Fedora logo so that on systems which boot in less then 5 seconds the system simply immediately transitions to gdm. On systems which take slightly longer to boot this makes &lt;a href=&quot;https://fedorapeople.org/~jwrdegoede/flickerfree-videos/workstation-plymouth.webm&quot; rel=&quot;nofollow&quot;&gt;the charging Fedora logo show up&lt;/a&gt;, which IMHO makes the boot &lt;a href=&quot;https://fedorapeople.org/~jwrdegoede/flickerfree-videos/workstation-plymouth.webm&quot; rel=&quot;nofollow&quot;&gt;less fluid&lt;/a&gt;. This option increases the time plymouth waits with showing the splash to 20 seconds.&lt;br/&gt;&lt;/li&gt;
&lt;/ol&gt;
So if you have a machine with Intel integrated graphics and booting in UEFI mode, you can give flickerfree boot support a spin with Fedora 29 by just adding these 2 commandline options. Note this requires the new grub hidden menu feature to be enabled, see the &lt;a href=&quot;https://hansdegoede.livejournal.com/19081.html&quot; rel=&quot;nofollow&quot;&gt;FAQ on this&lt;/a&gt;.&lt;p&gt;The need for these 2 commandline options shows that the work on this is not yet entirely complete, here is my current TODO list for finishing this feature:
&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Work with the upstream i915 driver devs to make i915.fastboot the default. If you try i915.fastboot=1 and it causes problems for you please let me know.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Write a new plymouth theme based on the spinner theme which used the vendor logo as background and draws the spinner beneath it. Since this keeps the logo and black background as is and just draws the spinner on top this avoids the current visually jarring transition from logo screen to plymouth, allowing us to set plymouth.splash-delay to 0. This also has the advantage that the spinner will provide visual feedback that something is actually happening as soon as plymouth loads.&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;Look into making this work with AMD and NVIDIA graphics.&lt;br/&gt;&lt;/li&gt;
&lt;/ol&gt;
Please give the new flickerfree support a spin and let me know if you have any issues with it.

</description>
<pubDate>Tue, 02 Oct 2018 17:50:58 +0000</pubDate>
<dc:creator>kbumsik</dc:creator>
<og:description>A big project Ive been working on recently for Fedora Workstation is what we call flickerfree boot. The idea here is that the firmware lights up the display in its native mode and no further modesets are done after that. Likewise there are also no unnecessary jarring graphical transitions.…</og:description>
<og:image>https://l-stat.livejournal.net/img/sign.png</og:image>
<og:title>Announcing flickerfree boot for Fedora 29</og:title>
<og:type>article</og:type>
<og:url>https://hansdegoede.livejournal.com/19224.html</og:url>
<dc:format>text/html</dc:format>
<dc:identifier>https://hansdegoede.livejournal.com/19224.html?nojs=1</dc:identifier>
</item>
<item>
<title>Fastai for PyTorch: Fast and accurate neural nets using modern best practices</title>
<link>http://www.fast.ai/2018/10/02/fastai-ai/</link>
<guid isPermaLink="true" >http://www.fast.ai/2018/10/02/fastai-ai/</guid>
<description>&lt;span class=&quot;post-date&quot;&gt;Written: 02 Oct 2018 by &lt;em&gt;Jeremy Howard&lt;/em&gt;&lt;/span&gt;
&lt;p class=&quot;message&quot;&gt;&lt;em&gt;Note from Jeremy&lt;/em&gt;: Want to learn more? Listen to me discuss fastai with Sam Charrington in this &lt;a href=&quot;https://twimlai.com/twiml-talk-186-the-fastai-v1-deep-learning-framework-with-jeremy-howard&quot;&gt;in-depth interview&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Today fast.ai is releasing v1 of a new free open source library for deep learning, called &lt;a href=&quot;http://docs.fast.ai&quot;&gt;fastai&lt;/a&gt;. The library sits on top of &lt;a href=&quot;https://code.fb.com/ai-research/facebook-accelerates-ai-development-with-new-partners-and-production-capabilities-for-pytorch-1-0&quot;&gt;PyTorch v1&lt;/a&gt; (released today in preview), and provides a single consistent API to the most important deep learning applications and data types. fast.ai’s &lt;a href=&quot;http://www.fast.ai/2018/08/10/fastai-diu-imagenet/&quot;&gt;recent research breakthroughs&lt;/a&gt; are embedded in the software, resulting in significantly improved accuracy and speed over other deep learning libraries, whilst requiring dramatically less code. You can download it today from conda, pip, or &lt;a href=&quot;https://github.com/fastai/fastai/&quot;&gt;GitHub&lt;/a&gt; or use it on &lt;a href=&quot;https://cloud.google.com/&quot;&gt;Google Cloud Platform&lt;/a&gt;. AWS support is coming soon.&lt;/p&gt;
&lt;h2 id=&quot;about-fastai&quot;&gt;About fast.ai&lt;/h2&gt;
&lt;p&gt;fast.ai’s mission is to make the power of state of the art deep learning available to anyone. In order to make that happen, we do three things:&lt;/p&gt;
&lt;ol readability=&quot;1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Research how to apply state of the art deep learning to practical problems quickly and reliably&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;Build software to make state of the art deep learning as easy to use as possible, whilst remaining easy to customize for researchers wanting to explore hypotheses&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Teach courses so that as many people as possible can use the research results and software&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;You may well already be familiar with our courses. Hundreds of thousands of people have already taken our &lt;a href=&quot;http://course.fast.ai/&quot;&gt;Practical Deep Learning for Coders&lt;/a&gt; course, and many alumni are now doing amazing work with their new skills, at organizations like Google Brain, OpenAI, and Github. (Many of them now actively contribute to our busy deep learning practitioner &lt;a href=&quot;http://forums.fast.ai/&quot;&gt;discussion forums&lt;/a&gt;, along with other members of the wider deep learning community.)&lt;/p&gt;
&lt;p&gt;You may also have heard about some of our recent research breakthroughs (with help from our students and collaborators!), including &lt;a href=&quot;https://www.technologyreview.com/s/611858/small-team-of-ai-coders-beats-googles-code/&quot;&gt;breaking deep learning speed records&lt;/a&gt; and achieving a new &lt;a href=&quot;http://nlp.fast.ai/classification/2018/05/15/introducting-ulmfit.html&quot;&gt;state of the art in text classification&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;the-new-fastai-library&quot;&gt;The new fastai library&lt;/h2&gt;
&lt;p&gt;So that covers the research and teaching parts of the three listed areas—but what about software? Today we’re releasing v1.0 of our new &lt;a href=&quot;http://docs.fast.ai&quot;&gt;fastai deep learning library&lt;/a&gt;, which has been under development for the last 18 months. fastai sits on top of &lt;a href=&quot;https://pytorch.org/&quot;&gt;PyTorch&lt;/a&gt;, which provides the foundation for our work. When we announced the initial development of fastai &lt;a href=&quot;http://www.fast.ai/2017/09/08/introducing-pytorch-for-fastai/&quot;&gt;over one year ago&lt;/a&gt;, we described many of the advantages that PyTorch provides us. For instance, we talked about how we could “&lt;em&gt;use all of the flexibility and capability of regular python code to build and train neural networks&lt;/em&gt;”, and “&lt;em&gt;we were able to tackle a much wider range of problems&lt;/em&gt;”. The PyTorch team has been very supportive throughout fastai’s development, including contributing critical performance optimizations that have enabled key functionality in our software.&lt;/p&gt;
&lt;p&gt;fastai is the first deep learning library to provide a single consistent interface to all the most commonly used deep learning applications for vision, text, tabular data, time series, and collaborative filtering. This is important for practitioners, because it means if you’ve learnt to create practical computer vision models with fastai, then you can use the same approach to create natural language processing (NLP) models, or any of the other types of model we support.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://cloud.google.com/&quot;&gt;Google Cloud Platform&lt;/a&gt; are making fastai v1 available to all their customers from today in an experimental Deep Learning image for Google Compute Engine, including ready-to-run notebooks and preinstalled datasets. To use it, simply head over to &lt;a href=&quot;https://cloud.google.com/deep-learning-vm/docs/images&quot;&gt;Deep Learning images page&lt;/a&gt; on Google Cloud Marketplace and setup configuration for your instance, set framework to PyTorch 1.0RC and click “deploy”. That’s it, you now have the VM with Jupyter Lab, PyTorch 1.0 and fastai on it! Read more about how you can use the images &lt;a href=&quot;https://blog.kovalevskyi.com/google-compute-engine-now-has-images-with-pytorch-1-0-0-and-fastai-1-0-2-57c49efd74bb&quot;&gt;in this post&lt;/a&gt; from Google’s Viacheslav Kovalevskyi. And if you want to use fastai in a GPU-powered Jupyter Notebook, it’s now a single click away thanks to fastai support on &lt;a href=&quot;https://salamander.ai/&quot;&gt;Salamander&lt;/a&gt;, also released today.&lt;/p&gt;
&lt;p&gt;Good news too from Bratin Saha, VP, &lt;a href=&quot;https://aws.amazon.com/&quot;&gt;Amazon Web Services&lt;/a&gt;: “To support fast.ai’s mission to make the power of deep learning available at scale, the fastai library will soon be available in the AWS &lt;a href=&quot;https://aws.amazon.com/machine-learning/amis/&quot;&gt;Deep Learning AMIs&lt;/a&gt; and &lt;a href=&quot;https://aws.amazon.com/sagemaker/&quot;&gt;Amazon SageMaker&lt;/a&gt;”.&lt;/p&gt;
&lt;h2 id=&quot;early-users&quot;&gt;Early users&lt;/h2&gt;
&lt;h3 id=&quot;semantic-code-search-at-github&quot;&gt;Semantic code search at GitHub&lt;/h3&gt;
&lt;p&gt;fast.ai are enthusiastic users of &lt;strong&gt;&lt;a href=&quot;https://github.com/&quot;&gt;Github&lt;/a&gt;’s&lt;/strong&gt; collaboration tools, and many of the Github team work with fast.ai tools too - even the &lt;a href=&quot;https://www.reddit.com/r/AMA/comments/8pc8mf/im_nat_friedman_future_ceo_of_github_ama/e0a2qjj/&quot;&gt;CEO of Github studies deep learning&lt;/a&gt; using our courses! &lt;a href=&quot;https://www.linkedin.com/in/hamelhusain/&quot;&gt;Hamel Husain&lt;/a&gt;, a Senior Machine Learning Scientist at Github who has been studying deep learning through fast.ai for the last two years, says:&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;“The fast.ai course has been taken by data scientists and executives at Github alike ushering in a new age of data literacy at GitHub. It gave data scientists at GitHub the confidence to tackle state of the art problems in machine learning, which were previously believed to be only accessible to large companies or folks with PhDs.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Husain and his colleague &lt;a href=&quot;https://www.linkedin.com/in/hohsiangwu/&quot;&gt;Ho-Hsiang Wu&lt;/a&gt; recently released a new experimental tool for &lt;a href=&quot;https://experiments.github.com/semantic-code-search&quot;&gt;semantic code search&lt;/a&gt;, which allows Github users to find useful code snippets using questions written in plain English. In a &lt;a href=&quot;https://githubengineering.com/towards-natural-language-semantic-code-search/&quot;&gt;blog post&lt;/a&gt; announcing the tool, they describe how they switched from Google’s Tensorflow Hub to fastai, because it “&lt;em&gt;gave us easy access to state of the art architectures such as AWD LSTMs, and techniques such as cyclical learning rates with random restarts&lt;/em&gt;”.&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;640&quot; src=&quot;http://www.fast.ai/images/fastai_v1beta/image_0.png&quot; alt=&quot;Screenshot from Github’s semantic code search tool&quot;/&gt; Screenshot from Github’s semantic code search tool
&lt;p&gt;Husain has been using a pre-release version of the fastai library for the last 12 months. He told us:&lt;/p&gt;
&lt;blockquote readability=&quot;11.053140096618&quot;&gt;
&lt;p&gt;“I choose fast.ai because of its modularity, high level apis that implemented &lt;a href=&quot;https://blog.floydhub.com/ten-techniques-from-fast-ai/&quot;&gt;state of the art techniques&lt;/a&gt;, and innovations that &lt;a href=&quot;http://www.fast.ai/2018/04/30/dawnbench-fastai/&quot;&gt;reduce the need for tons of compute&lt;/a&gt; but with the same performance characteristics. The semantic code search demo is only the tip of the iceberg, as folks in sales, marketing, fraud are currently leveraging the power of fastai to bring transformative change to their business areas.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;music-generation&quot;&gt;Music generation&lt;/h3&gt;
&lt;p&gt;One student that stood out in our last fast.ai deep learning course was &lt;a href=&quot;http://christinemcleavey.com/&quot;&gt;Christine McLeavey Payne&lt;/a&gt;, who had already had a fascinating journey as an award-winning classical pianist with an SF Symphony chamber group, a high performance computing expert in the finance world, and a neuroscience and medical researcher at Stanford. Her journey has only gotten more interesting since, and today she is a Research Fellow at the famous &lt;a href=&quot;https://openai.com/&quot;&gt;OpenAI&lt;/a&gt; research lab. In her most recent OpenAI project, she used fastai to help her create &lt;a href=&quot;http://christinemcleavey.com/clara-a-neural-net-music-generator/&quot;&gt;Clara: A Neural Net Music Generator&lt;/a&gt;. Here is some of her &lt;a href=&quot;http://christinemcleavey.com/wp-content/uploads/2018/08/0-2.wav&quot;&gt;generated chamber music&lt;/a&gt;. Christine says:&lt;/p&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;“The fastai library is an amazing resource. Even when I was just starting in deep learning, it was easy to get a fastai model up and running in only a few lines of code. At that point, I didn’t understand the state-of-the-art techniques happening under the hood, but still they worked, meaning my models trained faster, and reached significantly better accuracy.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Christine has even created a &lt;a href=&quot;http://christinemcleavey.com/human-or-ai/&quot;&gt;human or computer&lt;/a&gt; quiz that you can try for yourself; see if you can figure which pieces were generated by her algorithm! Clara is closely based on work she did on language modeling for one of her fast.ai student projects, and leverages the fastai library’s support for recent advances in natural language processing. Christine told us:&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;“It’s only more recently that I appreciate just how important these details are, and how much work the fastai library saves me. It took me just under two weeks to get this music generation project up and getting great initial results. I’m certain that speed couldn’t have been possible without fastai.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We think that Clara is a great example of the expressive power of deep learning—in this case, a model designed to generate and classify text has been used to generate music, with relatively few modifications. “&lt;em&gt;I took a fastai Language Model almost exactly (very slight changes in sampling the generation) and experimented with ways to write out the music in either a “notewise” or “chordwise” encoding&lt;/em&gt;” she &lt;a href=&quot;https://twitter.com/mcleavey/status/1043258046334595072&quot;&gt;wrote on Twitter&lt;/a&gt;. The result was a crowd favorite, with Vanessa M Garcia, a Senior Researcher at IBM Watson, declaring it her top choice at OpenAI’s Demo Day.&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;640&quot; src=&quot;http://www.fast.ai/images/fastai_v1beta/image_1.png&quot; alt=&quot;Twitter comment about Christine's music generation demo&quot;/&gt; Twitter comment about Christine's music generation demo
&lt;h3 id=&quot;fastai-for-art-projects&quot;&gt;fastai for art projects&lt;/h3&gt;
&lt;p&gt;Architect and Investor &lt;strong&gt;Miguel Pérez Michaus&lt;/strong&gt; has been using a pre-release version of fastai to research a system for art experiments that he calls &lt;a href=&quot;https://medium.com/@miguelpmich/was-this-your-face-vincent-48e4059ace69&quot;&gt;Style Reversion&lt;/a&gt;. This is definitely a case where a picture tells a thousand words, so rather than try to explain what it does, I’ll let you see for yourself:&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;640&quot; src=&quot;http://www.fast.ai/images/fastai_v1beta/image_2.png&quot; alt=&quot;Example of Style Reversion&quot;/&gt; Example of Style Reversion
&lt;p&gt;Pérez Michaus says he likes designing with fastai because “&lt;em&gt;I know that it can get me where [Google’s Tensorflow library] Keras can not, for example, whenever something ‘not standard’ has to be achieved&lt;/em&gt;”. As an early adopter, he’s seen the development of the library over the last 12 months:&lt;/p&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;“I was lucky enough to see alpha version of fastai evolving, and even back then its power and flexibility was evident. Additionally, it was fully usable for people like myself, with domain knowledge but no formal Computer Science background. And it only has gotten better. My quite humble intuition about the future of deep learning is that we will need a fine grained understanding of what is really goes on under the hood, and in that landscape I think fastai is going to shine.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;fastai-for-academic-research&quot;&gt;fastai for academic research&lt;/h3&gt;
&lt;p&gt;Entrepreneurs &lt;strong&gt;Piotr Czapla and Marcin Kardas&lt;/strong&gt; are the co-founders of &lt;a href=&quot;https://www.n-waves.com/&quot;&gt;n-waves&lt;/a&gt;, a deep learning consulting company. They used fastai to develop a &lt;a href=&quot;https://www.n-waves.com/perspectives/fastai-v1&quot;&gt;novel algorithm for text classification&lt;/a&gt; in Polish, based on ideas shown in fast.ai’s &lt;a href=&quot;http://course.fast.ai/part2.html&quot;&gt;Cutting Edge Deep Learning for Coders&lt;/a&gt; course. Polish is challenging for NLP, since it is a morphologically rich language (e.g. number, gender, animacy, and case are all collapsed into a word’s suffix). The algorithm that Czapla and Kardas developed won first prize in the top NLP academic competition in Poland, and a paper based on this new research will be published soon. According to Czapla, the fastai library was critical to their success:&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;“I love that fastai works well for normal people that do not have hundreds of servers at their disposal. It supports quick development and prototyping, and has all the best deep learning practices incorporated into it.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The course and community have also been important for them:&lt;/p&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;“fast.ai’s courses opened my eyes to deep learning, and helped me to think and develop intuitions around how deep learning really works. Most of the answers to my questions are already on the forum somewhere, just a search away. I love how the notes from the lectures are composed into Wiki topics, and that other students are creating transcriptions of the lessons so that they are easier to find.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;example-transfer-learning-in-computer-vision&quot;&gt;Example: Transfer learning in computer vision&lt;/h2&gt;
&lt;p&gt;fast.ai’s research is embedded in that fastai library, so you get the benefits of it automatically. Let’s take a look at an example of what that means…&lt;/p&gt;
&lt;p&gt;Kaggle’s &lt;a href=&quot;https://www.kaggle.com/c/dogs-vs-cats&quot;&gt;Dogs vs Cats&lt;/a&gt; competition has been a favorite part of our courses since the very start, and it represents an important class of problems: transfer learning of a pre-trained model. So we’ll take a look at how the fastai library goes on this task.&lt;/p&gt;
&lt;p&gt;Before we built fastai, we did most of our research and teaching using Keras (with the Tensorflow backend), and we’re still big fans of it. Keras really led the way in showing how to make deep learning easier to use, and it’s been a big inspiration for us. Today, it is (for good reason) the most popular way to train neural networks. In this brief example we’ll compare Keras and fastai on what we think are the three most important metrics: amount of code required, accuracy, and speed.&lt;/p&gt;
&lt;p&gt;Here’s all the code required to do 2-stage fine tuning with fastai - not only is there very little code to write, there’s very few parameters to set:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;10.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;16&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_from_imagefolder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/dogscats'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ds_tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imagenet_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ConvLearner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tvm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resnet34&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unfreeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;slice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3e-4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Let’s compare the two libraries on this task (we’ve tried to match &lt;a href=&quot;https://github.com/fastai/fastai_v1/blob/master/dev_nb/experiments/keras_lesson1.ipynb&quot;&gt;our Keras implementation&lt;/a&gt; as closely as possible, although since Keras doesn’t support all the features that fastai provides, it’s not identical):&lt;/p&gt;
&lt;table readability=&quot;2&quot;&gt;&lt;tr&gt;&lt;td/&gt;
&lt;td&gt;fastai resnet34*&lt;/td&gt;
&lt;td&gt;fastai resnet50&lt;/td&gt;
&lt;td&gt;Keras&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Lines of code (excluding imports)&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;31&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Stage 1 error&lt;/td&gt;
&lt;td&gt;0.70%&lt;/td&gt;
&lt;td&gt;0.65%&lt;/td&gt;
&lt;td&gt;2.05%&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Stage 2 error&lt;/td&gt;
&lt;td&gt;0.50%&lt;/td&gt;
&lt;td&gt;0.50%&lt;/td&gt;
&lt;td&gt;0.80%&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Test time augmentation (TTA) error&lt;/td&gt;
&lt;td&gt;0.30%&lt;/td&gt;
&lt;td&gt;0.40%&lt;/td&gt;
&lt;td&gt;N/A*&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Stage 1 time&lt;/td&gt;
&lt;td&gt;4:56&lt;/td&gt;
&lt;td&gt;9:30&lt;/td&gt;
&lt;td&gt;8:30&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Stage 2 time&lt;/td&gt;
&lt;td&gt;6:44&lt;/td&gt;
&lt;td&gt;12:48&lt;/td&gt;
&lt;td&gt;17:38&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;&lt;em&gt;* Keras does not provide resnet 34 or TTA&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;(It’s important to understand that these improved results over Keras in no way suggest that Keras isn’t an excellent piece of software. Quite the contrary! If you tried to complete this task with almost any other library, you would need to write &lt;em&gt;far&lt;/em&gt; more code, and would be unlikely to see better speed or accuracy than Keras. That’s why we’re showing Keras in this comparison - because we’re admirers of it, and it’s the strongest benchmark we know of!)&lt;/p&gt;
&lt;p&gt;fastai also show similarly strong performance for NLP. The state of the art text classification algorithm is &lt;a href=&quot;https://arxiv.org/abs/1801.06146&quot;&gt;ULMFit&lt;/a&gt;. Here’s the relative error of ULMFiT versus previous top ranked algorithms on the popular IMDb dataset, as shown in the ULMFiT paper:&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;640&quot; src=&quot;http://www.fast.ai/images/fastai_v1beta/image_3.png&quot; alt=&quot;Summary of text classification performance&quot;/&gt; Summary of text classification performance
&lt;p&gt;fastai is currently the only library to provide this algorithm. Because the algorithm is built in to fastai, you can match the paper’s results with similar code to that shown above for Dogs vs Cats. Here’s how you train the language model for ULMFiT:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;13.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;22&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_from_textcsv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LM_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_func&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RNNLearner&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;language_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drop_mult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pretrained_fnames&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'lstm_wt103'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'itos_wt103'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;moms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unfreeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;moms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pct_start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&quot;under-the-hood---pytorch-v1&quot;&gt;Under the hood - pytorch v1&lt;/h2&gt;
&lt;p&gt;A critical component of fastai is the extraordinary foundation provided by &lt;a href=&quot;https://pytorch.org/&quot;&gt;PyTorch&lt;/a&gt;, v1 (preview) of which is also being released today. fastai isn’t something that replaces and hides PyTorch’s API, but instead is designed to expand and enhance it. For instance, you can create new data augmentation methods by simply creating a function that does standard PyTorch tensor operations; here’s the entire definition of fastai’s &lt;code class=&quot;highlighter-rouge&quot;&gt;jitter&lt;/code&gt; function:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;7&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;9&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;jitter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;magnitude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;magnitude&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;As another example, fastai uses and extends PyTorch’s concise and expressive Dataset and DataLoader classes for accessing data. When we wanted to add support for image segmentation problems, it was as simple as defining this standard PyTorch Dataset class:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;10&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;15&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MatchedFilesDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DatasetBase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__getitem__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;open_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;open_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This means that as practitioners want to dive deeper into their models, data, and training methods, they can take advantage of all the richness of the full PyTorch ecosystem. Thanks to PyTorch’s dynamic nature, programmers can easily debug their models using standard Python tools. In many areas of deep learning, PyTorch is the most common platform for researchers publishing their research; fastai makes it simple to test our these new approaches.&lt;/p&gt;
&lt;h2 id=&quot;under-the-hood---fastai&quot;&gt;Under the hood - fastai&lt;/h2&gt;
&lt;p&gt;In the coming months we’ll be publishing academic papers and blog posts describing the key pieces of the fastai library, as well as releasing a new course that will walk students through how the library was developed from scratch. To give you a taste, we’ll touch on a couple of interesting pieces here, focussing on computer vision.&lt;/p&gt;
&lt;p&gt;One thing we care a lot about is speed. That’s why we competed in Stanford’s &lt;a href=&quot;https://dawn.cs.stanford.edu/benchmark/&quot;&gt;DAWNBench&lt;/a&gt; competition for rapid and accurate model training, where (along with our collaborators) we have achieved first place in every category we entered. If you want to match our top single-machine CIFAR-10 result, it’s as simple as four lines of code:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot; readability=&quot;13.5&quot;&gt;
&lt;div class=&quot;highlight&quot; readability=&quot;22&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;
&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;crop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row_pct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col_pct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;flip_lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_from_imagefolder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/cifar10'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'test'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ds_tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tfms&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cifar_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Learner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wrn_22&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_fp16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;learn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_one_cycle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wd&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Much of the magic is buried underneath that &lt;code class=&quot;highlighter-rouge&quot;&gt;to_fp16()&lt;/code&gt; method call. Behind the scenes, we’re following all of Nvidia’s &lt;a href=&quot;https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html&quot;&gt;recommendations for mixed precision training&lt;/a&gt;. No other library that we know of provides such an easy way to leverage Nvidia’s latest technology, which gives two to three times better performance compared to previous approaches.&lt;/p&gt;
&lt;p&gt;Another thing we care a lot about is accuracy. We want your models to work well not just on your training data, but on new test data as well. Therefore, we’ve built an entirely new computer vision library from scratch that makes it easy to develop and use data augmentation methods, to improve your model’s performance on unseen data. The new library uses a new approach to minimize the number of lossy transformations that your data goes through. For instance, take a look at the three images below:&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;640&quot; src=&quot;http://www.fast.ai/images/fastai_v1beta/image_4.png&quot; alt=&quot;Example of fastai transforms&quot;/&gt; Example of fastai transforms
&lt;p&gt;On the left is the original low resolution image from the CIFAR-10 dataset. In the middle is the result of zooming and rotating this image using standard deep learning augmentation libraries. On the right is the same zoom and rotation, using fastai v1. As you can see, with fastai the detail is kept much better; for instance, take a look at how the pilot’s window is much crisper in the right-hand image than the middle image. This change to how data augmentation is applied means that practitioners using fastai can use far more augmentation than users of other libraries, resulting in models that generalize better.&lt;/p&gt;
&lt;p&gt;These data augmentations even work automatically with non-image data such as bounding boxes. For instance, here’s an example of how fastai’s works with an image detection dataset, automatically tracking each bounding box through all augmentations:&lt;/p&gt;
&lt;img class=&quot;image&quot; width=&quot;640&quot; src=&quot;http://www.fast.ai/images/fastai_v1beta/image_5.png&quot; alt=&quot;Transforming bounding box data&quot;/&gt; Transforming bounding box data
&lt;p&gt;These kinds of thoughtful features can be found throughout the fastai library. Over the coming months we’ll be doing deep dives in to many of them, for those of you interested in the details of how fastai is implemented behind the scenes.&lt;/p&gt;
&lt;h2 id=&quot;thanks&quot;&gt;Thanks!&lt;/h2&gt;
&lt;p&gt;Many thanks to the PyTorch team. Without PyTorch, none of this would have been possible. Thanks also to Amazon Web Services, who sponsored fast.ai’s first Researcher in Residence, Sylvain Gugger, who has contributed much of the development of fastai v1. Thanks also to fast.ai alumni Fred Monroe, &lt;a href=&quot;https://www.linkedin.com/in/anshaw/&quot;&gt;Andrew Shaw&lt;/a&gt;, and &lt;a href=&quot;https://www.linkedin.com/in/stasbekman/?originalSubdomain=ca&quot;&gt;Stas Bekman&lt;/a&gt;, who have all made significant contributions, to Yaroslav Bulatov, who was a key contributor to our most recent DAWNBench project, to Viacheslav Kovalevskyi, who handled Google Cloud integration, and of course to all the students and collaborators who have helped make the community and software successful.&lt;/p&gt;
</description>
<pubDate>Tue, 02 Oct 2018 17:11:40 +0000</pubDate>
<dc:creator>stablemap</dc:creator>
<dc:language>en-us</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.fast.ai/2018/10/02/fastai-ai/</dc:identifier>
</item>
<item>
<title>Startups I Want to Fund</title>
<link>https://startupandrew.com/posts/startups-i-want-to-fund/</link>
<guid isPermaLink="true" >https://startupandrew.com/posts/startups-i-want-to-fund/</guid>
<description>&lt;p&gt;I hear a lot of startup pitches. I’ve been angel investing now for ~4 years, and I’m an LP and advisor to a number of VC funds. I also heard a lot of pitches through my work at &lt;a href=&quot;https://firebase.google.com/&quot;&gt;Firebase&lt;/a&gt; (the company I co-founded), as many of its customers are startups.&lt;/p&gt;
&lt;p&gt;I like being pitched – partly because I enjoy meeting smart people, and partly because it’s a chance to pay-it-forward to the next cohort of entrepreneurs, but largely because it’s a chance to be a part of the solution to some of the world’s biggest problems.&lt;/p&gt;
&lt;p&gt;My favorite pitches solve a problem I’m already concerned about. These pitches present me with a novel approach I had not considered, and they back up their approach with some promising initial data and a high-powered team that’s ready to take this all the way to the finish line. I walk away from these pitches excited, hopeful, and with a new perspective on the problem. I find myself thinking “what can I do to make sure they are successful?” These are the startups I invest in, and they’re the ones I share with my investor friends.&lt;/p&gt;
&lt;p&gt;The pitches I’m most excited to hear are the ones solving the big, scary problems that most people don’t want to touch. Climate change? Here’s a credible path to solving it. Infectious diseases? Here’s how home testing can make a difference. Net neutrality? Here’s how a new model for ISPs can change things. Electricity access for the poor? Here’s how 1.3 billion more people can get it.&lt;/p&gt;
&lt;p&gt;So, without further ado, here are some startup pitches I’m just itching to hear!&lt;/p&gt;
&lt;h2 id=&quot;bigger-bolder-developer-platforms&quot;&gt;Bigger, bolder developer platforms&lt;/h2&gt;
&lt;p&gt;It should come as a surprise to no one that I’m an active investor in the developer products space (some of my investments here include &lt;a href=&quot;https://www.imgix.com/&quot;&gt;Imgix&lt;/a&gt;, &lt;a href=&quot;https://iterative.ai/&quot;&gt;Iterative.ai&lt;/a&gt;, &lt;a href=&quot;http://sentenai.com/&quot;&gt;Sentenai&lt;/a&gt;, and &lt;a href=&quot;https://www.envkey.com/&quot;&gt;EnvKey&lt;/a&gt;). Here are several ecosystem-wide problems that I think about a lot, and for which I’m eager to hear a good solution.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;An open app runtime&lt;/strong&gt; – Proprietary mobile app runtimes are winning, as they provide a better user experience, better performance, and greater security than the open web. Proprietary app stores are winning too – and in the process, they are distorting markets and censoring apps. The open web is in full retreat, but the war has not been lost. There are still far more web developers than native developers, and they’re just waiting for a platform that can really go toe-to-toe with native apps. Could a browser be built that provides an actually better app experience and performance than native apps? What legacy could we throw out to make this happen? URLs? The DOM? Even HTML?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A new developer-oriented touchscreen OS&lt;/strong&gt; – The number of touchscreens in our daily lives is exploding. Android and iOS are optimized for consumer tablets and phones, but what if you’re a developer building a non-consumer product? What if you want to build a cash register, or a digital menu, or an in-flight entertainment solution, or a vending machine?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Federated databases&lt;/strong&gt; – The most common use case I hear for “the blockchain” is the ability to have a database “in the cloud” that multiple parties can share without needing to trust a single, central authority to run it. We don’t need blockchain for this! Tools like git have already partially solved this problem for source code. Could a similar solution be built for structured data? Could cryptography provide solutions for access control and auditing that provide protections against malicious actors?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Re-inventing the package manager&lt;/strong&gt; – existing package managers are security and compliance nightmares. What if a package manager could give me confidence that the software I’m relying on is built by trustworthy people, has dependencies I understand, has a license I understand, and will continue to be maintained going forward? Or, what if a package manager could help developers of open source software monetize their work?&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;social-silo-busters&quot;&gt;Social Silo-busters&lt;/h2&gt;
&lt;p&gt;Facebook started as a way to share updates with your friends. Instagram and Snapchat started as ways to share photos. YouTube began as a way to share videos. Twitter began as a way to share short thoughts.&lt;/p&gt;
&lt;p&gt;Each of these services _started _as a way to help the producers of content get their message out to the world. They thrived and grew rapidly. But then they changed… the advertising business model created an incentive not just to help people produce and share content, but to keep people in the app as long as possible. They morphed into carefully engineered machines for sucking up as much of your time and attention as possible. They encouraged narcissism, clickbait, partisan politics, “fake news”, creepy videos, and other negatives. They stopped being healthy, fun ways to connect with your loved ones.&lt;/p&gt;
&lt;p&gt;Then came privacy issues. Advertising requires personal data, so these companies began mining our personal communications for ad targeting. This led to adverse product decisions – weakening of encryption, overly-liberal privacy defaults, merging of personal data between seemingly independent sources, “creepy” behavior, and so on.&lt;/p&gt;
&lt;p&gt;People are becoming aware of these problems like never before, and they’re beginning to demand better solutions. Below are some areas that I would be excited to invest in:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Social utilities&lt;/strong&gt; – What if a social app was optimized for the creation experience rather than the consumption experience? What if the goal was to minimize time-in-app rather than maximize it? What social products would people pay for? (note: Google Photos is the closest I’ve seen to this so far)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Messaging and Email&lt;/strong&gt; – in the beginning, we had email. And it was federated, and open, and it was good. Then came spam, and mobile, and tons of images and video, and new security threats. With these new requirements, we still had email, but now we also had SMS, and Whatsapp, and iMessage, and Messenger, and WeChat, and Skype, and Twitter DMs, and Hangouts, and Slack. And, it is unusable. Is it possible to return to a single, federated protocol that supports modern requirements? Could email be upgraded to make this possible, or could a new open, federated service be invented? Could we break up the messaging silos and return to a single unified inbox?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;A social calendar&lt;/strong&gt; – Google seems to be winning the calendar fight without really trying. Their basic UI and functionality hasn’t changed in years. Why can’t my calendar better help me manage my day? Why can’t it make it easier for me to spend time with friends and family? Why can’t I more easily see the calendars of businesses and events nearby? The existence of Doodle, Stanza.co, and other products built around the calendar to plug its feature gaps tells me this space is ripe for a new approach.&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;capital-heavy-industries&quot;&gt;Capital-heavy Industries&lt;/h2&gt;
&lt;p&gt;Capital-lite startups have reigned for the last decade. AirBnB, Uber, and Instacart have been poster-children of this movement. “Let someone else own the assets,” they said. “We’ll just bring the software”.&lt;/p&gt;
&lt;p&gt;There were some big successes here, to be sure, but I think we’re now starting to see that there are limits to innovation when all you have is software. More recently, we’ve started to see what can be done when software is combined with capital assets: Bird and LimeBike are buying huge numbers of scooters, SpaceX, Rocket Lab, and others are building new launch vehicles, Joby Aviation is building new airplanes, and WeWork is one of the world’s biggest landlords. Public tech companies are even better examples of this: Tesla is investing billions in batteries and manufacturing, Amazon is investment billions in distribution centers, and Google, Microsoft, and Amazon are investing $10’s of billions on data centers for their cloud products.&lt;/p&gt;
&lt;p&gt;I’m very bullish on a capital-heavy, asset-full future for startups. I believe this combination will be needed to tackle our most pressing problems: energy, infrastructure, transportation, and so on. Some capital-heavy investments I’ve made already include &lt;a href=&quot;https://www.charmindustrial.com/&quot;&gt;Charm&lt;/a&gt;, &lt;a href=&quot;https://b8ta.com/&quot;&gt;B8ta&lt;/a&gt;, &lt;a href=&quot;https://www.crunchbase.com/organization/aurrion#section-overview&quot;&gt;Aurrion&lt;/a&gt;, and &lt;a href=&quot;https://sigora.co/&quot;&gt;Sigora&lt;/a&gt;, and. I remain very excited about the space, and below I’ve listed some specific areas I’d be excited to invest in.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Waste management&lt;/strong&gt; – how can technology transform this sector? For example, could AI be used to sort recyclables and other valuables efficiently out of trash? Why can’t I manage waste pickup from an app? What might a re-invented garbage truck look like?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Next-gen ISPs&lt;/strong&gt; – Fixed wireless radios, cheap satellites, LoRa, and mesh networking have the potential to make existing wired ISPs obsolete, as well as to bring internet access to billions in the developing world, and trillions of IoT devices.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Utility-scale batteries&lt;/strong&gt; – energy storage is critical to a clean energy future, but today’s batteries are too expensive. If size, weight, and mobility constraints are removed, could battery costs per KWh be reduced 90%? 99%? Many people are already working on flow batteries and other technologies in this space, but I believe much more investment is needed here.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Electric charging stations&lt;/strong&gt; – Electric charging is less dangerous, less toxic, and more space efficient than pumping gas, meaning it’s more practical to place it next to shopping, food, and entertainment. In addition, charging a car takes longer than filling a gas tank. Could the “gas stations” of the future be exciting destinations rather than eyesores?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Air conditioning&lt;/strong&gt; – As more people in hot climates enter the middle class, and as climate change accelerates, the demand for air conditioning will explode. What innovation is possible here?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alternative energy generation&lt;/strong&gt; – Ocean thermal? Fusion? Thorium? Biofuels? Fuel cells? Bring me your crazy.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Experiential retail&lt;/strong&gt; – many traditional retailers are dying at the same time that B8ta, Apple, Amazon, and Warby Parker are growing rapidly. People will always like to shop, but they’ll look to stores for experiences and product discovery, rather than as just a place to buy things. What new businesses will emerge from this shift?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;New aircraft for regional transit&lt;/strong&gt; – Aircraft have historically been used almost exclusively for long-range transportation, but could cheaper, denser batteries and smarter AI make short-range, regional air travel practical? How could these new aircraft change cities, especially in emerging markets? Many people are already working on this space, including Joby Aviation, Kitty Hawk, Lilium, and others, but I believe much more investment is warranted here, given the size of the opportunity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Receiver-centric package delivery&lt;/strong&gt; – why do we still mail packages to an address rather than to a person? When I shop online, why are my delivery options limited by what the retailer chooses to support? Why can’t I see a list of all packages en-route to me from a single app and re-route them to a different address with one button click? If I’m on vacation, why can’t I have my packages held and delivered on a future date, or placed in a nearby locker until I return?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Space&lt;/strong&gt; – what opportunities will cheap commercial rocket launches open up?&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;sleeper-markets&quot;&gt;Sleeper Markets&lt;/h2&gt;
&lt;p&gt;Despite all of the recent “disruption” from Silicon Valley, there are still many huge industries that have been left largely untouched. Many of these industries look boring from the outside, or appear to have intractable problems that software can’t solve. When a startup does manage to crack one of these markets, though, they find themselves with a huge market and no competition in site.&lt;/p&gt;
&lt;p&gt;Investments I’ve made in these “sleeper” markets include &lt;a href=&quot;https://openlattice.com/#/&quot;&gt;OpenLattice&lt;/a&gt;, &lt;a href=&quot;https://www.itsfairy.com/&quot;&gt;Fairy&lt;/a&gt;, and &lt;a href=&quot;https://embarktrucks.com/&quot;&gt;Embark&lt;/a&gt;. Here are some additional startups I’d like to fund:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;New staffing agencies&lt;/strong&gt; – companies like Adecco and Manpower take a huge cut of workers’ pay, and the industry hasn’t fundamentally changed in years. Could a new staffing agency use software to provide higher quality staffing to companies and better pay and services to workers?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;New insurance companies&lt;/strong&gt; – renters insurance, title insurance, business insurance, etc have yet to enter the 21st century.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;New media companies&lt;/strong&gt; – BuzzFeed, Vox, and Huffington Post have built successful online-first media businesses. What does the internet-native version of the WSJ or The Economist look like?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Online zoo&lt;/strong&gt; – Animals are more popular than ever. 700 million people visit a zoo each year. Online, videos of animals are among the most popular. Meanwhile, climate change and habitat destruction are threatening our world’s wildlife, and many endangered animals are at risk because local communities lack the funds to effectively protect them. Could an online zoo address a huge underserved market while simultaneously help to save wildlife? Could high speed internet and VR finally make this a really good experience?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you’re working in one of these areas, feel free to reach out to me: startupandrew (at) gmail dot com. I typically like to invest early in pre-seed or seed (though I’ve invested all the way up through Series B in the past). A normal first check from me ranges from $50k to $250k.&lt;/p&gt;
&lt;p&gt;Besides providing just money, as an investor I can be especially helpful advising on engineering plans, team-building, and overall business strategy. I also can provide introductions to other investors, and in some cases, help with hiring and business development.&lt;/p&gt;
&lt;p&gt;If you’re a founder who is just starting out, and you’re not yet looking for investment, feel free to borrow some ideas from this list. And, don’t be shy about reaching out as well. I’d be interested in hearing about your plans, and I may be able to provide more insight into the space you’re tackling too.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to Max Henderson, &lt;a href=&quot;https://twitter.com/JamesTamplin&quot;&gt;James Tamplin&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/reinpk&quot;&gt;Peter Reinhardt&lt;/a&gt;, and &lt;a href=&quot;https://twitter.com/binarybits&quot;&gt;Timothy Lee&lt;/a&gt; for reviewing drafts of this post.&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 02 Oct 2018 16:56:56 +0000</pubDate>
<dc:creator>vikrum</dc:creator>
<og:title>Startups I Want to Fund</og:title>
<og:description>I hear a lot of startup pitches. I’ve been angel investing now for ~4 years, and I’m an LP and advisor to a number of VC funds. I also heard a lot of pitches through my work at Firebase (the company I co-founded), as many of its customers are startups. I like being pitched – partly because I enjoy meeting smart people, and partly because it’s a chance to pay-it-forward to the next cohort of entrepreneurs, but largely because it’s a chance to be a part of the solution to some of the world’s biggest problems.</og:description>
<og:type>article</og:type>
<og:url>https://startupandrew.com/posts/startups-i-want-to-fund/</og:url>
<og:image>https://startupandrew.com/images/andrew.jpg</og:image>
<dc:language>en-us</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://startupandrew.com/posts/startups-i-want-to-fund/</dc:identifier>
</item>
<item>
<title>Facebook launches PyTorch 1.0</title>
<link>https://code.fb.com/ai-research/facebook-accelerates-ai-development-with-new-partners-and-production-capabilities-for-pytorch-1-0/</link>
<guid isPermaLink="true" >https://code.fb.com/ai-research/facebook-accelerates-ai-development-with-new-partners-and-production-capabilities-for-pytorch-1-0/</guid>
<description>&lt;p&gt;Earlier this year, &lt;a href=&quot;https://code.fb.com/ai-research/announcing-pytorch-1-0-for-both-research-and-production/&quot;&gt;we shared a vision&lt;/a&gt; for making AI development faster and more interoperable. Today, during our first-ever PyTorch Developer Conference, we are announcing updates about the growing ecosystem of software, hardware, and education partners that are deepening their investment in PyTorch. We’re also bringing together our active community of researchers, engineers, educators, and more to share how they’re using the open source deep learning platform for research and production, and walking through more details on the preview release of PyTorch 1.0.&lt;/p&gt;
&lt;p&gt;PyTorch 1.0 accelerates the workflow involved in taking breakthrough research in artificial intelligence to production deployment. With deeper cloud service support from Amazon, Google, and Microsoft, and tighter integration with technology providers ARM, Intel, IBM, NVIDIA, and Qualcomm, developers can more easily take advantage of PyTorch’s ecosystem of compatible software, hardware, and developer tools. The more software and hardware that is compatible with PyTorch 1.0, the easier it will be for AI developers to quickly build, train, and deploy state-of-the-art deep learning models.&lt;/p&gt;
&lt;h2&gt;What’s new in PyTorch 1.0&lt;/h2&gt;
&lt;p&gt;The latest additions to the framework include a new hybrid front end that enables tracing and scripting models from eager mode into graph mode for bridging the gap between exploration and production deployment, a revamped torch.distributed library that allows for faster training across Python and C++ environments, and an eager mode C++ interface (released in beta) for performance-critical research.&lt;/p&gt;
&lt;p&gt;Currently, researchers and engineers have to work across a number of frameworks and tools, many of which are often incompatible, to prototype new deep learning models and transfer them to run at scale in a production environment. Doing this slows down the rate at which we can deploy AI research breakthroughs at production scale. With this latest release, we’ve combined the flexibility of the existing PyTorch framework with the production capabilities of Caffe2 to deliver a seamless path from research to production-ready AI.&lt;/p&gt;
&lt;h2&gt;Deeper support from the ecosystem&lt;/h2&gt;
&lt;p&gt;AWS, Google, and Microsoft are deepening their investment in PyTorch 1.0 through more robust support for the framework across their cloud platforms, products, and services. For example, &lt;a href=&quot;https://aws.amazon.com/pytorch/&quot;&gt;Amazon SageMaker&lt;/a&gt;, AWS’s fully managed platform for training and deploying machine learning models at scale, now provides preconfigured environments for PyTorch 1.0, which include rich capabilities such as automatic model tuning.&lt;/p&gt;
&lt;p&gt;Google is &lt;a href=&quot;https://cloud.google.com/blog/products/ai-machine-learning/introducing-pytorch-across-google-cloud&quot;&gt;announcing new PyTorch 1.0 integrations&lt;/a&gt; across its software and hardware tools for AI development. Google Cloud Platform’s Deep Learning VM has a new VM image with PyTorch 1.0 that comes with NVIDIA drivers and tutorials preinstalled. Google also offers Cloud Tensor Processing Units (TPUs), which are custom-developed application-specific integrated circuits (ASIC) for machine learning (ML). Engineers on Google’s Cloud TPU team are in active collaboration with our PyTorch team to enable support for PyTorch 1.0 models on this custom hardware.&lt;/p&gt;
&lt;p&gt;Microsoft, an early partner with Facebook on another important AI initiative, &lt;a href=&quot;http://onnx.ai/&quot;&gt;ONNX&lt;/a&gt;, is also furthering its commitment to &lt;a href=&quot;https://azure.microsoft.com/en-us/blog/world-class-pytorch-support-on-azure/&quot;&gt;providing first-class support for PyTorch across its suite of machine learning offerings&lt;/a&gt;. Azure Machine Learning service now allows developers to seamlessly move from training PyTorch models on a local machine to scaling out on the Azure cloud. For data science experimentation, Microsoft is offering preconfigured Data Science Virtual Machines (DSVM) that are preinstalled with PyTorch. For developers looking to start exploring PyTorch without having to install software and set up a local machine, Azure Notebooks provides a free, cloud-hosted Jupyter Notebooks solution set up with PyTorch tutorials. Finally, Visual Studio Code’s Tools for AI extension provides tight integration of Azure ML and PyTorch APIs for streamlined PyTorch code development and training.&lt;/p&gt;
&lt;p&gt;In addition to software and cloud service providers, technology partners — including &lt;a href=&quot;https://community.arm.com/tools/b/blog/posts/facebook-arm-machine-learning-beyond-the-perfect-selfie&quot;&gt;ARM&lt;/a&gt;, &lt;a href=&quot;https://developer.ibm.com/blogs/2018/10/01/announcing-pytorch-1-support-in-fabric-for-deep-learning/&quot;&gt;IBM&lt;/a&gt;, &lt;a href=&quot;https://ai.intel.com/investing-in-the-pytorch-developer-community/&quot;&gt;Intel&lt;/a&gt;, &lt;a href=&quot;https://news.developer.nvidia.com/pytorch-1-0-accelerated-on-nvidia-gpus/&quot;&gt;NVIDIA&lt;/a&gt;, and &lt;a href=&quot;https://developer.qualcomm.com/blog/snapdragon-supports-pytorch-10-ai-research-and-production-same-framework&quot;&gt;Qualcomm&lt;/a&gt; — are adding support for PyTorch 1.0 through direct optimizations, kernel library integration, and support for additional tools such as compilers and inference runtimes. This extra support ensures that PyTorch developers can run models across a broad array of hardware, optimized for training and inference, for both data center and edge devices.&lt;/p&gt;
&lt;h2&gt;Educating future AI developers&lt;/h2&gt;
&lt;p&gt;We’ve already seen a variety of education providers using the existing PyTorch framework to teach deep learning in online programs and university courses. The framework’s approachability and deep integration into Python have made it easier for students to understand and experiment with various deep learning concepts. With the evolution of PyTorch 1.0, we’re thrilled that more partners will be further focusing their curricula around it.&lt;/p&gt;
&lt;p&gt;Udacity is partnering with Facebook to &lt;a href=&quot;https://blog.udacity.com/2018/10/introducing-the-pytorch-scholarship-challenge-from-facebook.html&quot;&gt;give developers access to a free Intro to Deep Learning course&lt;/a&gt;, which is taught entirely on PyTorch. In addition, Facebook will sponsor 300 students who have successfully completed this intermediate-level course to continue their education in Udacity’s Deep Learning Nanodegree program, which has been revamped to run on PyTorch 1.0.&lt;/p&gt;
&lt;p&gt;Fast.ai, which offers free online courses for introductory and advanced deep learning and machine learning using PyTorch, is &lt;a href=&quot;http://www.fast.ai/2018/10/02/fastai-ai/&quot;&gt;announcing the first release of fastai, an open source software library built on top of PyTorch 1.0&lt;/a&gt;. The library offers improved accuracy and speed with significantly less code, making deep learning more accessible to new and experienced developers.&lt;/p&gt;
&lt;h2&gt;Continued collaboration&lt;/h2&gt;
&lt;p&gt;We are excited to hear from the community as you begin working with PyTorch 1.0 over the coming months. We also look forward to continuing our collaboration with leaders in the deep learning ecosystem, to help more people take advantage of AI and accelerate the path from research to production.&lt;/p&gt;
&lt;p&gt;To get started, download the &lt;a href=&quot;https://pytorch.org/get-started&quot;&gt;developer preview&lt;/a&gt; of PyTorch 1.0, or experience it with one of our cloud partners. We also welcome the entire PyTorch community to join the full day of live stream talks from the core PyTorch team at Facebook, as well as from contributors and organizations in academia, industry, and more at &lt;a href=&quot;http://facebook.com/pytorch&quot;&gt;facebook.com/pytorch&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;We’d like to thank the entire PyTorch 1.0 team for its contributions to this work.&lt;/em&gt;&lt;/p&gt;

</description>
<pubDate>Tue, 02 Oct 2018 16:40:25 +0000</pubDate>
<dc:creator>jimarcey</dc:creator>
<og:type>article</og:type>
<og:title>Facebook accelerates AI development with new partners and production capabilities for PyTorch 1.0</og:title>
<og:url>https://code.fb.com/ai-research/facebook-accelerates-ai-development-with-new-partners-and-production-capabilities-for-pytorch-1-0/</og:url>
<og:description>Earlier this year, we shared a vision for making AI development faster and more interoperable. Today, during our first-ever PyTorch Developer Conference, we are announcing updates about the growing…</og:description>
<og:image>https://code.fb.com/wp-content/uploads/2018/09/PyTorch_Blog-Post_Hero.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://code.fb.com/ai-research/facebook-accelerates-ai-development-with-new-partners-and-production-capabilities-for-pytorch-1-0/</dc:identifier>
</item>
<item>
<title>Ferret – Declarative web scraping</title>
<link>https://github.com/MontFerret/ferret</link>
<guid isPermaLink="true" >https://github.com/MontFerret/ferret</guid>
<description>&lt;div class=&quot;Box-body p-6&quot;&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://travis-ci.com/MontFerret/ferret&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/13ebdef2cf9f039a31e38327efebe6f36638543b/68747470733a2f2f7472617669732d63692e636f6d2f4d6f6e744665727265742f6665727265742e7376673f6272616e63683d6d6173746572&quot; alt=&quot;Build Status&quot; data-canonical-src=&quot;https://travis-ci.com/MontFerret/ferret.svg?branch=master&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://raw.githubusercontent.com/MontFerret/ferret/master/assets/intro.jpg&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/MontFerret/ferret/master/assets/intro.jpg&quot; alt=&quot;ferret&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;What is it?&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;ferret&lt;/code&gt; is a web scraping system aiming to simplify data extraction from the web for such things like ui testing, machine learning and analytics.&lt;br/&gt;Having it's own declarative language, &lt;code&gt;ferret&lt;/code&gt; abstracts away technical details and complexity of the underlying technologies, helping to focus on the data itself.&lt;br/&gt;It's extremely portable, extensible and fast.&lt;/p&gt;
&lt;h2&gt;Show me some code&lt;/h2&gt;
&lt;p&gt;&lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://raw.githubusercontent.com/MontFerret/ferret/master/assets/example.jpg&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/MontFerret/ferret/master/assets/example.jpg&quot; alt=&quot;example&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The following example demonstrates the use of dynamic pages.&lt;br/&gt;First of all, we load the main Google Search page, type search criteria into an input box and then click a search button.&lt;br/&gt;The click action triggers a redirect, so we wait till its end.&lt;br/&gt;Once the page gets loaded, we iterate over all elements in search results and assign output to a variable.&lt;br/&gt;The final for loop filters out empty elements that might be because of inaccurate use of selectors.&lt;/p&gt;
&lt;pre lang=&quot;aql&quot;&gt;
&lt;code&gt;LET google = DOCUMENT(&quot;https://www.google.com/&quot;, true)

INPUT(google, 'input[name=&quot;q&quot;]', &quot;ferret&quot;)
CLICK(google, 'input[name=&quot;btnK&quot;]')

WAIT_NAVIGATION(google)

LET result = (
    FOR result IN ELEMENTS(google, '.g')
       RETURN {
           title: ELEMENT(result, 'h3 &amp;gt; a'),
           description: ELEMENT(result, '.st'),
           url: ELEMENT(result, 'cite')
       }
)

RETURN (
    FOR page IN result
    FILTER page.title != NONE
    RETURN page
)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;Features&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;Declarative language&lt;/li&gt;
&lt;li&gt;Support of both static and dynamic web pages&lt;/li&gt;
&lt;li&gt;Embeddable&lt;/li&gt;
&lt;li&gt;Extensible&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Motivation&lt;/h2&gt;
&lt;p&gt;Nowadays data is everything and who owns data - owns the world.&lt;br/&gt;I have worked on multiple data-driven projects where data was an essential part of a system and I realized how cumbersome writing tons of scrapers is.&lt;br/&gt;After some time looking for a tool that would let me to not write a code, but just express what data I need, decided to come up with my own solution.&lt;br/&gt;&lt;code&gt;ferret&lt;/code&gt; project is an ambitious initiative trying to bring universal platform for writing scrapers without any hassle.&lt;/p&gt;
&lt;h2&gt;Inspiration&lt;/h2&gt;
&lt;p&gt;FQL (Ferret Query Language) is heavily inspired by &lt;a href=&quot;https://www.arangodb.com/&quot; rel=&quot;nofollow&quot;&gt;AQL&lt;/a&gt; (ArangoDB Query Language).&lt;br/&gt;But due to the domain specifics, there are some differences in how things work.&lt;/p&gt;
&lt;h2&gt;WIP&lt;/h2&gt;
&lt;p&gt;Be aware, the the project is under heavy development. There is no documentation and some things may change in the final release.&lt;br/&gt;For query syntax, you may go to &lt;a href=&quot;https://docs.arangodb.com/3.3/AQL/index.html&quot; rel=&quot;nofollow&quot;&gt;ArangoDB web site&lt;/a&gt; and use AQL docs as docs for FQL - since they are identical.&lt;/p&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;h3&gt;Prerequisites&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Go &amp;gt;=1.6&lt;/li&gt;
&lt;li&gt;GoDep&lt;/li&gt;
&lt;li&gt;GNU Make&lt;/li&gt;
&lt;li&gt;Chrome or Docker (optional)&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
make build
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can use your local copy of Google Chrome / Chromium, but for ease of use it's recommended to run it inside a Docker container:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
docker pull alpeware/chrome-headless-trunk
docker run -d -p=0.0.0.0:9222:9222 --name=chrome-headless -v /tmp/chromedata/:/data alpeware/chrome-headless-trunk
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Quick start&lt;/h2&gt;
&lt;h3&gt;Browserless mode&lt;/h3&gt;
&lt;p&gt;If you want to play with &lt;code&gt;fql&lt;/code&gt; and check its syntax, you can run CLI with the following commands:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;go run ./cmd/cli/main.go
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;ferret&lt;/code&gt; will run in REPL mode.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
Welcome to Ferret REPL
Please use &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;Ctrl-D&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt; to &lt;span class=&quot;pl-c1&quot;&gt;exit&lt;/span&gt; this program.
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;%
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;LET doc = DOCUMENT(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;https://news.ycombinator.com/&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;FOR post IN ELEMENTS(doc, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;.storylink&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;RETURN post.attributes.href
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;%
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; symbol &lt;code&gt;%&lt;/code&gt; is used to start and end multi line queries. You also can use heredoc format.&lt;/p&gt;
&lt;p&gt;If you want to execute a query stored in a file, just pass a file name:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;go run ./cmd/cli/main.go ./docs/examples/hackernews.fql
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;cat ./docs/examples/hackernews.fql | go run ./cmd/cli/main.go 
&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;go run ./cmd/cli/main.go &amp;lt; ./docs/examples/hackernews.fql
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3&gt;Browser mode&lt;/h3&gt;
&lt;p&gt;By default, &lt;code&gt;ferret&lt;/code&gt; loads HTML pages via http protocol, because it's faster.&lt;br/&gt;But nowadays, there are more and more websites rendered with JavaScript, and therefore, this 'old school' approach does not really work.&lt;br/&gt;For such cases, you may fetch documents using Chrome or Chromium via Chrome DevTools protocol (aka CDP).&lt;br/&gt;First, you need to make sure that you launched Chrome with &lt;code&gt;remote-debugging-port=9222&lt;/code&gt; flag.&lt;br/&gt;Second, you need to pass the address to &lt;code&gt;ferret&lt;/code&gt; CLI.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;go run ./cmd/cli/main.go --cdp http://127.0.0.1:9222
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; By default, &lt;code&gt;ferret&lt;/code&gt; will try to use this local address as a default one, so it makes sense to explicitly pass the parameter only in case of either different port number or remote address.&lt;/p&gt;
&lt;p&gt;Alternatively, you can tell CLI to launch Chrome for you.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
go run ./cmd/cli/main.go --cdp-launch
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Launch command is currently broken on MacOS.&lt;/p&gt;
&lt;p&gt;Once &lt;code&gt;ferret&lt;/code&gt; knows how to communicate with Chrome, you can use a function &lt;code&gt;DOCUMENT(url, isDynamic)&lt;/code&gt; with &lt;code&gt;true&lt;/code&gt; boolean value for dynamic pages:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
Welcome to Ferret REPL
Please use &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;exit&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt; or &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;Ctrl-D&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt; to &lt;span class=&quot;pl-c1&quot;&gt;exit&lt;/span&gt; this program.
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;%
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;LET doc = DOCUMENT(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;https://soundcloud.com/charts/top&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, true)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;WAIT_ELEMENT(doc, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;.chartTrack__details&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;, 5000)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;LET tracks = ELEMENTS(doc, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;.chartTrack__details&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;FOR track IN tracks
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;    LET username = ELEMENT(track, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;.chartTrack__username&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;    LET title = ELEMENT(track, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;.chartTrack__title&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;    RETURN {
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;       artist: username.innerText,
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;        track: title.innerText
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;    }
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;%
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
Welcome to Ferret REPL
Please use &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;exit&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt; or &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;Ctrl-D&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt; to &lt;span class=&quot;pl-c1&quot;&gt;exit&lt;/span&gt; this program.
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;%
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;LET doc = DOCUMENT(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;https://github.com/&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;, true)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;LET btn = ELEMENT(doc, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;.HeaderMenu a&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;)

&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;CLICK(btn)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;WAIT_NAVIGATION(doc)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;WAIT_ELEMENT(doc, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;.IconNav&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)

&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;FOR el IN ELEMENTS(doc, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;.IconNav a&lt;span class=&quot;pl-pds&quot;&gt;'&lt;/span&gt;&lt;/span&gt;)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;    RETURN TRIM(el.innerText)
&lt;span class=&quot;pl-k&quot;&gt;&amp;gt;&lt;/span&gt;%
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;Embedded mode&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;ferret&lt;/code&gt; is a very modular system and therefore, can be easily be embedded into your Go application.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-go&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-k&quot;&gt;package&lt;/span&gt; main

&lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; (
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;context&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;encoding/json&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;fmt&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;github.com/MontFerret/ferret/pkg/compiler&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;os&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
)

&lt;span class=&quot;pl-k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;pl-v&quot;&gt;Topic&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;struct&lt;/span&gt; {
        &lt;span class=&quot;pl-v&quot;&gt;Name&lt;/span&gt;        &lt;span class=&quot;pl-k&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;json:&quot;name&quot;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-v&quot;&gt;Description&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;json:&quot;description&quot;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-v&quot;&gt;Url&lt;/span&gt;         &lt;span class=&quot;pl-k&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;json:&quot;url&quot;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt;
}

&lt;span class=&quot;pl-k&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;main&lt;/span&gt;() {
        &lt;span class=&quot;pl-smi&quot;&gt;topics&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;getTopTenTrendingTopics&lt;/span&gt;()

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                fmt.&lt;span class=&quot;pl-c1&quot;&gt;Println&lt;/span&gt;(err)
                os.&lt;span class=&quot;pl-c1&quot;&gt;Exit&lt;/span&gt;(&lt;span class=&quot;pl-c1&quot;&gt;1&lt;/span&gt;)
        }

        &lt;span class=&quot;pl-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;pl-smi&quot;&gt;_&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;topic&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;range&lt;/span&gt; topics {
                fmt.&lt;span class=&quot;pl-c1&quot;&gt;Println&lt;/span&gt;(fmt.&lt;span class=&quot;pl-c1&quot;&gt;Sprintf&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;pl-c1&quot;&gt;%s&lt;/span&gt;: &lt;span class=&quot;pl-c1&quot;&gt;%s&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;, topic.&lt;span class=&quot;pl-smi&quot;&gt;Name&lt;/span&gt;, topic.&lt;span class=&quot;pl-smi&quot;&gt;Description&lt;/span&gt;, topic.&lt;span class=&quot;pl-smi&quot;&gt;Url&lt;/span&gt;))
        }
}

&lt;span class=&quot;pl-k&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;getTopTenTrendingTopics&lt;/span&gt;() ([]*&lt;span class=&quot;pl-v&quot;&gt;Topic&lt;/span&gt;, &lt;span class=&quot;pl-v&quot;&gt;error&lt;/span&gt;) {
        &lt;span class=&quot;pl-smi&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;             LET doc = DOCUMENT(&quot;https://github.com/topics&quot;)&lt;/span&gt;

&lt;span class=&quot;pl-s&quot;&gt;             FOR el IN ELEMENTS(doc, &quot;.py-4.border-bottom&quot;)&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                     LIMIT 10&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                     LET url = ELEMENT(el, &quot;a&quot;)&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                     LET name = ELEMENT(el, &quot;.f3&quot;)&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                     LET desc = ELEMENT(el, &quot;.f5&quot;)&lt;/span&gt;

&lt;span class=&quot;pl-s&quot;&gt;                     RETURN {&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                             name: TRIM(name.innerText),&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                             description: TRIM(desc.innerText),&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                             url: &quot;https://github.com&quot; + url.attributes.href&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                     }&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;     &lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt;

        &lt;span class=&quot;pl-smi&quot;&gt;comp&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; compiler.&lt;span class=&quot;pl-c1&quot;&gt;New&lt;/span&gt;()

        &lt;span class=&quot;pl-smi&quot;&gt;program&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; comp.&lt;span class=&quot;pl-c1&quot;&gt;Compile&lt;/span&gt;(query)

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;, err
        }

        &lt;span class=&quot;pl-smi&quot;&gt;out&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; program.&lt;span class=&quot;pl-c1&quot;&gt;Run&lt;/span&gt;(context.&lt;span class=&quot;pl-c1&quot;&gt;Background&lt;/span&gt;())

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;, err
        }

        &lt;span class=&quot;pl-smi&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;make&lt;/span&gt;([]*Topic, &lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;pl-c1&quot;&gt;10&lt;/span&gt;)

        err = json.&lt;span class=&quot;pl-c1&quot;&gt;Unmarshal&lt;/span&gt;(out, &amp;amp;res)

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;, err
        }

        &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; res, &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Extensibility&lt;/h2&gt;
&lt;p&gt;That said, &lt;code&gt;ferret&lt;/code&gt; is a very modular system which also allows not only embed it, but extend its standard library.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-go&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-k&quot;&gt;package&lt;/span&gt; main

&lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; (
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;context&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;encoding/json&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;fmt&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;github.com/MontFerret/ferret/pkg/compiler&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;github.com/MontFerret/ferret/pkg/runtime/core&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;github.com/MontFerret/ferret/pkg/runtime/values&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
        &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;os&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
)

&lt;span class=&quot;pl-k&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;main&lt;/span&gt;() {
        &lt;span class=&quot;pl-smi&quot;&gt;strs&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;getStrings&lt;/span&gt;()

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                fmt.&lt;span class=&quot;pl-c1&quot;&gt;Println&lt;/span&gt;(err)
                os.&lt;span class=&quot;pl-c1&quot;&gt;Exit&lt;/span&gt;(&lt;span class=&quot;pl-c1&quot;&gt;1&lt;/span&gt;)
        }

        &lt;span class=&quot;pl-k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;pl-smi&quot;&gt;_&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;range&lt;/span&gt; strs {
                fmt.&lt;span class=&quot;pl-c1&quot;&gt;Println&lt;/span&gt;(str)
        }
}

&lt;span class=&quot;pl-k&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;getStrings&lt;/span&gt;() ([]&lt;span class=&quot;pl-v&quot;&gt;string&lt;/span&gt;, &lt;span class=&quot;pl-v&quot;&gt;error&lt;/span&gt;) {
        &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; function implements is a type of a function that ferret supports as a runtime function&lt;/span&gt;
        &lt;span class=&quot;pl-smi&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;func&lt;/span&gt;(ctx context.&lt;span class=&quot;pl-smi&quot;&gt;Context&lt;/span&gt;, args ...&lt;span class=&quot;pl-smi&quot;&gt;core&lt;/span&gt;.&lt;span class=&quot;pl-smi&quot;&gt;Value&lt;/span&gt;) (core.&lt;span class=&quot;pl-smi&quot;&gt;Value&lt;/span&gt;, &lt;span class=&quot;pl-k&quot;&gt;error&lt;/span&gt;) {
                &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; it's just a helper function which helps to validate a number of passed args&lt;/span&gt;
                &lt;span class=&quot;pl-smi&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; core.&lt;span class=&quot;pl-c1&quot;&gt;ValidateArgs&lt;/span&gt;(args, &lt;span class=&quot;pl-c1&quot;&gt;1&lt;/span&gt;)

                &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                        &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; it's recommended to return built-in None type, instead of nil&lt;/span&gt;
                        &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; values.&lt;span class=&quot;pl-smi&quot;&gt;None&lt;/span&gt;, err
                }

                &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; this is another helper functions allowing to do type validation&lt;/span&gt;
                err = core.&lt;span class=&quot;pl-c1&quot;&gt;ValidateType&lt;/span&gt;(args[&lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;], core.&lt;span class=&quot;pl-smi&quot;&gt;StringType&lt;/span&gt;)

                &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                        &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; values.&lt;span class=&quot;pl-smi&quot;&gt;None&lt;/span&gt;, err
                }

                &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; cast to built-in string type&lt;/span&gt;
                &lt;span class=&quot;pl-smi&quot;&gt;str&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; args[&lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;].(values.&lt;span class=&quot;pl-smi&quot;&gt;String&lt;/span&gt;)

                &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; str.&lt;span class=&quot;pl-c1&quot;&gt;Concat&lt;/span&gt;(values.&lt;span class=&quot;pl-c1&quot;&gt;NewString&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;_ferret&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;)).&lt;span class=&quot;pl-c1&quot;&gt;ToUpper&lt;/span&gt;(), &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;
        }

        &lt;span class=&quot;pl-smi&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;             FOR el IN [&quot;foo&quot;, &quot;bar&quot;, &quot;qaz&quot;]&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                     // conventionally all functions are registered in upper case&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;                     RETURN TRANSFORM(el)&lt;/span&gt;
&lt;span class=&quot;pl-s&quot;&gt;     &lt;span class=&quot;pl-pds&quot;&gt;`&lt;/span&gt;&lt;/span&gt;

        &lt;span class=&quot;pl-smi&quot;&gt;comp&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; compiler.&lt;span class=&quot;pl-c1&quot;&gt;New&lt;/span&gt;()
        comp.&lt;span class=&quot;pl-c1&quot;&gt;RegisterFunction&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;transform&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;, transform)

        &lt;span class=&quot;pl-smi&quot;&gt;program&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; comp.&lt;span class=&quot;pl-c1&quot;&gt;Compile&lt;/span&gt;(query)

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;, err
        }

        &lt;span class=&quot;pl-smi&quot;&gt;out&lt;/span&gt;, &lt;span class=&quot;pl-smi&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; program.&lt;span class=&quot;pl-c1&quot;&gt;Run&lt;/span&gt;(context.&lt;span class=&quot;pl-c1&quot;&gt;Background&lt;/span&gt;())

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;, err
        }

        &lt;span class=&quot;pl-smi&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;make&lt;/span&gt;([]&lt;span class=&quot;pl-k&quot;&gt;string&lt;/span&gt;, &lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;pl-c1&quot;&gt;3&lt;/span&gt;)

        err = json.&lt;span class=&quot;pl-c1&quot;&gt;Unmarshal&lt;/span&gt;(out, &amp;amp;res)

        &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; err != &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt; {
                &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;, err
        }

        &lt;span class=&quot;pl-k&quot;&gt;return&lt;/span&gt; res, &lt;span class=&quot;pl-c1&quot;&gt;nil&lt;/span&gt;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;On top of that, you can completely turn off standard library, by passing the following option:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-go&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-smi&quot;&gt;comp&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; compiler.&lt;span class=&quot;pl-c1&quot;&gt;New&lt;/span&gt;(compiler.&lt;span class=&quot;pl-c1&quot;&gt;WithoutStdlib&lt;/span&gt;())
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And after that, you can easily provide your own implementation of functions from standard library.&lt;/p&gt;
&lt;p&gt;If you don't need a particular set of functions from standard library, you can turn off the entire &lt;code&gt;stdlib&lt;/code&gt; and register separate packages from that:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-go&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-k&quot;&gt;package&lt;/span&gt; main

&lt;span class=&quot;pl-k&quot;&gt;import&lt;/span&gt; (
    &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;github.com/MontFerret/ferret/pkg/compiler&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
    &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;github.com/MontFerret/ferret/pkg/stdlib/strings&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;
)

&lt;span class=&quot;pl-k&quot;&gt;func&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;main&lt;/span&gt;() {
    &lt;span class=&quot;pl-smi&quot;&gt;comp&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;:=&lt;/span&gt; compiler.&lt;span class=&quot;pl-c1&quot;&gt;New&lt;/span&gt;(compiler.&lt;span class=&quot;pl-c1&quot;&gt;WithoutStdlib&lt;/span&gt;())

    comp.&lt;span class=&quot;pl-c1&quot;&gt;RegisterFunctions&lt;/span&gt;(strings.&lt;span class=&quot;pl-c1&quot;&gt;NewLib&lt;/span&gt;())
}
&lt;/pre&gt;&lt;/div&gt;
&lt;/article&gt;&lt;/div&gt;
</description>
<pubDate>Tue, 02 Oct 2018 15:59:34 +0000</pubDate>
<dc:creator>ziflex</dc:creator>
<og:image>https://avatars0.githubusercontent.com/u/39228646?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>MontFerret/ferret</og:title>
<og:url>https://github.com/MontFerret/ferret</og:url>
<og:description>Declarative web scraping. Contribute to MontFerret/ferret development by creating an account on GitHub.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/MontFerret/ferret</dc:identifier>
</item>
</channel>
</rss>