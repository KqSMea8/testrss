<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>REST is the new SOAP</title>
<link>https://medium.com/@pakaldebonchamp/rest-is-the-new-soap-97ff6c09896d</link>
<guid isPermaLink="true" >https://medium.com/@pakaldebonchamp/rest-is-the-new-soap-97ff6c09896d</guid>
<description>&lt;p name=&quot;dd88&quot; id=&quot;dd88&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;written by Pascal Chambon, reviewed by Raphaël Gomès — December 15, 2017&lt;/em&gt;&lt;/p&gt;
&lt;h3 name=&quot;8feb&quot; id=&quot;8feb&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Introduction&lt;/h3&gt;
&lt;p name=&quot;03ec&quot; id=&quot;03ec&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Some years ago, I developed a new information system in a big telecom company. We had to communicate with an increasing number of web services, exposed by older systems or by business partners.&lt;/p&gt;
&lt;p name=&quot;7a39&quot; id=&quot;7a39&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Needless to say, we had our fair share of &lt;a href=&quot;https://en.wikipedia.org/wiki/SOAP&quot; data-href=&quot;https://en.wikipedia.org/wiki/SOAP&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;SOAP&lt;/a&gt; Hell. Abstruse &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_Services_Description_Language&quot; data-href=&quot;https://en.wikipedia.org/wiki/Web_Services_Description_Language&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;WSDLs&lt;/a&gt;, incompatible libraries, weird bugs… So whenever we could, we advocated — and used — simple Remote Procedure Call protocols: XMLRPC or JSONRPC.&lt;/p&gt;
&lt;p name=&quot;088f&quot; id=&quot;088f&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Our first servers and clients for these protocols were pretty basic, limited, fragile. But gradually, we improved them; and with a few hundreds lines of additional code, we achieved the dream: support for different dialects (such as Apache-specific XMLRPC extensions), built-in conversion between python exceptions and hierarchical error codes, separate handling of functional and technical errors, auto-retries for the latter, relevant logging and stats before/after requests, thorough validation of input data…&lt;/p&gt;
&lt;p name=&quot;acef&quot; id=&quot;acef&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Now we were able to robustly connect to any such API, with just a few lines of code.&lt;/p&gt;
&lt;p name=&quot;a7cc&quot; id=&quot;a7cc&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Now we were able to expose any set of functions to a wide audience, to servers and to web browsers, with a few decorators and doc updates.&lt;/p&gt;
&lt;p name=&quot;21ae&quot; id=&quot;21ae&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;And when it came to communicating between our different applications (microservice-style), it was a job for our system administrator; software-side, it was almost transparent.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*s5CjnzON8j3VV2EB2m_AYw.jpeg&quot; data-width=&quot;955&quot; data-height=&quot;470&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*s5CjnzON8j3VV2EB2m_AYw.jpeg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*s5CjnzON8j3VV2EB2m_AYw.jpeg&quot;/&gt;&lt;/div&gt;
Developer resting after a tough 30mn spent integrating an RPC API.
&lt;p name=&quot;6614&quot; id=&quot;6614&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Then came REST. &lt;br/&gt;REpresentational State Transfer.&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;9c84&quot; id=&quot;9c84&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;A wave of renewal shook the foundations of inter-services communication.&lt;/p&gt;
&lt;p name=&quot;0304&quot; id=&quot;0304&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;RPC was dead, the future was RESTful: resources living each on its own URL, and manipulated exclusively through HTTP protocol.&lt;/p&gt;
&lt;p name=&quot;c6b1&quot; id=&quot;c6b1&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;From then on, every API we had to expose or consume became a new challenge; not to say a testimony to insanity.&lt;/p&gt;
&lt;h3 name=&quot;bb20&quot; id=&quot;bb20&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;What’s the problem with REST?&lt;/h3&gt;
&lt;p name=&quot;c43f&quot; id=&quot;c43f&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;A short example is worth a long talk. Here is a small API, with data types removed for readability.&lt;/p&gt;
&lt;pre name=&quot;5a40&quot; id=&quot;5a40&quot; class=&quot;graf graf--pre graf-after--p&quot;&gt;
createAccount(username, contact_email, password) -&amp;gt; account_id
&lt;/pre&gt;
&lt;pre name=&quot;45c7&quot; id=&quot;45c7&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
addSubscription(account_id, subscription_type) -&amp;gt; subscription_id
&lt;/pre&gt;
&lt;pre name=&quot;337e&quot; id=&quot;337e&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
sendActivationReminderEmail(account_id) -&amp;gt; null
&lt;/pre&gt;
&lt;pre name=&quot;8e57&quot; id=&quot;8e57&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
cancelSubscription(subscription_id, reason, immediate=True) -&amp;gt; null
&lt;/pre&gt;
&lt;pre name=&quot;c449&quot; id=&quot;c449&quot; class=&quot;graf graf--pre graf-after--pre&quot;&gt;
getAccountDetails(account_id) -&amp;gt; {full data tree}
&lt;/pre&gt;
&lt;p name=&quot;dafa&quot; id=&quot;dafa&quot; class=&quot;graf graf--p graf-after--pre&quot;&gt;Just add a properly documented hierarchy of exceptions (InvalidParameterError, MissingParameterError, WorkflowError…), with subclasses to identify important cases (eg. AlreadyExistingUsernameError), and you’re good to go.&lt;/p&gt;
&lt;p name=&quot;8c0f&quot; id=&quot;8c0f&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This API is easy to understand, easy to use, and robust. It is backed by a precise state machine, but the restricted set of available operations keeps users away from nonsensical interactions (like changing the creation date of an Account).&lt;/p&gt;
&lt;p name=&quot;59a5&quot; id=&quot;59a5&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Estimated time to expose this API as a simple RPC service: a few hours.&lt;/strong&gt;&lt;/p&gt;
&lt;p name=&quot;42dd&quot; id=&quot;42dd&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Ok, now time to go the RESTful way.&lt;/p&gt;
&lt;p name=&quot;8a73&quot; id=&quot;8a73&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;No more standards, no more precise specifications. Just a vague “RESTful philosophy”, prone to endless metaphysical debates, and as many ugly workarounds.&lt;/p&gt;
&lt;p name=&quot;5a30&quot; id=&quot;5a30&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;How do you map the precise functions above, to a handful of CRUD operations? Is sending the activation reminder email an update on a “must_send_activation_reminder_email” attribute? Or the creation of a “activation_reminder_email resource”? Is it sensible to use DELETE for cancelSubscription() if the subscription remains alive during a grace period, and may be resurrected during that time? How do you split the data tree of getAccountDetails() between endpoints, to respect the data model of REST?&lt;/p&gt;
&lt;p name=&quot;85b0&quot; id=&quot;85b0&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;What URL endpoint do you assign to each of your “resources”? Yeah it’s easy, but it has to be to be done anyway.&lt;/p&gt;
&lt;p name=&quot;3374&quot; id=&quot;3374&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;How do you express the diversity of error conditions, using the very limited bunch of HTTP codes?&lt;/p&gt;
&lt;p name=&quot;748f&quot; id=&quot;748f&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;What serialization formats, which specific dialects do you use for input and output payloads?&lt;/p&gt;
&lt;p name=&quot;a72f&quot; id=&quot;a72f&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;How exactly do you scatter these simple signatures between HTTP method, URL, query string, payload, headers, and status code?&lt;/p&gt;
&lt;p name=&quot;23ec&quot; id=&quot;23ec&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;And you’re gone for hours, reinventing the wheel. Not even a tailored, smart wheel. A broken and fragile wheel, requiring tons of documentation to be understood, and violating specifications without even knowing it.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*9Rvg-2GBv4R_92aNePXfGA.png&quot; data-width=&quot;648&quot; data-height=&quot;362&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*9Rvg-2GBv4R_92aNePXfGA.png&quot;/&gt;&lt;/div&gt;
&lt;p name=&quot;2640&quot; id=&quot;2640&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;How come REST means so much WORK?&lt;/strong&gt;&lt;br/&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;This is both a paradox, and a shameless pun.&lt;/em&gt;&lt;/p&gt;
&lt;p name=&quot;1e9f&quot; id=&quot;1e9f&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Let’s dive further into the artificial problems born from this design philosophy.&lt;/p&gt;
&lt;h3 name=&quot;86e9&quot; id=&quot;86e9&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;The joy of REST verbs&lt;/h3&gt;
&lt;p name=&quot;d235&quot; id=&quot;d235&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Rest is not CRUD, its advocates will ensure that you don’t mix up these two. Yet minutes later they will rejoice that HTTP verbs have well defined semantics to create (POST), retrieve (GET), update (PUT/PATCH) and delete (DELETE) resources.&lt;/p&gt;
&lt;p name=&quot;4a50&quot; id=&quot;4a50&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;They’ll delight in professing that these few HTTP verbs are enough to express any operation. Well, of course they are; the same way that a handful of verbs would be enough to express any concept in English: “Today I updated my CarDriverSeat with my body, and created an EngineIgnition, but the FuelTank deleted itself”; being possible doesn’t make it any less awkward. Unless you’re an admirator of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Toki_Pona&quot; data-href=&quot;https://en.wikipedia.org/wiki/Toki_Pona&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;Toki Pona&lt;/a&gt; language.&lt;/p&gt;
&lt;p name=&quot;9227&quot; id=&quot;9227&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;If the point is to be minimalist, at least let it be done right. Do you know why PUT, PATCH, and DELETE have never been implemented in web browser forms? Because they are useless and harmful. We can just use GET for read and POST for write. Or POST exclusively, when HTTP-level caching is unwanted. Other verbs will at best get in your way, at worst ruin your day.&lt;/p&gt;
&lt;p name=&quot;3c52&quot; id=&quot;3c52&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;You want to use PUT to update your resource? OK, but some Holy Specifications state that the data input has to be a “complete resource”, i.e follow the same schema as the corresponding GET output. So what do you do with the numerous read-only parameters returned by GET (creation time, last update time, server-generated token…)? You omit them and violate the PUT principles? You include them anyway, and expect an “HTTP 409 Conflict” if they don’t match server-side values (forcing you to then issue a GET...)? You give them random values and expect servers to ignore them (the joy of silent errors)? Pick your poison, REST clearly has no clue what a read-only attribute it, and this won’t be fixed anytime soon. Meanwhile, a GET is dangerously supposed to return the password (or credit card number) which was sent in a previous POST/PUT; good luck dealing with such write-only parameters too.&lt;/p&gt;
&lt;p name=&quot;8db2&quot; id=&quot;8db2&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;You want to use PATCH to update your resource? Nice, but like 99% of people using this verb, you’ll just send a subset of resource fields in your request payload, hoping that the server properly understands the operation intended (and all its possible side effects); lots of resource parameters are deeply linked or mutually exclusive(ex. it’s either credit card OR paypal token, in a user’s billing info), but RESTful design hides this important information too. Anyway, you’d violate specs once more: PATCH is not supposed to send a bunch of fields to be overridden. Instead, you’re supposed to provide a “set of instructions” to be applied on the resources. So here you go again, take your paperboard and your coffee mug, you’ll have to specify how to express these instructions, and their semantics. Not-Invented-Here syndrome is a de-facto standard in the REST world.&lt;/p&gt;
&lt;p name=&quot;a45e&quot; id=&quot;a45e&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;You want to DELETE resources? OK, but I hope you don’t need to provide substantial context data; like a PDF scan of the termination request from the user. DELETE prohibits having a payload. A constraint that REST architects often dismiss, since most webservers don’t enforce this rule on the requests they receive. How compatible, anyway, would be a DELETE request with 2 MBs of base64 query string attached?&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*YCrFiVDbRL04YQePi566qQ.png&quot; data-width=&quot;400&quot; data-height=&quot;372&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*YCrFiVDbRL04YQePi566qQ.png&quot;/&gt;&lt;/div&gt;
&lt;p name=&quot;2ead&quot; id=&quot;2ead&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;REST aficionados easily profess that “people are doing it wrong” and their APIs are “actually not RESTful”. For exemple, lots of developers use PUT to create a resource directly on its final URL (&lt;em class=&quot;markup--em markup--p-em&quot;&gt;/myresourcebase/myresourceid&lt;/em&gt;), whereas the “good way” of doing it is to POST on a parent URL (&lt;em class=&quot;markup--em markup--p-em&quot;&gt;/myresourcebase&lt;/em&gt;), and let the server indicate, with an HTTP redirection, the new resource’s URL. The good news is: it doesn’t matter. These rigorous principles are like Big Endian vs Little Endian, they occupy philosophers for hours, but have very little impact on real life problems, i.e “getting stuff done”.&lt;/p&gt;
&lt;p name=&quot;fa35&quot; id=&quot;fa35&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;By the way… handcrafting URLs is always great fun. Do you know how many implementations properly urlencode() identifiers while building REST urls? Not that many. Get ready for nasty breakages and SSRF/CSRF attacks.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*IMeQwZ3twaG24DVCPk-obg.jpeg&quot; data-width=&quot;1600&quot; data-height=&quot;1200&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*IMeQwZ3twaG24DVCPk-obg.jpeg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*IMeQwZ3twaG24DVCPk-obg.jpeg&quot;/&gt;&lt;/div&gt;
When you forget to urlencode usernames in 1 of your 30 handcrafted URLs.
&lt;h3 name=&quot;f779&quot; id=&quot;f779&quot; class=&quot;graf graf--h3 graf-after--figure&quot;&gt;The joy of HTTP error handling&lt;/h3&gt;
&lt;p name=&quot;0e98&quot; id=&quot;0e98&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;About every coder is able to make a “nominal case” work. Error handling is one of these features which will decide if your code is robust software, or a huge pile of matchsticks.&lt;/p&gt;
&lt;p name=&quot;5df2&quot; id=&quot;5df2&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;HTTP provides a list of error codes out-of-the-box. Great, let’s see that.&lt;/p&gt;
&lt;p name=&quot;390f&quot; id=&quot;390f&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Using “HTTP 404 Not Found” to notify about an unexisting resource sounds RESTful as heck, doesn’t it? Too bad: your nginx was misconfigured for 1 hour, so your API consumers got only 404 errors and purged hundreds of accounts, thinking they were deleted….&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*sdlrtm_QU7K0PW6P-vQ2OQ.jpeg&quot; data-width=&quot;960&quot; data-height=&quot;531&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*sdlrtm_QU7K0PW6P-vQ2OQ.jpeg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*sdlrtm_QU7K0PW6P-vQ2OQ.jpeg&quot;/&gt;&lt;/div&gt;
Our customers, after we deleted their gigabytes of kitten images by error.
&lt;p name=&quot;a463&quot; id=&quot;a463&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;Using “HTTP 401 Unauthorized” when a user doesn’t have access credentials to a third-party service sounds acceptable, doesn’t it? However, if an ajax call in your Safari browser gets this error code, it’ll startle your end customer with a very unexpected password prompt.&lt;/p&gt;
&lt;p name=&quot;86f7&quot; id=&quot;86f7&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;HTTP existed long before REST, and the web ecosystem is filled with assumptions about the meaning of its error codes. Using them to transport application errors is like using milk bottles to dispose of toxic waste: inevitably, one day, there will be trouble.&lt;/p&gt;
&lt;p name=&quot;c442&quot; id=&quot;c442&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Some standard HTTP error codes are specific to Webdav, others to Microsoft, and the few remaining have definitions so fuzzy that they are of no help. In the end, like most REST users, you’ll probably use random HTTP codes, like “HTTP 418 I’m a teapot” or unassigned numbers, to express your application-specific exceptions. Or you’ll shamelessly return “HTTP 400 Bad Request” for all functional errors, and then invent your own clunky error format, with booleans, integer codes, slugs, and translated messages stuffed into an arbitrary payload. Or you’ll give up altogether on proper error handling; you’ll just return a plain message, in natural language, and hope that the caller will be a human able to analyze the problem, and take action. Good luck interacting with such APIs from an autonomous program.&lt;/p&gt;
&lt;h3 name=&quot;ef6b&quot; id=&quot;ef6b&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;The joy of REST concepts&lt;/h3&gt;
&lt;p name=&quot;518a&quot; id=&quot;518a&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;REST has made a career out of boasting about concepts that any service architect in his right mind already respects, or about principles that it doesn’t even follow. Here are some excerpts, grabbed from top-ranked webpages.&lt;/p&gt;
&lt;p name=&quot;a9de&quot; id=&quot;a9de&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;REST is a client-server architecture. The client and the server both have a different set of concerns.&lt;/em&gt; What a scoop in the software world.&lt;/p&gt;
&lt;p name=&quot;d2c1&quot; id=&quot;d2c1&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;REST provides a uniform interface between components.&lt;/em&gt; Well, like any other protocol does, when it’s enforced as the &lt;em class=&quot;markup--em markup--p-em&quot;&gt;franca lingua&lt;/em&gt; of a whole ecosystem of services.&lt;/p&gt;
&lt;p name=&quot;11df&quot; id=&quot;11df&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;REST is a layered system. Individual components cannot see beyond the immediate layer with which they are interacting.&lt;/em&gt; It sounds like a natural consequence of any well designed, loosely coupled architecture; amazing.&lt;/p&gt;
&lt;p name=&quot;999a&quot; id=&quot;999a&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Rest is awesome, because it is STATELESS. Yes there is probably a huge database behind the webservice, but it doesn’t remember the state of the client. Or, well, yes, actually it remember its authentication session, its access permissions… but it’s stateless, nonetheless. Or more precisely, just as stateless as any HTTP-based protocol, like simple RPC mentioned previously.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*SNHPbOMcF2hUik348lo26A.png&quot; data-width=&quot;702&quot; data-height=&quot;588&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*SNHPbOMcF2hUik348lo26A.png&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*SNHPbOMcF2hUik348lo26A.png&quot;/&gt;&lt;/div&gt;
&lt;p name=&quot;1fbb&quot; id=&quot;1fbb&quot; class=&quot;graf graf--p graf-after--figure&quot;&gt;With REST, you can leverage the power of HTTP CACHING! Well here is at last one concluding point: a GET request and its cache-control headers are indeed friendly with web caches. That being said, aren’t local caches (Memcached etc.) enough for 99% of web services? Out-of-control caches are dangerous beasts; how many people want to expose their APIs in clear text, so that a Varnish or a Proxy on the road may keep delivering outdated content, long after a resource has been updated or deleted? Maybe even delivering it “forever”, if a configuration mistake once occurred? A system must be secure by default. I perfectly admit that some heavily loaded systems want to benefit from HTTP caching, but it costs much less to expose a few GET endpoints for heavy read-only interactions, than to switch all operations to REST and its dubious error handling.&lt;/p&gt;
&lt;p name=&quot;7adf&quot; id=&quot;7adf&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;Thanks to all this, REST has HIGH PERFORMANCE&lt;/em&gt;! Are we sure of that? Any API designer knows it: locally, we want fine-grained APIs, to be able to do whatever we want; and remotely, we want coarse-grained APIs, to limit the impact of network round-trips. Here is again a domain in which REST fails miserably. The split of data between “resources”, each instance on its own endpoint, naturally leads to the N+1 Query problem. To get a user’s full data (account, subscriptions, billing information…), you have to issue as many HTTP requests; and you can’t parallelize them, since you don’t know in advance the unique IDs of related resources. This, plus the inability to fetch only part of resource objects, naturally creates nasty bottlenecks.&lt;/p&gt;
&lt;p name=&quot;05ec&quot; id=&quot;05ec&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;REST offers better compatibility.&lt;/em&gt; How so? Why do so many REST webservices have “/v2/” or “/v3/” in their base URLs then? Backwards and forward compatible APIs are not hard to achieve, with high level languages, as long as simple rules are followed when adding/deprecating parameters. As far as I know, REST doesn’t bring anything new on the subject.&lt;/p&gt;
&lt;p name=&quot;81c6&quot; id=&quot;81c6&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;REST is SIMPLE, everyone knows HTTP!&lt;/em&gt; Well, everyone knows pebbles too, yet people are happy to have better blocks when building their house. The same way XML is a meta-language, HTTP is a meta-protocol. To have a real application protocol (like “dialects” are to XML), you’ll need to specify lots of things; and you’ll end up with Yet Another RPC Protocol, as if there were not enough already.&lt;/p&gt;
&lt;p name=&quot;dc97&quot; id=&quot;dc97&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;REST is so easy, it can be queried from any shell, with CURL!&lt;/em&gt; OK, actually, every HTTP-based protocol can be queried with CURL. Even SOAP. Issuing a GET is particularly straightforward, for sure, but good luck writing json or xml POST payloads by hand; people usually use fixture files, or, much more handy, full-fledged API clients instantiated directly in the command line interface of their favorite language.&lt;/p&gt;
&lt;p name=&quot;1b29&quot; id=&quot;1b29&quot; class=&quot;graf graf--p graf--startsWithDoubleQuote graf-after--p&quot;&gt;&lt;em class=&quot;markup--em markup--p-em&quot;&gt;“The client does not need any prior knowledge of the service in order to use it”&lt;/em&gt;. This is by far my favourite quote. I’ve found it numerous times, under different forms, especially when the buzzword &lt;a href=&quot;https://fr.wikipedia.org/wiki/HATEOAS&quot; data-href=&quot;https://fr.wikipedia.org/wiki/HATEOAS&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;HATEOAS&lt;/a&gt; lurked around; sometimes with some careful (but insufficient) “except” phrases following. Still, I don’t know in which fantasy world these people live, but in this one, a client program is not a colony of ants; it doesn’t browse remote APIs randomly, and then decide how to best handle them, based on pattern recognition or black magic. Quite the opposite; the client has strong expectations on what it means, to PUT this one field to this one URL with this one value, and the server had better respect the semantic which was agreed upon during integration, else all hell might break loose.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*KUJ2Zl358Q_tS9gijKB49Q.jpeg&quot; data-width=&quot;720&quot; data-height=&quot;479&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*KUJ2Zl358Q_tS9gijKB49Q.jpeg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*KUJ2Zl358Q_tS9gijKB49Q.jpeg&quot;/&gt;&lt;/div&gt;
When you ask how HATEOAS is supposed to work.
&lt;h3 name=&quot;a2c9&quot; id=&quot;a2c9&quot; class=&quot;graf graf--h3 graf-after--figure&quot;&gt;How to do REST right and quick?&lt;/h3&gt;
&lt;p name=&quot;eb47&quot; id=&quot;eb47&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;Forget about the “right” part. REST is like a religion, no mere mortal will ever grasp the extent of its genius, nor “do it right”.&lt;/p&gt;
&lt;p name=&quot;9120&quot; id=&quot;9120&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;So the real question is: if you’re forced to expose or consume webservices in a kinda-RESTful way, how to rush through this job, and switch to more constructive tasks &lt;em class=&quot;markup--em markup--p-em&quot;&gt;asap&lt;/em&gt;?&lt;/p&gt;
&lt;h4 name=&quot;bd4d&quot; id=&quot;bd4d&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;How to industrialize server-side exposure?&lt;/h4&gt;
&lt;p name=&quot;07bd&quot; id=&quot;07bd&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;Each web framework has its own way of defining URL endpoint. So expect some big dependencies, or a good layer of handwritten boilerplate, to plug your existing API onto your favorite server as a set of REST endpoint.&lt;/p&gt;
&lt;p name=&quot;bf1f&quot; id=&quot;bf1f&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Libraries like Django-Rest-Framework automate the creation of REST APIs, by acting as data-centric wrappers above SQL/noSQL schemas. If you just want to make “CRUD over HTTP”, you could be fine with them. But if you want to expose real APIs, with workflows, constraints and such, you’ll have a hard time bending any REST framework to fit your needs.&lt;/p&gt;
&lt;p name=&quot;4d20&quot; id=&quot;4d20&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Be prepared to connect, one by one, each HTTP method of each endpoint, to the corresponding method call; with a fair share of handmade exception handling, to translate passing-through exceptions into corresponding error codes and payloads.&lt;/p&gt;
&lt;h4 name=&quot;843a&quot; id=&quot;843a&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;How to industrialize client-side integration?&lt;/h4&gt;
&lt;p name=&quot;8f92&quot; id=&quot;8f92&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;From experience, my guess is: you don’t.&lt;/p&gt;
&lt;p name=&quot;db8e&quot; id=&quot;db8e&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;For each API integration, you’ll have to browse lengthy docs, and follow detailed recipes on how each of the N possible operations has to be performed.&lt;/p&gt;
&lt;p name=&quot;68ad&quot; id=&quot;68ad&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;You’ll have to craft URLs by hand, write serializers and deserializers, and learn how to workaround the ambiguities of the API. Expect quite some trial-and-error before you tame the beast.&lt;/p&gt;
&lt;p name=&quot;5d70&quot; id=&quot;5d70&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Do you know how webservices providers make up for this, and ease adoption?&lt;/p&gt;
&lt;p name=&quot;5a6e&quot; id=&quot;5a6e&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Simple, they write their own official client implementations.&lt;/p&gt;
&lt;p name=&quot;dd39&quot; id=&quot;dd39&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;FOR. EVERY. MAJOR. LANGUAGE. AND. PLATFORM.&lt;/p&gt;
&lt;p name=&quot;8706&quot; id=&quot;8706&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;I’ve recently dealt with a subscription management system. They provide clients for PHP, Ruby, Python, .NET, iOS, Android, Java… plus some external contributions for Go and NodeJS.&lt;/p&gt;
&lt;p name=&quot;52d3&quot; id=&quot;52d3&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Each client lives in its own Github repository. Each which its own big list of commits, bug tracking tickets, and pull requests. Each with its own usage examples. Each with its own awkward architecture, somewhere between ActiveRecord and RPC proxy.&lt;/p&gt;
&lt;p name=&quot;ba55&quot; id=&quot;ba55&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This is astounding. How much time is spent developing such weird wrappers, instead of improving the real, the valuable, the getting-stuff-done, webservice?&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*VlkAg8dodbaaKp-Po7DrAA.jpeg&quot; data-width=&quot;389&quot; data-height=&quot;383&quot; data-is-featured=&quot;true&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*VlkAg8dodbaaKp-Po7DrAA.jpeg&quot;/&gt;&lt;/div&gt;
&lt;em class=&quot;markup--em markup--figure-em&quot;&gt;Sisyphus developing&lt;/em&gt; Yet Another Client for his API.
&lt;h3 name=&quot;4e5d&quot; id=&quot;4e5d&quot; class=&quot;graf graf--h3 graf-after--figure&quot;&gt;&lt;strong class=&quot;markup--strong markup--h3-strong&quot;&gt;Conclusion&lt;/strong&gt;&lt;/h3&gt;
&lt;p name=&quot;c740&quot; id=&quot;c740&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;For decades, about every programming language has functioned with the same workflow: sending inputs to a callable, and getting results or errors as output. This worked well. Quite well.&lt;/p&gt;
&lt;p name=&quot;056e&quot; id=&quot;056e&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;With Rest, this has turned into an insane work of mapping apples to oranges, and praising HTTP specifications to better violate them minutes later.&lt;/p&gt;
&lt;p name=&quot;d8d8&quot; id=&quot;d8d8&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;In an era where &lt;a href=&quot;https://en.wikipedia.org/wiki/Microservices&quot; data-href=&quot;https://en.wikipedia.org/wiki/Microservices&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;MICROSERVICES&lt;/a&gt; are more and more common, how come such an easy task — linking libraries over networks — remains so artificially crafty and cumbersome?&lt;/p&gt;
&lt;p name=&quot;6995&quot; id=&quot;6995&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;I don’t doubt that some smart people out there will provide cases where REST shines; they’ll showcase their homemade REST-based protocol, allowing to discover and do CRUD operation on arbitrary object trees, thanks to hyperlinks; they’ll explain how the REST design is so brilliant, that I’ve just not read enough articles and dissertations about its concepts.&lt;/p&gt;
&lt;p name=&quot;f109&quot; id=&quot;f109&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;I don’t care. Trees are recognized by their own fruits. What took me a few hours of coding and worked very robustly, with simple RPC, now takes weeks and can’t stop inventing new ways of failing or breaking expectations. Development has been replaced by tinkering.&lt;/p&gt;
&lt;p name=&quot;f7e0&quot; id=&quot;f7e0&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Almost-transparent remote procedure call was what 99% people really needed, and existing protocols, as imperfect as they were, did the job just fine. This mass monomania for the lowest common denominator of the web, HTTP, has mainly resulted in a huge waste of time and grey matter.&lt;/p&gt;
&lt;p name=&quot;d26d&quot; id=&quot;d26d&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;&lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;REST promised simplicity and delivered complexity.&lt;br/&gt;REST promised robustness and delivered fragility.&lt;br/&gt;REST promised interoperability and delivered heterogeneity.&lt;br/&gt;REST is the new SOAP.&lt;/strong&gt;&lt;/p&gt;
&lt;h3 name=&quot;47ad&quot; id=&quot;47ad&quot; class=&quot;graf graf--h3 graf-after--p&quot;&gt;Epilogue&lt;/h3&gt;
&lt;p name=&quot;ab8c&quot; id=&quot;ab8c&quot; class=&quot;graf graf--p graf-after--h3&quot;&gt;The future could be bright. There are still tons of excellent protocols available, in binary or text format, with or without schema, some leveraging the new abilities of HTTP2… so let’s move on, people. We can’t forever remain in the Stone Age of Webservices.&lt;/p&gt;
&lt;div class=&quot;aspectRatioPlaceholder is-locked&quot;&gt;

&lt;img class=&quot;graf-image&quot; data-image-id=&quot;1*gcVvKJVJ9kV596vyXlZiNA.jpeg&quot; data-width=&quot;1200&quot; data-height=&quot;900&quot; data-action=&quot;zoom&quot; data-action-value=&quot;1*gcVvKJVJ9kV596vyXlZiNA.jpeg&quot; src=&quot;https://cdn-images-1.medium.com/max/1600/1*gcVvKJVJ9kV596vyXlZiNA.jpeg&quot;/&gt;&lt;/div&gt;
“Always finish a rant on a positive note”, momma said.</description>
<pubDate>Sat, 16 Dec 2017 03:51:54 +0000</pubDate>
<dc:creator>sidcool</dc:creator>
<og:title>REST is the new SOAP – Pakal De Bonchamp – Medium</og:title>
<og:url>https://medium.com/@pakaldebonchamp/rest-is-the-new-soap-97ff6c09896d</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*VlkAg8dodbaaKp-Po7DrAA.jpeg</og:image>
<og:description>A journey through a trendy hell</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://medium.com/@pakaldebonchamp/rest-is-the-new-soap-97ff6c09896d</dc:identifier>
</item>
<item>
<title>Stuff You Can&amp;#039;t Say in Silicon Valley</title>
<link>https://elaineou.com/2017/11/24/stuff-you-cant-say-in-silicon-valley/</link>
<guid isPermaLink="true" >https://elaineou.com/2017/11/24/stuff-you-cant-say-in-silicon-valley/</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://i0.wp.com/elaineou.com/wp-content/uploads/2017/11/timf.jpg?resize=150%2C150&amp;amp;ssl=1&quot; alt=&quot;&quot; width=&quot;150&quot; height=&quot;150&quot; class=&quot;aligncenter size-thumbnail wp-image-11579&quot; srcset=&quot;https://i0.wp.com/elaineou.com/wp-content/uploads/2017/11/timf.jpg?resize=150%2C150&amp;amp;ssl=1 150w, https://i0.wp.com/elaineou.com/wp-content/uploads/2017/11/timf.jpg?resize=300%2C300&amp;amp;ssl=1 300w, https://i0.wp.com/elaineou.com/wp-content/uploads/2017/11/timf.jpg?w=630&amp;amp;ssl=1 630w&quot; sizes=&quot;(max-width: 150px) 100vw, 150px&quot; data-recalc-dims=&quot;1&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Tim Ferriss recently left Silicon Valley, citing &lt;a href=&quot;https://www.reddit.com/r/IAmA/comments/7erct8/i_am_tim_ferriss_host_of_the_tim_ferriss_show_and/dq6zrh1/&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;liberal McCarthyism&lt;/a&gt; as one of the catalysts for his departure.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-width=&quot;550&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Seen this quote surface a bunch in the last 24hrs in similar befuddlement.&lt;/p&gt;
&lt;p&gt;Reminded me of this post by &lt;a href=&quot;https://twitter.com/jesslivingston?ref_src=twsrc%5Etfw&quot;&gt;@jesslivingston&lt;/a&gt; from nearly a year ago with a similar theme &lt;a href=&quot;https://t.co/3MIVjMopfW&quot;&gt;https://t.co/3MIVjMopfW&lt;/a&gt; &lt;a href=&quot;https://t.co/15vofrD88A&quot;&gt;https://t.co/15vofrD88A&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;— Bryce Roberts (@bryce) &lt;a href=&quot;https://twitter.com/bryce/status/933918031901704193?ref_src=twsrc%5Etfw&quot;&gt;November 24, 2017&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;People seem awfully puzzled that there are things you can’t say in Silicon Valley. I can’t tell if these people are willfully ignorant, or if their heads are jammed so far up their asses that they can’t conjure a single controversial idea.&lt;/p&gt;
&lt;p&gt;Here, I’ll help you guys out.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stuff You Can’t Say&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;It’s okay to support Trump.&lt;br/&gt;&lt;em&gt;We agree that people shouldn’t be fired for their political views, but this isn’t a disagreement on tax policy, this is advocating hatred and violence.&lt;/em&gt; —&lt;a href=&quot;https://mobile.nytimes.com/2016/10/20/technology/how-silicon-valley-treats-a-trump-backer-peter-thiel.html&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Ellen Pao&lt;/a&gt;, after her company severed ties with Y Combinator for refusing to fire Peter Thiel&lt;/li&gt;
&lt;li&gt;Diversity of thought is more important than diversity of skin color.&lt;br/&gt;&lt;em&gt;Apple diversity head Denise Young Smith apologizes for controversial choice of words —&lt;a href=&quot;https://techcrunch.com/2017/10/13/apple-diversity-head-denise-young-smith-apologizes-for-controversial-choice-of-words-at-summit/&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Techcrunch&lt;/a&gt;, Oct 13 2017&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Silicon Valley uses H-1B visas to &lt;a href=&quot;https://www.huffingtonpost.com/entry/trump-h-1b_us_5890d86ce4b0522c7d3d84af&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;lower wages&lt;/a&gt; and &lt;a href=&quot;http://www.stltoday.com/opinion/columnists/silicon-valley-is-using-h--b-visas-to-crowd/article_2c3ac63c-360a-5c79-88b2-729d8673aa28.html&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;crowd out American minorities&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;If San Francisco residents really believed that &lt;a href=&quot;http://www.mercurynews.com/2017/04/30/oceans-rising-faster-than-scientific-forecasts/&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;sea levels were rising&lt;/a&gt;, they’d have all sold their homes by now.&lt;/li&gt;
&lt;li&gt;“The distribution of preferences and abilities of men and women differ in part due to biological causes and these differences may explain why we don’t see equal representation of women in tech…”&lt;br/&gt;&lt;em&gt;Google Fires Author of Divisive Memo on Gender Differences —&lt;a href=&quot;https://www.bloomberg.com/news/articles/2017-08-08/google-fires-employee-behind-controversial-diversity-memo&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Bloomberg&lt;/a&gt;, Aug 7 2017&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;The only way to achieve equality is by &lt;a href=&quot;https://www.rush.com/songs/the-trees/&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;hatchet, axe, and saw…&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;

&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-width=&quot;550&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;^ I am confused that an independently wealthy man, who doesn’t live in SV, posting on a global website to a global audience can’t share his true feelings because SIlicon Valley is a singularly intolerant culture.&lt;/p&gt;
&lt;p&gt;Go for it. We’re not going to Putin you, man!&lt;/p&gt;
&lt;p&gt;— Parker Thompson (@pt) &lt;a href=&quot;https://twitter.com/pt/status/933910897566683136?ref_src=twsrc%5Etfw&quot;&gt;November 24, 2017&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Parker Thompson raises a valid point: Why is it so hard for Tim Ferriss to speak his mind? After all, I just spouted a bunch of crimethink, and I’m but a lowly peon. Tim is independently wealthy; the worst that could happen to him is he loses some Twitter followers, or maybe Silicon Valley’s squawking heads call on tech leaders to cut ties with him.&lt;/p&gt;
&lt;p&gt;We tend to toss these threats around lightly, but remember — rich investors have really fragile egos. Their world revolves around thinking about what the world thinks of them. Self-absorption is one of the key factors to success around here. Why do you think tech leaders spend so much time on Twitter? Heck, why do you think Parker Thompson is virtue-signaling so hard right now? These guys aren’t worried about being persecuted; they’re worried about being ignored. Just like &lt;a href=&quot;https://www.bloomberg.com/news/articles/2015-06-29/gross-gets-personal-i-just-wanted-to-run-money-and-be-famous-&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;Bill Gross&lt;/a&gt;, these people are empty narcissists on a neurotic quest for love. That’s another thing you can’t say in Silicon Valley.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;See Also:&lt;/strong&gt;&lt;br/&gt;&lt;a href=&quot;http://paulgraham.com/say.html&quot; rel=&quot;noopener&quot; target=&quot;_blank&quot;&gt;What You Can’t Say&lt;/a&gt; &lt;em&gt;–Paul Graham&lt;/em&gt;&lt;/p&gt;
&lt;div class=&quot;sharedaddy sd-sharing-enabled&quot;&gt;
&lt;div class=&quot;robots-nocontent sd-block sd-social sd-social-icon sd-sharing&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Go talk about it:&lt;/h3&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-unloaded&quot; id=&quot;like-post-wrapper-91135772-11573-5a3522744006a&quot; data-src=&quot;https://widgets.wp.com/likes/#blog_id=91135772&amp;amp;post_id=11573&amp;amp;origin=elaineou.com&amp;amp;obj_id=91135772-11573-5a3522744006a&quot; data-name=&quot;like-post-frame-91135772-11573-5a3522744006a&quot;&gt;
&lt;h3 class=&quot;sd-title&quot;&gt;Like this:&lt;/h3&gt;
&lt;div class=&quot;likes-widget-placeholder post-likes-widget-placeholder&quot;&gt;&lt;span class=&quot;button&quot;&gt;&lt;span&gt;Like&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;loading&quot;&gt;Loading...&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

</description>
<pubDate>Sat, 16 Dec 2017 02:46:36 +0000</pubDate>
<dc:creator>mr_spothawk</dc:creator>
<og:type>article</og:type>
<og:title>Stuff You Can’t Say in Silicon Valley</og:title>
<og:url>https://elaineou.com/2017/11/24/stuff-you-cant-say-in-silicon-valley/</og:url>
<og:description>Tim Ferriss recently left Silicon Valley, citing liberal McCarthyism as one of the catalysts for his departure. People seem awfully puzzled that there are things you can’t say in Silicon Valley. I …</og:description>
<og:image>https://s0.wp.com/i/blank.jpg</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://elaineou.com/2017/11/24/stuff-you-cant-say-in-silicon-valley/</dc:identifier>
</item>
<item>
<title>CDC gets list of forbidden words</title>
<link>https://www.washingtonpost.com/national/health-science/cdc-gets-list-of-forbidden-words-fetus-transgender-diversity/2017/12/15/f503837a-e1cf-11e7-89e8-edec16379010_story.html</link>
<guid isPermaLink="true" >https://www.washingtonpost.com/national/health-science/cdc-gets-list-of-forbidden-words-fetus-transgender-diversity/2017/12/15/f503837a-e1cf-11e7-89e8-edec16379010_story.html</guid>
<description>&lt;p&gt;The Trump administration is prohibiting officials at the nation’s top public health agency from using a list of seven words or phrases — including “fetus” and “transgender” — in any official documents being prepared for next year’s budget.&lt;/p&gt;&lt;p&gt;Policy analysts at the &lt;a href=&quot;https://www.washingtonpost.com/news/to-your-health/wp/2017/12/11/new-cdc-head-faces-questions-about-financial-conflicts-of-interest/?utm_term=.cb08b77bb858&quot; shape=&quot;rect&quot;&gt;Centers for Disease Control and Prevention&lt;/a&gt; in Atlanta were told of the list of forbidden words at a meeting Thursday with senior CDC officials who oversee the budget, according to an analyst who took part in the 90-minute briefing. The forbidden words are “vulnerable,” “entitlement,” “diversity,” “transgender,” “fetus,” “evidence-based” and “science-based.”&lt;/p&gt;
&lt;p&gt;In some instances, the analysts were given alternative phrases. Instead of “science-based” or ­“evidence-based,” the suggested phrase is “CDC bases its recommendations on science in consideration with community standards and wishes,” the person said. In other cases, no replacement words were immediately offered.&lt;/p&gt;
&lt;p&gt;The question of how to address such issues as sexual orientation, gender identity and abortion rights — all of which received significant visibility under the Obama administration — has surfaced repeatedly in federal agencies since President Trump took office. Several key departments — including Health and Human Services, which oversees the CDC, as well as &lt;a href=&quot;https://www.washingtonpost.com/local/public-safety/trump-administration-asks-court-to-toss-out-challenge-to-military-transgender-ban/2017/10/05/3819aec4-a9d5-11e7-92d1-58c702d2d975_story.html?utm_term=.410eba3483e2&quot; shape=&quot;rect&quot;&gt;Justice&lt;/a&gt;, Education, and Housing and Urban Development — have changed some federal policies and how they collect government information about lesbian, gay, bisexual and transgender Americans.&lt;/p&gt;
&lt;p&gt;In March, for example, HHS dropped questions about sexual orientation and gender identity in two surveys of elderly people.&lt;/p&gt;
&lt;div class=&quot;inline-content inline-video&quot;&gt;

&lt;div class=&quot;inline-video-caption&quot;&gt;&lt;span class=&quot;pb-caption&quot;&gt;President Trump's nominee to lead the Department of Health and Human Services, Alex Azar, laid out his vision for the focus of the department on Nov. 29: lowering drug prices, providing affordable, available and tailored health-care plans, reforming Medicare and tackling the opioid epidemic. (Reuters)&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;HHS has also removed information about LGBT Americans from its website. The department’s Administration for Children and Families, for example, &lt;a href=&quot;https://wayback.archive-it.org/8654/20170329001223/https:/www.acf.hhs.gov/program-topics/lgbt-0&quot; shape=&quot;rect&quot;&gt;archived a page&lt;/a&gt; that outlined federal services that are available for LGBT people and their families, including how they can adopt and receive help if they are the victims of sex trafficking.&lt;/p&gt;
&lt;p&gt;At the CDC, the meeting about the banned words was led by Alison Kelly, a senior leader in the agency’s Office of Financial Services, according to the CDC analyst, who spoke on the condition of anonymity because the person was not authorized to speak publicly. Kelly did not say why the words are being banned, according to the analyst, and told the group that she was merely relaying the information.&lt;/p&gt;
&lt;p&gt;Other CDC officials confirmed the existence of a list of forbidden words.It’s likely that other parts of HHS are operating under the same guidelines regarding the use of these words, the analyst said&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At the CDC, several offices have responsibility for work that uses some of these words. The National Center for HIV/AIDS, Viral Hepatitis, STD, and TB Prevention is working on ways to &lt;a href=&quot;https://www.cdc.gov/hiv/group/gender/transgender/index.html&quot; shape=&quot;rect&quot;&gt;prevent HIV among transgender&lt;/a&gt; people and reduce health disparities. The CDC’s work on &lt;a href=&quot;https://www.washingtonpost.com/news/to-your-health/wp/2017/04/04/zika-poses-even-greater-risk-for-birth-defects-than-was-previously-known-cdc-reports/?utm_term=.df1bd389a3dc&quot; shape=&quot;rect&quot;&gt;birth defects caused by the Zika&lt;/a&gt; virus includes research on the developing fetus.&lt;/p&gt;
&lt;p&gt;The ban is related to the budget and supporting materials that are to be given to the CDC’s partners and to Congress, the analyst said. The president’s budget for 2019 is expected to be released in early February. The budget blueprint is generally shaped to reflect an administration’s priorities.&lt;/p&gt;
&lt;p&gt;Federal agencies are sending in their budget proposals to the Office of Management and Budget, which has authority about what is included.&lt;/p&gt;
&lt;p&gt;Neither an OMB spokesman nor a CDC spokeswoman responded to requests for comment Friday.&lt;/p&gt;
&lt;p channel=&quot;wp.com&quot; class=&quot;interstitial-link&quot;&gt;&lt;em&gt;[&lt;a href=&quot;https://www.washingtonpost.com/politics/trump-administration-plans-to-minimize-civil-rights-efforts-in-agencies/2017/05/29/922fc1b2-39a7-11e7-a058-ddbb23c75d82_story.html?utm_term=.09139d8115d6&quot; shape=&quot;rect&quot;&gt;This is how the Trump administration has shifted course on civil rights&lt;/a&gt;]&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The longtime CDC analyst, whose job includes writing descriptions of the CDC’s work for the administration’s annual spending blueprint, could not recall a previous time when words were banned from budget documents because they were considered controversial.&lt;/p&gt;
&lt;p&gt;The reaction of people in the meeting was “incredulous,” the analyst said. “It was very much, ‘Are you serious? Are you kidding?’ ”&lt;/p&gt;
&lt;p&gt;“In my experience, we’ve never had any pushback from an ideological standpoint,” the analyst said.&lt;/p&gt;
&lt;p&gt;News of the ban on certain words hasn’t yet spread to the broader group of scientists at the CDC, but it’s likely to provoke a backlash, the analyst said. “Our subject matter experts will not lay down quietly — this hasn’t trickled down to them yet.”&lt;/p&gt;
&lt;p&gt;The CDC has a budget of about $7 billion and more than 12,000 employees working across the nation and around the globe on everything from food and water safety, to heart disease and cancer, to &lt;a href=&quot;https://www.washingtonpost.com/news/to-your-health/wp/2016/05/26/the-superbug-that-doctors-have-been-dreading-just-reached-the-u-s/?tid=a_inl&amp;amp;utm_term=.fc36279d5c79&quot; shape=&quot;rect&quot;&gt;infectious disease outbreak&lt;/a&gt; prevention. Much of the CDC’s work has strong bipartisan support.&lt;/p&gt;
&lt;p&gt;Kelly told the analysts that “certain words” in the CDC’s budget drafts were being sent back to the agency for correction. Three words that had been flagged in these drafts were “vulnerable,” “entitlement” and “diversity.” Kelly told the group the ban on the other words had been conveyed verbally.&lt;/p&gt;
</description>
<pubDate>Sat, 16 Dec 2017 02:17:44 +0000</pubDate>
<dc:creator>js2</dc:creator>
<og:type>article</og:type>
<og:url>https://www.washingtonpost.com/national/health-science/cdc-gets-list-of-forbidden-words-fetus-transgender-diversity/2017/12/15/f503837a-e1cf-11e7-89e8-edec16379010_story.html</og:url>
<og:image>https://www.washingtonpost.com/rf/image_1484w/2010-2019/WashingtonPost/2017/12/16/Interactivity/Images/Antibiotic_Overuse-06223.jpg?t=20170517</og:image>
<og:title>CDC gets list of forbidden words: fetus, transgender, diversity</og:title>
<og:description>Agency analysts are told to avoid these 7 banned words and phrases in budget documents</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.washingtonpost.com/national/health-science/cdc-gets-list-of-forbidden-words-fetus-transgender-diversity/2017/12/15/f503837a-e1cf-11e7-89e8-edec16379010_story.html</dc:identifier>
</item>
<item>
<title>Uber Accused of Espionage, Bribery, Hacking, in Former Employee&amp;#039;s Letter</title>
<link>https://www.buzzfeed.com/ryanmac/ric-jacobs-uber-letter-allegations-waymo</link>
<guid isPermaLink="true" >https://www.buzzfeed.com/ryanmac/ric-jacobs-uber-letter-allegations-waymo</guid>
<description>&lt;p&gt;The judge in the $1.9 billion civil suit between Alphabet’s self-driving car unit Waymo and Uber released the letter of a disgruntled former employee on Friday, laying bare a number of explosive allegations against the ride-hailing company that include corporate espionage, unlawful surveillance, illegal wiretapping, bribery of foreign officials, and illicit hacking. That document also says that former Uber CEO Travis Kalanick, who was ousted in June, directly received stolen trade secrets.&lt;/p&gt;&lt;p&gt;That 37-page letter, penned by &lt;a href=&quot;https://www.buzzfeed.com/ryanmac/waymo-uber-bombshell-letter-ric-jacobs?utm_term=.vyawyyG8e#.erRezz8bW&quot; data-skimlinks-tracking=&quot;4706322&quot;&gt;former Uber employee Ric Jacobs&lt;/a&gt; and sent to the company in May, became the center of a fierce debate between Waymo, the self-driving car unit of Google's parent company Alphabet, and Uber, which did not previously disclose the document to Judge William Alsup. In turn, the federal district judge excoriated Uber’s lawyers in pre-trial hearings in November and suggested that they were attempting to hide something from the court.&lt;/p&gt;
&lt;p&gt;Alsup only recently found out about the letter, after a US attorney investigating Uber for a potential federal case forwarded it to him. The document caused the judge to delay jury selection and the trial until the new year so that the plaintiffs could review the new evidence.&lt;/p&gt;
&lt;p&gt;The letter, available in full to the public for the first time on Friday, contains allegations that could dramatically affect the outcome of Waymo’s case against Uber, and completely shatter the San Francisco-based company’s already frail reputation after a year of scandals. Crucially, it includes a claim that collections of stolen trade secret data were delivered directly to former CEO Travis Kalanick, though it's unclear if that information was related to Waymo.&lt;/p&gt;
&lt;p&gt;“While we haven’t substantiated all the claims in this letter — and, importantly, any related to Waymo — our new leadership has made clear that going forward we will compete honestly and fairly, on the strength of our ideas and technology,” an Uber spokesperson said in a statement.&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;A spokesperson for Kalanick declined to comment.&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;In testimony last month, Jacobs walked back on some of the claims in his letter, noting that it was written by his lawyer and that he did not review it in full before it was sent.&lt;/p&gt;
&lt;p&gt;Jacobs, who now lives in Seattle, left Uber in April after he was allegedly caught trying to download internal documents with the intention of making them public. After his departure, his lawyer sent Uber’s deputy general counsel Angela Padilla the letter detailing what he perceived to be illegal behavior inside the company. During her testimony last month, Padilla called Jacobs’ demands at the time “extortionate,” though Alsup questioned why a company would pay anyone millions of dollars to simply make claims go away.&lt;/p&gt;
&lt;p&gt;Uber ultimately paid Jacobs $4.5 million in cash and stock in exchange for agreeing not to disparage it in public — though that did not prevent him from testifying — and for his help in resolving the security issues he outlined in his letter. According to his testimony, Jacobs’ settlement prevents him from disparaging Uber in public, though it does not stop him from telling the truth in a court setting. Jacobs remains a consultant for Uber.&lt;/p&gt;
&lt;p&gt;Jacobs and his lawyer Clayton Halunen, who received $3 million as part of the settlement, did not immediately respond to request for comment. Halunen previously told BuzzFeed News that Padilla’s testimony about his client was &lt;a href=&quot;https://www.buzzfeed.com/ryanmac/uber-attorney-calls-former-employees-allegations-of?utm_term=.ti23mmDqg#.ownJMMYQ8&quot; data-skimlinks-tracking=&quot;4706322&quot;&gt;“outrageous and possibly defamatory,”&lt;/a&gt; and that the settlement he received was standard per the 40% cut he takes from all contingency cases.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Below are some of the most contentious allegations in that document, some of which have already been discussed at length in November’s hearings:&lt;/strong&gt;&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;
&lt;ul readability=&quot;47&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;That “not only was Uber able to obtain trade secrets, but used the data it obtained to inflate the ultimate valuation of Uber.”&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;6&quot;&gt;
&lt;p&gt;“Uber's Marketplace Analytics (MA) team, exists expressly for the purpose of acquiring trade secrets, codebase, and competitive intelligence- including deriving key business metrics of supply, demand, and the function of applications-from major ridesharing competitors globally.”&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;8&quot;&gt;
&lt;p&gt;In January 2017, a person “contacted Jacobs on Wickr and advised they 'had a bug in a meeting with transport regulators,&quot; and that they ‘needed help cleaning up the audio.’ Jacobs immediately contacted Craig Clark, Uber's then-legal director for threat operations, and informed him of the unlawful request. Clark instructed Jacobs to tell the city team that Uber did not have the technical capabilities to assist, encourage them not to transmit the audio, and convince them to ‘make it go away’.”&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;“Jacobs reasonably believed that bribery of foreign officials was taking place”, but the names of the places where he thought this was happening were redacted.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;Uber “used undercover agents to collect intelligence against the taxi groups and local political figures. The agents took rides in local taxis, loitered around locations where taxi drivers congregated, and leveraged a local network of contacts with connections to police and regulatory authorities.”&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;8&quot;&gt;
&lt;p&gt;Uber &quot;collected details on [redacted], including: information on these firms' connections to political and regulatory officials, their data sharing agreement and connection to the [redacted], their efforts to replace Uber in [redacted], and their investments in the taxi sector in [redacted]. These facts demonstrate that vendors, directed by Uber employees, conducted foreign espionage against a sovereign nation despite Jacobs's objections.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;Jacobs felt the things Uber was doing overseas “needlessly exposed Uber and its employees to severe risk — including the likely termination of Uber's operations and possible imprisonment of its employees — should capable security services in many overseas locations discover Uber's espionage.”&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;Jacobs wanted to create a “secure and encrypted database to ensure confidentiality and presented a draft proposal” to his managers. However, “discussions broke down immediately as the group objected to preserving any intelligence that would make preservation and legal discovery a simple process for future litigants.”&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;&lt;em&gt;“&lt;/em&gt;Jacobs questioned the legality of collecting intelligence necessary for the analysis, which targeted politicians, regulators, and taxi union officials.&quot;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;“In January 2017, Jacobs informed Clark, as discussed above, that a [redacted] team member had illegally bugged a meeting. Clark did nothing.”&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;In February, Jacobs was demoted without warning, which he felt was a direct response to his unwillingness to engage in illegal activity.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;6&quot;&gt;
&lt;p&gt;&quot;Since his termination, Jacobs has learned that, rather than conduct a legitimate investigation, CEO Travis Kalanick informed several of the implicated parties about Jacobs' claims prior to any legitimate investigation. This is largely the reason that Jacobs does not feel Uber has acted in good faith, and why he does not wish to sit down for a formal interview.”&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;Uber may have improperly recorded a phone call with employees &quot;following allegations of of sexual harassment by a former Uber employee. Uber did not tell the participants that the call was being recorded and accordingly had not received permission from the call participants to record it, as required by California law.&quot;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;8&quot;&gt;
&lt;p&gt;Uber hired at least one CIA-trained contractor to collect &quot;mobile-phone metadata either directly through signal-intercept equipment, hacked mobile devices, or through the mobile network itself. The information eventually shared with Jacobs and others included call logs, with time and date of communications, communicants' phone numbers, call durations, and the identification of the mobile phone subscribers.&quot;&lt;br/&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Uber accessed a protected computer database to lure drivers away to work for the company even though &quot;the database was protected by 'Captcha' to prevent the sort of automated downloading that Uber's MA team intended to carry out. MA was ultimately successful in hacking the system and obtaining the driver database. Because Uber knowingly accessed a protected computer in order to fraudulently capture its valuable contents to gain a competitive advantage, the hack violates the [Computer Fraud and Abuse Act], as well as California Penal Code Section 502.&quot;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;When asked last month by Waymo’s lawyer on whether he was aware of a unit within Uber stealing trade secrets, something he outlined in his lawyer’s letter, Jacobs distanced himself the claims. “I don’t stand by that statement,” Jacobs testified when asked about a passage in the letter that discussed an Uber employee recruiting job candidates with sensitive information from competitors. A lawyer for Jacobs also filed a motion last month in an attempt to prevent the letter from being viewed by the general public.&lt;/p&gt;
&lt;p&gt;“There's hyperbolic language in here or things that I would not have stated in the same manner, but… I did not write the letter,” Jacobs said in court, placing the responsibility for the document on his previous lawyer, Halunen.&lt;/p&gt;
&lt;p&gt;In a November 29 email to employees, Uber CEO Dara Khosrowshahi wrote, “With regard to the allegations outlined in Ric Jacobs’ letter, I can tell you that we have not been able to substantiate every one of his claims, including any related to Waymo. But I will also say that there is more than enough there to merit serious concern.”&lt;/p&gt;
&lt;p&gt;A lawyer for Clark, who was fired from the company last month for his role in covering up an October 2016 incident in which &lt;a href=&quot;https://www.buzzfeed.com/ryanmac/uber-says-hackers-compromised-57-million-accounts-a-year&quot; data-skimlinks-tracking=&quot;4706322&quot;&gt;Uber was hacked&lt;/a&gt;, also denied that his client did anything wrong.&lt;/p&gt;
&lt;p&gt;&quot;He has never been allowed to see Mr. Jacobs’ letter and looks forward to addressing it at the appropriate time,&quot; Mark Howitson, Clark's attorney, said in a statement. &quot;Mr. Jacobs' testimony on the content of his letter speaks for itself.&quot;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;Also on Friday, a court administrator issued an opinion on the matter of the Jacobs letter, stating that Uber knew of the letter’s existence and should have released it as part of the previous discovery process.&lt;/p&gt;
&lt;p&gt;“The facts in this case suggest that Ms. Padilla knew of the Jacobs Letter at the time Uber had to respond to discovery requests calling for its production — it certainly was ‘reasonably accessible’,” the filing reads. “Mr. Jacobs’ correspondence alleged systemic, institutionalized, and criminal efforts by Uber to conceal evidence and steal trade secrets…”&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;Alsup can now respond to this finding, and could potentially choose to sanction Uber’s legal team for its failure to produce the document.&lt;/p&gt;
</description>
<pubDate>Sat, 16 Dec 2017 01:00:46 +0000</pubDate>
<dc:creator>danso</dc:creator>
<og:url>https://www.buzzfeed.com/ryanmac/ric-jacobs-uber-letter-allegations-waymo</og:url>
<og:image>https://img.buzzfeed.com/buzzfeed-static/static/2017-12/15/18/enhanced/buzzfeed-prod-fastlane-01/original-29877-1513382378-2.jpg?crop=3354:1756;0,240</og:image>
<og:title>Uber Accused Of Espionage, Bribery, Hacking And More In Bombshell Letter</og:title>
<og:description>A former Uber employee accused the company of corporate espionage, unlawful surveillance, illegal wiretapping, bribery of foreign officials, and illicit hacking.</og:description>
<og:type>article</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.buzzfeed.com/ryanmac/ric-jacobs-uber-letter-allegations-waymo</dc:identifier>
</item>
<item>
<title>MobileCoin: A New Cryptocurrency from Moxie Marlinspike</title>
<link>https://www.wired.com/story/mobilecoin-cryptocurrency/</link>
<guid isPermaLink="true" >https://www.wired.com/story/mobilecoin-cryptocurrency/</guid>
<description>&lt;p&gt;&lt;span class=&quot;lede&quot;&gt;In the early&lt;/span&gt; bitcoin years, proponents promised that you would soon be able to pay for anything and everything with cryptocurrency. Order &lt;a href=&quot;https://www.wired.com/2011/11/mf_bitcoin/&quot;&gt;pizza&lt;/a&gt;! &lt;a href=&quot;https://www.techrepublic.com/article/pay-with-bitcoin-10-of-the-most-interesting-places-to-spend-it/&quot; target=&quot;_blank&quot;&gt;Buy Etsy&lt;/a&gt; trinkets! Use a &lt;a href=&quot;https://www.wired.com/2014/01/bitcoin_atm/&quot;&gt;bitcoin ATM&lt;/a&gt;! While PayPal had existed for more than a decade, frictionless, social payment platforms like Venmo were just first taking off, and cryptocurrency seemed like a legitimate way for digital transactions to evolve.&lt;/p&gt;
&lt;p&gt;It didn't happen. Cryptocurrency remains confusing and challenging for the average person to acquire and manage, much less &lt;a href=&quot;https://twitter.com/TedOnPrivacy/status/940588631709896704&quot; target=&quot;_blank&quot;&gt;sell&lt;/a&gt;. And the protocols that underlie bitcoin and other mainstream cryptocurrencies like ethereum suffer significant scalability and &lt;a href=&quot;https://www.wired.com/story/bitcoin-is-soaring-heres-why-its-not-ready-for-the-big-time/&quot;&gt;transaction bottleneck issues&lt;/a&gt;. Visa currently processes about 3,674 transactions per second; the best bitcoin network &lt;em&gt;might&lt;/em&gt; be able to process seven per second.&lt;/p&gt;
&lt;p&gt;But now the creator of the dead simple end-to-end encrypted messaging app &lt;a href=&quot;http://www.wired.com/tag/signal&quot;&gt;Signal&lt;/a&gt;, &lt;a href=&quot;https://www.wired.com/2016/07/meet-moxie-marlinspike-anarchist-bringing-encryption-us/&quot;&gt;Moxie Marlinspike&lt;/a&gt;, is on a mission to overcome those limitations, and to create a streamlined digital currency that's private, easy-to-use, and allows for quick transactions from any device. And while it may feel like the last thing the world needs is yet another cryptocurrency, Marlinspike's track record with Signal—and the organization behind it, Open Whisper Systems—makes this a project worth watching.&lt;/p&gt;
&lt;h3&gt;Coin Toss&lt;/h3&gt;
&lt;p&gt;The currency Marlinspike has been working on as technical advisor for the last four months, alongside technologist Joshua Goldbard, is MobileCoin. The two based it on the open-source Stellar Consensus Protocols platform, an alternative payment network that underlies systems like an &lt;a href=&quot;https://www.stellar.org/blog/IBM-KlickEx-Partnership/&quot; target=&quot;_blank&quot;&gt;inter-bank payment network run by IBM&lt;/a&gt; in the South Pacific, and the low-fee international &lt;a href=&quot;https://tempo.eu.com/en/news/post/15&quot; target=&quot;_blank&quot;&gt;money transfer service Tempo&lt;/a&gt; in Europe.&lt;/p&gt;

&lt;div class=&quot;inset-left-component inset-left-component--pullquote&quot; readability=&quot;8&quot;&gt;
&lt;blockquote name=&quot;inset-left&quot; class=&quot;inset-left-component__el&quot; readability=&quot;5&quot;&gt;
&lt;p&gt;'Usability is the biggest challenge with cryptocurrency today.'&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p name=&quot;inset-left&quot; class=&quot;inset-left-component__el&quot;&gt;Signal Creator Moxie Marlinspike&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The Stellar blockchain is also generally regarded as being faster and more efficient than its predecessors; On Wednesday, the mobile messaging service Kik &lt;a href=&quot;https://www.youtube.com/watch?v=qePiRXQE3Jk&quot; target=&quot;_blank&quot;&gt;announced&lt;/a&gt; that it will move its Kin cryptocurrency platform from Ethereum to Stellar. &quot;We've been using Ethereum to date, and to be honest I call it the dial-up era of blockchain,&quot; CEO Ted Livingston said.&lt;/p&gt;
&lt;p&gt;MobileCoin wants to leverage an extensive architecture to add simplicity to real privacy protections and resilience against attacks. The ultimate goal: To make MobileCoin as intuitive as any other payment system.&lt;/p&gt;
&lt;p&gt;That vision mirrors the animating purpose of Signal, which was developed to make robust end-to-end encrypted communication as easy and straightforward as less secure options, a simple experience that belies the complex cryptographic communication protocols that enable it.&lt;/p&gt;
&lt;p&gt;&quot;I think usability is the biggest challenge with cryptocurrency today,&quot; says Marlinspike. &quot;The innovations I want to see are ones that make cryptocurrency deployable in normal environments, without sacrificing the properties that distinguish cryptocurrency from existing payment mechanisms.&quot;&lt;/p&gt;


&lt;p&gt;Usability efforts for older generation cryptocurrency protocols, like bitcoin, have largely been left to services like Coinbase, which centralize everything from currency exchange to your wallet, key management, and processing transactions. These platforms make actually using cryptocurrency more realistic for the average person, but they also consolidate mechanisms that are meant to be kept separate in the private and decentralized concept of cryptocurrency. They generally detail extensive privacy and security protections, but they do require users to trust both their intentions and implementation.&lt;/p&gt;
&lt;p&gt;By contrast, the idea of MobileCoin is to build a system that hides everything from everyone, leaving fewer (or theoretically no) opportunities for abuse.&lt;/p&gt;
&lt;h3&gt;On the Node&lt;/h3&gt;
&lt;p&gt;Ideally, there would be a way to fix the structural problems of existing cryptocurrencies, rather than creating another new offering. But Marlinspike and Goldbard concluded that the only way to orient a cryptocurrency around user needs was to start from scratch, and architect everything with that &quot;target user experience&quot; in mind.&lt;/p&gt;
&lt;p&gt;To that end, MobileCoin delegates all the complicated and processing-intensive work of participating in a blockchain ledger and validating transactions to nodes—servers with constant connectivity that store and work on a fully updated copy of a currency's blockchain. The nodes can then provide software services to users, like apps that seamlessly integrate easy and quick MobileCoin transactions. The nodes also handle key management for users, so the public—and particularly the private—numeric sequences that encrypt each person's transactions are stored and used by the node. But crucially MobileCoin is designed so the node operators can never directly access users' private keys.&lt;/p&gt;
&lt;div class=&quot;inset-left-component inset-left-component--pullquote&quot; readability=&quot;9.5&quot;&gt;
&lt;blockquote name=&quot;inset-left&quot; class=&quot;inset-left-component__el&quot; readability=&quot;6&quot;&gt;
&lt;p&gt;'If you can’t look at the ledger, how can you cheat it?'&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p name=&quot;inset-left&quot; class=&quot;inset-left-component__el&quot;&gt;Joshua Goldbard, MobileCoin&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This is where the special features of MobileCoin come in. The currency is designed to utilize an Intel processor component known as Software Guard Extensions, or a &quot;secure enclave.&quot; SGX is a sequestered portion of a processor that runs code like any other, but the software inside it can't be accessed or changed by a device's broader operating system. Computers can still check that an enclave is running the right software to validate it before connecting, but neither MobileCoin users nor node administrators can decrypt and view the enclave.&lt;/p&gt;

&lt;p&gt;For MobileCoin, the enclaves in all of the nodes of the network hide the currency's indelible ledger from view. Users' private keys are stored and shielded in the enclave, too.&lt;/p&gt;
&lt;p&gt;&quot;If you put the cryptocurrency inside of the secure enclave, then people can run the nodes without seeing what’s happening inside them,&quot; Goldbard says. &quot;If you can’t look at the ledger, how can you cheat it?&quot;&lt;/p&gt;
&lt;p&gt;Marlinspike first &lt;a href=&quot;https://www.wired.com/story/signal-contact-lists-private-secure-enclave/&quot;&gt;experimented with SGX for Signal&lt;/a&gt; as a workaround so users can find people they know on Signal through their address books without exposing all of that data.&lt;/p&gt;

&lt;p&gt;Secure enclaves create some technical challenges, because they have limited processing capacity. But MobileCoin is designed with efficiency in mind. The system does as much data processing as possible outside the enclave, and only uses SGX for sensitive computing that needs to be shielded. And not needing to trust the nodes—because sensitive data isn't exposed on them—means that more can happen off of a user's device without sacrificing privacy, making transactions quick and easy on mobile devices.&lt;/p&gt;
&lt;p&gt;&quot;MobileCoin is designed to be deployable in normal resource-constrained environments like mobile devices, and to deliver a simple user experience along with privacy and security,&quot; Marlinspike says. &quot;The design gives you the benefits of server assistance without the downsides of having to trust a server to act appropriately and not be hacked.&lt;/p&gt;

&lt;p&gt;The platform has other protections layered with SGX as well. Even if someone compromised a MobileCoin enclave and could view the transaction ledger, one-time addresses and special one-time signatures for each transaction would still prevent an attacker from being able to trace and link events. And a privacy bonus of the Stellar Consensus Protocol is that the nodes don't need to store a full transaction history in the blockchain; they can discard most data after each payment is completed. These components make MobileCoin more resistant to surveillance, whether it's coming from a government or a criminal who wants to track and extort users.&lt;/p&gt;
&lt;h3&gt;Getting Practical&lt;/h3&gt;
&lt;p&gt;There are lots of potential applications for MobileCoin, but Goldbard and Marlinspike envision it first as an integration in chat apps like Signal or WhatsApp. Here's how it would work in practice: To start using MobileCoin, you would generate a public and private key, and a recovery PIN. Then you would set up your account with an app that incorporates MobileCoin. The app would validate the software running in its service's node, establish an encrypted communication channel to the enclave, and then send your keys and the short, easy-to-remember recovery PIN that you'll use to access your MobileCoin—like a smartphone lock passcode.&lt;/p&gt;
&lt;p&gt;To send MobileCoin to your friend Brian within a service that both of you use, your app would look up his public key, generate a one-time key and signature to use for the transaction, and send the transaction to the app's MobileCoin node. The node would sync and validate the transaction, update the ledger, and check the one-time key and signature to prevent spoofed double-spending. At this point Brian's MobileCoin node would take over, receiving and validating the transaction and communicating with Brian's app to generate the one-time private key that will allow Brian to receive the payment. And then Brian gets a notification that you paid him. The messaging app (or whatever service you're both using) doubles as a wallet for each of you.&lt;/p&gt;
&lt;p&gt;It's a complicated process to wade through. The point of MobileCoin, though, is that you and Brian don't have to worry about any of it. The complicated parts all take place in the background.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://www.mobilecoin.com&quot; target=&quot;_blank&quot;&gt;MobileCoin site&lt;/a&gt;, where developers looking to adopt the cryptocurrency will ultimately be able to access the software development kit, currently houses a white paper describing how MobileCoin works in more detail. But Goldbard says that the currency is still six months to a year from release, while he and Marlinspike refine the platform to eliminate potential problems, like the possibility that secure enclaves can inadvertently leak data.&lt;/p&gt;

&lt;div class=&quot;inset-left-component inset-left-component--article&quot;&gt;
&lt;h4 class=&quot;inset-left-component__el&quot;&gt;Related Stories&lt;/h4&gt;
&lt;ul class=&quot;inset-left-component--article__list&quot;&gt;&lt;li class=&quot;article-list-item-embed-component__post&quot; readability=&quot;23&quot;&gt;

&lt;div class=&quot;article-list-item-embed-component__description&quot; readability=&quot;32&quot;&gt;
&lt;p&gt;&lt;span&gt;Tom Simonite&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;article-list-item-embed-component__title&quot;&gt;Bitcoin Is Splitting in Two. Now What?&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li class=&quot;article-list-item-embed-component__post&quot; readability=&quot;23.5&quot;&gt;

&lt;div class=&quot;article-list-item-embed-component__description&quot; readability=&quot;33&quot;&gt;
&lt;p&gt;&lt;span&gt;Mark Frauenfelder&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;article-list-item-embed-component__title&quot;&gt;‘I Forgot My PIN’: An Epic Tale of Losing $30,000 in Bitcoin&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li class=&quot;article-list-item-embed-component__post&quot; readability=&quot;23.5&quot;&gt;

&lt;div class=&quot;article-list-item-embed-component__description&quot; readability=&quot;33&quot;&gt;
&lt;p&gt;&lt;span&gt;Andy Greenberg&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;article-list-item-embed-component__title&quot;&gt;Meet Moxie Marlinspike, the Anarchist Bringing Encryption to All of Us&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;p&gt;That means there are still plenty of questions to be answered, including one big one: whether MobileCoin will be able to cut through all the noise and hype of the cryptocurrency community to actually be adopted by mainstream apps that could put it in everyone's hands. Currencies, after all, need a critical mass of people to not just be able to use them, but to agree on their worth.&lt;/p&gt;
&lt;p&gt;And though speculation has driven bitcoin to all-time-high valuations, most cryptocurrencies don't end up capturing much value, languishing instead in far-flung corners of the internet. Here again, though, MobileCoin's creators hope to emulate Signal. End-to-end encryption was once a fringe feature; then &lt;a href=&quot;https://www.wired.com/2016/04/forget-apple-vs-fbi-whatsapp-just-switched-encryption-billion-people/&quot;&gt;WhatsApp gave it to a billion people at once&lt;/a&gt; using the Signal Protocol.&lt;/p&gt;
&lt;p&gt;&quot;Nobody actually transacts in cryptocurrency,&quot; Goldbard says. &quot;So making something that people can actually use is our first goal. And then we want to find additional ways that people can implement it over time. But initially all we want is to make it so people can actually complete transactions.&quot;&lt;/p&gt;
&lt;p&gt;If it works, the project will give hope to people who once believed cryptocurrency could truly replace cash in modern society—even if you're only buying a pizza.&lt;/p&gt;
</description>
<pubDate>Fri, 15 Dec 2017 21:59:02 +0000</pubDate>
<dc:creator>golangnews</dc:creator>
<og:type>article</og:type>
<og:title>The Creator of Signal Has a Plan to Fix Cryptocurrency</og:title>
<og:description>MobileCoin aims to make cryptocurrency transactions quick and easy for everyone, while still preserving privacy and decentralization.</og:description>
<og:image>https://media.wired.com/photos/5a31accea850e23a4736f420/191:100/pass/cryptocurrency_mobilecoin-01-FINAL.jpg</og:image>
<og:url>https://www.wired.com/story/mobilecoin-cryptocurrency/</og:url>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.wired.com/story/mobilecoin-cryptocurrency/</dc:identifier>
</item>
<item>
<title>Overcoming Us vs. Them</title>
<link>http://nautil.us/issue/55/trust/why-your-brain-hates-other-people-rp</link>
<guid isPermaLink="true" >http://nautil.us/issue/55/trust/why-your-brain-hates-other-people-rp</guid>
<description>&lt;p&gt;&lt;span class=&quot;dropcap&quot;&gt;A&lt;/span&gt;s a kid, I saw the 1968 version of &lt;em&gt;Planet of the Apes&lt;/em&gt;. As a future primatologist, I was mesmerized. Years later I discovered an anecdote about its filming: At lunchtime, the people playing chimps and those playing gorillas ate in separate groups.&lt;/p&gt;
&lt;p&gt;It’s been said, “There are two kinds of people in the world: those who divide the world into two kinds of people and those who don’t.” In reality, there’s lots more of the former. And it can be vastly consequential when people are divided into Us and Them, ingroup and outgroup, “the people” (i.e., our kind) and the Others.&lt;/p&gt;
&lt;blockquote class=&quot;pull-quote&quot;&gt;
&lt;p&gt;The core of Us/Them-ing is emotional and automatic.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Humans universally make Us/Them dichotomies along lines of race, ethnicity, gender, language group, religion, age, socioeconomic status, and so on. And it’s not a pretty picture. We do so with remarkable speed and neurobiological efficiency; have complex taxonomies and classifications of ways in which we denigrate Thems; do so with a versatility that ranges from the minutest of microaggression to bloodbaths of savagery; and regularly decide what is inferior about Them based on pure emotion, followed by primitive rationalizations that we mistake for rationality. Pretty depressing.&lt;/p&gt;
&lt;p&gt;But crucially, there is room for optimism. Much of that is grounded in something definedly human, which is that we all carry multiple Us/Them divisions in our heads. A Them in one case can be an Us in another, and it can only take an instant for that identity to flip. Thus, there is hope that, with science’s help, clannishness and xenophobia can lessen, perhaps even so much so that Hollywood-extra chimps and gorillas can break bread together.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Strength of Us Versus Them&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Considerable evidence suggests that dividing the world into Us and Them is deeply hard-wired in our brains, with an ancient evolutionary legacy. For starters, we detect Us/Them differences with stunning speed. Stick someone in a “functional MRI”—a brain scanner that indicates activity in various brain regions under particular circumstances. Flash up pictures of faces for 50 milliseconds—a 20th of a second—barely at the level of detection. And remarkably, with even such minimal exposure, the brain processes faces of Thems differently than Us-es.&lt;/p&gt;
&lt;img src=&quot;http://static.nautil.us/12553_3d9728c728f49af2642c560be7cc3f79.png&quot;/&gt;&lt;p&gt;This has been studied extensively with the inflammatory Us/Them of race. Briefly flash up the face of someone of a different race (compared with a same-race face) and, on average, there is preferential activation of the amygdala, a brain region associated with fear, anxiety, and aggression. Moreover, other-race faces cause less activation than do same-race faces in the fusiform cortex, a region specializing in facial recognition; along with that comes less accuracy at remembering other-race faces. Watching a film of a hand being poked with a needle causes an “isomorphic reflex,” where the part of the motor cortex corresponding to your own hand activates, and your hand clenches—unless the hand is of another race, in which case less of this effect is produced.&lt;/p&gt;
&lt;p&gt;The brain’s fault lines dividing Us from Them are also shown with the hormone oxytocin. It’s famed for its pro-social effects—oxytocin prompts people to be more trusting, cooperative, and generous. But, crucially, this is how oxytocin influences behavior toward members of your &lt;em&gt;own&lt;/em&gt; group. When it comes to outgroup members, it does the opposite.&lt;/p&gt;
&lt;p&gt;The automatic, unconscious nature of Us/Them-ing attests to its depth. This can be demonstrated with the fiendishly clever Implicit Association Test. Suppose you’re deeply prejudiced against trolls, consider them inferior to humans. To simplify, this can be revealed with the Implicit Association Test, where subjects look at pictures of humans or trolls, coupled with words with positive or negative connotations. The couplings can support the direction of your biases (e.g., a human face and the word “honest,” a troll face and the word “deceitful”), or can run counter to your biases. And people take slightly longer, a fraction of a second, to process discordant pairings. It’s automatic—you’re not fuming about clannish troll business practices or troll brutality in the Battle of Somewhere in 1523. You’re processing words and pictures, and your anti-troll bias makes you unconsciously pause, stopped by the dissonance linking troll with “lovely,” or human with “malodorous.”&lt;/p&gt;
&lt;p&gt;We’re not alone in Us/Them-ing. It’s no news that other primates can make violent Us/Them distinctions; after all, chimps band together and systematically kill the males in a neighboring group. Recent work, adapting the Implicit Association Test to another species, suggests that even other primates have implicit negative associations with Others. Rhesus monkeys would look at pictures either of members of their own group or strangers, coupled with pictures of things with positive or negative connotations. And monkeys would look longer at pairings discordant with their biases (e.g., pictures of members of their own group with pictures of spiders). These monkeys don’t just fight neighbors over resources. They have negative associations about them—“Those guys are like yucky spiders, but us, us, we’re like luscious fruit.”&lt;/p&gt;
&lt;p&gt;Thus, the strength of Us/Them-ing is shown by the: speed and minimal sensory stimuli required for the brain to process group differences; tendency to group according to arbitrary differences, and then imbue those differences with supposedly rational power; unconscious automaticity of such processes; and rudiments of it in other primates. As we’ll see now, we tend to think of Us, but not Thems, fairly straightforwardly.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Nature of Us&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Across cultures and throughout history, people who comprise Us are viewed in similarly self-congratulatory ways—We are more correct, wise, moral, and worthy. Us-ness also involves inflating the merits of our arbitrary markers, which can take some work—rationalizing why our food is tastier, our music more moving, our language more logical or poetic.&lt;/p&gt;
&lt;p&gt;Us-ness also carries obligations toward the other guy—for example, in studies in sports stadiums, a researcher posing as a fan, complete with sweatshirt supporting one of the teams and in need of help with something, is more likely to be helped by a fellow fan than by an opposing one.&lt;/p&gt;
&lt;p&gt;Ingroup favoritism raises a key question—at our core, do we want Us to do “well” by maximizing absolute levels of well being, or merely “better than,” by maximizing the gap between Us and Them?&lt;/p&gt;
&lt;p&gt;We typically claim to wish for the former, but can smolder with desire for the latter. This can be benign—in a tight pennant race, a loss for the hated rival to a third party is as good as a win for the home team, and for sectarian sports fans, both outcomes similarly activate brain pathways associated with reward and the neurotransmitter dopamine. But sometimes, choosing “better than” over “well” can be disastrous. It’s not a great mindset to think you’ve won World War III if afterward Us have two mud huts and three fire sticks and They have only one of each.&lt;/p&gt;
&lt;img src=&quot;http://static.nautil.us/12554_6644cb08d30b2ca55c284344a9750c2e.png&quot;/&gt;&lt;p&gt;Among the most pro-social things we do for ingroup members is readily forgive them for transgressions. When a Them does something wrong, it reflects essentialism—that’s the way They are, always have been, always will be. When an Us is in the wrong, however, the pull is toward situational interpretations—we’re not usually like that, and here’s the extenuating circumstance to explain why he did this. Situational explanations for misdeeds are the reason why defense lawyers want jurors who will view the defendant as an Us.&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;Something interesting and different can happen when someone’s transgression airs Us’s dirty laundry, affirming a negative stereotype. Ingroup shame can provoke intense punishment for the benefit of outsiders. Consider Rudy Giuliani, growing up in Brooklyn in an Italian-American enclave dominated by organized crime (Giuliani’s father served time for armed robbery and then worked for a mob loan shark). Giuliani gained prominence in 1985 as the attorney prosecuting the “Five Families” in the Mafia Commission Trial, effectively destroying them. He was strongly motivated to counter the stereotype of “Italian-American” as synonymous with organized crime—“If [the successful prosecution is] not enough to remove the Mafia prejudice, then there probably could not be anything you could do to remove it.” If you want someone to ferociously prosecute Mafiosi, get a proud Italian-American outraged by the stereotypes generated by the mob.&lt;/p&gt;
&lt;p&gt;Thus, being an Us carries an array of ingroup expectations and obligations. Is it possible to switch from one category of Us to another? That’s easy in, say, sports—when a player is traded he doesn’t serve as a fifth column, throwing games in his new uniform to benefit his old team. The core of such a contractual relationship is the fungibility of employer and employee.&lt;/p&gt;
&lt;p&gt;At the other extreme are Us memberships that are not fungible, transcending negotiation. People aren’t traded from the Shiites to the Sunnis, or from the Iraqi Kurds to the Sami herders in Finland. It’s a rare Kurd who wants to be Sami, and her ancestors would likely turn over in their graves when she nuzzled her first reindeer. Converts are often subject to retribution by those they left—consider Meriam Ibrahim, sentenced to death in Sudan in 2014 for converting to Christianity—and suspicion from those they joined.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Nature of Them&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Do we think or feel our way toward disliking Them?&lt;/p&gt;
&lt;p&gt;Us/Them-ing is readily framed cognitively. Ruling classes do cognitive cartwheels to justify the status quo. Likewise, it’s a cognitive challenge to accommodate the celebrity Them, the neighborly Them who has saved our keister—“Ah, this Them is different.”&lt;/p&gt;
&lt;p&gt;Viewing Thems in certain threatening ways requires cognitive subtlety. Being afraid that some Them will rob you is rife with affect and particularism. But fearing that those Thems will take our jobs, manipulate the banks, dilute our bloodlines, etc., requires thoughts about economics, sociology, and pseudoscience.&lt;/p&gt;
&lt;img src=&quot;http://static.nautil.us/12547_a3fc34dce15cda93287496c84af5203c.png&quot; width=&quot;733&quot; alt=&quot;&quot;/&gt;&lt;span class=&quot;caption&quot;&gt;&lt;strong&gt;it’s negotiable:&lt;/strong&gt; When a Confederate general was wounded during the U.S. Civil War, he gave a secret Masonic sign that was recognized by a Union officer, who protected him and took him to a Union hospital.&lt;/span&gt;&lt;span class=&quot;credit&quot;&gt;Stock Montage / Contributor / Getty Images&lt;/span&gt;
&lt;p&gt;Despite that role of cognition, the core of Us/Them-ing is emotional and automatic, as summarized by when we say, “I can’t put my finger on why, but it’s just wrong when They do that.” Jonathan Haidt of New York University has shown that often, cognitions are post-hoc justifications for feelings and intuitions, to convince ourselves that we have indeed rationally put our finger on why.&lt;/p&gt;
&lt;p&gt;This can be shown with neuroimaging studies. As noted, when fleetingly seeing the face of a Them, the amygdala activates. Critically, this comes long before (on the time scale of brain processing) more cognitive, cortical regions are processing the Them. The emotions come first.&lt;/p&gt;
&lt;blockquote class=&quot;pull-quote&quot;&gt;
&lt;p&gt;Dividing the world into Us and Them is deeply hard-wired.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The strongest evidence that abrasive Them-ing originates in emotional, automatic processes is that supposed rational cognitions about Thems can be unconsciously manipulated. Just consider this array of findings: Show subjects slides about some obscure country; afterward, they will have more negative attitudes toward the place if, between slides, pictures of faces with expressions of fear appeared at subliminal speeds. Sitting near smelly garbage makes people more socially conservative about outgroup issues (e.g., attitudes toward gay marriage among heterosexuals). Christians express more negative attitudes toward non-Christians if they’ve just walked past a church. In another study, commuters at train stations in predominantly white suburbs filled out questionnaires about political views. Then, at half the stations, a pair of young Mexicans, conservatively dressed and chatting quietly, appeared daily on the platform for two weeks. Then commuters filled out second questionnaires. Remarkably, the presence of such pairs made people more supportive of decreasing &lt;em&gt;legal&lt;/em&gt; immigration from Mexico and making English the official language, and more opposed to amnesty for undocumented immigrants (without changing attitudes about Asian-Americans, African-Americans or Middle Easterners). Women, when ovulating, have more negative attitudes about outgroup men.&lt;/p&gt;
&lt;p&gt;In other words, our visceral, emotional views of Thems are shaped by subterranean forces we’d never suspect. And then our cognitions sprint to catch up with our affective selves, generating the minute factoid or plausible fabrication that explains why we hate Them. It’s a kind of confirmation bias: remembering supportive better than opposing evidence; testing things in ways that can support but not negate your hypothesis; skeptically probing outcomes you don’t like more than ones you do.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The Heterogeneity of Thems&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Of course, different types of Thems evoke different feelings (and different neurobiological responses). Most common is to view Them as threatening, angry, and untrustworthy. In economic games people implicitly treat other-race individuals as less trustworthy or reciprocating. Whites judge African-American faces as angrier than white faces, and are more likely to categorize racially ambiguous angry faces as the other race.&lt;/p&gt;
&lt;img src=&quot;http://static.nautil.us/12555_04c7f37f2420f0532d7f0e062ff2d5b5.png&quot;/&gt;&lt;p&gt;But Thems do not solely evoke a sense of menace; sometimes, it’s disgust. This brings up one fascinating brain region, the insula. In mammals, it responds to the taste or smell of something rotten, and triggers stomach lurching and gag reflexes. In other words, it protects animals from poisonous food. Crucially, in humans the insula not only mediates such sensory disgust, but also moral disgust—have subjects recount something rotten they’ve done, show them pictures of morally appalling things (e.g., a lynching), and the insula activates. It’s why it’s not just metaphorical that sufficiently morally disgusting material makes us feel sick to our stomachs. And Thems that typically evoke a sense of disgust (e.g. drug addicts) activate the insula at least as much as the amygdala.&lt;/p&gt;
&lt;p&gt;Having viscerally negative feelings about abstract features of Thems is challenging; being disgusted by another group’s abstract beliefs isn’t easy for the insula. Us/Them markers provide a stepping-stone. Feeling disgusted by Them because they eat repulsive, sacred, or adorable things, slather themselves with rancid scents, dress in scandalous ways—this the insula can sink its teeth into. In the words of the psychologist Paul Rozin of the University of Pennsylvania, “Disgust serves as an ethnic or outgroup marker.” Deciding that They eat disgusting things facilitates deciding that They also have disgusting ideas about, say, deontological ethics.&lt;/p&gt;
&lt;p&gt;Then there are Thems who are ridiculous, i.e., subject to ridicule, humor as hostility. Outgroups mocking the ingroup is a weapon of the weak, lessening the sting of subordination. But when an ingroup mocks an outgroup, it solidifies negative stereotypes and reifies the hierarchy.&lt;/p&gt;
&lt;p&gt;Thems are also frequently viewed as more homogeneous than Us, with simpler emotions and less sensitivity to pain. For example, whether in ancient Rome, medieval England, imperial China, or the antebellum South, the elite had system-justifying stereotypes of slaves as simple, childlike, and incapable of independence.&lt;/p&gt;
&lt;p&gt;Thus, different Thems come in different flavors with immutable, icky essences—threatening and angry, disgusting and repellent, ridiculous, primitive, and undifferentiated.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cold and/or Incompetent&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Important work by Susan Fiske of Princeton University explores the taxonomies of Thems we carry in our heads. She finds that we tend to categorize Thems along two axes: “warmth” (is the individual or group a friend or foe, benevolent or malevolent?) and “competence” (how effectively can the individual or group carry out their intentions?).&lt;/p&gt;
&lt;p&gt;The axes are independent. Ask subjects to assess someone; priming them with cues about the person’s status alters ratings of competence but not of warmth. Priming about the person’s competitiveness does the opposite. These two axes produce a matrix with four corners. We rate ourselves as high in both warmth and competence (H/H), naturally. Americans typically rate good Christians, African-American professionals, and the middle class this way.&lt;/p&gt;
&lt;p&gt;There’s the other extreme, low in both warmth and competence (L/L). Such ratings go to the homeless or addicts.&lt;/p&gt;
&lt;p&gt;Then there’s the high-warmth/low-competence (H/L) realm—the mentally disabled, people with handicaps, infirm elderly. Low warmth/high competence (L/H) is how people in the developing world tend to view the Europeans who colonized them (“competence” here is not about skill at rocket science, but rather the efficacy those people had when getting it into their heads to, say, steal your ancestral lands), and how many minority Americans view whites. It’s the hostile stereotype of Asian-Americans by white America, of Jews in Europe, of Indo-Pakistanis in East Africa, of Lebanese in West Africa, of ethnic Chinese in Indonesia, and of the rich by the poor most everywhere—they’re cold, greedy, clannish but, dang, go to one who is a doctor if you’re seriously sick.&lt;/p&gt;
&lt;blockquote class=&quot;pull-quote&quot;&gt;
&lt;p&gt;Between envy and disgust are our most hostile urges.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Each extreme tends to evoke consistent feelings. For H/H (i.e., Us), there’s pride. L/H—envy and resentment. H/L—pity. L/L—disgust. Viewing pictures of L/L people activates the amygdala and insula, but not the fusiform face area; this is the same profile evoked by a picture of, say, a maggot-infested wound. In contrast, viewing L/H or H/L individuals activates emotional and cognitive parts of the frontal cortex.&lt;/p&gt;
&lt;p&gt;The places between the extremes evoke their own characteristic responses. Individuals who evoke a reaction between pity and pride evoke a desire to help. Floating between pity and disgust is a desire to exclude and demean. Between pride and envy is a desire to associate, to derive benefits from. And between envy and disgust are our most hostile urges to attack.&lt;/p&gt;
&lt;p&gt;What fascinates me is when someone’s categorization changes. Most straightforward are shifts from high-warmth/high-competence (H/H) status:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;H/H to H/L&lt;/em&gt;: A parent declining into dementia, evoking poignant protectiveness.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;H/H to L/H&lt;/em&gt;: The business partner who turns out to have embezzled for decades. Betrayal.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;H/H to L/L&lt;/em&gt;: The rare instance of that successful acquaintance, where “something happened” and now he’s homeless. Disgust mingled with bafflement—what went wrong?&lt;/p&gt;
&lt;p&gt;Then there’s L/L to L/H. When I was a kid in the ’60s, the parochial American view of Japan was the former—World War II’s shadow generating dislike and contempt, and “Made in Japan” was about cheap plastic gewgaws. Then, suddenly, “Made in Japan” meant outcompeting American automakers.&lt;/p&gt;
&lt;p&gt;When a homeless guy does cartwheels to return someone’s lost wallet—and you realize he’s more decent than your friends—that’s L/L to H/L.&lt;/p&gt;
&lt;img src=&quot;http://static.nautil.us/12548_194585b5215aea447389c5fefca09c61.png&quot; width=&quot;733&quot; alt=&quot;&quot;/&gt;&lt;p&gt;Most interesting to me is L/H to L/L, which invokes gleeful gloating, helping to explain why persecution of L/H groups usually involves degrading and humiliating them to L/L status. During China’s Cultural Revolution, resented elites were first paraded in dunce caps before exile to labor camps. Nazis eliminated the mentally ill, already viewed as L/L, by unceremoniously murdering them; in contrast, pre-murder treatment of the L/H Jews involved forcing them to wear degrading yellow armbands, cutting one another’s beards, scrubbing sidewalks with toothbrushes before jeering crowds. When Idi Amin expelled tens of thousands of L/H Indo-Pakistani citizens from Uganda in the 1970s, he first invited his army to rob, beat, and rape them. Turning L/H Thems into L/L Thems accounts for some of our worst savagery.&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;Complexities in our categorization of Thems abound. There’s the phenomenon of the grudging respect, even a sense of camaraderie with an enemy, the perhaps apocryphal picture of World War I flying aces, where a glimmer of Us-ness is shared with someone trying to kill you (“Ah, monsieur, if it were another time, I would delight in discussing aeronautics with you over some good wine.” “Baron, it is an honor that it is you who shoots me out of the sky”). And there’s the intricacies of differing feelings about economic versus cultural enemies, new versus ancient ones, or the distant alien enemy versus the familiar one next door (consider Ho Chi Minh, rejecting the offer of help from Chinese troops during the Vietnam War, stating to the effect of “The Americans will leave in a year or a decade, but the Chinese will stay for a thousand years if we let them in”).&lt;/p&gt;
&lt;p&gt;And then there is the profoundly strange phenomenon of the self-hating ________ (take your pick of the outgroup member), who has bought into the negative stereotypes and favors the ingroup. This was shown by psychologists Kenneth and Mamie Clark in their heart-breaking “doll studies,” in the 1940s, demonstrating how African-American children, along with white children, preferred playing with white dolls over black ones, ascribing more positive attributes to them (e.g., nice, pretty). That this effect was most pronounced in black kids in segregated schools was cited in &lt;em&gt;Brown v. Board of Education&lt;/em&gt;. Or consider the scenario of the strident crusader against gay rights who turns out to be closeted—the Mobius strip pathology of accepting that you are an inferior Them. We put monkeys, even with their complexities of associating alien monkeys with spiders, to shame when it comes to the psychological vagaries of dividing the world into Us and Them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Multiple Us-es&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We also recognize that other individuals belong to multiple categories, and shift which we consider most relevant. Not surprisingly, lots of that literature concerns race, exploring whether it is an Us/Them categorization that trumps all others.&lt;/p&gt;
&lt;p&gt;The primacy of race has folk-intuition appeal. First, race is a biological attribute, a conspicuous fixed identity that readily prompts essentialist thinking. Moreover, humans evolved under conditions where different skin color conspicuously signals that someone is a distant Them. Furthermore, a large percentage of cultures, long before Western contact, make status distinctions by skin color.&lt;/p&gt;
&lt;p&gt;And yet, evidence is to the contrary. First, while there are obvious biological contributions to racial differences, “race” is a biological continuum rather than discrete categories—for example, unless you cherry-pick the data, genetic variation within race is generally as great as between races. And this really is no surprise when looking at the range of variation within a racial rubric—go compare, say, Sicilians with Swedes.&lt;/p&gt;
&lt;p&gt;Moreover, race fails as a fixed classification system. At various times in U.S. census history, “Mexican” and “Armenian” were considered races; southern Italians and northern Europeans were classified differently; someone with one black great-grandparent and seven white ones was “white” in Oregon but not Florida. This is race as a cultural construct.&lt;/p&gt;
&lt;div class=&quot;reco&quot;&gt;
&lt;article class=&quot;issue-article&quot;&gt;&lt;div&gt;&lt;a href=&quot;http://nautil.us/issue/19/Illusions/your-brain-cant-handle-the-moon&quot; class=&quot;obnd_lnk&quot; data-trval=&quot;your-brain-cant-handle-the-moon&quot; data-trlbl=&quot;foc_rec&quot; data-tract=&quot;internal_art&quot;&gt;&lt;img src=&quot;http://static.nautil.us/4733_901797aebf0b23ecbab534d61ad33bb1.png&quot; alt=&quot;Sapolsky_TH-F1&quot; width=&quot;314&quot; height=&quot;177&quot;/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;span class=&quot;article-tag&quot;&gt;&lt;span class=&quot;article-tag&quot;&gt;&lt;span class=&quot;article-tag-focus&quot;&gt;&lt;a href=&quot;http://nautil.us/term/f/Psychology&quot;&gt;Also in Psychology&lt;/a&gt;&lt;/span&gt;  &lt;/span&gt;&lt;/span&gt;
&lt;h4 class=&quot;article-title&quot;&gt;&lt;a href=&quot;http://nautil.us/issue/19/Illusions/your-brain-cant-handle-the-moon&quot; class=&quot;obnd_lnk&quot; data-trval=&quot;your-brain-cant-handle-the-moon&quot; data-trlbl=&quot;foc_rec&quot; data-tract=&quot;internal_art&quot;&gt;Your Brain Can’t Handle the Moon&lt;/a&gt;&lt;/h4&gt;
&lt;p class=&quot;article-author&quot;&gt;By Brian Gallagher&lt;/p&gt;
&lt;p&gt;What is this new theory?” the long-retired New York University cognitive psychologist, Lloyd Kaufman, asked me. We were sitting behind the wooden desk of his cozy home office. He had a stack of all his papers on the moon illusion,...&lt;strong&gt;&lt;a href=&quot;http://nautil.us/issue/19/Illusions/your-brain-cant-handle-the-moon&quot; class=&quot;obnd_lnk&quot; data-trval=&quot;your-brain-cant-handle-the-moon&quot; data-trlbl=&quot;foc_rec&quot; data-tract=&quot;internal_art&quot;&gt;READ MORE&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;/article&gt;&lt;/div&gt;
&lt;p&gt;So it’s not surprising that racial Us/Them dichotomies are frequently trumped by other classifications. In one study, subjects saw pictures of individuals, each black or white, each associated with a statement, and then had to recall which face went with which statement. There was automatic racial categorization—if subjects misattributed a quote, the correct and incorrect faces were likely to be of the same race. Next, half the blacks and whites pictured wore the same distinctive yellow shirt; the other half wore gray. Now subjects most often confused statements by shirt color. Furthermore, gender reclassification particularly overrides unconscious racial categorization. After all, while races have evolved relatively recently in hominid history (probably over the course of just a few tens of thousands of years), our ancestors, almost all the way back to when they were paramecia, cared about Boy or Girl.&lt;/p&gt;
&lt;p&gt;Important research by Mary Wheeler along with Fiske showed how categorization is shifted, studying other-race/amygdala activation. When subjects are instructed to look for a distinctive dot in each picture, other-race faces don’t activate the amygdala; face-ness wasn’t being processed. Judging whether each face looked older than some age wasn’t a recategorization that could eliminate the other-race amygdaloid response. But for a third group of subjects, a vegetable was displayed before each face; subjects judged whether the person liked that vegetable. And the amygdala didn’t respond to other-race faces.&lt;/p&gt;
&lt;p&gt;Why? You look at the Them, thinking about what food she’d like. You picture her shopping, or ordering a meal in a restaurant. Best case scenario, you decide you and she share some vegetable preference—a smidgen of Us-ness. Worst case, you decide you two differ, a relatively benign Them—history is not stained with blood spilled by animosities between partisans for broccoli versus cauliflower. Most importantly, as you imagine her sitting at dinner, enjoying that food, you are thinking of her as an &lt;em&gt;individual&lt;/em&gt;, the surest way to weaken automatic categorization of someone as a Them.&lt;/p&gt;
&lt;p&gt;Rapid recategorizations can occur in the most brutal, unlikely, and intensely poignant circumstances:&lt;/p&gt;
&lt;p&gt;In the Battle of Gettysburg, Confederate general Lewis Armistead was mortally wounded. As he lay on the battlefield, he gave a secret Masonic sign, hoping it would be recognized by a fellow Mason. It was, by Union officer Hiram Bingham, who protected him, and got him to a Union field hospital. In an instant the Us/Them of Union/Confederate faded before Mason/non-Mason.&lt;/p&gt;
&lt;p&gt;During World War II, British commandos kidnapped German general Heinrich Kreipe in Crete, followed by a dangerous 18-day march to the coast to rendezvous with a British ship. One day the party saw the snows of Crete’s highest peak. Kreipe mumbled to himself the first line (in Latin) of an ode by Horace about a snowcapped mountain. At which point the British commander, Patrick Leigh Fermor, continued the recitation. The two men realized that they had, in Leigh Fermor’s words, “drunk at the same fountains.” A recategorization. Leigh Fermor had Kreipe’s wounds treated and personally ensured his safety. The two stayed in touch after the war and were reunited decades later on Greek television. “No hard feelings,” said Kreipe, praising their “daring operation.”&lt;/p&gt;
&lt;p&gt;And finally there is the World War I Christmas truce, where opposing trench soldiers spent the day singing, praying, and partying together, playing soccer, and exchanging gifts, where soldiers up and down the lines struggled to extend the truce. It took all of one day for British-versus-German to yield to something more important—&lt;em&gt;all&lt;/em&gt; of us in the trenches versus the officers in the rear who want us to kill each other.&lt;/p&gt;
&lt;p&gt;We all have multiple dichotomies in our heads, and ones that seem inevitable and crucial can, under the right circumstances, evaporate in an instant.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Lessening the Impact of Us/Them-ing&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;So how can we &lt;em&gt;make&lt;/em&gt; these dichotomies evaporate? Some thoughts:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Contact&lt;/em&gt;: The consequences of growing up amid diversity just discussed bring us to the effects of prolonged contact on Us/Theming. In the 1950s the psychologist Gordon Allport proposed “contact theory.” Inaccurate version: bring Us-es and Thems together (say, teenagers from two hostile nations in a summer camp), animosities disappear, similarities start to outweigh differences, everyone becomes an Us. More accurate version: put Us and Thems together under narrow circumstances and something sort of resembling that happens, but you can also blow it and worsen things.&lt;/p&gt;
&lt;p&gt;Some of the effective narrower circumstances: each side has roughly equal numbers; everyone’s treated equally and unambiguously; contact is lengthy and on neutral territory; there are “superordinate” goals where everyone works together on a meaningful task (say, summer campers turning a meadow into a soccer field).&lt;/p&gt;
&lt;p&gt;Even then, effects are typically limited—Us-es and Thems quickly lose touch, changes are transient and often specific—“I hate those Thems, but I know one from last summer who’s actually a good guy.” Where contact really causes fundamental change is when it is prolonged. Then we’re making progress.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Approaching the implicit&lt;/em&gt;: If you want to lessen an implicit Us/Them response, one good way is priming beforehand with a counter-stereotype (e.g., a reminder of a beloved celebrity Them). Another approach is making the implicit explicit—show people their implicit biases. Another is a powerful cognitive tool—perspective taking. Pretend you’re a Them and explain your grievances. How would you feel? Would your feet hurt after walking a mile in their shoes?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Replace essentialism with individuation&lt;/em&gt;: In one study, white subjects were asked about their acceptance of racial inequalities. Half were first primed toward essentialist thinking, being told, “Scientists pinpoint the genetic underpinnings of race.” Half heard an anti-essentialist prime—“Scientists reveal that race has no genetic basis.” The latter made subjects less accepting of inequalities.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Flatten hierarchies&lt;/em&gt;: Steep ones sharpen Us/Them differences, as those on top justify their status by denigrating the have-nots, while the latter view the ruling class as low warmth/high competence. For example, the cultural trope that the poor are more carefree, in touch with and able to enjoy life’s simple pleasures while the rich are unhappy, stressed, and burdened with responsibility (think of miserable Scrooge and those happy-go-lucky Cratchits). Likewise with the “they’re poor but loving” myth of framing the poor as high warmth/low competence. In one study of 37 countries, the greater the income inequality, the more the wealthy held such attitudes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Some Conclusions&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;From massive barbarity to pinpricks of microaggression, Us versus Them has produced oceans of pain. Yet, I don’t think our goal should be to “cure” us of all Us/Them dichotomizing (separate of it being impossible, unless you have no amygdala).&lt;/p&gt;
&lt;p&gt;I’m fairly solitary—I’ve spent a lot of my life living alone in a tent in Africa, studying another species. Yet some of my most exquisitely happy moments have come from feeling like an Us, feeling accepted, safe, and not alone, feeling part of something large and enveloping, with a sense of being on the right side and doing both well and good. There are even Us/Thems that I—eggheady, meek, and amorphously pacifistic—would kill or die for.&lt;/p&gt;
&lt;p&gt;If we accept that there will always be sides, it’s challenging to always be on the side of angels. Distrust essentialism. Remember that supposed rationality is often just rationalization, playing catch-up with subterranean forces we never suspect. Focus on shared goals. Practice perspective taking. Individuate, individuate, individuate. And recall how often, historically, the truly malignant Thems hid themselves while making third parties the fall guy.&lt;/p&gt;
&lt;p&gt;Meanwhile, give the right-of-way to people driving cars with the “Mean people suck” bumper sticker, and remind everyone that we’re in this together against Lord Voldemort and House Slytherin.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Robert Sapolsky is a professor of biology, neurology, and neurosurgery at Stanford University, and author of&lt;/em&gt; A Primate’s Memoir, Why Zebras Don’t Get Ulcers, &lt;em&gt;and&lt;/em&gt; Behave: The Biology of Humans at Our Best and Worst, &lt;em&gt;his newest book.&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;From&lt;/em&gt; Behave: The Biology of Humans at Our Best and Worst &lt;em&gt;by Robert M. Sapolsky, published on May 2, 2017 by Penguin Press, an imprint of Penguin Publishing Group, a division of Penguin Random House, LLC. Copyright © 2017 by Robert M. Sapolsky.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This article was originally published in our “The Absurd” issue in June, 2017.&lt;/em&gt;&lt;/p&gt;
&lt;section class=&quot;leaderboard-ad-belt&quot;&gt;&lt;div class=&quot;leaderboard-ad-belt-inner adarticle&quot;&gt;&lt;div id=&quot;div-gpt-ad-1380044019755-0&quot; class=&quot;leaderboard-ad&quot;/&gt;
&lt;/div&gt;
&lt;/section&gt;</description>
<pubDate>Fri, 15 Dec 2017 19:06:57 +0000</pubDate>
<dc:creator>dnetesn</dc:creator>
<og:type>website</og:type>
<og:url>http://nautil.us/issue/55/trust/why-your-brain-hates-other-people-rp</og:url>
<og:title>Why Your Brain Hates Other People - Issue 55: Trust - Nautilus</og:title>
<og:description>As a kid, I saw the 1968 version of Planet of the Apes. As a future primatologist, I was mesmerized. Years later I discovered an anecdote&amp;#8230;</og:description>
<og:image>http://static.nautil.us/12544_f4984314d122393d8dee3c843cbd16d7.png</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>http://nautil.us/issue/55/trust/why-your-brain-hates-other-people-rp</dc:identifier>
</item>
<item>
<title>Ask HN: Writing cover letters for tech jobs</title>
<link>https://news.ycombinator.com/item?id=15934135</link>
<guid isPermaLink="true" >https://news.ycombinator.com/item?id=15934135</guid>
<description>&lt;tr readability=&quot;0.55737704918033&quot;&gt;&lt;td bgcolor=&quot;#FF6600&quot;&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;7.9163498098859&quot;&gt;&lt;td&gt;
&lt;table class=&quot;fatitem&quot; border=&quot;0&quot; readability=&quot;5.7173637515843&quot;&gt;&lt;tr class=&quot;athing&quot; id=&quot;15934135&quot; readability=&quot;0&quot;&gt;&lt;td align=&quot;right&quot; valign=&quot;top&quot; class=&quot;title&quot;/&gt;
&lt;td valign=&quot;top&quot; class=&quot;votelinks&quot;&gt;
&lt;center&gt;

&lt;/center&gt;
&lt;/td&gt;
&lt;td class=&quot;title&quot;&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=15934135&quot; class=&quot;storylink&quot;&gt;Ask HN: Writing cover letters for tech jobs&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;0.73170731707317&quot;&gt;&lt;td colspan=&quot;2&quot;/&gt;
&lt;td class=&quot;subtext&quot;&gt;&lt;span class=&quot;score&quot; id=&quot;score_15934135&quot;&gt;212 points&lt;/span&gt; by &lt;a href=&quot;https://news.ycombinator.com/user?id=scabarott&quot; class=&quot;hnuser&quot;&gt;scabarott&lt;/a&gt; &lt;span class=&quot;age&quot;&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=15934135&quot;&gt;21 hours ago&lt;/a&gt;&lt;/span&gt; &lt;span id=&quot;unv_15934135&quot;/&gt; | &lt;a href=&quot;https://news.ycombinator.com/hide?id=15934135&amp;amp;goto=item%3Fid%3D15934135&quot;&gt;hide&lt;/a&gt; | &lt;a href=&quot;https://hn.algolia.com/?query=Ask%20HN%3A%20Writing%20cover%20letters%20for%20tech%20jobs&amp;amp;sort=byDate&amp;amp;dateRange=all&amp;amp;type=story&amp;amp;storyText=false&amp;amp;prefix&amp;amp;page=0&quot; class=&quot;hnpast&quot;&gt;past&lt;/a&gt; | &lt;a href=&quot;https://www.google.com/search?q=Ask%20HN%3A%20Writing%20cover%20letters%20for%20tech%20jobs&quot;&gt;web&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/fave?id=15934135&amp;amp;auth=8e9f377cd3b616d21c52c7ce00555b41766477df&quot;&gt;favorite&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/item?id=15934135&quot;&gt;97 comments&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td/&gt;
&lt;/tr&gt;&lt;tr readability=&quot;9&quot;&gt;&lt;td colspan=&quot;2&quot;/&gt;
&lt;td&gt;I really hate writing cover letters as I never know what to write or if anyone is even going to read them. I see a lot of sites offering advice on how to write generic cover letters, but most all of them don’t seem appropriate (at least to me) for tech jobs - more for formal sales, business jobs. I'm interested to know what HN’ers with experience on either or both sides have to say by way of advice - What do you usually write/expect, is it even really a requirement?. Do you attach a separate document or just write an informal email. What tone do you take - formal, familiar. Do you summarize your skills experience or just include a link to Github etc.&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td/&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot;/&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;1.0096153846154&quot;&gt;&lt;td&gt;&lt;img src=&quot;https://news.ycombinator.com/s.gif&quot; height=&quot;10&quot; width=&quot;0&quot;/&gt;&lt;br/&gt;&lt;center&gt;&lt;span class=&quot;yclinks&quot;&gt;&lt;a href=&quot;https://news.ycombinator.com/newsguidelines.html&quot;&gt;Guidelines&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/newsfaq.html&quot;&gt;FAQ&lt;/a&gt; | &lt;a href=&quot;mailto:hn@ycombinator.com&quot;&gt;Support&lt;/a&gt; | &lt;a href=&quot;https://github.com/HackerNews/API&quot;&gt;API&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/security.html&quot;&gt;Security&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/lists&quot;&gt;Lists&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/bookmarklet.html&quot; rel=&quot;nofollow&quot;&gt;Bookmarklet&lt;/a&gt; | &lt;a href=&quot;https://news.ycombinator.com/dmca.html&quot;&gt;DMCA&lt;/a&gt; | &lt;a href=&quot;http://www.ycombinator.com/apply/&quot;&gt;Apply to YC&lt;/a&gt; | &lt;a href=&quot;mailto:hn@ycombinator.com&quot;&gt;Contact&lt;/a&gt;&lt;/span&gt;
&lt;/center&gt;
&lt;/td&gt;
&lt;/tr&gt;</description>
<pubDate>Fri, 15 Dec 2017 18:59:50 +0000</pubDate>
<dc:creator>scabarott</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://news.ycombinator.com/item?id=15934135</dc:identifier>
</item>
<item>
<title>Unknown Mozilla dev addon &quot;Looking Glass 1.0.3&quot; on browser</title>
<link>https://support.mozilla.org/en-US/questions/1194583</link>
<guid isPermaLink="true" >https://support.mozilla.org/en-US/questions/1194583</guid>
<description>&lt;div itemprop=&quot;text&quot; readability=&quot;25.422077922078&quot;&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;pre&gt;
     &quot;name&quot;: &quot;Looking Glass&quot;,
     &quot;version&quot;: &quot;1.0.3&quot;,
     &quot;isActive&quot;: false,
     &quot;id&quot;: &quot;pug.experience@shield.mozilla.org&quot;
&lt;/pre&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;Addon info reads: Looking Glass version 1.0.3 MY REALITY IS JUST FIFFERENT FROM YOURS Created By: PUG Experience Group(Gregg Lind, Bianca Danforth, Kamyar Ardekani, Matt Grimes Diana Livits, Jeffrey Kaufman and others) &amp;lt;glind at &lt;a href=&quot;http://mozilla.com&quot; rel=&quot;nofollow&quot;&gt;mozilla.com&lt;/a&gt;&amp;gt;&lt;/p&gt;
&lt;p&gt;I did not remember installing this addon, I would not knowingly install it. Firefox, Antivirus and OS are all up-to-date. Any explanations welcomme because I can't find any reference online.&lt;/p&gt;
&lt;p&gt;Screenshot isn't being uploaded, external link: &lt;a href=&quot;https://imgur.com/RDZf6Z0&quot; rel=&quot;nofollow&quot;&gt;https://imgur.com/RDZf6Z0&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;{ &quot;name&quot;: &quot;Looking Glass&quot;, &quot;version&quot;: &quot;1.0.3&quot;, &quot;isActive&quot;: false, &quot;id&quot;: &quot;pug.experience@shield.mozilla.org&quot; } Addon info reads: Looking Glass version 1.0.3 MY REALITY IS JUST FIFFERENT FROM YOURS Created By: PUG Experience Group(Gregg Lind, Bianca Danforth, Kamyar Ardekani, Matt Grimes Diana Livits, Jeffrey Kaufman and others) &amp;lt;glind at mozilla.com&amp;gt; I did not remember installing this addon, I would not knowingly install it. Firefox, Antivirus and OS are all up-to-date. Any explanations welcomme because I can't find any reference online. Screenshot isn't being uploaded, external link: https://imgur.com/RDZf6Z0&lt;/p&gt;
&lt;p class=&quot;edited&quot;&gt;Modified &lt;time datetime=&quot;2017-12-15T09:56:57-08:00&quot;&gt;December 15, 2017 at 9:56:57 AM PST&lt;/time&gt; by James&lt;/p&gt;
&lt;div class=&quot;solution&quot; readability=&quot;7.5419847328244&quot;&gt;
&lt;h3 title=&quot;Solution chosen by warah&quot;&gt;Chosen solution&lt;/h3&gt;

&lt;/div&gt;
</description>
<pubDate>Fri, 15 Dec 2017 13:47:26 +0000</pubDate>
<dc:creator>shak77</dc:creator>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://support.mozilla.org/en-US/questions/1194583</dc:identifier>
</item>
<item>
<title>Metal Gear Solid V – Graphics Study</title>
<link>http://www.adriancourreges.com/blog/2017/12/15/mgs-v-graphics-study/</link>
<guid isPermaLink="true" >http://www.adriancourreges.com/blog/2017/12/15/mgs-v-graphics-study/</guid>
<description>&lt;p&gt;&lt;img class=&quot;right&quot; src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/logo.jpg&quot; width=&quot;420&quot;/&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/Metal_Gear&quot;&gt;&lt;em&gt;Metal Gear&lt;/em&gt;&lt;/a&gt; series achieved world-wide recognition when &lt;a href=&quot;https://en.wikipedia.org/wiki/Metal_Gear_Solid&quot;&gt;&lt;em&gt;Metal Gear Solid&lt;/em&gt;&lt;/a&gt; became a best-seller on the original &lt;a href=&quot;https://en.wikipedia.org/wiki/PlayStation_(console)&quot;&gt;PlayStation&lt;/a&gt; almost two decades ago. The title introduced many players to the genre of “tactical espionage action”, an expression coined by &lt;a href=&quot;https://en.wikipedia.org/wiki/Hideo_Kojima&quot;&gt;Hideo Kojima&lt;/a&gt; the creator of the franchise.&lt;/p&gt;
&lt;p&gt;Though in my case the first time I played as &lt;a href=&quot;http://metalgear.wikia.com/wiki/Big_Boss&quot;&gt;&lt;em&gt;Snake&lt;/em&gt;&lt;/a&gt; wasn’t with this game but with the &lt;a href=&quot;https://en.wikipedia.org/wiki/Metal_Gear:_Ghost_Babel&quot;&gt;&lt;em&gt;Ghost Babel&lt;/em&gt;&lt;/a&gt; spin-off on &lt;a href=&quot;https://en.wikipedia.org/wiki/Game_Boy_Color&quot;&gt;GBC&lt;/a&gt;, a lesser-known but nevertheless excellent title with an impressive depth.&lt;/p&gt;
&lt;p&gt;The final chapter &lt;a href=&quot;https://en.wikipedia.org/wiki/Metal_Gear_Solid_V:_The_Phantom_Pain&quot;&gt;&lt;em&gt;Metal Gear Solid V: The Phantom Pain&lt;/em&gt;&lt;/a&gt; was released in 2015 and brings the series to a whole new level of graphics quality thanks to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Fox_Engine&quot;&gt;Fox Engine&lt;/a&gt; developed by &lt;a href=&quot;https://en.wikipedia.org/wiki/Kojima_Productions&quot;&gt;Kojima Productions&lt;/a&gt;. The analysis below is based on the PC version of the game with all the quality knobs set to maximum. Some of the information I present here has already been made public in the GDC 2013 session &lt;a href=&quot;https://www.gdcvault.com/play/1018086/Photorealism-Through-the-Eyes-of&quot;&gt;“Photorealism Through the Eyes of a FOX”&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here is a frame taken from the very beginning of the game, during the prologue when &lt;em&gt;Snake&lt;/em&gt; tries to make his way out of the hospital. &lt;em&gt;Snake&lt;/em&gt; is lying on the floor trying to blend in among the other corpses, he’s at the bottom of the screen with his naked shoulder. Not the most glamorous scene but it illustrates well the different effects the engine can achieve.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;center&quot; src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/99_final.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Right in front of &lt;em&gt;Snake&lt;/em&gt; two soldiers are standing up, they’re looking at some burning silhouette at the end of the hallway. I’ll simply refer to that mysterious individual as the “Man on Fire” not to spoil anything about the story.&lt;/p&gt;
&lt;p&gt;So let’s see how this frame is rendered!&lt;/p&gt;
&lt;h3&gt;Depth Pre-Pass&lt;/h3&gt;
&lt;p&gt;This pass renders only the geometry of the terrain underneath the hospital as viewed from the point of view of the player and outputs its depth information to a depth buffer. The terrain mesh is generated from the &lt;a href=&quot;http://en.wikipedia.org/wiki/Heightmap&quot;&gt;heightmap&lt;/a&gt; you can see below: it’s a 16-bit floating point texture containing the terrain elevation value (view from the top). The engine divides the heightmap into different tiles, for each tile a draw call is dispatched with a flat grid of 16x16 vertices. The vertex shader reads the heightmap and modifies on-the-fly the vertex position to match the elevation value. The terrain is rasterized in about 150 draw calls.&lt;/p&gt;
&lt;h3&gt;G-Buffer Generation&lt;/h3&gt;
&lt;p&gt;MGS V uses a &lt;a href=&quot;https://en.wikipedia.org/wiki/Deferred_shading&quot;&gt;deferred renderer&lt;/a&gt; like many games of its generation, if you already read the &lt;a href=&quot;http://www.adriancourreges.com/blog/2015/11/02/gta-v-graphics-study/&quot;&gt;GTA V study&lt;/a&gt; you will notice several similar elements. So instead of calculating directly the final lighting value of each pixel as the scene is rendered, the engine first stores the properties of each pixels (like albedo colors, normals…) in several render targets called &lt;abbr title=&quot;Geometry Buffer&quot;&gt;&lt;em&gt;G-Buffer&lt;/em&gt;&lt;/abbr&gt; and will later combine all this information together.&lt;/p&gt;
&lt;p&gt;All the following buffers are generated at the same time:&lt;/p&gt;

&lt;p&gt;Here we have a relatively light G-Buffer with 3 render targets in &lt;abbr title=&quot;Blue, Red, Green, Alpha, 8 bits each&quot;&gt;B8G8R8A8&lt;/abbr&gt; format:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Albedo map&lt;/strong&gt;: the RGB channels contain the diffuse albedo color of the meshes, the intrinsic color when no lighting is applied. The alpha channel contains the opacity / light “transmittance” value of the material (typically 1 for completely opaque objects, and 0 for grass or foliage).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Normal map&lt;/strong&gt;: the normal vector (x, y, z) of the pixel is stored in the RGB channels. The alpha channel contains the coefficient for the &lt;a href=&quot;https://youtu.be/0qhPoT4coOI?t=43m31s&quot;&gt;view-dependent roughness&lt;/a&gt; of certain materials.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Specular map&lt;/strong&gt;:
&lt;ul&gt;&lt;li&gt;Red: roughness&lt;/li&gt;
&lt;li&gt;Green: specular&lt;/li&gt;
&lt;li&gt;Blue: material ID&lt;/li&gt;
&lt;li&gt;Alpha: translucency for the &lt;a href=&quot;https://en.wikipedia.org/wiki/Subsurface_scattering&quot;&gt;sub-surface scattering&lt;/a&gt; (only skin and hair materials seem concerned here)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Depth map&lt;/strong&gt;: a 32-bit float representing the depth of the pixel. The depth is also reversed (value of 1 for meshes close to the camera) in order to keep a high floating-point precision for meshes far away and avoid &lt;a href=&quot;https://en.wikipedia.org/wiki/Z-fighting&quot;&gt;Z-fight&lt;/a&gt;. It’s important for open-world games where the draw distance can be very high.&lt;/li&gt;
&lt;/ul&gt;&lt;div&gt;&lt;img class=&quot;forceBorderFill&quot; src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/04_gbuffer_format.png&quot;/&gt;&lt;/div&gt;
&lt;p&gt;The G-Buffer rendering was done in the following order: first all the opaque meshes of the main scene (characters, hospital building…), then all the terrain (again) and finally the decals.&lt;/p&gt;
&lt;p&gt;This is where the depth pre-pass proved useful: it made the second step (terrain rendering) extremely fast. Any terrain pixel which is occluded by another mesh won’t have the expected depth predicted by the depth pre-pass, in which case it can be safely discarded immediately without having to fetch any terrain-related textures and writing back that data to the G-Buffer.&lt;/p&gt;
&lt;h3&gt;Velocity Map&lt;/h3&gt;
&lt;p&gt;To apply a &lt;a href=&quot;https://en.wikipedia.org/wiki/Motion_blur&quot;&gt;motion blur&lt;/a&gt; effect as a post-process it’s necessary to know the velocity of each pixel on the screen.&lt;br/&gt;If the scene is entirely static, it’s fairly easy to know each point velocity: it can be deduced from its depth and the difference of the projection matrix between the previous frame and the current frame. But it gets more tricky when there are dynamic objects like some characters who can run around, they can move independently from the camera.&lt;br/&gt;This is where a velocity map comes into play: it stores the motion vectors (velocity) of each pixel of the current frame.&lt;/p&gt;
&lt;div class=&quot;table-carousel&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/05_velocity_dyn.png&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Velocity Map (Dynamic Meshes)&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;First the engine generates a velocity map only for the dynamic meshes like you see on the right.&lt;/p&gt;
&lt;p&gt;Now you’ll notice in this particular scene only the &lt;em&gt;Man on Fire&lt;/em&gt; is considered as a dynamic mesh. Even if &lt;em&gt;Snake&lt;/em&gt; and the soldiers are not static meshes technically, the engine treats them as such, which is acceptable in this case because they’re barely moving. By doing so the engine can avoid some computation: animated characters need to be vertex-skinned twice (previous and current pose) to calculate their velocity and it can be costly.&lt;br/&gt;The red channel acts like a mask (set to 1 where the character is drawn), the actual velocity vector is written into the blue and alpha channels. The &lt;em&gt;Man on Fire&lt;/em&gt; isn’t moving so we have a dynamic velocity of (0, 0).&lt;/p&gt;
&lt;p&gt;Next the engine computes the static geometry velocity from the current depth buffer and the last two projection matrices and composites on the top the dynamic velocity map using the red channel as a blending factor.&lt;br/&gt;This is the final velocity map (static and dynamic):&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/05_velocity_fin.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Velocity Map (Static + Dynamic)&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Don’t pay too much attention to the noise, there’s actually barely any movement in this scene: the camera is slowly zooming in on the &lt;em&gt;Man on Fire&lt;/em&gt;, all the pixels have an almost null velocity, what you see are rounding precision errors when the components are written to 8-bit channels. I simply boosted the colors to make the image more readable, I also swapped the green and alpha channels, the actual buffer stores the velocity in the blue and alpha channels.&lt;/p&gt;
&lt;h3&gt;Screen Space Ambient Occlusion&lt;/h3&gt;
&lt;p&gt;The &lt;a href=&quot;http://en.wikipedia.org/wiki/Screen_space_ambient_occlusion&quot;&gt;SSAO&lt;/a&gt; effect is supposed to add some darkening in areas with less ambient lighting, typically narrow holes or creases. Interestingly the Fox Engine performs two distinct passes of SSAO using different algorithms and combines the results with a final pass.&lt;/p&gt;
&lt;h4&gt;Line Integral SSAO&lt;/h4&gt;
&lt;p&gt;Line Integral SSAO is the ambient occlusion technique &lt;a href=&quot;https://en.wikipedia.org/wiki/Avalanche_Software&quot;&gt;Avalanche Software&lt;/a&gt; used in Disney’s &lt;a href=&quot;https://en.wikipedia.org/wiki/Toy_Story_3:_The_Video_Game&quot;&gt;Toy Story 3 game&lt;/a&gt;.&lt;br/&gt;Despite its daunting name, the algorithm itself is relatively easy to grasp and very well explained in this &lt;a href=&quot;http://advances.realtimerendering.com/s2010/Ownby,Hall%20and%20Hall%20-%20Toystory3%20(SIGGRAPH%202010%20Advanced%20RealTime%20Rendering%20Course).pdf&quot;&gt;2010 Siggraph talk&lt;/a&gt;: for each pixel of the scene, a sphere centered on that pixel is considered, this spherical volume is then sub-divided into several “line-shaped” sub-volumes. The occlusion factor of each sub-volume is calculated by performing a single tap in the depth map, the total occlusion factor of the sphere is then simply a weighted-sum of each sub-volume’s factor.&lt;br/&gt;Here the Fox Engine uses 2 pairs of symmetric samples, so a total of 5 taps per pixel if we include the original sample.&lt;/p&gt;
&lt;table class=&quot;table-carousel&quot;&gt;&lt;tr&gt;&lt;td&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/06_liao_rgb.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;RGB: Linear Depth&lt;/div&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/06_liao_alpha.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Alpha: LISSAO&lt;/div&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;The calculation is performed at half-resolution and stored in a RGBA8 texture, with alpha containing the actual ambient occlusion result and RGB containing the linear depth value (it’s a Float-to-RGB encoding, similar to &lt;a href=&quot;https://aras-p.info/blog/2009/07/30/encoding-floats-to-rgba-the-final/&quot;&gt;this technique&lt;/a&gt;).&lt;br/&gt;The result in alpha is actually noisy due to a low number of samples, this SSAO map will be smoothed-out later with a depth-aware blur, having the linear depth in the RGB channels means all the necessary data can be retrieved in a single tap.&lt;/p&gt;
&lt;h4&gt;Scalable Ambient Obscurance&lt;/h4&gt;
&lt;div class=&quot;table-carousel&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/07_sao.jpg&quot;/&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The second SSAO pass uses a variation of the &lt;a href=&quot;http://research.nvidia.com/publication/scalable-ambient-obscurance&quot;&gt;Scalable Ambient Obscurance&lt;/a&gt; technique.&lt;/p&gt;
&lt;p&gt;It differs from the “official” SAO in the way that it does not rely on some depth mip levels and doesn’t reconstruct the normal, it reads directly the normal map and works at half-resolution, performs 11 taps per pixel (though with a different strategy for sample locations).&lt;br/&gt;It uses exactly the same medium contrast filtering and bilateral box-filter as the original SAO implementation.&lt;/p&gt;
&lt;p&gt;Notice that the SAO parameters were tuned so that high-frequency variations (like on the soldier’s legs) really stand out compared to the LISSAO version.&lt;/p&gt;
&lt;p&gt;In a similar way as the LISSAO, the SAO map is blurred with 2 depth-aware lateral passes.&lt;br/&gt;Then a compute shader combines the LISSAO and SAO images together to produce the final SSAO result:&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/08_ssao.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Final SSAO&lt;/div&gt;
&lt;/div&gt;
&lt;h3&gt;Irradiance Spherical Maps&lt;/h3&gt;
&lt;p&gt;To deal with &lt;a href=&quot;https://en.wikipedia.org/wiki/Global_illumination&quot;&gt;global illumination&lt;/a&gt; the Fox Engine relies on local irradiance &lt;a href=&quot;https://en.wikipedia.org/wiki/Sphere_mapping&quot;&gt;spherical maps&lt;/a&gt;: different areas are defined in the level and for each of these areas one spherical map approximates the irradiance coming from different directions.&lt;/p&gt;
&lt;div class=&quot;table-carousel&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/09_sh_maps.png&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Irradiance Spherical Maps&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This step generates all the spherical maps which are used in this scene, one by one, and stores each into a 16x16 tile of an HDR texture atlas. This is this texture atlas you can see on the left: the disk in the middle of each tile is roughly what a metallic sphere would reflect if it was placed in the middle of the irradiance zone it represents.&lt;/p&gt;
&lt;p&gt;So how were these spherical maps generated? They are computed from &lt;a href=&quot;http://silviojemma.com/public/papers/lighting/spherical-harmonic-lighting.pdf&quot;&gt;spherical harmonics&lt;/a&gt;. The mathematics behind it can be scary but spherical harmonics are just a way to encode the value of a 360° signal into a set of coefficient, typically 9 coefficients provide a good-enough precision (2nd order &lt;abbr title=&quot;Spherical Harmonics&quot;&gt;SH&lt;/abbr&gt;). And just from these 9 numbers you can roughly reconstruct the signal value in any direction.&lt;br/&gt;If you’re familiar with the concept of how a &lt;a href=&quot;https://en.wikipedia.org/wiki/Fourier_transform&quot;&gt;Fourier transform&lt;/a&gt; can break a signal into component sine waves it’s a bit similar except here we’re decomposing the signal into functions on the surface of a sphere.&lt;/p&gt;
&lt;p&gt;Where do these coefficients come from? They’re calculated offline, my guess is that the environment of each area marked by the level designers is captured into a cubemap. It is then converted to an irradiance cubemap and &lt;a href=&quot;http://graphics.stanford.edu/papers/envmap/envmap.pdf&quot;&gt;encoded into spherical harmonics coefficients&lt;/a&gt; that will be fetched by the engine at runtime.&lt;/p&gt;
&lt;p&gt;So you might wonder why cubemaps are not used directly to represent the irradiance. It would work, you could use irradiance cubemaps but they have drawbacks, the main one being the memory waste of storing the 6 faces of a cubemap whereas spherical harmonics bring down the cost to just 9 RGB numbers per map. It saves a lot of memory space and bandwidth on the GPU which is important when you’re dealing with dozens of maps in the scene.&lt;/p&gt;
&lt;p&gt;All these spherical maps are generated every frame from the offline-baked spherical harmonic coefficients and the player’s current camera position and orientation.&lt;/p&gt;
&lt;h3&gt;Diffuse Lighting (Global Illumination)&lt;/h3&gt;
&lt;p&gt;Time to use all these irradiance maps we generated! Each zone affected by an irradiance map is sent to the GPU for rasterization. Typically each draw call (one per irradiance map) sends a bounding-box-shaped mesh representing the volume of influence in the world, the idea is just to be able to touch all the pixels which are supposed to receive some influence from this particular irradiance map.&lt;br/&gt;The diffuse map is computed in a half-resolution HDR texture, reading from the normal, depth and irradiance map.&lt;/p&gt;
&lt;p&gt;The process is repeated for each irradiance map, with additive blending of the new fragments on the top of the old ones.&lt;/p&gt;
&lt;p&gt;After all the lighting contributed by the global illumination has been accumulated into this diffuse buffer, it gets upscaled from half to full resolution. Note that the upscaling isn’t a naive &lt;a href=&quot;https://en.wikipedia.org/wiki/Bilinear_filtering&quot;&gt;bilinear-filtering&lt;/a&gt; though, it’s a &lt;a href=&quot;https://en.wikipedia.org/wiki/Bilateral_filter&quot;&gt;bilateral upscale&lt;/a&gt; which reads the half-resolution buffer and also, more importantly, the original full-resolution depth map (to attribute weights to neighbor color pixels) so the final result still has crisp edges around the mesh borders. Visually it almost looks like we’ve been rendering at full-resolution the whole time!&lt;/p&gt;
&lt;table class=&quot;table-carousel&quot;&gt;&lt;tr&gt;&lt;td&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/11_up_nearest.png&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;2x Upscale (No Filtering)&lt;/div&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/11_up_linear.png&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;2x Bilinear Upscale&lt;/div&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/11_up_bilateral.png&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;2x Bilateral Upscale&lt;/div&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;h3&gt;Non-Shadow-Casting Lights&lt;/h3&gt;
&lt;p&gt;After all this static diffuse lighting from the global illumination, now is time to add some dynamic lighting contributed by point lights and spot lights. We are working at full resolution and render one by one a volume of influence for each light of the scene, for now only the lights which don’t cast any shadow are rendered:&lt;/p&gt;
&lt;div id=&quot;12_nonshadow_diffuse&quot;&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/12_nonshadow_diffuse_1.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Diffuse Lighting: 5%&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/12_nonshadow_diffuse_2.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Diffuse Lighting: 30%&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/12_nonshadow_diffuse_3.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Diffuse Lighting: 60%&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/12_nonshadow_diffuse_4.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Diffuse Lighting: 100%&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Actually at the same time the diffuse lighting buffer was being updated, another render target also HDR full-resolution was being rendered too: the specular lighting buffer. Each light draw call you saw above was writing to the diffuse and specular buffer simultaneously.&lt;/p&gt;
&lt;div id=&quot;12_nonshadow_specular&quot;&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/12_nonshadow_specular_1.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Specular Lighting: 5%&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/12_nonshadow_specular_2.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Specular Lighting: 30%&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/12_nonshadow_specular_3.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Specular Lighting: 60%&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/12_nonshadow_specular_4.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Specular Lighting: 100%&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3&gt;Shadow Maps&lt;/h3&gt;
&lt;p&gt;You can guess what’s coming after the non-shadow-casting lights: the shadow-casting lights!&lt;br/&gt;These lights are much more expensive so their number is usually quite limited in games, the reason they’re costly is that they require a &lt;a href=&quot;https://en.wikipedia.org/wiki/Shadow_mapping&quot;&gt;shadow map&lt;/a&gt; generation each. It basically means rendering the scene again from the point of view of each light.&lt;br/&gt;Here we have 2 spot-lights in the hallway ceiling casting light downward, a 4k x 4k shadow map is generated for each.&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/13_shadowmap.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;2 Shadow Maps&lt;/div&gt;
&lt;/div&gt;
&lt;h3&gt;Shadow-Casting Lights&lt;/h3&gt;
&lt;p&gt;Now that the shadow maps have been generated, the lighting of the 2 ceiling spot-lights is computed. Both the diffuse and specular buffers are updated at the same time. Finally the sunlight is applied (from a spherical harmonics sphere map previously generated).&lt;/p&gt;

&lt;h3&gt;Lighting Combination and Tonemap&lt;/h3&gt;
&lt;p&gt;This step combines together all the buffers we’ve generated: the albedo color is multiplied by the diffuse lighting, to which the specular is added. The color is then multiplied by the SSAO value and the result is interpolated with the fog color (which is itself derived from a fog look-up texture and the current pixel’s depth). Finally the &lt;a href=&quot;(https://en.wikipedia.org/wiki/Tone_mapping&quot;&gt;tonemapping&lt;/a&gt; is applied to convert from an &lt;abbr title=&quot;High Dynamic Range&quot;&gt;HDR&lt;/abbr&gt; space to a &lt;abbr title=&quot;Low Dynamic Range. 8-bits per channel.&quot;&gt;LDR&lt;/abbr&gt; space. The alpha channel stores some additional information: each pixel’s original HDR &lt;a href=&quot;https://en.wikipedia.org/wiki/Luminance&quot;&gt;luminance&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;img-nobox&quot; src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/15_combine.png&quot;/&gt;&lt;/p&gt;

&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/16_light_combine.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Lighting Combination&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Which tonemapper is used in MGS V by the way? It’s completely linear between 0 and a certain threshold (0.6) and returns the original channel value, then above the threshold it slowly grows to an horizontal asymptote.&lt;br/&gt;Here is the function applied to each RGB channel, with $math$ \text{$A = 0.6$} $math$ and $math$ \text{$B = 0.45333$} $math$ :&lt;/p&gt;
&lt;p class=&quot;mathframe&quot;&gt;$math$ ToneMap(x) = \begin{cases} x &amp;amp; \text{if $x \le A$} \\[2ex] min\left( \text{1 , } A + B - \large{\frac{\text{$B$ ²}}{x - A + B}}\right) &amp;amp; \text{if $x \gt A$} \end{cases} $math$&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;left highlight&quot; src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/17_tmcurve.png&quot; width=&quot;373&quot;/&gt;&lt;/p&gt;

&lt;p&gt;So the tone-mapping was applied as well as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Gamma_correction&quot;&gt;gamma correction&lt;/a&gt; to go from a linear space to sRGB space. In other games it often means we’ve reached the final steps of the frame rendering.&lt;br/&gt;Are we done here too? Not at all, we’re just getting started! Interestingly the Fox Engine performs tone-mapping quite early and continues its work in LDR space, including passes for transparent objects, reflections, depth of field…&lt;/p&gt;
&lt;h3&gt;Emissive and Transparent Objects&lt;/h3&gt;
&lt;p&gt;In this pass the engine draws all the objects with an emissive property like the green “Exit” sign or the incandescent flame spots on the &lt;em&gt;Man on Fire&lt;/em&gt;. It also draws transparent objects like glass.&lt;/p&gt;
&lt;div id=&quot;18_transparent&quot;&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/16_light_combine.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Emissive &amp;amp; Transparent: Before&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/18_transparent.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Emissive &amp;amp; Transparent: After&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;It’s not really visible in the screenshot above but in the case of glass, the reflection from the environment is also applied.&lt;br/&gt;All the environment data is fetched from the 256x256 HDR &lt;a href=&quot;https://en.wikipedia.org/wiki/Cube_mapping&quot;&gt;cubemap&lt;/a&gt; you can see below (also called reflection probe).&lt;/p&gt;
&lt;div&gt;
&lt;div class=&quot;forceBorder&quot;&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/cubemaps/20_yn.png&quot; class=&quot;img-nobox&quot;/&gt;&lt;div class=&quot;screenshot-caption&quot;&gt;Reflection Probe&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The cubemap is not dynamic, it’s only baked once offline and used as-is at runtime so you won’t see any dynamic meshes inside. Its role is to provide “good-enough” reflection of the surrounding static environment data. There are several probes like this throughout the level at different locations. The total number of cubemaps for the entire game is &lt;em&gt;huge&lt;/em&gt;, not only you need probes in lots of locations, you also need different versions of the same probe depending on the hour of the day/night. Plus you also need to take into account the weather so for a same location at the same hour the engine generates 4 cubemaps for sunny, cloudy, rainy and stormy weather. The game needs to deal with an impressive amount of permutations.&lt;br/&gt;A short clip was played at the GDC 2013 &lt;a href=&quot;https://youtu.be/0qhPoT4coOI?t=1h1m22s&quot;&gt;showing the engine generating&lt;/a&gt; such light probes.&lt;/p&gt;
&lt;h3&gt;Screen Space Reflections&lt;/h3&gt;
&lt;p&gt;This step constructs a reflection image of the scene using only information from the pixels we’ve rendered in the previous pass. It performs some &lt;a href=&quot;https://en.wikipedia.org/wiki/Ray_casting&quot;&gt;ray-casting&lt;/a&gt; in screen space at half-resolution: a number of rays are shot for each pixel of the screen, the direction of these rays is calculated from the depth buffer (giving the pixel position) and its normal. Each ray is tested for collision by sampling the depth buffer at 4 equidistant points located along the ray. If a hit is found the color of the pixel where the hit happened is used as a reflection color, modulated by the original pixel roughness.&lt;/p&gt;
&lt;table class=&quot;table-carousel&quot;&gt;&lt;tr&gt;&lt;td&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/20_ssr_color.jpg&quot;/&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/20_ssr_alpha.jpg&quot;/&gt;&lt;/div&gt;

&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;We obviously lack “global” information: any object outside the screen is unable to contribute to any reflection. To make artifacts less noticeable the reflection map uses an alpha mask to smoothly fade-out the opacity as we get closer to the screen edges. The SSR value lies in the fact that it can provide realtime &lt;em&gt;dynamic&lt;/em&gt; reflections for quite a cheap price.&lt;br/&gt;The noise in the SSR map is later reduced with a &lt;a href=&quot;https://en.wikipedia.org/wiki/Gaussian_blur&quot;&gt;Gaussian blur&lt;/a&gt; and blended on the top of the scene.&lt;/p&gt;
&lt;h3&gt;Heat Distortion, Decals and Particles&lt;/h3&gt;
&lt;p&gt;The burning area where the &lt;em&gt;Man on Fire&lt;/em&gt; is standing has a temperature so high it creates light distortion. The effect is achieved with several draw calls, each making a copy of the entire render target and applying a distortion by stretching the pixels along some direction locally. It’s especially visible on the first arch connecting the left wall to the ceiling.&lt;br/&gt;After that some decals are applied like the liquid on the floor and finally particles are drawn to render the fire and the smoke.&lt;/p&gt;

&lt;h3&gt;Bloom&lt;/h3&gt;
&lt;div class=&quot;table-carousel&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/24_bloom_brightpass.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Bright Pass&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This step creates a &lt;a href=&quot;http://en.wikipedia.org/wiki/Bloom_%28shader_effect%29&quot;&gt;bloom&lt;/a&gt; texture from the original scene. It works at very low resolution: first the scene is downscaled by a factor of 4 then a bright-pass filter is applied to make only the brightest pixels stand out just like you can see on the image on the right.&lt;/p&gt;
&lt;p&gt;How does the bright-pass filter discriminate between “dark” and “bright” pixels? We’re not in HDR space anymore, we’re post-tonemap in LDR space where it’s more tricky to know which color was originally bright. Well remember that the scene buffer alpha channel contains the original HDR luminance of each pixel pre-tonemap, this is this information the filter uses to decide how “bright” a pixel actually is.&lt;/p&gt;
&lt;div class=&quot;table-carousel&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/24_bloom_flares.png&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Lens Flares&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In the Fox Engine the bloom is not just about bright pixels spreading their colors around: it also takes into account &lt;a href=&quot;https://en.wikipedia.org/wiki/Lens_flare&quot;&gt;lens flares&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Chromatic_aberration&quot;&gt;chromatic aberration&lt;/a&gt; which are procedurally generated from the bright-pass buffer. Here in this dark scene there’s no strong light source making the lens flares stand out, they’re barely visible but you can get an idea of what they look like with the image on the right where I artificially boosted the colors.&lt;/p&gt;
&lt;p&gt;Lens flares get composited on the top of the bright-pass filter, then a large-radius blurred version of the buffer is generated, by running 4 consecutive iterations of &lt;a href=&quot;http://www.daionet.gr.jp/~masa/archives/GDC2003_DSTEAL.ppt&quot;&gt;Masaki Kawase’s blur algorithm&lt;/a&gt;. Kawase’s approach is able to achieve &lt;a href=&quot;https://software.intel.com/en-us/blogs/2014/07/15/an-investigation-of-fast-real-time-gpu-based-image-blur-algorithms&quot;&gt;large-radius blur similar to Gaussian but at higher performance&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Depth of Field&lt;/h3&gt;
&lt;p&gt;The Metal Gear games are known for their long, movie-like cinematics so it’s natural the engine tries as hard as possible to replicate the behavior of real world cameras with a &lt;a href=&quot;http://en.wikipedia.org/wiki/Depth_of_field&quot;&gt;depth-of-field&lt;/a&gt; effect: only a certain area appears sharp, the other out-of-focus areas appear blurred.&lt;/p&gt;
&lt;p&gt;The scene is downscaled to half-resolution and converted back from sRGB space to linear space.&lt;br/&gt;Then the engine generates 2 images corresponding to the “near field” (the area between the camera and the focus distance) and the “far field” (the area beyond the focus distance). The discrimination is purely depth-based (distance from the camera), any pixel closer than the soldiers will be copied to the near field buffer, and other pixels further away will go to the far field buffer.&lt;br/&gt;Each field is then processed separately to apply some blur. Each pixel’s &lt;a href=&quot;https://en.wikipedia.org/wiki/Circle_of_confusion&quot;&gt;Circle of Confusion&lt;/a&gt; is calculated based simply on its depth and the camera configuration (aperture, focal distance…), the CoC value basically says how much “out-of-focus” a pixel is, the bigger the CoC the more the pixel color spreads around.&lt;br/&gt;Here are the 2 fields once the blur has been performed:&lt;/p&gt;
&lt;table class=&quot;table-carousel&quot;&gt;&lt;tr&gt;&lt;td&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/30_dof_near_transparent.png&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;DoF - Near Field&lt;/div&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/30_dof_far_transparent.png&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;DoF - Far Field&lt;/div&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/34_bokeh_sprite.png&quot; class=&quot;img-nobox&quot;/&gt; A few words about this “blur” operation: it’s actually a relatively heavy operation where one sprite is spawned and rendered for every single pixel of the scene. The sprite itself contains a disk like you can see on the right, you could replace it by any shape, an hexagon for example if you prefer hexagonal bokeh…&lt;/p&gt;
&lt;p&gt;The sprite will be centered on the pixel which spawned it, it has the same color as the pixel and its size scales with the pixel CoC. The idea is that you want pixels to “spread their color around” using this disk shape, the more out-of-focus a pixel is the larger the sprite it spawns should be. &lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/35_dof_compose.png&quot; class=&quot;img-nobox&quot;/&gt; All the sprites are drawn on the top of each others with additive blending.&lt;/p&gt;
&lt;p&gt;This technique is a “sprite scattering” approach, it’s used in several games like &lt;a href=&quot;https://www.beyond3d.com/content/news/499&quot;&gt;&lt;em&gt;Lost Planet&lt;/em&gt;&lt;/a&gt;, &lt;a href=&quot;https://bartwronski.com/2014/04/07/bokeh-depth-of-field-going-insane-part-1/&quot;&gt;&lt;em&gt;The Witcher&lt;/em&gt; series&lt;/a&gt; or &lt;a href=&quot;https://docs.unrealengine.com/udk/Three/rsrc/Three/DirectX11Rendering/MartinM_GDC11_DX11_presentation.pdf&quot;&gt;UE4’s Bokeh-DoF&lt;/a&gt; post-process.&lt;/p&gt;
&lt;p&gt;Once our blurred far and near fields are generated we just simply blend them on the top of the original scene:&lt;/p&gt;

&lt;div id=&quot;30_dof&quot;&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/23_particles_3.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;DoF: Before&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/30_dof_after.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;DoF: After&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;This technique works and produces beautiful results, though it can quickly become a performance hog at high resolution with strongly out-of-focus scenes: very large sprites overlapping each others can cause some crazy overdraw.&lt;br/&gt;So how does the Fox Engine mitigate this issue?&lt;br/&gt;Well I actually over-simplified my explanation above when I wrote one field is represented by an half-resolution accumulation buffer, it’s not just this one buffer there are also other smaller ones at ¼th, 1/8th, 1/16th of the resolution. Depending on the pixel CoC, the sprite it spawns will end up in only one of these buffers: typically big sprites go to low-resolution buffers to reduce the total number of pixels touched. In order to do this the engine treats each buffer level one after another, spawning 100% of the sprites and letting the vertex shader kill the sprites not belonging to the current level. The vertex shader knows from the original pixel’s CoC the final size the sprite will have, if this size is not appropriate for the current level the shader just kicks the vertex outside the frustum by setting a negative depth value. The sprite geometry never makes it to the rasterization stage by the pixel shader. All these buffers then get combined to produce one half-resolution field.&lt;/p&gt;
&lt;h3&gt;Lens Dirt and More Lens Flares&lt;/h3&gt;
&lt;div&gt;
&lt;div id=&quot;40_dirt_progress&quot;&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/40_dirt_1.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Dirt &amp;amp; Flares 30%&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/40_dirt_2.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Dirt &amp;amp; Flares 60%&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/40_dirt_3.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Dirt &amp;amp; Flares 100%&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Snake&lt;/em&gt; is in a difficult situation in an hostile environment, with explosions all around, some projections are going to hit the camera lens and make it dirty. To reflect this a bit of lens dirt is added artificially on the top of our image, the dirt is generated from some sprites.&lt;/p&gt;
&lt;p&gt;Then we need more lens flares! Yes we already added a few of these before but there’s nothing like too many lens flares, right? This time we add &lt;a href=&quot;https://en.wikipedia.org/wiki/Anamorphic_format&quot;&gt;anamorphic lenses&lt;/a&gt; artifacts: the long vertical light streaks in the middle of the screen, caused by the bright flames. These are also generated purely from sprites.&lt;/p&gt;
&lt;p&gt;All these steps are performed with a dozen draw calls rendering to a half-resolution buffer which is then composited on the top of the scene with additive alpha-blending.&lt;/p&gt;
&lt;div id=&quot;40_dirt_after&quot;&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/30_dof_after.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Dirt &amp;amp; Flares: Before&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/40_dirt_after.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Dirt &amp;amp; Flares: After&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3&gt;Motion Blur&lt;/h3&gt;
&lt;p&gt;You remember we’ve generated a velocity buffer at the beginning of the frame? It’s finally time to use it to apply some motion blur to the scene. The technique used by the Fox Engine is inspired by the &lt;a href=&quot;http://casual-effects.com/research/McGuire2012Blur/index.html&quot;&gt;MHBO 2012 paper&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It generates a low-resolution map with square tiles containing the maximum velocity of its pixels. The image of the scene is locally stretched along the direction of the velocity vectors to create an impression of movement. Here the motion blur effect is hard to visualize because there’s barely any movement in this scene.&lt;/p&gt;
&lt;h3&gt;Color Grading&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Color_grading&quot;&gt;Color grading&lt;/a&gt; is about adjusting the final color of the scene. The artists can decide to balance the colors, apply some filters… This is done by an operation which takes the original RGB value of a pixel and matches it to a new RGB value, all in LDR space. In some cases you can come up with some mathematics function to perform such conversion (it’s what a tonemapping operator does when it converts from HDR to LDR), but usually artists want more advanced control over the color conversion and no mathematics function will get the job done.&lt;br/&gt;In this case we have to bite the bullet and consider the brute force approach: a big &lt;a href=&quot;https://en.wikipedia.org/wiki/Lookup_table&quot;&gt;look-up table&lt;/a&gt; (LUT) mapping every single possible RGB value to another RGB value.&lt;br/&gt;Sounds crazy? Let’s see: there are 256 x 256 x 256 possible RGB values, that’s more than 16 million mappings to maintain! This will be hard to feed efficiently to a pixel shader… unless we resort to some trick.&lt;br/&gt;And the trick is to consider the RGB space as a 3-dimensional cube, defined by 3 axes: red, green and blue.&lt;/p&gt;
&lt;table class=&quot;table-carousel&quot;&gt;&lt;tr&gt;&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;Then we take this cube on the left,&lt;br/&gt;cut it into 16 slices and we store&lt;br/&gt;each slice into a 16 x 16 texture.&lt;br/&gt;&lt;img class=&quot;img-nobox&quot; src=&quot;http://www.adriancourreges.com/img/arrow-right.png&quot;/&gt;&lt;br/&gt;We end up with the 16 slices&lt;br/&gt;you can see on the right.&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;So we now have “discretized” our cube down to 16 x 16 x 16 voxels, so 4096 mappings, which is just a tiny fraction of the original 16 million entries. How do we reconstruct all the other missing entries? By &lt;a href=&quot;http://en.wikipedia.org/wiki/Linear_interpolation&quot;&gt;linear interpolation&lt;/a&gt;: given some RGB color just look for its 8 nearest neighbors in the cube for which we know the exact mapping.&lt;br/&gt;In practice that means finding the 2 layers closest the blue value, then inside each layer finding the 4 closest pixels to the red and green values. Then it’s a just a linear interpolation: a weighted average of the 8 colors using the distance to influence the weights. Such interpolation from a small number of values works because color grading is usually about low-frequency variations.&lt;/p&gt;
&lt;p&gt;You can store your 16 layers into a 3D texture on the GPU and then the shader code is dead simple: just ask for a lookup at some 3D coordinates and the hardware transparently performs the trilinear filtering of the 8 closest points and returns the correct value. Fast and easy.&lt;/p&gt;
&lt;p&gt;So we have a way to encode color mapping through this 16-slices-LUT, but how can the artist actually create such LUT?&lt;br/&gt;It’s quite straight-forward, just lay-out all the slices next to each other to produce an image like this:&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;img-nobox&quot; src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/50_lut_original.png&quot;/&gt;&lt;br/&gt;&lt;em&gt;256x16 LUT texture&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Then take a screenshot in the game of some scene that requires color-grading. Embed the LUT image above in some corner of the screenshot, give the image to the artists and let them do the magic. They’ll use their favorite image editor, make adjustments they like, when they’re done and send you back the corrected picture, the LUT you embedded in the corner will reflect the new RGB color mapping. You can simply extract the modified 256x16 LUT and feed it directly to the game engine.&lt;/p&gt;
&lt;div id=&quot;50_color_grading&quot;&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/50_cg_before.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Color Grading + Bloom: Before&lt;br/&gt;LUT  &lt;img class=&quot;img-nobox&quot; src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/50_lut_original.png&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/50_cg_after.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Color Grading + Bloom: After&lt;br/&gt;LUT  &lt;img class=&quot;img-nobox&quot; src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/50_lut_modified.png&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In this step the bloom buffer was added on the top of the scene before applying the LUT color-grading.&lt;/p&gt;
&lt;h3&gt;Anti-Aliasing&lt;/h3&gt;
&lt;div&gt;
&lt;div id=&quot;55_fxaa&quot;&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/55_fxaa_off.png&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;FXAA: Before&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/55_fxaa_on.png&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;FXAA: After&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;The mesh edges follow a bit too much the pixel grid of the frame buffer, we can see hard jagged borders which look unnatural.&lt;/p&gt;
&lt;p&gt;This is a limitation of a deferred renderer where each pixel stores only a single information; in a forward renderer it would be less of an issue, you could really on &lt;a href=&quot;https://en.wikipedia.org/wiki/Multisample_anti-aliasing&quot;&gt;MSAA&lt;/a&gt; to have multiple color samples per pixel which produces softer edge transitions.&lt;/p&gt;
&lt;p&gt;Here the Fox Engine fixes some edge-aliasing by performing a post-processing pass of &lt;a href=&quot;http://en.wikipedia.org/wiki/Fast_approximate_anti-aliasing&quot;&gt;FXAA&lt;/a&gt;: a pixel shader tries to recognize and fix aliased edges based on the color values of the neighbor pixels.&lt;br/&gt;Notice how all the stair-case visible at the border of the handrail is smoothed-out in the final result.&lt;/p&gt;

&lt;h3&gt;Final Touch&lt;/h3&gt;
&lt;p&gt;Are we finally done after anti-aliasing? Not quite but almost! In this last step the artists have the possibility to apply some masks in certain areas of the image to darken or lighten the pixels. These are just a series of sprites drawn on the top of the scene. It’s interesting to see how far the Fox Engine goes to keep artists in control up until the very last step of the rendering.&lt;/p&gt;
&lt;div id=&quot;80_finaltouch&quot;&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/80_post_fxaa.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Finishing Touches: 0%&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/81_final1.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Finishing Touches: 30%&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/81_final2.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Finishing Touches: 60%&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/99_final.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Finishing Touches: 100%&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;And we are done! The frame can now be sent over to the monitor for display and the GPU will begin this same process again from scratch to generate a whole new frame.&lt;/p&gt;
&lt;p&gt;A few metrics about this particular scene: 2331 draw calls, 623 textures and 73 render targets were used.&lt;/p&gt;

&lt;h3&gt;Watch the Buffers in Motion&lt;/h3&gt;
&lt;p&gt;Here is a short clip showing the different buffers I presented before (G-Buffer, SSAO…) live while playing the game.&lt;/p&gt;
&lt;div class=&quot;forceBorder&quot;&gt;
&lt;div class=&quot;embed-video-container&quot;&gt;&lt;iframe class=&quot;embed-video-container&quot; width=&quot;1280&quot; height=&quot;720&quot; src=&quot;//www.youtube.com/embed/Zq5mrApE98A?vq=hd720&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;If you’re curious about how this video was made: it turns out this study required quite a bit of effort compared to my previous ones, none of the graphics debuggers out there were usable because MGS V will shutdown when it detects &lt;a href=&quot;https://en.wikipedia.org/wiki/DLL_injection&quot;&gt;DLL injectors&lt;/a&gt; tampering with certain D3D functions. I had to get my hands dirty and forked an old version of &lt;a href=&quot;https://reshade.me/&quot;&gt;ReShade&lt;/a&gt; I extended with my own custom hooks so I could dump intermediate buffers, textures, shader binaries (the &lt;a href=&quot;http://timjones.io/blog/archive/2015/09/02/parsing-direct3d-shader-bytecode&quot;&gt;DXBC&lt;/a&gt; containing all the debug data)…&lt;br/&gt;Once I had my own runtime hooks it was fairly easy to produce the video above: I could just copy any intermediate buffer I wished to the final framebuffer right before it goes to the monitor.&lt;/p&gt;
&lt;h3&gt;Ishmael’s True Face&lt;/h3&gt;
&lt;p&gt;Ishmael is the mysterious patient in the bed next to &lt;em&gt;Snake&lt;/em&gt; who helps him escape the hospital. His head is covered with bandage concealing his true identity. Ever wondered what his face really looks like?&lt;br/&gt;Well let’s have a look! Here is the diffuse albedo buffer right after and before the bandage is rendered.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;No spoiler here.&lt;/strong&gt; The slide-show is set to manual-play just in case, watch it only if you wish. Won’t really spoil anything…&lt;/em&gt;&lt;/p&gt;
&lt;div id=&quot;90_ishmael_mask&quot;&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/90_ishmael_mask.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;Slide to take off Ishmael’s bandage…&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;slick-margin05&quot;&gt;
&lt;div&gt;
&lt;div&gt;&lt;img src=&quot;http://www.adriancourreges.com/img/blog/2017/mgsv/90_ishmael_nomask.jpg&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;screenshot-caption&quot;&gt;That’s… not quite the face he’s suposed to have…&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;But let’s push this a bit further!&lt;br/&gt;Instead of just dumping the albedo map in the middle of the G-Buffer generation like I did above, it would be nice to see Ishmael’s face while playing the game live, by preventing the engine from rendering the bandage.&lt;br/&gt;This is fairly easy to do: with the custom hooks I can choose not to forward certain calls to the GPU, after poking around a little I could identify the 2 draw calls responsible for the bandage rendering and blacklist them. If you want to reproduce my experiment at home these are the calls in question:&lt;/p&gt;
&lt;span&gt;Bandage Draw Calls&lt;/span&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;
&lt;pre class=&quot;line-numbers&quot;&gt;
&lt;span class=&quot;line-number&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;line-number&quot;&gt;2&lt;/span&gt;
&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&quot;code&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;c&quot;&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;n&quot;&gt;ID3D11DeviceContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DrawIndexed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;0x591&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;0xF009&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;0x0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;n&quot;&gt;ID3D11DeviceContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DrawIndexed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;0xB4F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;0xFA59&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;0x0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;
&lt;p&gt;And below is a video of the game with Ishmael’s true face. I’m using a hot-key to toggle the bandage rendering on/off. The transition is progressive by slowing decreasing the number of triangles used to draw the bandage until complete fade-out.&lt;/p&gt;
&lt;div class=&quot;forceBorder&quot;&gt;
&lt;div class=&quot;embed-video-container&quot;&gt;&lt;iframe class=&quot;embed-video-container&quot; width=&quot;1280&quot; height=&quot;720&quot; src=&quot;//www.youtube.com/embed/T-qHmWIBX-g?vq=hd720&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Note that this trick of blocking draw calls won’t work in all cases, sometimes the original mesh simply doesn’t have the data for the hidden surfaces. Which makes sense for optimizing performance: less unnecessary geometry pushed to the GPU!&lt;br/&gt;For example the model of &lt;a href=&quot;http://metalgear.wikia.com/wiki/Psycho_Mantis&quot;&gt;Tretij Rebenok&lt;/a&gt; doesn’t have any triangles underneath the gas mask for the bottom of his face, you’ll never see his nose and mouth simply because they don’t exist.&lt;/p&gt;

&lt;p&gt;This concludes the analysis of MGS V, I hope you could get a better understanding of how the Fox Engine renders a frame.&lt;br/&gt;If you’re eager to know more below is a selection of links with extra material:&lt;/p&gt;
</description>
<pubDate>Fri, 15 Dec 2017 13:34:48 +0000</pubDate>
<dc:creator>jsheard</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.adriancourreges.com/blog/2017/12/15/mgs-v-graphics-study/</dc:identifier>
</item>
<item>
<title>Introducing the GoodWatch</title>
<link>https://goodwatch.org/posts/introducing-the-goodwatch/</link>
<guid isPermaLink="true" >https://goodwatch.org/posts/introducing-the-goodwatch/</guid>
<description>[unable to retrieve full-text content]&lt;p&gt;Article URL: &lt;a href=&quot;https://goodwatch.org/posts/introducing-the-goodwatch/&quot;&gt;https://goodwatch.org/posts/introducing-the-goodwatch/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=15930916&quot;&gt;https://news.ycombinator.com/item?id=15930916&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Points: 236&lt;/p&gt;&lt;p&gt;# Comments: 24&lt;/p&gt;
&lt;hr&gt;&lt;p&gt;hnrss is a labor of love, but if the project has made your job
or hobby project easier and you want to show some gratitude, &lt;a
href=&quot;https://donate.hnrss.org/&quot;&gt;donations are very much
appreciated&lt;/a&gt;. PayPal and Bitcoin both accepted. Thanks!&lt;/p&gt;
        </description>
<pubDate>Fri, 15 Dec 2017 10:41:53 +0000</pubDate>
<dc:creator>limmeau</dc:creator>
<dc:identifier>https://goodwatch.org/posts/introducing-the-goodwatch/</dc:identifier>
</item>
</channel>
</rss>