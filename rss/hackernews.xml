<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Neural Networks in JavaScript with Deeplearn.js</title>
<link>https://www.robinwieruch.de/neural-networks-deeplearnjs-javascript/</link>
<guid isPermaLink="true" >https://www.robinwieruch.de/neural-networks-deeplearnjs-javascript/</guid>
<description>&lt;header&gt;
&lt;/header&gt;&lt;div class=&quot;text-center&quot;&gt;  &lt;a target=&quot;_blank&quot; href=&quot;https://twitter.com/intent/follow?screen_name=rwieruch&quot; class=&quot;twitter-button-follow&quot;&gt;Follow @rwieruch&lt;/a&gt;   &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/rwieruch&quot; class=&quot;github-button-follow&quot;&gt;Follow @rwieruch&lt;/a&gt;&lt;/div&gt;
&lt;p class=&quot;text-muted text-uppercase mb-small text-center&quot;&gt;&lt;time datetime=&quot;2017-12-05&quot; itemprop=&quot;datePublished&quot;&gt;December 5, 2017&lt;/time&gt;&lt;span class=&quot;hidden-xs hidden-sm&quot;&gt;- &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/rwieruch/blog_robinwieruch_content/blob/master/neural-networks-deeplearnjs-javascript.md&quot;&gt;Edit this Post on GitHub&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;post-image-primary&quot;&gt;
&lt;div class=&quot;pinterest-pinner-wrapper&quot; itemscope=&quot;&quot; itemtype=&quot;http://schema.org/ImageObject&quot;&gt;

&lt;img class=&quot;img-lazy img-responsive&quot; data-lazy-src=&quot;/img/posts/neural-networks-deeplearnjs-javascript/banner.jpg&quot; data-is-src-set=&quot;is-src-set&quot; alt=&quot;neural network javascript deeplearnjs&quot; itemprop=&quot;image&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;A couple of my recent articles gave an introduction into a subfield of artificial intelligence by implementing foundational machine learning algorithms in JavaScript (e.g. &lt;a href=&quot;https://www.robinwieruch.de/linear-regression-gradient-descent-javascript/&quot;&gt;linear regression with gradient descent&lt;/a&gt;, &lt;a href=&quot;https://www.robinwieruch.de/multivariate-linear-regression-normal-equation-javascript&quot;&gt;linear regression with normal equation&lt;/a&gt; or &lt;a href=&quot;https://robinwieruch.de/logistic-regression-gradient-descent-classification-javascript&quot;&gt;logistic regression with gradient descent&lt;/a&gt;). These machine learning algorithms were implemented from scratch in JavaScript by using the &lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;http://mathjs.org/&quot;&gt;math.js node package&lt;/a&gt; for linear algebra (e.g. &lt;a href=&quot;https://www.robinwieruch.de/linear-algebra-matrix-javascript/&quot;&gt;matrix operations&lt;/a&gt;) and calculus. You can find all of these machine learning algorithms grouped in a &lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/javascript-machine-learning&quot;&gt;GitHub organization&lt;/a&gt;. If you find any flaws in them, please help me out to make the organization a great learning resource for others. I intend to grow the amount of repositories showcasing different machine learning algorithms to provide web developers a starting point when they enter the domain of machine learning.&lt;/p&gt;
&lt;p&gt;Personally, I found it becomes quite complex and challenging to implement those algorithms from scratch at some point. Especially when combining JavaScript and neural networks with the implementation of forward and back propagation. Since I am learning about neural networks myself at the moment, I started to look for libraries doing the job for me. Hopefully I am able to catch up with those foundational implementations to publish them in the GitHub organization in the future. However, for now, as I researched about potential candidates to facilitate neural networks in JavaScript, I came across &lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://deeplearnjs.org/&quot;&gt;deeplearn.js&lt;/a&gt; which was recently released by Google. So I gave it a shot. In this article / tutorial, I want to share my experiences by implementing with you a neural network in JavaScript with deeplearn.js to solve a real world problem for web accessibility.&lt;/p&gt;
&lt;p&gt;I highly recommend to take the &lt;a target=&quot;_blank&quot; rel=&quot;nofollow&quot; href=&quot;https://click.linksynergy.com/link?id=yL1MQRWYyXQ&amp;amp;offerid=467035.1560515719&amp;amp;type=2&amp;amp;murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fmachine-learning&quot;&gt;Machine Learning&lt;/a&gt; course by Andrew Ng. This article will not explain the machine learning algorithms in detail, but only demonstrate their usage in JavaScript. The course on the other hand goes into detail and explains these algorithms in an amazing quality. At this point in time of writing the article, I learn about the topic myself and try to internalize my learnings by writing about them and applying them in JavaScript. If you find any parts for improvements, please reach out in the comments or create a Issue/Pull Request on GitHub.&lt;/p&gt;
&lt;h2 class=&quot;chapter-header&quot; id=&quot;neural-network-purpose&quot;&gt;What's the purpose of the Neural Network?&lt;/h2&gt;
&lt;p&gt;The neural network implemented in this article should be able to improve web accessibility by choosing an appropriate font color regarding a background color. For instance, the font color on a dark blue background should be white whereas the font color on a light yellow background should be black. You might wonder: Why would you need a neural network for the task in the first place? It isn’t too difficult to compute an accessible font color depending on a background color programmatically, is it? I quickly found a solution on Stack Overflow for the problem and adjusted it to my needs to facilitate colors in RGB space.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;function&lt;/span&gt; &lt;span&gt;getAccessibleColor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;let&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;r&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;g&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;b&lt;/span&gt; &lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;let&lt;/span&gt; &lt;span&gt;colors&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;r&lt;/span&gt; &lt;span&gt;/&lt;/span&gt; &lt;span&gt;255&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;g&lt;/span&gt; &lt;span&gt;/&lt;/span&gt; &lt;span&gt;255&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;b&lt;/span&gt; &lt;span&gt;/&lt;/span&gt; &lt;span&gt;255&lt;/span&gt;&lt;span&gt;];&lt;/span&gt;

  &lt;span&gt;let&lt;/span&gt; &lt;span&gt;c&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;colors&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;map&lt;/span&gt;&lt;span&gt;((&lt;/span&gt;&lt;span&gt;col&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;col&lt;/span&gt; &lt;span&gt;&amp;lt;=&lt;/span&gt; &lt;span&gt;0.03928&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
      &lt;span&gt;return&lt;/span&gt; &lt;span&gt;col&lt;/span&gt; &lt;span&gt;/&lt;/span&gt; &lt;span&gt;12.92&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;Math.&lt;/span&gt;&lt;span&gt;pow&lt;/span&gt;&lt;span&gt;((&lt;/span&gt;&lt;span&gt;col&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;0.055&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;/&lt;/span&gt; &lt;span&gt;1.055&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;2.4&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
  &lt;span&gt;});&lt;/span&gt;

  &lt;span&gt;let&lt;/span&gt; &lt;span&gt;L&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;0.2126&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;])&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;0.7152&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;])&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;0.0722&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;

  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;L&lt;/span&gt; &lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;0.179&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
    &lt;span&gt;?&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;]&lt;/span&gt;
    &lt;span&gt;:&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;255&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;255&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;255&lt;/span&gt; &lt;span&gt;];&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The use case of the neural network isn’t too valuable for the real world because there is already a programmatic way to solve the problem. There isn’t a need to use a machine trained algorithm for it. However, since there is a programmatic approach to solve the problem, it becomes simple to validate the performance of a neural network which might be able to solve the problem for us too. Checkout the animation in the &lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/javascript-machine-learning/color-accessibility-neural-network-deeplearnjs&quot;&gt;GitHub repository of a learning neural network&lt;/a&gt; to get to know how it will perform eventually and what you are going to build in this tutorial.&lt;/p&gt;
&lt;p&gt;If you are familiar with machine learning, you might have noticed that the task at hand is a classification problem. An algorithm should decide a binary output (font color: white or black) based on an input (background color). Over the course of training the algorithm with a neural network, it will eventually output the correct font colors based on background colors as inputs.&lt;/p&gt;
&lt;p&gt;The following sections will give you guidance to setup all parts for your neural network from scratch. It is up to you to wire the parts together in your own file/folder setup. But you can consolidate the previous referenced GitHub repository for the implementation details.&lt;/p&gt;
&lt;h2 class=&quot;chapter-header&quot; id=&quot;data-set-generation-javascript&quot;&gt;Data Set Generation in JavaScript&lt;/h2&gt;
&lt;p&gt;A training set in machine learning consists of input data points and output data points (labels). It is used to train the algorithm which will predict the output for new input data points outside of the training set (e.g. test set). During the training phase, the algorithm trained by the neural network adjusts its weights to predict the given labels of the input data points. In conclusion, the trained algorithm is a function which takes a data point as input and approximates the output label.&lt;/p&gt;
&lt;p&gt;After the algorithm is trained with the help of the neural network, it can output font colors for new background colors which weren’t in the training set. Therefore you will use a &lt;strong&gt;test set&lt;/strong&gt; later on. It is used to verify the accuracy of the trained algorithm. Since we are dealing with colors, it isn’t difficult to generate a sample data set of input colors for the neural network.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;function&lt;/span&gt; &lt;span&gt;generateRandomRgbColors&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;m&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;const&lt;/span&gt; &lt;span&gt;rawInputs&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[];&lt;/span&gt;

  &lt;span&gt;for&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;let&lt;/span&gt; &lt;span&gt;i&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;i&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt; &lt;span&gt;m&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;i&lt;/span&gt;&lt;span&gt;++&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;rawInputs&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;push&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;generateRandomRgbColor&lt;/span&gt;&lt;span&gt;());&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;

  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;rawInputs&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;function&lt;/span&gt; &lt;span&gt;generateRandomRgbColor&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;
    &lt;span&gt;randomIntFromInterval&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;255&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;randomIntFromInterval&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;255&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
    &lt;span&gt;randomIntFromInterval&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;255&lt;/span&gt;&lt;span&gt;),&lt;/span&gt;
  &lt;span&gt;];&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;function&lt;/span&gt; &lt;span&gt;randomIntFromInterval&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;min&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;max&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;Math.&lt;/span&gt;&lt;span&gt;floor&lt;/span&gt;&lt;span&gt;(Math.&lt;/span&gt;&lt;span&gt;random&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;max&lt;/span&gt; &lt;span&gt;-&lt;/span&gt; &lt;span&gt;min&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;min&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The &lt;code&gt;generateRandomRgbColors()&lt;/code&gt; function creates partial data sets of a given size m. The data points in the data sets are colors in the RGB color space. Each color is represented as a row in a matrix whereas each column is a &lt;strong&gt;feature&lt;/strong&gt; of the color. A feature is either the R, G or B encoded value in the RGB space. The data set hasn’t any labels yet, so the training set isn’t complete, because it has only input values but no output values.&lt;/p&gt;
&lt;p&gt;Since the programmatic approach to generate an accessible font color based on a color is known, an adjusted version of the functionality can be derived to generate the labels for the training set (and the test set later on). The labels are adjusted for a binary classification problem and reflect the colors black and white implicitly in the RGB space. Therefore a label is either [0, 1] for the color black or [ 1, 0 ] for the color white.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;function&lt;/span&gt; &lt;span&gt;getAccessibleColor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;let&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;r&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;g&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;b&lt;/span&gt; &lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;let&lt;/span&gt; &lt;span&gt;color&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;r&lt;/span&gt; &lt;span&gt;/&lt;/span&gt; &lt;span&gt;255&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;g&lt;/span&gt; &lt;span&gt;/&lt;/span&gt; &lt;span&gt;255&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;b&lt;/span&gt; &lt;span&gt;/&lt;/span&gt; &lt;span&gt;255&lt;/span&gt;&lt;span&gt;];&lt;/span&gt;

  &lt;span&gt;let&lt;/span&gt; &lt;span&gt;c&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;color&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;map&lt;/span&gt;&lt;span&gt;((&lt;/span&gt;&lt;span&gt;col&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;col&lt;/span&gt; &lt;span&gt;&amp;lt;=&lt;/span&gt; &lt;span&gt;0.03928&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
      &lt;span&gt;return&lt;/span&gt; &lt;span&gt;col&lt;/span&gt; &lt;span&gt;/&lt;/span&gt; &lt;span&gt;12.92&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;Math.&lt;/span&gt;&lt;span&gt;pow&lt;/span&gt;&lt;span&gt;((&lt;/span&gt;&lt;span&gt;col&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;0.055&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;/&lt;/span&gt; &lt;span&gt;1.055&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;2.4&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
  &lt;span&gt;});&lt;/span&gt;

  &lt;span&gt;let&lt;/span&gt; &lt;span&gt;L&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;0.2126&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;])&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;0.7152&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;])&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;0.0722&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;c&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;

&lt;span&gt;  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;L&lt;/span&gt; &lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;0.179&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;?&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;]&lt;/span&gt; &lt;span&gt;// black&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;:&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;];&lt;/span&gt; &lt;span&gt;// white&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now you have everything in place to generate random data sets (training set, test set) of (background) colors which are classified either for black or white (font) colors.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;function&lt;/span&gt; &lt;span&gt;generateColorSet&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;m&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;const&lt;/span&gt; &lt;span&gt;rawInputs&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;generateRandomRgbColors&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;m&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
  &lt;span&gt;const&lt;/span&gt; &lt;span&gt;rawTargets&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;rawInputs&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;map&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;getAccessibleColor&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;

  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;rawInputs&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;rawTargets&lt;/span&gt; &lt;span&gt;};&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Another step to give the underlying algorithm in the neural network a better time is &lt;a href=&quot;https://www.robinwieruch.de/improving-gradient-descent-javascript/&quot;&gt;feature scaling&lt;/a&gt;. In a simplified version of feature scaling, you want to have the values of your RGB channels between 0 and 1. Since you know about the maximum value, you can simply derive the normalized value for each color channel.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;function&lt;/span&gt; &lt;span&gt;normalizeColor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;return&lt;/span&gt; &lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;map&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;v&lt;/span&gt; &lt;span&gt;/&lt;/span&gt; &lt;span&gt;255&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It is up to you to put this functionality in your neural network model or as separate utility function. I will put it in the neural network model in the next step.&lt;/p&gt;
&lt;h2 class=&quot;chapter-header&quot; id=&quot;setup-neural-network-javascript&quot;&gt;Setup Phase of a Neural Network Model in JavaScript&lt;/h2&gt;
&lt;p&gt;Now comes the exciting part where you will implement a neural network in JavaScript. Before you can start implementing it, you should install the deeplearn.js library. It is a framework for neural networks in JavaScript. The official pitch for it says: &lt;em&gt;“deeplearn.js is an open-source library that brings performant machine learning building blocks to the web, allowing you to train neural networks in a browser or run pre-trained models in inference mode.”&lt;/em&gt; In this article, you will train your model yourself and run it in inference mode afterward. There are two major advantages to use the library:&lt;/p&gt;
&lt;p&gt;First, it uses the GPU of your local machine which accelerates the vector computations in machine learning algorithms. These machine learning computations are similar to graphical computations and thus it is computational efficient to use the GPU instead of the CPU.&lt;/p&gt;
&lt;p&gt;Second, deeplearn.js is structured similar to the popular Tensorflow library which happens to be also developed by Google but is written in Python. So if you want to make the jump to machine learning in Python, deeplearn.js might give you a great gateway to the whole domain in JavaScript.&lt;/p&gt;
&lt;p&gt;Let’s get back to your project. If you have set it up with npm, you can simply install deeplearn.js on the command line. Otherwise check the official documentation of the deeplearn.js project for installation instructions.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;npm&lt;/span&gt; &lt;span&gt;install&lt;/span&gt; &lt;span&gt;deeplearn&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Since I didn’t build a vast number of neural networks myself yet, I followed the common practice of architecting the neural network in an object-oriented programming style. In JavaScript, you can use a &lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes&quot;&gt;JavaScript ES6 class&lt;/a&gt; to facilitate it. A class gives you the perfect container for your neural network by defining properties and class methods to the specifications of your neural network. For instance, your function to normalize a color could find a spot in the class as method.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;normalizeColor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;map&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;v&lt;/span&gt; &lt;span&gt;/&lt;/span&gt; &lt;span&gt;255&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;

&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Perhaps it is a place for your functions to generate the data sets as well. In my case, I only put the normalization in the class as class method and leave the data set generation outside of the class. You could argue that there are different ways to generate a data set in the future and thus it shouldn’t be defined in the neural network model itself. Nevertheless, that’s only a implementation detail.&lt;/p&gt;
&lt;p&gt;The training and inference phase are summarized under the umbrella term &lt;strong&gt;session&lt;/strong&gt; in machine learning. You can setup the session for the neural network in your neural network class. First of all, you can import the NDArrayMathGPU class from deeplearn.js which helps you to perform mathematical calculations on the GPU in a computational efficient way.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;  &lt;span&gt;NDArrayMathGPU&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;'deeplearn'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;
&lt;span&gt;&lt;span&gt;const&lt;/span&gt; &lt;span&gt;math&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;NDArrayMathGPU&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;
&lt;/span&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;...&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Second, declare your class method to setup your session. It takes a training set as argument in its function signature and thus it becomes the perfect consumer for a generated training set from a previous implemented function. In the third step, the session initializes an empty graph. In the next steps, the graph will reflect your architecture of the neural network. It is up to you to define all of its properties.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;span&gt;  &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;  &lt;span&gt;NDArrayMathGPU&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;'deeplearn'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

&lt;span&gt;  &lt;span&gt;setupSession&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;const&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;  &lt;span&gt;}&lt;/span&gt;
&lt;/span&gt;
  &lt;span&gt;..&lt;/span&gt;

&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Fourth, you define the shape of your input and output data points for your graph in form of a &lt;strong&gt;tensor&lt;/strong&gt;. A tensor is an array (of arrays) of numbers with a variable number of dimensions. It can be a vector, a matrix or a higher dimensional matrix. The neural network has these tensors as input and output. In our case, there are three input units (one input unit per color channel) and two output units (binary classification, e.g. white and black color).&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

&lt;span&gt;  &lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;  &lt;span&gt;targetTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;
  &lt;span&gt;setupSession&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;const&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;

&lt;span&gt;    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;inputTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;placeholder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'input RGB value'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;targetTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;placeholder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'output classifier'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;
&lt;/span&gt;  &lt;span&gt;}&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Fifth, a neural network has hidden layers in between. It’s the blackbox where the magic happens. Basically, the neural network comes up with its own cross computed paramaters which are trained in the session. After all, it is up to you to define the dimension (layer size with each unit size) of the hidden layer(s).&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;targetTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;setupSession&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;const&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;

    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;inputTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;placeholder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'input RGB value'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;
    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;targetTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;placeholder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'output classifier'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;

&lt;span&gt;    &lt;span&gt;let&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;64&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;32&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;2&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;16&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;  &lt;span&gt;}&lt;/span&gt;

&lt;span&gt;  &lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;inputLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;layerIndex&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;units&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;  &lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;  &lt;span&gt;}&lt;/span&gt;
&lt;/span&gt;
  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Depending on your number of layers, you are altering the graph to span more and more of its layers. The class method which creates the connected layer takes the graph, the mutated connected layer, the index of the new layer and number of units. The layer property of the graph can be used to return a new tensor that is identified by a name.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;targetTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;setupSession&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;const&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;

    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;inputTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;placeholder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'input RGB value'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;
    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;targetTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;placeholder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'output classifier'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;

    &lt;span&gt;let&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;64&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
    &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;32&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
    &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;2&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;16&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;

  &lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
    &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
    &lt;span&gt;inputLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
    &lt;span&gt;layerIndex&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
    &lt;span&gt;units&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;span&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;layers&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;dense&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;`fully_connected_&lt;/span&gt;&lt;span&gt;${&lt;/span&gt;&lt;span&gt;layerIndex&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;span&gt;`&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;inputLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;units&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;  &lt;span&gt;}&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Each neuron in a neural network has to have a defined &lt;strong&gt;activation function&lt;/strong&gt;. It can be a &lt;strong&gt;logistic activation function&lt;/strong&gt; that you might know already from logistic regression and thus it becomes a &lt;strong&gt;logistic unit&lt;/strong&gt; in the neural network. In our case, the neural network uses &lt;strong&gt;rectified linear units&lt;/strong&gt; as default.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;targetTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;setupSession&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;const&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;

    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;inputTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;placeholder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'input RGB value'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;
    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;targetTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;placeholder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'output classifier'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;

    &lt;span&gt;let&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;64&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
    &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;32&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
    &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;2&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;16&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;

  &lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
    &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
    &lt;span&gt;inputLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
    &lt;span&gt;layerIndex&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
    &lt;span&gt;units&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;    &lt;span&gt;activationFunction&lt;/span&gt;
&lt;/span&gt;  &lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;layers&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;dense&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
      &lt;span&gt;`fully_connected_&lt;/span&gt;&lt;span&gt;${&lt;/span&gt;&lt;span&gt;layerIndex&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;span&gt;`&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
      &lt;span&gt;inputLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
      &lt;span&gt;units&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;      &lt;span&gt;activationFunction&lt;/span&gt; &lt;span&gt;?&lt;/span&gt; &lt;span&gt;activationFunction&lt;/span&gt; &lt;span&gt;:&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;x&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;relu&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;x&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;
&lt;/span&gt;    &lt;span&gt;);&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Sixth, create the layer which outputs the binary classification. It has 2 output units; one for each discrete value (black, white).&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;targetTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;span&gt;  &lt;span&gt;predictionTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;
  &lt;span&gt;setupSession&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;const&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;

    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;inputTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;placeholder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'input RGB value'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;
    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;targetTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;placeholder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'output classifier'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;

    &lt;span&gt;let&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;64&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
    &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;32&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
    &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;2&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;16&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;

&lt;span&gt;    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;predictionTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;3&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;2&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;  &lt;span&gt;}&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Seventh, declare a cost tensor which defines the loss function. In this case, it will be a mean squared error. It optimizes the algorithm that takes the target tensor (labels) of the training set and the predicted tensor from the trained algorithm to evaluate the cost.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;targetTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;predictionTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;span&gt;  &lt;span&gt;costTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;
  &lt;span&gt;setupSession&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;const&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;

    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;inputTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;placeholder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'input RGB value'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;
    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;targetTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;placeholder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'output classifier'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;

    &lt;span&gt;let&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;64&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
    &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;32&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
    &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;2&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;16&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;

    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;predictionTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;3&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;2&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;span&gt;    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;costTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;meanSquaredCost&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;targetTensor&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;predictionTensor&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;  &lt;span&gt;}&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Last but not least, setup the session with the architected graph. Afterward, you can start to prepare the incoming training set for the upcoming training phase.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;  &lt;span&gt;Session&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;  &lt;span&gt;NDArrayMathGPU&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;'deeplearn'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

&lt;span&gt;  &lt;span&gt;session&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;
  &lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;targetTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;predictionTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;costTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;setupSession&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;const&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;

    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;inputTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;placeholder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'input RGB value'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;
    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;targetTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;placeholder&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;'output classifier'&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;]);&lt;/span&gt;

    &lt;span&gt;let&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;64&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
    &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;32&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
    &lt;span&gt;connectedLayer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;2&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;16&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;

    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;predictionTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;createConnectedLayer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;connectedLayer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;3&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;2&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;costTensor&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;graph&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;meanSquaredCost&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;targetTensor&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;predictionTensor&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;

&lt;span&gt;    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;session&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;Session&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;math&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;
&lt;span&gt;    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;prepareTrainingSet&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;  &lt;span&gt;}&lt;/span&gt;

&lt;span&gt;  &lt;span&gt;prepareTrainingSet&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;  &lt;span&gt;}&lt;/span&gt;
&lt;/span&gt;
  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The setup isn’t done before preparing the training set for the neural network. First, you can support the computation by using a callback function in the GPU performed math context. But it’s not mandatory and you could perform the computation without it.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;Session&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;NDArrayMathGPU&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;'deeplearn'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;const&lt;/span&gt; &lt;span&gt;math&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;NDArrayMathGPU&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;

&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;session&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;targetTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;predictionTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;costTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

  &lt;span&gt;prepareTrainingSet&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;span&gt;    &lt;span&gt;math&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;scope&lt;/span&gt;&lt;span&gt;(()&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;});&lt;/span&gt;
&lt;/span&gt;  &lt;span&gt;}&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Second, you can destructure the input and output (labels, also called targets) from the training set to map them into a readable format for the neural network. The mathematical computations in deeplearn.js use their in-house NDArrays. After all, you can imagine them as simple array in array matrices or vectors. In addition, the colors from the input array are normalized to improve the performance of the neural network.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;span&gt;  &lt;span&gt;Array1D&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;  &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;Session&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;NDArrayMathGPU&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;'deeplearn'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;const&lt;/span&gt; &lt;span&gt;math&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;NDArrayMathGPU&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;

&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;session&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;targetTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;predictionTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;costTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

  &lt;span&gt;prepareTrainingSet&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;math&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;scope&lt;/span&gt;&lt;span&gt;(()&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;span&gt;      &lt;span&gt;const&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;rawInputs&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;rawTargets&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;
&lt;span&gt;      &lt;span&gt;const&lt;/span&gt; &lt;span&gt;inputArray&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;rawInputs&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;map&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;Array1D&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;normalizeColor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt;&lt;span&gt;)));&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;const&lt;/span&gt; &lt;span&gt;targetArray&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;rawTargets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;map&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;Array1D&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt;&lt;span&gt;));&lt;/span&gt;
&lt;/span&gt;    &lt;span&gt;});&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Third, the input and target arrays are shuffled. The shuffler provided by deeplearn.js keeps both arrays in sync when shuffling them. The shuffle happens for each training iteration to feed different inputs as batches to the neural network. The whole shuffling process improves the trained algorithm, because it is more likely to make generalizations by avoiding over-fitting.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;Array1D&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;  &lt;span&gt;InCPUMemoryShuffledInputProviderBuilder&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;  &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;Session&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;NDArrayMathGPU&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;'deeplearn'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;const&lt;/span&gt; &lt;span&gt;math&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;NDArrayMathGPU&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;

&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;session&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;targetTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;predictionTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;costTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

  &lt;span&gt;prepareTrainingSet&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;math&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;scope&lt;/span&gt;&lt;span&gt;(()&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
      &lt;span&gt;const&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;rawInputs&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;rawTargets&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

      &lt;span&gt;const&lt;/span&gt; &lt;span&gt;inputArray&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;rawInputs&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;map&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;Array1D&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;normalizeColor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt;&lt;span&gt;)));&lt;/span&gt;
      &lt;span&gt;const&lt;/span&gt; &lt;span&gt;targetArray&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;rawTargets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;map&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;Array1D&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt;&lt;span&gt;));&lt;/span&gt;

&lt;span&gt;      &lt;span&gt;const&lt;/span&gt; &lt;span&gt;shuffledInputProviderBuilder&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;InCPUMemoryShuffledInputProviderBuilder&lt;/span&gt;&lt;span&gt;([&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;inputArray&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;targetArray&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;]);&lt;/span&gt;
&lt;/span&gt;
&lt;span&gt;      &lt;span&gt;const&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;inputProvider&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;targetProvider&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;shuffledInputProviderBuilder&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;getInputProviders&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;
&lt;/span&gt;    &lt;span&gt;});&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Last but not least, the feed entries are the ultimate input for the feedforward algorithm of the neural network in the training phase. It matches data and tensors (which were defined by their shapes in the setup phase).&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;Array1D&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;InCPUMemoryShuffledInputProviderBuilder&lt;/span&gt;
  &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;Session&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;NDArrayMathGPU&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;'deeplearn'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;const&lt;/span&gt; &lt;span&gt;math&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;NDArrayMathGPU&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;

&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;session&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;targetTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;predictionTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;costTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;  &lt;span&gt;feedEntries&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;
  &lt;span&gt;...&lt;/span&gt;

  &lt;span&gt;prepareTrainingSet&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;math&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;scope&lt;/span&gt;&lt;span&gt;(()&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
      &lt;span&gt;const&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;rawInputs&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;rawTargets&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

      &lt;span&gt;const&lt;/span&gt; &lt;span&gt;inputArray&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;rawInputs&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;map&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;Array1D&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;normalizeColor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt;&lt;span&gt;)));&lt;/span&gt;
      &lt;span&gt;const&lt;/span&gt; &lt;span&gt;targetArray&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;rawTargets&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;map&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;Array1D&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;v&lt;/span&gt;&lt;span&gt;));&lt;/span&gt;

      &lt;span&gt;const&lt;/span&gt; &lt;span&gt;shuffledInputProviderBuilder&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;InCPUMemoryShuffledInputProviderBuilder&lt;/span&gt;&lt;span&gt;([&lt;/span&gt;
        &lt;span&gt;inputArray&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
        &lt;span&gt;targetArray&lt;/span&gt;
      &lt;span&gt;]);&lt;/span&gt;

      &lt;span&gt;const&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;
        &lt;span&gt;inputProvider&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
        &lt;span&gt;targetProvider&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
      &lt;span&gt;]&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;shuffledInputProviderBuilder&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;getInputProviders&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;

&lt;span&gt;      &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;feedEntries&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;{&lt;/span&gt; &lt;span&gt;tensor&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;data&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;inputProvider&lt;/span&gt; &lt;span&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;{&lt;/span&gt; &lt;span&gt;tensor&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;targetTensor&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;data&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;targetProvider&lt;/span&gt; &lt;span&gt;},&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;];&lt;/span&gt;
&lt;/span&gt;    &lt;span&gt;});&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The setup phase of the neural network is finished. The neural network is implemented with all its layers and units. Moreover the training set is prepared for training. Only two &lt;strong&gt;hyperparameters&lt;/strong&gt; are missing to configure the high level behaviour of the neural network. These are used in the next phase: the training phase.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;Array1D&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;InCPUMemoryShuffledInputProviderBuilder&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;Session&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;  &lt;span&gt;SGDOptimizer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;  &lt;span&gt;NDArrayMathGPU&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;'deeplearn'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;const&lt;/span&gt; &lt;span&gt;math&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;NDArrayMathGPU&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;

&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;session&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;  &lt;span&gt;optimizer&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;
&lt;span&gt;  &lt;span&gt;batchSize&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;300&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;  &lt;span&gt;initialLearningRate&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;0.06&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;
  &lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;targetTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;predictionTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;costTensor&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

  &lt;span&gt;feedEntries&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;  &lt;span&gt;constructor&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;optimizer&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;SGDOptimizer&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;initialLearningRate&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;  &lt;span&gt;}&lt;/span&gt;
&lt;/span&gt;
  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The first parameter is the &lt;strong&gt;learning rate&lt;/strong&gt;. You might remember it from linear or logistic regression with gradient descent. It determines how fast the algorithm converges to minimize the cost. So one could assume it should be high. But it mustn’t be too high. Otherwise gradient descent never converges because it cannot find a local optima.&lt;/p&gt;
&lt;p&gt;The second parameter is the &lt;strong&gt;batch size&lt;/strong&gt;. It defines how many data points of the training set are passed through the neural network in one &lt;strong&gt;epoch&lt;/strong&gt; (iteration). An epoch includes one forward pass and one backward pass of one batch of data points. There are two advantages to training a neural network with batches. First, it is not as computational intensive because the algorithm is trained with less data points in memory. Second, a neural network trains faster with batches because the weights are adjusted with each batch of data points in an epoch rather than the whole training set going through it.&lt;/p&gt;
&lt;h2 class=&quot;chapter-header&quot; id=&quot;training-neural-network-javascript&quot;&gt;Training Phase&lt;/h2&gt;
&lt;p&gt;The setup phase is finished. Next comes the training phases. It doesn’t need too much implementation anymore, because all the cornerstones were defined in the setup phase. First of all, the &lt;strong&gt;training phase&lt;/strong&gt; can be defined in a class method. It is executed again in the math context of deeplearn.js. In addition, it uses all the predefined properties of the neural network instance to train the algorithm.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;  &lt;span&gt;train&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;math&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;scope&lt;/span&gt;&lt;span&gt;(()&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;session&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;train&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;costTensor&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;feedEntries&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;batchSize&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;optimizer&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;});&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;  &lt;span&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The train method is only one epoch of the neural network training. So when it is called from outside, it has to be called iteratively. Moreover it trains only one batch. In order to train the algorithm for multiple batches, you have to run multiple iterations of the train method again.&lt;/p&gt;
&lt;p&gt;That’s it for a basic training phase. But it can be improved by adjusting the learning rate over time. The learning rate can be high in the beginning, but when the algorithm converges with each step it takes, the learning rate could be decreased.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;  &lt;span&gt;train&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;step&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;let&lt;/span&gt; &lt;span&gt;learningRate&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;initialLearningRate&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;Math.&lt;/span&gt;&lt;span&gt;pow&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0.90&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Math.&lt;/span&gt;&lt;span&gt;floor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;step&lt;/span&gt; &lt;span&gt;/&lt;/span&gt; &lt;span&gt;50&lt;/span&gt;&lt;span&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;optimizer&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;setLearningRate&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;learningRate&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;
    &lt;span&gt;math&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;scope&lt;/span&gt;&lt;span&gt;(()&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
      &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;session&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;train&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
        &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;costTensor&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
        &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;feedEntries&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
        &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;batchSize&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
        &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;optimizer&lt;/span&gt;
      &lt;span&gt;);&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In our case, the learning rate decreases by 10% every 50 steps. Next, it would be interesting to get the cost in the training phase to verify that it decreases over time. It could be simply returned with each iteration, but that’s leads to computational inefficiency. Every time the cost is requested from the neural network, it has to access the GPU to return it. Therefore, we only access the cost once in a while to verify that it’s decreasing. If the cost is not requested, the cost reduction constant for the training is defined with NONE (which was the default before).&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;Array1D&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;InCPUMemoryShuffledInputProviderBuilder&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;Graph&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;Session&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;SGDOptimizer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
  &lt;span&gt;NDArrayMathGPU&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;  &lt;span&gt;CostReduction&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;'deeplearn'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;  &lt;span&gt;train&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;step&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;computeCost&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;    &lt;span&gt;let&lt;/span&gt; &lt;span&gt;learningRate&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;initialLearningRate&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;Math.&lt;/span&gt;&lt;span&gt;pow&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0.90&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;Math.&lt;/span&gt;&lt;span&gt;floor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;step&lt;/span&gt; &lt;span&gt;/&lt;/span&gt; &lt;span&gt;50&lt;/span&gt;&lt;span&gt;));&lt;/span&gt;
    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;optimizer&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;setLearningRate&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;learningRate&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;

&lt;span&gt;    &lt;span&gt;let&lt;/span&gt; &lt;span&gt;costValue&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;    &lt;span&gt;math&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;scope&lt;/span&gt;&lt;span&gt;(()&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;span&gt;      &lt;span&gt;const&lt;/span&gt; &lt;span&gt;cost&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;session&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;train&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
&lt;/span&gt;        &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;costTensor&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
        &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;feedEntries&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
        &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;batchSize&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
        &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;optimizer&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;span&gt;        &lt;span&gt;computeCost&lt;/span&gt; &lt;span&gt;?&lt;/span&gt; &lt;span&gt;CostReduction&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;MEAN&lt;/span&gt; &lt;span&gt;:&lt;/span&gt; &lt;span&gt;CostReduction&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;NONE&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;      &lt;span&gt;);&lt;/span&gt;

&lt;span&gt;      &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;computeCost&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;costValue&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;cost&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;get&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;}&lt;/span&gt;
&lt;/span&gt;    &lt;span&gt;});&lt;/span&gt;

&lt;span&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;costValue&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;  &lt;span&gt;}&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, that’s it for the training phase. Now it needs only to be executed iteratively from the outside after the session setup with the training set. The outside execution can decide on a condition if the train method should return the cost.&lt;/p&gt;
&lt;h2 class=&quot;chapter-header&quot; id=&quot;inference-neural-network-javascript&quot;&gt;Inference Phase&lt;/h2&gt;
&lt;p&gt;The final stage is the &lt;strong&gt;inference phase&lt;/strong&gt; where a test set is used to validate the performance of the trained algorithm. The input is a color in RGB space for the background color and as output it should predict the classifier [ 0, 1 ] or [ 1, 0 ] for either black or white for the font color. Since the input data points were normalized, don’t forget to normalize the color in this step as well.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;  &lt;span&gt;predict&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;let&lt;/span&gt; &lt;span&gt;classifier&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[];&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;math&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;scope&lt;/span&gt;&lt;span&gt;(()&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;const&lt;/span&gt; &lt;span&gt;mapping&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;[{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;tensor&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;inputTensor&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;data&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;Array1D&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;normalizeColor&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;)),&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;}];&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;classifier&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;session&lt;/span&gt;&lt;span&gt;.eval(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;predictionTensor&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;mapping&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;span&gt;getValues&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;});&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;...&lt;/span&gt;&lt;span&gt;classifier&lt;/span&gt; &lt;span&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;  &lt;span&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;&lt;span&gt;}&lt;/span&gt;
&lt;/span&gt;
&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The method run the performance critical parts in the math context again. There it needs to define a mapping that will end up as input for the session evaluation. Keep in mind, that the predict method doesn’t need to run strictly after the training phase. It can be used during the training phase to output validations of the test set.&lt;/p&gt;
&lt;p&gt;Ultimately the neural network is implemented for setup, training and inference phase.&lt;/p&gt;
&lt;h2 class=&quot;chapter-header&quot; id=&quot;neural-network-visualization-javascript&quot;&gt;Visualize a learning Neural Network in JavaScript&lt;/h2&gt;
&lt;p&gt;Now it’s about time using the neural network to train it with a training set in the training phase and validate the predictions in the inference phase with a test set. In its simplest form, you would set up the neural network, run the training phase with a training set, validate over the time of training the minimizing cost and finally predict a couple of data points with a test set. All of it would happen on the developer console in the web browser with a couple of console.log statements. However, since the neural network is about color prediction and deeplearn.js runs in the browser anyway, it would be much more enjoyable to visualize the training phase and inference phase of the neural network.&lt;/p&gt;
&lt;p&gt;At this point, you can decide on your own how to visualize the phases of your performing neural network. It can be plain JavaScript by using a &lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API&quot;&gt;canvas&lt;/a&gt; and the &lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/window/requestAnimationFrame&quot;&gt;requestAnimationFrame&lt;/a&gt; API. But in the case of this article, I will demonstrate it by using &lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://reactjs.org/&quot;&gt;React.js&lt;/a&gt;, because I write about it on my blog as well.&lt;/p&gt;
&lt;p&gt;So after setting up the project with &lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/facebookincubator/create-react-app&quot;&gt;create-react-app&lt;/a&gt;, the App component will be our entry point for the visualization. First of all, import the neural network class and the functions to generate the data sets from your files. Moreover, add a couple of constants for the training set size, test set sizes and number of training iterations.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt; &lt;span&gt;React&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;Component&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;'react'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;import&lt;/span&gt; &lt;span&gt;'./App.css'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;generateColorSet&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;'./data'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;&lt;span&gt;import&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;'./neuralNetwork'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;
&lt;span&gt;&lt;span&gt;const&lt;/span&gt; &lt;span&gt;ITERATIONS&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;750&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;&lt;span&gt;const&lt;/span&gt; &lt;span&gt;TRAINING_SET_SIZE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;1500&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;&lt;span&gt;const&lt;/span&gt; &lt;span&gt;TEST_SET_SIZE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;10&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/span&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;App&lt;/span&gt; &lt;span&gt;extends&lt;/span&gt; &lt;span&gt;Component&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
  &lt;span&gt;...&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;App&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In the constructor of the App component, generate the data sets (training set, test set), setup the neural network session by passing in the training set, and define the initial local state of the component. Over the course of the training phase, the value for the cost and number of iterations will be displayed somewhere, so these are the properties which end up in the component state.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt; &lt;span&gt;React&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;Component&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;'react'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;import&lt;/span&gt; &lt;span&gt;'./App.css'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;import&lt;/span&gt; &lt;span&gt;generateColorSet&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;'./data'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;span&gt;import&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt; &lt;span&gt;from&lt;/span&gt; &lt;span&gt;'./neuralNetwork'&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;const&lt;/span&gt; &lt;span&gt;ITERATIONS&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;750&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;span&gt;const&lt;/span&gt; &lt;span&gt;TRAINING_SET_SIZE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;1500&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;span&gt;const&lt;/span&gt; &lt;span&gt;TEST_SET_SIZE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;10&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;class&lt;/span&gt; &lt;span&gt;App&lt;/span&gt; &lt;span&gt;extends&lt;/span&gt; &lt;span&gt;Component&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;testSet&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
  &lt;span&gt;colorAccessibilityModel&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

&lt;span&gt;  &lt;span&gt;constructor&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;super&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;testSet&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;generateColorSet&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;TEST_SET_SIZE&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;generateColorSet&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;TRAINING_SET_SIZE&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;colorAccessibilityModel&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; &lt;span&gt;ColorAccessibilityModel&lt;/span&gt;&lt;span&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;colorAccessibilityModel&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;setupSession&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;trainingSet&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;state&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;currentIteration&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;cost&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;-&lt;/span&gt;&lt;span&gt;42&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;};&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;  &lt;span&gt;}&lt;/span&gt;
&lt;/span&gt;
  &lt;span&gt;...&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;App&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next, after setting up the session of the neural network in the constructor, you could train the neural network iteratively. In a naive approach you would only need a for loop in a mounting component lifecycle hook of React.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;App&lt;/span&gt; &lt;span&gt;extends&lt;/span&gt; &lt;span&gt;Component&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

  &lt;span&gt;componentDidMount&lt;/span&gt; &lt;span&gt;()&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;for&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;let&lt;/span&gt; &lt;span&gt;i&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;i&lt;/span&gt; &lt;span&gt;&amp;lt;=&lt;/span&gt; &lt;span&gt;ITERATIONS&lt;/span&gt;&lt;span&gt;;&lt;/span&gt; &lt;span&gt;i&lt;/span&gt;&lt;span&gt;++&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
      &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;colorAccessibilityModel&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;train&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;i&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
    &lt;span&gt;}&lt;/span&gt;
  &lt;span&gt;};&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;App&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;However, it wouldn’t work to render an output during the training phase in React, because the component couldn’t re-render while the neural network blocks the single JavaScript thread. That’s where requestAnimationFrame can be used in React. Rather than defining a for loop statement ourselves, each requested animation frame of the browser can be used to run exactly one training iteration.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;App&lt;/span&gt; &lt;span&gt;extends&lt;/span&gt; &lt;span&gt;Component&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

&lt;span&gt;  &lt;span&gt;componentDidMount&lt;/span&gt; &lt;span&gt;()&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;requestAnimationFrame&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;tick&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;  &lt;span&gt;};&lt;/span&gt;
&lt;/span&gt;
&lt;span&gt;  &lt;span&gt;tick&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;()&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;setState&lt;/span&gt;&lt;span&gt;((&lt;/span&gt;&lt;span&gt;state&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;({&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;currentIteration&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;state&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;currentIteration&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;}));&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;state&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;currentIteration&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt; &lt;span&gt;ITERATIONS&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;requestAnimationFrame&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;tick&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;colorAccessibilityModel&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;train&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;state&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;currentIteration&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;    &lt;span&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;  &lt;span&gt;};&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;App&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In addition, the cost can be computed every 5th step. As mentioned, the GPU needs to be accessed to retrieve the cost. Thus it should be avoided to train the neural network faster.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;App&lt;/span&gt; &lt;span&gt;extends&lt;/span&gt; &lt;span&gt;Component&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

  &lt;span&gt;componentDidMount&lt;/span&gt; &lt;span&gt;()&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;requestAnimationFrame&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;tick&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
  &lt;span&gt;};&lt;/span&gt;

  &lt;span&gt;tick&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;()&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;setState&lt;/span&gt;&lt;span&gt;((&lt;/span&gt;&lt;span&gt;state&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;({&lt;/span&gt;
      &lt;span&gt;currentIteration&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;state&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;currentIteration&lt;/span&gt; &lt;span&gt;+&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;
    &lt;span&gt;}));&lt;/span&gt;

    &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;state&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;currentIteration&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt; &lt;span&gt;ITERATIONS&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
      &lt;span&gt;requestAnimationFrame&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;tick&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;

&lt;span&gt;      &lt;span&gt;let&lt;/span&gt; &lt;span&gt;computeCost&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;!&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;state&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;currentIteration&lt;/span&gt; &lt;span&gt;%&lt;/span&gt; &lt;span&gt;5&lt;/span&gt;&lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;let&lt;/span&gt; &lt;span&gt;cost&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;colorAccessibilityModel&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;train&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;state&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;currentIteration&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;computeCost&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;);&lt;/span&gt;
&lt;/span&gt;
&lt;span&gt;      &lt;span&gt;if&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;cost&lt;/span&gt; &lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;        &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;setState&lt;/span&gt;&lt;span&gt;(()&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt; &lt;span&gt;({&lt;/span&gt; &lt;span&gt;cost&lt;/span&gt; &lt;span&gt;}));&lt;/span&gt;
&lt;/span&gt;&lt;span&gt;      &lt;span&gt;}&lt;/span&gt;
&lt;/span&gt;    &lt;span&gt;}&lt;/span&gt;
  &lt;span&gt;};&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;App&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The training phase is running once the component mounted. Now it is about rendering the test set with the programmatically computed output and the predicted output. Over time, the predicted output should be the same as the programmatically computed output. The training set itself is never visualized.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt; &lt;span&gt;App&lt;/span&gt; &lt;span&gt;extends&lt;/span&gt; &lt;span&gt;Component&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;

  &lt;span&gt;...&lt;/span&gt;

  &lt;span&gt;render&lt;/span&gt;&lt;span&gt;()&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;
    &lt;span&gt;const&lt;/span&gt; &lt;span&gt;{&lt;/span&gt; &lt;span&gt;currentIteration&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;cost&lt;/span&gt; &lt;span&gt;}&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;state&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;

    &lt;span&gt;return&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;className&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&quot;app&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
          &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;h1&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;Neural&lt;/span&gt; &lt;span&gt;Network&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; &lt;span&gt;Font&lt;/span&gt; &lt;span&gt;Color&lt;/span&gt; &lt;span&gt;Accessibility&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/h1&amp;gt;&lt;/span&gt;
          &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;p&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;Iterations&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;currentIteration&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/p&amp;gt;&lt;/span&gt;
          &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;p&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;Cost&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;{&lt;/span&gt;&lt;span&gt;cost&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/p&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/div&amp;gt;&lt;/span&gt;

        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;className&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&quot;content&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
          &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;className&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&quot;content-item&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;ActualTable&lt;/span&gt;
              &lt;span&gt;testSet&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;testSet&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;
            &lt;span&gt;/&amp;gt;&lt;/span&gt;
          &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/div&amp;gt;&lt;/span&gt;

          &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;className&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&quot;content-item&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;InferenceTable&lt;/span&gt;
              &lt;span&gt;model&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;colorAccessibilityModel&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;
              &lt;span&gt;testSet&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;testSet&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;
            &lt;span&gt;/&amp;gt;&lt;/span&gt;
          &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/div&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/div&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/div&amp;gt;&lt;/span&gt;
    &lt;span&gt;);&lt;/span&gt;
  &lt;span&gt;}&lt;/span&gt;
&lt;span&gt;}&lt;/span&gt;

&lt;span&gt;const&lt;/span&gt; &lt;span&gt;ActualTable&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;({&lt;/span&gt; &lt;span&gt;testSet&lt;/span&gt; &lt;span&gt;})&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;p&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;Programmatically&lt;/span&gt; &lt;span&gt;Computed&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/p&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/div&amp;gt;&lt;/span&gt;

&lt;span&gt;const&lt;/span&gt; &lt;span&gt;InferenceTable&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;({&lt;/span&gt; &lt;span&gt;testSet&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;model&lt;/span&gt; &lt;span&gt;})&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;p&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;Neural&lt;/span&gt; &lt;span&gt;Network&lt;/span&gt; &lt;span&gt;Computed&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/p&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/div&amp;gt;&lt;/span&gt;

&lt;span&gt;export&lt;/span&gt; &lt;span&gt;default&lt;/span&gt; &lt;span&gt;App&lt;/span&gt;&lt;span&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The actual table iterates over the size of the test set size to display each color. The test set has the input colors (background colors) and output colors (font colors). Since the output colors are classified into black [ 0, 1 ] and white [ 1, 0 ] vectors when a data set is generated, they need to be transformed into actual colors again.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;const&lt;/span&gt; &lt;span&gt;ActualTable&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;({&lt;/span&gt; &lt;span&gt;testSet&lt;/span&gt; &lt;span&gt;})&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;p&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;Programmatically&lt;/span&gt; &lt;span&gt;Computed&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/p&amp;gt;&lt;/span&gt;

    &lt;span&gt;{Array(&lt;/span&gt;&lt;span&gt;TEST_SET_SIZE&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;span&gt;fill&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;span&gt;map&lt;/span&gt;&lt;span&gt;((&lt;/span&gt;&lt;span&gt;v&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;i&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;ColorBox&lt;/span&gt;
        &lt;span&gt;key&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;i&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;
        &lt;span&gt;rgbInput&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;testSet&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;rawInputs&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;i&lt;/span&gt;&lt;span&gt;]}&lt;/span&gt;
        &lt;span&gt;rgbTarget&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;fromClassifierToRgb&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;testSet&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;rawTargets&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;i&lt;/span&gt;&lt;span&gt;])}&lt;/span&gt;
      &lt;span&gt;/&amp;gt;&lt;/span&gt;
    &lt;span&gt;)}&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/div&amp;gt;&lt;/span&gt;

&lt;span&gt;const&lt;/span&gt; &lt;span&gt;fromClassifierToRgb&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;classifier&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt;
  &lt;span&gt;classifier&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]&lt;/span&gt; &lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;classifier&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;
    &lt;span&gt;?&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;255&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;255&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;255&lt;/span&gt; &lt;span&gt;]&lt;/span&gt;
    &lt;span&gt;:&lt;/span&gt; &lt;span&gt;[&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;0&lt;/span&gt; &lt;span&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The ColorBox component is a generic component which takes the input color (background color) and target color (font color). It simply displays a rectangle with the input color style, the RGB code of the input color as string and styles the font of the RGB code into the given target color.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;const&lt;/span&gt; &lt;span&gt;ColorBox&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;({&lt;/span&gt; &lt;span&gt;rgbInput&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;rgbTarget&lt;/span&gt; &lt;span&gt;})&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div&lt;/span&gt; &lt;span&gt;className&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&quot;color-box&quot;&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;{{&lt;/span&gt; &lt;span&gt;backgroundColor&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;getRgbStyle&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;rgbInput&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;}}&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;span&lt;/span&gt; &lt;span&gt;style&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;{{&lt;/span&gt; &lt;span&gt;color&lt;/span&gt;&lt;span&gt;:&lt;/span&gt; &lt;span&gt;getRgbStyle&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;rgbTarget&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;}}&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;RgbString&lt;/span&gt; &lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;rgbInput&lt;/span&gt;&lt;span&gt;}&lt;/span&gt; &lt;span&gt;/&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/span&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/div&amp;gt;&lt;/span&gt;

&lt;span&gt;const&lt;/span&gt; &lt;span&gt;RgbString&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;({&lt;/span&gt; &lt;span&gt;rgb&lt;/span&gt; &lt;span&gt;})&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt;
  &lt;span&gt;`rgb(&lt;/span&gt;&lt;span&gt;${&lt;/span&gt;&lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;toString&lt;/span&gt;&lt;span&gt;()&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;span&gt;)`&lt;/span&gt;

&lt;span&gt;const&lt;/span&gt; &lt;span&gt;getRgbStyle&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;(&lt;/span&gt;&lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt;
  &lt;span&gt;`rgb(&lt;/span&gt;&lt;span&gt;${&lt;/span&gt;&lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;&lt;span&gt;${&lt;/span&gt;&lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;1&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;&lt;span&gt;${&lt;/span&gt;&lt;span&gt;rgb&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;&lt;span&gt;)`&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Last but not least, the exciting part of visualizing the predicted colors in the inference table. It uses the color box as well, but gives a different set of props into it.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;
&lt;span&gt;const&lt;/span&gt; &lt;span&gt;InferenceTable&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;({&lt;/span&gt; &lt;span&gt;testSet&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;model&lt;/span&gt; &lt;span&gt;})&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;p&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;Neural&lt;/span&gt; &lt;span&gt;Network&lt;/span&gt; &lt;span&gt;Computed&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/p&amp;gt;&lt;/span&gt;
    &lt;span&gt;{Array(&lt;/span&gt;&lt;span&gt;TEST_SET_SIZE&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;span&gt;fill&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;0&lt;/span&gt;&lt;span&gt;).&lt;/span&gt;&lt;span&gt;map&lt;/span&gt;&lt;span&gt;((&lt;/span&gt;&lt;span&gt;v&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;i&lt;/span&gt;&lt;span&gt;)&lt;/span&gt; &lt;span&gt;=&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;ColorBox&lt;/span&gt;
        &lt;span&gt;key&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;i&lt;/span&gt;&lt;span&gt;}&lt;/span&gt;
        &lt;span&gt;rgbInput&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;testSet&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;rawInputs&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;i&lt;/span&gt;&lt;span&gt;]}&lt;/span&gt;
        &lt;span&gt;rgbTarget&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;{&lt;/span&gt;&lt;span&gt;fromClassifierToRgb&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;model&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;predict&lt;/span&gt;&lt;span&gt;(&lt;/span&gt;&lt;span&gt;testSet&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;rawInputs&lt;/span&gt;&lt;span&gt;[&lt;/span&gt;&lt;span&gt;i&lt;/span&gt;&lt;span&gt;]))}&lt;/span&gt;
      &lt;span&gt;/&amp;gt;&lt;/span&gt;
    &lt;span&gt;)}&lt;/span&gt;
  &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;/div&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The input color is still the color defined in the test set. But the target color isn’t the target color from the test set. The crucial part is that the target color is predicted in this component by using the neural network’s predict method. It takes the input color and should predict the target color over the course of the training phase.&lt;/p&gt;
&lt;p&gt;Finally, when you start your application, you should see the neural network in action. Whereas the actual table uses the fixed test set from the beginning, the inference table should change its font colors during the training phase. In fact, while the ActualTable component shows the actual test set, the InferenceTable shows the input data points of the test set, but the predicted output by using the neural network. The React rendered part can be seen in the &lt;a target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot; href=&quot;https://github.com/javascript-machine-learning/color-accessibility-neural-network-deeplearnjs&quot;&gt;GitHub repository&lt;/a&gt; animation too.&lt;/p&gt;
&lt;hr class=&quot;section-divider&quot;/&gt;&lt;p&gt;The article has shown you how deeplearn.js can be used to build neural networks in JavaScript for machine learning. If you have any recommendation for improvements, please leave a comment below. In addition, I am curious whether you are interested in the crossover of machine learning and JavaScript. If that’s is the case, I would write more about it.&lt;/p&gt;
&lt;p&gt;Furthermore, I would love to get more into the topic and I am open for opportunities in the field of machine learning. At the moment, I apply my learnings in JavaScript, but I am so keen to get into Python at some point as well. So if you know about any opportunities in the field, please reach out to me :-)&lt;/p&gt;
&lt;div class=&quot;feedback-and-share text-center&quot;&gt;
&lt;hr/&gt;&lt;p class=&quot;lead&quot;&gt;I would like to hear your thoughts :-) Find me on &lt;a target=&quot;_blank&quot; href=&quot;https://twitter.com/rwieruch&quot;&gt;Twitter&lt;/a&gt; and &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/rwieruch&quot;&gt;GitHub&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;lead&quot;&gt;Did the article help you? You can share it with your friends on social media , support me on &lt;a target=&quot;_blank&quot; href=&quot;https://www.patreon.com/rwieruch&quot;&gt;Patreon&lt;/a&gt; or take one of my courses&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;box-inline col-md-12&quot;&gt;
&lt;div class=&quot;col-md-12 text-center&quot;&gt;
&lt;h2 class=&quot;newsletter&quot;&gt;The Road to learn React&lt;/h2&gt;
&lt;div class=&quot;col-md-4&quot;&gt;&lt;img class=&quot;img-lazy img-responsive&quot; data-lazy-src=&quot;https://www.robinwieruch.de/img/page/cover.png&quot;/&gt;&lt;/div&gt;
&lt;p class=&quot;lead&quot;&gt;Build a Hacker News App along the way. No setup configuration. No tooling. No Redux. Plain React in 190+ pages of learning material. Learn React like &lt;strong&gt;14.500+ readers&lt;/strong&gt;.&lt;/p&gt;
&lt;a class=&quot;btn btn-template-main&quot; href=&quot;https://www.getrevue.co/profile/rwieruch&quot;&gt;Get the Book &lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Tue, 05 Dec 2017 20:19:00 +0000</pubDate>
<dc:creator>rwieruch</dc:creator>
<og:title>Neural Networks in JavaScript with deeplearn.js - RWieruch</og:title>
<og:description>A tutorial on how to implement a neural network in JavaScript with deeplearn.js to perform machine learning in JavaScript ...</og:description>
<og:type>website</og:type>
<og:url>https://www.robinwieruch.de/neural-networks-deeplearnjs-javascript/</og:url>
<og:image>https://www.robinwieruch.de/img/posts/neural-networks-deeplearnjs-javascript/banner_640.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.robinwieruch.de/neural-networks-deeplearnjs-javascript/</dc:identifier>
</item>
<item>
<title>Microsoft launches Windows 10 on ARM</title>
<link>https://www.anandtech.com/show/12119/microsoft-launches-windows-10-on-arm-always-connected-pcs</link>
<guid isPermaLink="true" >https://www.anandtech.com/show/12119/microsoft-launches-windows-10-on-arm-always-connected-pcs</guid>
<description>[unable to retrieve full-text content]&lt;p&gt;Article URL: &lt;a href=&quot;https://www.anandtech.com/show/12119/microsoft-launches-windows-10-on-arm-always-connected-pcs&quot;&gt;https://www.anandtech.com/show/12119/microsoft-launches-windows-10-on-arm-always-connected-pcs&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=15855195&quot;&gt;https://news.ycombinator.com/item?id=15855195&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Points: 331&lt;/p&gt;&lt;p&gt;# Comments: 205&lt;/p&gt;
&lt;hr&gt;&lt;p&gt;hnrss is a labor of love, but if the project has made your job
or hobby project easier and you want to show some gratitude, &lt;a
href=&quot;https://donate.hnrss.org/&quot;&gt;donations are very much
appreciated&lt;/a&gt;. PayPal and Bitcoin both accepted. Thanks!&lt;/p&gt;
        </description>
<pubDate>Tue, 05 Dec 2017 19:55:06 +0000</pubDate>
<dc:creator>OberstKrueger</dc:creator>
<dc:identifier>https://www.anandtech.com/show/12119/microsoft-launches-windows-10-on-arm-always-connected-pcs</dc:identifier>
</item>
<item>
<title>The FastMail Security Mindset</title>
<link>https://blog.fastmail.com/2017/12/05/the-fastmail-security-mindset/</link>
<guid isPermaLink="true" >https://blog.fastmail.com/2017/12/05/the-fastmail-security-mindset/</guid>
<description>&lt;p class=&quot;blog-author&quot;&gt;Neil Jenkins – 5 December 2017&lt;/p&gt;
&lt;p&gt;This is the fifth post in the &lt;a href=&quot;https://blog.fastmail.com/2017/12/01/fastmail-advent-2017/&quot;&gt;2017 FastMail Advent Calendar&lt;/a&gt;. The previous post was about &lt;a href=&quot;https://blog.fastmail.com/2017/12/04/calconnect/&quot;&gt;what we are up to at CalConnect&lt;/a&gt;. The next post is an example of our philosophy in action with a look at our revamp of &lt;a href=&quot;https://blog.fastmail.com/2017/12/06/security-account-recovery/&quot;&gt;2FA, passwords and recovery&lt;/a&gt;.&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;“Security” is a word that gets bandied around a lot in the IT world, often with little actual thought or substance behind its use. The phrase “we take your privacy and security seriously” is &lt;a href=&quot;https://krebsonsecurity.com/2014/09/we-take-your-privacy-and-security-seriously/&quot;&gt;the preamble to many a mea culpa&lt;/a&gt; from companies who, frankly, didn’t.&lt;/p&gt;
&lt;p&gt;FastMail has always been an engineering-focused company, from the top down. As such there is a strong culture of no-bullshit, and an intense dislike of &lt;a href=&quot;https://www.schneier.com/essays/archives/2009/11/beyond_security_thea.html&quot;&gt;security theatre&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Our approach to security is to proactively develop and adopt any measures which meaningfully improve the &lt;a href=&quot;https://blog.fastmail.com/2014/12/15/security-confidentiality/&quot;&gt;confidentiality&lt;/a&gt;, &lt;a href=&quot;https://blog.fastmail.com/2014/12/10/security-availability/&quot;&gt;availability&lt;/a&gt; or &lt;a href=&quot;https://blog.fastmail.com/2014/12/05/security-integrity/&quot;&gt;integrity&lt;/a&gt; of our customer’s data. We are not interested in implementing things that sound good in marketing spiel but don’t actually help, or may even actively hurt, our customers’ security. We also strongly believe that usability is part of security; we need to make it easy to stay safe, hard to get wrong, in order to be secure.&lt;/p&gt;
&lt;p&gt;As an example of this mindset, we were one of the early adopters of opportunistic TLS encryption of SMTP connections when &lt;a href=&quot;https://blog.fastmail.com/2010/01/29/opportunistic-ssltls-encryption-on-outgoing-emails/&quot;&gt;sending&lt;/a&gt; and &lt;a href=&quot;https://blog.fastmail.com/2009/04/16/opportunistic-ssltls-encryption-on-incoming-emails/&quot;&gt;receiving&lt;/a&gt; mail. This prevents passive man-in-the-middle attacker from snooping on your data, making mass surveillance much harder.&lt;/p&gt;
&lt;p&gt;This even protects interception of metadata; someone watching our outbound connections might just know FastMail connected to Gmail, for example. There’s a lot of email sent between us by many different users, so observing this connection would not leak much information. (Interestingly this is where there is safety in numbers: if you and your intended recipient both hosted your own email on individual servers, then encrypting the connection doesn’t really hide who the message is from or to!)&lt;/p&gt;
&lt;p&gt;Supporting encrypted SMTP meaningfully improved the confidentiality of our customer’s data, without impacting our users’ workflow. And there’s still more we can do in this area! Initiatives like &lt;a href=&quot;https://tools.ietf.org/html/draft-ietf-uta-mta-sts-11&quot;&gt;MTA-STS&lt;/a&gt; will allow us to further protect against active man-in-the-middle attacks on mail delivery, and all without impacting usability.&lt;/p&gt;
&lt;p&gt;Just as important as what we &lt;em&gt;do&lt;/em&gt; do is what we &lt;em&gt;don’t&lt;/em&gt;. For example, we don’t do full message encryption (e.g. PGP) in the browser. In theory it means you “don’t have to trust us”. However in reality, every time you open your email you would be trusting the code delivered to your browser. If the server were compromised, it could easily be made to return code that intercepted and sent back your password next time you logged in; it could even just do this for specific users. It is very unlikely that a user would notice.&lt;/p&gt;
&lt;p&gt;We therefore don’t believe this offers a meaningful increase in security, and can be actively harmful in a number of ways. It reduces availability, because if you forget your password we cannot help you recover access to your own mail. It makes phishing (by far the biggest cause of compromised accounts) much harder to filter out.&lt;/p&gt;
&lt;p&gt;It can also be seriously dangerous when users misunderstand the security characteristics. For example, if you were a journalist working undercover in certain countries, you may justifiably require secure, anonymous communication. “Encrypted email” sounds like just the thing you need. But if your mail host doesn’t &lt;a href=&quot;https://blog.fastmail.com/2014/09/16/better-security-and-privacy-through-image-proxying/&quot;&gt;proxy images to hide your IP&lt;/a&gt;, someone could simply send you a message which when opened made your device connect directly to their servers. This reveals your IP address, which can often be used to fairly precisely determine your location, and sends cookies that may allow them to correlate your email address with visits to other sites on the web. That’s a &lt;em&gt;much&lt;/em&gt; bigger risk.&lt;/p&gt;
&lt;p&gt;Ultimately, security is a process, not a checkbox. We are always looking for further measures that will help secure our customer’s sensitive data. But we don’t do stuff just to check a marketing box. It may lose us a few customers enticed by razzle-dazzle claims, but we feel better about the integrity of our service.&lt;/p&gt;


</description>
<pubDate>Tue, 05 Dec 2017 17:32:49 +0000</pubDate>
<dc:creator>DASD</dc:creator>
<og:image>https://www.fastmail.com/static/images/app-icon-256.png</og:image>
<og:type>website</og:type>
<og:title>The FastMail Security Mindset | FastMail Blog</og:title>
<og:description>This is the fifth post in the 2017 FastMail Advent Calendar. The previous post was about what we are up to at CalConnect. The next post is an example of our philosophy in action with a look at our revamp of 2FA, passwords and recovery.</og:description>
<og:url>https://blog.fastmail.com/2017/12/05/the-fastmail-security-mindset/</og:url>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.fastmail.com/2017/12/05/the-fastmail-security-mindset/</dc:identifier>
</item>
<item>
<title>AMA: NY AG Schneiderman on net neutrality and protecting our voice in government</title>
<link>https://news.ycombinator.com/item?id=15853374</link>
<guid isPermaLink="true" >https://news.ycombinator.com/item?id=15853374</guid>
<description>Hey everyone, New York AG Eric Schneiderman here.
&lt;p&gt;For the last 6 months, my office has been investigating a flood of fake comments that corrupted the FCC’s net neutrality comment process. Approximately 1 million of those comments may have been submitted using real people’s stolen identities--including those of as many as 50K New Yorkers, such as a dead person and a 13 year old child. This is akin to identity theft on a massive scale, and it undermines the public’s right to be heard at the most basic level of our government’s rulemaking.&lt;/p&gt;&lt;p&gt;Yesterday, FCC Commissioner Jessica Rosenworcel and I held a press conference to update on my office’s investigation and called on the FCC to delay its net neutrality vote until we can get to the bottom of it. In an era where foreign governments have indisputably tried to use the internet and social media to influence our elections, federal &amp;amp; state governments should be working together to ensure that malevolent actors cannot subvert our administrative agencies’ decision-making processes. You can watch our full press conference here: &lt;a href=&quot;https://youtu.be/TtZEC21QN-c&quot; rel=&quot;nofollow&quot;&gt;https://youtu.be/TtZEC21QN-c&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I’ll be back this afternoon to take your questions!&lt;/p&gt;
&lt;p&gt;In the meantime, a few things you can do to help in this fight:&lt;/p&gt;
&lt;p&gt;1. My office requested help in our investigation from the FCC at least 9 times, but the FCC’s Chairman and his staff responded by stonewalling (yesterday, the FCC’s IG finally indicated they may assist with our investigation). So we’ve gone to the public. My office has set up a website for you to check whether your name was used to submit fake comments, &amp;amp; file a report if it was: &lt;a href=&quot;https://ag.ny.gov/fakecomments&quot; rel=&quot;nofollow&quot;&gt;https://ag.ny.gov/fakecomments&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;2. While FCC Chairman Pai has declared his intention to roll back net neutrality, we can still beat this effort back in Congress. If you haven't already spoken to your representatives, please do it today. You can contact your Senators and Congresspeople through the Capitol switchboard at (202) 224-3121.&lt;/p&gt;
&lt;p&gt;Thanks all. Keep speaking out.&lt;/p&gt;
</description>
<pubDate>Tue, 05 Dec 2017 17:25:04 +0000</pubDate>
<dc:creator>AGSchneiderman</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://news.ycombinator.com/item?id=15853374</dc:identifier>
</item>
<item>
<title>CryptoKitties craze slows down transactions on Ethereum</title>
<link>http://www.bbc.co.uk/news/technology-42237162</link>
<guid isPermaLink="true" >http://www.bbc.co.uk/news/technology-42237162</guid>
<description>&lt;figure class=&quot;media-landscape no-caption full-width lead&quot;&gt;&lt;span class=&quot;image-and-copyright-container&quot;&gt;
                
                &lt;img class=&quot;js-image-replace&quot; alt=&quot;Cartoon cats&quot; src=&quot;https://ichef-1.bbci.co.uk/news/320/cpsprodpb/D468/production/_99067345_share.png&quot; width=&quot;976&quot; height=&quot;549&quot;/&gt;&lt;span class=&quot;off-screen&quot;&gt;Image copyright&lt;/span&gt;
                 &lt;span class=&quot;story-image-copyright&quot;&gt;www.cryptokitties.co&lt;/span&gt;
                
            &lt;/span&gt;
            
        &lt;/figure&gt;&lt;p class=&quot;story-body__introduction&quot;&gt;A new craze for virtual kittens is slowing down trade in one of the largest crypto-currencies.  &lt;/p&gt;&lt;p&gt;CryptoKitties lets players buy and breed &quot;crypto-pets&quot; on Ethereum's underlying blockchain network. &lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.bloomberg.com/news/articles/2017-12-04/cryptokitties-quickly-becomes-most-widely-used-ethereum-app?utm_source=t.co&amp;amp;utm_medium=referral&quot; class=&quot;story-body__link-external&quot;&gt;The game's developers told the Bloomberg news agency&lt;/a&gt; that CryptoKitties was a &quot;key step&quot; to making blockchains more accessible. &lt;/p&gt;&lt;p&gt;But its popularity has underscored one of the technology's biggest downsides: its lack of scalability.  &lt;/p&gt;&lt;p&gt;Etherscan has reported &lt;a href=&quot;https://etherscan.io/chart/pendingtx&quot; class=&quot;story-body__link-external&quot;&gt;a sixfold increase&lt;/a&gt; in pending transactions on Ethereum since the game's release, by the Axiom Zen innovation studio, on 28 November. &lt;/p&gt;&lt;p&gt;&quot;CryptoKitties has become so popular that it's taking up a significant amount of available space for transactions on the Ethereum platform,&quot; said Garrick Hileman, from the Cambridge Centre for Alternative Finance.&lt;/p&gt;&lt;p&gt;&quot;Some people are concerned that a frivolous game is now going to be crowding out more serious, significant-seeming business uses.&quot;  &lt;/p&gt;&lt;p&gt;An estimated $4.5m (£3.35m) has been spent on the cartoon cats at the time of writing, according to &lt;a href=&quot;https://kittysales.herokuapp.com/&quot; class=&quot;story-body__link-external&quot;&gt;Crypto Kitty Sales&lt;/a&gt;.&lt;/p&gt;&lt;figure class=&quot;media-landscape has-caption full-width&quot;&gt;&lt;span class=&quot;image-and-copyright-container&quot;&gt;
                
                
                
                
                
                 &lt;span class=&quot;off-screen&quot;&gt;Image copyright&lt;/span&gt;
                 &lt;span class=&quot;story-image-copyright&quot;&gt;www.cryptokitties.co&lt;/span&gt;
                
            &lt;/span&gt;
            
            &lt;figcaption class=&quot;media-caption&quot;&gt;&lt;span class=&quot;off-screen&quot;&gt;Image caption&lt;/span&gt;
                &lt;span class=&quot;media-caption__text&quot;&gt;
                    CryptoKitties is the first game built on Ethereum
                &lt;/span&gt;
            &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;What is a CryptoKitty?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Think of these rather unpalatable cartoon kittens as unique digital Pokemon cards. The game's developers describe them as &quot;breedable Beanie Babies&quot;, each with its own unique 256-bit genome.  &lt;/p&gt;&lt;p&gt;These crypto-collectibles are also gender-fluid, able to play the role of either the &quot;dame&quot; or the &quot;sire&quot; when bred together. The kitties' unique DNA can lead to four billion possible genetic variations. &lt;/p&gt;&lt;p&gt;Some of the varieties created so far look lifelike, with grey striped fur and bulging green eyes. Others are speckled with neon-blue spots or magenta-patterned swirls. &lt;/p&gt;&lt;figure class=&quot;media-landscape has-caption full-width&quot;&gt;&lt;span class=&quot;image-and-copyright-container&quot;&gt;
                
                
                
                
                
                 &lt;span class=&quot;off-screen&quot;&gt;Image copyright&lt;/span&gt;
                 &lt;span class=&quot;story-image-copyright&quot;&gt;www.cryptokitties.co&lt;/span&gt;
                
            &lt;/span&gt;
            
            &lt;figcaption class=&quot;media-caption&quot;&gt;&lt;span class=&quot;off-screen&quot;&gt;Image caption&lt;/span&gt;
                &lt;span class=&quot;media-caption__text&quot;&gt;
                    One of the less attractive CryptoKitties
                &lt;/span&gt;
            &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;How much are CryptoKitties worth?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;At the time of writing, the median, or mid-range, price of a CryptoKitty is approximately $23.06 (£17.19), according to Crypto Kitty Sales.&lt;/p&gt;&lt;p&gt;The game's top cat brought in $117,712.12 (£87,686.11) when it sold on Saturday, 2 December. &lt;/p&gt;&lt;p&gt;&lt;strong&gt;How can I  pay for my own litter?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;CryptoKitties can be bought using only Ether, a crypto-currency that acts as the fuel of the Ethereum blockchain network. &lt;/p&gt;&lt;p&gt;To get started, users must install a Chrome extension called MetaMask, which acts as a digital wallet and lets players send and receive Ether from their computers. &lt;/p&gt;&lt;p&gt;Ether must be purchased from a crypto-currency exchange before it can be added to MetaMask.  &lt;/p&gt;&lt;figure class=&quot;media-landscape has-caption full-width&quot;&gt;&lt;span class=&quot;image-and-copyright-container&quot;&gt;
                
                
                
                
                
                 &lt;span class=&quot;off-screen&quot;&gt;Image copyright&lt;/span&gt;
                 &lt;span class=&quot;story-image-copyright&quot;&gt;www.cryptokitties.co&lt;/span&gt;
                
            &lt;/span&gt;
            
            &lt;figcaption class=&quot;media-caption&quot;&gt;&lt;span class=&quot;off-screen&quot;&gt;Image caption&lt;/span&gt;
                &lt;span class=&quot;media-caption__text&quot;&gt;
                    The sale page for a CryptoKitty
                &lt;/span&gt;
            &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Where do the CryptoKitties come from?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Axiom Zen releases a new CryptoKitty every 15 minutes, but the rest of the supply is powered by the breeding of existing crypto-pets.  Owners of kittens can put them up for sale and set their own price in ethers.  &lt;/p&gt;&lt;p&gt;&lt;strong&gt;Why does it matter if CryptoKitties is slowing down Ethereum?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;According to ETH Gas Station, the CryptoKitties game accounts for over 10% of network traffic on Ethereum. As traffic increases, transactions become more expensive to execute quickly. &lt;/p&gt;&lt;p&gt;&quot;The real big issue is other major players looking for alternatives to Ethereum and moving to different systems,&quot; Mr Hileman said.  &lt;/p&gt;&lt;p&gt;&quot;There's definitely an urgency for Ethereum to try and address this issue.&quot;&lt;/p&gt;
    </description>
<pubDate>Tue, 05 Dec 2017 17:16:55 +0000</pubDate>
<dc:creator>scaryclam</dc:creator>
<og:title>CryptoKitties cripple Ethereum blockchain</og:title>
<og:type>article</og:type>
<og:description>A new craze for &quot;crypto-collectibles&quot; slows down transactions on the popular blockchain.</og:description>
<og:url>http://www.bbc.co.uk/news/technology-42237162</og:url>
<og:image>https://ichef-1.bbci.co.uk/news/1024/cpsprodpb/D468/production/_99067345_share.png</og:image>
<dc:language>en-GB</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.bbc.co.uk/news/technology-42237162</dc:identifier>
</item>
<item>
<title>Parcel – A fast, zero configuration web application bundler</title>
<link>https://parceljs.org/</link>
<guid isPermaLink="true" >https://parceljs.org/</guid>
<description>&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;/&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;/&gt;&lt;title&gt;📦 Parcel&lt;/title&gt;&lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; href=&quot;assets/hljs-github.min.css&quot;/&gt;&lt;/head&gt;&lt;body id=&quot;readabilityBody&quot; readability=&quot;28.99484004128&quot;&gt;
&lt;header&gt;&lt;img class=&quot;logo&quot; src=&quot;https://parceljs.org/assets/logo.svg&quot; alt=&quot;Parcel&quot;/&gt;&lt;h2&gt;Blazing fast, zero configuration web application bundler&lt;/h2&gt;
&lt;div class=&quot;parcel&quot;&gt;&lt;img src=&quot;https://parceljs.org/assets/parcel-back.png&quot; srcset=&quot;assets/parcel-back@2x.png 2x, assets/parcel-back@3x.png 3x&quot;/&gt;
&lt;img src=&quot;https://parceljs.org/assets/parcel-front.png&quot; srcset=&quot;assets/parcel-front@2x.png 2x, assets/parcel-front@3x.png 3x&quot;/&gt;&lt;/div&gt;
&lt;a class=&quot;button get-started&quot; href=&quot;https://parceljs.org/getting_started.html&quot;&gt;Get Started&lt;/a&gt; &lt;a class=&quot;button&quot; href=&quot;https://github.com/parcel-bundler/parcel&quot; target=&quot;_blank&quot;&gt;Github&lt;/a&gt;
&lt;nav class=&quot;links&quot;&gt;&lt;a href=&quot;https://parceljs.org/getting_started.html&quot;&gt;Documentation&lt;/a&gt; &lt;a href=&quot;https://github.com/parcel-bundler/parcel&quot; target=&quot;_blank&quot;&gt;Github&lt;/a&gt;&lt;/nav&gt;&lt;/header&gt;&lt;div class=&quot;features&quot; readability=&quot;18&quot;&gt;
&lt;section readability=&quot;4&quot;&gt;&lt;h3&gt;🚀 Blazing fast bundle times&lt;/h3&gt;
&lt;p&gt;Parcel uses worker processes to enable multicore compilation, and has a filesystem cache for fast rebuilds even after a restart.&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;6&quot;&gt;&lt;h3&gt;📦 Bundle all your assets&lt;/h3&gt;
&lt;p&gt;Parcel has out of the box support for JS, CSS, HTML, file assets, and more - no plugins needed.&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;5&quot;&gt;&lt;h3&gt;🐠 Automatic transforms&lt;/h3&gt;
&lt;p&gt;Code is automatically transformed using Babel, PostCSS, and PostHTML when needed - even &lt;code&gt;node_modules&lt;/code&gt;.&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;4&quot;&gt;&lt;h3&gt;✂️ Zero config code splitting&lt;/h3&gt;
&lt;p&gt;Using the dynamic &lt;code&gt;import()&lt;/code&gt; syntax, Parcel splits your output bundles so you only load what is needed on initial load.&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;4&quot;&gt;&lt;h3&gt;🔥 Hot module replacement&lt;/h3&gt;
&lt;p&gt;Parcel automatically updates modules in the browser as you make changes during development, no configuration needed.&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;3&quot;&gt;&lt;h3&gt;🚨 Friendly error logging&lt;/h3&gt;
&lt;p&gt;Parcel prints syntax highlighted code frames when it encounters errors to help you pinpoint the problem.&lt;/p&gt;
&lt;/section&gt;&lt;/div&gt;
&lt;section readability=&quot;9&quot;&gt;&lt;h2&gt;Hello World&lt;/h2&gt;
&lt;p&gt;Start with the entry HTML file for your application. Parcel follows the dependencies from there to build your whole app.&lt;/p&gt;
&lt;div class=&quot;examples&quot; readability=&quot;9&quot;&gt;
&lt;div class=&quot;example&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;✏️ index.html&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;
&lt;code&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;html&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;body&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;script&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;src&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;./index.js&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;script&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;body&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;html&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;example&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;🛠 index.js&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;
&lt;code&gt;
&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; main &lt;span class=&quot;hljs-keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;hljs-string&quot;&gt;'./main'&lt;/span&gt;;

main();&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;example&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;🛠 main.js&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;
&lt;code&gt;
&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; classes &lt;span class=&quot;hljs-keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;hljs-string&quot;&gt;'./main.css'&lt;/span&gt;;

&lt;span class=&quot;hljs-keyword&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;default&lt;/span&gt; () =&amp;gt; {
  &lt;span class=&quot;hljs-built_in&quot;&gt;console&lt;/span&gt;.log(classes.main);
};&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;example&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;💅 main.css&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;hljs&quot;&gt;
&lt;code&gt;&lt;span class=&quot;hljs-selector-class&quot;&gt;.main&lt;/span&gt; {
  
  &lt;span class=&quot;hljs-attribute&quot;&gt;background&lt;/span&gt;: &lt;span class=&quot;hljs-built_in&quot;&gt;url&lt;/span&gt;(&lt;span class=&quot;hljs-string&quot;&gt;'./images/background.png'&lt;/span&gt;);
  &lt;span class=&quot;hljs-attribute&quot;&gt;color&lt;/span&gt;: red;
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Just run &lt;code&gt;parcel index.html&lt;/code&gt; to start a dev server. Importing JavaScript, CSS, images, and more just works! 👌&lt;/p&gt;
&lt;/section&gt;&lt;section readability=&quot;5&quot;&gt;&lt;h2&gt;Benchmarks&lt;/h2&gt;
&lt;table&gt;&lt;tr&gt;&lt;th&gt;Bundler&lt;/th&gt;
&lt;th&gt;Time&lt;/th&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;browserify&lt;/td&gt;
&lt;td&gt;22.98s&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;webpack&lt;/td&gt;
&lt;td&gt;20.71s&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;parcel&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;9.98s&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;parcel - with cache&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;2.64s&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;&lt;p&gt;Based on a reasonably sized app, containing 1726 modules, 6.5M uncompressed. Built on a 2016 MacBook Pro with 4 physical CPUs.&lt;/p&gt;
&lt;/section&gt;&lt;footer readability=&quot;0.33636363636364&quot;&gt;&lt;a class=&quot;button&quot; href=&quot;https://parceljs.org/getting_started.html&quot;&gt;Get Started&lt;/a&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;nav&gt;&lt;h3&gt;Documentation&lt;/h3&gt;

&lt;/nav&gt;&lt;nav&gt;&lt;h3&gt;Links&lt;/h3&gt;
&lt;/nav&gt;&lt;/div&gt;
&lt;div class=&quot;copyright&quot; readability=&quot;5.6&quot;&gt;Copyright ©  Devon Govett. This website is &lt;a href=&quot;https://github.com/parcel-bundler/website&quot; target=&quot;_blank&quot;&gt;open source&lt;/a&gt;.&lt;/div&gt;
&lt;/footer&gt;&lt;/body&gt;</description>
<pubDate>Tue, 05 Dec 2017 17:05:24 +0000</pubDate>
<dc:creator>KeitIG</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://parceljs.org/</dc:identifier>
</item>
<item>
<title>Student Loan Debt Is Now as Big as the U.S. Junk Bond Market</title>
<link>https://www.bloomberg.com/news/articles/2017-12-05/student-loans-raise-other-risks-as-debt-equals-u-s-junk-market</link>
<guid isPermaLink="true" >https://www.bloomberg.com/news/articles/2017-12-05/student-loans-raise-other-risks-as-debt-equals-u-s-junk-market</guid>
<description>&lt;p&gt;U.S. student loan debt now equals the size of the $1.3 trillion U.S. high-yield corporate bond market, presenting investors with a whole different range of risks.&lt;/p&gt;

&lt;aside class=&quot;inline-newsletter&quot; data-state=&quot;ready&quot;/&gt;&lt;p&gt;“Delinquency rates on student loans are much higher than those on auto loans or mortgages, due to loose student loan underwriting standards, the unsecured nature of student debt, and the inability to charge off non-performing student loans in bankruptcy,” Goldman Sachs Group Inc. analysts Marty Young and Lotfi Karoui wrote in a note Tuesday. “The substantial majority of student loan default risk is borne by the U.S. Treasury.” &lt;/p&gt;

&lt;div class=&quot;image&quot;&gt;
&lt;div id=&quot;lazy-img-321218731&quot; class=&quot;lazy-img&quot;&gt;&lt;img src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i.uhYY0SLHkw/v2/60x-1.png&quot; data-native-src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i.uhYY0SLHkw/v2/-1x-1.png&quot; class=&quot;lazy-img__image&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;While the trend of rising defaults on student loans doesn’t pose “systemic financial risks,” it does impact household behavior as the debt load itself hurts home ownership rates, Young and Karoui said.&lt;/p&gt;


&lt;p&gt;The share of student loan debt that is securitized, meaning it’s backed by assets and known as asset-backed securities, is about $190 billion, according to Goldman Sachs. Of that, about $150 billion is linked to loans where the repayment of the principal is guaranteed by the U.S. government.&lt;/p&gt;

&lt;div class=&quot;image&quot;&gt;
&lt;div id=&quot;lazy-img-321218959&quot; class=&quot;lazy-img&quot;&gt;&lt;img src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i2zWoMxIAfDs/v2/60x-1.jpg&quot; data-native-src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i2zWoMxIAfDs/v2/-1x-1.jpg&quot; class=&quot;lazy-img__image&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;“Most of the remaining student loan debt not in ABS format is provided to students by the U.S. government through its Federal Direct lending program,” wrote Young and Karoui.&lt;/p&gt;
</description>
<pubDate>Tue, 05 Dec 2017 16:08:22 +0000</pubDate>
<dc:creator>rayuela</dc:creator>
<og:description>U.S. student loan debt now equals the size of the $1.3 trillion U.S. high-yield corporate bond market, presenting investors with a whole different range of risks.</og:description>
<og:image>https://assets.bwbx.io/images/users/iqjWHBFdfxIU/il1fTIMOeo78/v1/1200x800.jpg</og:image>
<og:title>Student Loan Debt Is Now As Big as the U.S. Junk Market</og:title>
<og:type>article</og:type>
<og:url>https://www.bloomberg.com/news/articles/2017-12-05/student-loans-raise-other-risks-as-debt-equals-u-s-junk-market</og:url>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.bloomberg.com/news/articles/2017-12-05/student-loans-raise-other-risks-as-debt-equals-u-s-junk-market</dc:identifier>
</item>
<item>
<title>FCC won’t delay vote, says net neutrality supporters are “desperate”</title>
<link>https://arstechnica.com/tech-policy/2017/12/fcc-chair-refuses-to-delay-net-neutrality-vote-despite-pending-court-case/</link>
<guid isPermaLink="true" >https://arstechnica.com/tech-policy/2017/12/fcc-chair-refuses-to-delay-net-neutrality-vote-despite-pending-court-case/</guid>
<description>&lt;img src=&quot;https://cdn.arstechnica.net/wp-content/uploads/2017/10/getty-pai-confirmation-800x629.jpg&quot;/&gt;&lt;div class=&quot;caption-text&quot;&gt;&lt;a href=&quot;https://cdn.arstechnica.net/wp-content/uploads/2017/10/getty-pai-confirmation.jpg&quot; class=&quot;enlarge-link&quot; data-height=&quot;2000&quot; data-width=&quot;2544&quot;&gt;Enlarge&lt;/a&gt; &lt;span class=&quot;sep&quot;&gt;/&lt;/span&gt; Federal Communications Commission Chairman Ajit Pai arrives for his confirmation hearing with the Senate Commerce Committee on July 19, 2017 in Washington, DC.&lt;/div&gt;&lt;aside id=&quot;social-left&quot;&gt;&lt;a title=&quot;142 posters participating&quot; class=&quot;comment-count icon-comment-bubble-down&quot; href=&quot;https://arstechnica.com/tech-policy/2017/12/fcc-chair-refuses-to-delay-net-neutrality-vote-despite-pending-court-case/?comments=1&quot;&gt;&lt;span class=&quot;comment-count-before&quot;&gt;reader comments&lt;/span&gt; &lt;span class=&quot;comment-count-number&quot;&gt;369&lt;/span&gt;&lt;/a&gt;
&lt;div class=&quot;share-links&quot;&gt;&lt;span&gt;Share this story&lt;/span&gt;    &lt;/div&gt;
&lt;/aside&gt;&lt;p&gt;The Federal Communications Commission will move ahead with its vote to kill net neutrality rules next week despite an unresolved court case that could strip away even more consumer protections.&lt;/p&gt;
&lt;p&gt;FCC Chairman Ajit Pai says that net neutrality rules aren't needed because the Federal Trade Commission can protect consumers from broadband providers. But a pending court case involving AT&amp;amp;T could strip the FTC of its regulatory authority over AT&amp;amp;T and similar ISPs.&lt;/p&gt;
&lt;p&gt;A few dozen consumer advocacy groups and the City of New York urged Pai to delay the net neutrality-killing vote in a &lt;a href=&quot;https://www.publicknowledge.org/assets/uploads/documents/Request_for_Delay_Letter_12-4-17_FINAL.pdf&quot;&gt;letter today&lt;/a&gt;. If the FCC eliminates its rules &lt;em&gt;and&lt;/em&gt; the court case goes AT&amp;amp;T's way, there would be a &quot;'regulatory gap' that would leave consumers utterly unprotected,&quot; the letter said.&lt;/p&gt;
&lt;p&gt;When contacted by Ars, Pai's office issued this statement in response to the letter:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is just evidence that supporters of heavy-handed Internet regulations are becoming more desperate by the day as their effort to defeat Chairman Pai's plan to restore Internet freedom has stalled. The vote will proceed as scheduled on December 14.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Consumer advocacy group Public Knowledge is not satisfied by Pai's response.&lt;/p&gt;
&lt;p&gt;&quot;Forty organizations ask the Federal Communications Commission why, if they are relying on the FTC to protect consumers, they do not do the prudent thing and wait until the cloud over FTC jurisdiction is resolved,&quot; Public Knowledge Senior VP Harold Feld told Ars. &quot;The FCC's official response is name calling. This tells anyone interested who is 'fear mongering' and who really has the interests of consumers at heart.&quot;&lt;/p&gt;
&lt;h2&gt;AT&amp;amp;T vs. the FTC&lt;/h2&gt;
&lt;p&gt;The court case centers on the FTC's &lt;a href=&quot;https://arstechnica.com/tech-policy/2014/10/us-sues-att-alleges-severe-throttling-of-unlimited-data-customers/&quot;&gt;attempt&lt;/a&gt; to punish AT&amp;amp;T for throttling the mobile Internet connections of customers with unlimited data plans. While the FTC is not legally able to regulate common carriers, the agency says it can regulate the non-common carriage portions of a company that is otherwise a common carrier.&lt;/p&gt;
&lt;p&gt;At the time of the throttling, AT&amp;amp;T was a common carrier for landline phone and mobile voice service but not for mobile Internet access. AT&amp;amp;T argued that its common carrier status prevented the FTC from regulating any portion of its business, and a panel of judges at the US Court of Appeals for the Ninth Circuit sided with AT&amp;amp;T in &lt;a href=&quot;https://arstechnica.com/tech-policy/2016/08/atts-common-carrier-status-helps-it-defeat-data-throttling-lawsuit/&quot;&gt;August 2016&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The ruling seemed to &lt;a href=&quot;https://arstechnica.com/tech-policy/2016/09/atts-throttling-victory-may-hinder-ftcs-power-to-protect-consumers/&quot;&gt;leave the FTC&lt;/a&gt; without any enforcement powers over the broadband businesses of traditional phone companies like AT&amp;amp;T and Verizon. But there was no &quot;regulatory gap&quot; because the FCC had classified ISPs as common carriers in a February 2015 decision, giving itself broad authority over broadband service.&lt;/p&gt;
&lt;aside class=&quot;pullbox sidebar story-sidebar right&quot;&gt;
&lt;/aside&gt;&lt;p&gt;Now that the FCC is led by Republicans, it plans to eliminate the common carrier classification of broadband providers and says the FTC will pick up the slack. Eliminating the common carrier classification of broadband will &quot;[r]estore the Federal Trade Commission's ability to protect consumers online from any unfair, deceptive, and anticompetitive practices,&quot; &lt;a href=&quot;http://transition.fcc.gov/Daily_Releases/Daily_Business/2017/db1122/DOC-347927A1.pdf&quot;&gt;Pai's proposal says&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;FTC may retain power, but it’s not a done deal&lt;/h2&gt;
&lt;p&gt;Pai's argument is supported by a &lt;a href=&quot;https://arstechnica.com/tech-policy/2017/05/att-could-be-punished-for-unlimited-data-throttling-after-all/&quot;&gt;May 2017 decision by the Ninth Circuit&lt;/a&gt; that vacated AT&amp;amp;T's victory over the FTC and ordered the case to be reheard &lt;em&gt;en banc&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The decision to rehear the case before the full court may indicate that the FTC will ultimately be allowed to regulate broadband providers even when those companies offer non-common carrier services such as traditional phone lines. But it isn't a certainty because the full court still hasn't issued its decision.&lt;/p&gt;
&lt;aside class=&quot;pullbox sidebar story-sidebar right&quot;&gt;
&lt;/aside&gt;&lt;p&gt;&quot;Given the enormous danger to consumers of losing all protections should the Ninth Circuit decide to affirm the panel decision and side with AT&amp;amp;T Mobility, the FCC should delay a vote until the &lt;em&gt;en banc&lt;/em&gt; panel of the Ninth Circuit issues its decision,&quot; consumer advocacy groups and the city of New York wrote to Pai today.&lt;/p&gt;
&lt;p&gt;Pai's anti-net neutrality proposal says that there is no need to wait for the final decision from the Ninth Circuit.&lt;/p&gt;
&lt;p&gt;&quot;Consistent with the Commission's request, the Ninth Circuit granted rehearing &lt;em&gt;en banc&lt;/em&gt; of the panel decision, and, in doing so, it set aside the earlier panel opinion,&quot; Pai's proposal says. &quot;In light of these considerations and the benefits of reclassification, we find objections based on &lt;em&gt;FTC v. AT&amp;amp;T Mobility&lt;/em&gt; insufficient to warrant a different outcome.&quot;&lt;/p&gt;
&lt;p&gt;But the danger of the Ninth Circuit stripping the FTC of regulatory authority is made even greater by the FCC's proposal to &lt;a href=&quot;https://arstechnica.com/tech-policy/2017/11/fcc-will-also-order-states-to-scrap-plans-for-their-own-net-neutrality-laws/&quot;&gt;preempt state consumer protection laws&lt;/a&gt;, the letter from consumer advocacy groups said:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This potential regulatory gap is further compounded by the Draft Order's purported preemption of any state regulations the FCC deems &quot;incompatible&quot; with the newly announced &quot;deregulatory&quot; federal policy. Although the Draft Order is vague as to what, precisely, the FCC is preempting, it would appear from context that it includes state consumer protection laws. In short, the FCC has decided to put all remaining consumer protection eggs in one basket, but cannot be troubled to wait until the Ninth Circuit affirms that this approach is actually consistent with the FTC's own jurisdictional statute.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The FCC attempt to preempt state laws is part of the anti-net neutrality proposal and would thus be approved in the same vote on December 14.&lt;/p&gt;
&lt;p&gt;Common carrier rules include numerous consumer protections that go beyond the core net neutrality rules, as we've &lt;a href=&quot;https://arstechnica.com/tech-policy/2017/07/how-title-ii-goes-beyond-net-neutrality-to-protect-internet-users-from-isps/&quot;&gt;previously detailed&lt;/a&gt;. According to Feld, the FCC's plan to move ahead with the vote shows that &quot;Chairman Pai and the other Republican commissioners simply do not care if consumers are protected or not.&quot;&lt;/p&gt;
</description>
<pubDate>Tue, 05 Dec 2017 14:56:15 +0000</pubDate>
<dc:creator>adidash</dc:creator>
<og:url>https://arstechnica.com/tech-policy/2017/12/fcc-chair-refuses-to-delay-net-neutrality-vote-despite-pending-court-case/</og:url>
<og:title>FCC won’t delay vote, says net neutrality supporters are “desperate”</og:title>
<og:image>https://cdn.arstechnica.net/wp-content/uploads/2017/10/getty-pai-confirmation-760x380.jpg</og:image>
<og:description>Pai says FTC will protect consumers—but FTC could lose its regulatory authority.</og:description>
<og:type>article</og:type>
<dc:language>en-us</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://arstechnica.com/tech-policy/2017/12/fcc-chair-refuses-to-delay-net-neutrality-vote-despite-pending-court-case/</dc:identifier>
</item>
<item>
<title>Virtual Keyboard Developer Leaked 31M Client Records</title>
<link>https://mackeepersecurity.com/post/virtual-keyboard-developer-leaked-31-million-of-client-records</link>
<guid isPermaLink="true" >https://mackeepersecurity.com/post/virtual-keyboard-developer-leaked-31-million-of-client-records</guid>
<description>&lt;div readability=&quot;31.79&quot;&gt;
&lt;p class=&quot;full-post__author_text&quot;&gt;&lt;span class=&quot;full-post__author_by&quot;&gt;By&lt;/span&gt; &lt;span class=&quot;full-post__author_name&quot;&gt;Bob Diachenko&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;full-post__author_date&quot;&gt;2017-12-05&lt;/p&gt;
&lt;div class=&quot;full-post__author-details&quot; readability=&quot;35.127906976744&quot;&gt;
&lt;div class=&quot;full-post__author-details_profile&quot;&gt;
&lt;p class=&quot;full-post__author-details_name&quot;&gt;Bob Diachenko&lt;/p&gt;

&lt;/div&gt;
&lt;p class=&quot;full-post__author-details_text&quot;&gt;Bob Diachenko, Kromtech's Chief Communication Officer, is also a security enthusiast and has been cited by NBC News, ZDNet, VICE, and many other&lt;/p&gt;
&lt;a class=&quot;posts-list__link posts-list__link_bio&quot; href=&quot;https://mackeepersecurity.com/author/bob-diachenko&quot; target=&quot;_blank&quot;&gt;Show full bio &lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;&lt;div readability=&quot;145.4571529745&quot;&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span class=&quot;e-content&quot;&gt;The Kromtech Security Center has discovered a massive amount of customer files leaked online and publically available. Researchers were able to access the data and details of 31,293,959 users. The misconfigured MongoDB database appears to belong to Ai.Type a Tel Aviv-based startup that designs and develops a personalized keyboard for mobile phones and tablets for both Android and iOS devices.&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span class=&quot;e-content&quot;&gt;Ai.Type was founded in 2010 and According to their site, their flagship product for Android was downloaded about 40 million times from the Google Play store and the numbers of downloads and user bases are rapidly growing. They plan to integrate Matching Bots as a user types their conversation and that their Ai type keyboard will soon offer a “Bots Discovery Platform” Via Keyboard. There was also a notice of a name change from Ai.Type to Bots Matching Mobile Keyboard in the coming year.  &lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span class=&quot;e-content&quot;&gt;&lt;span&gt;&lt;strong&gt;Giving up data for personalized services and apps&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;Consumers give up more data than ever before in exchange for using services or applications. The scary part is that companies collect and use their personal data in ways they may not know. The concept is where people willing provide their digital in exchange for free or lower priced services or products. A study from the Annenberg School for Communication at the University of Pennsylvania concluded that a majority of Americans do not think the trade-off of their data for personalized services is a fair deal.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;Once that data is gone users have little to no knowledge of what is done with their personal data. When researchers installed Ai.Type they were shocked to discover that users must allow “Full Access” to all of their data stored on the testng iPhone, including all keyboard data past and present. It raises the question of why would a keyboard and emoji application need to gather the entire data of the user’s phone or tablet? Based on the leaked database they appear to collect everything from contacts to keystrokes. This is a shocking amount of information on their users who assume they are getting a simple keyboard application.  &lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;strong&gt;How the data leak&lt;/strong&gt;&lt;/span&gt; &lt;strong&gt;&lt;span&gt;occured&lt;/span&gt;&lt;/strong&gt; &lt;span&gt;&lt;strong&gt;and what it contained&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;Ai.Type accidentally exposed their entire 577GB Mongo-hosted database to anyone with an internet connection. This also exposed just how much data they access and how they obtain a treasure trove of data that average users do not expect to be extracted or datamined from their phone or tablet. MongoDB is a common platform used by many well known companies and organizations  to store data, but a simple misconfiguration could allow the database to be easily exposed online. One flaw is that the default settings of a MongoDB database would allow anyone with an internet connection to browse the databases, download them, or even worst case scenario to even delete the data stored on them.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;strong&gt;Summary of what the database contained:&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;strong&gt;Client Registration&lt;/strong&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;Client files that included the personal details of &lt;strong&gt;31,293,959&lt;/strong&gt; users who installed ai.type virtual keyboard. This is highly sensitive and identifiable information such as:&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;Phone number, full name of the owner, device name and model, mobile network name, SMS number, screen resolution, user languages enabled, Android version, IMSI number (international mobile subscriber identity used for interconnection), IMEI number (a unique number given to every single mobile phone), emails associated with the phone, country of residence, links and the information associated with the social media profiles (birthdate, title, emails etc.) and photo (links to Google+, Facebook etc.), IP (if available), location details (long/lat).&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;strong&gt;Phonebook and Contact Records&lt;/strong&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;6,435,813 records that contained data collected from users’ contact books, including names (as entered originally) and phone numbers, in total &lt;strong&gt;more than 373 million records&lt;/strong&gt; scraped from registered users’ phones, which include all their contacts saved/synced on linked Google account.&lt;br/&gt; &lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.mackeepersecurity.com/image/upload/tmp_8d5e19691d2ac3288856012978222aa3.png&quot;/&gt;&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.mackeepersecurity.com/image/upload/tmp_bc3fa8a94a2c233c605a7e6e0c125fa8.png&quot;/&gt;&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;Additionally, user data from a folder titled ‘old database’ that contained 753,456 records were also available.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;There was a range of other statistics like the most popular users’ Google queries for different regions. Data like average messages per day, words per message, age of users, words_per_day': 0.0, 'word_per_session and a detailed look at their customers&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://static.mackeepersecurity.com/image/upload/tmp_615d1bb992daf5adf00ff4e28d2169b0.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt; &lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://static.mackeepersecurity.com/image/upload/tmp_2d7d399b7b191d972bc87c45d16e9aab.png&quot;/&gt;&lt;br/&gt; &lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://static.mackeepersecurity.com/image/upload/tmp_fa417c3a3d140fda403b8eb3fec50931.png&quot;/&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt; &lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;span&gt;&lt;strong&gt;The Danger of the Ai.Type Data Leak&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;Bob Diachenko, head of communications at Kromtech Security Center:&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;em&gt;Theoretically, it is logical that anyone who has downloaded and installed the Ai.Type virtual keyboard on their phone has had all of their phone data exposed publicly online. This presents a real danger&lt;/em&gt; &lt;em&gt;for&lt;/em&gt; &lt;em&gt;cyber criminals&lt;/em&gt; &lt;em&gt;who could commit fraud or scams using such detailed information about the user. It raises the question once again if it is really worth it for consumers to submit their data in exchange for free or discounted products or services that gain full access to their devices.&lt;/em&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt; &lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;Alex Kernishniuk, VP of strategic alliances, Kromtech:&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;em&gt;It is clear that data is valuable and everyone wants access to it for different reasons. Some want to sell the data they collect, others use it for targeted marketing, predictive artificial intelligence, and cyber criminals want to use it to make money in more and more creative ways. This is once again a wakeup call for any company that gathers and stores data on their customers to protect, secure, and audit their data privacy practices.&lt;/em&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt; &lt;/p&gt;
&lt;div readability=&quot;8.1168224299065&quot;&gt;
&lt;p dir=&quot;ltr&quot;&gt;***&lt;br/&gt;Attention - Portions of this article may be used for publication if properly referenced and credit is given to Kromtech Security Center.&lt;br/&gt;Do you have security tips or suggestions? Contact: &lt;a href=&quot;mailto:security@kromtech.com&quot;&gt;security@kromtech.com&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;


&lt;/div&gt;</description>
<pubDate>Tue, 05 Dec 2017 14:26:36 +0000</pubDate>
<dc:creator>danso</dc:creator>
<og:title>Virtual Keyboard Developer Leaked 31 Million of Client Records</og:title>
<og:description>31 Million Client Registration Files Leaked by Personalized Keyboard Developer.</og:description>
<og:image>https://static.mackeepersecurity.com/image/upload/post_4a30a6a062281f1ce86c3c4b0f91c93d.jpg</og:image>
<og:url>https://mackeepersecurity.com/post/virtual-keyboard-developer-leaked-31-million-of-client-records</og:url>
<og:type>website</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://mackeepersecurity.com/post/virtual-keyboard-developer-leaked-31-million-of-client-records</dc:identifier>
</item>
<item>
<title>An $814M Mystery Near the Heart of the Biggest Bitcoin Exchange</title>
<link>https://www.bloomberg.com/news/articles/2017-12-05/mystery-shrouds-tether-and-its-links-to-biggest-bitcoin-exchange</link>
<guid isPermaLink="true" >https://www.bloomberg.com/news/articles/2017-12-05/mystery-shrouds-tether-and-its-links-to-biggest-bitcoin-exchange</guid>
<description>&lt;p&gt;Among the many mysteries at the heart of the cryptocurrency market are these: Does $814 million of a digital token known as &lt;a itemscope=&quot;itemscope&quot; itemprop=&quot;StoryLink&quot; href=&quot;https://tether.to&quot; title=&quot;Tether’s Website&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;tether&lt;/a&gt; really exist? And what is tether’s connection to &lt;a itemscope=&quot;itemscope&quot; itemprop=&quot;StoryLink&quot; href=&quot;https://www.bitfinex.com&quot; title=&quot;Bitfinex Website&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Bitfinex&lt;/a&gt;, the world’s biggest bitcoin exchange?&lt;/p&gt;

&lt;p&gt;This is the state of crypto in late 2017, where questions about the companies behind the currencies are multiplying with the profits. While cryptocurrencies appeal to people who lack faith in governments and banks, the digital assets often require a blind trust in companies about which few facts are available.&lt;/p&gt;

&lt;div class=&quot;image&quot;&gt;
&lt;div id=&quot;lazy-img-321228427&quot; class=&quot;lazy-img&quot;&gt;&lt;img src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iyD.teH_JToo/v0/60x-1.jpg&quot; data-native-src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iyD.teH_JToo/v0/-1x-1.jpg&quot; class=&quot;lazy-img__image&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Photographer: Andrew Harrer/Bloomberg&lt;/p&gt;
&lt;p data-tout-type=&quot;story&quot;&gt;&lt;a itemscope=&quot;itemscope&quot; itemprop=&quot;StoryLink&quot; href=&quot;https://www.bloomberg.com/news/articles/2017-12-01/bitcoin-futures-to-start-trading-as-regulators-rush-to-catch-up&quot; title=&quot;Click for full story&quot; target=&quot;_blank&quot;&gt;Read More: Bitcoin Heads to Wall Street Whether Regulators Are Ready or Not&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Take tether. The currency, which started trading in 2015, is described as a stable alternative to bitcoin’s wild price swings. A restaurant owner who accepts bitcoin but fears its volatility could shift bitcoin into tether, which can be easier to do than exchanging bitcoin for dollars. Its price has stayed near $1 for most of its life because Tether, the company behind the digital token, says that every tether is backed by one U.S. dollar held in reserve. Since there’s $814 million of tether circulating, there should be $814 million parked in bank accounts somewhere.&lt;/p&gt;

&lt;p&gt;Not everyone believes there is.&lt;/p&gt;
&lt;p&gt;“Is there anything backing this?” said Tim Swanson, who does risk analysis for blockchain and cryptocurrency startups. Swanson, also director of research at Post Oaks Labs, said he fears problems with tether could hobble exchanges that trade it. “If these aren’t backed 1-to-1, then what is the contagion risk if one of these exchanges goes down?”&lt;/p&gt;
&lt;div class=&quot;image&quot;&gt;
&lt;div id=&quot;lazy-img-321199860&quot; class=&quot;lazy-img&quot;&gt;&lt;img src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iPX_2XsZ9Ly8/v2/60x-1.png&quot; data-native-src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iPX_2XsZ9Ly8/v2/-1x-1.png&quot; class=&quot;lazy-img__image&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Some wonder whether tether has helped pump up the price of bitcoin, which recently surpassed $11,000 after beginning the year below $1,000. Charlie Lee, creator of Litecoin, the world’s seventh-largest cryptocurrency, wrote in a Nov. 30 &lt;a itemscope=&quot;itemscope&quot; itemprop=&quot;StoryLink&quot; href=&quot;https://twitter.com/SatoshiLite/status/936325730383695872&quot; title=&quot;His Tweet&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;Twitter post&lt;/a&gt;, “There’s a fear going on that the recent price rise was helped by printing of USDT (Tether) that is not backed by USD in a bank account.”&lt;/p&gt;
&lt;p&gt;Little public information exists about how tether is created, fueling questions, said Barry Leybovich, a product manager at IPC System who creates risk and compliance products for financial institutions interested in blockchain applications. The market believes that each tether is worth $1, even if they’re not actually backed by that money, and trades of tether for bitcoin at Bitfinex are helping drive up the price of bitcoin, he said.&lt;/p&gt;
&lt;h3&gt;No Guarantee&lt;/h3&gt;

&lt;p&gt;Tether’s website makes a claim that’s unusual among cryptocurrencies: “every tether is always backed 1-to-1 by traditional currency held in our reserves.” The site also says each tether can be redeemed for $1. But its terms of service say: “There is no contractual right or other right or legal claim against us to redeem or exchange your tethers for money. We do not guarantee any right of redemption or exchange of tethers by us for money.”&lt;/p&gt;
&lt;p&gt;On Dec. 2, Bitfinex released a &lt;a itemscope=&quot;itemscope&quot; itemprop=&quot;StoryLink&quot; href=&quot;https://pastebin.com/y6Mfp7FH&quot; title=&quot;Bitfinex Report&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;quarterly report&lt;/a&gt; announcing it would no longer serve U.S. customers because it’s too expensive to do business with them. This followed Wells Fargo &amp;amp; Co.’s decision earlier in the year to end its role as a correspondent bank through which customers in the U.S. could send money to Bitfinex and Tether’s banks in Taiwan. Bitfinex and Tether filed suit against Wells Fargo, but later withdrew the case.&lt;/p&gt;
&lt;h3&gt;‘Clear Challenges’&lt;/h3&gt;
&lt;p&gt;“We continue to experience banking bottlenecks for some customers, but are proceeding to open accounts around the world,” according to the quarterly report. “While we have some clear challenges, please note that tens of millions of dollars continue to flow in and out of Bitfinex daily. Although not available to everyone, these fiat flows have been sufficient to keep our market in alignment with other exchanges as we continue to gain market share.”&lt;/p&gt;
&lt;p&gt;Bitfinex and Tether identified four Taiwanese banks in the Wells Fargo lawsuit. However, Ronn Torossian, a spokesman for Bitfinex and Tether, refused to identify their current banks unless a reporter signed a non-disclosure agreement, an offer that wasn’t accepted.&lt;/p&gt;
&lt;h3&gt;Polish Bank&lt;/h3&gt;
&lt;p&gt;Documents posted online show Bitfinex directing prospective customers to Poland’s Bank Spoldzielczy in Skierniewice. Torossian wouldn’t comment on whether the documents are authentic.&lt;/p&gt;
&lt;p&gt;Wladyslaw Klazynski, the bank’s chief executive officer, wouldn’t confirm if any accounts have been opened by Bitfinex clients, citing Polish financial law that forbids revealing client data. “We are in touch with the Polish financial market watchdog in order to explain media information” about the situation, he said in a phone interview, adding that his firm isn’t “financially engaged” with any company trading bitcoin.&lt;/p&gt;
&lt;p&gt;Neither Tether nor Bitfinex disclose on their websites or in any public documents where they’re located or who’s in charge, but information is available elsewhere.&lt;/p&gt;
&lt;p&gt;Jan Ludovicus van der Velde is CEO of both Bitfinex and Tether, Torossian said by email on Dec. 3. A &lt;a itemscope=&quot;itemscope&quot; itemprop=&quot;StoryLink&quot; href=&quot;https://www.linkedin.com/in/j-l-van-der-velde-26a24b6/&quot; title=&quot;LinkedIn Profile&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;LinkedIn page&lt;/a&gt; for someone named J. L. van der Velde, who identifies himself as Bitfinex’s CEO, says he speaks Dutch, English, German, Italian and Chinese, attended National Taiwan Normal University from 1985 to 1988 and was previously CEO of PAG Asia Inc.&lt;/p&gt;
&lt;h3&gt;Paradise Papers&lt;/h3&gt;
&lt;p&gt;Phil Potter is a Tether director, according to documents -- dubbed the &lt;a itemscope=&quot;itemscope&quot; itemprop=&quot;StoryLink&quot; href=&quot;https://www.bloomberg.com/news/articles/2017-11-07/the-paradise-papers-data-dump-what-s-been-reported-so-far&quot; title=&quot;The Paradise Papers Data Dump: What’s Been Reported (Correct)&quot; target=&quot;_blank&quot;&gt;Paradise Papers&lt;/a&gt; -- recently leaked by the International Consortium of Investigative Journalists. He’s also the chief strategy officer at Bitfinex. A graduate of Yale University, Potter worked as a derivatives analyst for Morgan Stanley and then moved to the private client services unit at Bear Stearns Cos., where he worked on technology infrastructure and software design. He’s given many interviews that can be found on YouTube, &lt;a itemscope=&quot;itemscope&quot; itemprop=&quot;StoryLink&quot; href=&quot;https://www.youtube.com/watch?v=QE1HjbgSxPo&quot; title=&quot;link to interview&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;including Q&amp;amp;As&lt;/a&gt; after Bitfinex was hacked last year.&lt;/p&gt;
&lt;p&gt;Bitfinex incorporated in Hong Kong in 2013, but then changed its name to Renrenbee Ltd. a year later, according to Companies Registry in Hong Kong. Giancarlo Devasini is listed as a director at Renrenbee by Companies Registry. He’s identified as a Tether director in the Paradise Papers.&lt;/p&gt;
&lt;p&gt;Torossian said van der Velde, Potter and Devasini weren’t available for interviews.&lt;/p&gt;
&lt;p&gt;Oguz Serdar said he tried tether, but came away disappointed. When Turkey banned PayPal last year, he began using bitcoin to pay contractors working with his advertising technology company, then started investing in it on his own. When he feared bitcoin was poised to drop, he said he shifted funds into tether. “It’s a way to park your gains,” he explained in a telephone interview. “It’s what you do temporarily.”&lt;/p&gt;
&lt;p&gt;He said that in early November he tried to cash out $1 million of tether, a request Tether refused.&lt;/p&gt;
&lt;h3&gt;‘Banking Difficulties’&lt;/h3&gt;
&lt;p&gt;“Due to ongoing banking difficulties we are only able to process requests for verified corporate customers,” Serdar was told by Tether, according to emails he shared with Bloomberg News. Serdar said the company stated that its currency was backed by reserves, meaning it was one of few places to exchange tethers for dollars, and while he didn’t have an account he approached them to find out who they banked with.&lt;/p&gt;
&lt;p&gt;Tether, Serdar says, declined to disclose its banks and instead recommended in an email that he try to sell on one of the exchange partners it lists on its website. More than a dozen names appear there, but many don’t offer investors a way to exchange tether for dollars. One that does is Kraken, but Serdar didn’t think that market could handle his trade. “The demand side is entirely empty there,” he said. “You try to sell $1 million of U.S. dollar tether, the price crashes to zero, so you don’t do that.”&lt;/p&gt;
&lt;aside class=&quot;inline-newsletter&quot; data-state=&quot;ready&quot;/&gt;&lt;p&gt;Serdar “doesn’t have any money with us and he never did,” Torossian said. “The customer in question was flagged as suspicious because of numerous irregularities,” he added. “If this customer wishes to complete our KYC process properly, we may review this matter further. Until that time, this individual will not be permitted to do business with us,” he said, referring to know-your-customer regulations that require financial firms to vet their clients.&lt;/p&gt;
&lt;p&gt;Serdar said he alerted the U.S. Treasury Department and the Justice Department about his concerns regarding Tether through an online tip website, but hasn’t heard back. As for how the company characterizes him now, he said, “they’re speculating on me being some type of enemy.”&lt;/p&gt;
&lt;h3&gt;Lawyers Hired&lt;/h3&gt;
&lt;p&gt;On Dec. 3, Bitfinex said it had hired law firm Steptoe &amp;amp; Johnson LLP because of “false claims and related activity by various parties,” according to an emailed press release. “To date, every claim made by these bad actors has been patently false and made simply to agitate the cryptocurrency ecosystem,” Stuart Hoegner, counsel for Bitfinex, said in the statement.&lt;/p&gt;
&lt;p&gt;Serdar says he eventually traded his $1 million tether stake for bitcoin. “I don’t think they have even $100 million or $200 million in a legitimate country,” he said. “It’s the elephant in the room, but a lot of people don’t want to talk about it because they’re invested in it.”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;— With assistance by Marta Waldoch, and Benjamin Robertson&lt;/em&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 05 Dec 2017 14:20:06 +0000</pubDate>
<dc:creator>rayuela</dc:creator>
<og:description>Among the many mysteries at the heart of the cryptocurrency market are these: Does $814 million of a digital token known as tether really exist? And what is tether’s connection to Bitfinex, the world’s biggest bitcoin exchange?</og:description>
<og:image>https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i1lRxhwrKt9s/v0/1200x800.jpg</og:image>
<og:title>There’s an $814 Million Mystery Near the Heart of the Biggest Bitcoin Exchange</og:title>
<og:type>article</og:type>
<og:url>https://www.bloomberg.com/news/articles/2017-12-05/mystery-shrouds-tether-and-its-links-to-biggest-bitcoin-exchange</og:url>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.bloomberg.com/news/articles/2017-12-05/mystery-shrouds-tether-and-its-links-to-biggest-bitcoin-exchange</dc:identifier>
</item>
</channel>
</rss>