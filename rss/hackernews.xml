<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>A summary of what quantitative trading firms do</title>
<link>https://blog.headlandstech.com/2017/08/03/quantitative-trading-summary/</link>
<guid isPermaLink="true" >https://blog.headlandstech.com/2017/08/03/quantitative-trading-summary/</guid>
<description>&lt;p&gt;This summary is an attempt to shed some light on modern quantitative trading since there is limited information available for people who are not already in the industry. Hopefully this is useful for students and candidates coming from outside the industry who are looking to understand what it’s like working for a quantitative trading firm. Job titles like “researcher” or “developer” don’t give a clear picture of the day-to-day roles and responsibilities at a trading firm. Most quantitative trading firms have converged on roughly the same basic organizational framework so this is a reasonably accurate description of the roles at any established quantitative trading firm.&lt;/p&gt;
&lt;p&gt;The product of a quantitative trading company is an automated software program that buys and sells electronically traded &lt;a href=&quot;https://en.wikipedia.org/wiki/Security_(finance)&quot;&gt;securities&lt;/a&gt; to make a profit. This software program is supported by many systems designed to maintain and optimize it. Most companies are roughly divided into 3 main groups: strategy research, core development, and operations. Employees generally start and stay in one of these groups throughout a career. This guide focuses on strategy research and core development roles.&lt;/p&gt;
&lt;p&gt;Primary job requirements:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Strategy research (‘research’): Programming, statistics, trading intuition, and the ability to understand market data&lt;/li&gt;
&lt;li&gt;Core development (‘dev’): Low-level software engineering, networking, and system architecture&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The software components of a quantitative trading system are built by one of these two teams. The majority of the components are built in-house at most major trading firms, so below is a list of the programs you could expect to build or maintain if you were on the research or dev teams. Each of these programs can be a separate process, although we’ll discuss some variants later.&lt;/p&gt;
&lt;p&gt;Programs for live production trading:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Market data parser: Dev. Normalizes each exchange’s protocol (including different versions over time) into the same internal format.&lt;/li&gt;
&lt;li&gt;Trading strategy: Research/Dev. Receives normalized data, decides whether to buy or sell.&lt;/li&gt;
&lt;li&gt;Order gateway: Dev. Converts from internal order format to each exchange’s order entry protocol (different than the market data protocol).&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Programs to support live production trading:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Monitoring GUI: Dev. GUIs used to be important for click traders but are now mainly used to monitor that the trading system is performing appropriately. They are still occasionally used to manually adjust a few parameters, such as overall risk tolerance.&lt;/li&gt;
&lt;li&gt;Drop copy: Dev. Secondary order confirmation to make sure you have the trading positions you think you do.&lt;/li&gt;
&lt;li&gt;Market data capture: Dev. Record the market data in parallel to what’s going into the strategy to verify later that the strategy behaved as intended and to run statistical tests on historical data (live capture is more reliable than purchasing from a vendor so most major firms avoid buying data from a vendor).&lt;/li&gt;
&lt;li&gt;Startup scripts: Dev/Operations. Launch all these different software programs in the right order and at the right time of day each time they need to be restarted (typically daily or weekly), and alert or recover from startup problems.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Programs to optimize and analyze the trading strategy:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Parameter optimization: Research. Regressions or other metrics to help people compare one trading strategy parameter setting to another to find the best.&lt;/li&gt;
&lt;li&gt;Production reconciliation: Research. Metrics to confirm that the state in the trading strategy’s internal algorithm matched calculations using captured market data.&lt;/li&gt;
&lt;li&gt;Back testing simulator: Research. Shows estimated trading strategy profit or loss on historical data.&lt;/li&gt;
&lt;li&gt;Graphing: Dev/Research. Display profit or loss, volume, price and other statistics over time.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;In a ‘typical’ established quantitative trading company the department breakdown would be:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Research&lt;/li&gt;
&lt;li&gt;Dev&lt;/li&gt;
&lt;li&gt;Back office and operations
&lt;ul&gt;&lt;li&gt;operations/monitoring&lt;/li&gt;
&lt;li&gt;telco/networking/hardware&lt;/li&gt;
&lt;li&gt;accounting/HR&lt;/li&gt;
&lt;li&gt;management/business development&lt;/li&gt;
&lt;li&gt;legal/compliance&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Since we won’t focus on them later, here’s a brief description of the latter groups:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Operations/monitoring: Monitor strategies and risk intraday and overnight to ensure there are no problems (like &lt;a href=&quot;https://www.sec.gov/litigation/admin/2013/34-70694.pdf&quot;&gt;Knight Capital’s +$400m loss&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Telco/networking/hardware: Purchase and rack servers, configure switch firmware, operating system settings, and network interface cards or FPGAs, connect co-located datacenters (possibly in different countries), etc.&lt;/li&gt;
&lt;li&gt;Accounting/HR: Like any business there is tax, accounting, and human resources work&lt;/li&gt;
&lt;li&gt;Management/business development: There’s a lot of legwork to trading multiple exchanges around the world, such as finding contacts in other countries, negotiating fees, licensing telecom networks, and keeping ahead of new updates.&lt;/li&gt;
&lt;li&gt;Legal/compliance: Trading is one of the most regulated industries. There are US and international regulators (SEC, CFTC, FCA, etc), huge and diverse rulesets such as MIFID, industry regulating agencies like FINRA, and exchange-level self-regulatory regimes (CME, NYSE, etc) that each have their own rules. Ensuring and documenting compliance with each set of rules takes a lot of work.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Some of the key differentiating factors between quantitative trading companies are:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;How they divide up research teams – internal collaboration vs competition between siloed research/trading teams.&lt;/li&gt;
&lt;li&gt;Which exchanges and products they focus on.&lt;/li&gt;
&lt;li&gt;What type of trading strategy is used and how it’s optimized.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Although we are unable to explain how each specific company divides up their research/trading teams, the overall structure and organization of employees and software at most major quantitative trading firms follows a similar general pattern to what was described above.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Trading strategies&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now that you have a high-level understanding of what a typical quantitative trading company does and the different roles that exist, let’s go into more detail about trading strategies.&lt;/p&gt;
&lt;p&gt;The industry has generally settled on three main types of strategies that are sustainable because they provide real economic value to the market:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Arbitrage: Arbitrage and its economic benefits have been well understood for quite some time and documented by academia. The companies that are still competitive in arbitrage have one of 3 advantages:
&lt;ul&gt;&lt;li&gt;Scale: To determine that some complex option or futures spread products are mispriced relative to a set of others, nontrivial calculations must be performed, including the fee per leg, and then the hedged position has to be held and margined until expiry. Being able to manage this and have low fees requires scale.&lt;/li&gt;
&lt;li&gt;Speed: Speed either comes from having faster telco or being able to hedge. For example, triangular arbitrage on FX products traded in London, NY, and Japan and are a major impetus for the Go West and Hibernia microwave telecom projects. Arbitrageurs rely on the speed of their order gateway connections so they can hedge on related markets if they are overfilled.&lt;/li&gt;
&lt;li&gt;Queue position: Being able to enter one leg of an arbitrage by passively buying on the bid or selling on the offer reduces costs by not having to cross the spread on that leg, so being able to achieve good queue position can give an edge in arb trades.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Market Taking: Placing a marketable buy or sell order to profit from a predicted price change. The economic value market takers are being paid for is either:
&lt;ul&gt;&lt;li&gt;properly pricing the relative value of related securities&lt;/li&gt;
&lt;li&gt;trading and thereby contributing to price discovery in products after observed changes in supply and demand&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Like a real estate negotiation that can change a deal’s value minute-by-minute when negotiators come to the table face-to-face and discover each other’s positions, even though the fundamentals of the deal or real estate market certainly don’t fluctuate by the minute, market takers are the high-stakes-mediators of the trading world. Market taking requires predictive signals and relatively low-latency because you pay to cross the spread. A common low-latency market taking strategy would be to attempt to buy the remaining liquidity at a price after a large buy trade. Some firms have FPGAs configured to send orders as soon as they see a trade message matching the right conditions (more on this later).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;Market Making: Posting passive non-marketable buy and sell orders with the goal to profit from the spread. The economic value market makers are being paid for is connecting buyers and sellers who don’t arrive at the market at the same time. Market makers are compensated for the risk that there may be more buyers than sellers or vice versa for an extended time, such as during times of market stress.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Basic trading system design&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A quantitative trading system’s input is market data and its output is orders. In between is the strategy algorithm.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Input&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The input to a trading system is tick-by-tick market data. The input is handled in an event loop. The events are the packets sent by the exchange that are read off the network and normalized by the market data parser. Each packet gives information about the current supply and demand for a security and the current price. A packet can tell you one of three things:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;A limit order was added to the book. Primary fields: {price, side, order id, quantity}&lt;/li&gt;
&lt;li&gt;A limit order was canceled. Primary fields: {order id}&lt;/li&gt;
&lt;li&gt;A trade occurred. Primary fields: {price, aggressor side, quantity}&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;For example, a few packets look like this (&lt;em&gt;for a more detailed, real example &lt;a href=&quot;https://www.hotspotfx.com/pdfs/Itch_Protocol.pdf&quot;&gt;see here&lt;/a&gt;&lt;/em&gt;):&lt;/p&gt;
&lt;p&gt;AddOrder { end_of_packet: 1; seq_number: 103901; symbol_id: 81376629; receive_time: 13:03:46.304606537089; source: 1; side: S; qty: 1; order_id: 210048618; price: 99.25; }&lt;/p&gt;
&lt;p&gt;CancelOrder { end_of_packet: 1; seq_number: 103900; symbol_id: 81376629; receive_time: 13:03:41.863834923132; source: 1; qty: 0; order_id: 210048542; price: 99.00; side: S; }&lt;/p&gt;
&lt;p&gt;Trade { end_of_packet: 1; seq_number: 103902; symbol_id: 81376629; receive_time: 13:03:46.304606537835; source: 1; aggressor_side: B; qty: 1; order_id: 210048321; price: 99.00; match_id: 20154940; }&lt;/p&gt;
&lt;p&gt;If the trading system adds up all the AddOrder packets and subtracts CancelOrder and Trade packets, it can see what the order book currently looks like. The order book shows the aggregate visible supply and demand currently available at each price. The order book is an industry-standard normalization layer.&lt;/p&gt;
&lt;p&gt;When you add up all the orders, the order book could look like this:&lt;/p&gt;
&lt;p&gt;Sell 10 for $99.25&lt;/p&gt;
&lt;p&gt;Sell 5 for $99.00 (best offer)&lt;/p&gt;
&lt;p&gt;Buy 10 for $98.75 (best bid)&lt;/p&gt;
&lt;p&gt;Buy 10 for $98.50&lt;/p&gt;
&lt;p&gt;This is the main view of the market data input used by the strategy algorithm.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Strategy algorithm&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To put into practice what we discussed above, let’s outline a market taking strategy utilizing what is often referred to as market micro-structure signals that may have made money back before quantitative trading became very competitive. Some companies have each member of their intern classes program a strategy like this as a teaching project during a summer. This strategy calculates some signals using the order book as input, and buys or sells when the aggregate signals are strong enough.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Market microstructure signals&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A signal is an algorithm that takes market data as the input and outputs a theoretical price for a security. Market micro-structure signals generally rely on price, size, and trade data coming directly from data feeds. Please reference the order book state provided previously as we walk through the following signal examples.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;A basic signal, likely used in some form by most firms, is ‘book pressure’. In this case book pressure is simply (99.00*10 + 98.75*5)/(10+5) = 98.9167. Because there is more demand on the bid, the theoretical price is closer to the offer than the bid. Another way of understanding why this is a valid predictor it is that if buy and sell trades randomly arrive in the market on the bid and offer, then there’s a 2/3 chance of them filling the entire offer before the entire bid, because it’s 2 times bigger, so the expected future price is slightly closer to the offer than the bid.&lt;/li&gt;
&lt;li&gt;A second basic signal that many quantitative trading firms use is ‘trade impulse’. A common form is to plug trade quantity into something like the book pressure formula, but with the average bid and offer quantity in the denominator instead of the current quantity (let’s say the average is 15). So if there is a sell trade for 9 on this book, the trade impulse would be -0.25*9/15 = -0.15. This example signal would only be valid for the span of 1 packet. Another way of understanding why this is a valid predictor is that sometimes buy and sell trade quantity is autocorrelated over very short intervals, because there are often multiple orders in flight sent in reaction to the same trigger by different people (this is easily measured), so if you see one sell trade, then typically the next order will also be a sell.&lt;/li&gt;
&lt;li&gt;A third common basic signal is ‘related trade’. Basically, you could just take the same signal as (2), but translate it over from a different security that is highly correlated, by multiplying it by the correlation between them.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The book pressure and trade impulse signal are enough to create a market taking strategy. After the sell trade for 9, the remaining quantity on the book is:&lt;/p&gt;
&lt;p&gt;Sell 10 for $99.25&lt;/p&gt;
&lt;p&gt;Sell 5 for $99.00 (best offer)&lt;/p&gt;
&lt;p&gt;Buy &lt;u&gt;(10-9 = 1)&lt;/u&gt; for $98.75 (best bid)&lt;/p&gt;
&lt;p&gt;Buy 10 for $98.50&lt;/p&gt;
&lt;p&gt;But our theoretical price is = book pressure + trade impulse = (99.00*1 + 98.75*5)/(1+5) + -0.25*9/15 = 98.79167 – 0.15 = $98.64167! Since our theoretical price is below the best bid, we will send an order to sell the last remaining quantity of 1 at $98.75, for a theoretical profit of $0.10833.&lt;/p&gt;
&lt;p&gt;That is a high-level overview of a simple quantitative strategy, and provides a basic understanding of the flow from the input (market data) to the output (orders).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Digression: Trade signal on an FPGA&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If you ran the market taking strategy from the previous section live in a real trading system, you would likely find that your orders rarely get filled. You want to trade when your theoretical price implies there’s a profitable opportunity, but other trading systems are faster than yours so their orders reach the market first and there’s nothing left for you.&lt;/p&gt;
&lt;p&gt;State of the art latency, as of 2017, can be achieved by putting the trading logic on an FPGA. A basic trading system architecture with an FPGA is to have the FPGA connected directly to the exchange and also to the old trading system. The old trading system is now only responsible for calculating hypothetical scenarios. Instead of sending the order, it notifies the FPGA what hypothetical condition needs to be met to send the order. Using the same case as before, it could hypothetically evaluate the signal for a range of trade quantities:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Sell trade, quantity = 1…&lt;/li&gt;
&lt;li&gt;Sell trade, quantity = 2…&lt;/li&gt;
&lt;li&gt;Sell trade, quantity = 3…&lt;/li&gt;
&lt;li&gt;Sell trade, quantity = 4…&lt;/li&gt;
&lt;li&gt;Sell trade, quantity = 5…&lt;/li&gt;
&lt;li&gt;Sell trade, quantity = 6: (99.00*4 + 98.75*5)/(4+5) + -0.25*6/15 = 98.7611&lt;/li&gt;
&lt;li&gt;Sell trade, quantity = 7: (99.00*3 + 98.75*5)/(3+5) + -0.25*7/15 = 98.7271&lt;/li&gt;
&lt;li&gt;Sell trade, quantity = 8…&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;With any sell trade of quantity 7 or more, the theoretical price would cross below the threshold of the best bid (98.75), indicating a profitable opportunity to trade, so we’d want to send an order to sell the remaining bid. With a trade quantity of 6 or less we wouldn’t want to do anything.&lt;/p&gt;
&lt;p&gt;The FPGA is pre-programmed to know the byte layout of the exchange’s trade message, so all it has to do now is wait for the market data, and then check a few bits and send the order. This doesn’t require advanced Verilog. For example, the message from the exchange could look like the following struct:&lt;/p&gt;
&lt;p&gt;struct Trade {&lt;/p&gt;
&lt;p&gt;uint64_t time;&lt;/p&gt;
&lt;p&gt;uint32_t security_id;&lt;/p&gt;
&lt;p&gt;uint8_t side;&lt;/p&gt;
&lt;p&gt;uint64_t price;&lt;/p&gt;
&lt;p&gt;uint32_t quantity;&lt;/p&gt;
&lt;p&gt;} __attribute__((packed));&lt;/p&gt;
&lt;p&gt;Because of the relative ease of this setup, it has become a very competitive trade – some trading firms can make these types of trade decisions in less than one microsecond. Also, because the FPGA connects directly to the exchange, an additional connection must be purchased for each FPGA, which can get expensive. Unfortunately, if you only have one shared connection, and broadcast data internally with a switch, the switch might introduce too much latency to be competitive. Many companies will now pay for multiple connections which raises their costs significantly.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Digression: ‘Minimum viable trading system’&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As I mentioned above, the simple 3-signal trading strategy could have made money several years ago. Even a few years ago, the ‘minimum viable trading system’ that could cover trading fees was simple enough that an individual could build a successful one. Here’s a good article by someone who created their own trading system in 2009, and could be another starting point to understand the basics of automated trading if all of this has gone over your head- &lt;a href=&quot;http://jspauld.com/post/35126549635/how-i-made-500k-with-machine-learning-and-hft&quot;&gt;http://jspauld.com/post/35126549635/how-i-made-500k-with-machine-learning-and-hft&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This guide only covers, at a high level, trading and work being done by professionals in established quantitative trading firms, so things like co-location, direct connection to the exchange without going through an API, using a high-performance language like C++ for production (never Python, R, Matlab, etc), Linux configuration (processor affinity, NUMA, etc), clock synchronization, etc are taken for granted. These are large and interesting topics which are now well understood inside and outside the industry.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Other strategies besides market micro-structure signals&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Market micro-structure signal based strategies, as described above before the two digressions, are just one type of strategy. Here are some other example trading strategy algorithm components used by many major quantitative trading companies:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Model based
&lt;/li&gt;
&lt;li&gt;Rule based
&lt;ul&gt;&lt;li&gt;Only buy or sell during a certain time range&lt;/li&gt;
&lt;li&gt;Don’t trade against an &lt;a href=&quot;http://www.nasdaqomx.com/digitalAssets/99/99957_1328-q15-iceberg-order-fs_a4_v4.pdf&quot;&gt;iceberg order&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Cancel a resting order if the &lt;a href=&quot;http://www.rigtorp.se/2013/06/08/estimating-order-queue-position.html&quot;&gt;queue position&lt;/a&gt; is worse than 50%&lt;/li&gt;
&lt;li&gt;Don’t trade if the last 10 trades lost money&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Supporting research infrastructure&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Now that you have a brief high-level overview of the production trading system, let’s dive deeper into research. The job of a researcher is to optimize the settings of the trading system and to ensure it is behaving properly. Working for an established company, this whole software system will likely already be in place, and your job would be to make it better.&lt;/p&gt;
&lt;p&gt;With that in mind, here are some more details about 4 other main software components I listed above that are programmed and used by the research team to optimize and analyze the trading strategy:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Parameter optimization: Most major quantitative trading firms have a combination of signals, model-based pricing, and rule-based logic. Each of these also have parameters. Parameters enable you to tailor a generic strategy to make more money on a specific product, or adapt it over time. For one product, you might want to weight a certain signal higher than another, or you might want to down-weight it as the signal decays. You quickly run into the curse of dimensionality as parameter permutations multiply. &lt;strong&gt;One of the main jobs for a researcher is to figure out the optimal settings for everything, or to figure out automated ways of optimizing them.&lt;/strong&gt; Some approaches include:
&lt;ul&gt;&lt;li&gt;Manual selection based on intuition&lt;/li&gt;
&lt;li&gt;Regression for signal weights or hedge ratios&lt;/li&gt;
&lt;li&gt;Live tweaking or AB testing in production&lt;/li&gt;
&lt;li&gt;Backtesting different settings and picking the best&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Production reconciliation: Sophisticated strategies have many internal components that need to be continually verified in live production trading. Measuring these, monitoring them, and alerting on discrepancies is how researchers make sure things are working as they expected. If the algorithm performs differently in production than it did on historical data, then it may lose money when it was supposed to be profitable.&lt;/li&gt;
&lt;li&gt;Backtesting simulator: Plenty of information is available publicly about backtesting, such as the tools available from Quantopian or TradeStation. Simulating a low latency strategy using tick data is challenging. The volume of data to simulate a single day reaches into the 100s of GBs so storing and replaying data requires carefully designed systems.&lt;/li&gt;
&lt;li&gt;Graphing: The trading strategy is a mathematical formula in a computer, so debugging it and adding new features can be difficult. Utilizing a Python or JavaScript plotting library to publish custom data and statistics can be helpful. Additionally, it is essential to understand positions and profits or losses during and after the trading day. Graphical representations of different types of data sets makes many tasks easier.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Most people who are new to the industry think that researchers primarily work on new signal development, and developers primarily optimize latency. Hopefully now it’s obvious that the system has so many components that those two jobs are just a few parts of a much wider set of roles and responsibilities. The most important skills for success are actually very close attention to detail, hard work, and trading intuition. On top of that it should be clear that having strong programming skills is essential. All of these systems are tailor-made in-house and have to be constantly tweaked and improved by the users themselves – you.&lt;/p&gt;

&lt;p&gt;If you’re interested in joining our team at Headlands, please see our &lt;a href=&quot;http://www.headlandstech.com/careers/&quot;&gt;careers&lt;/a&gt; page and &lt;strong&gt;send your resume to careers@headlandstech.com&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The information above is a collection of some helpful information to shed some light on what a quantitative trading firm does and what you could be doing if you worked at one.  The information, although intended to be helpful to you, should not be relied on and is not represented to be accurate or current. Please note this is by no means an exhaustive description of what goes on at a quantitative trading firm.  Nor should this be taken as covering industry best practices or everything you need to know to start trading quantitatively.  This is simply a very high overview of information I think those considering joining a quantitative trading firm may find useful as they navigate the interview process. &lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Appendix: Latency and the timing of events&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Similar to the breakdowns by Grace Hopper (&lt;a href=&quot;https://youtu.be/ZR0ujwlvbkQ?t=45m08s&quot;&gt;https://youtu.be/ZR0ujwlvbkQ?t=45m08s&lt;/a&gt;) and Peter Norvig (&lt;a href=&quot;http://norvig.com/21-days.html#answers&quot;&gt;http://norvig.com/21-days.html#answers&lt;/a&gt;), here’s a table of approximately how long things take:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Time to receive market data and send an order via an FPGA: ~300 nanoseconds&lt;/li&gt;
&lt;li&gt;Time to receive market data and send an order via a ‘slow’ software trading system: ~30 microseconds&lt;/li&gt;
&lt;li&gt;Minimum time between two packets from the exchange: ~10-1000 microseconds&lt;/li&gt;
&lt;li&gt;Microwave between BATS and INET stock exchanges: ~100 microseconds&lt;/li&gt;
&lt;li&gt;Fiber between BATS and INET stock exchanges: ~150 microseconds&lt;/li&gt;
&lt;li&gt;Time for an exchange to match an order and send a response: ~100 microseconds – ~5 milliseconds&lt;/li&gt;
&lt;li&gt;Microwave between NY and Chicago: ~4 milliseconds&lt;/li&gt;
&lt;li&gt;Fiber between NY and Chicago: ~7 milliseconds&lt;/li&gt;
&lt;li&gt;Fiber between NY and European exchanges: ~35 milliseconds&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Appendix: Exchange idiosyncrasies&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Exchanges almost all use different technology, some which dates back 10+ years. Different technology decisions and antiquated infrastructure have resulted in trading idiosyncrasies. There are many publicly available discussions of the effects of these idiosyncrasies. Here are a few interesting items:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.eurexchange.com/blob/238346/40b5f1d684271727ef8c9c8cb9cdd09e/data/presentation_insights-into-trading-system-dynamics_en.pdf&quot;&gt;https://www.eurexchange.com/blob/238346/40b5f1d684271727ef8c9c8cb9cdd09e/data/presentation_insights-into-trading-system-dynamics_en.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.bloomberg.com/news/articles/2017-03-17/currency-traders-race-to-reform-last-look-after-bank-scandals&quot;&gt;https://www.bloomberg.com/news/articles/2017-03-17/currency-traders-race-to-reform-last-look-after-bank-scandals&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.nyse.com/publicdocs/nyse/markets/nyse/NYSE-Order-Type-Usage.pdf&quot;&gt;https://www.nyse.com/publicdocs/nyse/markets/nyse/NYSE-Order-Type-Usage.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.cmegroup.com/notices/disciplinary/2016/11/NOTICE-OF-EMERGENCY-ACTION/NYMEX-16-0600-ELDORADO-TRADING-GROUP-LLC.html&quot;&gt;http://www.cmegroup.com/notices/disciplinary/2016/11/NOTICE-OF-EMERGENCY-ACTION/NYMEX-16-0600-ELDORADO-TRADING-GROUP-LLC.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://brillianteyes.wordpress.com/2010/08/28/espeed-trading-procotol/&quot;&gt;https://brillianteyes.wordpress.com/2010/08/28/espeed-trading-procotol/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://cdn.batstrading.com/resources/membership/CBOE_FUTURES_EXCHANGE_PLATFORM_CHANGE_MATRIX.pdf&quot;&gt;http://cdn.batstrading.com/resources/membership/CBOE_FUTURES_EXCHANGE_PLATFORM_CHANGE_MATRIX.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://quantitativebrokers.com/wp-content/uploads/2017/05/match-20130603.pdf&quot;&gt;http://quantitativebrokers.com/wp-content/uploads/2017/05/match-20130603.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.wsj.com/articles/SB10001424127887323798104578455032466082920&quot;&gt;www.wsj.com/articles/SB10001424127887323798104578455032466082920&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.wsj.com/articles/SB10001424127887324766604578456783718395580&quot;&gt;https://www.wsj.com/articles/SB10001424127887324766604578456783718395580&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 21 Jan 2018 01:37:13 +0000</pubDate>
<dc:creator>hendzen</dc:creator>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.headlandstech.com/2017/08/03/quantitative-trading-summary/</dc:identifier>
</item>
<item>
<title>Brushing up on operating systems and C programming</title>
<link>http://www.shubhro.com/2018/01/20/brushing-up-os-c/</link>
<guid isPermaLink="true" >http://www.shubhro.com/2018/01/20/brushing-up-os-c/</guid>
<description>&lt;head&gt;&lt;meta charset=&quot;UTF-8&quot;/&gt;&lt;title&gt;Brushing up on operating systems and C programming | Shubhro Saha&lt;/title&gt;&lt;link href=&quot;http://fonts.googleapis.com/css?family=Vollkorn&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;/&gt;&lt;link href=&quot;/static/css/styles.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;/&gt;&lt;link href=&quot;/static/css/syntax.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot;/&gt;&lt;/head&gt;&lt;body id=&quot;readabilityBody&quot; readability=&quot;34.390596745027&quot;&gt;
&lt;div class=&quot;container&quot; readability=&quot;26.9547920434&quot;&gt;&lt;br/&gt;&lt;h2&gt;Brushing up on operating systems and C programming&lt;/h2&gt;
&lt;p&gt;If you were like me in college, you first learned about the C programming language in an introductory computer science course. Then, perhaps you &lt;a href=&quot;http://www.shubhro.com/2014/11/21/operating-systems/&quot;&gt;took a really hard course in operating systems&lt;/a&gt;. Then, you never thought deeply about those concepts ever again.&lt;/p&gt;
&lt;p&gt;Given that many software engineering generalists today work in higher level languages, I find that pattern of behavior to be common. Yet, I often encounter situations where I wish I remembered something about C or operating systems, whether it be for an optimization I’m making, a new project I’m starting, or a reference I’m trying to understand.&lt;/p&gt;
&lt;p&gt;It’s hard to find good tutorials to refresh one’s memory of these subjects, so I want to share a few that I found useful.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://greenteapress.com/thinkos/thinkos.pdf&quot;&gt;Think OS&lt;/a&gt; is an accessible, conversational introduction to operating systems. Read it from start to finish or flip to the chapters discussing concepts you want to brush up on. Alternatively, you can reach for one of the many legendary OS textbooks out there like &lt;a href=&quot;https://en.wikipedia.org/wiki/Modern_Operating_Systems&quot;&gt;MOS&lt;/a&gt;, but I find that Think OS contains just the right level of detail I’m looking for.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://viewsourcecode.org/snaptoken/&quot;&gt;Snaptoken Tutorials&lt;/a&gt; walk you through writing substantial C language projects and explain underlying concepts along the way. As of now, the only tutorial up is for a text editor, but it’s fantastic.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://crasseux.com/books/ctutorial/&quot;&gt;The GNU C Programming Tutorial&lt;/a&gt; is a wonderfully organized reference for C programming. It’s an excellent resource to look something up.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;This is by no means an exhaustive list; I may even add to it in the future. But I felt it’s worth sharing now because I wish I had discovered them earlier.&lt;/p&gt;
&lt;p&gt;January 2018&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=16196194&quot;&gt;Hacker News&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/body&gt;</description>
<pubDate>Sun, 21 Jan 2018 00:13:51 +0000</pubDate>
<dc:creator>shbhrsaha</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.shubhro.com/2018/01/20/brushing-up-os-c/</dc:identifier>
</item>
<item>
<title>Relativ – A VR headset that you can build yourself for $100</title>
<link>https://github.com/relativty/Relativ</link>
<guid isPermaLink="true" >https://github.com/relativty/Relativ</guid>
<description>&lt;h3&gt;README.md&lt;/h3&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;
&lt;h4 align=&quot;center&quot;&gt;We couldn't afford an Oculus so we built one&lt;/h4&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://camo.githubusercontent.com/282134a019e96dbf43fed396654899723fd78c09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f72656c6174697674792f52656c617469762e737667&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/282134a019e96dbf43fed396654899723fd78c09/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f72656c6174697674792f52656c617469762e737667&quot; data-canonical-src=&quot;https://img.shields.io/github/license/relativty/Relativ.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://camo.githubusercontent.com/3a88e596488f987b60c735d80d1909c775bde94b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72656c6174697674792f52656c617469762e737667&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/3a88e596488f987b60c735d80d1909c775bde94b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f72656c6174697674792f52656c617469762e737667&quot; data-canonical-src=&quot;https://img.shields.io/github/stars/relativty/Relativ.svg&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://camo.githubusercontent.com/3e2eac692f2413f4ec1edcad35ac09b97a6eb0af/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f72656c6174697674792f52656c617469762e737667&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/3e2eac692f2413f4ec1edcad35ac09b97a6eb0af/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f72656c6174697674792f52656c617469762e737667&quot; data-canonical-src=&quot;https://img.shields.io/github/issues/relativty/Relativ.svg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/relativty/fastVR-sdk/blob/master/img/fastVR_demo.gif&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/relativty/fastVR-sdk/raw/master/img/fastVR_demo.gif&quot; width=&quot;100%&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 align=&quot;center&quot;&gt;Build your own VR headset for $100 💸&lt;/h4&gt;

&lt;p&gt;My name is &lt;a href=&quot;https://twitter.com/maxcoutte&quot; rel=&quot;nofollow&quot;&gt;Maxime Coutté&lt;/a&gt;. I’m 16 years old and I live in a small village in France where I’m the only teenager. With my best friends, &lt;a href=&quot;https://medium.com/@jonasceccon&quot; rel=&quot;nofollow&quot;&gt;Jonas Ceccon&lt;/a&gt; and &lt;a href=&quot;https://medium.com/@gabrielcombe&quot; rel=&quot;nofollow&quot;&gt;Gabriel Combe&lt;/a&gt;, and my math teacher Jerome Dieudonne (we call him Sensei) we built our own VR headset for $100.&lt;/p&gt;
&lt;p&gt;I started programming when I was 13, thanks to Sensei when he created a robotics club. On the first day we were 12 students, the next week we were 3 - yep, you guessed it, the other two were Gabriel and Jonas. I fell in love with VR because of an anime called SAO, but the problem was that the Oculus Rift was way too expensive for me. I talked about this with Gabriel and we both agreed that we should build our own VR headset. That got us into the math and physics behind VR (quaternions, proper acceleration, antiderivatives…). Then we bought the cheapest components we could and we reinvented VR. Now using &lt;a href=&quot;https://github.com/relativty/fastVR-sdk&quot;&gt;FastVR&lt;/a&gt; and Relativ you can build your VR headset too.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/relativty/Relativ/blob/master/img/gabriel.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/relativty/Relativ/raw/master/img/gabriel.png&quot; width=&quot;370&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;Gabriel:&lt;/strong&gt; I work on optics for &lt;a href=&quot;https://github.com/relativty/fastVR-sdk&quot;&gt;FastVR&lt;/a&gt;, 3D conception with Maxime and cheap tracking for the next big update.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/relativty/Relativ/blob/master/img/maxime.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/relativty/Relativ/raw/master/img/maxime.png&quot; width=&quot;370&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;Maxime:&lt;/strong&gt; I created &lt;a href=&quot;https://github.com/relativty/wrmhl&quot;&gt;WRMHL&lt;/a&gt; and with Gabriel we created &lt;a href=&quot;https://github.com/relativty/fastVR-sdk&quot;&gt;FastVR&lt;/a&gt;. I'm also behind the code for the hardware.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/relativty/Relativ/blob/master/img/jonas.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/relativty/Relativ/raw/master/img/jonas.png&quot; width=&quot;370&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;Jonas:&lt;/strong&gt; I convinced a Chinese factory to sell us components at premium prices and I'm working on a Master Guide for Relativ.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/relativty/Relativ/blob/master/img/sensei.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/relativty/Relativ/raw/master/img/sensei.png&quot; width=&quot;370&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;Sensei:&lt;/strong&gt; I'm the theoretician of the team. I teach them math and I help them solving algorithm issues.&lt;/p&gt;

&lt;p&gt;Thanks to this project I’ve had the incredible fortune to meet amazing people, including the chief architect at Oculus, Atman Brinstock. He gave me a precious piece of advice: &quot;open source it&quot;. I deleted all the code I had, and started rewriting it all from scratch, better. And I convinced my two friends and our math teacher to put the project into open source.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/relativty/Relativ/blob/master/img/headset.JPG&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/relativty/Relativ/raw/master/img/headset.JPG&quot; width=&quot;100%&quot;/&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Relativ is based on &lt;a href=&quot;https://github.com/relativty/wrmhl&quot;&gt;WRMHL&lt;/a&gt; and &lt;a href=&quot;https://github.com/relativty/fastVR-sdk&quot;&gt;FastVR&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;What you'll need&lt;/h2&gt;
&lt;h3&gt;What components ?&lt;/h3&gt;
&lt;p&gt;First you will need the following components:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Arduino Due, $34 for the official one or $10 for a Chinese clone&lt;/li&gt;
&lt;li&gt;GY-521 MPU-6050, $1&lt;/li&gt;
&lt;li&gt;5.5 inch 2560*1440 2K LCD Screen HDMI to MIPI, up to 100€ on Alie Express (&lt;a href=&quot;https://fr.aliexpress.com/item/5-5-inch-1440x2560-2K-IPS-LCD-screen-display-with-HDMI-top-MIPI-controller-board-for/32817672501.html?spm=a2g0w.10010108.1000016.1.2931f508qMQrlz&amp;amp;isOrigTitle=true&quot; rel=&quot;nofollow&quot;&gt;recommended&lt;/a&gt;) ⚠️ Price may vary a lot&lt;/li&gt;
&lt;li&gt;Fresnel lens Focal Length 50mm, $3 (&lt;a href=&quot;https://www.ebay.fr/itm/2Pcs-Fresnel-lens-Focal-Length-40-50-55-60-70-80mm-for-Google-Cardboard-3D-VR/201984369021?_trkparms=aid%3D222007%26algo%3DSIM.MBE%26ao%3D2%26asc%3D20170831090034%26meid%3Db81b9551aff144f6a8e2a988fbcdf814%26pid%3D100005%26rk%3D2%26rkt%3D6%26sd%3D232148146221&amp;amp;_trksid=p2047675.c100005.m1851&quot; rel=&quot;nofollow&quot;&gt;recommended&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/relativty/Relativ/blob/master/img/component.JPG&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/relativty/Relativ/raw/master/img/component.JPG&quot; width=&quot;100%&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;How to Install?&lt;/h3&gt;
&lt;p&gt;You can either install it using &lt;a href=&quot;https://git-scm.com/&quot; rel=&quot;nofollow&quot;&gt;Git&lt;/a&gt; or direct &lt;a href=&quot;https://github.com/relativty/Relativ/archive/master.zip&quot;&gt;Download&lt;/a&gt;. Or from the &lt;strong&gt;command line&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; Clone this repository&lt;/span&gt;
$ git clone https://github.com/relativty/Relativ
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Copy all folders in &lt;strong&gt;Relativ/src/libraries&lt;/strong&gt; and past them in your Arduino Libraries folder: &lt;strong&gt;Documents\Arduino\libraries&lt;/strong&gt;. You're now ready to build the headset!&lt;/p&gt;

&lt;p&gt;Now what you need to do is 3D-print the hardware; if needed you can change any models with provided Source Files. You will need to print the following:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Relativ_headset_structure.STL x1&lt;/li&gt;
&lt;li&gt;box_Arduino_DUE.stl x1&lt;/li&gt;
&lt;li&gt;box_lens_1.STL x2 ⚠️&lt;/li&gt;
&lt;li&gt;box_lens_2.STL x2 ⚠️&lt;/li&gt;
&lt;li&gt;box_mpu6050.STL x1&lt;/li&gt;
&lt;li&gt;box_screen_adaptor.STL x1&lt;/li&gt;
&lt;li&gt;box_screen_controller.STL x1&lt;/li&gt;
&lt;li&gt;box_screen_spherical.STL x1 OR box_screen.STL x1 ⚠️&lt;/li&gt;
&lt;li&gt;support_lens.STL x1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Make sure you have all the libraries needed installed and upload the following program to the Arduino:&lt;/p&gt;
&lt;h4&gt;Path: Relativ/src/main/main.ino&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/relativty/Relativ/blob/master/img/arduino-upload.gif&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/relativty/Relativ/raw/master/img/arduino-upload.gif&quot;/&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can now play with your headset by downloading some cool demos by &lt;a href=&quot;https://github.com/relativty/Relativ/releases/download/v0.1-beta/Unity_build.zip&quot;&gt;clicking here&lt;/a&gt;. Or build your own game in a minute using the Relativty sdk, learn more by &lt;a href=&quot;https://github.com/relativty/fastVR-sdk&quot;&gt;clicking here&lt;/a&gt; .&lt;/p&gt;
&lt;p&gt;I would love to hear about what you’ve experienced building the headset or help if you have any questions. Ping me at maxime@relativty.com or &lt;a href=&quot;https://twitter.com/maximecoutte&quot; rel=&quot;nofollow&quot;&gt;@maximecoutte&lt;/a&gt;.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;😍🤙 You can now chan with me and the Fellowship &lt;a href=&quot;https://discord.gg/W9VKbjU&quot;&gt;https://discord.gg/W9VKbjU&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;&amp;lt;&amp;gt; with ❤️, maxime@relativty.com&lt;/strong&gt;&lt;/p&gt;
&lt;/article&gt;</description>
<pubDate>Sat, 20 Jan 2018 19:47:19 +0000</pubDate>
<dc:creator>realusername</dc:creator>
<og:image>https://avatars2.githubusercontent.com/u/31791204?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>relativty/Relativ</og:title>
<og:url>https://github.com/relativty/Relativ</og:url>
<og:description>Relativ - 🔥 Build your own VR headset for $100</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/relativty/Relativ</dc:identifier>
</item>
<item>
<title>Training Your Brain So That You Don’t Need Reading Glasses (2017)</title>
<link>https://www.nytimes.com/2017/03/27/upshot/training-your-brain-so-that-you-dont-need-reading-glasses.html</link>
<guid isPermaLink="true" >https://www.nytimes.com/2017/03/27/upshot/training-your-brain-so-that-you-dont-need-reading-glasses.html</guid>
<description>&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;310&quot; data-total-count=&quot;1734&quot; id=&quot;story-continues-4&quot;&gt;I’m 45. I don’t need to correct my vision for presbyopia yet, but I can tell it’s coming. I can still read the The New York Times print edition with ease, but to read text in somewhat smaller fonts, I have to strain. Any year now, I figured my eye doctor would tell me it was time to talk about bifocals.&lt;/p&gt;
&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;16&quot; data-total-count=&quot;1750&quot;&gt;Or so I thought.&lt;/p&gt;
&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;132&quot; data-total-count=&quot;1882&quot;&gt;Then I undertook a monthslong, strenuous regimen designed to train my brain to correct for what my eye muscles no longer can manage.&lt;/p&gt;
&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;385&quot; data-total-count=&quot;2267&quot;&gt;The approach &lt;a href=&quot;http://www.wsj.com/articles/SB10001424052702304854804579234162915397686&quot;&gt;has been reported&lt;/a&gt; in &lt;a href=&quot;http://www.foxnews.com/science/2014/01/23/app-can-eliminate-need-for-reading-glasses.html&quot;&gt;the news media&lt;/a&gt;, and perhaps you’ve heard of it. It’s based on perceptual learning, the improvement of visual performance as a result of demanding training on specific images. Some experts have &lt;a href=&quot;http://www.cbsnews.com/news/can-an-app-help-you-ditch-your-reading-glasses/&quot;&gt;expressed skepticism&lt;/a&gt; that it can work, but a number of &lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S004269890900282X&quot;&gt;studies provide evidence&lt;/a&gt; that it can improve visual acuity, contrast sensitivity and reading speed.&lt;/p&gt;
&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;490&quot; data-total-count=&quot;2757&quot;&gt;The training involves looking at images called “&lt;a href=&quot;http://neuroanatody.com/2016/05/whats-in-a-gabor-patch/&quot;&gt;Gabor patches&lt;/a&gt;” in various conditions. Gabor patches &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pubmed/7463179?dopt=Abstract&quot;&gt;optimally stimulate the part of the brain responsible for vision&lt;/a&gt;. A great deal of the training involves trying to see Gabor patches placed between closely spaced, distracting flankers. In training, the flanker spacing is varied, the target contrast is turned way down, and the images are flashed on a screen for fractions of a second — to the point that one can barely see the target.&lt;/p&gt;
&lt;span class=&quot;visually-hidden&quot;&gt;Photo&lt;/span&gt;
&lt;div class=&quot;image&quot;&gt;&lt;img src=&quot;https://static01.nyt.com/images/2017/03/28/upshot/28up-healthglasses/28up-healthglasses-master675-v2.jpg&quot; alt=&quot;&quot; class=&quot;media-viewer-candidate&quot; data-mediaviewer-src=&quot;https://static01.nyt.com/images/2017/03/28/upshot/28up-healthglasses/28up-healthglasses-superJumbo.jpg&quot; data-mediaviewer-caption=&quot;A screenshot of a Gabor patch from the GlassesOff app tutorial.&quot; data-mediaviewer-credit=&quot;GlassesOff&quot; itemprop=&quot;url&quot; itemid=&quot;https://static01.nyt.com/images/2017/03/28/upshot/28up-healthglasses/28up-healthglasses-master675-v2.jpg&quot;/&gt;&lt;/div&gt;
&lt;span class=&quot;caption-text&quot;&gt;A screenshot of a Gabor patch from the GlassesOff app tutorial.&lt;/span&gt; &lt;span class=&quot;credit&quot; itemprop=&quot;copyrightHolder&quot;&gt;&lt;span class=&quot;visually-hidden&quot;&gt;Credit&lt;/span&gt; GlassesOff&lt;/span&gt;
&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;161&quot; data-total-count=&quot;2918&quot;&gt;Do this and similar exercises hundreds of times over multiple sessions weekly; continue for months; and, gradually, presbyopia lessens, &lt;a href=&quot;http://www.nature.com/articles/srep25188&quot;&gt;a number&lt;/a&gt; of &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pubmed/26024459&quot;&gt;studies show&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;152&quot; data-total-count=&quot;3070&quot;&gt;&lt;a href=&quot;http://www.nature.com/articles/srep00278&quot;&gt;One&lt;/a&gt; &lt;a href=&quot;http://www.nature.com/articles/srep00278&quot;&gt;study also&lt;/a&gt; examined functions of the eye itself and found none of these improvements were because of changes in the eye. They’re all in the brain.&lt;/p&gt;
&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;168&quot; data-total-count=&quot;3238&quot;&gt;Various smartphone apps say they offer this kind of vision-improving training; I used one called &lt;a href=&quot;http://www.glassesoff.com/&quot;&gt;GlassesOff&lt;/a&gt;, the only one I found that was backed by scientific studies.&lt;/p&gt;


&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;572&quot; data-total-count=&quot;3810&quot;&gt;Perceptual learning can improve the vision of people who already see quite well and those with other conditions. For example, &lt;a href=&quot;http://www.nature.com/articles/srep07251&quot;&gt;a study&lt;/a&gt; tested the approach in 23 young adults, around age 24. Compared with a control group of 20 young adults, the treatment group increased letter recognition speed. Similar training is &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pubmed/19250947&quot;&gt;an effective component&lt;/a&gt; in &lt;a href=&quot;https://web.archive.org/web/20130709055313/http://optometry.berkeley.edu/pdf-s/berkoptmagazine_2012sml.pdf&quot;&gt;treating amblyopia&lt;/a&gt;, also called “&lt;a href=&quot;https://nei.nih.gov/health/amblyopia/amblyopia_guide&quot;&gt;lazy eye&lt;/a&gt;,” which is the most frequent cause of vision loss in infants and children, &lt;a href=&quot;https://web.archive.org/web/20130709055313/http://optometry.berkeley.edu/pdf-s/berkoptmagazine_2012sml.pdf&quot;&gt;affecting 3 percent of the population&lt;/a&gt;. It may also improve vision in those with &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pubmed/18361977?dopt=Abstract&quot;&gt;mild myopia&lt;/a&gt; (nearsightedness).&lt;/p&gt;
&lt;div id=&quot;story-ad-2&quot; class=&quot;story-ad ad ad-placeholder nocontent robots-nocontent&quot;&gt;

&lt;a class=&quot;visually-hidden skip-to-text-link&quot; href=&quot;https://www.nytimes.com/2017/03/27/upshot/training-your-brain-so-that-you-dont-need-reading-glasses.html#story-continues-5&quot;&gt;Continue reading the main story&lt;/a&gt;&lt;/div&gt;
&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;635&quot; data-total-count=&quot;4445&quot; id=&quot;story-continues-5&quot;&gt;It should be acknowledged that some researchers involved in many of these studies have financial ties to GlassesOff. However, &lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S0042698913002770&quot;&gt;other studies with no commercial links&lt;/a&gt; obtained similar results, and several scientists I spoke to, including those without ties to GlassesOff, thought the science behind the app was credible. &lt;a href=&quot;http://pss.sagepub.com/content/early/2015/03/06/0956797614567510&quot;&gt;One study published in Psychological Science&lt;/a&gt; trained 16 college-aged adults and 16 older adults (around age 71) with Gabor patch exercises for 1.5 hours per day for seven days. After training, the older adults’ ability to see low-contrast images improved to the level that the college-age ones had before training.&lt;/p&gt;
&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;154&quot; data-total-count=&quot;4599&quot;&gt;Scientists don’t know exactly how perceptual learning relieves presbyopia, but they have some clues based on how our brain processes visual information.&lt;/p&gt;
&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;639&quot; data-total-count=&quot;5238&quot;&gt;After first taking in “raw data” of an image through the eye, different sets of neurons in the brain process it as &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pubmed/9509156&quot;&gt;separate features&lt;/a&gt; like edges and colors. Then the brain must coordinate activity across sets of neurons to assemble these features into recognizable objects like chairs, faces, letters or words. Reading at our normal pace, the brain has only about &lt;a href=&quot;http://www.sciencedirect.com/science/article/pii/S1364661303002596&quot;&gt;250 milliseconds&lt;/a&gt; to do this work until the eyes automatically move onto the next letter or word. Once they do so, we’re taking in more information from whatever the eyes focus on next. If we haven’t yet processed the prior set of information, we can’t understand it.&lt;/p&gt;
&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;373&quot; data-total-count=&quot;5611&quot;&gt;Visual processing time is challenged and slowed by noisy images, low contrast or closely spaced information (like small fonts). There is a &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pubmed/18226828&quot;&gt;bottleneck in the brain&lt;/a&gt; as it attempts to build and then comprehend the image. Therefore, enhancing and speeding up the ability to process image components — through perceptual learning — improves a wide range of vision functions.&lt;/p&gt;
&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;351&quot; data-total-count=&quot;5962&quot;&gt;What’s surprising is that this is possible in adult brains. Neuroplasticity — the ability of the brain’s processing functions to change to acquire new skills — is most strongly associated with childhood. It’s still more pronounced in children than adults, but for some skills, &lt;a href=&quot;https://books.google.com/books?id=pu4Y9Ss1-GsC&amp;amp;lpg=PP1&amp;amp;dq=Fahle%2C%20M.%2C%20%26%20Poggio%2C%20T.%20(2002).%20Perceptual%20learning&amp;amp;pg=PR7#v=onepage&amp;amp;q=Fahle,%20M.,%20&amp;amp;%20Poggio,%20T.%20(2002).%20Perceptual%20learning&amp;amp;f=false&quot;&gt;including vision&lt;/a&gt;, the brain is more malleable than once thought.&lt;/p&gt;
&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;598&quot; data-total-count=&quot;6560&quot;&gt;The training with GlassesOff is long and challenging. I found it fun initially, perhaps because it was new. But weeks into it, I began to dread the monotonous labor. Yet, after a couple of months, the app reports I can read fonts nearly one third the size I could when I started and much more rapidly. According to feedback from GlassesOff, my vision after training is equivalent to a man about 10 years younger than my age. If I reach 50 — the age at which &lt;a href=&quot;http://www.nature.com/articles/srep00278&quot;&gt;almost everyone needs corrective lenses&lt;/a&gt; to read — and still don’t need reading glasses, I may conclude that the training has paid off.&lt;/p&gt;
&lt;p class=&quot;story-body-text story-content&quot; data-para-count=&quot;326&quot; data-total-count=&quot;6886&quot;&gt;As apps go, GlassesOff is not cheap. I paid $24.99 for three months of use — long enough to get me through the initial program. Upon completion, I was invited to pay another $59.99 per year for maintenance training. It’s a nice option, but the hard work and price probably mean that the bifocals market will remain strong.&lt;/p&gt;
&lt;a class=&quot;visually-hidden skip-to-text-link&quot; href=&quot;https://www.nytimes.com/2017/03/27/upshot/training-your-brain-so-that-you-dont-need-reading-glasses.html#whats-next&quot;&gt;Continue reading the main story&lt;/a&gt;</description>
<pubDate>Sat, 20 Jan 2018 18:23:07 +0000</pubDate>
<dc:creator>walterbell</dc:creator>
<og:url>https://www.nytimes.com/2017/03/27/upshot/training-your-brain-so-that-you-dont-need-reading-glasses.html</og:url>
<og:type>article</og:type>
<og:title>Training Your Brain So That You Don’t Need Reading Glasses</og:title>
<og:description>A monthslong regimen can compensate for what eye muscles no longer can do.</og:description>
<og:image>https://static01.nyt.com/images/2017/03/28/upshot/28up-healthglasses/28up-healthglasses-facebookJumbo.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.nytimes.com/2017/03/27/upshot/training-your-brain-so-that-you-dont-need-reading-glasses.html</dc:identifier>
</item>
<item>
<title>Intel Has a Big Problem</title>
<link>https://www.bloomberg.com/news/features/2018-01-18/intel-has-a-big-problem-it-needs-to-act-like-it</link>
<guid isPermaLink="true" >https://www.bloomberg.com/news/features/2018-01-18/intel-has-a-big-problem-it-needs-to-act-like-it</guid>
<description>&lt;p class=&quot;section-break&quot;&gt;Even without the aid of Hunter S. Thompson’s favorite drugs, &lt;a href=&quot;https://www.bloomberg.com/topics/ces&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; target=&quot;_blank&quot;&gt;CES&lt;/a&gt;, held in Las Vegas each January, has always been a little surreal. This year’s bacchanal was crammed with &lt;a href=&quot;https://www.bloomberg.com/news/photo-essays/2017-01-04/shiny-visions-of-the-future-from-superchaged-chips-to-self-driving-cars&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; target=&quot;_blank&quot;&gt;drones&lt;/a&gt;, &lt;a href=&quot;https://www.bloomberg.com/news/articles/2018-01-02/lyft-aptiv-to-partner-on-driverless-ride-hailing-at-vegas-show&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; target=&quot;_blank&quot;&gt;self-driving cars&lt;/a&gt;, and &lt;a href=&quot;https://www.bloomberg.com/news/articles/2018-01-09/u-by-moen-brings-smart-home-digital-assistants-into-the-bathroom&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; target=&quot;_blank&quot;&gt;internet-connected toilet seats&lt;/a&gt;—and the opening keynote speech was stranger than any of that. On Jan. 8, 5,000 ticket holders made their way through a sea of hired models and ultra-high-definition TVs to the Monte Carlo Resort and Casino on the Strip, where they squeezed into a theater to watch a two-hour psychedelic variety show. The opening act, a Blue Man Group-style quartet called Algorithm ’n Blues, pantomimed a performance of &lt;em&gt;Human&lt;/em&gt; by the Killers, backed up by a digital bassist on a giant LCD screen, flying drones that played keys on a giant piano, and a trio of acrobats, dressed like extras from &lt;em&gt;Tron&lt;/em&gt;, who performed a trampoline routine. And that’s not the weird part.&lt;/p&gt;


&lt;p&gt;After the music came Brian Krzanich, chief executive of &lt;a href=&quot;https://www.bloomberg.com/quote/INTC:US&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; rel=&quot;nofollow noopener&quot;&gt;Intel Corp.&lt;/a&gt;, doing about the best Willy Wonka impression one can do in a button-down blue dress shirt and jeans. “I’d love nothing more than to simply put my phone away and take this evening to truly celebrate innovation with you,” the 57-year-old CES regular said, bragging about his company’s advances in &lt;a href=&quot;https://www.bloomberg.com/news/articles/2018-01-09/new-google-headset-camera-aim-to-spread-vr-beyond-gaming&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; target=&quot;_blank&quot;&gt;virtual reality&lt;/a&gt; and new partnerships with autonomous-vehicle technology companies. Former NFL quarterback Tony Romo appeared onstage to talk up Intel’s work in 3D video, and Krzanich showed off a full-size pilotless helicopter before capping the evening by suggesting they head outside to see a light show over the famous Bellagio fountains involving hundreds of drones—all, of course, either made by Intel or running on Intel chips.&lt;/p&gt;


&lt;div class=&quot;image&quot;&gt;
&lt;div id=&quot;lazy-img-322676350&quot; class=&quot;lazy-img&quot;&gt;&lt;img src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i3OohSMYBylo/v3/60x-1.jpg&quot; data-native-src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/i3OohSMYBylo/v3/-1x-1.jpg&quot; class=&quot;lazy-img__image&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;CEO Krzanich holds Intel’s latest drone, the Shooting Star Mini, as he speaks at CES in Las Vegas on Jan. 8.  &lt;/p&gt;
&lt;p&gt;Photographer: Rick Wilking/Reuters&lt;/p&gt;
&lt;p&gt;The whole thing was a dizzying reminder that although Intel isn’t the household name it was during the PC boom of the 1990s, it can still put on a show. The company makes about 90 percent of the world’s computer processors and 99 percent of the server chips in the data centers that effectively run the internet. While the world’s largest chipmaker has struggled to expand beyond those core businesses, it reported $60 billion in 2017 revenue at a gross margin of 63 percent, an unimaginable profit for most factory owners.&lt;/p&gt;


&lt;p&gt;What made the Intel keynote so surreal was that Krzanich barely mentioned the potentially catastrophic news that was on everyone’s mind. The previous week, the &lt;em&gt;Register&lt;/em&gt;, a British technology journal, reported that independent researchers had &lt;a href=&quot;https://www.theregister.co.uk/2018/01/02/intel_cpu_design_flaw/&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;&gt;discovered flaws in Intel’s chip designs&lt;/a&gt; that hackers could exploit to steal data thought to be the most secure. These vulnerabilities, known as Meltdown and Spectre, are a very, very big deal, allowing hackers to peek at the part of the computer where companies and individuals store passwords, encryption keys, and most anything sensitive. The flaws are &lt;a href=&quot;https://www.bloomberg.com/news/articles/2018-01-08/-it-can-t-be-true-inside-the-semiconductor-industry-s-meltdown&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; target=&quot;_blank&quot;&gt;unprecedented&lt;/a&gt;. Every PC, every smartphone, and every server in the world is exposed. The episode has already led to lawsuits and calls for investigations, and undermines more than a decade of Intel’s technical wizardry.&lt;/p&gt;


&lt;p&gt;For the past few years, major cloud providers have sought ways to reduce their dependence on Intel’s server chip monopoly, quietly developing &lt;a href=&quot;https://www.bloomberg.com/news/articles/2017-05-17/google-to-sell-new-ai-supercomputer-chip-via-cloud-business&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; target=&quot;_blank&quot;&gt;their own models&lt;/a&gt; or funding nascent competitors. And just days before Krzanich took the stage in Vegas, Intel gave those companies—and everybody else—a massive incentive to accelerate those efforts.&lt;/p&gt;

&lt;p&gt;Even the researchers who discovered Meltdown and Spectre initially didn’t believe what they were seeing. “That would have been such a major f--- -up by Intel that it can’t be possible,” researcher Michael Schwarz recalls thinking. Spectre affects all modern chips, including those made by competitors, but the easier hack, Meltdown, applies almost exclusively to chips made by Intel.&lt;/p&gt;
&lt;p&gt;The flaws can be patched, but those patches could slow the Intel chips by as much as 30 percent, the equivalent of turning a state-of-the-art server chip into one from 2013. “There is no playbook for something like this,” says Charles Carmakal, a vice president at &lt;a href=&quot;https://www.bloomberg.com/quote/7600875Z:US&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; rel=&quot;nofollow noopener&quot;&gt;Mandiant&lt;/a&gt;, the arm of security company &lt;a href=&quot;https://www.bloomberg.com/quote/FEYE:US&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; rel=&quot;nofollow noopener&quot;&gt;FireEye&lt;/a&gt; that consults on high-profile hacks. “I don’t think I’ve ever seen a vulnerability that worked across so many different operating systems and devices.”&lt;/p&gt;
&lt;p&gt;If the slowdown turns out to be anywhere near as bad as some think it could be, it’ll amount to a major price increase for data center owners, who could in turn demand that Intel cover the cost. (So far, the big cloud providers have said their customers won’t be affected. Their plans, and the costs, remain unclear.) And because Intel is so reliant on chip revenue, there’d be no easy way to make up those losses. Intel’s stock is down 5 percent since the &lt;em&gt;Register&lt;/em&gt; report; shares of Advanced Micro Devices Inc., its only real competitor for PC and server chips, are up 11 percent.&lt;/p&gt;
&lt;p&gt;During the six months Intel was quietly working to try to fix the vulnerabilities, Krzanich sold $24 million in company shares. Intel says the stock sale was part of a plan that had been in place before anyone there knew about Meltdown or Spectre, but the day after Krzanich’s CES speech, two U.S. senators sent letters to the Securities and Exchange Commission and the Department of Justice demanding investigations. Consumer and shareholder lawyers have filed a dozen class actions against Intel, and there are few signs the pressure will let up on Krzanich anytime soon. In a research note, an analyst for &lt;a href=&quot;https://www.bloomberg.com/quote/4080071Z:US&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; rel=&quot;nofollow noopener&quot;&gt;Sanford C. Bernstein &amp;amp; Co.&lt;/a&gt; called the stock sale “indefensible.”&lt;/p&gt;
&lt;aside class=&quot;pullquote&quot; data-align=&quot;center&quot; readability=&quot;3&quot;&gt;&lt;p class=&quot;passage&quot;&gt;“I don’t think I’ve ever seen a vulnerability that worked across so many different operating systems and devices”&lt;/p&gt;
&lt;/aside&gt;&lt;p&gt;Intel, which declined to make Krzanich available for comment, has treated Meltdown and Spectre as something close to a nonstory. In its initial statement, issued on Jan. 3, the company disputed that Spectre and Meltdown represented “flaws,” describing them as merely a new field of “research” into an industrywide phenomenon. It said any slowdowns would be minimal, close to zero for most people, and that the episode would have no impact on Intel’s business. At CES, after Algorithm ’n Blues but before Romo, Krzanich briefly addressed the not-flaw by thanking Intel’s peers for “coming together” to “address the recent security findings.”&lt;/p&gt;
&lt;p&gt;Intel’s clients, including the biggest companies in the technology industry, have mostly kept quiet. They have no alternative supplier. Privately, some are seething. The day after Krzanich’s big show, &lt;a href=&quot;https://www.bloomberg.com/quote/MSFT:US&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; rel=&quot;nofollow noopener&quot;&gt;Microsoft Corp.&lt;/a&gt; published a blog post disputing Intel’s earlier assertion that users wouldn’t notice the slowdowns. Navin Shenoy, an Intel executive vice president, said in a statement that customer security is “a critical priority” for the company. In private conversations with clients, Intel’s top managers haven’t always acted that way, treating a disaster that threatens the security of every computer user and the profits of a whole category of businesses as no big deal, according to an executive at one of Intel’s large customers. The potential fallout isn’t an academic concern, the executive says, “it’s f---ing scary.”&lt;/p&gt;
&lt;p class=&quot;section-break&quot;&gt;Part of what makes Meltdown and Spectre so terrifying is that they upend more than a decade of conventional wisdom about information security. Starting in the mid-2000s, Intel added a layer of security within its chips and began encouraging developers to store users’ most sensitive information in the walled-off area rather than in regular software memory. Only about two years ago did researchers first notice, and begin trying to crack, a feature called speculative execution that Intel uses to speed up its chips. It essentially allows a chip to access any data it guesses a user is about to ask for, even if it’s inside the secure area, before checking whether the user is allowed to access it. This is a big reason computers and smartphones have kept getting faster year after year. It also left a gaping security hole.&lt;/p&gt;
&lt;p&gt;The feature’s vulnerabilities were discussed at conferences and in academic papers but were considered merely theoretical until last spring, when &lt;a href=&quot;https://www.bloomberg.com/news/articles/2018-01-17/how-a-22-year-old-discovered-the-worst-chip-flaws-in-history&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; target=&quot;_blank&quot;&gt;Jann Horn&lt;/a&gt;, a 22-year-old researcher in &lt;a href=&quot;https://www.bloomberg.com/quote/GOOGL:US&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; rel=&quot;nofollow noopener&quot;&gt;Google&lt;/a&gt;’s elite cybersecurity division, succeeded in reading private data from the secure area. Horn informed Intel in June, beating out three other research teams that discovered the flaw later in 2017. Together, they began working with Intel to patch the flaws; until the &lt;em&gt;Register&lt;/em&gt; report, they’d planned to disclose their findings on Jan. 9. As Google pointed out in a blog post about the discovery, the security flaws could allow a cloud user to covertly snoop on another customer’s machine. Anyone with an Amazon Web Services account could, in theory, steal another AWS user’s login data and access their files, though that would often require physical access to the target machine.&lt;/p&gt;
&lt;div class=&quot;image&quot;&gt;
&lt;div id=&quot;lazy-img-322675778&quot; class=&quot;lazy-img&quot;&gt;&lt;img src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/issCSnoNtDnI/v0/60x-1.png&quot; data-native-src=&quot;https://assets.bwbx.io/images/users/iqjWHBFdfxIU/issCSnoNtDnI/v0/-1x-1.png&quot; class=&quot;lazy-img__image&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;In interviews, Intel executives dispute suggestions that the company’s focus on chip speeds led it to overlook obvious vulnerabilities. Intel says it’s already provided software fixes for 90 percent of its chips and that this is nothing out of the ordinary. “We have an ongoing process to make our products better,” says Stephen Smith, general manager of the company’s data center group. “We just happen to be doing it under a spotlight now.” At CES, Krzanich told the crowd that “as of now” Intel had “not received any information that these exploits have been used to obtain customer data.”&lt;/p&gt;
&lt;p&gt;This sounds more comforting than it probably should. Security analysts say that if four groups of researchers independently figured out the exploits, then some number of governments with sophisticated cyberweapons programs (China, Russia, the U.S.) likely did, too. An intelligence agency armed with Spectre or Meltdown would likely aim big, according to Mandiant’s Carmakal. “A government wouldn’t use this to break into Target,” he says. “They’d use it to get into the Department of Defense.”&lt;/p&gt;

&lt;p class=&quot;section-break&quot;&gt;So far, Meltdown and Spectre probably pose less risk to the average person than, say, a simple phishing attack in which a hacker tries to send you to a malicious website. They won’t lead to the kind of widespread panic that resulted from the 2017 hack of Equifax’s customer database.&lt;/p&gt;
&lt;p&gt;But that could change. Hackers who hadn’t tried to break into Intel’s hardware, believing there was no way it would leave a side door open, are now seeking ways in. “You’re going to be looking for other things like this,” says Jeff Pollard, an analyst with the research firm Forrester. “This is a new kind of attack. This is going to linger.”&lt;/p&gt;
&lt;p&gt;And long-term fixes won’t be easy. While coders can pull a few all-nighters to close holes in software, a chip takes years to design, test, and mass-produce. Each model can cost tens of millions of dollars to develop. For now, computer owners and data center operators will have to make an unsavory choice: Use Intel’s software patches and accept &lt;a href=&quot;https://www.bloomberg.com/news/articles/2018-01-09/microsoft-says-chip-flaw-fix-may-significantly-slow-some-servers&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; target=&quot;_blank&quot;&gt;slower speeds&lt;/a&gt;, or skip the patches and remain at risk. (Intel has &lt;a href=&quot;https://www.bloomberg.com/news/articles/2018-01-09/intel-ceo-says-patch-to-fix-chip-security-will-slow-computers&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; target=&quot;_blank&quot;&gt;already said&lt;/a&gt; patches are causing some machines to reboot more often than usual.) Future designs will include hard-wired fixes that speed things up, but the first versions of those won’t appear until later this year, the company says.&lt;/p&gt;
&lt;p&gt;All of this puts Intel in a tough spot. The company is a nonfactor in the smartphone-chips business dominated by &lt;a href=&quot;https://www.bloomberg.com/quote/005930:KS&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; rel=&quot;nofollow noopener&quot;&gt;Samsung&lt;/a&gt;, &lt;a href=&quot;https://www.bloomberg.com/news/articles/2017-11-08/qualcomm-begins-selling-server-chip-it-says-beats-rival-intel-s&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; target=&quot;_blank&quot;&gt;Qualcomm&lt;/a&gt;, and &lt;a href=&quot;https://www.bloomberg.com/quote/ARM:LN&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; rel=&quot;nofollow noopener&quot;&gt;ARM&lt;/a&gt;, and rival &lt;a href=&quot;https://www.bloomberg.com/quote/NVDA:US&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; rel=&quot;nofollow noopener&quot;&gt;Nvidia&lt;/a&gt; has taken a commanding lead in the fast-growing market for graphics chips used in artificial intelligence applications. Now, Meltdown and Spectre threaten the core of Intel’s business. The company has no competitor in server chips at the moment, but this episode could change that. Microsoft and Google have publicly praised &lt;a href=&quot;https://www.bloomberg.com/quote/QCOM:US&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; rel=&quot;nofollow noopener&quot;&gt;Qualcomm Inc.&lt;/a&gt;’s first server chip, which went on sale in November, and &lt;a href=&quot;https://www.bloomberg.com/quote/AAPL:US&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; rel=&quot;nofollow noopener&quot;&gt;Apple&lt;/a&gt;, Google, Microsoft, &lt;a href=&quot;https://www.bloomberg.com/quote/AMZN:US&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; rel=&quot;nofollow noopener&quot;&gt;Amazon&lt;/a&gt;, and &lt;a href=&quot;https://www.bloomberg.com/quote/FB:US&quot; itemprop=&quot;StoryLink&quot; itemscope=&quot;itemscope&quot; rel=&quot;nofollow noopener&quot;&gt;Facebook&lt;/a&gt; all have internal divisions working on chip designs.&lt;/p&gt;

&lt;p&gt;Intel’s more immediate threat is political. It’ll almost certainly have to withstand criticism from lawmakers at a time when governments around the world are increasingly skeptical of tech companies with de facto monopolies. “This hyper-dependence on one chipmaker, indeed one technology, although billed as a way to lower prices, has had the effect also of greatly increasing society’s exposure not only to hackers but also to ‘shock events’ that disrupt entire systems,” the Open Markets Institute, a Washington think tank that advocates for controls on market concentration, wrote in its weekly newsletter on Jan. 11. For now, Intel’s big problem is Krzanich’s stock sales, but if it becomes clear that customers have been harmed by hacking or higher costs, regulators will likely seek recourse through consumer protection suits, antitrust investigations, or both.&lt;/p&gt;
&lt;p&gt;Intel has faced this kind of public pressure before. In 1994 the company was heavily criticized for trying to ignore evidence that its Pentium chips were generating errors for certain obscure calculations. The crisis caused IBM to announce that it would no longer ship machines that used the flawed chips. Intel’s meticulously constructed brand, Intel Inside, which had served as a sort of Good Housekeeping Seal for computer buyers, suddenly looked questionable. As part of Intel’s extensive mea culpa, then-CEO Andy Grove offered to replace all the buggy chips and took an inventory writedown of $475 million, about half its annual R&amp;amp;D budget at the time.&lt;/p&gt;
&lt;p&gt;Grove’s lesson, as he recounted in his business-advice book &lt;em&gt;Only the Paranoid Survive&lt;/em&gt;, was that Intel had been caught out. Even a quarter-century into its existence, the massive company still saw itself as a scrappy tech startup. With its size and influence, he acknowledged, came new responsibilities. “The trouble was,” Grove wrote, “not only didn’t we realize that the rules had changed, but what was worse, we didn’t know what rules we now had to abide by.”&lt;/p&gt;
&lt;p&gt;Intel has been the top chipmaker for the past 25 years, but Meltdown and Spectre could turn out to be much worse than the Pentium bug. If the company wants to maintain its position, it’ll need real humility, not cheap theatrics.&lt;br/&gt;—&lt;em&gt;With Dina Bass, Mark Bergen, Alex Webb, and Dune Lawrence&lt;/em&gt;&lt;/p&gt;


</description>
<pubDate>Sat, 20 Jan 2018 16:46:40 +0000</pubDate>
<dc:creator>MilnerRoute</dc:creator>
<og:description>Meltdown and Spectre have opened up new hacking threats, sparked class actions, and enraged longtime partners.</og:description>
<og:image>https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iM.QiZ_Yfsio/v0/1200x630.jpg</og:image>
<og:title>Intel Has a Big Problem and It Needs to Act Like It</og:title>
<og:type>article</og:type>
<og:url>https://www.bloomberg.com/news/features/2018-01-18/intel-has-a-big-problem-it-needs-to-act-like-it</og:url>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.bloomberg.com/news/features/2018-01-18/intel-has-a-big-problem-it-needs-to-act-like-it</dc:identifier>
</item>
<item>
<title>British 15-year-old gained access to intelligence, pretending to be head of CIA</title>
<link>http://www.telegraph.co.uk/news/2018/01/19/british-15-year-old-gained-access-intelligence-operations-afghanistan</link>
<guid isPermaLink="true" >http://www.telegraph.co.uk/news/2018/01/19/british-15-year-old-gained-access-intelligence-operations-afghanistan</guid>
<description>&lt;div class=&quot;articleBodyText version-2 section&quot;&gt;
&lt;div class=&quot;article-body-text component version-2&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;p&gt;&lt;span class=&quot;m_first-letter m_first-letter--flagged&quot;&gt;A&lt;/span&gt; 15-year-old gained access to plans for intelligence operations in Afghanistan and Iran by pretending to be the head of the CIA to gain access to his computers, a court has heard. &lt;/p&gt;
&lt;p&gt;From the bedroom of the Leicestershire home he shared with his mother, Kane Gamble used “social engineering” – where a person builds up a picture of information and uses it manipulate others into handing over more – to access the personal and work accounts of some of America's most powerful spy chiefs .&lt;/p&gt;
&lt;p&gt;The teenager persuaded call handlers at an internet giant that he was John Brennan, the then director of the CIA, to gain access to his computers and an FBI helpdesk that he was Mark Giuliano, then the agency’s Deputy Director, to re-gain access to an intelligence database.&lt;/p&gt;
&lt;p&gt;He also targeted the US Secretary of Homeland Security and Barack Obama's Director of National Intelligence from his semi-detached council house in Coalville. &lt;/p&gt;
&lt;p&gt;Gamble taunted his victims online, released personal information, bombarded them with calls and messages, downloaded pornography onto their computers and took control of their iPads and TV screens, a court heard.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&quot;articleBodyText section&quot;&gt;
&lt;div class=&quot;article-body-text component&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;p&gt;&lt;span class=&quot;m_first-letter m_first-letter--flagged&quot;&gt;M&lt;/span&gt;r Justice Haddon-Cave noted: “He got these people in his control and played with them in order to make their lives difficult.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;articleBodyText section&quot;&gt;
&lt;div class=&quot;article-body-text component&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;p&gt;&lt;span class=&quot;m_first-letter m_first-letter--flagged&quot;&gt;J&lt;/span&gt;ohn Lloyd-Jones QC, prosecuting, said that Gamble founded Crackas With Attitude (CWA) in 2015, telling a journalist: “It all started by me getting more and more annoyed about how corrupt and cold blooded the US Government are so I decided to do something about it.”&lt;/p&gt;
&lt;p&gt;Mr Lloyd-Jones said that it was a common misconception that the group were hackers when in fact they used “social engineering” to gain access to emails, phones, computers and law enforcement portals.&lt;/p&gt;
&lt;p&gt;“It involves manipulating people, invariably call centre or help desk staff, into permitting acts or divulging confidential information,” the prosecutor said.&lt;/p&gt;
&lt;p&gt;Gamble, who has pleaded guilty to ten offences under the computer misuse act, first targeted Mr Brennan and gained access to his Verizon internet account by pretending first to be employee of the company and then Mr Brennan himself, building up an increasingly detailed picture.&lt;/p&gt;
&lt;p&gt;At first he was denied access to his computers as he could not name Mr Brennan’s first pet, but on later calls the handler changed the pin and security questions.&lt;/p&gt;
&lt;p&gt;He used similar methods to access Mr Brennan’s AOL account and eventually Gamble was able to access his emails, contacts, his iCloud storage account and his wife’s iPad remotely.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;articleBodyImage section&quot;&gt;
&lt;div class=&quot;article-body-image component&quot; itemscope=&quot;&quot; itemtype=&quot;https://schema.org/ImageObject&quot; data-frz-ancestor=&quot;&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;div class=&quot;lazy-image article-body-image-image&quot; data-js=&quot;LazyImage&quot; data-src=&quot;/content/dam/news/2018/01/19/TELEMMGLPICT000013214521_trans_NvBQzQNjv4BqOteZPuJZ0QHE72RjNfH2-886OMB_5Lsk8hitRXclHWM.jpeg?imwidth=480&quot; data-srcset=&quot;/content/dam/news/2018/01/19/TELEMMGLPICT000013214521_trans_NvBQzQNjv4BqOteZPuJZ0QHE72RjNfH2-886OMB_5Lsk8hitRXclHWM.jpeg?imwidth=480 480w,/content/dam/news/2018/01/19/TELEMMGLPICT000013214521_trans_NvBQzQNjv4BqOteZPuJZ0QHE72RjNfH2-886OMB_5Lsk8hitRXclHWM.jpeg?imwidth=960 960w,/content/dam/news/2018/01/19/TELEMMGLPICT000013214521_trans_NvBQzQNjv4BqOteZPuJZ0QHE72RjNfH2-886OMB_5Lsk8hitRXclHWM.jpeg?imwidth=580 580w,/content/dam/news/2018/01/19/TELEMMGLPICT000013214521_trans_NvBQzQNjv4BqOteZPuJZ0QHE72RjNfH2-886OMB_5Lsk8hitRXclHWM.jpeg?imwidth=1160 1160w,/content/dam/news/2018/01/19/TELEMMGLPICT000013214521_trans_NvBQzQNjv4BqOteZPuJZ0QHE72RjNfH2-886OMB_5Lsk8hitRXclHWM.jpeg?imwidth=620 620w,/content/dam/news/2018/01/19/TELEMMGLPICT000013214521_trans_NvBQzQNjv4BqOteZPuJZ0QHE72RjNfH2-886OMB_5Lsk8hitRXclHWM.jpeg?imwidth=1240 1240w&quot; data-alt=&quot;Former CIA director John Brennan was one of the officials targetted by Gamble&quot; sizes=&quot;100vw,(min-width: 480px) 480px,(min-width: 730px) 580px,(min-width: 1008px) 620px&quot;&gt;&lt;span class=&quot;article-body-image-image-container&quot;&gt;&lt;noscript&gt;
&lt;p&gt;&lt;img class=&quot;responsive article-body-image-image&quot; src=&quot;http://www.telegraph.co.uk/content/dam/news/2018/01/19/TELEMMGLPICT000013214521_trans_NvBQzQNjv4BqOteZPuJZ0QHE72RjNfH2-886OMB_5Lsk8hitRXclHWM.jpeg?imwidth=480&quot; alt=&quot;Former CIA director John Brennan was one of the officials targetted by Gamble&quot;/&gt;&lt;/p&gt;
&lt;/noscript&gt;&lt;/span&gt;&lt;/div&gt;
&lt;span itemprop=&quot;caption&quot; class=&quot;article-body-image-caption&quot;&gt;Former CIA director John Brennan was one of the officials targetted by Gamble&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;articleBodyText section&quot;&gt;
&lt;div class=&quot;article-body-text component&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;p&gt;&lt;span class=&quot;m_first-letter m_first-letter--flagged&quot;&gt;M&lt;/span&gt;r Lloyd-Jones QC said: “He accessed some extremely sensitive accounts referring to, among other things, military operations and intelligence operations in Afghanistan and Iran.”&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;articleBodyText section&quot;&gt;
&lt;div class=&quot;article-body-text component&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;p&gt;&lt;span class=&quot;m_first-letter m_first-letter--flagged&quot;&gt;G&lt;/span&gt;amble, who is now 18, later posted sensitive information on Twitter and Wikileaks and taunted officials about his access, sometimes using the tag #freePalestine and claiming it was because the US Government was “killing innocent people”.&lt;/p&gt;
&lt;p&gt;Gamble used similar techniques to hack the home broadband of Jeh Johnson, the Secretary of Homeland Security, and was able listened to his voicemails and send texts from his phone.&lt;/p&gt;
&lt;p&gt;He bombarded Mr Johnson and his wife with calls, asking her: “Am I scaring you?” and left messages threatening to “bang his daughter”, the court heard.&lt;/p&gt;
&lt;p&gt;Around October 2015, when Gamble turned 16, gained access to Mr Giuliano’s home accounts by pretending to be the FBI boss and using the information gained he accessed the FBI’s Law Enforcement Enterprise Portal (Leap).&lt;/p&gt;
&lt;p&gt;Mr Lloyd-Jones QC described it as “a gateway providing law enforcement agencies, intelligence groups and criminal justice agencies access to beneficial resources”.&lt;/p&gt;
&lt;p&gt;This included criminal intelligence and details of police officers and government employees, and Gamble boasted: “This has to be the biggest hack, I have access to all the details the Feds use for background checks.”&lt;/p&gt;
&lt;p&gt;The FBI had realised that their system was breached and the password was changed, but at one point Gamble managed to change it and regain access by pretending to be Mr Giuliano in a call to the helpdesk.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;articleBodyText section&quot;&gt;
&lt;div class=&quot;article-body-text component&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;p&gt;&lt;span class=&quot;m_first-letter m_first-letter--flagged&quot;&gt;H&lt;/span&gt;e used his access to steal and post online personal details of Officer Darren Wilson who shot and killed black teenager Michael Brown in Ferguson Missouri.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;articleBodyText section&quot;&gt;
&lt;div class=&quot;article-body-text component&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;p&gt;&lt;span class=&quot;m_first-letter m_first-letter--flagged&quot;&gt;A&lt;/span&gt;t the same time he harassed the Giuliano family and people associated with them and bombarded them with calls, meaning that they were forced to seek protection from the intelligence agencies and an armed guard was placed at their home.  &lt;/p&gt;
&lt;p&gt;Mr Obama's  senior science and technology adviser John Holdren had his personal accounts hacked and Gamble passed all of his personal details to an accomplice who used them to make hoax calls to the local police claiming that there was a violent incident at Mr Holdren’s house resulting in an armed swat team being deployed.&lt;/p&gt;
&lt;p&gt;His eight month reign of chaos was brought to an end in February 2016 after he gained access to the US Department of Justice’s network over a number of days, accessing details of 20,000 FBI employees and case files including that on the Deepwater Horizon Oil Spill. &lt;/p&gt;
&lt;p&gt;The FBI and the US secret service had such concern over the material that he had seen that they immediately called police in the UK and he was arrested at his home.&lt;/p&gt;
&lt;p&gt;The Old Bailey also heard that he accessed the private calls and emails of Avril Haines, the White House deputy national security adviser and FBI Special Agent Amy Hess.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;articleBodyText section&quot;&gt;
&lt;div class=&quot;article-body-text component&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;p&gt;&lt;span class=&quot;m_first-letter m_first-letter--flagged&quot;&gt;I&lt;/span&gt;n the case of Ms Hess he downloaded films on to her computer, including one called Hackers and V for Vendetta as well as a pornographic title. He changed an equipment list no her computer to a list of derogatory terms.  &lt;/p&gt;
&lt;p&gt;James Clapper, Director of National Intelligence under President Obama, was also targeted and all of his home phone calls were diverted to the Free Palestine Movement.&lt;/p&gt;
&lt;p&gt;Vonna Weir Heaton, the former intelligence executive of the US National Geospatial Intelligence Agency. Had her social media accounts access by Gamble who sent messages pretending to be her.&lt;/p&gt;
&lt;p&gt;At one point on an internet chat he said that he had considered not sharing any more information “because it put lives at risk, but then I thought they are killing innocent people every day”, the court heard.&lt;/p&gt;
&lt;p&gt;Medical experts for the defence argue that he is on the autism spectrum and at the time of his offending had the mental development of a 12 or 13-year-old.&lt;/p&gt;
&lt;p&gt;He has no friends to speak off and is closest to his mother Ann, a cleaner who reportedly won a £1.6million lottery jackpot in 1997  but  “lost all the money on doomed property deals”.  &lt;/p&gt;
&lt;p&gt;William Harbage QC said that after his arrest he told doctors “it was kind of easy” and that he had little consequences of his actions “in his bedroom on the internet thousands of miles away”. &lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;articleBodyText section&quot;&gt;
&lt;div class=&quot;article-body-text component&quot;&gt;
&lt;div class=&quot;component-content&quot;&gt;
&lt;p&gt;&lt;span class=&quot;m_first-letter m_first-letter--flagged&quot;&gt;M&lt;/span&gt;r Justice Haddon-Cave will sentence him on a date to be fixed. &lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Sat, 20 Jan 2018 11:34:51 +0000</pubDate>
<dc:creator>rbanffy</dc:creator>
<og:title>British 15-year-old gained access to intelligence operations in Afghanistan and Iran by pretending to be head of CIA, court hears</og:title>
<og:description>A 15-year-old gained access to plans for intelligence operations in Afghanistan and Iran by pretending to be the head of the CIA to gain access to his computers, a court has heard.</og:description>
<og:type>article</og:type>
<og:url>http://www.telegraph.co.uk/news/2018/01/19/british-15-year-old-gained-access-intelligence-operations-afghanistan/</og:url>
<og:image>http://www.telegraph.co.uk/content/dam/news/2018/01/19/TELEMMGLPICT000151752386-xlarge_trans_NvBQzQNjv4BqiJ6nA5oGE9mElZ-k_B3GwX9NBJbfJ4XWKGgc5tcZdVg.jpeg</og:image>
<dc:language>en-GB</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.telegraph.co.uk/news/2018/01/19/british-15-year-old-gained-access-intelligence-operations-afghanistan/</dc:identifier>
</item>
<item>
<title>JS things I didn’t know existed</title>
<link>https://air.ghost.io/js-things-i-never-knew-existed/</link>
<guid isPermaLink="true" >https://air.ghost.io/js-things-i-never-knew-existed/</guid>
<description>&lt;p&gt;I was reading through the MDN docs the other day and found these JS features and APIs I never knew existed. So here is a short list of those things, useful or not - learning JS seemingly never ends.&lt;/p&gt;

&lt;p&gt;You can name &lt;code&gt;for&lt;/code&gt; loops and blocks in JS... who knew (not me)! You can then refer to that name and use &lt;code&gt;break&lt;/code&gt; or &lt;code&gt;continue&lt;/code&gt; in &lt;code&gt;for&lt;/code&gt; loops and &lt;code&gt;break&lt;/code&gt; in blocks.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-javascript&quot;&gt;loop1: // labeling &quot;loop1&quot; 
for (let i = 0; i &amp;lt; 3; i++) { // &quot;loop1&quot;
   loop2: // labeling &quot;loop2&quot;
   for (let j = 0; j &amp;lt; 3; j++) { // &quot;loop2&quot;
      if (i === 1) {
         continue loop1; // continues upper &quot;loop1&quot;
         // break loop1; // breaks out of upper &quot;loop1&quot;
      }
      console.log(`i = ${i}, j = ${j}`);
   }
}

/* 
 * # Output
 * i = 0, j = 0
 * i = 0, j = 1
 * i = 0, j = 2
 * i = 2, j = 0
 * i = 2, j = 1
 * i = 2, j = 2
 */
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Here is an example of block naming, you can only use &lt;code&gt;break&lt;/code&gt; in blocks.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-javascript&quot;&gt;foo: {
  console.log('one');
  break foo;
  console.log('this log will not be executed');
}
console.log('two');

/*
 * # Output
 * one
 * two
 */
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;I thought I knew all the operators until I saw this one which has been in &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/New_in_JavaScript/1.1&quot;&gt;JS since 1996&lt;/a&gt;. It's supported by all browers and its pretty easy to understand, quote from MDN:&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;The void operator evaluates the given expression and then returns undefined.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This allow you to write an alternative IIFE like this:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-javascript&quot;&gt;void function iife() {
        console.log('hello');
}();

// is the same as...

(function iife() {
    console.log('hello');
})()
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;One cavaet with &lt;code&gt;void&lt;/code&gt; is the evaluation of the expression is... void (undefined)!&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-javascript&quot;&gt;const word = void function iife() {
        return 'hello';
}();

// word is &quot;undefined&quot;

const word = (function iife() {
        return 'hello';
})();

// word is &quot;hello&quot;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;You can also use &lt;code&gt;void&lt;/code&gt; with &lt;code&gt;async&lt;/code&gt;, you could then use it as an asynchronous entry point to your code:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-javascript&quot;&gt;void async function() { 
    try {
        const response = await fetch('air.ghost.io'); 
        const text = await response.text();
        console.log(text);
    } catch(e) {
        console.error(e);
    }
}()

// or just stick to this :)

(async () =&amp;gt; {
    try {
        const response = await fetch('air.ghost.io'); 
        const text = await response.text();
        console.log(text);
    } catch(e) {
        console.error(e);
    }
})();
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;After reading about the comma operator, I realised I was not fully aware of how it works. Here is a good quote from MDN:&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;The comma operator evaluates each of its operands (from left to right) and returns the value of the last operand.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;
&lt;code class=&quot;language-javascript&quot;&gt;function myFunc() {
  let x = 0;
  return (x += 1, x); // same as return ++x;
}

y = false, true; // returns true in console
console.log(y); // false (left-most)

z = (false, true); // returns true in console
console.log(z); // true (right-most)
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;withconditionaloperator&quot;&gt;With &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Conditional_Operator&quot;&gt;Conditional Operator&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The last value in the comma operator becomes the return value for the conditional. So you can put any number of expressions before it, in the example below I put a console log before the returned boolean value.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-javascript&quot;&gt;const type = 'man';

const isMale = type === 'man' ? (
    console.log('Hi Man!'),
    true
) : (
    console.log('Hi Lady!'),
    false
);

console.log(`isMale is &quot;${isMale}&quot;`);
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Internationalization is difficult to get right at the best of times, luckily there is a &lt;a href=&quot;https://caniuse.com/#feat=internationalization&quot;&gt;well supported&lt;/a&gt; API for it now in most browsers. One of my favourite features from it is the date formatter, see example below.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-javascript&quot;&gt;const date = new Date();

const options = {
  year: 'numeric', 
  month: 'long', 
  day: 'numeric'
};

const formatter1 = new Intl.DateTimeFormat('es-es', options);
console.log(formatter1.format(date)); // 22 de diciembre de 2017

const formatter2 = new Intl.DateTimeFormat('en-us', options);
console.log(formatter2.format(date)); // December 22, 2017
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;At time of writing this is only supported in Firefox 58+ behind a flag, however Babel does already have a proposal plugin for it &lt;a href=&quot;https://github.com/babel/babel/tree/master/packages/babel-plugin-proposal-pipeline-operator&quot;&gt;here&lt;/a&gt;. It looks very bash inspired and I like it!&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-javascript&quot;&gt;const square = (n) =&amp;gt; n * n;
const increment = (n) =&amp;gt; n + 1;

// without pipeline operator
square(increment(square(2))); // 25

// with pipeline operator
2 |&amp;gt; square |&amp;gt; increment |&amp;gt; square; // 25
&lt;/code&gt;
&lt;/pre&gt;


&lt;p&gt;Atomic operations give predictable read and write values when data is shared between the multiple threads, waiting for other operations to finish before the next one is executed. Useful for keeping data in sync between things like the main thread and another WebWorker.&lt;/p&gt;
&lt;p&gt;I really like Atomics in other languages like Java. I feel these will be used more in JS when more of us use WebWorkers to move operations away from the main thread.&lt;/p&gt;

&lt;p&gt;Ok, I've never seen this used because its basically &lt;code&gt;Array.prototype.reduce()&lt;/code&gt; + &lt;code&gt;Array.prototype.reverse()&lt;/code&gt; and its quite rare you need to do that. If you do... then &lt;code&gt;reduceRight&lt;/code&gt; is perfect!&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-javascript&quot;&gt;const flattened = [[0, 1], [2, 3], [4, 5]].reduceRight(function(a, b) {
    return a.concat(b);
}, []);

// flattened array is [4, 5, 2, 3, 0, 1]
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;I could of probably saved myself a &lt;code&gt;.bind(...)&lt;/code&gt; or two by knowing this - and it's been around forever.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-javascript&quot;&gt;setTimeout(alert, 1000, 'Hello world!');

/*
 * # Output (alert)
 * Hello World!
 */

function log(text, textTwo) {
    console.log(text, textTwo);
}

setTimeout(log, 1000, 'Hello World!', 'And Mars!');

/*
 * # Output
 * Hello World! And Mars!
 */
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;I had used custom data attributes &lt;code&gt;data-*&lt;/code&gt; on HTML elements before now but I blissfully was unaware there was an API to query them easily. Apart from a few naming restrictions (see link above) it's essentially dash-case naming for attributes and camelCase when querying them in JS. So attribute &lt;code&gt;data-birth-planet&lt;/code&gt; would become &lt;code&gt;birthPlanet&lt;/code&gt; in JS.&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-html&quot;&gt;&amp;lt;div id='person' data-name='john' data-birth-planet='earth'&amp;gt;&amp;lt;/div&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Query:&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;language-javascript&quot;&gt;let personEl = document.querySelector('#person');

console.log(personEl.dataset) // DOMStringMap {name: &quot;john&quot;, birthPlanet: &quot;earth&quot;}
console.log(personEl.dataset.name) // john
console.log(personEl.dataset.birthPlanet) // earth

// you can programmatically add more too
personEl.dataset.foo = 'bar';
console.log(personEl.dataset.foo); // bar
&lt;/code&gt;
&lt;/pre&gt;

&lt;p&gt;Hope you discovered something new in the list for JS like I did. Shout out to Mozilla for the new MDN site, looks much nicer in my opinion - I spent way longer than I thought reading through it.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Edit: Fixed some naming and added &lt;code&gt;try&lt;/code&gt;, &lt;code&gt;catch&lt;/code&gt; to &lt;code&gt;async&lt;/code&gt; functions. Thanks Reddit!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Happy New 2018!&lt;/p&gt;
</description>
<pubDate>Sat, 20 Jan 2018 10:40:01 +0000</pubDate>
<dc:creator>fagnerbrack</dc:creator>
<og:type>article</og:type>
<og:title>JS things I never knew existed</og:title>
<og:description>I was reading through the MDN docs the other day and found these JS features and APIs I never knew existed. So here is a short list of those things, useful or not - learning JS seemingly never ends. Label Statements You can name for loops and blocks in JS.</og:description>
<og:url>http://air.ghost.io/js-things-i-never-knew-existed/</og:url>
<og:image>http://air.ghost.io/content/images/2017/12/holidays-2017.png</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://air.ghost.io/js-things-i-never-knew-existed/</dc:identifier>
</item>
<item>
<title>Learn FFmpeg the hard way</title>
<link>https://github.com/leandromoreira/ffmpeg-libav-tutorial#learn-ffmpeg-libav-the-hard-way</link>
<guid isPermaLink="true" >https://github.com/leandromoreira/ffmpeg-libav-tutorial#learn-ffmpeg-libav-the-hard-way</guid>
<description>&lt;h3&gt;README.md&lt;/h3&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://img.shields.io/badge/license-BSD--3--Clause-blue.svg&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/274d07206c413193cf01e32de7f897d98da66ca2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4253442d2d332d2d436c617573652d626c75652e737667&quot; alt=&quot;license&quot; data-canonical-src=&quot;https://img.shields.io/badge/license-BSD--3--Clause-blue.svg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I was looking for a tutorial/book that would teach me how to start to use &lt;a href=&quot;https://www.ffmpeg.org/&quot; rel=&quot;nofollow&quot;&gt;FFmpeg&lt;/a&gt; as a library (a.k.a. libav) and then I found the &lt;a href=&quot;http://dranger.com/ffmpeg/&quot; rel=&quot;nofollow&quot;&gt;&quot;How to write a video player in less than 1k lines&quot;&lt;/a&gt; tutorial. Unfortunately it was deprecated, so I decided to write this one.&lt;/p&gt;
&lt;p&gt;Most of the code in here will be in c &lt;strong&gt;but don't worry&lt;/strong&gt;: you can easily understand and apply it to your preferred language. FFmpeg libav has lots of bindings for many languages like &lt;a href=&quot;https://mikeboers.github.io/PyAV/&quot; rel=&quot;nofollow&quot;&gt;python&lt;/a&gt;, &lt;a href=&quot;https://github.com/imkira/go-libav&quot;&gt;go&lt;/a&gt; and even if your language doesn't have it, you can still support it through the &lt;code&gt;ffi&lt;/code&gt; (here's an example with &lt;a href=&quot;https://github.com/daurnimator/ffmpeg-lua-ffi/blob/master/init.lua&quot;&gt;Lua&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;We'll start with a quick lesson about what is video, audio, codec and container and then we'll go to a crash course on how to use &lt;code&gt;FFmpeg&lt;/code&gt; command line and finally we'll write code, feel free to skip directly to the section &lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial#learn-ffmpeg-libav-the-hard-way&quot;&gt;Learn FFmpeg libav the Hard Way.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Some people used to say that the Internet video streaming is the future of the traditional TV, in any case, the FFmpeg is something that is worth studying.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;video - what you see!&lt;/h2&gt;
&lt;p&gt;If you have a sequence series of images and change them at a given frequency (let's say &lt;a href=&quot;https://www.filmindependent.org/blog/hacking-film-24-frames-per-second/&quot; rel=&quot;nofollow&quot;&gt;24 images per second&lt;/a&gt;), you will create an &lt;a href=&quot;https://en.wikipedia.org/wiki/Persistence_of_vision&quot; rel=&quot;nofollow&quot;&gt;illusion of movement&lt;/a&gt;. In summary this is the very basic idea behind a video: &lt;strong&gt;a series of pictures / frames running at a given rate&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://camo.githubusercontent.com/966d1f292c623eb0714881944f7c089025bbb049/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f312f31662f4c696e6e65745f6b696e656f67726170685f313838362e6a7067&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/966d1f292c623eb0714881944f7c089025bbb049/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f312f31662f4c696e6e65745f6b696e656f67726170685f313838362e6a7067&quot; title=&quot;flip book&quot; height=&quot;280&quot; data-canonical-src=&quot;https://upload.wikimedia.org/wikipedia/commons/1/1f/Linnet_kineograph_1886.jpg&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Zeitgenössische Illustration (1886)&lt;/p&gt;
&lt;h2&gt;audio - what you listen!&lt;/h2&gt;
&lt;p&gt;Although a muted video can express a variety of feelings, adding sound to it brings more pleasure to the experience.&lt;/p&gt;
&lt;p&gt;Sound is the vibration that propagates as a wave of pressure, through the air or any other transmission medium, such as a gas, liquid or solid.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In a digital audio system, a microphone converts sound to an analog electrical signal, then an analog-to-digital converter (ADC)—typically using &lt;a href=&quot;https://en.wikipedia.org/wiki/Pulse-code_modulation&quot; rel=&quot;nofollow&quot;&gt;pulse-code modulation—converts (PCM)&lt;/a&gt; the analog signal into a digital signal.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://camo.githubusercontent.com/0ba780b908e6545646bc84e7ccd149f42c505517/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f7468756d622f632f63372f4350542d536f756e642d4144432d4441432e7376672f36343070782d4350542d536f756e642d4144432d4441432e7376672e706e67&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://camo.githubusercontent.com/0ba780b908e6545646bc84e7ccd149f42c505517/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f7468756d622f632f63372f4350542d536f756e642d4144432d4441432e7376672f36343070782d4350542d536f756e642d4144432d4441432e7376672e706e67&quot; alt=&quot;audio analog to digital&quot; title=&quot;audio analog to digital&quot; data-canonical-src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/CPT-Sound-ADC-DAC.svg/640px-CPT-Sound-ADC-DAC.svg.png&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;https://commons.wikimedia.org/wiki/File:CPT-Sound-ADC-DAC.svg&quot; rel=&quot;nofollow&quot;&gt;Source&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;codec - shrinking data&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;CODEC is an electronic circuit or software that &lt;strong&gt;compresses or decompresses digital audio/video.&lt;/strong&gt; It converts raw (uncompressed) digital audio/video to a compressed format or vice versa. &lt;a href=&quot;https://en.wikipedia.org/wiki/Video_codec&quot; rel=&quot;nofollow&quot;&gt;https://en.wikipedia.org/wiki/Video_codec&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;But if we chose to pack millions of images in a single file and called it a movie, we might end up with a huge file. Let's do the math:&lt;/p&gt;
&lt;p&gt;Suppose we are creating a video with a resolution of &lt;code&gt;1080 x 1920&lt;/code&gt; (height x width) and that we'll spend &lt;code&gt;3 bytes&lt;/code&gt; per pixel (the minimal point at a screen) to encode the color (or &lt;a href=&quot;https://en.wikipedia.org/wiki/Color_depth#True_color_.2824-bit.29&quot; rel=&quot;nofollow&quot;&gt;24 bit color&lt;/a&gt;, what gives us 16,777,216 different colors) and this video runs at &lt;code&gt;24 frames per second&lt;/code&gt; and it is &lt;code&gt;30 minutes&lt;/code&gt; long.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
toppf = &lt;span class=&quot;pl-c1&quot;&gt;1080&lt;/span&gt; * &lt;span class=&quot;pl-c1&quot;&gt;1920&lt;/span&gt; &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt;total_of_pixels_per_frame&lt;/span&gt;
cpp = &lt;span class=&quot;pl-c1&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt;cost_per_pixel&lt;/span&gt;
tis = &lt;span class=&quot;pl-c1&quot;&gt;30&lt;/span&gt; * &lt;span class=&quot;pl-c1&quot;&gt;60&lt;/span&gt; &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt;time_in_seconds&lt;/span&gt;
fps = &lt;span class=&quot;pl-c1&quot;&gt;24&lt;/span&gt; &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt;frames_per_second&lt;/span&gt;

required_storage = tis * fps * toppf * cpp
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This video would require approximately &lt;code&gt;250.28GB&lt;/code&gt; of storage or &lt;code&gt;1.11Gbps&lt;/code&gt; of bandwidth! That's why we need to use a &lt;a href=&quot;https://github.com/leandromoreira/digital_video_introduction#how-does-a-video-codec-work&quot;&gt;CODEC&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;container - a comfy place for audio and video&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;A container or wrapper format is a metafile format whose specification describes how different elements of data and metadata coexist in a computer file. &lt;a href=&quot;https://en.wikipedia.org/wiki/Digital_container_format&quot; rel=&quot;nofollow&quot;&gt;https://en.wikipedia.org/wiki/Digital_container_format&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A &lt;strong&gt;single file that contains all the streams&lt;/strong&gt; (mostly the audio and video) and it also provides &lt;strong&gt;synchronization and general metadata&lt;/strong&gt;, such as title, resolution and etc.&lt;/p&gt;
&lt;p&gt;Usually we can infer the format of a file by looking at its extension: for instance a &lt;code&gt;video.webm&lt;/code&gt; is probably a video using the container &lt;a href=&quot;https://www.webmproject.org/&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;webm&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/img/container.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/raw/master/img/container.png&quot; alt=&quot;container&quot;/&gt;&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A complete, cross-platform solution to record, convert and stream audio and video.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To work with multimedia we can use the AMAZING tool/library called &lt;a href=&quot;https://www.ffmpeg.org/&quot; rel=&quot;nofollow&quot;&gt;FFmpeg&lt;/a&gt;. Chances are you already know/use it directly or indirectly (do you use &lt;a href=&quot;https://www.chromium.org/developers/design-documents/video&quot; rel=&quot;nofollow&quot;&gt;Chrome?&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;It has a command line program called &lt;code&gt;ffmpeg&lt;/code&gt;, a very simple yet powerful binary. For instance, you can convert from &lt;code&gt;mp4&lt;/code&gt; to the container &lt;code&gt;avi&lt;/code&gt; just by typing the follow command:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
$ ffmpeg -i input.mp4 output.avi
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We just made a &lt;strong&gt;remuxing&lt;/strong&gt; here, which is converting from one container to another one. Technically FFmpeg could also be doing a transcoding but we'll talk about that later.&lt;/p&gt;
&lt;h2&gt;FFmpeg command line tool 101&lt;/h2&gt;
&lt;p&gt;FFmpeg does have a &lt;a href=&quot;https://www.ffmpeg.org/ffmpeg.html&quot; rel=&quot;nofollow&quot;&gt;documentation&lt;/a&gt; that does a great job of explaining how it works.&lt;/p&gt;
&lt;p&gt;To make things short, the FFmpeg command line program expects the following argument format to perform its actions &lt;code&gt;ffmpeg {1} {2} -i {3} {4} {5}&lt;/code&gt;, where:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;global options&lt;/li&gt;
&lt;li&gt;input file options&lt;/li&gt;
&lt;li&gt;input url&lt;/li&gt;
&lt;li&gt;output file options&lt;/li&gt;
&lt;li&gt;output url&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;The parts 2, 3, 4 and 5 can be as many as you need. It's easier to understand this argument format in action:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
$ wget -O bunny_1080p_60fps.mp4 http://distribution.bbb3d.renderfarming.net/video/mp4/bbb_sunflower_1080p_60fps_normal.mp4

$ ffmpeg \
-y &lt;span class=&quot;pl-cce&quot;&gt;\ &lt;/span&gt;&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; global options&lt;/span&gt;
-c:a libfdk_aac -c:v libx264 &lt;span class=&quot;pl-cce&quot;&gt;\ &lt;/span&gt;&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; input options&lt;/span&gt;
-i bunny_1080p_60fps.mp4 &lt;span class=&quot;pl-cce&quot;&gt;\ &lt;/span&gt;&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; input url&lt;/span&gt;
-c:v libvpx-vp9 -c:a libvorbis &lt;span class=&quot;pl-cce&quot;&gt;\ &lt;/span&gt;&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; output options&lt;/span&gt;
bunny_1080p_60fps_vp9.webm &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; output url&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This command takes an input file &lt;code&gt;mp4&lt;/code&gt; containing two streams (an audio encoded with &lt;code&gt;aac&lt;/code&gt; CODEC and a video encoded using &lt;code&gt;h264&lt;/code&gt; CODEC) and convert it to &lt;code&gt;webm&lt;/code&gt;, changing its audio and video CODECs too.&lt;/p&gt;
&lt;p&gt;We could simplify the command above but then be aware that FFmpeg will adopt or guess the default values for you. For instance when you just type &lt;code&gt;ffmpeg -i input.avi output.mp4&lt;/code&gt; what audio/video CODEC does it use to produce the &lt;code&gt;output.mp4&lt;/code&gt;?&lt;/p&gt;
&lt;p&gt;Werner Robitza wrote a must read/execute &lt;a href=&quot;http://slhck.info/ffmpeg-encoding-course/#/&quot; rel=&quot;nofollow&quot;&gt;tutorial about encoding and editing with FFmpeg&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;While working with audio/video we usually do a set of tasks with the media.&lt;/p&gt;
&lt;h2&gt;Transcoding&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/img/transcoding.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/raw/master/img/transcoding.png&quot; alt=&quot;transcoding&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What?&lt;/strong&gt; the act of converting one of the streams (audio or video) from one CODEC to another one.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt; sometimes some devices (TVs, smartphones, console and etc) doesn't support X but Y and newer CODECs provide better compression rate.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How?&lt;/strong&gt; converting an &lt;code&gt;H264&lt;/code&gt; (AVC) video to an &lt;code&gt;H265&lt;/code&gt; (HEVC).&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
$ ffmpeg \
-i bunny_1080p_60fps.mp4 \
-c:v libx265 \
bunny_1080p_60fps_h265.mp4
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Transmuxing&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/img/transmuxing.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/raw/master/img/transmuxing.png&quot; alt=&quot;transmuxing&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What?&lt;/strong&gt; the act of converting from one format (container) to another one.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt; sometimes some devices (TVs, smartphones, console and etc) doesn't support X but Y and sometimes newer containers provide modern required features.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How?&lt;/strong&gt; converting a &lt;code&gt;mp4&lt;/code&gt; to a &lt;code&gt;webm&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
$ ffmpeg \
-i bunny_1080p_60fps.mp4 \
-c copy &lt;span class=&quot;pl-cce&quot;&gt;\ &lt;/span&gt;&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; just saying to ffmpeg to skip encoding&lt;/span&gt;
bunny_1080p_60fps.webm
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Transrating&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/img/transrating.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/raw/master/img/transrating.png&quot; alt=&quot;transrating&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What?&lt;/strong&gt; the act of changing the bit rate, or producing other renditions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt; people will try to watch your video in a &lt;code&gt;2G&lt;/code&gt; (edge) connection using a less powerful smartphone or in a &lt;code&gt;fiber&lt;/code&gt; Internet connection on their 4K TVs therefore you should offer more than on rendition of the same video with different bit rate.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How?&lt;/strong&gt; producing a rendition with bit rate between 3856K and 2000K.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
$ ffmpeg \
-i bunny_1080p_60fps.mp4 \
-minrate 964K -maxrate 3856K -bufsize 2000K \
bunny_1080p_60fps_transrating_964_3856.mp4
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Usually we'll be using transrating with transsizing. Werner Robitza wrote another must read/execute &lt;a href=&quot;http://slhck.info/posts/&quot; rel=&quot;nofollow&quot;&gt;series of posts about FFmpeg rate control&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Transsizing&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/img/transsizing.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/raw/master/img/transsizing.png&quot; alt=&quot;transsizing&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What?&lt;/strong&gt; the act of converting from one resolution to another one. As said before transsizing is often used with transrating.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt; reasons are about the same as for the transrating.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How?&lt;/strong&gt; converting a &lt;code&gt;1080p&lt;/code&gt; to a &lt;code&gt;480p&lt;/code&gt; resolution.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
$ ffmpeg \
-i bunny_1080p_60fps.mp4 \
-vf scale=480:-1 \
bunny_1080p_60fps_transsizing_480.mp4
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;Bonus Round: Adaptive Streaming&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/img/adaptive-streaming.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/raw/master/img/adaptive-streaming.png&quot; alt=&quot;adaptive streaming&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What?&lt;/strong&gt; the act of producing many resolutions (bit rates) and split the media into chunks and serve them via http.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why?&lt;/strong&gt; to provide a flexible media that can be watched on a low end smartphone or on a 4K TV, it's also easy to scale and deploy but it can add latency.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How?&lt;/strong&gt; creating an adaptive WebM using DASH.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-shell&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; video streams&lt;/span&gt;
$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 160x90 -b:v 250k -keyint_min 150 -g 150 -an -f webm -dash 1 video_160x90_250k.webm

$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 320x180 -b:v 500k -keyint_min 150 -g 150 -an -f webm -dash 1 video_320x180_500k.webm

$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 640x360 -b:v 750k -keyint_min 150 -g 150 -an -f webm -dash 1 video_640x360_750k.webm

$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 640x360 -b:v 1000k -keyint_min 150 -g 150 -an -f webm -dash 1 video_640x360_1000k.webm

$ ffmpeg -i bunny_1080p_60fps.mp4 -c:v libvpx-vp9 -s 1280x720 -b:v 1500k -keyint_min 150 -g 150 -an -f webm -dash 1 video_1280x720_1500k.webm

&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; audio streams&lt;/span&gt;
$ ffmpeg -i bunny_1080p_60fps.mp4 -c:a libvorbis -b:a 128k -vn -f webm -dash 1 audio_128k.webm

&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;#&lt;/span&gt; the DASH manifest&lt;/span&gt;
$ ffmpeg \
 -f webm_dash_manifest -i video_160x90_250k.webm \
 -f webm_dash_manifest -i video_320x180_500k.webm \
 -f webm_dash_manifest -i video_640x360_750k.webm \
 -f webm_dash_manifest -i video_640x360_1000k.webm \
 -f webm_dash_manifest -i video_1280x720_500k.webm \
 -f webm_dash_manifest -i audio_128k.webm \
 -c copy -map 0 -map 1 -map 2 -map 3 -map 4 -map 5 \
 -f webm_dash_manifest \
 -adaptation_sets &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;id=0,streams=0,1,2,3,4 id=1,streams=5&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt; \
 manifest.mpd
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;PS: I stole this example from the &lt;a href=&quot;http://wiki.webmproject.org/adaptive-streaming/instructions-to-playback-adaptive-webm-using-dash&quot; rel=&quot;nofollow&quot;&gt;Instructions to playback Adaptive WebM using DASH&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Going beyond&lt;/h2&gt;
&lt;p&gt;There are &lt;a href=&quot;https://github.com/leandromoreira/digital_video_introduction/blob/master/encoding_pratical_examples.md#split-and-merge-smoothly&quot;&gt;many and many other usages for FFmpeg&lt;/a&gt;. I use it in conjunction with &lt;em&gt;iMovie&lt;/em&gt; to produce/edit some videos for YouTube and you can certainly use it professionally.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Don't you wonder sometimes 'bout sound and vision? &lt;strong&gt;David Robert Jones&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Since the &lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial#ffmpeg---command-line&quot;&gt;FFmpeg&lt;/a&gt; is so useful as a command line tool to do essential tasks over the media files, how can we use it in our programs?&lt;/p&gt;
&lt;p&gt;FFmpeg is &lt;a href=&quot;https://www.ffmpeg.org/doxygen/trunk/index.html&quot; rel=&quot;nofollow&quot;&gt;composed by several libraries&lt;/a&gt; that can be integrated into our own programs. Usually, when you install FFmpeg, it installs automatically all these libraries. I'll be referring to the set of these libraries as &lt;strong&gt;FFmpeg libav&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This title is a homage to Zed Shaw's series &lt;a href=&quot;https://learncodethehardway.org/&quot; rel=&quot;nofollow&quot;&gt;Learn X the Hard Way&lt;/a&gt;, particularly his book Learn C the Hard Way.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Chapter 0 - The infamous hello world&lt;/h2&gt;
&lt;p&gt;This hello world actually won't show the message &lt;code&gt;&quot;hello world&quot;&lt;/code&gt; in the terminal 👅 Instead we're going to &lt;strong&gt;print out information about the video&lt;/strong&gt;, things like its format (container), duration, resolution, audio channels and, in the end, we'll &lt;strong&gt;decode some frames and save them as image files&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;FFmpeg libav architecture&lt;/h3&gt;
&lt;p&gt;But before we start to code, let's learn how &lt;strong&gt;FFmpeg libav architecture&lt;/strong&gt; works and how its components communicate with others.&lt;/p&gt;
&lt;p&gt;Here's a diagram of the process of decoding a video:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/img/decoding.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/raw/master/img/decoding.png&quot; alt=&quot;ffmpeg libav architecture - decoding process&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You'll first need to load your media file into a component called &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/structAVFormatContext.html&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;AVFormatContext&lt;/code&gt;&lt;/a&gt; (the video container is also known as format). It actually doesn't fully load the whole file: it often only reads the header.&lt;/p&gt;
&lt;p&gt;Once we loaded the minimal &lt;strong&gt;header of our container&lt;/strong&gt;, we can access its streams (think of them as a rudimentary audio and video data). Each stream will be available in a component called &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/structAVStream.html&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;AVStream&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Stream is a fancy name for a continuous flow of data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Suppose our video has two streams: an audio encoded with &lt;a href=&quot;https://en.wikipedia.org/wiki/Advanced_Audio_Coding&quot; rel=&quot;nofollow&quot;&gt;AAC CODEC&lt;/a&gt; and a video encoded with &lt;a href=&quot;https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC&quot; rel=&quot;nofollow&quot;&gt;H264 (AVC) CODEC&lt;/a&gt;. From each stream we can extract &lt;strong&gt;pieces (slices) of data&lt;/strong&gt; called packets that will be loaded into components named &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/structAVPacket.html&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;AVPacket&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;data inside the packets are still coded&lt;/strong&gt; (compressed) and in order to decode the packets, we need to pass them to a specific &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/structAVCodec.html&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;AVCodec&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;AVCodec&lt;/code&gt; will decode them into &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/structAVFrame.html&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;AVFrame&lt;/code&gt;&lt;/a&gt; and finally, this component gives us &lt;strong&gt;the uncompressed frame&lt;/strong&gt;. Noticed that the same terminology/process is used either by audio and video stream.&lt;/p&gt;
&lt;h3&gt;Chapter 0 - code walkthrough&lt;/h3&gt;
&lt;blockquote&gt;
&lt;h4&gt;TLDR; show me the &lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/0_hello_world.c&quot;&gt;code&lt;/a&gt; and execution.&lt;/h4&gt;

&lt;/blockquote&gt;
&lt;p&gt;We'll skip some details, but don't worry: the &lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/0_hello_world.c&quot;&gt;source code is available at github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The first thing we need to do is to register all the codecs, formats and protocols. To do it, we just need to call the function &lt;a href=&quot;http://ffmpeg.org/doxygen/trunk/group__lavf__core.html#ga917265caec45ef5a0646356ed1a507e3&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;av_register_all&lt;/code&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-en&quot;&gt;av_register_all&lt;/span&gt;();
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we're going to allocate memory to the component &lt;a href=&quot;http://ffmpeg.org/doxygen/trunk/structAVFormatContext.html&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;AVFormatContext&lt;/code&gt;&lt;/a&gt; that will hold information about the format (container).&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
AVFormatContext *pFormatContext = avformat_alloc_context();
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we're going to open the file and read its header and fill the &lt;code&gt;AVFormatContext&lt;/code&gt; with minimal information about the format (notice that usually the codecs are not opened). The function used to do this is &lt;a href=&quot;http://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga31d601155e9035d5b0e7efedc894ee49&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;avformat_open_input&lt;/code&gt;&lt;/a&gt;. It expects an &lt;code&gt;AVFormatContext&lt;/code&gt;, a &lt;code&gt;filename&lt;/code&gt; and two optional arguments: the &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/structAVInputFormat.html&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;AVInputFormat&lt;/code&gt;&lt;/a&gt; (if you pass &lt;code&gt;NULL&lt;/code&gt;, FFmpeg will guess the format) and the &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/structAVDictionary.html&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;AVDictionary&lt;/code&gt;&lt;/a&gt; (which are the options to the demuxer).&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-en&quot;&gt;avformat_open_input&lt;/span&gt;(&amp;amp;pFormatContext, filename, &lt;span class=&quot;pl-c1&quot;&gt;NULL&lt;/span&gt;, &lt;span class=&quot;pl-c1&quot;&gt;NULL&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can print the format name and the media duration:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-en&quot;&gt;printf&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;Format &lt;span class=&quot;pl-c1&quot;&gt;%s&lt;/span&gt;, duration &lt;span class=&quot;pl-c1&quot;&gt;%lld&lt;/span&gt; us&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;, pFormatContext-&amp;gt;iformat-&amp;gt;long_name, pFormatContext-&amp;gt;duration);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To access the &lt;code&gt;streams&lt;/code&gt;, we need to read data from the media. The function &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#gad42172e27cddafb81096939783b157bb&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;avformat_find_stream_info&lt;/code&gt;&lt;/a&gt; does that. Now, the &lt;code&gt;pFormatContext-&amp;gt;nb_streams&lt;/code&gt; will hold the amount of streams and the &lt;code&gt;pFormatContext-&amp;gt;streams[i]&lt;/code&gt; will give us the &lt;code&gt;i&lt;/code&gt; stream (an &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/structAVStream.html&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;AVStream&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-en&quot;&gt;avformat_find_stream_info&lt;/span&gt;(pFormatContext,  &lt;span class=&quot;pl-c1&quot;&gt;NULL&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we'll loop through all the streams.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-k&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;pl-k&quot;&gt;int&lt;/span&gt; i = &lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;; i &amp;lt; pFormatContext-&amp;gt;nb_streams; i++)
{
  &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt;&lt;/span&gt;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For each stream, we're going to keep the &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/structAVCodecParameters.html&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;AVCodecParameters&lt;/code&gt;&lt;/a&gt;, which describes the properties of a codec used by the stream &lt;code&gt;i&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
AVCodecParameters *pLocalCodecParameters = pFormatContext-&amp;gt;streams[i]-&amp;gt;codecpar;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With the codec properties we can look up the proper CODEC querying the function &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga19a0ca553277f019dd5b0fec6e1f9dca&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;avcodec_find_decoder&lt;/code&gt;&lt;/a&gt; and find the registered decoder for the codec id and return an &lt;a href=&quot;http://ffmpeg.org/doxygen/trunk/structAVCodec.html&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;AVCodec&lt;/code&gt;&lt;/a&gt;, the component that knows how to en&lt;strong&gt;CO&lt;/strong&gt;de and &lt;strong&gt;DEC&lt;/strong&gt;ode the stream.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
AVCodec *pLocalCodec = avcodec_find_decoder(pLocalCodecParameters-&amp;gt;codec_id);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we can print information about the codecs.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; specific for video and audio&lt;/span&gt;
&lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; (pLocalCodecParameters-&amp;gt;codec_type == AVMEDIA_TYPE_VIDEO) {
  &lt;span class=&quot;pl-c1&quot;&gt;printf&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;Video Codec: resolution &lt;span class=&quot;pl-c1&quot;&gt;%d&lt;/span&gt; x &lt;span class=&quot;pl-c1&quot;&gt;%d&lt;/span&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;, pLocalCodecParameters-&amp;gt;width, pLocalCodecParameters-&amp;gt;height);
} &lt;span class=&quot;pl-k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;if&lt;/span&gt; (pLocalCodecParameters-&amp;gt;codec_type == AVMEDIA_TYPE_AUDIO) {
  &lt;span class=&quot;pl-c1&quot;&gt;printf&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;Audio Codec: &lt;span class=&quot;pl-c1&quot;&gt;%d&lt;/span&gt; channels, sample rate &lt;span class=&quot;pl-c1&quot;&gt;%d&lt;/span&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;, pLocalCodecParameters-&amp;gt;channels, pLocalCodecParameters-&amp;gt;sample_rate);
}
&lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; general&lt;/span&gt;
&lt;span class=&quot;pl-en&quot;&gt;printf&lt;/span&gt;(&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;pl-cce&quot;&gt;\t&lt;/span&gt;Codec &lt;span class=&quot;pl-c1&quot;&gt;%s&lt;/span&gt; ID &lt;span class=&quot;pl-c1&quot;&gt;%d&lt;/span&gt; bit_rate &lt;span class=&quot;pl-c1&quot;&gt;%lld&lt;/span&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;, pLocalCodec-&amp;gt;long_name, pLocalCodec-&amp;gt;id, pCodecParameters-&amp;gt;bit_rate);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;With the codec, we can allocate memory for the &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/structAVCodecContext.html&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;AVCodecContext&lt;/code&gt;&lt;/a&gt;, which will hold the context for our decode/encode process, but then we need to fill this codec context with CODEC parameters; we do that with &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#gac7b282f51540ca7a99416a3ba6ee0d16&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;avcodec_parameters_to_context&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once we filled the codec context, we need to open the codec. We call the function &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/group__lavc__core.html#ga11f785a188d7d9df71621001465b0f1d&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;avcodec_open2&lt;/code&gt;&lt;/a&gt; and then we can use it.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
AVCodecContext *pCodecContext = avcodec_alloc_context3(pCodec);
&lt;span class=&quot;pl-en&quot;&gt;avcodec_parameters_to_context&lt;/span&gt;(pCodecContext, pCodecParameters);
&lt;span class=&quot;pl-en&quot;&gt;avcodec_open2&lt;/span&gt;(pCodecContext, pCodec, &lt;span class=&quot;pl-c1&quot;&gt;NULL&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now we're going to read the packets from the stream and decode them into frames but first, we need to allocate memory for both components, the &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/structAVPacket.html&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;AVPacket&lt;/code&gt;&lt;/a&gt; and &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/structAVFrame.html&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;AVFrame&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
AVPacket *pPacket = av_packet_alloc();
AVFrame *pFrame = av_frame_alloc();
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Let's feed our packets from the streams with the function &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/group__lavf__decoding.html#ga4fdb3084415a82e3810de6ee60e46a61&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;av_read_frame&lt;/code&gt;&lt;/a&gt; while it has packets.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-k&quot;&gt;while&lt;/span&gt; (av_read_frame(pFormatContext, pPacket) &amp;gt;= &lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;) {
  &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt;...&lt;/span&gt;
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Let's &lt;strong&gt;send the raw data packet&lt;/strong&gt; (compressed frame) to the decoder, through the codec context, using the function &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga58bc4bf1e0ac59e27362597e467efff3&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;avcodec_send_packet&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-en&quot;&gt;avcodec_send_packet&lt;/span&gt;(pCodecContext, pPacket);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And let's &lt;strong&gt;receive the raw data frame&lt;/strong&gt; (uncompressed frame) from the decoder, through the same codec context, using the function &lt;a href=&quot;https://ffmpeg.org/doxygen/trunk/group__lavc__decoding.html#ga11e6542c4e66d3028668788a1a74217c&quot; rel=&quot;nofollow&quot;&gt;&lt;code&gt;avcodec_receive_frame&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-en&quot;&gt;avcodec_receive_frame&lt;/span&gt;(pCodecContext, pFrame);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We can print the frame number, the &lt;a href=&quot;https://en.wikipedia.org/wiki/Presentation_timestamp&quot; rel=&quot;nofollow&quot;&gt;PTS&lt;/a&gt;, DTS, &lt;a href=&quot;https://en.wikipedia.org/wiki/Video_compression_picture_types&quot; rel=&quot;nofollow&quot;&gt;frame type&lt;/a&gt; and etc.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-en&quot;&gt;printf&lt;/span&gt;(
    &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;Frame &lt;span class=&quot;pl-c1&quot;&gt;%c&lt;/span&gt; (&lt;span class=&quot;pl-c1&quot;&gt;%d&lt;/span&gt;) pts &lt;span class=&quot;pl-c1&quot;&gt;%d&lt;/span&gt; dts &lt;span class=&quot;pl-c1&quot;&gt;%d&lt;/span&gt; key_frame &lt;span class=&quot;pl-c1&quot;&gt;%d&lt;/span&gt; [coded_picture_number &lt;span class=&quot;pl-c1&quot;&gt;%d&lt;/span&gt;, display_picture_number &lt;span class=&quot;pl-c1&quot;&gt;%d&lt;/span&gt;]&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;,
    &lt;span class=&quot;pl-en&quot;&gt;av_get_picture_type_char&lt;/span&gt;(pFrame-&amp;gt;pict_type),
    pCodecContext-&amp;gt;frame_number,
    pFrame-&amp;gt;pts,
    pFrame-&amp;gt;pkt_dts,
    pFrame-&amp;gt;key_frame,
    pFrame-&amp;gt;coded_picture_number,
    pFrame-&amp;gt;display_picture_number
);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally we can save our decoded frame into a &lt;a href=&quot;https://en.wikipedia.org/wiki/Netpbm_format#PGM_example&quot; rel=&quot;nofollow&quot;&gt;simple gray image&lt;/a&gt;. The process is very simple, we'll use the &lt;code&gt;pFrame-&amp;gt;data&lt;/code&gt; where the index is related to the &lt;a href=&quot;https://en.wikipedia.org/wiki/YCbCr&quot; rel=&quot;nofollow&quot;&gt;planes Y, Cb and Cr&lt;/a&gt;, we just picked &lt;code&gt;0&lt;/code&gt; (Y) to save our gray image.&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-c&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-en&quot;&gt;save_gray_frame&lt;/span&gt;(pFrame-&amp;gt;data[&lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;], pFrame-&amp;gt;linesize[&lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;], pFrame-&amp;gt;width, pFrame-&amp;gt;height, frame_filename);

&lt;span class=&quot;pl-k&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;pl-en&quot;&gt;save_gray_frame&lt;/span&gt;(&lt;span class=&quot;pl-k&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;pl-k&quot;&gt;char&lt;/span&gt; *buf, &lt;span class=&quot;pl-k&quot;&gt;int&lt;/span&gt; wrap, &lt;span class=&quot;pl-k&quot;&gt;int&lt;/span&gt; xsize, &lt;span class=&quot;pl-k&quot;&gt;int&lt;/span&gt; ysize, &lt;span class=&quot;pl-k&quot;&gt;char&lt;/span&gt; *filename)
{
    &lt;span class=&quot;pl-c1&quot;&gt;FILE&lt;/span&gt; *f;
    &lt;span class=&quot;pl-k&quot;&gt;int&lt;/span&gt; i;
    f = &lt;span class=&quot;pl-c1&quot;&gt;fopen&lt;/span&gt;(filename,&lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;w&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;);
    &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; writing the minimal required header for a pgm file format&lt;/span&gt;
    &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; portable graymap format -&amp;gt; https://en.wikipedia.org/wiki/Netpbm_format#PGM_example&lt;/span&gt;
    &lt;span class=&quot;pl-c1&quot;&gt;fprintf&lt;/span&gt;(f, &lt;span class=&quot;pl-s&quot;&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;P5&lt;span class=&quot;pl-cce&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;pl-c1&quot;&gt;%d&lt;/span&gt; &lt;span class=&quot;pl-c1&quot;&gt;%d&lt;/span&gt;&lt;span class=&quot;pl-cce&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;pl-c1&quot;&gt;%d&lt;/span&gt;&lt;span class=&quot;pl-cce&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;pl-pds&quot;&gt;&quot;&lt;/span&gt;&lt;/span&gt;, xsize, ysize, &lt;span class=&quot;pl-c1&quot;&gt;255&lt;/span&gt;);

    &lt;span class=&quot;pl-c&quot;&gt;&lt;span class=&quot;pl-c&quot;&gt;//&lt;/span&gt; writing line by line&lt;/span&gt;
    &lt;span class=&quot;pl-k&quot;&gt;for&lt;/span&gt; (i = &lt;span class=&quot;pl-c1&quot;&gt;0&lt;/span&gt;; i &amp;lt; ysize; i++)
        &lt;span class=&quot;pl-c1&quot;&gt;fwrite&lt;/span&gt;(buf + i * wrap, &lt;span class=&quot;pl-c1&quot;&gt;1&lt;/span&gt;, xsize, f);
    &lt;span class=&quot;pl-c1&quot;&gt;fclose&lt;/span&gt;(f);
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And voilà! Now we have a gray scale image with 2MB:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/img/generated_frame.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/raw/master/img/generated_frame.png&quot; alt=&quot;saved frame&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Chapter 1 - syncing audio and video&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Be the player&lt;/strong&gt; - a young JS developer writing a new MSE video player.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Before we move to &lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial#chapter-2---transcoding&quot;&gt;code a transcoding example&lt;/a&gt; let's talk about &lt;strong&gt;timing&lt;/strong&gt;, or how a video player knows the right time to play a frame.&lt;/p&gt;
&lt;p&gt;In the last example, we saved some frames that can be seen here:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/img/hello_world_frames/frame0.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/raw/master/img/hello_world_frames/frame0.png&quot; alt=&quot;frame 0&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/img/hello_world_frames/frame1.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/raw/master/img/hello_world_frames/frame1.png&quot; alt=&quot;frame 1&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/img/hello_world_frames/frame2.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/raw/master/img/hello_world_frames/frame2.png&quot; alt=&quot;frame 2&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/img/hello_world_frames/frame3.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/raw/master/img/hello_world_frames/frame3.png&quot; alt=&quot;frame 3&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/img/hello_world_frames/frame4.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/raw/master/img/hello_world_frames/frame4.png&quot; alt=&quot;frame 4&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/blob/master/img/hello_world_frames/frame5.png&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://github.com/leandromoreira/ffmpeg-libav-tutorial/raw/master/img/hello_world_frames/frame5.png&quot; alt=&quot;frame 5&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;When we're designing a video player we need to &lt;strong&gt;play each frame at a given pace&lt;/strong&gt;, otherwise it would be hard to pleasantly see the video either because it's playing so fast or so slow.&lt;/p&gt;
&lt;p&gt;Therefore we need to introduce some logic to play each frame smoothly. For that matter, each frame has a &lt;strong&gt;presentation timestamp&lt;/strong&gt; (PTS) which is an increasing number factored in a &lt;strong&gt;timebase&lt;/strong&gt; that is a rational number (where the denominator is known as &lt;strong&gt;timescale&lt;/strong&gt;) divisible by the &lt;strong&gt;frame rate (fps)&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;It's easier to understand when we look at some examples, let's simulate some scenarios.&lt;/p&gt;
&lt;p&gt;For a &lt;code&gt;fps=60/1&lt;/code&gt; and &lt;code&gt;timebase=1/60000&lt;/code&gt; each PTS will increase &lt;code&gt;timescale / fps = 1000&lt;/code&gt; therefore the &lt;strong&gt;PTS real time&lt;/strong&gt; for each frame could be (supposing it started at 0):&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;frame=0, PTS = 0, PTS_TIME = 0&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;frame=1, PTS = 1000, PTS_TIME = PTS * timebase = 0.016&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;frame=2, PTS = 2000, PTS_TIME = PTS * timebase = 0.033&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;For almost the same scenario but with a timebase equal to &lt;code&gt;1/60&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;frame=0, PTS = 0, PTS_TIME = 0&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;frame=1, PTS = 1, PTS_TIME = PTS * timebase = 0.016&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;frame=2, PTS = 2, PTS_TIME = PTS * timebase = 0.033&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;frame=3, PTS = 3, PTS_TIME = PTS * timebase = 0.050&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;For a &lt;code&gt;fps=25/1&lt;/code&gt; and &lt;code&gt;timebase=1/75&lt;/code&gt; each PTS will increase &lt;code&gt;timescale / fps = 3&lt;/code&gt; and the PTS time could be:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;frame=0, PTS = 0, PTS_TIME = 0&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;frame=1, PTS = 3, PTS_TIME = PTS * timebase = 0.04&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;frame=2, PTS = 6, PTS_TIME = PTS * timebase = 0.08&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;frame=3, PTS = 9, PTS_TIME = PTS * timebase = 0.12&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;li&gt;&lt;code&gt;frame=24, PTS = 72, PTS_TIME = PTS * timebase = 0.96&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;li&gt;&lt;code&gt;frame=4064, PTS = 12192, PTS_TIME = PTS * timebase = 162.56&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Now with the &lt;code&gt;pts_time&lt;/code&gt; we can find a way to render this synched with audio &lt;code&gt;pts_time&lt;/code&gt; or with a system clock. The FFmpeg libav provides these info through its API:&lt;/p&gt;
&lt;p&gt;Just out of curiosity, the frames we saved were sent in a DTS order (frames: 1,6,4,2,3,5) but played at a PTS order (frames: 1,2,3,4,5). Also, notice how cheap are B-Frames in comparison to P or I-Frames.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;LOG: AVStream-&amp;gt;r_frame_rate 60/1
LOG: AVStream-&amp;gt;time_base 1/60000
...
LOG: Frame 1 (type=I, size=153797 bytes) pts 6000 key_frame 1 [DTS 0]
LOG: Frame 2 (type=B, size=8117 bytes) pts 7000 key_frame 0 [DTS 3]
LOG: Frame 3 (type=B, size=8226 bytes) pts 8000 key_frame 0 [DTS 4]
LOG: Frame 4 (type=B, size=17699 bytes) pts 9000 key_frame 0 [DTS 2]
LOG: Frame 5 (type=B, size=6253 bytes) pts 10000 key_frame 0 [DTS 5]
LOG: Frame 6 (type=P, size=34992 bytes) pts 11000 key_frame 0 [DTS 1]
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;Chapter 2 - transcoding&lt;/h2&gt;
&lt;/article&gt;</description>
<pubDate>Sat, 20 Jan 2018 09:58:42 +0000</pubDate>
<dc:creator>dreampeppers99</dc:creator>
<og:image>https://avatars3.githubusercontent.com/u/55913?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>leandromoreira/ffmpeg-libav-tutorial</og:title>
<og:url>https://github.com/leandromoreira/ffmpeg-libav-tutorial</og:url>
<og:description>ffmpeg-libav-tutorial - [WIP] Learn FFmpeg libav the Hard Way</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/leandromoreira/ffmpeg-libav-tutorial</dc:identifier>
</item>
<item>
<title>A prime number whose binary representation looks like a giraffe</title>
<link>https://www.reddit.com/r/math/comments/7qpfls/does_there_exist_a_prime_number_whose/</link>
<guid isPermaLink="true" >https://www.reddit.com/r/math/comments/7qpfls/does_there_exist_a_prime_number_whose/</guid>
<description>&lt;p&gt;This subreddit is for discussion of mathematical links and questions. &lt;strong&gt;Please read the &lt;a href=&quot;http://www.reddit.com/r/math/wiki/faq&quot;&gt;FAQ&lt;/a&gt; before posting.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Homework problems, practice problems, and similar questions should be directed to &lt;a href=&quot;https://www.reddit.com/r/learnmath&quot;&gt;/r/learnmath&lt;/a&gt;, &lt;a href=&quot;https://www.reddit.com/r/homeworkhelp&quot;&gt;/r/homeworkhelp&lt;/a&gt; or &lt;a href=&quot;https://www.reddit.com/r/cheatatmathhomework&quot;&gt;/r/cheatatmathhomework&lt;/a&gt;. Do not &lt;strong&gt;ask or answer&lt;/strong&gt; this type of question in &lt;a href=&quot;https://www.reddit.com/r/math&quot;&gt;/r/math&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you're asking for help learning/understanding something mathematical, post in the &lt;em&gt;&lt;a href=&quot;http://www.reddit.com/r/math/search?q=Simple+Questions+author%3Aautomoderator+&amp;amp;restrict_sr=on&amp;amp;sort=new&amp;amp;t=all&quot;&gt;Simple Questions&lt;/a&gt;&lt;/em&gt; thread or &lt;a href=&quot;https://www.reddit.com/r/learnmath&quot;&gt;/r/learnmath&lt;/a&gt;. &lt;strong&gt;This includes reference requests&lt;/strong&gt; - also see our lists of recommended &lt;a href=&quot;https://www.reddit.com/r/math/wiki/faq#wiki_what_are_some_good_books_on_topic_x.3F&quot;&gt;books&lt;/a&gt; and &lt;a href=&quot;http://redd.it/2mkmk0&quot;&gt;free online resources&lt;/a&gt;. &lt;a href=&quot;https://www.reddit.com/r/math/comments/7i9t5y/book_recommendation_thread/&quot;&gt;Here&lt;/a&gt; is a more recent thread with book recommendations.&lt;/p&gt;
&lt;p&gt;If you are asking for a calculation to be made, please post to &lt;a href=&quot;https://www.reddit.com/r/askmath&quot;&gt;/r/askmath&lt;/a&gt; or &lt;a href=&quot;https://www.reddit.com/r/learnmath&quot;&gt;/r/learnmath&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you are asking for advice on choosing classes or career prospects, please post in the stickied Career &amp;amp; Education Questions thread.&lt;/p&gt;
&lt;p&gt;Image-only posts should be on-topic and should promote discussion; &lt;strong&gt;please do not post memes or similar content here&lt;/strong&gt;. Please be polite and civil when commenting, and always follow &lt;a href=&quot;http://www.reddit.com/help/reddiquette&quot;&gt;reddiquette&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;All posts and comments should be directly related to mathematics. &lt;strong&gt;General political debate is not permitted&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Filters: &lt;a href=&quot;http://ni.reddit.com/r/math/#ni&quot;&gt;Hide Image Posts&lt;/a&gt; &lt;a href=&quot;http://reddit.com/r/math/#nofilter&quot;&gt;Show All Posts&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;Recurring Threads and Resources&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.reddit.com/r/math/wiki/everythingaboutx&quot;&gt;&lt;em&gt;Everything about X&lt;/em&gt;&lt;/a&gt; - every Wednesday&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;http://www.reddit.com/r/math/search?q=what+are+you+working+on%3F+author%3Aautomoderator+&amp;amp;sort=new&amp;amp;restrict_sr=on&amp;amp;t=all&quot;&gt;What Are You Working On?&lt;/a&gt;&lt;/em&gt; - posted Mondays&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;http://www.reddit.com/r/math/search?q=Career+and+Education+Questions+author%3Aautomoderator+&amp;amp;restrict_sr=on&amp;amp;sort=new&amp;amp;t=all&quot;&gt;Career and Education Q&amp;amp;A&lt;/a&gt;&lt;/em&gt; - Every other Thursday&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;http://www.reddit.com/r/math/search?q=Simple+Questions+author%3Aautomoderator+&amp;amp;restrict_sr=on&amp;amp;sort=new&amp;amp;t=all&quot;&gt;Simple Questions&lt;/a&gt;&lt;/em&gt; - Posted Fridays&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;http://redd.it/2mkmk0&quot;&gt;A Compilation of Free, Online Math Resources&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://kiwiirc.com/client/irc.snoonet.org/math&quot;&gt;Click here to chat with us on IRC!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;Using LaTeX&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To view LaTeX on reddit, install &lt;em&gt;one&lt;/em&gt; of the following:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://a.carapetis.com/mathjax_for_reddit.user.js&quot;&gt;MathJax userscript&lt;/a&gt; (install Greasemonkey or Tampermonkey first)&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://chrome.google.com/webstore/detail/mbfninnbhfepghkkcgdnmfmhhbjmhggn&quot;&gt;TeXtheWorld Chrome extension&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://thewe.net/tex/textheworld7.user.js&quot;&gt;TeXtheWorld userscript&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;[; e^{\pi i} + 1 = 0 ;]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Post the equation above like this:&lt;/p&gt;
&lt;p&gt;`[&lt;em&gt;;&lt;/em&gt; e^{\pi i}+1=0 &lt;em&gt;;&lt;/em&gt;]`&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;Using Superscripts and Subscripts&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;x*_sub_* makes x&lt;em&gt;&lt;em&gt;sub&lt;/em&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;x*`sup`* and x^(sup) both make x&lt;sup&gt;sup&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;x*_sub_`sup`* makes x&lt;em&gt;&lt;em&gt;sub&lt;/em&gt;&lt;code&gt;sup&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;x*`sup`_sub_* makes x&lt;em&gt;&lt;code&gt;sup&lt;/code&gt;&lt;em&gt;sub&lt;/em&gt;&lt;/em&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;Useful Symbols&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Basic Math Symbols&lt;/p&gt;
&lt;p&gt;≠ ± ∓ ÷ × ∙ – √ ‰ ⊗ ⊕ ⊖ ⊘ ⊙ ≤ ≥ ≦ ≧ ≨ ≩ ≺ ≻ ≼ ≽ ⊏ ⊐ ⊑ ⊒ ² ³ °&lt;/p&gt;
&lt;p&gt;Geometry Symbols&lt;/p&gt;
&lt;p&gt;∠ ∟ ° ≅ ~ ‖ ⟂ ⫛&lt;/p&gt;
&lt;p&gt;Algebra Symbols&lt;/p&gt;
&lt;p&gt;≡ ≜ ≈ ∝ ∞ ≪ ≫ ⌊⌋ ⌈⌉ ∘∏ ∐ ∑ ⋀ ⋁ ⋂ ⋃ ⨀ ⨁ ⨂ 𝖕 𝖖 𝖗&lt;/p&gt;
&lt;p&gt;Set Theory Symbols&lt;/p&gt;
&lt;p&gt;∅ ∖ ∁ ↦ ↣ ∩ ∪ ⊆ ⊂ ⊄ ⊊ ⊇ ⊃ ⊅ ⊋ ⊖ ∈ ∉ ∋ ∌ ℕ ℤ ℚ ℝ ℂ ℵ ℶ ℷ ℸ 𝓟&lt;/p&gt;
&lt;p&gt;Logic Symbols&lt;/p&gt;
&lt;p&gt;¬ ∨ ∧ ⊕ → ← ⇒ ⇐ ↔ ⇔ ∀ ∃ ∄ ∴ ∵ ⊤ ⊥ ⊢ ⊨ ⫤ ⊣&lt;/p&gt;
&lt;p&gt;Calculus and Analysis Symbols&lt;/p&gt;
&lt;p&gt;∫ ∬ ∭ ∮ ∯ ∰ ∇ ∆ δ ∂ ℱ ℒ ℓ&lt;/p&gt;
&lt;p&gt;Greek Letters&lt;/p&gt;
&lt;h2&gt;𝛢𝛼 𝛣𝛽 𝛤𝛾 𝛥𝛿 𝛦𝜀𝜖 𝛧𝜁 𝛨𝜂 𝛩𝜃𝜗 𝛪𝜄 𝛫𝜅 𝛬𝜆 𝛭𝜇 𝛮𝜈 𝛯𝜉 𝛰𝜊 𝛱𝜋 𝛲𝜌 𝛴𝜎 𝛵𝜏 𝛶𝜐 𝛷𝜙𝜑 𝛸𝜒 𝛹𝜓 𝛺𝜔&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Other Subreddits&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Math&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Related fields&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 20 Jan 2018 08:28:43 +0000</pubDate>
<dc:creator>svenfaw</dc:creator>
<og:image>https://www.redditstatic.com/icon.png</og:image>
<og:description>674 points and 107 comments so far on reddit</og:description>
<og:title>Does there exist a prime number whose representation on a phone screen looks like a giraffe? • r/math</og:title>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.reddit.com/r/math/comments/7qpfls/does_there_exist_a_prime_number_whose/</dc:identifier>
</item>
<item>
<title>NSA deleted surveillance data it pledged to preserve</title>
<link>https://www.politico.com/story/2018/01/19/nsa-deletes-surveillance-data-351730</link>
<guid isPermaLink="true" >https://www.politico.com/story/2018/01/19/nsa-deletes-surveillance-data-351730</guid>
<description>&lt;div class=&quot; story-intro format-s&quot; itemscope=&quot;&quot; itemprop=&quot;mainEntityOfPage&quot; itemtype=&quot;http://schema.org/Article&quot; readability=&quot;32.564935064935&quot;&gt;

&lt;span itemprop=&quot;image&quot; itemscope=&quot;&quot; itemtype=&quot;https://schema.org/ImageObject&quot;/&gt;
&lt;div class=&quot;fig-graphic&quot;&gt;&lt;img src=&quot;https://static.politico.com/dims4/default/a9770ff/2147483647/resize/1160x%3E/quality/90/?url=https%3A%2F%2Fstatic.politico.com%2F47%2F05%2F7c9c962c4d479d0b52e18c9413b7%2F180119-nsa-1160.jpg&quot; alt=&quot;NSA headquarters is pictured. | Getty Images &quot; title=&quot;NSA headquarters is pictured. | Getty Images &quot;/&gt;&lt;/div&gt;
&lt;p&gt;Since 2007, the NSA has been under court orders to preserve data about some of its surveillance efforts. | Getty Images&lt;/p&gt;
&lt;div class=&quot;summary&quot; readability=&quot;5.5851063829787&quot;&gt;
&lt;header class=&quot;&quot; readability=&quot;2&quot;&gt;
&lt;p class=&quot;subhead&quot;&gt;The agency tells a federal judge that it is investigating and 'sincerely regrets its failure.'&lt;/p&gt;
&lt;/header&gt;&lt;footer class=&quot;meta&quot;&gt;
&lt;p class=&quot;byline&quot;&gt;By &lt;a href=&quot;https://www.politico.com/staff/josh-gerstein&quot; rel=&quot;author&quot; class=&quot;url fn&quot; target=&quot;_top&quot;&gt;JOSH GERSTEIN&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;timestamp&quot;&gt;&lt;time itemprop=&quot;datePublished&quot; datetime=&quot;2018-01-19 19:39:25&quot;&gt;01/19/2018 07:39 PM EST&lt;/time&gt;&lt;/p&gt;
&lt;/footer&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The National Security Agency destroyed surveillance data it pledged to preserve in connection with pending lawsuits and apparently never took some of the steps it told a federal court it had taken to make sure the information wasn’t destroyed, according to recent court filings.&lt;/p&gt;
&lt;p&gt;Word of the NSA’s foul-up is emerging just as Congress has extended for six years the legal authority the agency uses for much of its surveillance work conducted through U.S. internet providers and tech firms. President Donald Trump signed that measure into law Friday.&lt;/p&gt;
&lt;p class=&quot;story-continued&quot;&gt;Story Continued Below&lt;/p&gt;

&lt;p&gt;Since 2007, the NSA has been under court orders to preserve data about certain of its surveillance efforts that came under legal attack following disclosures that President George W. Bush ordered warrantless wiretapping of international communications after the 2001 terrorist attacks on the U.S. In addition, the agency has made a series of representations in court over the years about how it is complying with its duties.&lt;/p&gt;
&lt;p&gt;However, the NSA told U.S. District Court Judge Jeffrey White in a filing on Thursday night and another little-noticed submission last year that the agency did not preserve the content of internet communications intercepted between 2001 and 2007 under the program Bush ordered. To make matters worse, backup tapes that might have mitigated the failure were erased in 2009, 2011 and 2016, the NSA said.&lt;/p&gt;
&lt;aside class=&quot;story-related cl-l db&quot;&gt;&lt;aside class=&quot;content-group inline-module-playbook&quot;&gt;&lt;section class=&quot;speedbump layout-bi&quot;&gt;&lt;div class=&quot;speedbump-item pos-alpha&quot;&gt;
&lt;div class=&quot;spotlight spotlight--flex&quot; readability=&quot;6.5&quot;&gt;
&lt;div class=&quot;summary link-alt fx1&quot; readability=&quot;8&quot;&gt;
&lt;h2&gt;The most reliable politics newsletter.&lt;/h2&gt;
&lt;p&gt;Sign up for POLITICO Playbook and get the latest news, every morning — in your inbox.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;speedbump-item pos-beta&quot;&gt;
&lt;div class=&quot;js-tealium-newsletter&quot; data-subscription-module=&quot;newsletter_inline_standard_Playbook - POLITICO&quot; readability=&quot;6.5&quot;&gt;
&lt;div class=&quot;dari-frame dari-frame-loaded&quot; name=&quot;inline-module-playbook-full-0000014f-1646-d88f-a1cf-5f46b7bd0000&quot; data-insertion-mode=&quot;replace&quot; data-extra-form-data=&quot;_frame.path=5c388a2e37218b65f1db610df3d5c42a&amp;amp;_frame.name=inline-module-playbook-full-0000014f-1646-d88f-a1cf-5f46b7bd0000&quot; readability=&quot;8&quot;&gt;

&lt;p class=&quot;legal-disclaimer&quot;&gt;By signing up you agree to receive email newsletters or alerts from POLITICO. You can unsubscribe at any time.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;&lt;/aside&gt;&lt;/aside&gt;&lt;p&gt;“The NSA sincerely regrets its failure to prevent the deletion of this data,” NSA’s deputy director of capabilities, identified publicly as “Elizabeth B.,” wrote in &lt;a href=&quot;https://www.politico.com/f/?id=00000161-10d3-d990-af71-f8f7a0010001&quot; target=&quot;_blank&quot;&gt;&lt;u&gt;a declaration filed in October&lt;/u&gt;&lt;/a&gt;. “NSA senior management is fully aware of this failure, and the Agency is committed to taking swift action to respond to the loss of this data.”&lt;/p&gt;
&lt;p&gt;In &lt;a href=&quot;https://www.politico.com/f/?id=00000161-10d4-d990-af71-f8f547280001&quot; target=&quot;_blank&quot;&gt;&lt;u&gt;the update Thursday&lt;/u&gt;&lt;/a&gt;, another NSA official said the data were deleted during a broad, housecleaning effort aimed at making space for incoming information.&lt;/p&gt;
&lt;p&gt;“The NSA’s review to date reveals that this [Presidential Surveillance Program] Internet content data was not specifically targeted for deletion,” wrote the official, identified as “Dr. Mark O,” “but rather the PSP Internet content data matched criteria that were broadly used to delete data of a certain type … in response to mission requirements to free-up space and improve performance of the [redacted] back-up system. The NSA is still investigating how these deletions came about given the preservation obligations extant at the time. The NSA, however, has no reason to believe at this time that PSP Internet content data was specifically targeted for deletion.”&lt;/p&gt;
&lt;p&gt;An NSA spokesman declined to comment on Friday.&lt;/p&gt;
&lt;p&gt;Defiance of a court order can result in civil or criminal contempt charges, as well as sanctions against the party responsible. So far, no one involved appears to have asked White to impose any punishment or sanction on the NSA over the newly disclosed episodes, although the details of what happened are still emerging.&lt;/p&gt;
&lt;p&gt;“It’s really disappointing,” said David Greene, an attorney with the Electronic Frontier Foundation, which has been leading the prolonged litigation over the program in federal court in San Francisco. “The obligation’s been in place for a really long time now. … We had a major dust-up about it just a few years ago. This is definitely something that should’ve been found sooner.”&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.politico.com/blogs/under-the-radar/2014/03/judge-orders-nsa-to-preserve-call-data-184873&quot; target=&quot;_blank&quot;&gt;&lt;u&gt;The last legal showdown over the issue&lt;/u&gt;&lt;/a&gt; may have actually compounded the NSA’s problems. In May 2014, an NSA official known as “Miriam P.” assured the court that the data were safe.&lt;/p&gt;
&lt;p&gt;The NSA is “preserving magnetic/digital tapes of the Internet content intercepted under the [PSP] since the inception of the program,” she wrote, adding that “the NSA has stored these tapes in the offices of its General Counsel.”&lt;/p&gt;
&lt;p&gt;The agency now says, “regrettably,” that the statement “may have been only partially accurate when made.”&lt;/p&gt;
&lt;p&gt;The latest NSA filing says the ongoing investigation indicates that officials did a “physical inspection” in 2014 to confirm the tapes’ presence in the counsel’s office storage space. However, “those tapes largely concerned metadata,” not the content of communications the NSA intercepted.&lt;/p&gt;
&lt;aside class=&quot;story-related&quot;&gt;&lt;article class=&quot;story-frag format-sm&quot;&gt;&lt;div class=&quot;fig-graphic&quot;&gt;&lt;a href=&quot;https://www.politico.com/story/2018/01/19/twitter-users-russian-trolls-437247&quot; target=&quot;_top&quot; data-tracking=&quot;mpos=inside-body&amp;amp;mid=parentheticalmodule&amp;amp;lindex=Unknown&amp;amp;lcol=Unknown&quot; class=&quot;js-tealium-tracking&quot;&gt;&lt;img data-lazy-img=&quot;https://static.politico.com/dims4/default/9ac1a69/2147483647/legacy_thumbnail/90x49%3E/quality/90/?url=http%3A%2F%2Fs3-origin-images.politico.com%2F2013%2F09%2F13%2F130913_twitter_rtr_605.jpg&quot; src=&quot;data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==&quot; alt=&quot;The Twitter logo is pictured. | AP Photo &quot; data-size=&quot;promo_xsmall_rectangle&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;/article&gt;&lt;/aside&gt;&lt;p&gt;The NSA says the impact of the misstatement and the deletion on the litigation should be “limited” because it has found back-ups of some content from about four months in 2003 and because it has a larger set of metadata from 2004 to 2007. That metadata should give a strong indication of whether the plaintiffs in the suits had their communications captured by the NSA, even if the communications themselves may be lost, the filings indicate. The NSA is also using “extraordinary” efforts to recover the data from tapes that were reused, it said.&lt;/p&gt;
&lt;p&gt;Asked why the Electronic Frontier Foundation hasn’t publicized the episode, Greene said his group was waiting for the NSA to turn over data that the plaintiffs in the suits have demanded before considering next steps regarding the spy agency’s failure to maintain the records it said it was keeping.&lt;/p&gt;
&lt;p&gt;“We don't know exactly how bad it is,” the lawyer said, adding: “Even if you take them at their word that this was just an honest mistake, what it shows is despite your best intention to comply with important restrictions, it can be really difficult to implement. … It shows that with the really tremendous volume of information they’re vacuuming up, it is impossible to be meticulous.”&lt;br/&gt;&lt;/p&gt;

&lt;div class=&quot;story-supplement&quot;&gt;
&lt;aside class=&quot;content-categories&quot;&gt;&lt;h6&gt;This article tagged under:&lt;/h6&gt;
&lt;/aside&gt;&lt;/div&gt;
&lt;div class=&quot;&quot;&gt;
&lt;aside class=&quot;content-group&quot;&gt;&lt;div class=&quot;story-supplement&quot;&gt;
&lt;div class=&quot;spotlight&quot; readability=&quot;6.0165289256198&quot;&gt;
&lt;div class=&quot;summary fs-i&quot; readability=&quot;7.7355371900826&quot;&gt;
&lt;p&gt;Missing out on the latest scoops? Sign up for &lt;a href=&quot;http://www.politico.com/subscribe/playbook?cid=su_stft_pb&quot; target=&quot;_blank&quot;&gt;POLITICO Playbook&lt;/a&gt; and get the latest news, every morning — in your inbox.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/aside&gt;&lt;/div&gt;


</description>
<pubDate>Sat, 20 Jan 2018 04:10:45 +0000</pubDate>
<dc:creator>tonyztan</dc:creator>
<og:title>NSA deleted surveillance data it pledged to preserve</og:title>
<og:description>The agency tells a federal judge that it is investigating and 'sincerely regrets its failure.'</og:description>
<og:type>article</og:type>
<og:url>http://politi.co/2BfbiXW</og:url>
<og:image>https://static.politico.com/47/05/7c9c962c4d479d0b52e18c9413b7/180119-nsa-1160.jpg</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.politico.com/story/2018/01/19/nsa-deletes-surveillance-data-351730</dc:identifier>
</item>
</channel>
</rss>