<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Non-profit’s $300 hepatitis C cure as effective as $84,000 alternative</title>
<link>https://www.theguardian.com/science/2018/apr/12/non-profits-300-hepatitis-c-cure-as-effective-as-84000-alternative</link>
<guid isPermaLink="true" >https://www.theguardian.com/science/2018/apr/12/non-profits-300-hepatitis-c-cure-as-effective-as-84000-alternative</guid>
<description>&lt;p&gt;An affordable hepatitis C treatment has been shown to be safe and effective, with very high cure rates for patients including hard-to-treat cases, in interim clinical trial results that offer hope to the 71 million people living with the disease worldwide.&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;The treatment is expected to cost $300 for 12 weeks, or $3.50 per day, in Malaysia, where trials were conducted along with Thailand – a fraction of the cost of other hepatitis C medicines produced by major drugmakers, which often run to tens of thousands of dollars.&lt;/p&gt;
&lt;p&gt;The &lt;a href=&quot;https://www.dndi.org/&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;Drugs for Neglected Diseases initiative&lt;/a&gt; (DNDi), a not-for-profit organisation, is working with the Egyptian drugmaker Pharco Pharmaceuticals to bring a combination treatment of two hepatitis C tablets, ravidasvir ­(a new drug)­ and sofosbuvir, to countries that cannot afford to pay the high prices charged by US companies Gilead and AbbVie. This is taking longer than expected but has moved a big step closer with the latest results.&lt;/p&gt;
&lt;p&gt;The interim results of the phase II/III trial of 301 people will be presented in Paris on Thursday. It has been funded by Médecins Sans Frontières, one of DNDi’s founding partners which also include France’s Institut Pasteur.&lt;/p&gt;
&lt;p&gt;DNDi said 97% of patients were cured after being treated with the combination pill for 12 weeks. Even hard-to-treat cases such as people with HIV or liver cirrhosis showed very high cure rates, of 96% and 97% respectively.&lt;/p&gt;

&lt;div class=&quot;u-responsive-ratio&quot;&gt;&lt;img class=&quot;gu-image&quot; itemprop=&quot;contentUrl&quot; alt=&quot;Egyptian labourers queue for hepatitis C test. Egypt has the highest prevalence of hepatitis C infections in the world – 7% of Egyptians between the ages of 15 and 59 are infected with the virus. The epidemic started after government mass vaccinations were carried out with unsterilised syringes in the 1950s.&quot; src=&quot;https://i.guim.co.uk/img/media/a8e8f398ada3699a9b7dce7f023039c5fa119f18/553_487_4215_2529/master/4215.jpg?w=300&amp;amp;q=55&amp;amp;auto=format&amp;amp;usm=12&amp;amp;fit=max&amp;amp;s=fb10f697dbab8f8ff229a6075df62935&quot;/&gt;&lt;/div&gt;

Egyptian labourers queue for hepatitis C test. Egypt has the highest prevalence of hepatitis C infections in the world – 7% of Egyptians between the ages of 15 and 59 are infected with the virus. The epidemic started after government mass vaccinations were carried out with unsterilised syringes in the 1950s. Photograph: Khaled Desouki/AFP/Getty Images
&lt;p&gt;&lt;a href=&quot;https://www.theguardian.com/society/hepatitis-c&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;Hepatitis C&lt;/a&gt; is a blood-borne viral infection that can lead to liver cirrhosis, cancer and death. It affects more than 71 million people worldwide and causes 400,000 deaths a year. Although highly effective medicines have been available for several years, their high cost means that less than three million people are on treatment.&lt;/p&gt;
&lt;aside class=&quot;element element-rich-link element--thumbnail element-rich-link--not-upgraded&quot; data-component=&quot;rich-link&quot; data-link-name=&quot;rich-link-2 | 1&quot;&gt;
&lt;/aside&gt;&lt;p&gt;US drugmaker Gilead has lowered the price of its Harvoni tablet and other medicines in lower and middle-income countries, but it is still too high for governments to roll out mass hepatitis C treatment programmes.&lt;/p&gt;
&lt;p&gt;Harvoni now costs about $48,000 for a 12-week course in Malaysia and $12,000 in Chile. Gilead’s previous Sovaldi treatment cost $1,000 a pill, or $84,000 over 12 weeks. Prices vary around the world and tend to be highest in the US.&lt;/p&gt;
&lt;p&gt;Gilead has come under pressure from US rival AbbVie, which launched a new hepatitis C medicine, Mavyret, last year with a shorter, eight-week treatment course priced at $26,400.&lt;/p&gt;
&lt;p&gt;Bernard Pécoul, executive director of DNDi, said: “The results indicate that the sofosbuvir/ravidasvir combination is comparable to the very best hepatitis C therapies available today but it is priced affordably and could allow an alternative option in countries excluded from pharmaceutical company access programmes.”&lt;/p&gt;
&lt;aside class=&quot;element element-rich-link element--thumbnail element-rich-link--not-upgraded&quot; data-component=&quot;rich-link&quot; data-link-name=&quot;rich-link-2 | 2&quot;&gt;
&lt;/aside&gt;&lt;p&gt;The treatment is expected to be available in Malaysia within one to two years. DNDi has also signed deals in Latin America to make it available for $500 for the 12 week course, with a provision to bring the price down to $300.&lt;/p&gt;
&lt;p&gt;The trial using medicines produced by Pharco was run by DNDi and co-sponsored by the Malaysian Ministry of &lt;a href=&quot;https://www.theguardian.com/society/health&quot; data-link-name=&quot;auto-linked-tag&quot; data-component=&quot;auto-linked-tag&quot; class=&quot;u-underline&quot;&gt;Health&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The medicine has also been tested on 300 patients in &lt;a href=&quot;https://www.theguardian.com/world/egypt&quot; data-link-name=&quot;auto-linked-tag&quot; data-component=&quot;auto-linked-tag&quot; class=&quot;u-underline&quot;&gt;Egypt&lt;/a&gt;, who have different genetic characteristics, with a 100% cure rate. Further studies are being carried out in South Africa and Ukraine to cover all six genotypes of the disease.&lt;/p&gt;
&lt;p&gt;DNDi has licensed rights for ravidasvir in low and middle income countries from the Californian firm that developed it, Presidio Pharmaceuticals. The UK &lt;a href=&quot;https://www.nhs.uk/conditions/hepatitis-c/&quot; data-link-name=&quot;in body link&quot; class=&quot;u-underline&quot;&gt;has an estimated 215,000 hepatitis C cases&lt;/a&gt;, while the US has 3.4m.&lt;/p&gt;


</description>
<pubDate>Thu, 12 Apr 2018 06:57:19 +0000</pubDate>
<dc:creator>lnguyen</dc:creator>
<og:url>http://www.theguardian.com/science/2018/apr/12/non-profits-300-hepatitis-c-cure-as-effective-as-84000-alternative</og:url>
<og:description>Exclusive: 71 million people stand to benefit from reduced price treatment for virus which can lead to liver cirrhosis, cancer and death</og:description>
<og:image>https://i.guim.co.uk/img/media/49402bd9af35c354529e0ade6c6c180fffce034d/0_142_4761_2857/master/4761.jpg?w=1200&amp;h=630&amp;q=55&amp;auto=format&amp;usm=12&amp;fit=crop&amp;crop=faces%2Centropy&amp;bm=normal&amp;ba=bottom%2Cleft&amp;blend64=aHR0cHM6Ly91cGxvYWRzLmd1aW0uY28udWsvMjAxOC8wMS8zMS9mYWNlYm9va19kZWZhdWx0LnBuZw&amp;s=33645deedbffc173df6ea14e90ddead4</og:image>
<og:type>article</og:type>
<og:title>Non-profit’s $300 hepatitis C cure as effective as $84,000 alternative</og:title>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.theguardian.com/science/2018/apr/12/non-profits-300-hepatitis-c-cure-as-effective-as-84000-alternative</dc:identifier>
</item>
<item>
<title>Could a Neuroscientist Understand a Microprocessor? (2017)</title>
<link>http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268</link>
<guid isPermaLink="true" >http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268</guid>
<description>&lt;div class=&quot;abstract toc-section&quot; readability=&quot;24&quot;&gt;
&lt;h2&gt;Abstract&lt;/h2&gt;

&lt;p&gt;There is a popular belief in neuroscience that we are primarily data limited, and that producing large, multimodal, and complex datasets will, with the help of advanced data analysis algorithms, lead to fundamental insights into the way the brain processes information. These datasets do not yet exist, and if they did we would have no way of evaluating whether or not the algorithmically-generated insights were sufficient or even correct. To address this, here we take a classical microprocessor as a model organism, and use our ability to perform arbitrary experiments on it to see if popular data analysis methods from neuroscience can elucidate the way it processes information. Microprocessors are among those artificial information processing systems that are both complex and that we understand at all levels, from the overall logical flow, via logical gates, to the dynamics of transistors. We show that the approaches reveal interesting structure in the data but do not meaningfully describe the hierarchy of information processing in the microprocessor. This suggests current analytic approaches in neuroscience may fall short of producing meaningful understanding of neural systems, regardless of the amount of data. Additionally, we argue for scientists using complex non-linear dynamical systems with known ground truth, such as the microprocessor as a validation platform for time-series and structure discovery methods.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;abstract toc-section&quot; readability=&quot;13&quot;&gt;
&lt;h2&gt;Author Summary&lt;/h2&gt;

&lt;p&gt;Neuroscience is held back by the fact that it is hard to evaluate if a conclusion is correct; the complexity of the systems under study and their experimental inaccessability make the assessment of algorithmic and data analytic technqiues challenging at best. We thus argue for testing approaches using known artifacts, where the correct interpretation is known. Here we present a microprocessor platform as one such test case. We find that many approaches in neuroscience, when used naïvely, fall short of producing a meaningful understanding.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;articleinfo&quot; readability=&quot;93.9125&quot;&gt;
&lt;p&gt;&lt;strong&gt;Citation:&lt;/strong&gt; Jonas E, Kording KP (2017) Could a Neuroscientist Understand a Microprocessor? PLoS Comput Biol 13(1): e1005268. https://doi.org/10.1371/journal.pcbi.1005268&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Editor:&lt;/strong&gt; Jörn Diedrichsen, University College London, UNITED KINGDOM&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Received:&lt;/strong&gt; September 18, 2016; &lt;strong&gt;Accepted:&lt;/strong&gt; November 16, 2016; &lt;strong&gt;Published:&lt;/strong&gt; January 12, 2017&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Copyright:&lt;/strong&gt; © 2017 Jonas, Kording. This is an open access article distributed under the terms of the &lt;a href=&quot;http://creativecommons.org/licenses/by/4.0/&quot;&gt;Creative Commons Attribution License&lt;/a&gt;, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data Availability:&lt;/strong&gt; All data are available at &lt;a href=&quot;http://ericmjonas.github.io/neuroproc/&quot;&gt;http://ericmjonas.github.io/neuroproc/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Funding:&lt;/strong&gt; EJ is supported in part by NSF CISE Expeditions Award CCF-1139158, DOE Award SN10040 DE-SC0012463, and DARPA XData Award FA8750-12-2-0331, and gifts from Amazon Web Services, Google, IBM, SAP, The Thomas and Stacey Siebel Foundation, Adatao, Adobe, Apple, Inc., Blue Goji, Bosch, Cisco, Cray, Cloudera, EMC2, Ericsson, Facebook, Fujitsu, Guavus, HP, Huawei, Informatica, Intel, Microsoft, NetApp, Pivotal, Samsung, Schlumberger, Splunk, Virdata, and VMware. KPK is supported by the National Institutes of Health (MH103910, NS074044, EY021579). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Competing interests:&lt;/strong&gt; The authors have declared that no competing interests exist.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section1&quot; class=&quot;section toc-section&quot; readability=&quot;114.88358406735&quot;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The development of high-throughput techniques for studying neural systems is bringing about an era of big-data neuroscience [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref001&quot; class=&quot;ref-tip&quot;&gt;1&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref002&quot; class=&quot;ref-tip&quot;&gt;2&lt;/a&gt;]. Scientists are beginning to reconstruct connectivity [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref003&quot; class=&quot;ref-tip&quot;&gt;3&lt;/a&gt;], record activity [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref004&quot; class=&quot;ref-tip&quot;&gt;4&lt;/a&gt;], and simulate computation [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref005&quot; class=&quot;ref-tip&quot;&gt;5&lt;/a&gt;] at unprecedented scales. However, even state-of-the-art neuroscientific studies are still quite limited in organism complexity and spatiotemporal resolution [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref006&quot; class=&quot;ref-tip&quot;&gt;6&lt;/a&gt;–&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref008&quot; class=&quot;ref-tip&quot;&gt;8&lt;/a&gt;]. It is hard to evaluate how much scaling these techniques will help us understand the brain.&lt;/p&gt;

&lt;p&gt;In neuroscience it can be difficult to evaluate the quality of a particular model or analysis method, especially in the absence of known truth. However, there are other systems, in particular man made ones that we do understand. As such, one can take a human-engineered system and ask if the methods used for studying biological systems would allow understanding the artificial system. In this way, we take as inspiration Yuri Lazbnick’s well-known 2002 critique of modeling in molecular biology, “Could a biologist fix a radio?” [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref009&quot; class=&quot;ref-tip&quot;&gt;9&lt;/a&gt;]. However, a radio is clearly much simpler than the nervous system, leading us to seek out a more complex, yet still well-understood engineered system. The microprocessors in early computing systems can serve this function.&lt;/p&gt;

&lt;p&gt;Here we will try to understand a known artificial system, a classical microprocessor by applying data analysis methods from neuroscience. We want to see what kind of an understanding would emerge from using a broad range of currently popular data analysis methods. To do so, we will analyze the connections on the chip, the effects of destroying individual transistors, single-unit tuning curves, the joint statistics across transistors, local activities, estimated connections, and whole-device recordings. For each of these, we will use standard techniques that are popular in the field of neuroscience. We find that many measures are surprisingly similar between the brain and the processor but that our results do not lead to a meaningful understanding of the processor. The analysis can not produce the hierarchical understanding of information processing that most students of electrical engineering obtain. It suggests that the availability of unlimited data, as we have for the processor, is in no way sufficient to allow a real understanding of the brain. We argue that when studying a complex system like the brain, methods and approaches should first be sanity checked on complex man-made systems that share many of the violations of modeling assumptions of the real system.&lt;/p&gt;
&lt;div id=&quot;section1&quot; class=&quot;section toc-section&quot; readability=&quot;69.575021682567&quot;&gt;
&lt;h3&gt;An engineered model organism&lt;/h3&gt;

&lt;p&gt;The MOS 6502 (and the virtually identical MOS 6507) were the processors in the Apple I, the Commodore 64, and the Atari Video Game System (VCS) (see [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref010&quot; class=&quot;ref-tip&quot;&gt;10&lt;/a&gt;] for a comprehensive review). The Visual6502 team reverse-engineered the 6507 from physical integrated circuits [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref011&quot; class=&quot;ref-tip&quot;&gt;11&lt;/a&gt;] by chemically removing the epoxy layer and imaging the silicon die with a light microscope. Much like with current connectomics work [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref012&quot; class=&quot;ref-tip&quot;&gt;12&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref013&quot; class=&quot;ref-tip&quot;&gt;13&lt;/a&gt;], a combination of algorithmic and human-based approaches were used to label regions, identify circuit structures, and ultimately produce a transistor-accurate netlist (a full connectome) for this processor consisting of 3510 enhancement-mode transistors. Several other support chips, including the Television Interface Adaptor (TIA) were also reverse-engineered and a cycle-accurate simulator was written that can simulate the voltage on every wire and the state of every transistor. The reconstruction has sufficient fidelity to run a variety of classic video games, which we will detail below. The simulation generates roughly 1.5GB/sec of state information, allowing a real big-data analysis of the processor.&lt;/p&gt;

&lt;p&gt;The simplicity of early video games has led to their use as model systems for reinforcement learning [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref014&quot; class=&quot;ref-tip&quot;&gt;14&lt;/a&gt;] and computational complexity research [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref015&quot; class=&quot;ref-tip&quot;&gt;15&lt;/a&gt;]. The video game system (“whole animal”) has a well defined output in each of the three behavioral conditions (games). It produces an input-dependent output that is dynamic, and, in the opinion of the authors, quite exciting. It can be seen as a more complex version of the &lt;em&gt;Mus Silicium&lt;/em&gt; project [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref016&quot; class=&quot;ref-tip&quot;&gt;16&lt;/a&gt;]. It is also a concrete implementation of a thought experiment that has been mentioned on and off in the literature [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref017&quot; class=&quot;ref-tip&quot;&gt;17&lt;/a&gt;–&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref020&quot; class=&quot;ref-tip&quot;&gt;20&lt;/a&gt;]. The richness of the dynamics and our knowledge about its inner workings makes it an attractive test case for approaches in neuroscience.&lt;/p&gt;

&lt;p&gt;Here we will examine three different “behaviors”, that is, three different games: Donkey Kong (1981), Space Invaders (1978), and Pitfall (1981). Obviously these “behaviors” are qualitatively different from those of animals and may seem more complicated. However, even the simple behaviors that are studied in neuroscience still involve a plethora of components, typically including the allocation of attention, cognitive processing, and multiple modalities of inputs and outputs. As such, the breadth of ongoing computation in the processor may actually be simpler than those in the brain.&lt;/p&gt;

&lt;p&gt;The objective of clever experimental design in neuroscience often is to find behaviors that only engage one kind of computation in the brain. In the same way, all our experiments on the chip will be limited by us only using these games to probe it. As much as more neuroscience is interested in naturalistic behaviors [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref021&quot; class=&quot;ref-tip&quot;&gt;21&lt;/a&gt;], here we analyze a naturalistic behavior of the chip. In the future it may be possible to excute simpler, custom code on the processor to tease apart aspects of computation, but we currently lack such capability in biological organisms.&lt;/p&gt;

&lt;p&gt;Much has been written about the differences between computation &lt;em&gt;in silico&lt;/em&gt; and computation &lt;em&gt;in vivo&lt;/em&gt; [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref022&quot; class=&quot;ref-tip&quot;&gt;22&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref023&quot; class=&quot;ref-tip&quot;&gt;23&lt;/a&gt;]—the stochasticity, redundancy, and robustness [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref024&quot; class=&quot;ref-tip&quot;&gt;24&lt;/a&gt;] present in biological systems seems dramatically different from that of a microprocessor. But there are many parallels we can draw between the two types of systems. Both systems consist of interconnections of a large number of simpler, stereotyped computing units. They operate on multiple timescales. They consist of somewhat specialized modules organized hierarchically. They can flexibly route information and retain memory over time. Despite many differences there are also many similarities. We do not wish to overstate this case—in many ways, the functional specialization present in a large mammalian brain far eclipses that present in the processor. Indeed, the processor’s scale and specialization share more in common with &lt;em&gt;C. elegans&lt;/em&gt; than a mouse.&lt;/p&gt;

&lt;p&gt;Yet many of the differences should make analysing the chip easier than analyzing the brain. For example, it has a clearer architecture and far fewer modules. The human brain has hundreds of different types of neurons and a similar diversity of proteins at each individual synapse [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref025&quot; class=&quot;ref-tip&quot;&gt;25&lt;/a&gt;], whereas our model microprocessor has only one type of transistor (which has only three terminals). The processor is deterministic while neurons exhibit various sources of randomness. With just a couple thousand transistors it is also far smaller. And, above all, in the simulation it is fully accessible to any and all experimental manipulations that we might want to do on it.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section2&quot; class=&quot;section toc-section&quot; readability=&quot;46.886060606061&quot;&gt;
&lt;h3&gt;What does it mean to understand a system&lt;/h3&gt;

&lt;p&gt;Importantly, the processor allows us to ask “do we really understand this system?” Most scientists have at least behavioral-level experience with these classical video game systems, and many in our community, including some electrophysiologists and computational neuroscientists, have formal training in computer science, electrical engineering, computer architecture, and software engineering. As such, we believe that most neuroscientists may have better intuitions about the workings of a processor than about the workings of the brain.&lt;/p&gt;

&lt;p&gt;What constitutes an understanding of a system? Lazbnick’s original paper argued that understanding was achieved when one could “fix” a broken implementation. Understanding of a particular region or part of a system would occur when one could describe so accurately the inputs, the transformation, and the outputs that one brain region could be replaced with an entirely synthetic component. Indeed, some neuroengineers are following this path for sensory [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref026&quot; class=&quot;ref-tip&quot;&gt;26&lt;/a&gt;] and memory [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref027&quot; class=&quot;ref-tip&quot;&gt;27&lt;/a&gt;] systems. Alternatively, we could seek to understand a system at differing, complementary levels of analysis, as David Marr and Tomaso Poggio outlined in 1982 [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref028&quot; class=&quot;ref-tip&quot;&gt;28&lt;/a&gt;]. First, we can ask if we understand what the system does at the computational level: what is the problem it is seeking to solve via computation? We can ask how the system performs this task algorithmically: what processes does it employ to manipulate internal representations? Finally, we can seek to understand how the system implements the above algorithms at a physical level. What are the characteristics of the underlying implementation (in the case of neurons, ion channels, synaptic conductances, neural connectivity, and so on) that give rise to the execution of the algorithm? Ultimately, we want to understand the brain at all these levels.&lt;/p&gt;

&lt;p&gt;In this paper, much as in systems neuroscience, we consider the quest to gain an understanding of how circuit elements give rise to computation. Computer architecture studies how small circuit elements, like registers and adders, give rise to a system capable of performing general-purpose computation. When it comes to the processor, we understand this level extremely well, as it is taught to most computer science undergraduates. Knowing what a satisfying answer to “how does a processor compute?” looks like makes it easy to evaluate how much we learn from an experiment or an analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section3&quot; class=&quot;section toc-section&quot; readability=&quot;45.947169811321&quot;&gt;
&lt;h3&gt;What would a satisfying understanding of the processor look like?&lt;/h3&gt;

&lt;p&gt;We can draw from our understanding of computer architecture to firmly ground what a full understanding of a processor would look like (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g001&quot;&gt;Fig 1&lt;/a&gt;). The processor is used to implement a computing machine. It implements a finite state machine which sequentially reads in an instruction from memory (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g001&quot;&gt;Fig 1a&lt;/a&gt;, green) and then either modifies its internal state or interacts with the world. The internal state is stored in a collection of byte-wide registers (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g001&quot;&gt;Fig 1a&lt;/a&gt;, red). As an example, the processor might read an instruction from memory telling it to add the contents of register A to the contents of register B. It then decodes this instruction, enabling the arithmetic logic unit (ALU, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g001&quot;&gt;Fig 1a&lt;/a&gt;, blue) to add those registers, storing the output. Optionally, the next instruction might save the result back out to RAM (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g001&quot;&gt;Fig 1a&lt;/a&gt;, yellow). It is this repeated cycle that gives rise to the complex series of behaviors we can observe in this system. Note that this description in many ways ignores the functions of the individual transistors, focusing instead on circuits modules like “registers” which are composed of many transistors, much as a systems neuroscientist might focus on a cytoarchitecturally-distinct area like hipppocampus as opposed to individual neurons.&lt;/p&gt;

&lt;div class=&quot;figure&quot; data-doi=&quot;10.1371/journal.pcbi.1005268.g001&quot; readability=&quot;17.1259765625&quot;&gt;
&lt;div class=&quot;img-box&quot;&gt;&lt;a title=&quot;Click for larger image&quot; href=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=medium&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g001&quot; data-doi=&quot;info:doi/10.1371/journal.pcbi.1005268&quot; data-uri=&quot;info:doi/10.1371/journal.pcbi.1005268.g001&quot;&gt;&lt;img src=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=inline&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g001&quot; alt=&quot;thumbnail&quot; class=&quot;thumbnail&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;p&gt;&lt;span&gt;Fig 1.&lt;/span&gt; A microprocessor is understood at all levels.&lt;/p&gt;

&lt;p&gt;(&lt;strong&gt;A&lt;/strong&gt;) The instruction fetcher obtains the next instruction from memory. This then gets converted into electrical signals by the instruction decoder, and these signals enable and disable various internal parts of the processor, such as registers and the arithmetic logic unit (ALU). The ALU performs mathematical operations such as addition and subtraction. The results of these computations can then be written back to the registers or memory. (&lt;strong&gt;B&lt;/strong&gt;) Within the ALU there are well-known circuits, such as this one-bit adder, which sums two one-bit signals and computes the result and a carry signal. (&lt;strong&gt;C&lt;/strong&gt;) Each logic gate in (&lt;strong&gt;B&lt;/strong&gt;) has a known truth table and is implemented by a small number of transistors. (&lt;strong&gt;D&lt;/strong&gt;) A single NAND gate is comprised of transistors, each transistor having three terminals (&lt;strong&gt;E&lt;/strong&gt;). We know (&lt;strong&gt;F&lt;/strong&gt;) the precise silicon layout of each transistor.&lt;/p&gt;
&lt;p class=&quot;caption_object&quot;&gt;&lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1005268.g001&quot;&gt;https://doi.org/10.1371/journal.pcbi.1005268.g001&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Each of the functions within the processor contains algorithms and a specific implementation. Within the arithmetic logic unit, there is a byte wide adder, which is in part made of binary adders (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g001&quot;&gt;Fig 1b&lt;/a&gt;), which are made out of AND/NAND gates, which are made of transistors. This is in a similar way as the brain consists of regions, circuits, microcircuits, neurons, and synapses.&lt;/p&gt;

&lt;p&gt;If we were to analyze a processor using techniques from systems neuroscience we would hope that it helps guide us towards the descriptions that we used above. In the rest of the paper we will apply neuroscience techniques to data from the processor. We will finally discuss how neuroscience can work towards techniques that will make real progress at moving us closer to a satisfying understanding of computation, in the chip, and in our brains.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;section2&quot; class=&quot;section toc-section&quot; readability=&quot;138.078255918&quot;&gt;
&lt;h2&gt;Results&lt;/h2&gt;

&lt;p&gt;Validating our understanding of complex systems is incredibly difficult when we do not know the actual ground truth. Thus we use an engineered system, the MOS6502, where we understand every aspect of its behavior at many levels. We will examine the processor at increasingly-fine spatial and temporal resolutions, eventually achieving true “big-data” scale: a “processor activity map”, with every transistor state and every wire voltage. As we apply the various techniques that are currently used in neuroscience we will ask how the analyses bring us closer to an understanding of the microprocessor (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g002&quot;&gt;Fig 2&lt;/a&gt;). We will use this well defined comparison to ask questions about the validity of current approaches to studying information processing in the brain.&lt;/p&gt;

&lt;div class=&quot;figure&quot; data-doi=&quot;10.1371/journal.pcbi.1005268.g002&quot; readability=&quot;12.812379110251&quot;&gt;
&lt;div class=&quot;img-box&quot;&gt;&lt;a title=&quot;Click for larger image&quot; href=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=medium&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g002&quot; data-doi=&quot;info:doi/10.1371/journal.pcbi.1005268&quot; data-uri=&quot;info:doi/10.1371/journal.pcbi.1005268.g002&quot;&gt;&lt;img src=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=inline&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g002&quot; alt=&quot;thumbnail&quot; class=&quot;thumbnail&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;p&gt;&lt;span&gt;Fig 2.&lt;/span&gt; Optical reconstruction of the microprocessor to obtain its connectome.&lt;/p&gt;

&lt;p&gt;In [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref011&quot; class=&quot;ref-tip&quot;&gt;11&lt;/a&gt;], the (&lt;strong&gt;A&lt;/strong&gt;) MOS 6502 silicon die was examined under a visible light microscope (&lt;strong&gt;B&lt;/strong&gt;) to build up an image mosaic (&lt;strong&gt;C&lt;/strong&gt;) of the chip surface. Computer vision algorithms were used to identify metal and silicon regions (&lt;strong&gt;E&lt;/strong&gt;) to detect transistors (&lt;strong&gt;F&lt;/strong&gt;), (&lt;strong&gt;G&lt;/strong&gt;) ultimately producing a complete accurate netlist of the processor (&lt;strong&gt;D&lt;/strong&gt;).&lt;/p&gt;
&lt;p class=&quot;caption_object&quot;&gt;&lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1005268.g002&quot;&gt;https://doi.org/10.1371/journal.pcbi.1005268.g002&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section1&quot; class=&quot;section toc-section&quot; readability=&quot;64.89480032163&quot;&gt;
&lt;h3&gt;Connectomics&lt;/h3&gt;

&lt;p&gt;The earliest investigations of neural systems were in-depth anatomical inquiries [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref029&quot; class=&quot;ref-tip&quot;&gt;29&lt;/a&gt;]. Fortunately, through large scale microscopy (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g002&quot;&gt;Fig 2a&lt;/a&gt;) we have available the full 3d connectome of the system. In other words, we know how each transistor is connected to all the others. The reconstruction is so good, that we can now simulate this processor perfectly—indeed, were it not for the presence of the processor’s connectome, this paper would not have been possible. This process is aided by the fact that we know a transistor’s deterministic input-output function, whereas neurons are both stochastic and vastly more complex.&lt;/p&gt;

&lt;p&gt;Recently several graph analysis methods ranging from classic [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref030&quot; class=&quot;ref-tip&quot;&gt;30&lt;/a&gt;] to modern [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref031&quot; class=&quot;ref-tip&quot;&gt;31&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref032&quot; class=&quot;ref-tip&quot;&gt;32&lt;/a&gt;] approaches have been applied to neural connectomes. The approach in [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref031&quot; class=&quot;ref-tip&quot;&gt;31&lt;/a&gt;] was also applied to a region of this processor, attempting to identify both circuit motifs as well as transistor “types” (analogous to cell types) in the transistor wiring diagram. &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g003&quot;&gt;Fig 3&lt;/a&gt; (adapted from [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref031&quot; class=&quot;ref-tip&quot;&gt;31&lt;/a&gt;]) shows the results of the analysis. We see that one identified transistor type contains the “clocked” transistors, which retain digital state. Two other types contain transistors with pins C1 or C2 connected to ground, mostly serving as inverters. An additional identified type controls the behavior of the three registers of interest (X, Y, and S) with respect to the SB data bus, either allowing them to latch or drive data from the bus. The repeat patterns of spatial connectivity are visible in &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g003&quot;&gt;Fig 3a&lt;/a&gt;, showing the man-made horizontal and vertical layout of the same types of transistors.&lt;/p&gt;

&lt;div class=&quot;figure&quot; data-doi=&quot;10.1371/journal.pcbi.1005268.g003&quot; readability=&quot;15.043062200957&quot;&gt;
&lt;div class=&quot;img-box&quot;&gt;&lt;a title=&quot;Click for larger image&quot; href=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=medium&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g003&quot; data-doi=&quot;info:doi/10.1371/journal.pcbi.1005268&quot; data-uri=&quot;info:doi/10.1371/journal.pcbi.1005268.g003&quot;&gt;&lt;img src=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=inline&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g003&quot; alt=&quot;thumbnail&quot; class=&quot;thumbnail&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;p&gt;&lt;span&gt;Fig 3.&lt;/span&gt; Discovering connectivity and cell type.&lt;/p&gt;

&lt;p&gt;Reproduced from [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref031&quot; class=&quot;ref-tip&quot;&gt;31&lt;/a&gt;]. (&lt;strong&gt;A&lt;/strong&gt;) The spatial distribution of the transistors in each cluster show a clear pattern (&lt;strong&gt;B&lt;/strong&gt;) The clusters and connectivity versus distance for connections between Gate and C1, Gate and C2, and C1 and C2 terminals on a transistor. Purple and yellow types have a terminal pulled down to ground and mostly function as inverters. The blue types are clocked, stateful transistors, green control the ALU and orange control the special data bus (SDB).&lt;/p&gt;
&lt;p class=&quot;caption_object&quot;&gt;&lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1005268.g003&quot;&gt;https://doi.org/10.1371/journal.pcbi.1005268.g003&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;While superficially impressive, based on the results of these algorithms we still can not get anywhere near an understanding of the way the processor really works. Indeed, we know that for this processor there is only one physical “type” of transistor, and that the structure we recover is a complex combination of local and global circuitry.&lt;/p&gt;

&lt;p&gt;In neuroscience, reconstructing all neurons and their connections perfectly is the dream of a large community studying connectomics [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref033&quot; class=&quot;ref-tip&quot;&gt;33&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref034&quot; class=&quot;ref-tip&quot;&gt;34&lt;/a&gt;]. Current connectomics approaches are limited in their accuracy and ability to definitively identify synapses [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref013&quot; class=&quot;ref-tip&quot;&gt;13&lt;/a&gt;], Unfortunately, we do not yet have the techniques to also reconstruct the i/o function–neurotransmitter type, ion channel type, I/V curve of each synapse, etc.—of each neuron. But even if we did, just as in the case of the processor, we would face the problem of understanding the brain based on its connectome. As we do not have algorithms that go from anatomy to function at the moment that go considerably beyond cell-type clustering [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref031&quot; class=&quot;ref-tip&quot;&gt;31&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref035&quot; class=&quot;ref-tip&quot;&gt;35&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref036&quot; class=&quot;ref-tip&quot;&gt;36&lt;/a&gt;] it is far from obvious how a connectome would allow an understanding of the brain.&lt;/p&gt;

&lt;p&gt;Note we are not suggesting connectomics is useless, quite the contrary–in the case of the processor the connectome was the first crucial step in enabling reliable, whole-brain-scale simulation. But even with the whole-brain connectome, extracting hierarchical organization and understanding the nature of the underlying computation is incredibly difficult.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section2&quot; class=&quot;section toc-section&quot; readability=&quot;53.893159108378&quot;&gt;
&lt;h3&gt;Lesion a single transistor at a time&lt;/h3&gt;

&lt;p&gt;Lesions studies allow us to study the causal effect of removing a part of the system. We thus chose a number of transistors and asked if they are necessary for each of the behaviors of the processor (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g004&quot;&gt;Fig 4&lt;/a&gt;. In other words, we asked if removed each transistor, if the processor would then still boot the game. Indeed, we found a subset of transistors that makes one of the behaviors (games) impossible. We can thus conclude they are uniquely necessary for the game—perhaps there is a Donkey Kong transistor or a Space Invaders transistor. Even if we can lesion each individual transistor, we do not get much closer to an understanding of how the processor really works.&lt;/p&gt;

&lt;div class=&quot;figure&quot; data-doi=&quot;10.1371/journal.pcbi.1005268.g004&quot; readability=&quot;13.346469622332&quot;&gt;
&lt;div class=&quot;img-box&quot;&gt;&lt;a title=&quot;Click for larger image&quot; href=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=medium&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g004&quot; data-doi=&quot;info:doi/10.1371/journal.pcbi.1005268&quot; data-uri=&quot;info:doi/10.1371/journal.pcbi.1005268.g004&quot;&gt;&lt;img src=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=inline&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g004&quot; alt=&quot;thumbnail&quot; class=&quot;thumbnail&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;p&gt;&lt;span&gt;Fig 4.&lt;/span&gt; Lesioning every single transistor to identify function.&lt;/p&gt;

&lt;p&gt;We identify transistors whose elimination disrupts behavior analogous to lethal alleles or lesioned brain areas. These are transistors whose elimination results in the processor failing to render the game. (&lt;strong&gt;A&lt;/strong&gt;) Transistors which impact only one behavior, colored by behavior. (&lt;strong&gt;B&lt;/strong&gt;) Breakdown of the impact of transistor lesion by behavioral state. The elimination of 1565 transistors have no impact, and 1560 inhibit all behaviors.&lt;/p&gt;
&lt;p class=&quot;caption_object&quot;&gt;&lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1005268.g004&quot;&gt;https://doi.org/10.1371/journal.pcbi.1005268.g004&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;This finding of course is grossly misleading. The transistors are not specific to any one behavior or game but rather implement simple functions, like full adders. The finding that some of them are important while others are not for a given game is only indirectly indicative of the transistor’s role and is unlikely to generalize to other games. Lazebnik [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref009&quot; class=&quot;ref-tip&quot;&gt;9&lt;/a&gt;] made similar observations about this approach in molecular biology, suggesting biologists would obtain a large number of identical radios and shoot them with metal particles at short range, attempting to identify which damaged components gave rise to which broken phenotype.&lt;/p&gt;

&lt;p&gt;This example nicely highlights the importance of isolating individual behaviors to understand the contribution of parts to the overall function. If we had been able to isolate a single function, maybe by having the processor produce the same math operation every single step, then the lesioning experiments could have produced more meaningful results. However, the same problem exists in neuroscience. It is extremely difficult or technically impossible to produce behaviors that only require a single aspect of the brain.&lt;/p&gt;

&lt;p&gt;Beyond behavioral choices, we have equivalent problems in neuroscience that make the interpretation of lesioning data complicated [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref037&quot; class=&quot;ref-tip&quot;&gt;37&lt;/a&gt;]. In many ways the chip can be lesioned in a cleaner way than the brain: we can individually abolish every single transistor (this is only now becoming possible with neurons in simple systems [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref038&quot; class=&quot;ref-tip&quot;&gt;38&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref039&quot; class=&quot;ref-tip&quot;&gt;39&lt;/a&gt;]). Even without this problem, finding that a lesion in a given area abolishes a function is hard to interpret in terms of the role of the area for general computation. And this ignores the tremendous plasticity in neural systems which can allow regions to take over for damaged areas. In addition to the statistical problems that arise from multiple hypothesis testing, it is obvious that the “causal relationship” we are learning is incredibly superficial: a given transistor is obviously not specialized for Donkey Kong or Space Invaders.&lt;/p&gt;

&lt;p&gt;While in most organisms individual transistors are not vital, for many less-complex systems they are. Lesion individual interneurons in &lt;em&gt;C. elegans&lt;/em&gt; or the H1 neuron in the fly can have marked behavioral impacts. And while lesioning larger pieces of circuitry, such as the entire TIA graphics chip, might allow for gross segregation of function, we take issue with this constituting “understanding”. Simply knowing functional localization, at any spatial scale, is only the most nacent step to the sorts of understanding we have outlined above.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section3&quot; class=&quot;section toc-section&quot; readability=&quot;32.029379760609&quot;&gt;
&lt;h3&gt;Analyzing tuning properties of individual transistors&lt;/h3&gt;

&lt;p&gt;We may want to try to understand the processor by understanding the activity of each individual transistor. We study the “off-to-on” transition, or “spike”, produced by each individual transistor. Each transistor will be activated at multiple points in time. Indeed, these transitions look surprisingly similar to the spike trains of neurons (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g005&quot;&gt;Fig 5&lt;/a&gt;). Following the standards in neuroscience we may then quantify the tuning selectivity of each transistor. For each of our transistors we can plot the spike rate as a function of the luminance of the most recently displayed pixel (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g006&quot;&gt;Fig 6&lt;/a&gt;). For a small number of transistors we find a strong tuning to the luminance of the most recently displayed pixel, which we can classify into simple (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g006&quot;&gt;Fig 6a&lt;/a&gt;) and (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g006&quot;&gt;Fig 6b&lt;/a&gt;) complex curves. Interestingly, however, we know for each of the five displayed transistors that they are not directly related to the luminance of the pixel to be written, despite their strong tuning. The transistors relate in a highly nonlinear way to the ultimate brightness of the screen. As such their apparent tuning is not really insightful about their role. In our case, it probably is related to differences across game stages. In the brain a neuron can calculate something, or be upstream or downstream of the calculation and still show apparent tuning making the inference of a neurons role from observational data very difficult [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref040&quot; class=&quot;ref-tip&quot;&gt;40&lt;/a&gt;]. This shows how obtaining an understanding of the processor from tuning curves is difficult.&lt;/p&gt;



&lt;div class=&quot;figure&quot; data-doi=&quot;10.1371/journal.pcbi.1005268.g006&quot; readability=&quot;8.6794520547945&quot;&gt;
&lt;div class=&quot;img-box&quot;&gt;&lt;a title=&quot;Click for larger image&quot; href=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=medium&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g006&quot; data-doi=&quot;info:doi/10.1371/journal.pcbi.1005268&quot; data-uri=&quot;info:doi/10.1371/journal.pcbi.1005268.g006&quot;&gt;&lt;img src=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=inline&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g006&quot; alt=&quot;thumbnail&quot; class=&quot;thumbnail&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;p&gt;&lt;span&gt;Fig 6.&lt;/span&gt; Quantifying tuning curves to understand function.&lt;/p&gt;

&lt;p&gt;Mean transistor response as a function of output pixel luminance. (&lt;strong&gt;A&lt;/strong&gt;) Some transistors exhibit simple unimodal tuning curves. (&lt;strong&gt;B&lt;/strong&gt;) More complex tuning curves. (&lt;strong&gt;C&lt;/strong&gt;) Transistor location on chip.&lt;/p&gt;
&lt;p class=&quot;caption_object&quot;&gt;&lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1005268.g006&quot;&gt;https://doi.org/10.1371/journal.pcbi.1005268.g006&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Much of neuroscience is focused on understanding tuning properties of neurons, circuits, and brain areas [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref041&quot; class=&quot;ref-tip&quot;&gt;41&lt;/a&gt;–&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref044&quot; class=&quot;ref-tip&quot;&gt;44&lt;/a&gt;]. Arguably this approach is more justified for the nervous system because brain areas are more strongly modular. However, this may well be an illusion and many studies that have looked carefully at brain areas have revealed a dazzling heterogeneity of responses [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref045&quot; class=&quot;ref-tip&quot;&gt;45&lt;/a&gt;–&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref047&quot; class=&quot;ref-tip&quot;&gt;47&lt;/a&gt;]. Even if brain areas are grouped by function, examining the individual units within may not allow for conclusive insight into the nature of computation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section4&quot; class=&quot;section toc-section&quot; readability=&quot;24.515044814341&quot;&gt;
&lt;h3&gt;The correlational structure exhibits weak pairwise and strong global correlations&lt;/h3&gt;

&lt;p&gt;Moving beyond correlating single units with behavior, we can examine the correlations present between individual transistors. We thus perform a spike-word analysis [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref048&quot; class=&quot;ref-tip&quot;&gt;48&lt;/a&gt;] by looking at “spike words” across 64 transistors in the processor. We find little to very weak correlation among most pairs of transistors (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g007&quot;&gt;Fig 7a&lt;/a&gt;). This weak correlation suggests modeling the transistors’ activities as independent, but as we see from shuffle analysis (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g007&quot;&gt;Fig 7b&lt;/a&gt;), this assumption fails disastrously at predicting correlations across many transistors.&lt;/p&gt;

&lt;div class=&quot;figure&quot; data-doi=&quot;10.1371/journal.pcbi.1005268.g007&quot; readability=&quot;12.384787472036&quot;&gt;
&lt;div class=&quot;img-box&quot;&gt;&lt;a title=&quot;Click for larger image&quot; href=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=medium&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g007&quot; data-doi=&quot;info:doi/10.1371/journal.pcbi.1005268&quot; data-uri=&quot;info:doi/10.1371/journal.pcbi.1005268.g007&quot;&gt;&lt;img src=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=inline&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g007&quot; alt=&quot;thumbnail&quot; class=&quot;thumbnail&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;p&gt;&lt;span&gt;Fig 7.&lt;/span&gt; Spike-word analysis to understand synchronous states.&lt;/p&gt;

&lt;p&gt;(&lt;strong&gt;A&lt;/strong&gt;) Pairs of transistors show very weak pairwise correlations during behavior SI, suggesting independence. (&lt;strong&gt;B&lt;/strong&gt;) If transistors were independent, shuffling transistor labels (blue) would have no impact on the distribution of spikes per word, which is not the case (red).&lt;/p&gt;
&lt;p class=&quot;caption_object&quot;&gt;&lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1005268.g007&quot;&gt;https://doi.org/10.1371/journal.pcbi.1005268.g007&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;In neuroscience, it is known that pairwise correlations in neural systems can be incredibly weak, while still reflecting strong underlying coordinated activity. This is often assumed to lead to insights into the nature of interactions between neurons [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref048&quot; class=&quot;ref-tip&quot;&gt;48&lt;/a&gt;]. However, the processor has a very simple nature of interactions and yet produces remarkably similar spike word statistics. This again highlights how hard it is to derive functional insights from activity data using standard measures.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section5&quot; class=&quot;section toc-section&quot; readability=&quot;36.968523002421&quot;&gt;
&lt;h3&gt;Analyzing local field potentials&lt;/h3&gt;

&lt;p&gt;The activity of the entire chip may be high dimensional, yet we know that the chip, just like the brain, has some functional modularity. As such, we may be able to understand aspects of its function by analyzing the average activity within localized regions, in a way analogous to the local field potentials or the BOLD signals from functional magnetic imaging that are used in neuroscience. We thus analyzed data in spatially localized areas (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g008&quot;&gt;Fig 8a&lt;/a&gt;). Interestingly, these average activities look quite a bit like real brain signals (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g008&quot;&gt;Fig 8b&lt;/a&gt;). Indeed, they show a rather similar frequency power relation of roughly power-law behavior. This is often seen as a strong sign of self-organized criticality [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref049&quot; class=&quot;ref-tip&quot;&gt;49&lt;/a&gt;]. Spectral analysis of the time-series reveals region-specific oscillations or “rhythms” that have been suggested to provide a clue to both local computation and overall inter-region communication. In the chip we know that while the oscillations may reflect underlying periodicity of activity, the specific frequencies and locations are epiphenomena. They arise as an artifact of the computation and tell us little about the underlying flow of information. And it is very hard to attribute (self-organized) criticality to the processor.&lt;/p&gt;

&lt;div class=&quot;figure&quot; data-doi=&quot;10.1371/journal.pcbi.1005268.g008&quot; readability=&quot;11.23828125&quot;&gt;
&lt;div class=&quot;img-box&quot;&gt;&lt;a title=&quot;Click for larger image&quot; href=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=medium&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g008&quot; data-doi=&quot;info:doi/10.1371/journal.pcbi.1005268&quot; data-uri=&quot;info:doi/10.1371/journal.pcbi.1005268.g008&quot;&gt;&lt;img src=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=inline&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g008&quot; alt=&quot;thumbnail&quot; class=&quot;thumbnail&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;p&gt;&lt;span&gt;Fig 8.&lt;/span&gt; Examining local field potentials to understand network properties.&lt;/p&gt;

&lt;p&gt;We recorded from the processor during behavior DK. (&lt;strong&gt;A&lt;/strong&gt;) Transistor switching is integrated and low-pass filtered over the indicated region. (&lt;strong&gt;B&lt;/strong&gt;) local-field potential measurements from the indicated areas. (&lt;strong&gt;C&lt;/strong&gt;) Spectral analysis of the indicated LFP regions identifies varying region-specific oscillations or “rhythms”.&lt;/p&gt;
&lt;p class=&quot;caption_object&quot;&gt;&lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1005268.g008&quot;&gt;https://doi.org/10.1371/journal.pcbi.1005268.g008&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;In neuroscience there is a rich tradition of analyzing the rhythms in brain regions, the distribution of power across frequencies as a function of the task, and the relation of oscillatory activity across space and time. However, the example of the processor shows that the relation of such measures to underlying function can be extremely complicated. In fact, the authors of this paper would have expected far more peaked frequency distributions for the chip. Moreover, the distribution of frequencies in the brain is often seen as indicative about the underlying biophysics. In our case, there is only one element, the transistor, and not multiple neurotransmitters. And yet, we see a similarly rich distribution of power in the frequency domain. This shows that complex multi-frequency behavior can emerge from the combination of many simple elements. Analyzing the frequency spectra of artifacts thus leads us to be careful about the interpretation of those occurring in the brain. Modeling the processor as a bunch of coupled oscillators, as is common in neuroscience, would make little sense.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section6&quot; class=&quot;section toc-section&quot; readability=&quot;36.48997926745&quot;&gt;
&lt;h3&gt;Granger causality to describe functional connectivity&lt;/h3&gt;

&lt;p&gt;Granger causality [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref050&quot; class=&quot;ref-tip&quot;&gt;50&lt;/a&gt;] has emerged as a method of assessing putative causal relationships between brain regions based on LFP data. Granger causality assesses the relationship between two timeseries &lt;em&gt;X&lt;/em&gt; and &lt;em&gt;Y&lt;/em&gt; by comparing the predictive power of two different time-series models to predict future values of &lt;em&gt;Y&lt;/em&gt;. The first model uses only past values of &lt;em&gt;Y&lt;/em&gt;, whereas the second uses the history of &lt;em&gt;X&lt;/em&gt; and &lt;em&gt;Y&lt;/em&gt;. The additon of &lt;em&gt;X&lt;/em&gt; allows one to assess the putative “causality” (really, the predictive power) of &lt;em&gt;X&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;To see if we can understand information transmission pathways in the chip based on such techniques, we perform conditional Granger causality analysis on the above-indicated LFP regions for all three behavioral tasks, and plot the resulting inferences of causal interactions (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g009&quot;&gt;Fig 9&lt;/a&gt;). We find that the decoders affect the status bits. We also find that the registers are affected by the decoder, and that the accumulator is affected by the registers. We also find communication between the two parts of the decoder for Donkey Kong, and a lack of communication from the accumulator to the registers in Pitfall. Some of these findings are true, registers really affect the accumulator and decoders really affect the status bits. Other insights are less true, e.g. decoding is independent and the accumulator obviously affects the registers. While some high level insights may be possible, the insight into the actual function of the processor is limited.&lt;/p&gt;

&lt;div class=&quot;figure&quot; data-doi=&quot;10.1371/journal.pcbi.1005268.g009&quot; readability=&quot;12.401960784314&quot;&gt;
&lt;div class=&quot;img-box&quot;&gt;&lt;a title=&quot;Click for larger image&quot; href=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=medium&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g009&quot; data-doi=&quot;info:doi/10.1371/journal.pcbi.1005268&quot; data-uri=&quot;info:doi/10.1371/journal.pcbi.1005268.g009&quot;&gt;&lt;img src=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=inline&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g009&quot; alt=&quot;thumbnail&quot; class=&quot;thumbnail&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;p&gt;&lt;span&gt;Fig 9.&lt;/span&gt; Analyzing conditional Granger causality to understand functional connectivity.&lt;/p&gt;

&lt;p&gt;Each of the recordings come from a well defined functional subcircuit. Green and blue are two parts of the decoder circuit. Red includes the status bits. Violet are part of the registers and yellow includes parts of the accumulator. We estimated for each behavioral state from LFP sites indicated in &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g008&quot;&gt;Fig 8&lt;/a&gt;. Arrows indicate direction of Granger-causal relationship, arrow thickness indicates effect magnitude.&lt;/p&gt;
&lt;p class=&quot;caption_object&quot;&gt;&lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1005268.g009&quot;&gt;https://doi.org/10.1371/journal.pcbi.1005268.g009&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;The analysis that we did is very similar to the situation in neuroscience. In neuroscience as well, the signals come from a number of local sources. Moreover, there are also lots of connections but we hope that the methods will inform us about the relevant ones. It is hard to interpret the results—what exactly does the Granger causality model tell us about. Granger causality tells us how activity in the past are predictive of activity in the future, and the link from there to causal interactions is tentative at best [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref051&quot; class=&quot;ref-tip&quot;&gt;51&lt;/a&gt;] and yet such methods are extensively used across large subfields of neuroscience. Even if such methods would reliably tell us about large scale influences, it is very hard to get from a coarse resolution network to the microscopic computations.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section7&quot; class=&quot;section toc-section&quot; readability=&quot;69.757701315078&quot;&gt;
&lt;h3&gt;Dimensionality reduction reveals global dynamics independent of behavior&lt;/h3&gt;

&lt;p&gt;In line with recent advances in whole-animal recordings [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref002&quot; class=&quot;ref-tip&quot;&gt;2&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref006&quot; class=&quot;ref-tip&quot;&gt;6&lt;/a&gt;–&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref008&quot; class=&quot;ref-tip&quot;&gt;8&lt;/a&gt;], we measure the activity across all 3510 transistors simultaneously for all three behavioral states (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g010&quot;&gt;Fig 10&lt;/a&gt;) and plot normalized activity for each transistor versus time. Much as in neural systems, some transistors are relatively quiet and some are quite active, with a clear behaviorally-specific periodicity visible in overall activity.&lt;/p&gt;

&lt;div class=&quot;figure&quot; data-doi=&quot;10.1371/journal.pcbi.1005268.g010&quot; readability=&quot;8.3161094224924&quot;&gt;
&lt;div class=&quot;img-box&quot;&gt;&lt;a title=&quot;Click for larger image&quot; href=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=medium&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g010&quot; data-doi=&quot;info:doi/10.1371/journal.pcbi.1005268&quot; data-uri=&quot;info:doi/10.1371/journal.pcbi.1005268.g010&quot;&gt;&lt;img src=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=inline&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g010&quot; alt=&quot;thumbnail&quot; class=&quot;thumbnail&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;p&gt;&lt;span&gt;Fig 10.&lt;/span&gt; The processor activity map.&lt;/p&gt;

&lt;p&gt;For each of three behavioral states we plotted all the activities. Each transistor’s activity is normalized to zero-mean and unit variance and plotted as a function of time.&lt;/p&gt;
&lt;p class=&quot;caption_object&quot;&gt;&lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1005268.g010&quot;&gt;https://doi.org/10.1371/journal.pcbi.1005268.g010&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;While whole-brain recording may facilitate identification of putative areas involved in particular behaviors [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref052&quot; class=&quot;ref-tip&quot;&gt;52&lt;/a&gt;], ultimately the spike-level activity at this scale is difficult to interpret. Thus scientists turn to dimensionality reduction techniques [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref002&quot; class=&quot;ref-tip&quot;&gt;2&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref053&quot; class=&quot;ref-tip&quot;&gt;53&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref054&quot; class=&quot;ref-tip&quot;&gt;54&lt;/a&gt;], which seek to explain high-dimensional data in terms of a low-dimensional representation of state. We use non-negative matrix factorization [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref055&quot; class=&quot;ref-tip&quot;&gt;55&lt;/a&gt;] to identify constituent signal parts across all time-varying transistor activity. We are thus, for the first time in the paper, taking advantage of all transistors simultaneously.&lt;/p&gt;

&lt;p&gt;Non-negative matrix factorization assumes each recovered timeseries of transistor activity is a linear combination of a small number of underlying nonnegative time-varying signals (dimensions). Analogous with [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref002&quot; class=&quot;ref-tip&quot;&gt;2&lt;/a&gt;] we plot the recovered dimensions as a function of time (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g011&quot;&gt;Fig 11a&lt;/a&gt;) and the transistor activity profile of each component (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g011&quot;&gt;Fig 11b&lt;/a&gt;). We can also examine a map of transistor-component activity both statically (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g011&quot;&gt;Fig 11c&lt;/a&gt;) and dynamically (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.s001&quot;&gt;S1&lt;/a&gt;–&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.s003&quot;&gt;S3&lt;/a&gt; Videos available in online supplementary materials). Clearly there is a lot of structure in this spatiotemporal dataset.&lt;/p&gt;

&lt;div class=&quot;figure&quot; data-doi=&quot;10.1371/journal.pcbi.1005268.g011&quot; readability=&quot;12.466555183946&quot;&gt;
&lt;div class=&quot;img-box&quot;&gt;&lt;a title=&quot;Click for larger image&quot; href=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=medium&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g011&quot; data-doi=&quot;info:doi/10.1371/journal.pcbi.1005268&quot; data-uri=&quot;info:doi/10.1371/journal.pcbi.1005268.g011&quot;&gt;&lt;img src=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=inline&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g011&quot; alt=&quot;thumbnail&quot; class=&quot;thumbnail&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;p&gt;&lt;span&gt;Fig 11.&lt;/span&gt; Dimensionality Reduction to understand the roles of transistors.&lt;/p&gt;

&lt;p&gt;We apply non-negative matrix factorization (NMF) to the space invaders (SI) task. (&lt;strong&gt;A&lt;/strong&gt;) shows the six reduced dimensions as a function of time showing clear stereotyped activity. (&lt;strong&gt;B&lt;/strong&gt;) the learned transistor state vectors for each dimension (&lt;strong&gt;C&lt;/strong&gt;) Map of total activity—color indicates the dimension where the transistor has maximum value, and both saturation and point size indicate the magnitude of that value.&lt;/p&gt;
&lt;p class=&quot;caption_object&quot;&gt;&lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1005268.g011&quot;&gt;https://doi.org/10.1371/journal.pcbi.1005268.g011&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;To derive insight into recovered dimensions, we can try and relate parts of the low-dimensional time series to known signals or variables we know are important (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g012&quot;&gt;Fig 12a&lt;/a&gt;). Indeed, we find that some components relate to both the onset and offset (rise and fall) of the clock signal(&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g012&quot;&gt;Fig 12b and 12c&lt;/a&gt;). This is quite interesting as we know that the processor uses a two-phase clock. We also find that a component relates strongly to the processors read-write signal (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g012&quot;&gt;Fig 12d&lt;/a&gt;). Thus, we find that variables of interest are indeed encoded by the population activity in the processor.&lt;/p&gt;

&lt;div class=&quot;figure&quot; data-doi=&quot;10.1371/journal.pcbi.1005268.g012&quot; readability=&quot;13.635359116022&quot;&gt;
&lt;div class=&quot;img-box&quot;&gt;&lt;a title=&quot;Click for larger image&quot; href=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=medium&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g012&quot; data-doi=&quot;info:doi/10.1371/journal.pcbi.1005268&quot; data-uri=&quot;info:doi/10.1371/journal.pcbi.1005268.g012&quot;&gt;&lt;img src=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=inline&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g012&quot; alt=&quot;thumbnail&quot; class=&quot;thumbnail&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;p&gt;&lt;span&gt;Fig 12.&lt;/span&gt; Relating dimensions to known signals to understanding the population code.&lt;/p&gt;

&lt;p&gt;(&lt;strong&gt;A&lt;/strong&gt;) For each of the recovered dimensions in &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g011&quot;&gt;Fig 11&lt;/a&gt; we compute the correlation in time with 25 known signals inside the process. As we know the purpose of these signals we can measure how well the dimensions explain true underlying function. (&lt;strong&gt;B&lt;/strong&gt;) Dimension 1 is strongly correlated with the processor clock CLK0, whereas (&lt;strong&gt;C&lt;/strong&gt;) dimension 4 is correlated with the 180-degree out of phase CLK1OUT signal. (&lt;strong&gt;D&lt;/strong&gt;) dimension 0 is strongly correlated with signal RW, indicating the processor switching between reading and writing memory.&lt;/p&gt;
&lt;p class=&quot;caption_object&quot;&gt;&lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1005268.g012&quot;&gt;https://doi.org/10.1371/journal.pcbi.1005268.g012&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;In neuroscience, it is also frequently found that components from dimensionality reduction relate to variables of interest [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref056&quot; class=&quot;ref-tip&quot;&gt;56&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref057&quot; class=&quot;ref-tip&quot;&gt;57&lt;/a&gt;]. This is usually then seen as an indication that the brain cares about these variables. However, clearly, the link to the read-write signal and the clock does not lead to an overly important insight into the way the processor actually processes information. Similar questions arise in neuroscience where scientists ask if signals, such as synchrony, are a central part of information processing or if they are an irrelevant byproduct [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref058&quot; class=&quot;ref-tip&quot;&gt;58&lt;/a&gt;]. We should be careful at evaluating how much we understand and how much we are aided by more data.&lt;/p&gt;

&lt;p&gt;Pondering the results of the processor analysis we can obtain some insights into the developments needed to better utilize dimensionality reduction towards an understanding. The narrow range of games that we considered and the narrow range of their internal states (we just simulated booting), means that many aspects of computation will not be reflected by the activities and hence not in the dimensionality reduction results. Moreover, the fact that we used linear reduction only allows for linear dependencies and transistors, just like neurons, have important nonlinear dependencies. Lastly, there is clearly a hierarchy in function in the processor and we would need to do it justice using hierarchical analysis approaches. The results of dimensionality reduction should be meaningful for guiding new experiments, necessitating transfer across chips in the same way as neuroscience experiments should transfer across animals. Importantly, the chip can work as a test case while we develop such methods.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;section3&quot; class=&quot;section toc-section&quot; readability=&quot;130.52410044256&quot;&gt;
&lt;h2&gt;Discussion&lt;/h2&gt;

&lt;p&gt;Here we have taken a reconstructed and simulated processor and treated the data “recorded” from it in the same way we have been trained to analyze brain data. We have used it as a test case to check the naïve use of various approaches used in neuroscience. We have found that the standard data analysis techniques produce results that are surprisingly similar to the results found about real brains. However, in the case of the processor we know its function and structure and our results stayed well short of what we would call a satisfying understanding.&lt;/p&gt;

&lt;p&gt;Obviously the brain is not a processor, and a tremendous amount of effort and time have been spent characterizing these differences over the past century [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref022&quot; class=&quot;ref-tip&quot;&gt;22&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref023&quot; class=&quot;ref-tip&quot;&gt;23&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref059&quot; class=&quot;ref-tip&quot;&gt;59&lt;/a&gt;]. Neural systems are analog and and biophysically complex, they operate at temporal scales vastly slower than this classical processor but with far greater parallelism than is available in state of the art processors. Typical neurons also have several orders of magnitude more inputs than a transistor. Moreover, the design process for the brain (evolution) is dramatically different from that of the processor (the MOS6502 was designed by a small team of people over a few years). As such, we should be skeptical about generalizing from processors to the brain.&lt;/p&gt;

&lt;p&gt;However, we cannot write off the failure of the methods we used on the processor simply because processors are different from neural systems. After all, the brain also consists of a large number of modules that can equally switch their input and output properties. It also has prominent oscillations, which may act as clock signals as well [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref060&quot; class=&quot;ref-tip&quot;&gt;60&lt;/a&gt;]. Similarly, a small number of relevant connections can produce drivers that are more important than those of the bulk of the activity. Also, the localization of function that is often assumed to simplify models of the brain is only a very rough approximation. This is true even in an area like V1 where a great diversity of co-localized cells can be found [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref061&quot; class=&quot;ref-tip&quot;&gt;61&lt;/a&gt;]. Altogether, there seems to be little reason to assume that any of the methods we used should be more meaningful on brains than on the processor.&lt;/p&gt;

&lt;p&gt;To analyze our simulations we needed to convert the binary transistor state of the processor into spike trains so that we could apply methods from neuroscience to (see &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#sec014&quot;&gt;Methods&lt;/a&gt;). While this may be artefactual, we want to remind the reader that in neuroscience the idea of an action potential is also only an approximate description of the effects of a cell’s activity. For example, there are known effects based on the extrasynaptic diffusion of neurotransmitters [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref062&quot; class=&quot;ref-tip&quot;&gt;62&lt;/a&gt;] and it is believed that active conductances in dendrites may be crucial to computation [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref063&quot; class=&quot;ref-tip&quot;&gt;63&lt;/a&gt;].&lt;/p&gt;

&lt;p&gt;Our behavioral mechanisms are entirely passive as both the transistor based simulator is too slow to play the game for any reasonable duration and the hardware for game input/output has yet to be reconstructed. Even if we could “play” the game, the dimensionality of the input space would consist at best of a few digital switches and a simple joystick. One is reminded of the reaching tasks which dominate a large fraction of movement research. Tasks that isolate one kind of computation would be needed so that interference studies would be really interpretable.&lt;/p&gt;

&lt;p&gt;If we had a way of hypothesizing the right structure, then it would be reasonably easy to test. Indeed, there are a number of large scale theories of the brain [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref005&quot; class=&quot;ref-tip&quot;&gt;5&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref064&quot; class=&quot;ref-tip&quot;&gt;64&lt;/a&gt;, &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref065&quot; class=&quot;ref-tip&quot;&gt;65&lt;/a&gt;]. However, the set of potential models of the brain is unbelievably large. Our data about the brain from all the experiments so far, is very limited and based on the techniques that we reviewed above. As such, it would be quite impressive if any of these high level models would actually match the human brain to a reasonable degree. Still, they provide beautiful inspiration for a lot of ongoing neuroscience research and are starting to exhibit some human-like behaviors [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref064&quot; class=&quot;ref-tip&quot;&gt;64&lt;/a&gt;]. If the brain is actually simple, then a human can guess a model, and through hypothesis generation and falsification we may eventually obtain that model. If the brain is not actually simple, then this approach may not ever converge. Simpler models might yield more insight—specifically seeking out an “adder” circuit might be possible, if we had a strong understanding of binary encoding and could tease apart the system to specifically control inputs and outputs of a subregion—examine it in slice, if you will.&lt;/p&gt;

&lt;p&gt;The analytic tools we have adopted are in many ways “classic”, and are taught to graduate students in neuroinformatics courses. Recent progress in methods for dimensionality reduction, subspace identification, time-series analysis, and tools for building rich probabilistic models may provide some additional insight, assuming the challenges of scale can be overcome. Culturally, applying these methods to real data, and rewarding those who innovate methodologically, may become more important. We can look at the rise of bioinformatics as an independent field with its own funding streams. Neuroscience needs strong neuroinformatics to make sense of the emerging datasets and known artificial systems can serve as a sanity check and a way of understanding failure modes.&lt;/p&gt;

&lt;p&gt;We also want to suggest that it may be an important intermediate step for neuroscience to develop methods that allow understanding a processor. Because they can be simulated in any computer and arbitrarily perturbed, they are a great testbed to ask how useful the methods are that we are using in neuroscience on a daily basis. Scientific fields often work well in situations where we can measure how well a project is doing. In the case of processors we know their function and we can know if our algorithms discover it. Unless our methods can deal with a simple processor, how could we expect it to work on our own brain? Machine learning and statistics currently lack good high-dimensional datasets with complex underlying dynamics and known ground truth. While not a perfect match, the dynamics of a processor may provide a compelling intermediate step. Additionally, most neural datasets are still “small data”—hundreds of cells over tens of minutes. The processor enables the generation of arbitrary complexity and arbitrarially-long timeseries, enabling a focus on &lt;em&gt;scalable&lt;/em&gt; algorithms. We must be careful to not over-fit, but neuroscience is rife with examples of adopting analytic tools from vary different domains (linear system theory, stochastic process theory, kalman filtering) to understand neural systems.&lt;/p&gt;

&lt;p&gt;In the case of the processor, we really understand how it works. We have a name for each of the modules on the chip and we know which area is covered by each of them (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g013&quot;&gt;Fig 13a&lt;/a&gt;). Moreover, for each of these modules we know how its outputs depend on its inputs and many students of electrical engineering would know multiple ways of implementing the same function. In the case of the brain, we also have a way of dividing it into regions (&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g013&quot;&gt;Fig 13b&lt;/a&gt;, adopted from [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref066&quot; class=&quot;ref-tip&quot;&gt;66&lt;/a&gt;]). However, we only use anatomy to divide into modules and even among specialists there is a lot of disagreement about the division. Most importantly though, we do not generally know how the output relates to the inputs. As we reviewed in this paper, we may even want to be careful about the conclusions about the modules that neuroscience has drawn so far, after all, much of our insights come from small datasets, with analysis methods that make questionable assumptions.&lt;/p&gt;

&lt;div class=&quot;figure&quot; data-doi=&quot;10.1371/journal.pcbi.1005268.g013&quot; readability=&quot;15.730722154223&quot;&gt;
&lt;div class=&quot;img-box&quot;&gt;&lt;a title=&quot;Click for larger image&quot; href=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=medium&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g013&quot; data-doi=&quot;info:doi/10.1371/journal.pcbi.1005268&quot; data-uri=&quot;info:doi/10.1371/journal.pcbi.1005268.g013&quot;&gt;&lt;img src=&quot;http://journals.plos.org/ploscompbiol/article/figure/image?size=inline&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.g013&quot; alt=&quot;thumbnail&quot; class=&quot;thumbnail&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;p&gt;&lt;span&gt;Fig 13.&lt;/span&gt; Understanding the processor.&lt;/p&gt;

&lt;p&gt;(&lt;strong&gt;A&lt;/strong&gt;) For the processor we understand its hierarchical organization as well as which part of the silicon implements which function. For each of these “functional modules” we know how the outputs depend on the inputs. (&lt;strong&gt;B&lt;/strong&gt;) For the brain, it is harder to be sure. The primate visual system is often depicted in a similar way, such as this diagram adapted from the classic Felleman and vanEssen [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref066&quot; class=&quot;ref-tip&quot;&gt;66&lt;/a&gt;] diagram. These areas are primarially divided according to anatomy, but there is extensive debate about the ideal way of dividing the brain into functional areas. Moreover, we currently have little of an understanding how each area’s outputs depend on its inputs.&lt;/p&gt;
&lt;p class=&quot;caption_object&quot;&gt;&lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1005268.g013&quot;&gt;https://doi.org/10.1371/journal.pcbi.1005268.g013&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;There are other computing systems that scientists are trying to reverse engineer. One particularly relevant one are artificial neural networks. A plethora of methods are being developed to ask how they work. This includes ways of letting the networks paint images [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref067&quot; class=&quot;ref-tip&quot;&gt;67&lt;/a&gt;] and ways of plotting the optimal stimuli for various areas [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref068&quot; class=&quot;ref-tip&quot;&gt;68&lt;/a&gt;]. While progress has been made on understanding the mechanisms and architecture for networks performing image classification, more complex systems are still completely opaque [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref069&quot; class=&quot;ref-tip&quot;&gt;69&lt;/a&gt;]. Thus a true understanding even for these comparatively simple, human-engineered systems remains elusive, and sometimes they can even surprise us by having truly surprising properties [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref070&quot; class=&quot;ref-tip&quot;&gt;70&lt;/a&gt;]. The brain is clearly far more complicated and our difficulty at understanding deep learning may suggest that the brain is hard to understand if it uses anything like gradient descent on a cost function.&lt;/p&gt;

&lt;p&gt;What kind of developments would make understanding the processor, and ultimately the brain, more tractable? While we can offer no definitive conclusion, we see multiple ways in which we could have better understood the processor. If we had experiments that would more cleanly separate one computation then results would be more meaningful. For example, lesion studies would be far more meaningful if we could also simultaneously control the exact code the processor was executing at a given moment. Better theories could most obviously have helped; if we had known that the microprocessor has adders we could have searched for them. Lastly, better data analysis methods, e.g. those that can explicitly search for hierarchical structure or utilize information across multiple processors. Development in these areas seems particularly promising. The microprocessor may help us by being a sieve for ideas: good ideas for understanding the brain should also help us understand the processor. Ultimately, the problem is not that neuroscientists could not understand a microprocessor, the problem is that they would not understand it given the approaches they are currently taking.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section4&quot; class=&quot;section toc-section&quot; readability=&quot;51.333692142088&quot;&gt;
&lt;h2&gt;Methods&lt;/h2&gt;
&lt;div id=&quot;section1&quot; class=&quot;section toc-section&quot; readability=&quot;13.958146487294&quot;&gt;
&lt;h3&gt;Netlist acquisition&lt;/h3&gt;

&lt;p&gt;All acquisition and development of the initial simulation was performed in James [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref011&quot; class=&quot;ref-tip&quot;&gt;11&lt;/a&gt;]. 200°F sulfuric acid was used to decap multiple 6502D ICs. Nikon LV150n and Nikon Optiphot 220 light microscopes were used to capture 72 tiled visible-light images of the die, resulting in 342 Mpix of data. Computational methods and human manual annotation used developed to reconstruct the metal, polysilicon, via, and interconnect layers. 3510 active enhancement-mode transistors were captured this way. The authors inferred 1018 depletion-mode transistors (serving as pullups) from the circuit topology as they were unable to capture the depletion mask layer.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section2&quot; class=&quot;section toc-section&quot; readability=&quot;14&quot;&gt;
&lt;h3&gt;Simulation and behaviors&lt;/h3&gt;

&lt;p&gt;An optimized C++ simulator was constructed to enable simulation at the rate of 1000 processor clock cycles per wallclock second. We evaluated the four provided ROMs (Donkey Kong, Space Invaders, Pitfall, and Asteroids) ultimately choosing the first three as they reliably drove the TIA and subsequently produced image frames. 10 seconds of behavior were simulated for each game, resulting in over 250 frames per game.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section3&quot; class=&quot;section toc-section&quot; readability=&quot;12.909722222222&quot;&gt;
&lt;h3&gt;Lesion studies&lt;/h3&gt;

&lt;p&gt;Whole-circuit simulation enables high-throughput targeted manipulation of the underlying circuit. We systematically perturb each transistor in the processor by forcing its input high, thus leaving it in an “on” state. We measure the impact of a lesion by whether or not the system advances far enough to draw the first frame of the game. Failure to produce the first frame constitutes as a loss of function. We identified 1560 transistors which resulted in loss of function across all games, 200 transistors which resulted in loss of function across two games, and 186 transistors which resulted in loss of function for a single game. We plot those single-behavior lesion transistors by game in &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g004&quot;&gt;Fig 4&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section4&quot; class=&quot;section toc-section&quot; readability=&quot;18.911832946636&quot;&gt;
&lt;h3&gt;Connectomic analysis&lt;/h3&gt;

&lt;p&gt;Using the acquired netlist, we implement the authors method from [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref031&quot; class=&quot;ref-tip&quot;&gt;31&lt;/a&gt;] on the region of the processor consisting of the X, Y, and S registers. A nonparametric distance-dependent stochastic block model is jointly fit to six connectivitiy matrices: &lt;em&gt;G&lt;/em&gt; → &lt;em&gt;C&lt;/em&gt;1, &lt;em&gt;G&lt;/em&gt; → &lt;em&gt;C&lt;/em&gt;2, &lt;em&gt;C&lt;/em&gt;1 → &lt;em&gt;C&lt;/em&gt;2 &lt;em&gt;C&lt;/em&gt;2 → &lt;em&gt;C&lt;/em&gt;1, &lt;em&gt;C&lt;/em&gt;1 → &lt;em&gt;G&lt;/em&gt;, &lt;em&gt;C&lt;/em&gt;2 → &lt;em&gt;G&lt;/em&gt;, and via Markov-chain Monte Carlo, seeks the maximum a posteriori estmate for the observed connectivity.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section5&quot; class=&quot;section toc-section&quot; readability=&quot;12&quot;&gt;
&lt;h3&gt;Spiking&lt;/h3&gt;

&lt;p&gt;We chose to focus on transistor switching as this is the closest in spirit to discrete action potentials of the sort readily available to neuroscientific analysis. The alternative, performing analysis with the signals on internal wires, would be analogous to measuring transmembrane voltage. Rasters were plotted from 10 example transistors which showed sufficient variance in spiking rate.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section6&quot; class=&quot;section toc-section&quot; readability=&quot;11.920634920635&quot;&gt;
&lt;h3&gt;Tuning curves&lt;/h3&gt;

&lt;p&gt;We compute luminance from the RGB output value of the simulator for each output pixel to the TIA. We then look at the transistor rasters and sum activity for 100 previous timesteps and call this the “mean rate”. For each transistor we then compute a tuning curve of mean rate versus luminance, normalized by the frequency of occurrence of that luminance value. Note that each game outputs only a small number of discrete colors and thus discrete luminance values. We used SI as it gave the most equal sampling of luminance space. We then evaluate the degree of fit to a unimodial Gaussian for each resulting tuning curve and classify tuning curves by eye into simple and complex responses, of which &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g004&quot;&gt;Fig 4&lt;/a&gt; contains representative examples.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section7&quot; class=&quot;section toc-section&quot; readability=&quot;8&quot;&gt;
&lt;h3&gt;Spike-word analysis&lt;/h3&gt;

&lt;p&gt;For the SI behavior we took spiking activity from the first 100ms of SI and performed spike word analysis on a random subset of 64 transistors close to the mean firing rate of all 3510.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section8&quot; class=&quot;section toc-section&quot; readability=&quot;12&quot;&gt;
&lt;h3&gt;Local field potential&lt;/h3&gt;

&lt;p&gt;To derive “local field potentials” we spatially integrate transistor switching over a region with a Gaussian weighting of &lt;em&gt;σ&lt;/em&gt; = 500&lt;em&gt;μm&lt;/em&gt; and low-pass filter the result using a window with a width of 4 timesteps.&lt;/p&gt;

&lt;p&gt;We compute periodograms using Welch’s method with 256-sample long windows with no overlap and a Hanning window.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section9&quot; class=&quot;section toc-section&quot; readability=&quot;9.9496221662469&quot;&gt;
&lt;h3&gt;Granger causality&lt;/h3&gt;

&lt;p&gt;We adopt methods for assessing conditional Granger causality as outlined in [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref071&quot; class=&quot;ref-tip&quot;&gt;71&lt;/a&gt;]. We take the LFP generated using methods in section and create 100 1&lt;em&gt;ms&lt;/em&gt;-long trials for each behavioral experiment. We then compute the conditional Granger causality for model orders ranging from 1 to 31. We compute BIC for all behaviors and select a model order of 20 as this is where BIC plateaus.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section10&quot; class=&quot;section toc-section&quot; readability=&quot;10&quot;&gt;
&lt;h3&gt;Whole brain recording&lt;/h3&gt;

&lt;p&gt;The transistor switching state for the first 10&lt;sup&gt;6&lt;/sup&gt; timestamps for each behavioral state is acquired, and binned in 100-timestep increments. The activity of each transistor is converted into a z-score by subtracting mean and normalizing to unit variance.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&quot;section11&quot; class=&quot;section toc-section&quot; readability=&quot;23.947655398037&quot;&gt;
&lt;h3&gt;Dimensionality reduction&lt;/h3&gt;

&lt;p&gt;We perform dimensionality reduction on the first 100,000 timesteps of the 3510-element transistor state vectors for each behavioral condition. We use non-negative matrix factorization, which attempts to find two matrices, &lt;em&gt;W&lt;/em&gt; and &lt;em&gt;H&lt;/em&gt;, whose product &lt;em&gt;WH&lt;/em&gt; approximates the observed data matrix &lt;em&gt;X&lt;/em&gt;. This is equivalent to minimizing the objective &lt;span class=&quot;inline-formula&quot;&gt;&lt;img src=&quot;http://journals.plos.org/ploscompbiol/article/file?type=thumbnail&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.e001&quot; class=&quot;inline-graphic&quot;/&gt;&lt;/span&gt;.&lt;/p&gt;

&lt;p&gt;The Scikit-Learn [&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi.1005268.ref072&quot; class=&quot;ref-tip&quot;&gt;72&lt;/a&gt;] implementation initialized via nonnegative double singular value decomposition solved via coordinate descent, as is the default. We use a latent dimensionality of 6 as it was found by hand to provide the most interpretable results. When plotting, the intensity of each transistor in a latent dimension is indicated by the saturation and size of point.&lt;/p&gt;

&lt;p&gt;To interpret the latent structure we first compute the signed correlation between the latent dimension and each of the 25 known signals. We show particularly interpretable results.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&quot;section5&quot; class=&quot;section toc-section&quot; readability=&quot;11.414012738854&quot;&gt;
&lt;h2&gt;Supporting Information&lt;/h2&gt;

&lt;div class=&quot;supplementary-material&quot; readability=&quot;8.9150326797386&quot;&gt;
&lt;h3 class=&quot;siTitle title-small&quot;&gt;&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article/file?type=supplementary&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.s001&quot;&gt;S1 Video.&lt;/a&gt; Video of timeseries of activity for Donkey Kong.&lt;/h3&gt;

&lt;p class=&quot;preSiDOI&quot;&gt;Top: color timeseries show the activation of the six found nonnegative components as a function of time. Bottom: Transistors active at a point in time, colored by their most-active component.&lt;/p&gt;
&lt;p class=&quot;siDoi&quot;&gt;&lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1005268.s001&quot;&gt;https://doi.org/10.1371/journal.pcbi.1005268.s001&lt;/a&gt;&lt;/p&gt;

&lt;p class=&quot;postSiDOI&quot;&gt;(MP4)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;supplementary-material&quot; readability=&quot;8.9352750809061&quot;&gt;
&lt;h3 class=&quot;siTitle title-small&quot;&gt;&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article/file?type=supplementary&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.s002&quot;&gt;S2 Video.&lt;/a&gt; Video of timeseries of activity for Space Invaders.&lt;/h3&gt;

&lt;p class=&quot;preSiDOI&quot;&gt;Top: color timeseries show the activation of the six found nonnegative components as a function of time. Bottom: Transistors active at a point in time, colored by their most-active component.&lt;/p&gt;
&lt;p class=&quot;siDoi&quot;&gt;&lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1005268.s002&quot;&gt;https://doi.org/10.1371/journal.pcbi.1005268.s002&lt;/a&gt;&lt;/p&gt;

&lt;p class=&quot;postSiDOI&quot;&gt;(MP4)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;supplementary-material&quot; readability=&quot;8.887417218543&quot;&gt;
&lt;h3 class=&quot;siTitle title-small&quot;&gt;&lt;a href=&quot;http://journals.plos.org/ploscompbiol/article/file?type=supplementary&amp;amp;id=info:doi/10.1371/journal.pcbi.1005268.s003&quot;&gt;S3 Video.&lt;/a&gt; Video of timeseries of activity for Pitfall.&lt;/h3&gt;

&lt;p class=&quot;preSiDOI&quot;&gt;Top: color timeseries show the activation of the six found nonnegative components as a function of time. Bottom: Transistors active at a point in time, colored by their most-active component.&lt;/p&gt;
&lt;p class=&quot;siDoi&quot;&gt;&lt;a href=&quot;https://doi.org/10.1371/journal.pcbi.1005268.s003&quot;&gt;https://doi.org/10.1371/journal.pcbi.1005268.s003&lt;/a&gt;&lt;/p&gt;

&lt;p class=&quot;postSiDOI&quot;&gt;(MP4)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;section toc-section&quot; readability=&quot;14.787234042553&quot;&gt;
&lt;h2&gt;Acknowledgments&lt;/h2&gt;

&lt;p&gt;We’d like to thank the Visual 6502 team for the original simulation and reconstruction work. We thank Gary Marcus, Adam Marblestone, Malcolm MacIver, John Krakauer, and Yarden Katz for helpful discussions, and The Kavli Foundation for sponsoring the “Workshop on Cortical Computation” where these ideas were first developed. Thanks to Phil Mainwaring for providing the schematic of the 6502 in &lt;a href=&quot;http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268#pcbi-1005268-g013&quot;&gt;Fig 13&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;contributions toc-section&quot;&gt;
&lt;h2&gt;Author Contributions&lt;/h2&gt;
&lt;ol class=&quot;simple&quot;&gt;&lt;li&gt;&lt;strong&gt;Conceptualization:&lt;/strong&gt; EJ.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data curation:&lt;/strong&gt; EJ.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Formal analysis:&lt;/strong&gt; EJ KPK.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Funding acquisition:&lt;/strong&gt; KPK.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Investigation:&lt;/strong&gt; EJ KPK.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Methodology:&lt;/strong&gt; EJ KPK.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Project administration:&lt;/strong&gt; EJ KPK.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Resources:&lt;/strong&gt; EJ.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Software:&lt;/strong&gt; EJ.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Supervision:&lt;/strong&gt; KPK.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Validation:&lt;/strong&gt; EJ KPK.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Visualization:&lt;/strong&gt; EJ.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Writing – original draft:&lt;/strong&gt; EJ KPK.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Writing – review &amp;amp; editing:&lt;/strong&gt; EJ KPK.&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;
&lt;div class=&quot;toc-section&quot;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol class=&quot;references&quot;&gt;&lt;li id=&quot;ref1&quot;&gt;&lt;span class=&quot;order&quot;&gt;1.&lt;/span&gt;  Sejnowski TJ, Churchland PS, Movshon JA. Putting big data to good use in neuroscience. Nature neuroscience. 2014;17(11):1440–1. pmid:25349909
&lt;/li&gt;
&lt;li id=&quot;ref2&quot;&gt;&lt;span class=&quot;order&quot;&gt;2.&lt;/span&gt;  Freeman J, Vladimirov N, Kawashima T, Mu Y, Sofroniew NJ, Bennett DV, et al. Mapping brain activity at scale with cluster computing. Nature methods. 2014;11(9). pmid:25068736
&lt;/li&gt;
&lt;li id=&quot;ref3&quot;&gt;&lt;span class=&quot;order&quot;&gt;3.&lt;/span&gt;  Vivien M. Charting the Brain’s Networks. Nature. 2012;490:293–298.
&lt;/li&gt;
&lt;li id=&quot;ref4&quot;&gt;&lt;span class=&quot;order&quot;&gt;4.&lt;/span&gt;  Alivisatos AP, Chun M, Church GM, Greenspan RJ, Roukes ML, Yuste R. The Brain Activity Map Project and the Challenge of Functional Connectomics. Neuron. 2012;74(6):970–974. pmid:22726828
&lt;/li&gt;
&lt;li id=&quot;ref5&quot;&gt;&lt;span class=&quot;order&quot;&gt;5.&lt;/span&gt;  Markram H. The human brain project. Scientific American. 2012;306:50–55. pmid:22649994
&lt;/li&gt;
&lt;li id=&quot;ref6&quot;&gt;&lt;span class=&quot;order&quot;&gt;6.&lt;/span&gt;  Ahrens MB, Li JM, Orger MB, Robson DN, Schier AF, Engert F, et al. Brain-wide neuronal dynamics during motor adaptation in zebrafish. Nature. 2012;485(7399):471–477. pmid:22622571
&lt;/li&gt;
&lt;li id=&quot;ref7&quot;&gt;&lt;span class=&quot;order&quot;&gt;7.&lt;/span&gt;  Prevedel R, Yoon Yg, Hoffmann M, Pak N, Wetzstein G, Kato S, et al. Simultaneous whole-animal 3D imaging of neuronal activity using light-field microscopy. Nature Methods. 2014;11(7):727–730. pmid:24836920
&lt;/li&gt;
&lt;li id=&quot;ref8&quot;&gt;&lt;span class=&quot;order&quot;&gt;8.&lt;/span&gt;  Nguyen JP, Shipley FB, Linder AN, Plummer GS, Liu M, Setru SU, et al. Whole-brain calcium imaging with cellular resolution in freely behaving Caenorhabditis elegans. Proceedings of the National Academy of Sciences of the United States of America. 2015;(9):33. pmid:26712014
&lt;/li&gt;
&lt;li id=&quot;ref9&quot;&gt;&lt;span class=&quot;order&quot;&gt;9.&lt;/span&gt;  Lazebnik Y. Can a biologist fix a radio?—Or, what I learned while studying apoptosis. Cancer Cell. 2002;2(3):179–182. pmid:12242150
&lt;/li&gt;
&lt;li id=&quot;ref10&quot;&gt;&lt;span class=&quot;order&quot;&gt;10.&lt;/span&gt;  Montfort N, Bogost I. Racing The Beam: The Atari Video Computer System. Cambridge: The MIT Press; 2009.
&lt;/li&gt;
&lt;li id=&quot;ref11&quot;&gt;&lt;span class=&quot;order&quot;&gt;11.&lt;/span&gt;  James G, Silverman B, Silverman B. Visualizing a classic CPU in action. In: ACM SIGGRAPH 2010 Talks on—SIGGRAPH’10. New York, New York, USA: ACM Press; 2010. p. 1. Available from: &lt;a href=&quot;http://portal.acm.org/citation.cfm?doid=1837026.1837061&quot;&gt;http://portal.acm.org/citation.cfm?doid=1837026.1837061&lt;/a&gt;. &lt;a href=&quot;https://doi.org/10.1145/1837026.1837061&quot;&gt;https://doi.org/10.1145/1837026.1837061&lt;/a&gt;
&lt;/li&gt;
&lt;li id=&quot;ref12&quot;&gt;&lt;span class=&quot;order&quot;&gt;12.&lt;/span&gt;  Takemura Sy, Bharioke A, Lu Z, Nern A, Vitaladevuni S, Rivlin PK, et al. A visual motion detection circuit suggested by Drosophila connectomics. Nature. 2013;500(7461):175–181. pmid:23925240
&lt;/li&gt;
&lt;li id=&quot;ref13&quot;&gt;&lt;span class=&quot;order&quot;&gt;13.&lt;/span&gt;  Helmstaedter M, Briggman KL, Turaga SC, Jain V, Seung HS, Denk W. Connectomic reconstruction of the inner plexiform layer in the mouse retina. Nature. 2013;500(7461):168–174. pmid:23925239
&lt;/li&gt;
&lt;li id=&quot;ref14&quot;&gt;&lt;span class=&quot;order&quot;&gt;14.&lt;/span&gt;  Mnih V, Kavukcuoglu K, Silver D, Rusu Aa, Veness J, Bellemare MG, et al. Human-level control through deep reinforcement learning. Nature. 2015;518(7540):529–533. pmid:25719670
&lt;/li&gt;
&lt;li id=&quot;ref15&quot;&gt;&lt;span class=&quot;order&quot;&gt;15.&lt;/span&gt; Aloupis G, Demaine ED, Guo A, Viglietta G. Classic Nintendo Games are (Computationally) Hard. In: Proceedings of the 7th International Conference on Fun with Algorithms (FUN 2014),. Lipari Island, Italy; 2014. p. 41–50. Available from: &lt;a href=&quot;http://arxiv.org/abs/1203.1895&quot;&gt;http://arxiv.org/abs/1203.1895&lt;/a&gt;.
&lt;/li&gt;
&lt;li id=&quot;ref16&quot;&gt;&lt;span class=&quot;order&quot;&gt;16.&lt;/span&gt;  Hopfield JJ, Brody CD. What is a moment? Transient synchrony as a collective mechanism for spatiotemporal integration. Proceedings of the National Academy of Sciences of the United States of America. 2001;98(3):1282–1287. pmid:11158631
&lt;/li&gt;
&lt;li id=&quot;ref17&quot;&gt;&lt;span class=&quot;order&quot;&gt;17.&lt;/span&gt;  Carandini M. From circuits to behavior: a bridge too far? Nature neuroscience. 2012;15(4):507–9. pmid:22449960
&lt;/li&gt;
&lt;li id=&quot;ref18&quot;&gt;&lt;span class=&quot;order&quot;&gt;18.&lt;/span&gt;  Marom S. On the Precarious Path of Reverse Neuro-Engineering. Frontiers in Computational Neuroscience. 2009;3(May):3–6. pmid:19503751
&lt;/li&gt;
&lt;li id=&quot;ref19&quot;&gt;&lt;span class=&quot;order&quot;&gt;19.&lt;/span&gt;  Mel B. In the brain, the model is the goal. Nature Neuroscience. 2000;3(november):90089.
&lt;/li&gt;
&lt;li id=&quot;ref20&quot;&gt;&lt;span class=&quot;order&quot;&gt;20.&lt;/span&gt;  Brown JW. The tale of the neuroscientists and the computer: Why mechanistic theory matters. Frontiers in Neuroscience. 2014;8(OCT):1–3. pmid:25400544
&lt;/li&gt;
&lt;li id=&quot;ref21&quot;&gt;&lt;span class=&quot;order&quot;&gt;21.&lt;/span&gt;  Kayser C, Kording K, Konig P. Processing of complex stimuli and natural scenes in the visual cortex. Current Opinion in Neurobiology. 2004;14(4):468–473. pmid:15302353
&lt;/li&gt;
&lt;li id=&quot;ref22&quot;&gt;&lt;span class=&quot;order&quot;&gt;22.&lt;/span&gt;  von Neumann J. The Computer and The Brain. 1st ed. New Haven: Yale University Press; 1958.
&lt;/li&gt;
&lt;li id=&quot;ref23&quot;&gt;&lt;span class=&quot;order&quot;&gt;23.&lt;/span&gt;  Marcus G, Marblestone A, Dean T. The atoms of neural computation. Science. 2014;346(6209):551–552. pmid:25359953
&lt;/li&gt;
&lt;li id=&quot;ref24&quot;&gt;&lt;span class=&quot;order&quot;&gt;24.&lt;/span&gt;  Marder E, Goaillard JM. Variability, compensation and homeostasis in neuron and network function. Nature Reviews. 2006;7(July):563–574. pmid:16791145
&lt;/li&gt;
&lt;li id=&quot;ref25&quot;&gt;&lt;span class=&quot;order&quot;&gt;25.&lt;/span&gt;  O’Rourke NA, Weiler NC, Micheva KD, Smith SJ. Deep molecular diversity of mammalian synapses: why it matters and how to measure it. Nature reviews Neuroscience. 2012;13(6):365–79. pmid:22573027
&lt;/li&gt;
&lt;li id=&quot;ref26&quot;&gt;&lt;span class=&quot;order&quot;&gt;26.&lt;/span&gt;  Horiuchi TK, Bishofberger B, Koch C. An Analog VLSI Saccadic Eye Movement System. Advances in Neural Information Processing Systems 6. 1994; p. 582–589.
&lt;/li&gt;
&lt;li id=&quot;ref27&quot;&gt;&lt;span class=&quot;order&quot;&gt;27.&lt;/span&gt;  Berger TW, Hampson RE, Song D, Goonawardena A, Marmarelis VZ, Deadwyler SA. A cortical neural prosthesis for restoring and enhancing memory. Journal of neural engineering. 2011;8(4):046017. pmid:21677369
&lt;/li&gt;
&lt;li id=&quot;ref28&quot;&gt;&lt;span class=&quot;order&quot;&gt;28.&lt;/span&gt;  Marr D. VISION. Cambridge, MA: MIT Press; 1982. &lt;a href=&quot;https://doi.org/10.7551/mitpress/9780262514620.001.0001&quot;&gt;https://doi.org/10.7551/mitpress/9780262514620.001.0001&lt;/a&gt;
&lt;/li&gt;
&lt;li id=&quot;ref29&quot;&gt;&lt;span class=&quot;order&quot;&gt;29.&lt;/span&gt;  Jones EG. Neuroanatomy: Cajal and after Cajal. Brain Research Reviews. 2007;55(2 SPEC. ISS.):248–255. pmid:17659350
&lt;/li&gt;
&lt;li id=&quot;ref30&quot;&gt;&lt;span class=&quot;order&quot;&gt;30.&lt;/span&gt;  Pavlovic DM, Vértes PE, Bullmore ET, Schafer WR, Nichols TE. Stochastic Blockmodeling of the Modules and Core of the Caenorhabditis elegans Connectome. PLoS ONE. 2014;9(7):e97584. pmid:24988196
&lt;/li&gt;
&lt;li id=&quot;ref31&quot;&gt;&lt;span class=&quot;order&quot;&gt;31.&lt;/span&gt;  Jonas E, Kording K. Automatic discovery of cell types and microcircuitry from neural connectomics. eLife. 2015;4:e04250. pmid:25928186
&lt;/li&gt;
&lt;li id=&quot;ref32&quot;&gt;&lt;span class=&quot;order&quot;&gt;32.&lt;/span&gt;  Towlson EK, Vertes PE, Ahnert SE, Schafer WR, Bullmore ET. The Rich Club of the C. elegans Neuronal Connectome. Journal of Neuroscience. 2013;33(15):6380–6387. pmid:23575836
&lt;/li&gt;
&lt;li id=&quot;ref33&quot;&gt;&lt;span class=&quot;order&quot;&gt;33.&lt;/span&gt;  Briggman KL, Denk W. Towards neural circuit reconstruction with volume electron microscopy techniques. Current Opinion in Neurobiology. 2006;16(5):562–570. pmid:16962767
&lt;/li&gt;
&lt;li id=&quot;ref34&quot;&gt;&lt;span class=&quot;order&quot;&gt;34.&lt;/span&gt;  Lichtman JW, Sanes JR. Ome sweet ome: what can the genome tell us about the connectome? Current Opinion in Neurobiology. 2008;18(3):346–353. pmid:18801435
&lt;/li&gt;
&lt;li id=&quot;ref35&quot;&gt;&lt;span class=&quot;order&quot;&gt;35.&lt;/span&gt;  Varshney LR, Chen BL, Paniagua E, Hall DH, Chklovskii DB. Structural properties of the Caenorhabditis elegans neuronal network. PLoS computational biology. 2011;7(2):e1001066. pmid:21304930
&lt;/li&gt;
&lt;li id=&quot;ref36&quot;&gt;&lt;span class=&quot;order&quot;&gt;36.&lt;/span&gt;  Usoskin D, Furlan A, Islam S, Abdo H, Lönnerberg P, Lou D, et al. Unbiased classification of sensory neuron types by large-scale single-cell RNA sequencing. Nature Neuroscience. 2014;18(1):145–153. pmid:25420068
&lt;/li&gt;
&lt;li id=&quot;ref37&quot;&gt;&lt;span class=&quot;order&quot;&gt;37.&lt;/span&gt;  Rorden C, Karnath HO. Using human brain lesions to infer function: a relic from a past era in the fMRI age? Nature reviews Neuroscience. 2004;5(10):813–9. pmid:15378041
&lt;/li&gt;
&lt;li id=&quot;ref38&quot;&gt;&lt;span class=&quot;order&quot;&gt;38.&lt;/span&gt;  Jenett A, Rubin G, Ngo TTB, Shepherd D, Murphy C, Dionne H, et al. A GAL4-Driver Line Resource for Drosophila Neurobiology. Cell Reports. 2012;2(4):991–1001. pmid:23063364
&lt;/li&gt;
&lt;li id=&quot;ref39&quot;&gt;&lt;span class=&quot;order&quot;&gt;39.&lt;/span&gt;  Aso Y, Hattori D, Yu Y, Johnston RM, Iyer Na, Ngo TT, et al. The neuronal architecture of the mushroom body provides a logic for associative learning. eLife. 2014;3:1–47. pmid:25535793
&lt;/li&gt;
&lt;li id=&quot;ref40&quot;&gt;&lt;span class=&quot;order&quot;&gt;40.&lt;/span&gt;  Yates J, Katz L, Park IM, Pillow JW, Huk A. Dissociated functional significance of choice-related activity across the primate dorsal stream. Cosyne Abstracts. 2014;535(7611):Salt Lake City USA.
&lt;/li&gt;
&lt;li id=&quot;ref41&quot;&gt;&lt;span class=&quot;order&quot;&gt;41.&lt;/span&gt;  Hubel DH, Wiesel TN. Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex. The Journal of Physiology. 1962;160(1):106–154. pmid:14449617
&lt;/li&gt;
&lt;li id=&quot;ref42&quot;&gt;&lt;span class=&quot;order&quot;&gt;42.&lt;/span&gt;  O’Keefe J, Dostrovsky J. The hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat. Brain Research. 1971;34(1):171–175. pmid:5124915
&lt;/li&gt;
&lt;li id=&quot;ref43&quot;&gt;&lt;span class=&quot;order&quot;&gt;43.&lt;/span&gt;  Hafting T, Fyhn M, Molden S, Moser M, Moser EI. Microstructure of a spatial map in the entorhinal cortex. Nature. 2005;436(7052):801–806. pmid:15965463
&lt;/li&gt;
&lt;li id=&quot;ref44&quot;&gt;&lt;span class=&quot;order&quot;&gt;44.&lt;/span&gt;  Kanwisher N, McDermott J, Chun MM. The fusiform face area: a module in human extrastriate cortex specialized for face perception. The Journal of neuroscience: the official journal of the Society for Neuroscience. 1997;17(11):4302–11. pmid:9151747
&lt;/li&gt;
&lt;li id=&quot;ref45&quot;&gt;&lt;span class=&quot;order&quot;&gt;45.&lt;/span&gt;  Gallant JL, Connor CE, Rakshit S, Lewis JW, Van Essen DC. Neural responses to polar, hyperbolic, and cartesian grating in area V4 of the macaque monkey. Journal of Neurophysiology. 1996;76(4):2718–2739. pmid:8899641
&lt;/li&gt;
&lt;li id=&quot;ref46&quot;&gt;&lt;span class=&quot;order&quot;&gt;46.&lt;/span&gt;  Skottun BC, De Valois RL, Grosof DH, Movshon JA, Albrecht DG, Bonds AB. Classifying simple and complex cells on the basis of response modulation. Vision Research. 1991;31(7–8):1079–1086. pmid:1909826
&lt;/li&gt;
&lt;li id=&quot;ref47&quot;&gt;&lt;span class=&quot;order&quot;&gt;47.&lt;/span&gt;  Quiroga R, Reddy L, Kreiman G, Koch C, Fried I. Invariant visual representation by single neurons in the human brain. Nature. 2005;435(7045):1102–1107. pmid:15973409
&lt;/li&gt;
&lt;li id=&quot;ref48&quot;&gt;&lt;span class=&quot;order&quot;&gt;48.&lt;/span&gt;  Schneidman E, Berry MJ, Segev R, Bialek W. Weak pairwise correlations imply strongly correlated network states in a neural population. Nature. 2006;440(April):1007–1012. pmid:16625187
&lt;/li&gt;
&lt;li id=&quot;ref49&quot;&gt;&lt;span class=&quot;order&quot;&gt;49.&lt;/span&gt;  Hesse J, Gross T. Self-organized criticality as a fundamental property of neural systems. Frontiers in Systems Neuroscience. 2014;8(September):166. pmid:25294989
&lt;/li&gt;
&lt;li id=&quot;ref50&quot;&gt;&lt;span class=&quot;order&quot;&gt;50.&lt;/span&gt;  Seth AK, Barrett AB, Barnett L. Granger Causality Analysis in Neuroscience and Neuroimaging. Journal of Neuroscience. 2015;35(8):3293–3297. pmid:25716830
&lt;/li&gt;
&lt;li id=&quot;ref51&quot;&gt;&lt;span class=&quot;order&quot;&gt;51.&lt;/span&gt;  Stevenson IH, Körding KP. On the Similarity of Functional Connectivity between Neurons Estimated across Timescales. PLoS ONE. 2010;5(2):e9206. pmid:20174620
&lt;/li&gt;
&lt;li id=&quot;ref52&quot;&gt;&lt;span class=&quot;order&quot;&gt;52.&lt;/span&gt;  Huettel SA, Song AW, McCarthy G. Functional Magnetic Resonance Imaging. 3rd ed. Sinauer Associates; 2014.
&lt;/li&gt;
&lt;li id=&quot;ref53&quot;&gt;&lt;span class=&quot;order&quot;&gt;53.&lt;/span&gt;  Cunningham JP, Yu BM. Dimensionality reduction for large-scale neural recordings. Nature Neuroscience. 2014;. pmid:25151264
&lt;/li&gt;
&lt;li id=&quot;ref54&quot;&gt;&lt;span class=&quot;order&quot;&gt;54.&lt;/span&gt;  Churchland MM, Cunningham JP, Kaufman MT, Foster JD, Nuyujukian P, Ryu SI, et al. Neural population dynamics during reaching. Nature. 2012;487(7405):51–6. pmid:22722855
&lt;/li&gt;
&lt;li id=&quot;ref55&quot;&gt;&lt;span class=&quot;order&quot;&gt;55.&lt;/span&gt;  Lee DD, Seung HS. Learning the parts of objects by non-negative matrix factorization. Nature. 1999;401(6755):788–91. pmid:10548103
&lt;/li&gt;
&lt;li id=&quot;ref56&quot;&gt;&lt;span class=&quot;order&quot;&gt;56.&lt;/span&gt;  Agarwal G, Stevenson IH, Berenyi A, Mizuseki K, Buzsaki G, Sommer FT. Spatially Distributed Local Fields in the Hippocampus Encode Rat Position. Science. 2014;344(6184):626–630. pmid:24812401
&lt;/li&gt;
&lt;li id=&quot;ref57&quot;&gt;&lt;span class=&quot;order&quot;&gt;57.&lt;/span&gt;  Ting LH, McKay JL. Neuromechanics of muscle synergies for posture and movement. Current Opinion in Neurobiology. 2007;17(6):622–628. pmid:18304801
&lt;/li&gt;
&lt;li id=&quot;ref58&quot;&gt;&lt;span class=&quot;order&quot;&gt;58.&lt;/span&gt;  Thiele A, Stoner G. Neuronal synchrony does not correlate with motion coherence in cortical area MT. Nature. 2003;421(6921):366–370. pmid:12540900
&lt;/li&gt;
&lt;li id=&quot;ref59&quot;&gt;&lt;span class=&quot;order&quot;&gt;59.&lt;/span&gt;  Kennedy MB. Signal-processing machines at the postsynaptic density. Science (New York, NY). 2000;290(5492):750–4.
&lt;/li&gt;
&lt;li id=&quot;ref60&quot;&gt;&lt;span class=&quot;order&quot;&gt;60.&lt;/span&gt;  Buzsaki G. Neuronal Oscillations in Cortical Networks. Science. 2004;304(5679):1926–1929. pmid:15218136
&lt;/li&gt;
&lt;li id=&quot;ref61&quot;&gt;&lt;span class=&quot;order&quot;&gt;61.&lt;/span&gt;  Ringach DL, Shapley RM, Hawken MJ. Orientation selectivity in macaque V1: diversity and laminar dependence. The Journal of neuroscience: the official journal of the Society for Neuroscience. 2002;22(13):5639–5651. pmid:12097515
&lt;/li&gt;
&lt;li id=&quot;ref62&quot;&gt;&lt;span class=&quot;order&quot;&gt;62.&lt;/span&gt;  Marder E, Thirumalai V. Cellular, synaptic and network effects of neuromodulation. Neural Networks. 2002;15(4–6):479–493. pmid:12371506
&lt;/li&gt;
&lt;li id=&quot;ref63&quot;&gt;&lt;span class=&quot;order&quot;&gt;63.&lt;/span&gt;  London M, Häusser M. Dendritic Computation. Annual Review of Neuroscience. 2005;28(1):503–532. pmid:16033324
&lt;/li&gt;
&lt;li id=&quot;ref64&quot;&gt;&lt;span class=&quot;order&quot;&gt;64.&lt;/span&gt;  Eliasmith C, Stewart TC, Choo X, Bekolay T, DeWolf T, Tang Y, et al. A Large-Scale Model of the Functioning Brain. Science. 2012;338(6111):1202–1205. pmid:23197532
&lt;/li&gt;
&lt;li id=&quot;ref65&quot;&gt;&lt;span class=&quot;order&quot;&gt;65.&lt;/span&gt;  Anderson JR, Matessa M, Lebiere C. ACT-R: A Theory of Higher Level Cognition and its Relation to Visual Attention. Human-Computer Interaction. 1997;12:439–462.
&lt;/li&gt;
&lt;li id=&quot;ref66&quot;&gt;&lt;span class=&quot;order&quot;&gt;66.&lt;/span&gt;  Felleman DJ, Van Essen DC. Distributed hierarchical processing in the primate cerebral cortex. Cerebral cortex (New York, NY: 1991). 1991;1(1):1–47. pmid:1822724
&lt;/li&gt;
&lt;li id=&quot;ref67&quot;&gt;&lt;span class=&quot;order&quot;&gt;67.&lt;/span&gt; Yosinski J, Clune J, Nguyen A, Fuchs T, Lipson H. Understanding Neural Networks Through Deep Visualization. International Conference on Machine Learning—Deep Learning Workshop 2015. 2015; p. 12.
&lt;/li&gt;
&lt;li id=&quot;ref68&quot;&gt;&lt;span class=&quot;order&quot;&gt;68.&lt;/span&gt;  Zeiler MD, Fergus R. Visualizing and understanding convolutional networks. Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics). 2014;8689 LNCS(PART 1):818–833.
&lt;/li&gt;
&lt;li id=&quot;ref69&quot;&gt;&lt;span class=&quot;order&quot;&gt;69.&lt;/span&gt; Lipton RJ, Regan KW. Magic To Do; 2016. Available from: &lt;a href=&quot;https://rjlipton.wordpress.com/2016/02/07/magic-to-do/&quot;&gt;https://rjlipton.wordpress.com/2016/02/07/magic-to-do/&lt;/a&gt;.
&lt;/li&gt;
&lt;li id=&quot;ref70&quot;&gt;&lt;span class=&quot;order&quot;&gt;70.&lt;/span&gt;  Szegedy C, Zaremba W, Sutskever I. Intriguing properties of neural networks. arXiv preprint. 2013; p. 1–10.
&lt;/li&gt;
&lt;li id=&quot;ref71&quot;&gt;&lt;span class=&quot;order&quot;&gt;71.&lt;/span&gt;  Ding M, Chen Y, Bressler SL. Granger Causality: Basic Theory and Application to Neuroscience. Handbook of Time Series Analysis. 2006;(February):451–474.
&lt;/li&gt;
&lt;li id=&quot;ref72&quot;&gt;&lt;span class=&quot;order&quot;&gt;72.&lt;/span&gt;  Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, et al. Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research. 2012;12:2825–2830.
&lt;/li&gt;
&lt;/ol&gt;&lt;/div&gt;

</description>
<pubDate>Thu, 12 Apr 2018 03:50:31 +0000</pubDate>
<dc:creator>eggspurt</dc:creator>
<og:type>article</og:type>
<og:url>http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268</og:url>
<og:title>Could a Neuroscientist Understand a Microprocessor?</og:title>
<og:description>Author Summary Neuroscience is held back by the fact that it is hard to evaluate if a conclusion is correct; the complexity of the systems under study and their experimental inaccessability make the assessment of algorithmic and data analytic technqiues challenging at best. We thus argue for testing approaches using known artifacts, where the correct interpretation is known. Here we present a microprocessor platform as one such test case. We find that many approaches in neuroscience, when used naïvely, fall short of producing a meaningful understanding.</og:description>
<og:image>http://journals.plos.org/ploscompbiol/article/figure/image?id=10.1371/journal.pcbi.1005268.g013&amp;size=inline</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005268</dc:identifier>
</item>
<item>
<title>Tesla issues strongest statement yet blaming driver for deadly crash</title>
<link>http://abc7news.com/automotive/exclusive-tesla-issues-strongest-statement-yet-blaming-driver-for-deadly-crash/3325908/</link>
<guid isPermaLink="true" >http://abc7news.com/automotive/exclusive-tesla-issues-strongest-statement-yet-blaming-driver-for-deadly-crash/3325908/</guid>
<description>&lt;div readability=&quot;114.48742071882&quot;&gt;
&lt;p&gt;MOUNTAIN VIEW, Calif. (KGO) --&lt;/p&gt;
Two-and-a-half weeks since an Apple engineer died when his Tesla crashed on Autopilot, his family is speaking out to the I-Team. Tuesday night, Tesla released its strongest statement yet blaming the driver, Walter Huang, for what happened.&lt;p&gt;But his family and their new attorney are fighting back.&lt;br/&gt;&lt;/p&gt;
&lt;strong&gt;VIDEO: Fiery Tesla crash kills driver in Mountain View&lt;/strong&gt;&lt;br/&gt;Despite his long hours at EA Games and then Apple starting last November, 38-year-old Walter Huang found time for his family.&lt;p&gt;&quot;His daily routine is to wake up every morning before everyone else to make breakfast for everyone and make coffee for Sevonne,&quot; said Will Huang, Walter's brother.&lt;/p&gt;&lt;p&gt;ABC7 News investigative reporter Dan Noyes spoke with Will, Huang's wife Sevonne, and the attorney they've hired to sue Tesla.&lt;/p&gt;&lt;p&gt;Huang died March 23 in a fiery Tesla crash in Mountain View on his way to work. Sevonne couldn't reach him and she turned on the news to see it. She told the ABC7 News I-Team that Walter complained that his Tesla's Autopilot had steered toward that same barrier on several occasions, she recognized the location and the blue Model X.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Dan Noyes:&lt;/strong&gt; &quot;Did you know right away that it was Walter? Did you think that was him?&quot;&lt;br/&gt;&lt;strong&gt;Sevonne Huang:&lt;/strong&gt; &quot;Yeah, I think that's him. It's just like -- lost everything for me. I didn't just lose my husband, I lost my best friend.&quot;&lt;br/&gt;&lt;/p&gt;
&lt;br/&gt;Tesla confirmed its data shows Walter Huang was using Autopilot at the time of the crash, but that his hands were off the wheel for six seconds right before impact.&lt;p&gt;&lt;strong&gt;I-TEAM EXCLUSIVE: &lt;a href=&quot;http://abc7news.com/automotive/i-team-exclusive-victim-who-died-in-tesla-crash-had-complained-about-auto-pilot/3275600/&quot;&gt;Victim who died in Tesla crash had complained about Autopilot&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Tesla sent Dan Noyes a statement Tuesday night that reads in part, &quot;Autopilot requires the driver to be alert and have hands on the wheel... the crash happened on a clear day with several hundred feet of visibility ahead, which means that the only way for this accident to have occurred is if Mr. Huang was not paying attention to the road.&quot;&lt;/p&gt;&lt;p&gt;&quot;We know that he's not the type who would not have his hands on the steering wheel, he's always been (a) really careful driver,&quot; said Will.&lt;br/&gt;&lt;/p&gt;
&lt;br/&gt;The family's lawyer believes Tesla is blaming Huang to distract from the family's concern about the car's Autopilot.&lt;p&gt;&quot;Its sensors misread the painted lane lines on the road and its braking system failed to detect a stationary object ahead,&quot; said lawyer Mike Fong.&lt;/p&gt;&lt;p&gt;You can already see the arguments forming for the lawsuit. The lawyer tells me he doesn't expect to file the complaint until the NTSB wraps up its investigation.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;VIDEO: &lt;a href=&quot;http://abc7news.com/exclusive-widow-of-deadly-tesla-crash-victim-speaks-out/3325427/&quot;&gt;Widow of deadly Tesla crash victim speaks out&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/p&gt;

&lt;br/&gt;Here is the full statement from Tesla: &lt;em readability=&quot;25&quot;&gt;&quot;We are very sorry for the family's loss.&lt;p&gt;According to the family, Mr. Huang was well aware that Autopilot was not perfect and, specifically, he told them it was not reliable in that exact location, yet he nonetheless engaged Autopilot at that location. The crash happened on a clear day with several hundred feet of visibility ahead, which means that the only way for this accident to have occurred is if Mr. Huang was not paying attention to the road, despite the car providing multiple warnings to do so.&lt;/p&gt;&lt;p&gt;The fundamental premise of both moral and legal liability is a broken promise, and there was none here. Tesla is extremely clear that Autopilot requires the driver to be alert and have hands on the wheel. This reminder is made every single time Autopilot is engaged. If the system detects that hands are not on, it provides visual and auditory alerts. This happened several times on Mr. Huang's drive that day.&lt;/p&gt;&lt;p&gt;We empathize with Mr. Huang's family, who are understandably facing loss and grief, but the false impression that Autopilot is unsafe will cause harm to others on the road. NHTSA found that even the early version of Tesla Autopilot resulted in 40% fewer crashes and it has improved substantially since then. The reason that other families are not on TV is because their loved ones are still alive.&quot;&lt;/p&gt;&lt;/em&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://abc7news.com/automotive/tesla-car-fire-abc7-investigates-deadly-accident-in-mountain-view/3293529&quot;&gt;Click here&lt;/a&gt; for more stories, photos, and video on this I-Team investigation into the deadly Tesla crash.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://abc7news.com/iteam/&quot;&gt;Click here&lt;/a&gt; for the latest stories by Dan Noyes and the I-Team and &lt;a href=&quot;http://abc7news.com/tag/tesla/&quot;&gt;click here&lt;/a&gt; for more stories and videos related to Tesla.&lt;/strong&gt;
&lt;/p&gt;

&lt;/div&gt;&lt;p&gt;(Copyright ©2018 KGO-TV. All Rights Reserved.)&lt;/p&gt;</description>
<pubDate>Wed, 11 Apr 2018 18:12:44 +0000</pubDate>
<dc:creator>otalp</dc:creator>
<og:type>article</og:type>
<og:url>http://abc7news.com/3325908/</og:url>
<og:title>EXCLUSIVE: Tesla issues strongest statement yet blaming driver for deadly crash</og:title>
<og:description>Two-and-a-half weeks since an Apple engineer died when his Tesla crashed on Autopilot, whis family is speaking out to the I-Team. Tuesday night, Tesla released its strongest statement yet blaming the driver, Walter Huang, for what happened.</og:description>
<og:image>http://cdn.abclocal.go.com/content/kgo/images/cms/3325959_1280x720.jpg</og:image>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://abc7news.com/automotive/exclusive-tesla-issues-strongest-statement-yet-blaming-driver-for-deadly-crash/3325908/</dc:identifier>
</item>
<item>
<title>Fuchsia is not Linux</title>
<link>https://fuchsia.googlesource.com/docs/+/master/the-book/</link>
<guid isPermaLink="true" >https://fuchsia.googlesource.com/docs/+/master/the-book/</guid>
<description>&lt;p&gt;&lt;em&gt;A modular, capability-based operating system&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This document is a collection of articles describing the Fuchsia operating system, organized around particular subsystems. Sections will be populated over time.&lt;/p&gt;

&lt;h2&gt;Zircon Kernel&lt;/h2&gt;
&lt;p&gt;Zircon is the microkernel underlying the rest of Fuchsia. Zircon also provides core drivers and Fuchsia's libc implementation.&lt;/p&gt;
&lt;h2&gt;Zircon Core&lt;/h2&gt;
&lt;h2&gt;Framework&lt;/h2&gt;
&lt;h2&gt;Storage&lt;/h2&gt;
&lt;h2&gt;Networking&lt;/h2&gt;
&lt;h2&gt;Graphics&lt;/h2&gt;
&lt;h2&gt;Media&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;Audio&lt;/li&gt;
&lt;li&gt;Video&lt;/li&gt;
&lt;li&gt;DRM&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Intelligence&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;Context&lt;/li&gt;
&lt;li&gt;Agent Framework&lt;/li&gt;
&lt;li&gt;Suggestions&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;User interface&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;Device, user, and story shells&lt;/li&gt;
&lt;li&gt;Stories and modules&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Backwards compatibility&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;POSIX lite (what subset of POSIX we support and why)&lt;/li&gt;
&lt;li&gt;Web runtime&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Update and recovery&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;Verified boot&lt;/li&gt;
&lt;li&gt;Updater&lt;/li&gt;
&lt;/ul&gt;</description>
<pubDate>Wed, 11 Apr 2018 18:09:50 +0000</pubDate>
<dc:creator>navigaid</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://fuchsia.googlesource.com/docs/+/master/the-book/</dc:identifier>
</item>
<item>
<title>Prototool – A Swiss Army Knife for Protocol Buffers</title>
<link>https://github.com/uber/prototool</link>
<guid isPermaLink="true" >https://github.com/uber/prototool</guid>
<description>&lt;h3&gt;README.md&lt;/h3&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://developers.google.com/protocol-buffers&quot; rel=&quot;nofollow&quot;&gt;Protobuf&lt;/a&gt; is one of the best interface description languages out there - it's widely adopted, and after over 15 years of use, it's practically bulletproof. However, working with Protobuf and maintaining consistency across your Protobuf files can be a pain - protoc, while being a tool that has stood the test of time, is non-trivial to use, and the Protobuf community has not developed common standards with regards to stub generation. Prototool aims to solve this by making working with Protobuf much simpler.&lt;/p&gt;
&lt;p&gt;Prototool lets you:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Handle installation of protoc and the import of all of the Well-Known Types behind the scenes in a platform-independent manner without any work on the part of the user.&lt;/li&gt;
&lt;li&gt;Standardize building of your Protobuf files with a common configuration, abstracting away all of the pain of protoc for you.&lt;/li&gt;
&lt;li&gt;Lint your Protobuf files with common linting rules according to a Style Guide.&lt;/li&gt;
&lt;li&gt;Format your Protobuf files in a consistent manner.&lt;/li&gt;
&lt;li&gt;Generate stubs using any plugin based on a simple configuration file, including handling imports of all the Well-Known Types.&lt;/li&gt;
&lt;li&gt;Call gRPC endpoints with ease, taking care of the JSON to binary conversion for you.&lt;/li&gt;
&lt;li&gt;Output errors and lint failures in a common file:line:column:message format, making integration with editors possible, Vim integration is provided out of the box.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Prototool accomplishes this by downloading and calling protoc on the fly for you, handing error messages from protoc and your plugins, and using the generated FileDescriptorSets for internal functionality, as well as wrapping a few great external libraries already in the Protobuf ecosystem.&lt;/p&gt;
&lt;h2&gt;Current Status&lt;/h2&gt;
&lt;p&gt;Prototool is stil in the early alpha stages, and should not be used in production yet. Expect significant breaking changes before the v1.0 release. To help with development, head to the &lt;a href=&quot;https://github.com/uber/prototool#development&quot;&gt;Development&lt;/a&gt; section and follow along!&lt;/p&gt;
&lt;h2&gt;Installation&lt;/h2&gt;
&lt;p&gt;Install Prototool from GitHub Releases.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;curl -sSL https://github.com/uber/prototool/releases/download/v0.1.0/prototool-$(uname -s)-$(uname -m) \
  -o /usr/local/bin/prototool &amp;amp;&amp;amp; \
  chmod +x /usr/local/bin/prototool &amp;amp;&amp;amp; \
  prototool -h
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;Quick Start&lt;/h2&gt;
&lt;p&gt;We'll start with a general overview of the commands. There are more commands, and we will get into usage below, but this shows the basic functionality.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;prototool help
prototool lint path/to/foo.proto path/to/bar.proto # file mode, specify multiple specific files
prototool lint idl/uber # directory mode, search for all .proto files recursively, obeying exclude_paths in prototool.yaml files
prototool lint # same as &quot;prototool lint .&quot;, by default the current directory is used in directory mode
prototool files idl/uber # list the files that will be used after applying exclude_paths from corresponding prototool.yaml files
prototool list-linters # list all current lint rules being used
prototool compile idl/uber # make sure all .proto files in idl/uber compile, but do not generate stubs
prototool gen idl/uber # generate stubs, see the generation directives in the config file example
prototool protoc-commands idl/uber # print out the protoc commands that would be invoked with prototool compile idl/uber
prototool protoc-commands --gen idl/uber # print out the protoc commands that would be invoked with prototool gen idl/uber
prototool grpc idl/uber 0.0.0.0:8080 foo.ExcitedService/Exclamation '{&quot;value&quot;:&quot;hello&quot;}' # call the foo.ExcitedService method Exclamation with the given data on 0.0.0.0:8080
cd $(prototool download) # download prints out the cached protoc dir, so this changes to the cache directory
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;Full Example&lt;/h2&gt;
&lt;p&gt;See the &lt;a href=&quot;https://github.com/uber/prototool/blob/dev/example&quot;&gt;example&lt;/a&gt; directory.&lt;/p&gt;
&lt;p&gt;The make command &lt;code&gt;make example&lt;/code&gt; runs prototool while installing the necessary plugins.&lt;/p&gt;
&lt;h2&gt;Configuration&lt;/h2&gt;
&lt;p&gt;Prototool operates using a config file named &lt;code&gt;prototool.yaml&lt;/code&gt;. For non-trivial use, you should have a config file checked in to at least the root of your repository. It is important because the directory of an associated config file is passed to &lt;code&gt;protoc&lt;/code&gt; as an include directory with &lt;code&gt;-I&lt;/code&gt;, so this is the logical location your Protobuf file imports should start from.&lt;/p&gt;
&lt;p&gt;Recommended base config file:&lt;/p&gt;
&lt;div class=&quot;highlight highlight-source-yaml&quot;&gt;
&lt;pre&gt;
&lt;span class=&quot;pl-ent&quot;&gt;protoc_version&lt;/span&gt;: &lt;span class=&quot;pl-s&quot;&gt;3.5.1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The command &lt;code&gt;prototool init&lt;/code&gt; will generate a config file in the current directory with all available configuration options commented out except &lt;code&gt;protoc_version&lt;/code&gt;. See &lt;a href=&quot;https://github.com/uber/prototool/blob/dev/etc/config/example/prototool.yaml&quot;&gt;etc/config/example/prototool.yaml&lt;/a&gt; for the config file that &lt;code&gt;prototool init --uncomment&lt;/code&gt; generates.&lt;/p&gt;
&lt;p&gt;When specifying a directory or set of files for Prototool to operate on, Prototool will search for config files for each directory starting at the given path, and going up a directory until hitting root. If no config file is found, Prototool will use default values and operate as if there was a config file in the current directory, including the current directory with &lt;code&gt;-I&lt;/code&gt; to &lt;code&gt;protoc&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;While almost all projects should not have multiple &lt;code&gt;prototool.yaml&lt;/code&gt; files (and this &lt;a href=&quot;https://github.com/uber/prototool/issues/10&quot;&gt;may be enforced before v1.0&lt;/a&gt;), as of now, multiple &lt;code&gt;prototool.yaml&lt;/code&gt; files corresponding to multiple found directories with Protobuf files may be used. For example, if you have the following layout:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;.
├── a
│   ├── d
│   │   ├── file.proto
│   │   ├── file2.proto
│   │   ├── file3.proto
│   │   └── prototool.yaml
│   ├── e
│   │   └── file.proto
│   ├── f
│   │   └── file.proto
│   └── file.proto
├── b
│   ├── file.proto
│   ├── g
│   │   └── h
│   │       └── file.proto
│   └── prototool.yaml
├── c
│   ├── file.proto
│   └── i
│       └── file.proto
└── prototool.yaml
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Everything under &lt;code&gt;a/d&lt;/code&gt; will use &lt;code&gt;a/d/prototool.yaml&lt;/code&gt;, everything under &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;b/g/h&lt;/code&gt; will use &lt;code&gt;b/prototool.yaml&lt;/code&gt;, and everything under &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;a/e&lt;/code&gt;, &lt;code&gt;a/f&lt;/code&gt;, &lt;code&gt;c&lt;/code&gt;, &lt;code&gt;c/i&lt;/code&gt; will use &lt;code&gt;prototool.yaml&lt;/code&gt;. See &lt;a href=&quot;https://github.com/uber/prototool/blob/dev/internal/x/file/testdata&quot;&gt;internal/x/file/testdata&lt;/a&gt; for the most current example.&lt;/p&gt;
&lt;h2&gt;File Discovery&lt;/h2&gt;
&lt;p&gt;In most Prototool commands, you will see help along the following lines:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ prototool help lint
Lint proto files and compile with protoc to check for failures.

Usage:
  prototool lint dirOrProtoFiles... [flags]

Flags:
      --dir-mode   Run as if the directory the file was given, but only print the errors from the file. Useful for integration with editors.
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;dirOrProtoFiles...&lt;/code&gt; can take multiple forms:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;You can specify multiple files. If this is done, these files will be explicitly used for &lt;code&gt;protoc&lt;/code&gt; calls.&lt;/li&gt;
&lt;li&gt;You can specify exactly one directory. If this is done, Prototool goes up until it finds a &lt;code&gt;prototool.yaml&lt;/code&gt; file (or uses the current directory if none is found), and then walks starting at this location for all &lt;code&gt;.proto&lt;/code&gt; files, and these are used, except for files in the &lt;code&gt;excludes&lt;/code&gt; lists in &lt;code&gt;prototool.yaml&lt;/code&gt; files.&lt;/li&gt;
&lt;li&gt;You can specify exactly one file, along with &lt;code&gt;--dir-mode&lt;/code&gt;. This has the effect as if you specified the directory of this file (using the logic above), but errors are only printed for that file. This is useful for e.g. Vim integration.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;The idea with &quot;directory builds&quot; is that you often need more than just one file to do a &lt;code&gt;protoc&lt;/code&gt; call, for example if you have types in other files in the same package that are not referenced by their fully-qualified name, and/or if you need to know what directories to specify with &lt;code&gt;-I&lt;/code&gt; to &lt;code&gt;protoc&lt;/code&gt; (by default, the directory of the &lt;code&gt;prototool.yaml&lt;/code&gt; file is used).&lt;/p&gt;
&lt;p&gt;In general practice, directory builds are what you always want to do. File builds were just added for convenience, and &lt;a href=&quot;https://github.com/uber/prototool/issues/16&quot;&gt;may be removed&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Command Overview&lt;/h2&gt;
&lt;p&gt;Let's go over some of the basic commands. There are more commands than listed here, and &lt;a href=&quot;https://github.com/uber/prototool/issues/11&quot;&gt;some may be removed before v1.0&lt;/a&gt;, but the following commands are what you mostly need to know.&lt;/p&gt;
&lt;h5&gt;&lt;code&gt;prototool init&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;Create a &lt;code&gt;prototool.yaml&lt;/code&gt; file in the current directory, with all options except &lt;code&gt;protoc_version&lt;/code&gt; commented out.&lt;/p&gt;
&lt;h5&gt;&lt;code&gt;prototool compile&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;Compile your Protobuf files, but do not generate stubs. This has the effect of calling &lt;code&gt;protoc&lt;/code&gt; with &lt;code&gt;-o /dev/null&lt;/code&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;code&gt;prototool gen&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;Compile your Protobuf files and generate stubs according to the rules in your &lt;code&gt;prototool.yaml&lt;/code&gt; file. See &lt;a href=&quot;https://github.com/uber/prototool/blob/dev/example/idl/uber/prototool.yaml&quot;&gt;example/idl/uber/prototool.yaml&lt;/a&gt; for an example.&lt;/p&gt;
&lt;h5&gt;&lt;code&gt;prototool lint&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;Lint your Protobuf files. The default rule set follows the Style Guide at &lt;a href=&quot;https://github.com/uber/prototool/blob/dev/etc/style/uber/uber.proto&quot;&gt;etc/style/uber/uber.proto&lt;/a&gt;. You can add or exclude lint rules in your &lt;code&gt;prototool.yaml&lt;/code&gt; file. The default rule set is &quot;strict&quot;, and we are working on having two main sets of rules, as well as refining the Style Guide, in &lt;a href=&quot;https://github.com/uber/prototool/issues/3&quot;&gt;this issue&lt;/a&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;code&gt;prototool format&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;Format a Protobuf file and print the formatted file to stdout. There are flags to perform different actions:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;-d&lt;/code&gt; Write a diff instead.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-l&lt;/code&gt; Write a lint error in the form file:line:column:message if a file is unformatted.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-w&lt;/code&gt; Overwrite the existing file instead.&lt;/li&gt;
&lt;/ul&gt;&lt;h5&gt;&lt;code&gt;prototool files&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;Print the list of all files that will be used given the input &lt;code&gt;dirOrProtoFiles...&lt;/code&gt;. Useful for debugging.&lt;/p&gt;
&lt;h5&gt;&lt;code&gt;prototool protoc-commands&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;Print all &lt;code&gt;protoc&lt;/code&gt; commands that would be run on &lt;code&gt;prototool compile&lt;/code&gt;. Add the &lt;code&gt;--gen&lt;/code&gt; flag to print all commands that would be run on &lt;code&gt;prototool gen&lt;/code&gt;.&lt;/p&gt;
&lt;h5&gt;&lt;code&gt;prototool grpc&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;Call a gRPC endpoint using a JSON input. What this does behind the scenes:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Compiles your Protobuf files with &lt;code&gt;protoc&lt;/code&gt;, generating a &lt;code&gt;FileDescriptorSet&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Uses the &lt;code&gt;FileDescriptorSet&lt;/code&gt; to figure out the request and response type for the endpoint, and to convert the JSON input to binary.&lt;/li&gt;
&lt;li&gt;Calls the gRPC endpoint.&lt;/li&gt;
&lt;li&gt;Uses the &lt;code&gt;FileDescriptorSet&lt;/code&gt; to convert the resulting binary back to JSON, and prints it out for you.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;All these steps take on the order of milliseconds, for example the overhead for a file with four dependencies is about 30ms, so there is little overhead for CLI calls to gRPC.&lt;/p&gt;
&lt;h2&gt;gRPC Example&lt;/h2&gt;
&lt;p&gt;There is a full example for gRPC in the &lt;a href=&quot;https://github.com/uber/prototool/blob/dev/example&quot;&gt;example&lt;/a&gt; directory. Run &lt;code&gt;make init example&lt;/code&gt; to make sure everything is installed and generated.&lt;/p&gt;
&lt;p&gt;Start the example server in a separate terminal by doing &lt;code&gt;go run example/cmd/excited/main.go&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;prototool grpc dirOrProtoFiles... serverAddress package.service/Method requestData&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;requestData&lt;/code&gt; can either be the JSON data to input, or &lt;code&gt;-&lt;/code&gt; which will result in the input being read from stdin.&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ make init example # make sure everything is built just in case

$ cat input.json
{&quot;value&quot;:&quot;hello&quot;}

$ cat input.json | prototool grpc example 0.0.0.0:8080 foo.ExcitedService/Exclamation -
{
  &quot;value&quot;: &quot;hello!&quot;
}

$ cat input.json | prototool grpc example 0.0.0.0:8080 foo.ExcitedService/ExclamationServerStream -
{
  &quot;value&quot;: &quot;h&quot;
}
{
  &quot;value&quot;: &quot;e&quot;
}
{
  &quot;value&quot;: &quot;l&quot;
}
{
  &quot;value&quot;: &quot;l&quot;
}
{
  &quot;value&quot;: &quot;o&quot;
}
{
  &quot;value&quot;: &quot;!&quot;
}

$ cat input.json
{&quot;value&quot;:&quot;hello&quot;}
{&quot;value&quot;:&quot;salutations&quot;}

$ cat input.json | prototool grpc example 0.0.0.0:8080 foo.ExcitedService/ExclamationClientStream -
{
  &quot;value&quot;: &quot;hellosalutations!&quot;
}

$ cat input.json | prototool grpc example 0.0.0.0:8080 foo.ExcitedService/ExclamationBidiStream -
{
  &quot;value&quot;: &quot;hello!&quot;
}
{
  &quot;value&quot;: &quot;salutations!&quot;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;Tips and Tricks&lt;/h2&gt;
&lt;p&gt;Prototool is meant to help enforce a consistent development style for Protobuf, and as such you should follow some basic rules:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Have all your imports start from the directory your &lt;code&gt;prototool.yaml&lt;/code&gt; is in. While there is a configuration option &lt;code&gt;protoc_includes&lt;/code&gt; to denote extra include directories, this is not recommended.&lt;/li&gt;
&lt;li&gt;Have all Protobuf files in the same directory use the same &lt;code&gt;package&lt;/code&gt;, and use the same values for &lt;code&gt;go_package&lt;/code&gt; and &lt;code&gt;java_package&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Do not use long-form &lt;code&gt;go_package&lt;/code&gt; values, ie use &lt;code&gt;foopb&lt;/code&gt;, not &lt;code&gt;github.com/bar/baz/foo;foopb&lt;/code&gt;. This helps &lt;code&gt;prototool gen&lt;/code&gt; do the best job.&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Vim Integration&lt;/h2&gt;
&lt;p&gt;This repository is a self-contained plugin for use with the &lt;a href=&quot;https://github.com/w0rp/ale&quot;&gt;ALE Lint Engine&lt;/a&gt;. It should be similarly easy to add support for Syntastic, Neomake, etc later.&lt;/p&gt;
&lt;p&gt;The Vim integration will currently provide lint errors, optionally regenerate all the stubs, and optionally format your files on save.&lt;/p&gt;
&lt;p&gt;The plugin is under &lt;a href=&quot;https://github.com/uber/prototool/blob/dev/vim/prototool&quot;&gt;vim/prototool&lt;/a&gt;, so your plugin manager needs to point there instead of the base of this repository. Assuming you are using Vundle, copy/paste &lt;a href=&quot;https://github.com/uber/prototool/blob/dev/etc/vim/example/vimrc&quot;&gt;etc/vim/example/vimrc&lt;/a&gt; into your vimrc and you should be good to go.&lt;/p&gt;
&lt;p&gt;Editor integration is a key goal of Prototool. We've demonstrated support internally for Intellij, and hope that we have integration for more editors in the future.&lt;/p&gt;
&lt;h2&gt;Development&lt;/h2&gt;
&lt;p&gt;Prototool is under active development, if you want to help, here's some places to start:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Try out &lt;code&gt;prototool&lt;/code&gt; and file issues, including points that are unclear in the documentation.&lt;/li&gt;
&lt;li&gt;Put up PRs with any changes you'd like to see made. We can't guarantee that many PRs will get merged for now, but we appreciate any input!&lt;/li&gt;
&lt;li&gt;Follow along on the &lt;a href=&quot;https://github.com/uber/prototool/issues?q=is%3Aissue+is%3Aopen+label%3A%22big+ticket+item%22&quot;&gt;big ticket items&lt;/a&gt; to see the major development points.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Over the coming months, we hope to push to a v1.0.&lt;/p&gt;
&lt;p&gt;A note on package layout: all Golang code except for &lt;code&gt;cmd/prototool/main.go&lt;/code&gt; is purposefully under the &lt;code&gt;internal&lt;/code&gt; package to not expose any API for the time being. Within the internal package, anything under &lt;code&gt;internal/x&lt;/code&gt; has not been reviewed, and is especially unstable. Any package in &lt;code&gt;internal&lt;/code&gt; not in &lt;code&gt;internal/x&lt;/code&gt; has been fully reviewed and is more stable.&lt;/p&gt;
&lt;h2&gt;Special Thanks&lt;/h2&gt;
&lt;p&gt;Prototool uses some external libraries that deserve special mention and thanks for their contribution to Prototool's functionality:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/emicklei/proto&quot;&gt;github.com/emicklei/proto&lt;/a&gt; - The Golang Protobuf parsing library that started it all, and is still used for the linting and formatting functionality. We can't thank Ernest Micklei enough for his help and putting up with all the &lt;a href=&quot;https://github.com/emicklei/proto/issues?q=is%3Aissue+is%3Aclosed&quot;&gt;filed issues&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/jhump/protoreflect&quot;&gt;github.com/jhump/protoreflect&lt;/a&gt; - Used for the JSON to binary and back conversion. Josh Humphries is an amazing developer, thank you so much.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/fullstorydev/grpcurl&quot;&gt;github.com/fullstorydev/grpcurl&lt;/a&gt; - Still used for the gRPC functionality. Again a thank you to Josh Humphries and the team over at FullStory for their work.&lt;/li&gt;
&lt;/ul&gt;&lt;/article&gt;</description>
<pubDate>Wed, 11 Apr 2018 15:40:56 +0000</pubDate>
<dc:creator>_mway</dc:creator>
<og:image>https://avatars0.githubusercontent.com/u/538264?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>uber/prototool</og:title>
<og:url>https://github.com/uber/prototool</og:url>
<og:description>prototool - Your Swiss Army Knife for Protocol Buffers</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/uber/prototool</dc:identifier>
</item>
<item>
<title>Sneak Peek at WebAssembly Studio</title>
<link>https://hacks.mozilla.org/2018/04/sneak-peek-at-webassembly-studio/</link>
<guid isPermaLink="true" >https://hacks.mozilla.org/2018/04/sneak-peek-at-webassembly-studio/</guid>
<description>&lt;p&gt;&lt;a class=&quot;markup--anchor markup--p-anchor&quot; href=&quot;https://webassembly.studio/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; data-href=&quot;https://webassembly.studio/&quot;&gt;WebAssembly.Studio&lt;/a&gt; is an online IDE (integrated development environment) that helps you learn and teach others about WebAssembly. It’s also a Swiss Army knife that comes in handy whenever working with WebAssembly.&lt;/p&gt;&lt;p class=&quot;graf graf--p&quot;&gt;We started working on WebAssembly Studio in late December 2017, in an attempt to merge two existing tools that we had developed: &lt;a class=&quot;markup--anchor markup--p-anchor&quot; href=&quot;https://mbebenita.github.io/WasmExplorer/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; data-href=&quot;https://mbebenita.github.io/WasmExplorer/&quot;&gt;WasmExplorer&lt;/a&gt; and &lt;a class=&quot;markup--anchor markup--p-anchor&quot; href=&quot;https://wasdk.github.io/WasmFiddle/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; data-href=&quot;https://wasdk.github.io/WasmFiddle/&quot;&gt;WasmFiddle&lt;/a&gt;. Since then, thanks to several contributors who jumped into the project early, we’ve made quite a bit of progress. We’ve merged those two tools and added several new features. Our beta (more like an alpha) release is now live at &lt;a class=&quot;markup--anchor markup--p-anchor&quot; href=&quot;https://webassembly.studio&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; data-href=&quot;https://webassembly.studio&quot;&gt;https://webassembly.studio&lt;/a&gt; and we are very interested in your feedback.&lt;/p&gt;
&lt;p&gt;&lt;iframe width=&quot;500&quot; height=&quot;281&quot; src=&quot;https://www.youtube.com/embed/2AQWR7Ly7EE?feature=oembed&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/p&gt;
&lt;h3 class=&quot;graf graf--h3&quot;&gt;Quick Start&lt;/h3&gt;
&lt;p class=&quot;graf graf--p&quot;&gt;To get started with the example above, simply click &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Build&lt;/strong&gt; and then &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Run&lt;/strong&gt;. WebAssembly Studio first compiles &lt;code&gt;main.c&lt;/code&gt; to &lt;code&gt;out/main.wasm&lt;/code&gt; and then creates an iframe sandbox in which it loads &lt;code&gt;main.html&lt;/code&gt;. The HTML file loads &lt;code&gt;main.js&lt;/code&gt; which loads and executes the WebAssembly module that ultimately prints “Hello World”. To understand exactly what’s going on, read the README.md file included in the project. This is an example I put together to show how C programs interact with WebAPIs. Our hope is that others will put together interesting examples and use WebAssembly Studio as a teaching tool.&lt;/p&gt;
&lt;h3 class=&quot;graf graf--h3&quot;&gt;Overview of Features&lt;/h3&gt;
&lt;h4 class=&quot;graf graf--h4&quot;&gt;C/C++/Rust Support&lt;/h4&gt;
&lt;p class=&quot;graf graf--p&quot;&gt;WebAssembly Studio has basic (very primitive) support for C, C++ and Rust out of the box. At the moment, compilation services run mostly server-side but we’re hoping to do more of this work on the client.&lt;/p&gt;
&lt;h4 class=&quot;graf graf--h4&quot;&gt;Editable Compiler Artifacts&lt;/h4&gt;
&lt;p class=&quot;graf graf--p&quot;&gt;WebAssembly binary modules (.wasm) as well as text files (.wat) are fully editable in WebAssembly Studio. Try opening &lt;code&gt;out/main.wasm&lt;/code&gt; and you’ll see the disassembled .wat output. You can actually edit this text, and when you save, the original .wasm file will be reassembled.&lt;/p&gt;
&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/mainwasm1.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-32162&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/mainwasm1.png&quot; alt=&quot;&quot; srcset=&quot;https://hacks.mozilla.org/files/2018/04/mainwasm1.png 1206w, https://hacks.mozilla.org/files/2018/04/mainwasm1-250x107.png 250w, https://hacks.mozilla.org/files/2018/04/mainwasm1-768x327.png 768w, https://hacks.mozilla.org/files/2018/04/mainwasm1-500x213.png 500w&quot; sizes=&quot;(max-width: 1206px) 100vw, 1206px&quot;/&gt;&lt;/a&gt;Note that you can hover over various keywords in the WebAssembly text format to gain insights into what they do. See below: &lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm2-doc.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-32161&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm2-doc.png&quot; alt=&quot;&quot; width=&quot;932&quot; height=&quot;194&quot; srcset=&quot;https://hacks.mozilla.org/files/2018/04/wasm2-doc.png 932w, https://hacks.mozilla.org/files/2018/04/wasm2-doc-250x52.png 250w, https://hacks.mozilla.org/files/2018/04/wasm2-doc-768x160.png 768w, https://hacks.mozilla.org/files/2018/04/wasm2-doc-500x104.png 500w&quot; sizes=&quot;(max-width: 932px) 100vw, 932px&quot;/&gt;&lt;/a&gt;WebAssembly Documentation
&lt;h4 class=&quot;graf graf--h4&quot;&gt;Easily Accessible Tools&lt;/h4&gt;
&lt;p class=&quot;graf graf--p&quot;&gt;Many of the interesting features in WebAssembly Studio are stashed away under context menus. For instance, if you right-click on the &lt;code&gt;out/main.wasm&lt;/code&gt; file, you’ll see a pop-up menu appear with several commands:&lt;/p&gt;
&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm3context.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-32160&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm3context.png&quot; alt=&quot;&quot;/&gt;&lt;/a&gt;Context Menu for .wasm Files
&lt;p class=&quot;graf graf--p&quot;&gt;You can use these context menu commands to apply various transformations on .wasm files:&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li class=&quot;graf graf--li&quot;&gt;Validate uses &lt;a class=&quot;markup--anchor markup--li-anchor&quot; href=&quot;https://github.com/WebAssembly/binaryen&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; data-href=&quot;https://github.com/WebAssembly/binaryen&quot;&gt;Binaryen&lt;/a&gt; to verify that a WebAssmebly Module is valid.&lt;/li&gt;
&lt;li class=&quot;graf graf--li&quot;&gt;Optimize runs several Binaryen optimization passes over a WebAssembly module.&lt;/li&gt;
&lt;/ul&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm4binaryen.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-32159&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm4binaryen.png&quot; alt=&quot;&quot; srcset=&quot;https://hacks.mozilla.org/files/2018/04/wasm4binaryen.png 1196w, https://hacks.mozilla.org/files/2018/04/wasm4binaryen-250x114.png 250w, https://hacks.mozilla.org/files/2018/04/wasm4binaryen-768x351.png 768w, https://hacks.mozilla.org/files/2018/04/wasm4binaryen-500x228.png 500w&quot; sizes=&quot;(max-width: 1196px) 100vw, 1196px&quot;/&gt;&lt;/a&gt;Optimized with Binaryen
&lt;ul class=&quot;postList&quot;&gt;&lt;li class=&quot;graf graf--li&quot;&gt;Disassemble uses &lt;a class=&quot;markup--anchor markup--li-anchor&quot; href=&quot;https://github.com/WebAssembly/wabt&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; data-href=&quot;https://github.com/WebAssembly/wabt&quot;&gt;Wabt&lt;/a&gt; to convert the file to WebAssembly text format. This can then be edited and reassembled back into a WebAssembly file.&lt;/li&gt;
&lt;/ul&gt;&lt;p class=&quot;graf graf--p&quot;&gt;Some of the commands generate new files, for example “Firefox x86” will produce a .x86 file with the disassembled output from Firefox’s WebAssembly engine. While this may not be very useful (or actionable) to a JavaScript developer, I find it useful when teaching others about WebAssembly. (It’s proof that WebAssembly is low-level!)&lt;/p&gt;
&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm6x86.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-32158&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm6x86.png&quot; alt=&quot;&quot; width=&quot;1058&quot; height=&quot;622&quot; srcset=&quot;https://hacks.mozilla.org/files/2018/04/wasm6x86.png 1058w, https://hacks.mozilla.org/files/2018/04/wasm6x86-250x147.png 250w, https://hacks.mozilla.org/files/2018/04/wasm6x86-768x452.png 768w, https://hacks.mozilla.org/files/2018/04/wasm6x86-500x294.png 500w&quot; sizes=&quot;(max-width: 1058px) 100vw, 1058px&quot;/&gt;&lt;/a&gt;Firefox x86 Disassembly
&lt;ul class=&quot;postList&quot;&gt;&lt;li class=&quot;graf graf--li&quot;&gt;Binary Explorer helps you understand how WebAssembly code is represented at a binary level.&lt;/li&gt;
&lt;/ul&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm7codeexplorer.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-32157&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm7codeexplorer.png&quot; alt=&quot;&quot; width=&quot;1600&quot; height=&quot;584&quot; srcset=&quot;https://hacks.mozilla.org/files/2018/04/wasm7codeexplorer.png 1600w, https://hacks.mozilla.org/files/2018/04/wasm7codeexplorer-250x91.png 250w, https://hacks.mozilla.org/files/2018/04/wasm7codeexplorer-768x280.png 768w, https://hacks.mozilla.org/files/2018/04/wasm7codeexplorer-500x183.png 500w&quot; sizes=&quot;(max-width: 1600px) 100vw, 1600px&quot;/&gt;&lt;/a&gt;Binary Code Explorer &lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm8binfileview.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-32156&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm8binfileview.png&quot; alt=&quot;&quot; width=&quot;1600&quot; height=&quot;367&quot; srcset=&quot;https://hacks.mozilla.org/files/2018/04/wasm8binfileview.png 1600w, https://hacks.mozilla.org/files/2018/04/wasm8binfileview-250x57.png 250w, https://hacks.mozilla.org/files/2018/04/wasm8binfileview-768x176.png 768w, https://hacks.mozilla.org/files/2018/04/wasm8binfileview-500x115.png 500w&quot; sizes=&quot;(max-width: 1600px) 100vw, 1600px&quot;/&gt;&lt;/a&gt;Binary File View
&lt;ul class=&quot;postList&quot;&gt;&lt;li class=&quot;graf graf--li&quot;&gt;Generate Call Graph plots the caller/callee relationships between functions (including imports and exports) to help you understand what’s included in a WebAssembly module.&lt;/li&gt;
&lt;/ul&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm9callgraph.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-32155&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm9callgraph.png&quot; alt=&quot;&quot; width=&quot;1600&quot; height=&quot;794&quot; srcset=&quot;https://hacks.mozilla.org/files/2018/04/wasm9callgraph.png 1600w, https://hacks.mozilla.org/files/2018/04/wasm9callgraph-250x124.png 250w, https://hacks.mozilla.org/files/2018/04/wasm9callgraph-768x381.png 768w, https://hacks.mozilla.org/files/2018/04/wasm9callgraph-500x248.png 500w&quot; sizes=&quot;(max-width: 1600px) 100vw, 1600px&quot;/&gt;&lt;/a&gt;Call Graph
&lt;p class=&quot;graf graf--p&quot;&gt;Some of the features in WebAssembly Studio need hosted back-end services (compilation), but many others run directly in the browser. &lt;a class=&quot;markup--anchor markup--p-anchor&quot; href=&quot;https://github.com/WebAssembly/binaryen/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; data-href=&quot;https://github.com/WebAssembly/binaryen/&quot;&gt;Binaryen&lt;/a&gt;, &lt;a class=&quot;markup--anchor markup--p-anchor&quot; href=&quot;https://github.com/WebAssembly/wabt&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; data-href=&quot;https://github.com/WebAssembly/wabt&quot;&gt;Wabt&lt;/a&gt;, &lt;a class=&quot;markup--anchor markup--p-anchor&quot; href=&quot;https://alexaltea.github.io/capstone.js/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; data-href=&quot;https://alexaltea.github.io/capstone.js/&quot;&gt;Capstone.js&lt;/a&gt; are all compiled to WebAssembly and run in the browser. This has the added benefit that we can scale much more easily, with less load on the server.&lt;/p&gt;
&lt;p class=&quot;graf graf--p&quot;&gt;For a dose of WebAssembly magic, right click on &lt;code&gt;main.c&lt;/code&gt; and select:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm10clang.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-32154&quot; src=&quot;https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2018/04/wasm10clang.png&quot; alt=&quot;&quot; width=&quot;276&quot; height=&quot;66&quot; srcset=&quot;https://hacks.mozilla.org/files/2018/04/wasm10clang.png 276w, https://hacks.mozilla.org/files/2018/04/wasm10clang-250x60.png 250w&quot; sizes=&quot;(max-width: 276px) 100vw, 276px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;graf graf--p&quot;&gt;… that’s right, &lt;a class=&quot;markup--anchor markup--p-anchor&quot; href=&quot;https://github.com/tbfleming/cib&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; data-href=&quot;https://github.com/tbfleming/cib&quot;&gt;Clang Format&lt;/a&gt; is also compiled to WebAssembly, runs locally, and works great.&lt;/p&gt;
&lt;h4 class=&quot;graf graf--h4&quot;&gt;Interactive Embeddings&lt;/h4&gt;
&lt;p class=&quot;graf graf--p&quot;&gt;Interactive embeddings of WebAssembly Studio projects are now possible thanks to &lt;a class=&quot;markup--anchor markup--p-anchor&quot; href=&quot;http://embed.ly&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; data-href=&quot;http://embed.ly&quot;&gt;embed.ly&lt;/a&gt;, a system for embedding interactive content in a wide variety of web &lt;a class=&quot;markup--anchor markup--p-anchor&quot; href=&quot;http://embed.ly/customers&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; data-href=&quot;http://embed.ly/customers&quot;&gt;platforms&lt;/a&gt;, including &lt;a class=&quot;markup--anchor markup--p-anchor&quot; href=&quot;http://embed.ly&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; data-href=&quot;http://embed.ly&quot;&gt;medium.com&lt;/a&gt;. You can simply paste the link to a &lt;strong class=&quot;markup--strong markup--p-strong&quot;&gt;Forked&lt;/strong&gt; project into your medium.com post&lt;/p&gt;
&lt;p&gt;.&lt;/p&gt;
&lt;h3 class=&quot;graf graf--h3&quot;&gt;What’s Next&lt;/h3&gt;
&lt;p class=&quot;graf graf--p&quot;&gt;Over the next few months we’re going to:&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li class=&quot;graf graf--li&quot;&gt;Add better support for C/C++/Rust projects. For C/C++ applications we’re currently using the &lt;a href=&quot;https://llvm.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;LLVM&lt;/a&gt; backend by itself, but we’re also hoping to add support for &lt;a href=&quot;https://github.com/kripken/emscripten&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Emscripten&lt;/a&gt; using that backend so that you can use APIs like SDL and OpenGL. For Rust, we’d like to support Cargo.&lt;/li&gt;
&lt;li class=&quot;graf graf--li&quot;&gt;Continue to add new features and integrate additional tools into WebAssembly Studio.&lt;/li&gt;
&lt;li class=&quot;graf graf--li&quot;&gt;Make it possible to download and build WebAssembly Studio projects locally using familiar tools.&lt;/li&gt;
&lt;li class=&quot;graf graf--li&quot;&gt;Improve UX, error reporting, and general performance optimizations.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Want to learn more or get more involved in this project? Please share feedback, file issues, and add feature requests on the &lt;a href=&quot;https://github.com/wasdk/WebAssemblyStudio&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;WebAssembly Studio&lt;/a&gt; GitHub repo. If you want to get more involved with WebAssembly &lt;a href=&quot;https://github.com/webassembly&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;check out the main repo&lt;/a&gt; to learn more about the project and its infrastructure.&lt;/p&gt;
&lt;section class=&quot;about&quot; readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;a class=&quot;url&quot; href=&quot;https://hacks.mozilla.org/author/mbebenitamozilla-com/&quot;&gt;More articles by Michael Bebenita…&lt;/a&gt;&lt;/p&gt;
&lt;/section&gt;</description>
<pubDate>Wed, 11 Apr 2018 15:00:31 +0000</pubDate>
<dc:creator>lainon</dc:creator>
<og:url>https://hacks.mozilla.org/2018/04/sneak-peek-at-webassembly-studio</og:url>
<og:title>Sneak Peek at WebAssembly Studio – Mozilla Hacks - the Web developer blog</og:title>
<og:description>WebAssembly.Studio is an online IDE (integrated development environment) that helps you learn and teach others. It’s also a Swiss Army knife that comes in handy whenever working with WebAssembly (WASM). ...</og:description>
<og:image>https://hacks.mozilla.org/files/2018/04/Screenshot-2018-4-11-WebAssembly-Studio.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://hacks.mozilla.org/2018/04/sneak-peek-at-webassembly-studio/</dc:identifier>
</item>
<item>
<title>Ask HN: Those making over $300k/year, how did you achieve it?</title>
<link>https://news.ycombinator.com/item?id=16811454</link>
<guid isPermaLink="true" >https://news.ycombinator.com/item?id=16811454</guid>
<description>Recently there was a thread about someone making ~$500k/year at a FAANG company and seeing that there's people who hang out here and make ~$300k/year I always have questions for high income earners. Since I don't know any personally (or at least I think I don't) I'm hoping some are lurking and willing to answer some questions. I've set it to $300k because I think at this range the salary is exceptional even in LA/SF/NYC.
&lt;p&gt;These are my questions and I'm adding my own answers though my income is not really in this range; some are slightly fudged to prevent de-anonymizing.&lt;/p&gt;&lt;p&gt;* What do you do?&lt;/p&gt;
&lt;p&gt;* What is your job title?&lt;/p&gt;
&lt;p&gt;* What is your total comp?&lt;/p&gt;
&lt;p&gt;* Who do you work for?&lt;/p&gt;
&lt;p&gt;* Where do you live (assuming you don't work from home)?&lt;/p&gt;
&lt;p&gt;* How long did it take you to get here?&lt;/p&gt;
&lt;p&gt;* How did you get here (networking/raw technical skill/job board/dumb luck, etc.)?&lt;/p&gt;
&lt;p&gt;* What do you do?&lt;/p&gt;
&lt;p&gt;- I do frontend development for financial applications; think trader dashboards, openfin, etc. I have done backend work previously and actually prefer it to frontend work&lt;/p&gt;
&lt;p&gt;* What is your job title?&lt;/p&gt;
&lt;p&gt;- Associate; a generic corporate title in banking&lt;/p&gt;
&lt;p&gt;* What is your total comp?&lt;/p&gt;
&lt;p&gt;- Last year I made $118k including my yearly bonus and 401k matching&lt;/p&gt;
&lt;p&gt;* Who do you work for?&lt;/p&gt;
&lt;p&gt;- JPMorgan&lt;/p&gt;
&lt;p&gt;* Where do you live (assuming you don't work from home)?&lt;/p&gt;
&lt;p&gt;- A large Texas city; one of Dallas/Houston/San Antonio&lt;/p&gt;
&lt;p&gt;* How long did it take you to get here?&lt;/p&gt;
&lt;p&gt;- 5 years from my first job as a developer&lt;/p&gt;
&lt;p&gt;* How did you get here (networking/raw technical skill/job board/dumb luck, etc.)?&lt;/p&gt;
&lt;p&gt;- It's been a gradual climb; whenever I feel there's no more to learn at my current job I look for another, each move included a pay bump. This job I managed through an acquaintance who offered to put my resume in although I was not looking for a job at the time&lt;/p&gt;
</description>
<pubDate>Wed, 11 Apr 2018 14:35:08 +0000</pubDate>
<dc:creator>thrwunderpaid</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://news.ycombinator.com/item?id=16811454</dc:identifier>
</item>
<item>
<title>EU copyright proposal could undermine the use of Creative Commons licenses</title>
<link>https://creativecommons.org/2018/03/29/head-copyright-committee-wants-deny-eu-creators-right-share/</link>
<guid isPermaLink="true" >https://creativecommons.org/2018/03/29/head-copyright-committee-wants-deny-eu-creators-right-share/</guid>
<description>&lt;p&gt;&lt;span&gt;Over the last few years the European Union has been working on&lt;/span&gt; &lt;a href=&quot;https://juliareda.eu/eu-copyright-reform/&quot;&gt;&lt;span&gt;revising its rules on copyright&lt;/span&gt;&lt;/a&gt;&lt;span&gt;. But the latest&lt;/span&gt; &lt;a href=&quot;https://www.communia-association.org/2018/03/29/mep-voss-doubles-worst-elements-article-11/&quot;&gt;&lt;span&gt;proposal&lt;/span&gt;&lt;/a&gt; &lt;span&gt;from the head of the copyright committee would&lt;/span&gt; &lt;em&gt;&lt;span&gt;deny creators the right to refuse remuneration&lt;/span&gt;&lt;/em&gt; &lt;span&gt;— the right to share a work without getting paid — which could undermine the use of CC licenses if approved.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Ever since the European Commission released a&lt;/span&gt; &lt;a href=&quot;https://creativecommons.org/2016/09/14/european-commission-copyright-proposal-leaves-users-dark/&quot;&gt;&lt;span&gt;lackluster draft Directive on copyright&lt;/span&gt;&lt;/a&gt; &lt;span&gt;in 2016, Creative Commons,&lt;/span&gt; &lt;a href=&quot;https://www.communia-association.org/&quot;&gt;&lt;span&gt;Communia Association&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, and dozens of other organisations have been engaging policymakers in the Parliament to make crucial changes in order to protect user rights and the commons, enable research and education, and promote creativity and business opportunities in the digital market.&lt;/span&gt;&lt;/p&gt;
&lt;a href=&quot;https://www.flickr.com/photos/ter-burg/40034654505/&quot;&gt;&lt;img data-attachment-id=&quot;54438&quot; data-permalink=&quot;https://creativecommons.org/2018/03/29/head-copyright-committee-wants-deny-eu-creators-right-share/fixcopyright-dinosaur/&quot; data-orig-file=&quot;https://d15omoko64skxi.cloudfront.net/wp-content/uploads/2018/03/fixcopyright-dinosaur.jpg&quot; data-orig-size=&quot;1365,2048&quot; data-comments-opened=&quot;0&quot; data-image-meta=&quot;{&amp;quot;aperture&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;credit&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;camera&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;caption&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;created_timestamp&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;copyright&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;focal_length&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;iso&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;shutter_speed&amp;quot;:&amp;quot;0&amp;quot;,&amp;quot;title&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;orientation&amp;quot;:&amp;quot;0&amp;quot;}&quot; data-image-title=&quot;fixcopyright dinosaur&quot; data-image-description=&quot;&quot; data-medium-file=&quot;https://d15omoko64skxi.cloudfront.net/wp-content/uploads/2018/03/fixcopyright-dinosaur.jpg&quot; data-large-file=&quot;https://d15omoko64skxi.cloudfront.net/wp-content/uploads/2018/03/fixcopyright-dinosaur.jpg&quot; class=&quot;wp-image-54438&quot; src=&quot;https://d15omoko64skxi.cloudfront.net/wp-content/uploads/2018/03/fixcopyright-dinosaur.jpg&quot; alt=&quot;&quot; width=&quot;289&quot; height=&quot;434&quot;/&gt;&lt;/a&gt;&lt;a href=&quot;https://www.flickr.com/photos/ter-burg/40034654505/&quot;&gt;Photo&lt;/a&gt; by &lt;a href=&quot;https://www.flickr.com/photos/ter-burg/&quot;&gt;Sebastiaan ter Burg&lt;/a&gt;, &lt;a href=&quot;https://creativecommons.org/publicdomain/zero/1.0/&quot;&gt;CC0&lt;/a&gt;
&lt;p&gt;&lt;span&gt;But as evidenced by the latest proposal, the direction of the copyright reform seems to be getting worse, not better. This week Axel Voss, the lead member of the European parliament (MEP) for the influential legal affairs committee,&lt;/span&gt; &lt;a href=&quot;https://juliareda.eu/wp-content/uploads/2018/03/voss11.pdf&quot;&gt;&lt;span&gt;released&lt;/span&gt;&lt;/a&gt; &lt;span&gt;his own proposed changes to an especially controversial part of the draft Directive, Article 11. This is the provision that would introduce an additional right for press publishers to extract fees from news aggregators for incorporating short snippets of—or even linking to—their content.  &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;This press publisher’s right (also commonly known as the “Link Tax”) already poses a significant threat to an informed and literate society. But Voss wants to amplify its worst features by asserting that press publishers will receive—whether they like it or not—an “inalienable right to obtain an [sic] fair and proportionate remuneration for such uses.” This means that publishers will be&lt;/span&gt; &lt;strong&gt;required&lt;/strong&gt; &lt;span&gt;to demand payment from news aggregators.   &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;This inalienable right directly conflicts with publishers who wish to share freely and openly using Creative Commons licenses. As we’ve&lt;/span&gt; &lt;a href=&quot;https://creativecommons.org/2017/07/19/copyright-law-deny-creators-right-share-freely-let-authors-choose/&quot;&gt;&lt;span&gt;warned before&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, an unwaivable right to compensation would interfere with the operation of open licensing by reserving a special and separate economic right above and beyond the intention of some publishers. For example, the Spanish news site&lt;/span&gt; &lt;a href=&quot;https://www.eldiario.es/&quot;&gt;&lt;span&gt;eldiario.es&lt;/span&gt;&lt;/a&gt; &lt;span&gt;releases all of their content&lt;/span&gt; &lt;a href=&quot;https://www.eldiario.es/licencia/&quot;&gt;&lt;span&gt;online for free&lt;/span&gt;&lt;/a&gt; &lt;span&gt;under the&lt;/span&gt; &lt;a href=&quot;https://creativecommons.org/licenses/by-sa/4.0/&quot;&gt;&lt;span&gt;Creative Commons Attribution-ShareAlike license&lt;/span&gt;&lt;/a&gt;&lt;span&gt;. By doing so, they are granting to the public a worldwide, royalty-free license to use the work under certain terms. Other news publishers in Europe using CC licenses that could also find themselves swept up under this new provision include&lt;/span&gt; &lt;a href=&quot;http://www.lastampa.it/&quot;&gt;&lt;span&gt;La Stampa&lt;/span&gt;&lt;/a&gt;&lt;span&gt;,&lt;/span&gt; &lt;a href=&quot;https://www.20minutos.es/&quot;&gt;&lt;span&gt;20 Minutos&lt;/span&gt;&lt;/a&gt;&lt;span&gt;, and&lt;/span&gt; &lt;a href=&quot;https://www.opendemocracy.net/&quot;&gt;&lt;span&gt;openDemocracy&lt;/span&gt;&lt;/a&gt;&lt;span&gt;.   &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Forcing publishers who use CC to accept additional inalienable rights to be remunerated violates the letter and spirit of Creative Commons licensing and denies publishers the freedom to conduct business and share content as they wish. The proposal would pose an existential threat to the over 1.3 billion CC-licensed works online, shared freely by hundreds of millions of creators from around the world.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;We support authors and creators, and we firmly believe in their right to choose to share, or to seek compensation for all or some uses of their works. At the same time, we must find solutions that also honor those au&lt;/span&gt;&lt;span&gt;thors who choose to share with few or no restrictions.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Voss’ proposal must be rejected, and&lt;/span&gt; &lt;a href=&quot;https://www.communia-association.org/2016/12/14/commissions-proposal-new-rights-press-publishers-terrible-solution-good-no-one/&quot;&gt;&lt;span&gt;Article 11 should be deleted&lt;/span&gt;&lt;/a&gt;&lt;span&gt;. It’s been clear all along that an additional right for press publishers won’t do much of anything to support quality journalism or grow the digital single market. Instead, it will negatively affect access to information and the ability for publishers to share using the platforms, technologies, and terms beneficial to them.&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;post-category&quot;&gt;&lt;span class=&quot;tags-label&quot;&gt;Category:&lt;/span&gt;&lt;span class=&quot;categories-links&quot;&gt;&lt;a href=&quot;https://creativecommons.org/category/policy-advocacy-copyright-reform/&quot; rel=&quot;category tag&quot;&gt;Policy / advocacy / copyright reform&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;


</description>
<pubDate>Wed, 11 Apr 2018 13:48:29 +0000</pubDate>
<dc:creator>c3o</dc:creator>
<og:type>article</og:type>
<og:title>Head of copyright committee wants to deny EU creators the right to share - Creative Commons</og:title>
<og:description>Over the last few years the European Union has been working on revising its rules on copyright. But the latest proposal from the head of the copyright committee would deny creators the right to refuse remuneration — the right to share a work without getting paid — which could undermine the use of CC licenses … Read More &quot;Head of copyright committee wants to deny EU creators the right to share&quot;</og:description>
<og:url>https://creativecommons.org/2018/03/29/head-copyright-committee-wants-deny-eu-creators-right-share/</og:url>
<og:image>https://d15omoko64skxi.cloudfront.net/wp-content/uploads/2018/03/fixcopyright-dinosaur.jpg</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://creativecommons.org/2018/03/29/head-copyright-committee-wants-deny-eu-creators-right-share/</dc:identifier>
</item>
<item>
<title>A Taxonomy of Technical Debt</title>
<link>https://engineering.riotgames.com/news/taxonomy-tech-debt</link>
<guid isPermaLink="true" >https://engineering.riotgames.com/news/taxonomy-tech-debt</guid>
<description>&lt;p dir=&quot;ltr&quot;&gt;Hi there. I’m Bill “LtRandolph” Clark, and I’m the engineering manager for the Champions team on &lt;em&gt;LoL&lt;/em&gt;. I’ve worked on several different teams on &lt;em&gt;League&lt;/em&gt; over the past years, but one focus has been consistent: I’m obsessed with tech debt. I want to find it, I want to understand it, and where possible, I want to fix it.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;When engineers talk about any existing piece of technology - for example &lt;em&gt;League of Legends&lt;/em&gt; &lt;a href=&quot;https://na.leagueoflegends.com/en/news/game-updates/patch/patch-84-notes&quot; target=&quot;_blank&quot;&gt;patch 8.4&lt;/a&gt; - we often talk about tech debt. I define tech debt as code or data that future developers will pay a cost for. Countless blog posts, articles, and definitions have been written about this scourge of software development. This post will focus on types of tech debt I’ve seen during my time working at Riot, and a model for discussing it that we’re starting to use internally. If you only take away one lesson from this article, I hope you remember the “contagion” metric discussed below.&lt;/p&gt;
&lt;p class=&quot;rtecenter&quot; dir=&quot;ltr&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://engineering.riotgames.com/sites/default/files/Taxonomy_sebastian_final.png&quot;/&gt;&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;In order to make good decisions about what problems to fix &lt;em&gt;now&lt;/em&gt; and what to fix &lt;em&gt;eventually&lt;/em&gt; (or, realistically, never), we need a way to measure a particular piece of tech debt. I’ve identified 3 major axes to evaluate on: impact, fix cost, and contagion.&lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;Impact&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://engineering.riotgames.com/sites/default/files/Taxonomy_1_Impact.png&quot;/&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;The first axis is the most obvious: the impact of the debt. This takes the form of player-facing issues (bugs, missing features, unexpected behavior), and developer-facing issues (slower implementation, workflow issues, random useless shit to remember). It’s worth noting that “developer” in this case can be anyone of any discipline. Some tech debt gets in the way of engineers writing new code, some blocks designers creating new scripts, some interferes with VFX artists making new particles, etc.&lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;Fix Cost&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://engineering.riotgames.com/sites/default/files/Taxonomy_2_Fix_Cost.png&quot;/&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;The second axis has to do with the cost to fix the tech debt. If we decide to fix an issue in our code or data, it will require someone’s measurable time to fix. If it’s a deeply rooted assumption that affects every line of code in the game, it may take weeks or months of engineering time. If it’s a dumb error in a single function, it may be fixable in a matter of minutes. Regardless of the time to implement a fix, though, we also must consider the risk of actually deploying that fix. Even a system I consider “wrong” can still be used as a tool to make a great game. If I change the way our scripting engine handles errors, or how particles compute their spawn time, that could break any of the 500+ spells on 140+ champions in the game.&lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;Contagion&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://engineering.riotgames.com/sites/default/files/Taxonomy_3_Contagion.png&quot;/&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;The third axis is something I’ve become obsessed with: contagion. If this tech debt is allowed to continue to exist, how much will it spread? That spreading can result from other systems interfacing with the afflicted system, from copy-pasting data built on top of the system, or from influencing the way other engineers will choose to implement new features.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;If a piece of tech debt is well-contained, the cost to fix it later compared to now is basically identical. You can weigh how much impact it has today when determining when a fix makes sense. If, on the other hand, a piece of tech debt is highly contagious, it will steadily become harder and harder to fix. What’s particularly gross about contagious tech debt is that its impact tends to increase as more and more systems become infected by the technical compromise at its core.&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;Now that we have a framework for measuring a particular piece of tech debt, let’s talk about some broad categories of tech debt that I’ve seen on &lt;em&gt;League of Legends&lt;/em&gt;.&lt;/p&gt;
&lt;h2 dir=&quot;ltr&quot;&gt;Local Debt&lt;/h2&gt;
&lt;p dir=&quot;ltr&quot;&gt;Local debt resembles the classic “black box” model of programming. As far as the rest of the game is concerned, the local system (spell, network layer, script engine) works pretty reliably. No one needs to keep the debt in mind as they develop around the system. But if anyone opens the lid and looks inside, they’ll be horrified, disgusted, or completely confused by what they see.&lt;/p&gt;
&lt;p class=&quot;rtecenter&quot; dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://engineering.riotgames.com/sites/default/files/Taxonomy_4_Eyeball.png&quot;/&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;You can find a couple real world examples of local debt in your eyes. Due to how the eye is constructed, you see things upside down. More significantly, the retinal nerve creates a blind spot near the middle of each eye. This malformed data is sent to the visual centers of the brain, which must flip the image and fill the blind spots so the rest of the brain can interact with the “correct” image. These oddities are localized to the eye/optic nerve system and easily avoided by other systems, so they’re “good enough.”&lt;/p&gt;
&lt;p class=&quot;rtecenter&quot; dir=&quot;ltr&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://engineering.riotgames.com/sites/default/files/A%20Taxonomy%20of%20Tech%20Debt%20Alt%20Header.png&quot;/&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;One of the most famous instances of local debt in &lt;em&gt;League of Legends&lt;/em&gt; is Jarvan’s Cataclysm, which is made of minions to this day. When designers need to attach gameplay effects to a location (or a set of locations), one of the tools available to them is the ability to spawn an “invisible minion.” RiotXypherous describes what I mean by “minion” &lt;a href=&quot;https://www.reddit.com/r/leagueoflegends/comments/3t0d0x/ward_debris_is_coded_as_minions_and_it_counts/cx2ilvf/&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;. These game objects are a stable and well-understood way to track and execute scripted logic. In cases like Jarvan’s wall, you need to spawn a high number of minions (24 to be precise) to make sure that no one can squeeze through the wall. An alternate solution could be a ring-terrain construct consisting of a single logical piece controlling the pathability of Cataclysm. If we took this approach, we could clean up the logic and slightly reduce computation cost. Let’s take a look at cataclysm using our impact, fix cost, and contagion model to see why a fix isn’t currently the best option.&lt;/p&gt;
&lt;h2 dir=&quot;ltr&quot;&gt;Cataclysm Metrics&lt;/h2&gt;
&lt;p class=&quot;rtecenter&quot; dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://engineering.riotgames.com/sites/default/files/Taxonomy_6_Cataclysm_Metrics.png&quot;/&gt;&lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;1.    Impact: 1 / 5&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;Back when there were 12 minions, people would occasionally squeak through the wall, so Riot Exgeniar bumped it to 24. The fact that the wall is made of minions pretty much never influences any other developer as they make new content. (As an aside, the infamous “&lt;a href=&quot;https://clips.twitch.tv/FlaccidEncouragingCamelSSSsss&quot; target=&quot;_blank&quot;&gt;Jarvan Ult Hitch&lt;/a&gt;” was due to the confluence between this debt and a loading bug from trying to read missing auto-attack definitions.)&lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;2.    Fix cost: 2 / 5&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;We don’t currently have the ability to composite shapes to create custom geometry without new code. If we wanted to create a ring shape to do an “area trigger” to more efficiently enforce Jarvan’s barrier, we would have to write some bespoke math to calculate collisions with a ring. We’re exploring &lt;a href=&quot;https://en.wikipedia.org/wiki/Constructive_solid_geometry&quot; target=&quot;_blank&quot;&gt;Constructive Solid Geometry&lt;/a&gt; for other purposes, which may cataclysmically reduce the cost to fix.&lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;3.    Contagion: 1 / 5&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;No one needs to take the implementation of Jarvan’s wall into account when developing features, which keeps it well contained. The one risk of contagion is other designers copy/pasting the implementation into their new champions (which has happened here and there). But as far as implementation problems go, the potential spread of Cataclysm is low and well understood.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;This is a pretty typical shape for local debt. In general, local debt is defined by a low contagion score. If the impact is higher than the cost to fix, it tends to get fixed by a good citizen before too long.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;When considering whether to fix local debt, first ask yourself if it’s worth it. If the debt is truly not contagious, it should be safe to leave alone for as long as necessary. One of the biggest mistakes I observe is an instinct to jump on local debt that itches an engineer’s perfectionist side when it doesn’t have a broad enough impact to warrant the effort. If you do decide to make a fix, it’s usually easy to confirm the fix and regression test, due to the locality of the change.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;Some recent examples of local debt that has been fixed include bugs with inhibitors causing champions to path towards 0,0,0 in certain circumstances, Janna’s Monsoon ignoring spell shields, and Tear of the Goddess stacking on manaless casts.&lt;/p&gt;
&lt;h2 dir=&quot;ltr&quot;&gt;MacGyver Debt&lt;/h2&gt;
&lt;p dir=&quot;ltr&quot;&gt;MacGyver debt is named after the TV show from the mid 80s. Angus MacGyver would solve problems using his swiss army knife, duct tape, and whatever else was on hand.&lt;/p&gt;
&lt;p class=&quot;rtecenter&quot; dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://engineering.riotgames.com/sites/default/files/Taxonomy_7_MacGyver.png&quot;/&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;His solutions often involved attaching two unlikely pieces; in the context of tech debt, this means two conflicting systems are “duct-taped” together at their interface points throughout the codebase.&lt;/p&gt;
&lt;p class=&quot;rtecenter&quot; dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://engineering.riotgames.com/sites/default/files/Taxonomy_8_City_Planning.png&quot;/&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;Seattle (among other cities) has a dramatic example of MacGyver debt as you can see above. The city used to have two competing settlements, each with its own grid. When those settlements grew into the modern Emerald City, the slightly different grids were mushed together, resulting in awkwardly shaped blocks and buildings and a less-than-efficient use of space. I’m particularly amused by the little shaved-off corner of the building in the bottom left.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;One of the best examples of MacGyver debt in the &lt;em&gt;LoL&lt;/em&gt; codebase is the use of C++’s std::string vs. our custom AString class. Both are ways to store, modify, and pass around strings of characters. In general, we’ve found that std::string leads to lots of “hidden” memory allocations and performance costs, and makes it easy to write code that does bad things. AString is specifically designed with thoughtful memory management in mind. Our strategy for replacing std::string with AString was to allow both to exist in the codebase and provide conversions between the two (via .c_str() and .Get() respectively). We gave AString a number of ease-of-use improvements that make it easier to work with and encouraged engineers to replace std::string at their leisure as they change code. Thus, we’re slowly phasing std::string out and the “duct tape” interface between the two systems slowly shrinks as we tidy up more of our code.&lt;/p&gt;
&lt;h2 dir=&quot;ltr&quot;&gt;std::string vs AString Metrics&lt;/h2&gt;
&lt;p class=&quot;rtecenter&quot; dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://engineering.riotgames.com/sites/default/files/Taxonomy_9_STD_String_Metrics.png&quot;/&gt;&lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;1.    Impact: 2 / 5&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;Most of the high-impact allocations from std::string have been phased out via &lt;a href=&quot;https://engineering.riotgames.com/news/profiling-measurement-and-analysis&quot; target=&quot;_blank&quot;&gt;profiling&lt;/a&gt;, so at this point, the main cost is the small mental switching cost to convert from one system to the other.&lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;2.    Fix cost: 3 / 5&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;The conversion to AString isn’t just a find-and-replace. There are a few flavors of AString for different purposes (AStackString for initial allocation in stack memory, ARefString for references to static strings, in addition to heap-allocated base AString). A real, thinking human needs to look at a replacement site to do it right. It will be a long, slow process to phase out the old system.&lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;3.    Contagion: -2 / 5&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;By making AString easier to work with than std::string, we’ve actually managed to flip contagion to our side. Every time an engineer checks in a change to game code, there’s a chance that AString has spread further, like a virus.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;The biggest cost to most MacGyver debt tends to be the intellectual cost of switching modes when crossing boundaries. If some bug or feature is held back by being on the “wrong” system, a targeted move to the “right” system tends to be straightforward. The relative contagion of the new system vs. the old system is the key metric to keep an eye out for. If you can flip that balance to favor the new system, then the better system will inevitably win.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;When considering whether to fix MacGyver debt, try to find ways to make the (global) better system more desirable at a local level. If a time-pressured engineer making greedy optimizations during their day to day work chooses to move towards the desired end state, then you’re well on your way.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;The other approach that can work is to do brute-force large-scale refactors. Depending on how closely the systems map, it may be possible to fix some or all of your MacGyver debt via clever regexes.&lt;/p&gt;
&lt;h2 dir=&quot;ltr&quot;&gt;Foundational Debt&lt;/h2&gt;
&lt;p dir=&quot;ltr&quot;&gt;Foundational debt is when some assumption lies deep in the heart of your system and has been baked into the way the entire thing works. Foundational debt is sometimes hard to recognize for experienced users of a system because it’s seen as “just the way it is.”&lt;/p&gt;
&lt;p class=&quot;rtecenter&quot; dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://engineering.riotgames.com/sites/default/files/Taxonomy_10_Imperial_Measurements.png&quot;/&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;A hilariously stupid piece of real world foundational debt is the measurement system referred to as United States Customary Units. Having grown up in the US, my brain is filled with useless conversions, like that 5,280 feet are in a mile, and 2 pints are in a quart, while 4 quarts are in a gallon. The US government has considered switching to metric multiple times, but we remain one of seven countries that haven’t adopted Système International as the official measurement system. This debt is baked into road signs, recipes, elementary schools, and human minds.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;We’ve talked about several of the big pieces of foundational debt that Riot has been tackling in previous Tech Blog articles like &lt;a href=&quot;https://engineering.riotgames.com/news/determinism-league-legends-introduction&quot; target=&quot;_blank&quot;&gt;Determinism in League of Legends&lt;/a&gt; and &lt;a href=&quot;https://engineering.riotgames.com/news/game-data-server&quot; target=&quot;_blank&quot;&gt;Game Data Server&lt;/a&gt;.&lt;/p&gt;
&lt;p class=&quot;rtecenter&quot; dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://engineering.riotgames.com/sites/default/files/Taxonomy_11_Blockbuilder.png&quot;/&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;Another example of foundational debt that I think about a lot is our use of the lua scripting language. Designers on &lt;em&gt;League&lt;/em&gt; use a tool called BlockBuilder to create complex behaviors by stringing together blocks of functionality like getting the distance between points, spawning minions, dealing damage, or doing all manner of script flow control. The set of operations designers choose from is varied but limited, and the parameters for each operation are constrained. Yet long long ago, in the prehistory of &lt;em&gt;League of Legends&lt;/em&gt;, the decision was made not to store the blocks and parameters in a simple, constrained format that matches the data. Instead they’re stored as arrays and tables in the powerful, beautiful, and entirely-too-complex-for-this-purpose lua language. A decade or so of game development took place upon that foundation since we made the decision and now manipulating lua objects is one of the most common operations in the engine.&lt;/p&gt;
&lt;h2 dir=&quot;ltr&quot;&gt;BlockBuilder Lua Metrics&lt;/h2&gt;
&lt;p class=&quot;rtecenter&quot; dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://engineering.riotgames.com/sites/default/files/Taxonomy_12_Lua_Metrics.png&quot;/&gt;&lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;1.    Impact: 4 / 5&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;The mismatch between lua and this problem space has many costs. Every callstack is polluted with ~6 marshalling stack frames for each frame of BlockBuilder logic. Those marshalling operations are not cheap in terms of server CPU usage. Reading diffs of script changes is needlessly difficult. Parsing/searching script files to determine functionality requires a fairly in-depth understanding of the lua language.&lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;2.    Fix cost: 4 / 5&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;Since lua is so deeply embedded into the engine, digging it out would be difficult. A current proposal is to create a wrapper class that behaves like the lua objects, but is a much simpler struct under the hood, so we can steadily morph our scripting innards into something more suitable. But any way we approach it, we’ll need to be careful and thoughtful.&lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;3.    Contagion: 4 / 5&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;Every time a system bumps up against scripting (which is the core unit of logic for &lt;em&gt;LoL&lt;/em&gt;), that system will be shaped by the operations and requirements of the lua backend. We average a new Building Block every ~3-4 days, each of which directly manipulates lua objects. The longer we don’t replace lua, the harder it becomes to replace lua.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;Foundational debt tends to index highly on all three axes. The high cost encourages sticking with the janky system, which is often the right call, but the high impact and high contagion mean that fixing egregious foundational debt can have a huge payoff.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;The most common strategy for fixing foundational debt that I’ve observed at Riot is to stand up the new system alongside the old one. If possible, I recommend then converting the foundational debt to MacGyver debt by slowly porting systems over to using the new system with conversion operations available to cross between new and old. This allows you to start reaping the benefits in targeted areas easily while limiting exposure to risk. Sometimes such a conversion isn’t possible, though. In that case, creating a compile time (or if possible, loading time) switch can help build confidence in the new system without forcing you to go all-in. The former is in use for the &lt;a href=&quot;https://engineering.riotgames.com/news/game-data-server&quot; target=&quot;_blank&quot;&gt;GDS&lt;/a&gt; conversion, and the latter worked for &lt;a href=&quot;https://engineering.riotgames.com/news/determinism-league-legends-introduction&quot; target=&quot;_blank&quot;&gt;Determinism&lt;/a&gt;.&lt;/p&gt;
&lt;h2 dir=&quot;ltr&quot;&gt;Data Debt&lt;/h2&gt;
&lt;p dir=&quot;ltr&quot;&gt;Data debt starts with a piece of tech debt from one of the other categories. Perhaps it’s a bug in the scripting system, a less-than-desirable file format for items, or two systems that don’t play very well with each other. But then a &lt;em&gt;ton&lt;/em&gt; of content (art, scripts, sounds, etc.) gets built on top of that code deficiency. Before too long, fixing the initial tech debt becomes extremely risky and it becomes painfully hard to tell what you’ll break if you try to fix anything.&lt;/p&gt;
&lt;p class=&quot;rtecenter&quot; dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://engineering.riotgames.com/sites/default/files/Taxonomy_13_Data_Debt.png&quot;/&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;My favorite real world example for understanding data debt is DNA. The genome of an organism is slowly built up over millions of years through lossy copies (mutations), transcription errors, and evolutionary pressure. Some copy errors are useless but benign, others are harmful, and others confer powerful advantages. Attempting to figure out what any piece of DNA &lt;em&gt;actually does&lt;/em&gt; is incredibly difficult. We fully understand what the base pairs mean, and how sets of base pairs translate into amino acids for protein construction. We are even starting to understand more about some non-encoding roles that DNA can play. But in the 3 billion plus base pairs of the human genome, there’s still so much we don’t even remotely understand. &lt;a href=&quot;http://www.radiolab.org/story/update-crispr/&quot; target=&quot;_blank&quot;&gt;Radiolab’s episode about CRISPR&lt;/a&gt; highlights one such puzzle that was recently cracked.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;Data debt on &lt;em&gt;League of Legends&lt;/em&gt; is most impactful when it turns an otherwise trivial fix into a grueling ordeal. I will share one tiny example, but trust me: data debt is one of the most crucial considerations when making changes to the &lt;em&gt;LoL&lt;/em&gt; engine. Our game engineers develop deep knowledge of how game systems were implemented and become quite skilled at predicting what data may break when they change some piece of code.&lt;/p&gt;
&lt;p class=&quot;rtecenter&quot; dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://engineering.riotgames.com/sites/default/files/Taxonomy_14_Spell_Params.png&quot;/&gt;&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;A memorable piece of data debt that we fixed a few years ago involved block parameters in our BlockBuilder scripting language. Above, you can see a toy example where I try to increase Owner’s armor by a variable plus a constant. I would expect Owner to receive 25 bonus armor: 20 from the variable Delta, which is passed into the block, and 5 from the constant. Since the variable’s name matches the parameter name, however, this used to yield 40. (Don’t even ask me why it wouldn’t yield 45; I have no idea what thought process led to the early-out.)&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;When NoopMoney, an engineer on Champions team, went to fix this nonsensical behavior, all he had to do was delete 4 lines of code. But with a highly contagious piece of debt like this, even a small change requires thorough planning. Any of 400,000 lines of script in &lt;em&gt;LoL&lt;/em&gt; might have any of their numerical parameters being doubled by this bug. What’s worse, those scripts are “behaving correctly” in that the game is balanced and tuned around those potentially doubled values. NoopMoney had to make the fix toggleable on Live (in case we had any unexpected bugs come up) in addition to doing extensive regex searching and QA sweeps to try to identify which scripts might rely on this bug to function properly. In the end, the problems from fixing this bug were fairly minor; a small handful of champions needed their scripts altered. But the data debt made it difficult to predict.&lt;/p&gt;
&lt;h2 dir=&quot;ltr&quot;&gt;Parameter Naming Bug Metrics&lt;/h2&gt;
&lt;p class=&quot;rtecenter&quot; dir=&quot;ltr&quot;&gt;&lt;img src=&quot;https://engineering.riotgames.com/sites/default/files/Taxonomy_15_Param_Naming_Metrics.png&quot;/&gt;&lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;1.    Impact: 2 / 5&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;This bug’s impact was small when it occurred. It doubled a passed-in value, and potentially discarded a constant. But it became just yet another bit of otherwise useless tribal knowledge that designers and engineers needed to carry around (once they became aware of it). Developer mindshare is a valuable resource to be wasted like this.&lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;2.    Fix cost: 2 / 5&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;All told, the fix was straightforward. By creating a live feature toggle, we were able to increase our confidence in the safety of the fix. The most expensive part was the initial screening to try to evaluate the scope of the problem in order to target testing.&lt;/p&gt;
&lt;h3 dir=&quot;ltr&quot;&gt;3.    Contagion: 4 / 5&lt;/h3&gt;
&lt;p dir=&quot;ltr&quot;&gt;The unfortunate thing about this bug was that it preyed on an extremely logical behavior. If, for example, you want to deal damage to a unit, saving the value in a variable called “Damage” is totally logical. Sadly, though, the ApplyDamage block took in the amount in a parameter of the same name, thus triggering the bug. Then, if someone else wants to make a similar spell, they’d copy/paste your blocks and carry on, thus spreading the bug even farther.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;In general, data debt indexes high on cost to fix since it makes changes hard to evaluate. More worryingly, it’s almost always extraordinarily contagious due to a few properties of data (as opposed to code). First, it’s generally acceptable to create a new piece of data with a copy/paste of an existing piece of data. If you’re making a new skillshot spell, starting with Ezreal’s Mystic Shot can save you tons of time. Any issues with an existing piece of data are propagated out to its descendents. Second, data is rarely subjected to technical review akin to code reviews. This makes it difficult to notice and halt the spread of bad practices even if they’re widely known. Finally, fixing any issue in the data typically requires a human being with eyes and a brain to verify - a compiler and formal logic won’t cut it.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;When fixing data debt, I’ve observed two main approaches. The first I call the “do it right checkbox.” This means making a toggle between the old “broken” behavior and the new “fixed” behavior for data creators. Ideally, you make the fixed version default while you make sure old content uses the broken version. Then, like with MacGyver debt, you can do a slow and steady replacement to get things onto the new version. This has a permanent cost of adding more and more crap to your editing UI.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;The second approach is the “just fix the damn thing” approach, like NoopMoney used on the parameter naming bug. This means fixing the bug and then trying to repair all the data that’s meaningfully affected. Several techniques can make this less terrifying. First is doing a lot of greps and regex searching to try to understand the theoretical impact. Second is a bunch of targeted testing. Finally, you can prepare a toggle to enable reverting to the old behavior once the fix ships in case you missed something worse than the bug you’re fixing. It’s worth noting that &lt;a href=&quot;https://engineering.riotgames.com/news/determinism-league-legends-introduction&quot; target=&quot;_blank&quot;&gt;Determinism&lt;/a&gt; helps us a lot with testing for these types of changes by letting us confirm that the server produces the same results before and after a change.&lt;/p&gt;

&lt;p dir=&quot;ltr&quot;&gt;When measuring a piece of tech debt, you can use impact (to customers and to developers), fix cost (time and risk), and contagion. I believe most developers regularly consider impact and fix cost, while I’ve rarely encountered discussions of contagion. Contagion can be a developer’s worst enemy as a problem burrows in and becomes harder and harder to dislodge. It is possible, however, to turn contagion into a weapon by making your fix more contagious than the problem.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;Working on &lt;em&gt;League&lt;/em&gt;, most of the tech debt I’ve seen falls into one of the 4 categories I’ve presented here. Local debt, like a black box of gross. MacGyver debt, where 2 or more systems are duct-taped together with conversion functions. Foundational debt, when the entire structure is built on some unfortunate assumptions. Data debt, when enormous quantities of data are piled on some other type of debt, making it risky and time-consuming to fix.&lt;/p&gt;
&lt;p dir=&quot;ltr&quot;&gt;I hope this post helps provide some useful terms for thinking about and discussing tech debt. Hit the comments below if you have questions or wisdom about how to deal with tech debt.&lt;/p&gt;

</description>
<pubDate>Wed, 11 Apr 2018 11:38:44 +0000</pubDate>
<dc:creator>edroche</dc:creator>
<og:title>A Taxonomy of Tech Debt</og:title>
<og:type>website</og:type>
<og:url>https://engineering.riotgames.com/news/taxonomy-tech-debt</og:url>
<og:image>https://engineering.riotgames.com/sites/default/files/articles/83/taxonomy-tech-debt-alt-header.png</og:image>
<og:description>Bill Clark discusses classifying and managing tech debt at Riot.</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://engineering.riotgames.com/news/taxonomy-tech-debt</dc:identifier>
</item>
<item>
<title>Deep Painterly Harmonization</title>
<link>https://github.com/luanfujun/deep-painterly-harmonization#user-content-examples</link>
<guid isPermaLink="true" >https://github.com/luanfujun/deep-painterly-harmonization#user-content-examples</guid>
<description>&lt;h3&gt;README.md&lt;/h3&gt;
&lt;article class=&quot;markdown-body entry-content&quot; itemprop=&quot;text&quot;&gt;
&lt;p&gt;Code and data for paper &quot;&lt;a href=&quot;https://arxiv.org/abs/1804.03189&quot; rel=&quot;nofollow&quot;&gt;Deep Painterly Harmonization&lt;/a&gt;&quot;&lt;/p&gt;
&lt;h2&gt;Disclaimer&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;This software is published for academic and non-commercial use only.&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;Setup&lt;/h2&gt;
&lt;p&gt;This code is based on torch. It has been tested on Ubuntu 16.04 LTS.&lt;/p&gt;
&lt;p&gt;Dependencies:&lt;/p&gt;
&lt;p&gt;CUDA backend:&lt;/p&gt;
&lt;p&gt;Download VGG-19:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;sh models/download_models.sh
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Compile &lt;code&gt;cuda_utils.cu&lt;/code&gt; (Adjust &lt;code&gt;PREFIX&lt;/code&gt; and &lt;code&gt;NVCC_PREFIX&lt;/code&gt; in &lt;code&gt;makefile&lt;/code&gt; for your machine):&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;make clean &amp;amp;&amp;amp; make
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;Usage&lt;/h2&gt;
&lt;p&gt;To generate all results (in &lt;code&gt;data/&lt;/code&gt;) using the provided scripts, simply run&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;python gen_all.py
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;in Python and then&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;run('filt_cnn_artifact.m')
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;in Matlab or Octave. The final output will be in &lt;code&gt;results/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Note that in the paper we trained a CNN on a dataset of 80,000 paintings collected from &lt;a href=&quot;https://www.wikiart.org&quot; rel=&quot;nofollow&quot;&gt;wikiart.org&lt;/a&gt;, which estimates the stylization level of a given painting and adjust weights accordingly. We will release the pre-trained model in the next update. Users will need to set those weights manually if running on their new paintings for now.&lt;/p&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;p&gt;Here are some results from our algorithm (from left to right are original painting, naive composite and our output):&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/0_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/0_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/0_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/0_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/0_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/0_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/1_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/1_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/1_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/1_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/1_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/1_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/2_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/2_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/2_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/2_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/2_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/2_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/3_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/3_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/3_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/3_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/3_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/3_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/4_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/4_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/4_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/4_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/4_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/4_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/5_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/5_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/5_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/5_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/5_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/5_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/6_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/6_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/6_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/6_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/6_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/6_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/7_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/7_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/7_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/7_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/7_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/7_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/8_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/8_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/8_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/8_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/8_final_res.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/8_final_res.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/8_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/8_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/8_naive_balloon.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/8_naive_balloon.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/8_result_balloon.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/8_result_balloon.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/9_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/9_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/9_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/9_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/9_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/9_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/10_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/10_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/10_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/10_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/10_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/10_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/11_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/11_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/11_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/11_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/11_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/11_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/12_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/12_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/12_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/12_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/12_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/12_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/13_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/13_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/13_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/13_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/13_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/13_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/14_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/14_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/14_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/14_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/14_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/14_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/15_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/15_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/15_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/15_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/15_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/15_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/16_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/16_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/16_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/16_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/16_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/16_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/17_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/17_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/17_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/17_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/17_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/17_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/17_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/17_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/17_naive_sherlock.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/17_naive_sherlock.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/17_result_sherlock.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/17_result_sherlock.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/18_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/18_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/18_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/18_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/18_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/18_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/19_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/19_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/19_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/19_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/19_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/19_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/20_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/20_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/20_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/20_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/20_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/20_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/21_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/21_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/21_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/21_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/21_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/21_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/22_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/22_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/22_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/22_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/22_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/22_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/23_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/23_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/23_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/23_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/23_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/23_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/24_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/24_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/24_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/24_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/24_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/24_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/25_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/25_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/25_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/25_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/25_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/25_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/26_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/26_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/26_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/26_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/26_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/26_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/27_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/27_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/27_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/27_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/27_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/27_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/28_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/28_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/28_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/28_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/28_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/28_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/29_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/29_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/29_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/29_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/29_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/29_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/30_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/30_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/30_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/30_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/30_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/30_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/31_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/31_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/31_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/31_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/31_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/31_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/32_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/32_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/32_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/32_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/32_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/32_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/33_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/33_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/33_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/33_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/33_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/33_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/34_target.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/34_target.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/data/34_naive.jpg&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/data/34_naive.jpg&quot; width=&quot;290&quot;/&gt;&lt;/a&gt; &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/luanfujun/deep-painterly-harmonization/blob/master/results/34_final_res2.png&quot;&gt;&lt;img src=&quot;https://github.com/luanfujun/deep-painterly-harmonization/raw/master/results/34_final_res2.png&quot; width=&quot;290&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Acknowledgement&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;Our torch implementation is based on Justin Johnson's &lt;a href=&quot;https://github.com/jcjohnson/neural-style&quot;&gt;code&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;Histogram loss is inspired by &lt;a href=&quot;https://arxiv.org/abs/1701.08893&quot; rel=&quot;nofollow&quot;&gt;Risser et al.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;Citation&lt;/h2&gt;
&lt;p&gt;If you find this work useful for your research, please cite:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;@article{luan2018deep,
  title={Deep Painterly Harmonization},
  author={Luan, Fujun and Paris, Sylvain and Shechtman, Eli and Bala, Kavita},
  journal={arXiv preprint arXiv:1804.03189},
  year={2018}
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2&gt;Contact&lt;/h2&gt;
&lt;p&gt;Feel free to contact me if there is any question (Fujun Luan &lt;a href=&quot;mailto:fl356@cornell.edu&quot;&gt;fl356@cornell.edu&lt;/a&gt;).&lt;/p&gt;
&lt;/article&gt;</description>
<pubDate>Wed, 11 Apr 2018 09:08:30 +0000</pubDate>
<dc:creator>isp</dc:creator>
<og:image>https://avatars3.githubusercontent.com/u/3760952?s=400&amp;v=4</og:image>
<og:type>object</og:type>
<og:title>luanfujun/deep-painterly-harmonization</og:title>
<og:url>https://github.com/luanfujun/deep-painterly-harmonization</og:url>
<og:description>deep-painterly-harmonization - Code and data for paper &quot;Deep Painterly Harmonization&quot;: https://arxiv.org/abs/1804.03189</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://github.com/luanfujun/deep-painterly-harmonization</dc:identifier>
</item>
</channel>
</rss>