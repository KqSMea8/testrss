<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Vue.js: the good, the meh, and the ugly</title>
<link>https://medium.com/@Pier/vue-js-the-good-the-meh-and-the-ugly-82800bbe6684</link>
<guid isPermaLink="true" >https://medium.com/@Pier/vue-js-the-good-the-meh-and-the-ugly-82800bbe6684</guid>
<description>&lt;div class=&quot;section-inner sectionLayout--insetColumn&quot; readability=&quot;51.317789968652&quot;&gt;
&lt;h3 name=&quot;cda5&quot; id=&quot;cda5&quot; class=&quot;graf graf--h3 graf--leading&quot;&gt;The Meh&lt;/h3&gt;
&lt;h4 name=&quot;62c7&quot; id=&quot;62c7&quot; class=&quot;graf graf--h4 graf-after--h3&quot;&gt;Component boilerplate&lt;/h4&gt;
&lt;p name=&quot;da31&quot; id=&quot;da31&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;Moving from React to Vue seems like a breath of fresh air. No more &lt;code class=&quot;markup--code markup--p-code&quot;&gt;bind(this)&lt;/code&gt; or &lt;code class=&quot;markup--code markup--p-code&quot;&gt;setState()&lt;/code&gt; everywhere. Yay! But after a while, you start to question the validity of Vue’s component syntax.&lt;/p&gt;
&lt;p name=&quot;3610&quot; id=&quot;3610&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Vue components are created with objects and here’s an example of defining a component function:&lt;/p&gt;
&lt;pre name=&quot;2456&quot; id=&quot;2456&quot; class=&quot;graf graf--pre graf-after--p&quot;&gt;
export default {&lt;br/&gt;methods: {&lt;br/&gt;increment () {&lt;br/&gt;this.count++;&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;}
&lt;/pre&gt;
&lt;p name=&quot;e24e&quot; id=&quot;e24e&quot; class=&quot;graf graf--p graf-after--pre&quot;&gt;You’ll be adding similar boilerplate for computed properties, component state, watchers, etc. Pretty much everything in Vue has its own special syntax with more boilerplate.&lt;/p&gt;
&lt;p name=&quot;8769&quot; id=&quot;8769&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;In contrast here’s the same thing for &lt;a href=&quot;https://markojs.com/&quot; data-href=&quot;https://markojs.com/&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;Marko&lt;/a&gt; which is way cleaner:&lt;/p&gt;
&lt;pre name=&quot;b6a8&quot; id=&quot;b6a8&quot; class=&quot;graf graf--pre graf-after--p&quot;&gt;
class {&lt;br/&gt;increment() {&lt;br/&gt;this.state.count++;&lt;br/&gt;}&lt;br/&gt;}
&lt;/pre&gt;
&lt;p name=&quot;7bec&quot; id=&quot;7bec&quot; class=&quot;graf graf--p graf-after--pre&quot;&gt;My point here is not about using classes or not, but that Vue is using arbitrary object structures instead of language features.&lt;/p&gt;
&lt;p name=&quot;3b2e&quot; id=&quot;3b2e&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;I won’t blame you if you feel a little dirty by having to create these annoying objects. Vue also offers a &lt;a href=&quot;https://github.com/vuejs/vue-class-component&quot; data-href=&quot;https://github.com/vuejs/vue-class-component&quot; class=&quot;markup--anchor markup--p-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;class based syntax&lt;/a&gt;, but it’s really more of an afterthought.&lt;/p&gt;
&lt;h4 name=&quot;487a&quot; id=&quot;487a&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;Chat based community&lt;/h4&gt;
&lt;p name=&quot;94e2&quot; id=&quot;94e2&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;The Vue community hangs out on Discord, a chat designed for gamer communities. If you hit a roadblock the chat is probably your best bet since the official forums are a desolate land, and don’t you dare ask a question on Github.&lt;/p&gt;
&lt;p name=&quot;e6b4&quot; id=&quot;e6b4&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Chats are messy, but the main problem is that chat content can’t be indexed by search engines. The same questions (and its related discussions) are doomed to be repeated again and again and again.&lt;/p&gt;
&lt;p name=&quot;9d12&quot; id=&quot;9d12&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;This trend of using chats for questions is plaguing open source projects and I think it needs to end. There is no collective learning anymore.&lt;/p&gt;
&lt;h4 name=&quot;1fb7&quot; id=&quot;1fb7&quot; class=&quot;graf graf--h4 graf-after--p&quot;&gt;Not so magic&lt;/h4&gt;
&lt;p name=&quot;4d63&quot; id=&quot;4d63&quot; class=&quot;graf graf--p graf-after--h4&quot;&gt;As long as you don’t steer away from the golden path everything will be fine, but after some time you will probably find lots of little &lt;em class=&quot;markup--em markup--p-em&quot;&gt;ifs&lt;/em&gt; and &lt;em class=&quot;markup--em markup--p-em&quot;&gt;buts&lt;/em&gt; around Vue.&lt;/p&gt;
&lt;p name=&quot;c0f5&quot; id=&quot;c0f5&quot; class=&quot;graf graf--p graf-after--p&quot;&gt;Some examples:&lt;/p&gt;
&lt;ul class=&quot;postList&quot;&gt;&lt;li name=&quot;70cb&quot; id=&quot;70cb&quot; class=&quot;graf graf--li graf-after--p&quot;&gt;The reactivity system will only track changes under certain conditions. Don’t expect to throw anything you wish at it. Quite often you may need to flatten your data as much as possible to avoid headaches. Of course, it’s all explained in the &lt;a href=&quot;https://vuejs.org/v2/guide/reactivity.html&quot; data-href=&quot;https://vuejs.org/v2/guide/reactivity.html&quot; class=&quot;markup--anchor markup--li-anchor&quot; rel=&quot;noopener nofollow&quot; target=&quot;_blank&quot;&gt;fine print of the documentation&lt;/a&gt;.&lt;/li&gt;
&lt;li name=&quot;0332&quot; id=&quot;0332&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;The transition system &lt;code class=&quot;markup--code markup--li-code&quot;&gt;&amp;lt;vue-transition&amp;gt;&lt;/code&gt; does not work for lists. You actually need to use &lt;code class=&quot;markup--code markup--li-code&quot;&gt;&amp;lt;transition-group&amp;gt;&lt;/code&gt; which works slightly differently and introduces new elements in your DOM. Also, one would expect staggering to be a solved thing, but you have to implement it &lt;a href=&quot;https://vuejs.org/v2/guide/transitions.html#Staggering-List-Transitions&quot; data-href=&quot;https://vuejs.org/v2/guide/transitions.html#Staggering-List-Transitions&quot; class=&quot;markup--anchor markup--li-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;yourself&lt;/a&gt;.&lt;/li&gt;
&lt;li name=&quot;3b79&quot; id=&quot;3b79&quot; class=&quot;graf graf--li graf-after--li&quot;&gt;If you need non-reactive state in a component instance you will be into &lt;a href=&quot;https://github.com/vuejs/vue/issues/1988&quot; data-href=&quot;https://github.com/vuejs/vue/issues/1988&quot; class=&quot;markup--anchor markup--li-anchor&quot; rel=&quot;nofollow noopener&quot; target=&quot;_blank&quot;&gt;uncharted territory&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;p name=&quot;950c&quot; id=&quot;950c&quot; class=&quot;graf graf--p graf-after--li&quot;&gt;Etc.&lt;/p&gt;
&lt;p name=&quot;96a6&quot; id=&quot;96a6&quot; class=&quot;graf graf--p graf-after--p graf--trailing&quot;&gt;Don’t get me wrong, these are not deal breakers, but it seems every time you start scratching the surface another minor annoyance pops up.&lt;/p&gt;
&lt;/div&gt;
</description>
<pubDate>Thu, 05 Jul 2018 20:12:50 +0000</pubDate>
<dc:creator>prostoalex</dc:creator>
<og:title>Vue.js: the good, the meh, and the ugly – Pier Bover – Medium</og:title>
<og:url>https://medium.com/@Pier/vue-js-the-good-the-meh-and-the-ugly-82800bbe6684</og:url>
<og:image>https://cdn-images-1.medium.com/max/1200/1*-PlqbnwqjqJi_EVmrhmuDQ.jpeg</og:image>
<og:description>Moving from React to Vue, two years later</og:description>
<og:type>article</og:type>
<dc:format>text/html</dc:format>
<dc:identifier>https://medium.com/@Pier/vue-js-the-good-the-meh-and-the-ugly-82800bbe6684</dc:identifier>
</item>
<item>
<title>California law requires businesses to let you cancel your subscription online</title>
<link>http://www.niemanlab.org/2018/07/thanks-to-california-a-news-site-or-other-business-now-has-to-let-you-cancel-your-subscription-online/</link>
<guid isPermaLink="true" >http://www.niemanlab.org/2018/07/thanks-to-california-a-news-site-or-other-business-now-has-to-let-you-cancel-your-subscription-online/</guid>
<description>&lt;p&gt;Here’s a script you’re surely familiar with if you’ve ever tried to cancel a subscription to, well, anything:&lt;/p&gt;
&lt;div readability=&quot;25.5&quot;&gt;FADE IN:
&lt;p&gt;INT. LIVING ROOM – DAY&lt;/p&gt;
&lt;p&gt;On a couch sits CUSTOMER, alcoholic beverage in one hand, smartphone in the other pressed to her ear. CUSTOMER looks steely, resolute, and frustrated, all at once.&lt;/p&gt;
&lt;div readability=&quot;7&quot;&gt;
&lt;p&gt;CUSTOMER&lt;/p&gt;
&lt;p&gt;Hi. I’d like to cancel my subscription.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The screen splits and on the right, wearing a Bluetooth headset, is CUSTOMER SERVICE REP.&lt;/p&gt;
&lt;div readability=&quot;8&quot;&gt;
&lt;p&gt;CUSTOMER SERVICE REP&lt;/p&gt;
&lt;p&gt;Sorry to hear you’ve been charged again and want to cancel. Are you &lt;em&gt;sure&lt;/em&gt; you want to cancel? How about we give you another free week? No? How about we give you another free two weeks? Still no?&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The connection drops; CUSTOMER SERVICE REP ghosts. The split screen wipes right, and we dolly in to a tight shot of CUSTOMER, eyes glazed, slowly taking a big gulp of her drink.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;A version of this exchange happened when I tried to cancel my &lt;a href=&quot;https://classpass.com/&quot;&gt;ClassPass&lt;/a&gt; account. A similar version happened when I tried to cancel my Boston Globe a few years ago when it kept being delivered to the wrong address.&lt;/p&gt;
&lt;p&gt;We all have our own subscription auto-renewal and cancellation grievances. (My colleague Laura collected &lt;a href=&quot;https://twitter.com/laurahazardowen/status/1002281414929403904?ref_src=twsrc%5Etfw&quot;&gt;a bunch of news organization-related ones&lt;/a&gt; on Twitter.)&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot; readability=&quot;9.6404494382022&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Me: *tries to cancel &lt;a href=&quot;https://twitter.com/nytimes?ref_src=twsrc%5Etfw&quot;&gt;@nytimes&lt;/a&gt; subscription on 27 January*&lt;/p&gt;
&lt;p&gt;NYT, just over *4 months later*: oops&lt;/p&gt;
&lt;p&gt;🤦🏻‍♂️ &lt;a href=&quot;https://t.co/FOe3iFzm0n&quot;&gt;pic.twitter.com/FOe3iFzm0n&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;— dan hon (@hondanhon) &lt;a href=&quot;https://twitter.com/hondanhon/status/1002763516800065536?ref_src=twsrc%5Etfw&quot;&gt;June 2, 2018&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot; readability=&quot;13.458064516129&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Had to call NYT to cancel digital sub. Spent 15 min on hold. First rep tried to retain per training, but when I told him I had meeting to get back to, just cancel it — he hung up on me.&lt;/p&gt;
&lt;p&gt;So I had to call back later that day, hold for another 15 mins to *finally* get it done&lt;/p&gt;
&lt;p&gt;— Cory Brown (@tcb) &lt;a href=&quot;https://twitter.com/tcb/status/1002299273810268160?ref_src=twsrc%5Etfw&quot;&gt;May 31, 2018&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But a &lt;a href=&quot;https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB313&quot;&gt;California law that went into effect July 1&lt;/a&gt; aims to stop companies from blockading customers looking to cancel their services — along with the practice of sneakily sliding them into another month’s subscription without much clarity on the real, full cost of the service. Among the changes: It bans companies from forcing you to, say, call a hard-to-find telephone number to cancel a subscription that you purchased online.&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot; readability=&quot;11.566265060241&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;I moved &amp;amp; updated address. No papers came; I marked them undelivered. Eventually the courier called me, irate, accused me of taking $ out of his pocket. He'd been delivering to old address. I attempted to update address again – still no papers. Finally had to cxl home delivery.&lt;/p&gt;
&lt;p&gt;— Tiffany Hamilton (@feathersandwax) &lt;a href=&quot;https://twitter.com/feathersandwax/status/1002284209631846401?ref_src=twsrc%5Etfw&quot;&gt;May 31, 2018&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;California’s &lt;a href=&quot;https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB313&quot;&gt;Senate Bill No. 313&lt;/a&gt;, which adds further protections for consumers to an existing law, would (according to its official legislative summary):&lt;/p&gt;
&lt;blockquote readability=&quot;26&quot;&gt;
&lt;p&gt;…commencing on July 1, 2018, require a business that makes an automatic renewal offer or continuous service offer that includes a free gift or trial, to include in the offer a clear and conspicuous explanation of the price that will be charged after the trial ends or the manner in which the subscription or purchasing agreement pricing will change upon conclusion of the trial.&lt;/p&gt;
&lt;p&gt;The bill would prohibit a business from charging a consumer’s credit or debit card, or the consumer’s account with a 3rd party, for an automatic renewal or continuous service that is made at a promotional or discounted price for a limited period of time without first obtaining the consumer’s consent to the agreement.&lt;/p&gt;
&lt;p&gt;The bill would also specify that if the automatic service offer or continuous service offer includes a free gift or trial, the business is required to disclose how to cancel, and allow the consumer to cancel, the automatic renewal or continuous service before the consumer pays for the goods or services.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And while it’s just a California law, it also applies to any company (or publisher) with paying customers in the state — so, pretty much everybody, &lt;a href=&quot;https://www.theguardian.com/technology/2018/may/25/gdpr-us-based-news-websites-eu-internet-users-la-times&quot;&gt;GDPR-style&lt;/a&gt;. (Credit/blame &lt;a href=&quot;http://sd18.senate.ca.gov/news/2132017-hertzberg-unveils-legislation-protect-consumers-automatic-service-renewals&quot;&gt;State Sen. Bob Hertzberg&lt;/a&gt;, the bill’s sponsor, for the new rules.)&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://twitter.com/rnakashi&quot;&gt;Ryan Nakashima&lt;/a&gt;, an AP technology writer who’s been &lt;a href=&quot;https://medium.com/@rnakashi/how-best-to-handle-ad-blocking-subscribers-raise-prices-1421b7b770a8&quot;&gt;conducting some adblocking and subscriptions research&lt;/a&gt; at the Bay Area News Group in California, mentioned to me that in an exit survey of people who were canceling their subscriptions, some cancelers had also called out the cancellation process itself. These are real complaints that the new bill will try to address.&lt;/p&gt;
&lt;p&gt;The text of the bill also notes that “a consumer who accepts an automatic renewal or continuous service offer online shall be &lt;strong&gt;allowed to terminate the automatic renewal or continuous service exclusively online&lt;/strong&gt;, which may include a termination email formatted and provided by the business that a consumer can send to the business without additional information.”&lt;/p&gt;
&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot; readability=&quot;8.4130434782609&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;Tried to cancel my print subscription to a Gannett paper. There was no apparent way to do it online. You HAVE to call and talk to person.&lt;/p&gt;
&lt;p&gt;— Jonathan Groves (@grovesprof) &lt;a href=&quot;https://twitter.com/grovesprof/status/1002281759952850948?ref_src=twsrc%5Etfw&quot;&gt;May 31, 2018&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I reached out to some of the major subscription news organizations in California before July 1 to see what progress they’d made on getting compliant, what sorts of reasons for cancellation they’ve seen from readers, and whether they would have made any of these pricing-transparency and subscription-mechanism improvements had there been no law. I got a lot of basic, affirmative statements. (Many other companies I reached out to declined to comment, citing upcoming vacations.)&lt;/p&gt;
&lt;p&gt;“Assuring customer satisfaction is always top of mind to McClatchy and its newspapers. We are aware and in compliance to new requirements for automatic renewal offers (‘auto-renewals’) per the California law,” read an emailed statement attributed to &lt;a href=&quot;https://www.linkedin.com/in/dan-schaub-75251414&quot;&gt;Dan Schaub&lt;/a&gt;, corporate director of audience development at McClatchy, passed along via a PR person. McClatchy owns California papers such as the Sacramento, Fresno, and Modesto Bees. “McClatchy adheres to all laws and regulations, and we have taken steps to allow our customers to access their account information easily on all of our websites.”&lt;/p&gt;
&lt;p&gt;“We are indeed updating our system and customer service pages to conform with the regulations by ensuring that online subscribers can cancel online, as I imagine all publishers are,” &lt;a href=&quot;https://twitter.com/chaseneil&quot;&gt;Neil Chase&lt;/a&gt;, executive editor of the Bay Area News Group, wrote me in an email. The San Jose Mercury News, East Bay Times, and Marin Independent Journal are part of BANG, which falls under the &lt;a href=&quot;https://en.wikipedia.org/wiki/Digital_First_Media&quot;&gt;infamous Digital First Media&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;“Our subscriptions are currently managed through the centralized team at Tribune Interactive/tronc,” a spokesperson for the Los Angeles Times wrote in an email. “We are indeed making changes to our systems to accommodate this new law. Of course it impacts the L.A. Times/San Diego most, but it also impacts California-based subscribers to any publication.” (I tried to follow up for details with a Tribune Interactive/Tronc spokesperson, who punted right away with a reply: “We are not going to comment on a paper we don’t own.”)&lt;/p&gt;
&lt;p&gt;While the new rules should make it easier for a customer to cancel a subscription, lots of publishers still have work to do to make it &lt;a href=&quot;https://twitter.com/brianboyer/status/961026489327210498&quot;&gt;easier for people to subscribe in the first place&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>Thu, 05 Jul 2018 18:55:44 +0000</pubDate>
<dc:creator>danso</dc:creator>
<og:title>Thanks to California, a news site (or other business) now has to let you cancel your subscription online</og:title>
<og:type>article</og:type>
<og:image>http://www.niemanlab.org/images/tin-can-phone-cc-700x500.png</og:image>
<og:url>http://www.niemanlab.org/2018/07/thanks-to-california-a-news-site-or-other-business-now-has-to-let-you-cancel-your-subscription-online/</og:url>
<og:description>Power to the people (who hate talking on phones).</og:description>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.niemanlab.org/2018/07/thanks-to-california-a-news-site-or-other-business-now-has-to-let-you-cancel-your-subscription-online/</dc:identifier>
</item>
<item>
<title>EU copyright law proposal rejected</title>
<link>https://twitter.com/Senficon/status/1014814460488413185</link>
<guid isPermaLink="true" >https://twitter.com/Senficon/status/1014814460488413185</guid>
<description>&lt;p&gt;This will come back, but in another form, the EU will not let this vote stand in its way, like so many times in the past it ignored democratic votes and found ways to implement its authoritarian designs as was the case with the Lisbon Treaty for example. Still, good job.&lt;/p&gt;
</description>
<pubDate>Thu, 05 Jul 2018 10:20:03 +0000</pubDate>
<dc:creator>iMerNibor</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://mobile.twitter.com/Senficon/status/1014814460488413185</dc:identifier>
</item>
<item>
<title>A Tutorial Introduction to Kubernetes</title>
<link>http://okigiveup.net/a-tutorial-introduction-to-kubernetes/</link>
<guid isPermaLink="true" >http://okigiveup.net/a-tutorial-introduction-to-kubernetes/</guid>
<description>&lt;p&gt;Kubernetes is the hottest kid on the block among container orchestration tools right now. I started writing this post when we decided to go with Kubernetes at &lt;a href=&quot;https://www.twylahelps.com/&quot;&gt;Twyla&lt;/a&gt; a year ago, and since then, the developments in the ecosystem have been simply overwhelming. In my opinion, the attention Kubernetes gets is completely deserved, due to the following reasons:&lt;/p&gt;&lt;ul readability=&quot;5.7818181818182&quot;&gt;&lt;li readability=&quot;2.672268907563&quot;&gt;
&lt;p&gt;It is a complete solution that is based on a fundamental set of ideas. These ideas are explained in the &lt;a href=&quot;https://research.google.com/pubs/archive/44843.pdf&quot;&gt;Borg, Omega and Kubernetes&lt;/a&gt; article that compares the consecutive orchestration solutions developed at Google, and the lessons learned.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;While it is container-native, Kubernetes is not limited to a single container platform, and the container platform is extended with e.g. networking and storage features.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;It offers an open and well-designed API, in addition to various patterns that suit differing workflows. The wonderful thing is that there is a very well-governed community process whereby the API is constantly developed further. You have to spend effort keeping up, but regularly receive goodies in return.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;In this tutorial, I want to document my journey of learning Kubernetes, clear up some points that tripped me as a beginner, and try to explain the most important concepts behind how it works. There is absolutely no claim of completeness; Kubernets is way too big for a blog tutorial like this.&lt;/p&gt;
&lt;h2 id=&quot;startingoff&quot;&gt;Starting off&lt;/h2&gt;
&lt;p&gt;The easiest way to start using Kubernetes is Minikube. If you have an account with a cloud provider, and would like to first figure out the details of running a cluster on their platform, this tutorial will still work for you, as the commands work for any recent version of Kubernetes. See &lt;a href=&quot;https://kubernetes.io/docs/getting-started-guides/minikube/&quot;&gt;here&lt;/a&gt; for details on how to get Minikube running on your computer. In order to manipulate the Kubernetes mini-cluster minikube runs, you need the official CLI client named kubectl, which can be installed following the instructions &lt;a href=&quot;https://kubernetes.io/docs/tasks/tools/install-kubectl/&quot;&gt;on this page&lt;/a&gt;. You will also need Docker to create and push container images. Install Docker on your computer following the instructions &lt;a href=&quot;https://docs.docker.com/engine/installation/#supported-platforms&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once you have installed everything, make sure they are all available with the following commands:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl version
docker version
minikube version
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;You can check whether Minikube is running using the following command, which also tells you whether there is an update available:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;minikube status
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;If minikube is not already running, you can start it with &lt;code&gt;minikube start&lt;/code&gt;. Normally, when you install minikube, it automatically configures kubectl to access it. You can check whether this is the case with &lt;code&gt;kubectl cluster-info&lt;/code&gt;. Its output should be something like the following:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Kubernetes master is running at https://192.168.99.100:8443
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;If the IP is not in the &lt;code&gt;192.168.*.*&lt;/code&gt; range, or kubectl complains that configuration is invalid or the cluster cannot be contacted, you need to run &lt;code&gt;minikube update-context&lt;/code&gt; to have minikube fix your configuration for you.&lt;/p&gt;
&lt;h2 id=&quot;howiskubectlconfigured&quot;&gt;How is kubectl configured?&lt;/h2&gt;
&lt;p&gt;I think it is a good idea to shortly mention how kubectl is configured. Which API endpoints and clusters kubectl accesses are defined in the &lt;code&gt;\~/.kube/config&lt;/code&gt; file by default. The file that is accessed can be changed with the &lt;code&gt;KUBECONFIG&lt;/code&gt; environment variable, which should specify a list of paths, so if kubectl displays weird behavior whih you suspect might be due to the configuration, don't forget checking whether this environment variable is set. The kubectl configuration file is in the YAML format, like many other things in Kubernetes. It has two top-level keys that are of immediate relevance: &lt;code&gt;contexts&lt;/code&gt; and &lt;code&gt;clusters&lt;/code&gt;. The clusters list contains endpoint and certificate information for the different clusters to which the user has access. A context combines one such cluster with the user and namespace values for accessing it. One of these contexts is the currently active one; you can find out which by either looking at the config file, or running &lt;code&gt;kubectl config current-context&lt;/code&gt;. You can also run &lt;code&gt;kubectl config view&lt;/code&gt; command to show the complete configuration. You can limit the data shown to the current context with this command using the &lt;code&gt;--minify&lt;/code&gt; option.&lt;/p&gt;
&lt;h2 id=&quot;nodesandnamespaces&quot;&gt;Nodes and namespaces&lt;/h2&gt;
&lt;p&gt;Two basic concepts that are relatively straightforward and can be explained without a lot of context are nodes and namespace. Nodes are the individual units of a Kubernetes cluster, be it a VM or an actual computer. What makes such a unit a node is the &lt;code&gt;kubelet&lt;/code&gt; process that runs on it. This process is responsible for communicating with the Kubernetes master, and running the right containers in the right way. You can get a list of the nodes with &lt;code&gt;kubectl get nodes&lt;/code&gt;. If you are using Minikube, and didn't do anything fancy with the configuration, there will be a single node. Nodes are not particularly interesting. You as a Kubernetes user will not be doing anything fancy with them, and cloud provisioners all have means of automatically or manually scaling the nodes in a Kubernetes cluster.&lt;/p&gt;
&lt;p&gt;Namespaces provide a means to separate subclusters conceptually from each other. If you are running different application stacks on the same cluster, for example, you can organize the resources per app by putting them in the same namespace. A resource created without a namespace specified is created in the &lt;code&gt;default&lt;/code&gt; namespace. It's not necessary to use namespaces, but they make certain things much easier, by helping you avoid name clashes, &lt;a href=&quot;https://kubernetes.io/docs/concepts/policy/resource-quotas/&quot;&gt;limit ressource allocation&lt;/a&gt;, or manage permissions. In case you start working with namespaces, and get annoyed by having to provide the &lt;code&gt;--namespace&lt;/code&gt; switch to every command, here is a handy command that will set the default namespace for the current context:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl config set-context $(kubectl config current-context) --namespace=my-namespace
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;kubernetesdashboard&quot;&gt;Kubernetes dashboard&lt;/h2&gt;
&lt;p&gt;Kubernetes comes with a built-in dashboard in which you can click around and discover things. You can find out whether it is running by listing the system pods with the following command:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl get pods -n kube-system
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;If there is an entry beginning with `kubernetes-dashboard`, it's running. In order to view the dashboard, first run the command &lt;code&gt;kubectl proxy&lt;/code&gt; to proxy to the Kubernetes API. The Kubernetes API should now be available at &lt;a href=&quot;http://localhost:8001&quot;&gt;http://localhost:8001&lt;/a&gt;, and the dashboard at &lt;a href=&quot;http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/&quot;&gt;this rather complicated URL&lt;/a&gt;. It used to be reachable at &lt;a href=&quot;http://localhost:8001/ui&quot;&gt;http://localhost:8001/ui&lt;/a&gt;, but this has been changed due to what I gather are security reasons.&lt;/p&gt;
&lt;h2 id=&quot;usingalocallybuiltimagewithminikube&quot;&gt;Using a locally built image with Minikube&lt;/h2&gt;
&lt;p&gt;In the following tutorial, we will be deploying various container images in order to demonstrate Kubernetes features. Kubernetes uses Docker to retrieve and run container images, meaning that the usual rules of Docker container pull logic apply. That is, for a container image that is not available, if only a name and a tag are provided, Docker contacts the Docker Hub, otherwise hitting the registry in the container name. The aim of this tutorial is to get you to playing around with services running within a Kubernetes cluster as quickly as possible. Hence, the method I would recommend for accessing the container images from minikube is directing your Docker client to the daemon running inside minikube, instead of the local one. Configuring Docker to do so is straightforward with &lt;code&gt;eval $(minikube docker-env)&lt;/code&gt;. Now, any image that you create and tag will be available inside minikube. You can make sure that this is the case by running &lt;code&gt;docker ps&lt;/code&gt;. If the output contains a list of images from &lt;code&gt;gcr.io/google_containers&lt;/code&gt;, you are doing it right. This proxy to the docker service in minikube will be valid only in the current shell; you will be back to using the local docker service when you switch to another shell.&lt;/p&gt;
&lt;p&gt;If you are not interested in modifying and building the sample services yourself, you can also pull the sample images &lt;a href=&quot;https://hub.docker.com/r/afroisalreadyin/&quot;&gt;from my Docker.io profile&lt;/a&gt;. It should be enough to replace the &lt;code&gt;kubetutorial&lt;/code&gt; prefix in the image tags with &lt;code&gt;afroisalreadyin&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&quot;runningaservice&quot;&gt;Running a service&lt;/h2&gt;
&lt;p&gt;Let's start off by running our first command to tell us whether there is anything running on the cluster. We will use the above mentioned kubectl client to do so, running the command &lt;code&gt;kubectl get pods&lt;/code&gt;. What pods are will be explained in a second. As long as the client is configured correctly, as explained above, you should see only the message &lt;em&gt;No resources found&lt;/em&gt;. What kubectl did was to access the Kubernetes cluster running within minikube as specified by the currently active context configuration and present the resulting information. kubectl is just one among many API clients; there are others, such as &lt;a href=&quot;https://github.com/kubernetes-incubator/client-python&quot;&gt;this Python client&lt;/a&gt; which is the other officially supported one. You can view the API requests &lt;code&gt;kubectl&lt;/code&gt; is making by increasing the verbosity of the logging with the &lt;code&gt;--v=7&lt;/code&gt; argument, but careful, this will lead to a lot of textual output.&lt;/p&gt;
&lt;p&gt;Kubernetes will not figure out for itself what we need to run, so let's go ahead and tell it to run a very simple application, namely the simple Python application from the Kubernetes demos repository. In order to do so, you need to first clone the repo, navigate to the subfolder &lt;code&gt;simple-python-app&lt;/code&gt;, and create a container image by running the following command:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;docker build -t kubetutorial/simple-python-app:v0.0.1 .
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Once the build runs, you should be able to see it in the list of available images in the result of running &lt;code&gt;docker images&lt;/code&gt;. After making sure this is the case, we are finally ready to run our first Kubernetes command, which is the following:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl run simple-python-app \
     --image=kubetutorial/simple-python-app:v0.0.1 \
     --image-pull-policy=IfNotPresent \
     --port=8080
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;It should be obvious that this command somehow runs the container that we just created, since the tag of the image is passed in with the &lt;code&gt;--image&lt;/code&gt; argument. The &lt;code&gt;imagePullPolicy=IfNotPresent&lt;/code&gt; argument tells Docker to use an existing local image instead of attempting to pull it. We are also specifying the port 8080 here as the port this deployment is exposing. This has to be the same port the application is binding to. Unless we provide this bit of information, Kubernetes has no way of knowing on which port to contact the application. Small side note: The demo service has to bind to this port on the general interface &lt;code&gt;0.0.0.0&lt;/code&gt; and not on &lt;code&gt;localhost&lt;/code&gt; or &lt;code&gt;127.0.0.1&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;How do we reach into Kubernetes to contact our service? This is the perfect time to introduce the most important abstraction in Kubernetes: &lt;em&gt;&lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/pods/pod/&quot;&gt;The Pod&lt;/a&gt;&lt;/em&gt;. As with the other abstractions, pods are resources on the Kubernetes API, and we can list and query them using kubectl. Let's see which pods are now running, with the same command that we ran earlier, &lt;code&gt;kubectl get pods&lt;/code&gt;. The output should closely resemble the following:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;NAME                               READY     STATUS    RESTARTS   AGE
simple-python-app-68543294-vhj7g   1/1       Running   0          21s
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Great, we have a pod running. But what is a pod, actually? A pod is the fundamental application unit in Kubernetes. It is a collection of containers that belong together, and whose lifetimes are managed together. These containers are deployed on the same node, their lifetimes are managed together, and they share operating system namespaces, volumes, and IP address. They can contact each other on &lt;code&gt;localhost&lt;/code&gt; and use OS-level IPC mechanisms such as shared memory. The decision of what to include in a pod hinges on what serves as a single unit across the dimensions of deployment, horizontal scaling, and replication. For example, it would not make sense to put the data store &lt;em&gt;and&lt;/em&gt; the application containers of a service into the same pod, because these scale and are replicated independently of each other. What &lt;em&gt;does&lt;/em&gt; belong together with the application container is a container that hosts the log aggregation process, for example.&lt;/p&gt;
&lt;p&gt;Now that we know what a pod is, and can figure out the name of our single pod running, we can query it using the kubectl proxy feature we already used above. Once the proxy is running, you can access the &lt;code&gt;simple-python-app&lt;/code&gt; container on the port we specified in the previous command by querying the special URL that Kubernetes makes available for this purpose (don't forget changing the name of the pod at the end of the URL):&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;curl http://localhost:8001/api/v1/proxy/namespaces/default/pods/simple-python-app-68543294-vhj7g
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;We can also see the logs of our brand new pod with &lt;code&gt;kubectl logs simple-python-app-68543294-vhj7g&lt;/code&gt;, which should show the stdout of our application. It is also possible to execute a command within the container, similar to the &lt;code&gt;docker exec&lt;/code&gt; command, with &lt;code&gt;kubectl exec -ti simple-python-app-68543294-vhj7g CMD&lt;/code&gt;. As with Docker, the &lt;code&gt;-ti&lt;/code&gt; bit signals that a tty should be allocated, and the command should run interactively. The &lt;code&gt;kubectl exec&lt;/code&gt; command allows you to pick which container to run the command in using the &lt;code&gt;-c&lt;/code&gt; switch. When ommitted, the default is the only container in the pod, if there is just one, as per the definition of the pod.&lt;/p&gt;
&lt;h3 id=&quot;whocreatedthepod&quot;&gt;Who created the pod?&lt;/h3&gt;
&lt;p&gt;It's nice that Kubernetes is running our container inside a pod, but we would still like to know where the pod actually comes from. We didn't tell Kubernetes to create any pods. In fact, pods are rarely created manually in Kubernetes. If that were the case, Kubernetes would not be offering anything new; the user would still be responsible for orchestrating the individual application units, and ensuring their availability. What the above &lt;code&gt;kubernetes run&lt;/code&gt; command did was to &lt;em&gt;create a Deployment&lt;/em&gt;. This can be seen by listing the deployments:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ kubectl get deployments
NAME                DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
simple-python-app   1         1         1            1           1s
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/&quot;&gt;Deployments&lt;/a&gt; are one of the special kinds of resources in the Kubernetes world, in that they are responsible for managing the lifetime of application containers. These kinds of resources are called &lt;em&gt;controllers&lt;/em&gt;, and they are central to the Kubernetes puzzle. You can get more detailed info about the new deployment with &lt;code&gt;kubectl describe deployments simple-python-app&lt;/code&gt;. The &lt;code&gt;describe&lt;/code&gt; subcommand is a very useful tool for getting detailed information on all resources. It also lists related resources, and events that concern the described resource. For this deployment, you can see a couple of things in the output of &lt;code&gt;kubectl describe&lt;/code&gt;. First of all, there is talk of something called a &lt;em&gt;pod template&lt;/em&gt;. This is what is used to create the pods when the deployment is being scaled, i.e. new pods are being created to meet the target.&lt;/p&gt;
&lt;p&gt;What happens when we delete the pod? In order to view what is happening in real time, I would advise you to open a second terminal, and run the command &lt;code&gt;kubectl get pods -w&lt;/code&gt; in it. The &lt;code&gt;-w&lt;/code&gt; switch updates the output in regular intervals. Now, delete the existing pod with &lt;code&gt;kubectl delete pod simple-python-app-68543294-vhj7g&lt;/code&gt;. In the output of the pod listing terminal, you should temporarily see a state like the following:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;NAME                                 READY     STATUS        RESTARTS   AGE
simple-python-app-5c9ccf7f5d-8lbb2   1/1       Running       0          4s
simple-python-app-5c9ccf7f5d-kl77s   1/1       Terminating   0          43s
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;So as one pod is being deleted, another was already created (the status might also be &lt;code&gt;ContainerCreating&lt;/code&gt; instead of &lt;code&gt;Running&lt;/code&gt;. The responsibility for this recreation goes to &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/&quot;&gt;Replica Sets&lt;/a&gt;. You can see the replica sets that belong to a deployment using the above mentioned &lt;code&gt;kubectl describe&lt;/code&gt; command; the Replica Sets will be listed at the bottom, before the events. You can see that there are two lists: &lt;code&gt;OldReplicaSets&lt;/code&gt; and &lt;code&gt;NewReplicaSets&lt;/code&gt;. The difference between the two will be explained later in the context of rollouts. You can also list the replica sets with the &lt;code&gt;kubectl get replicasets&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;Looking at the replica set created by our deployment with &lt;code&gt;kubectl describe replicaset $REPLICA_SET_NAME&lt;/code&gt;, we can see at a glimpse a number of relevant rows:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# ... snip
Replicas:       1 current / 1 desired
Pods Status:    1 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:       pod-template-hash=4035281104
                run=simple-python-app-2
  Containers:
   simple-python-app:
    Image:              kubetutorial/simple-python-app:v0.0.1
    Port:               8080/TCP
    Environment:        &amp;lt;none&amp;gt;
    Mounts:             &amp;lt;none&amp;gt;
  Volumes:              &amp;lt;none&amp;gt;
Events:                 &amp;lt;none&amp;gt;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;This Replica Set is responsible for keeping one Pod with our &lt;code&gt;simple-python-app&lt;/code&gt; container running, and it is doing that successfully, judging from the &lt;code&gt;1 current / 1 desired&lt;/code&gt; row. But as with pods, replica sets are intended to be created by Deployments, so you shouldn't have to create or manipulate them manually.&lt;/p&gt;
&lt;h2 id=&quot;shortexcursiononnetworking&quot;&gt;Short excursion on networking&lt;/h2&gt;
&lt;p&gt;As nice and useful as replica sets are, they not much of a help in terms of high availability. When a Pod goes down, another one is started, and it has a different name, a different IP address, and is possibly running on a completely different node. Also, what if we want to load balance these replicas? If Kubernetes were to offer service discovery only based on pod names, the clients of this service would need to do client-side load balancing, and keep an internal list of pods that need to be updated on every pod lifetime event. What about routing incoming traffic to services (ingress)? These are all pesky issues that need simplification. Kubernetes offers much easier mechanisms to achieve HA, load balancing and ingress. The basis for all this is the &lt;a href=&quot;https://kubernetes.io/docs/concepts/cluster-administration/networking/#kubernetes-model&quot;&gt;networking requirements Kubernetes imposes on the nodes and pods&lt;/a&gt;. These are the following:&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;-0.72727272727273&quot;&gt;
&lt;p&gt;All containers can communicate with all other containers without NAT (&lt;a href=&quot;https://en.wikipedia.org/wiki/Network_address_translation&quot;&gt;Network Address Translation&lt;/a&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;All nodes can communicate with all containers (and vice-versa) without NAT.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;The IP that a container sees itself as is the same IP that others see it as.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;It is possible to use &lt;a href=&quot;https://kubernetes.io/docs/concepts/cluster-administration/networking/#how-to-achieve-this&quot;&gt;any one of various networking options&lt;/a&gt; that fit this model, with kubenet being the default. The above requirements sound relatively straightforward. One would think that each application container gets its IP. That is not the case, however, as it is not the application containers, but the &lt;em&gt;Pods&lt;/em&gt; that get the IP addresses. Or in the words of the documentation:&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;Until now this document has talked about containers. In reality, Kubernetes applies IP addresses at the Pod scope - containers within a Pod share their network namespaces - including their IP address.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You can also verify that pods can be reached by IP on the exposed port by getting the private network IP address of the container with &lt;code&gt;kubectl get pods -o wide&lt;/code&gt;. Afterwards, log on to the Minikube node with the command &lt;code&gt;minikube ssh&lt;/code&gt;. From within this node, you can query the service with &lt;code&gt;curl $IP_ADDRESS:8080&lt;/code&gt;, which should return the response we have already seen.&lt;/p&gt;
&lt;p&gt;How are pods that belong to the same replica set organized, in order to provide high availability, load balancing and discovery? The answer to this question is requires introducing another Kubernetes concept.&lt;/p&gt;
&lt;h2 id=&quot;services&quot;&gt;Services&lt;/h2&gt;
&lt;p&gt;I have been calling the tiny web application we have been using for demo purposes a service, but service has a totally different meaning in the Kubernetes world. A Kubernetes Service is an abstraction that allows loose coupling of pods to enable load balancing, discovery and routing. Through services, pods can be replaced and rotated without impacting the availability of an application. Let's start with a very simple example where we turn our simple Python application into a Service, which can be achieved with the following very simple command:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl expose deploy simple-python-app --port 8080
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;If you now run &lt;code&gt;kubectl get services&lt;/code&gt;, you should see a list consisting of two entries: &lt;code&gt;kubernetes&lt;/code&gt; and &lt;code&gt;simple-python-app&lt;/code&gt;. The &lt;code&gt;kubernetes&lt;/code&gt; service is a part of the infrastructure, and you shouldn't meddle with it. The other service is what we are looking for, especially the IP address, which is listed under the column &lt;code&gt;CLUSTER-IP&lt;/code&gt;. We are interested in this IP address because it is something special. It's a &lt;em&gt;virtual IP&lt;/em&gt; Kubernetes has reserved for the new service. In the same output, you can also see that the port 8080 is exposed. We can now log on to the minikube VM (which is a Kubernetes node) with &lt;code&gt;minikube ssh&lt;/code&gt;, and query what is now truly a service with &lt;code&gt;curl $IP_ADDRESS:8080&lt;/code&gt;, once more returning &lt;code&gt;Hello from the simple python app&lt;/code&gt;. The network requirements mentioned above ensure the reachability of the service IP from the node.&lt;/p&gt;
&lt;p&gt;Things get much more interesting when there are multiple pods in a replica set. In order to see the effect, let's use another service that provides more information in its response. This service is in the &lt;code&gt;kubernetes-repository&lt;/code&gt; as &lt;code&gt;env-printer-app&lt;/code&gt;. When the base path is called, it returns a print of the environment variables. Just like with the previous application, you can go ahead and create a container with the following command:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;docker build -t kube-tutorial/env-printer-app:v0.0.1 .
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;We will start the Deployment with a replica count of 3, which will cause Kubernetes to start 3 pods right away. To do so, use the following command:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl run env-printer-app \
     --image=kube-tutorial/env-printer-app:v0.0.1 \
     --image-pull-policy=Never \
     --replicas=3 \
     --port=8080
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Now let's create a Service by exposing this Deployment with the following command, which is a slight modification of the expose command we used earlier:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl expose deploy env-printer-app --port 8080
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;A new service &lt;code&gt;env-printer-app&lt;/code&gt; should pop up in the output of &lt;code&gt;kubectl get services&lt;/code&gt;. Note the IP address for this service under &lt;code&gt;CLUSTER-IP&lt;/code&gt; as &lt;code&gt;$IP_ADDRESS&lt;/code&gt;, and log on to minikube via ssh again. Afterwards, run the following command a couple of times:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;curl -s $IP_ADDRESS:8080 | grep HOSTNAME
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;This command makes a request to the service endpoint, and filters the &lt;code&gt;HOSTNAME&lt;/code&gt; environment variable out of it. You should observe that the hostname alternates between the various pod names. Kubernetes is distributing the requests among the replica pods for us, giving us load balancing out of the box.&lt;/p&gt;
&lt;p&gt;This very short demo of services leads to more questions than answers. How does the service know which pods to hit when a request comes in, for example? Why can we contact our service only from within the cluster? How can we enable external access to it? Before we can answer these questions, however, we need to have a look at a better way of specifying deployments, services and other resources.&lt;/p&gt;
&lt;h2 id=&quot;usingthecommandlineversusmanifestfiles&quot;&gt;Using the command line versus manifest files&lt;/h2&gt;
&lt;p&gt;Until now, we have been using the command line interface to Kubernetes via &lt;code&gt;kubectl&lt;/code&gt;. It is possible to get quite far with &lt;code&gt;kubectl&lt;/code&gt;, as it is pretty complete, but it can become difficult to read, share with others, and organize in a repository. A much better method for organizing Kubernetes resources which adheres to the &lt;em&gt;infrastructure as code&lt;/em&gt; mantra is using manifest files. These are either YAML or JSON files (although YAML is preferred) that specify in a more structured format the resources to be created and actions to be undertaken. A manifest file takes the form of a list of resources of different &lt;em&gt;kinds&lt;/em&gt;, together with &lt;em&gt;metadata&lt;/em&gt; and a &lt;em&gt;spec&lt;/em&gt;. It is also common and recommended practice to specify the version of the API that is targeted with each entry. The different entries must be separated with a triple dash separator, which signifies the start of a new document in YAML. This separator is mandatory; if you leave it out, only the first item in a list will be processed.&lt;/p&gt;
&lt;p&gt;The resource specifications are documented in great detail in the &lt;a href=&quot;https://kubernetes.io/docs/api-reference/v1.7/&quot;&gt;Kubernetes API documentation&lt;/a&gt;. What's even better, however, is that the &lt;code&gt;kubectl&lt;/code&gt; command is self-documenting. To get documentation on pods, you can use the &lt;code&gt;kubectl explain pods&lt;/code&gt; command. This command will print, prefixed by a short description, the various fields a pod manifest can contain. In order to go deeper in this tree, you can run commands such as &lt;code&gt;kubectl explain pod.metadata.labels&lt;/code&gt;, which will give more detailed information on individual fields.&lt;/p&gt;
&lt;p&gt;If you have a look at the entry for &lt;a href=&quot;https://kubernetes.io/docs/api-reference/v1.7/#deployment-v1beta1-apps&quot;&gt;deployment&lt;/a&gt; in either the online or command line documentation, you will see that the metadata field is same across all resources, and the name field is required. This field enables us to refer to resources in commands when we want to get detailed information or delete them, or cross-reference from other manifest files. The spec field is required to adhere to the &lt;code&gt;DeploymentSpec&lt;/code&gt; configuration, which should have a &lt;em&gt;template&lt;/em&gt; field that describes the pod to be deployed. This template, in turn, must have a metadata field itself, and a spec that should contain a list of containers. As per this specification, here is how to create the above deployment example for the &lt;code&gt;env-printer-app&lt;/code&gt;, in YAML format:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: env-printer-app
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: env-printer-app
    spec:
      containers:
      - image: twyla.io/env-printer-app:v.0.0.1
        imagePullPolicy: IfNotPresent
        name: env-printer-app
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;It is possible to see a common pattern of nested resources that all have metadata which is used to refer to each other, templates that tell Kubernetes what kind of resources to create, and various other kinds of auxiliary information, such as the &lt;em&gt;replicas&lt;/em&gt; field. You can now go ahead and use this YAML file, saved into &lt;code&gt;deploy.yaml&lt;/code&gt; in the &lt;code&gt;kubernetes-repository/env-printer-app&lt;/code&gt; directory, to create a deployment by running &lt;code&gt;kubectl apply -f deploy.yaml&lt;/code&gt;. It is possible to create all resources in a directory by &lt;code&gt;kubectl apply -f&lt;/code&gt; with the directory path.&lt;/p&gt;
&lt;p&gt;You can also use &lt;code&gt;kubectl get KIND NAME -o yaml&lt;/code&gt; to get a detailed description of a resource in YAML format. This YAML document might include much more than the information you supplied when creating a resource, as the values for the defaults you omitted, and those calculated or set by Kubernetes are also included. Another really great feature that relies on the YAML representation capabilities of Kubernetes (one of my favorite features) is &lt;em&gt;editing&lt;/em&gt; a resource with the command &lt;code&gt;kubectl edit KIND NAME&lt;/code&gt;. This command will fetch the resource description in YAML, and load it in the editor defined by the &lt;code&gt;EDITOR&lt;/code&gt; (or &lt;code&gt;KUBE_EDITOR&lt;/code&gt;, if it's defined) environment variable. Once you save your changes and exit, the new resource description will be applied to the resource. This is a great way to try things out quickly without having to keep multiple versions of resource definitions.&lt;/p&gt;
&lt;h2 id=&quot;servicescontinued&quot;&gt;Services, continued&lt;/h2&gt;
&lt;p&gt;Alright, where were we? So we have a bunch of containers running in Pods, provisioned and kept alive through Deployments, bundled into a Service that puts them behind a common IP. And we can put all of these into one or more YAML files to recreate them arbitrarily. This is a good point to explain one very interesting and versatile feature of Kubernetes: Selectors. If you go ahead and get the details of the &lt;code&gt;env-printer-app&lt;/code&gt; service we have created above with &lt;code&gt;kubectl describe service env-printer-app&lt;/code&gt;, you should see a row that begins with ~Selector: ~. This selector configuration tells you how Kubernetes finds the pods it should collect behind the virtual IP of the service. If you didn't do anything funky in the meanwhile, the value of the selector row should be &lt;code&gt;run=env-printer-app&lt;/code&gt;. If you describe the deployment targeted by this service with &lt;code&gt;kubectl describe deploy env-printer-app&lt;/code&gt;, you will see exactly the same selector line. Services and deployments use the same mechanism to match the pods that they hit or control. Which pods are these? This question can be answered by filtering a search by label, as in the following command:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kc get pods -l run=env-printer-app
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Not surprisingly, these are the three pods created by the original deployment. This selector-based mechanism is used by many components in Kubernetes, and it is very versatile in that it allows custom labels. This opens up a whole lot of possibilities for different patterns, such as A/B deployments, rolling updates (which we will see later) and similar things.&lt;/p&gt;
&lt;p&gt;What is thus happening is that a collection of pods, as picked by the &lt;code&gt;spec.selector&lt;/code&gt; attribute, is exposed as a service on an IP. This is not the only way to expose a service, however: There are &lt;a href=&quot;https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services---service-types&quot;&gt;different kinds of Services&lt;/a&gt; based on how this exposing happens. The default is the &lt;strong&gt;ClusterIP&lt;/strong&gt; kind, which is what we have now. Other kinds are &lt;code&gt;NodePort&lt;/code&gt;, where a service is exposed on the same port on all exposed nodes, &lt;code&gt;LoadBalancer&lt;/code&gt; that uses a platform-native load balancer to expose a service to the outer world, and &lt;code&gt;ExternalName&lt;/code&gt; which enables you to provide an &lt;em&gt;external&lt;/em&gt; service on the local cluster as if it's an internal one.&lt;/p&gt;
&lt;p&gt;These all have their use cases, but the &lt;code&gt;ClusterIP&lt;/code&gt; service is the one that covers the most use cases, so we will concentrate on it here. Having multiple pods behind a single IP solves many problems, since Kubernetes also takes care of things like load balancing (done by randomly routing requests; a &lt;a href=&quot;https://kubernetes.io/docs/concepts/services-networking/service/#proxy-mode-ipvs&quot;&gt;new proxy mode&lt;/a&gt; will introduce more options) or managing modifications in target pod set. One thing it does not solve, however, is the problem of figuring out this IP in the first place. This is another point in which Kubernetes shines: Matching a name to an IP address is done using DNS on the internet, and Kubernetes builds on this common protocol by providing &lt;a href=&quot;https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/&quot;&gt;an internal DNS service&lt;/a&gt; itself. By default, a DNS A record is created, pointing to the service IP, for each &lt;code&gt;ClusterIP&lt;/code&gt; service. Hence, we should be able to refer our &lt;code&gt;env-printer-app&lt;/code&gt; under this exact name. To see that this is the case, run the following command to run bash on a container:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl run my-shell --rm -ti --image cfmanteiga/alpine-bash-curl-jq bash
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;There are quite some arguments to this command, which need some explanining. The &lt;code&gt;--rm&lt;/code&gt; switch tells kubectl to delete the deployment and the pod once the command is run, while &lt;code&gt;-ti&lt;/code&gt; asks it to attach a tty to the container, and make it connect to the stdin of the container process. The &lt;code&gt;--image&lt;/code&gt; argument specifies a lightweight alpine-based image with some debugging utilities, and the last argument is the command to use instead of the entry point of the container. In the shell that starts, you can now run &lt;code&gt;curl http://env-printer-app&lt;/code&gt;, and enjoy the environment varliable list delivered by the service.&lt;/p&gt;
&lt;h2 id=&quot;ingress&quot;&gt;Ingress&lt;/h2&gt;
&lt;p&gt;Our service is now humming in the cluster, accepting requests when we hit it at &lt;a href=&quot;http://env-printer-app&quot;&gt;http://env-printer-app&lt;/a&gt;. In order to make it available to the outer world, we need to do one last thing: Tell Kubernetes to route HTTP requests from the outside to a certain location to this service. This process is called Ingress, and Kubernetes offers a &lt;a href=&quot;https://kubernetes.io/docs/concepts/services-networking/ingress/&quot;&gt;complete system&lt;/a&gt; to handle it. There are two things you need to enable to route requests to the env-printer-app from the outside:&lt;/p&gt;
&lt;ul readability=&quot;3.5&quot;&gt;&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;An Ingress controller, essentially a reverse proxy running within Kubernetes that can be configured using Kubernetes-native resources. The two built-in solutions are GCE and Nginx-based. In order to use the Nginx-based ingress controller on Minikube, you have to enable the extension with &lt;code&gt;minikube addons enable ingress&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;Ingress specifications. These are resources just like Pods and Deployments, and contain information on how to map incoming requests to services, serving as configuration for the aforementioned ingress controller.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;An Ingress specification for the env-printer-app is included in the sample project repo as &lt;code&gt;ingress.yml&lt;/code&gt;. After activating the minikube ingress plugin, you can run &lt;code&gt;kubectl apply -f ingress.yml&lt;/code&gt; to create an ingress that maps requests to &lt;a href=&quot;http://env-printer&quot;&gt;http://env-printer&lt;/a&gt; to the &lt;code&gt;env-printer-app&lt;/code&gt; service. In order to test the ingress, you need to first figure out the IP of the minikube VM with &lt;code&gt;minikube ip&lt;/code&gt;, and then edit &lt;code&gt;/etc/hosts&lt;/code&gt; on your computer, adding the line &lt;code&gt;$IP_ADDRESS env-printer&lt;/code&gt;. You should now be able to navigate to &lt;a href=&quot;http://env-printer&quot;&gt;http://env-printer&lt;/a&gt; in your browser, and see the output of the &lt;code&gt;env-printer-app&lt;/code&gt; service.&lt;/p&gt;
&lt;h2 id=&quot;rollingupdates&quot;&gt;Rolling updates&lt;/h2&gt;
&lt;p&gt;Once you have a deployment managing a set of pods, there are a couple of things you can do with it to adapt to new conditions. First of these is scaling the set of containers to meet load conditions. One way of achieving this is using the &lt;code&gt;kubectl scale&lt;/code&gt; command, as follows:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl scale deploy env-printer-app --replicas=4
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Alternatively, you can use the &lt;code&gt;kubectl edit deploy env-printer-app&lt;/code&gt; command to bring up an editor, and change the &lt;code&gt;spec.replicas&lt;/code&gt; field to the required number. If you now run &lt;code&gt;kubectl describe deploy env-printer-app&lt;/code&gt;, there should be a new scaling event in the Events section. When the number of replicas is changed, Kubernetes simply creates new pods, or terminates existing ones, without any further complications. It's a different situation when the container spec for a deployment is changed, however. Kubernetes, based on the strategy specified by the user, replaces the pods progressively, to enable a smooth transition from one set of pods to the other. This is called &lt;em&gt;rolling updates&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In order to demo rolling updates, I added another project to the sample Kubernetes services repository, the &lt;code&gt;rollout-app&lt;/code&gt;. You can go ahead and create the service by running &lt;code&gt;kubectl apply -f deploy.yml --record&lt;/code&gt; in the app's directory, which will create the deployment, the service, and the ingress. The reason for the &lt;code&gt;--record&lt;/code&gt; switch will be explained in a couple of paragraphs. If you edit your &lt;code&gt;/etc/hosts&lt;/code&gt; file to add &lt;a href=&quot;http://rollout-app&quot;&gt;http://rollout-app&lt;/a&gt; with the minikube IP, you should be able to navigate to this URL and see a big display of the port's hostname.&lt;/p&gt;
&lt;p&gt;If you open &lt;code&gt;rollout-app/application.py&lt;/code&gt;, you can see two peculiar things there. One is the &lt;code&gt;/healthz&lt;/code&gt; endpoint that returns a simple &lt;em&gt;OK&lt;/em&gt; message and nothing else, and the other is a &lt;code&gt;time.sleep(5)&lt;/code&gt; before the app starts. The purpose of the &lt;code&gt;/healthz&lt;/code&gt; endpoint might become clearer if you also look at the &lt;code&gt;deploy.yml&lt;/code&gt; in the same directory; this endpoint is registered as a &lt;code&gt;readinessProbe&lt;/code&gt; on the deployment. The readiness probe is a part of the &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/&quot;&gt;pod lifecycle system&lt;/a&gt; of Kubernetes. Before this probe is valid (for HTTP probes, it must return a status code between 200 and 400), the new pod is not marked as &quot;ready&quot;, and requests will not be routed to it. Due to the sleep of 5 seconds before our application is started, the pods of the &lt;code&gt;rollout-app&lt;/code&gt; will not be ready for at least five seconds. Now let's have a look at how this delay interacts with the rolling updates feature of Kubernetes. Once you have deployed the application, change &lt;code&gt;application.py&lt;/code&gt; in some minor way, such as adding a newline. Afterwards, create a new docker container with a new tag with &lt;code&gt;docker build -t kubetutorial/rollout-app:v0.0.2 .&lt;/code&gt;. Then go ahead and change the Docker image for the &lt;code&gt;rollout-app&lt;/code&gt; deployment to the new version with the following command (again with the &lt;code&gt;--record&lt;/code&gt; switch which will be explained later):&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl set image deploy rollout-app rollout-app=kubetutorial/rollout-app:v0.0.2 --record
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Kubernetes gets to work right away, creating new pods and terminating the ones these are supposed to replace. You can see that this is the case by running &lt;code&gt;kubectl get pods&lt;/code&gt;. One peculiar (or actually nice) thing is that Kubernetes does not just pull down the running pods, starting their replacements at the same time. &lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#updating-a-deployment&quot;&gt;A rollout process&lt;/a&gt; is applied, whereby new pods are created as old ones are taken down. You can follow this process by running the command &lt;code&gt;kubectl rollout status deploy rollout-app&lt;/code&gt;. This command will hang with a message like &lt;em&gt;Waiting for rollout to finish: 2 of 3 updated replicas are available…&lt;/em&gt;. So now the deployment is in the middle of a rollout process. We will see where these numbers come from later. A rollout is actually the process of moving from one replica set to another. You can see that this is the case by running the command &lt;code&gt;kubectl get replicaset&lt;/code&gt; (or replace &lt;code&gt;replicaset&lt;/code&gt; with &lt;code&gt;rs&lt;/code&gt; to make the command shorter). You should see two replica sets that begin with &lt;code&gt;replica-set&lt;/code&gt;, one belonging to the old state, and the other belonging to the new state. The DESIRED, CURRENT and READY values of one should decrease, while the other one goes up and approaches required values.&lt;/p&gt;
&lt;p&gt;One thing you can do is pause this rollout while it is in progress with &lt;code&gt;kubectl rollout pause deploy rollout-app&lt;/code&gt;. This will leave the pod counts the way they are when you run the command, and give you the chance to run checks, to make sure everything is OK. Let's say that you start a rollout, pause it to run some checks, and discover that you made a mistake, and would like to rever to the previous version to fix the issue. This can be achieved by rolling &lt;em&gt;back&lt;/em&gt; the rollout with &lt;code&gt;kubectl rollout undo deploy rollout-app&lt;/code&gt;. But let's say that you want to move back even &lt;em&gt;further&lt;/em&gt; in the deployment history. This is where the &lt;code&gt;--record&lt;/code&gt; switch to the &lt;code&gt;kubectl apply&lt;/code&gt; command comes into play. Thanks to this switch, we can now see the commands that caused a rollout on this deployment, and a version number that we can use to refer to that rollout. After you deploy version 0.0.2 of &lt;code&gt;rollout-app&lt;/code&gt;, the output of the &lt;code&gt;kubectl rollout history deploy rollout-app&lt;/code&gt; should be similar to the following:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;REVISION        CHANGE-CAUSE
1               kubectl apply --filename=deploy.yml --record=true
2               kubectl set image deploy rollout-app rollout-app=kubetutorial/rollout-app:v0.0.2 --record=true
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;You can switch e.g. to revision 1 with the following command:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;kubectl rollout undo deploy rollout-app --to-revision=1
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;The rollout feature of Kubernetes is very well-designed and feature rich. Other things you can do are precisely control the number of percentage of pods that are replaced, or set conditions on failing rollouts so that they can be rolled back automatically by other tools.&lt;/p&gt;
&lt;h2 id=&quot;goingfurther&quot;&gt;Going further&lt;/h2&gt;
&lt;p&gt;Until now, I have been singing Kubernetes' praise, but not everything about it is perfect, unfortunately. We have run into a couple of issues building a Kubernetes cluster. Kubernetes, despite being a relatively young project, is under heavy development, and &lt;a href=&quot;https://gravitational.com/blog/kubernetes-release-cycle/#&quot;&gt;keeping up with it is not a simple job&lt;/a&gt;. The development process is very well-managed, but nevertheless it is a full-time responsibility to keep up with the changes. This situation is mirrored on the provider side of things, as cloud vendors are racing to provide the best hosted Kubernetes solution possible, which also leads to considerable trial-and-error. Azure, for example, started off with a feature called &lt;a href=&quot;https://github.com/Azure/ACS&quot;&gt;ACS&lt;/a&gt;, which was supposed to be a generic container management solution, but quickly recognized how popular Kubernetes was coming, and deprecated ACS in favor of &lt;a href=&quot;https://github.com/Azure/AKS&quot;&gt;AKS&lt;/a&gt; which is directed solely towards Kubernetes, and has extra features such as redundant master nodes. Unfortunately, we are on ACS, and need to make the move to AKS at some point.&lt;/p&gt;
&lt;p&gt;Another thing you have to keep in mind when running Kubernetes is that it has significant platform-dependent parts, and these are not uniform in terms of correctness and reliability. A short time after moving to Kubernetes on Azure, we found out that there was &lt;a href=&quot;https://github.com/Azure/ACS/issues/12&quot;&gt;a serious bug&lt;/a&gt; with Kubernetes on ACS that makes the storage mounting feature of Kubernetes nearly unusable. Our solution is to rely as much as possible on the cloud offerings of Azure such as CosmosDB and managed PostgreSQL, but we will need to use local storage in a service at some point. Fortunately, &lt;a href=&quot;https://github.com/kubernetes/kubernetes/pull/60183&quot;&gt;the bug appears to be fixed&lt;/a&gt; in Kubernetes 1.10.&lt;/p&gt;
&lt;p&gt;As Kubernetes increases in feature set and complexity, tools built on Kubernetes to simplify workloads and provide more integrated workflows have also started popping up. &lt;a href=&quot;https://twitter.com/kelseyhightower/status/969616896604581888&quot;&gt;Kubernetes was never meant as the last application level&lt;/a&gt;, meaning that there will be tools that build up on it for specific developer workflows, which is already happening. It looks like Helm is the most popular choice on this front, but there are other alternatives such as OpenShift. So be prepared to learn another tool that runs on top of Kubernetes in the near future.&lt;/p&gt;
&lt;h2 id=&quot;bonusshellhelpers&quot;&gt;Bonus: Shell Helpers&lt;/h2&gt;
&lt;p&gt;There are a couple motions you repeat over and over when you are working on a Kubernetes cluster. One of these is getting the name of a pod. As the pod name is derived from the name of the deployment, you end up running &lt;code&gt;kubectl get pods&lt;/code&gt; and either grepping it searching it visually. In the case of single-pod deployments, fetching the name of the pod is very eash with the following bash function:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function podname {
    kc get pods | grep $1 | awk '{print $1}';
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;If you want the name of the &lt;code&gt;simple-python-app&lt;/code&gt; pod, for example, you would need to run something as simple as &lt;code&gt;podname simple&lt;/code&gt;. You can also use this function as argument to other kubectl commands, e.g. to print the logs with &lt;code&gt;kubectl logs `podname simple`&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Another handy snippet (written by my Bash Jedi Master friend Matthias Krull) is the following, which lets you switch between Kubernetes configurations like between Python virtual environments:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function kubeon {
    if [ &quot;${1}&quot; ]; then
        local config_file=&quot;${1}&quot;
    else
        echo &quot;Usage: kubeon &amp;lt;config|config_file&amp;gt;&quot;
        return 1
    fi

    if [ ! -f &quot;${1}&quot; ]; then
        config_file=&quot;${HOME}/.kube/${1}&quot;
    fi

    if [ ! -f &quot;${config_file}&quot; ]; then
        echo &quot;No config file found. Tried ${1} and ${config_file}&quot;
        return 1
    fi

    export KUBECONFIG=&quot;${HOME}/.kube/${1}&quot;
    export KUBEON_PROMPT=&quot;${1}&quot;
    export KUBE_MASTER=$(kubectl config view|grep server:|cut -d/ -f3)

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Using this function, you can set any one of the configuration files in your &lt;code&gt;~/.kube&lt;/code&gt; directory as the current configuration with &lt;code&gt;kubeon filename&lt;/code&gt;. Among the variables set are &lt;code&gt;KUBEON_PROMPT&lt;/code&gt;, which you can use in your &lt;code&gt;PS1&lt;/code&gt; to visualize the active Kubernetes configuration, and the &lt;code&gt;KUBE_MASTER&lt;/code&gt; URL which might come in handy if you want to SSH to it.&lt;/p&gt;
</description>
<pubDate>Thu, 05 Jul 2018 10:05:58 +0000</pubDate>
<dc:creator>afroisalreadyin</dc:creator>
<og:type>article</og:type>
<og:title>A Tutorial Introduction to Kubernetes</og:title>
<og:description>Kubernetes is the hottest kid on the block among container orchestration tools right now. I started writing this post when we decided to go with Kubernetes at Twyla a year ago, and since then, the developments in the ecosystem have...</og:description>
<og:url>http://okigiveup.net/a-tutorial-introduction-to-kubernetes/</og:url>
<dc:format>text/html</dc:format>
<dc:identifier>http://okigiveup.net/a-tutorial-introduction-to-kubernetes/</dc:identifier>
</item>
<item>
<title>Why I Don&amp;#039;t Love Gödel, Escher, Bach</title>
<link>https://blog.infinitenegativeutility.com/2018/7/why-i-dont-love-godel-escher-bach</link>
<guid isPermaLink="true" >https://blog.infinitenegativeutility.com/2018/7/why-i-dont-love-godel-escher-bach</guid>
<description>&lt;p&gt;Douglas Hofstadter’s book &lt;em&gt;Gödel, Escher, Bach: An Eternal Golden Braid&lt;/em&gt; is a classic text that’s had a strong influence on countless people. It’s a venerated book among a certain stripe of computer scientist and mathematician, and it’s reputed to have inspired generations of people to pursue the study of logic and artificial intelligence. It’s a meandering meditation of a number of topics that oscillates around logic, language, formal systems, biology, neurology, music, art, and many more topics, with a particularly strong showing from the three titular figures—the logician Kurt Gödel, the artist Maurits Cornelis Escher, and the composer Johann Sebastian Bach—as well as a heaping dose of writer and mathematician Lewis Carroll, who does not appear in the title but, at least on my copy, is explicitly invoked by the subtitle, “A metaphorical fugue on minds and machines in the spirit of Lewis Carroll.” Many people count it as one of their very favorite books.&lt;/p&gt;
&lt;p&gt;So, if you’re among the latter group, I should warn you that I’m about to give it a very lukewarm review.&lt;/p&gt;
&lt;p&gt;I first read &lt;em&gt;Gödel, Escher, Bach&lt;/em&gt; when I was about 20, while I was an undergraduate, and it’s important to note that I was double-majoring in computer science and linguistics, and had a particular love of formal systems and logic, but was also proudly a generalist, and had a long-standing love of literature and music. That particular configuration of interests meant that this book was laser-focused to speak to exactly the things that I loved. It was a perfect book for me!&lt;/p&gt;
&lt;p&gt;…well, it would have been, but for some reason I kept struggling to get through it. I thought highly of it, but my secret shame was that my admiration for the book was based mostly on the first two hundred or so pages. It took slogging effort to get myself through the rest, effort sporadically applied over the course of years. I did eventually make my way through the whole thing, but even now, I can’t necessarily be sure I’ve read and absorbed every page, even though I’ve certainly &lt;em&gt;looked at&lt;/em&gt; each one. By the end, my impression of the book was much more reserved: it does have some genuine high points and I can understand how it came to have its classic reputation, but I also felt it had a number of problems I’ve rarely seen discussed. For me personally, it ended up falling short of its reputation as a sparkling, effervescent text that drew together art, mathematics, and culture, and given how little I’ve seen this discussed, I wanted to write down why I feel this way.&lt;/p&gt;
&lt;p&gt;The book is arranged into chapters, each beginning with a dialogue explaining a concept often using imaginative metaphor and a Socratic style, which is followed by a more traditional prose exploration of the concepts introduced in the dialogues. The dialogues are a big part of why I originally struggled with the book: they are meandering and long, and they regularly outstay their welcome. The Socratic style is a difficult one to write well without seeming contrived and difficult, and the book occasionally manages it, but it often falls incredibly flat: usually, they feature one character (usually Tortoise) explaining something verbosely, with conversational asides, but otherwise more or less mechanically, while the other character (usually Achilles) simply responds, “I see! Aha!” and follows up with a question that no real learner would ask but happens to be the next thing Hofstadter wants to talk about.&lt;/p&gt;
&lt;p&gt;The other sections revisit the same ideas in prose, giving more concrete examples and dispensing with the catechistic form, and as such are able to give much terser and more interesting examples. Many of these are much clearer, and I remember on my first attempt at reading the book I was often tempted to skip the dialogues and read those first, because their explanations were often much more satisfying and took only a fraction of the time to read through. In some cases, the dialogues attempted to use metaphors that were nonsensical or even broken, and &lt;em&gt;only&lt;/em&gt; by reading the chapter afterwards did the dialogue make any sense!&lt;/p&gt;
&lt;p&gt;A good example here is the book’s explanation of &lt;a href=&quot;https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems&quot;&gt;Gödel’s incompleteness theorem&lt;/a&gt;. The high-level, slightly handwavey description of this theorem is that, for any sufficiently expressive mathematical proof system, there are more true facts within the system than there are proofs for facts, which in turn means that not every fact can be proved: in short, that not every mathematical fact has a corresponding mathematical proof. My short explanation papers over a number of important features of this theorem, such as what I meant by a ‘sufficiently expressive mathematical system’, and all those features are addressed much more rigorously by the actual proof. It’s a fascinating theorem, and to Hofstadter’s great credit, &lt;em&gt;Gödel, Escher, Bach&lt;/em&gt; helped bring knowledge of this theorem to a much wider population.&lt;/p&gt;
&lt;p&gt;Unfortunately, when I first began to read the dialogue which touched on the theorem, I was frankly mystified. Hofstadter decided to explain its working by coming up with a metaphor involving record-players and records that are designed to physically break the record-players they’re played on. I’m familiar with how record-players work, but I have never played a record designed to break a record-player! This isn’t an intuitive metaphor, because while I have intuition for the operation of records and record-players, I don’t have any intuition at all about the universal manufacture of record-player-breaking records. The metaphor raises a number of questions: can the problem of record-player-breaking-records be suitably addressed by redesigning record-players? If no, why not? What if we simply read the information from a record using a visual device with no moving parts? What if we…?&lt;/p&gt;
&lt;p&gt;A good metaphor has depth: you can convert a situation into the metaphor, visualize or reason about the implications of the metaphorical situation in isolation of the original situation, and then apply that back and have learned something about the original situation. However, the record-players in this metaphor don’t actually work like record-players in the real world, so my own lack of intuition means that reasoning about the original situation via the metaphor is effectively impossible. When I first read the dialogue, I had no idea what was being explained: once I started the following prose chapter, I realized that the “record-players” were formal systems, “records” in were theorems designed to be unprovable within those formal systems, and that the whole thing was an awkward physical metaphor for Gödel’s incompleteness theorem. In fact, it was only this realization that made me fully grasp the workings of metaphor in the first place: instead of the metaphor illuminating the theorem, I had to use my knowledge of the actual theorem to grasp what Hofstadter intended for the metaphor!&lt;/p&gt;
&lt;p&gt;This is a pretty egregiously bad example, but it was also the point in the book where I realized that I &lt;em&gt;wanted&lt;/em&gt; to like the book much more than I actually liked it in practice. I began to read onward and reread past sections with more skepticism, and I realized that the weaknesses which were particularly evident in the dialogue about Gödel’s paradox were still partially present in many of the other dialogues. The original inspiration for the dialogue chapters was Lewis Carroll’s short allegory &lt;em&gt;What The Tortoise Said To Achilles&lt;/em&gt;, which expands on Zeno’s paradox of motion to make a point about the foundations of logic. Carroll’s dialogue is tight and focused and uses a rather clever metaphor, but the dialogues that punctuate &lt;em&gt;Gödel, Escher, Bach&lt;/em&gt; are broad and meandering and the metaphors range from moderately serviceable to (like the one above) actively nonsensical, and the writing style is a mostly-mediocre Carroll pastiche, which means the characters often gratingly pepper their dialogue with interjections like, “Oh, my gracious! Oh, dear me! Oh, but you misunderstand! Go-golly! Oh, but that certainly won’t do!” I eventually came to the conclusion that, while the dialogues &lt;em&gt;are&lt;/em&gt; one of the more memorable features of the book, they’re also an active impediment to conveying much of the book’s material in an efficient and clear way.&lt;/p&gt;
&lt;p&gt;The non-dialogue chapters, as I’ve said, are better, although they also range in quality. Many of them are clear, lucid explanations of mathematical concepts intended for a layperson, which often begin by introducing mathematical systems through simple examples, showing what can be done with pure symbol manipulation of those systems, and only afterwards pulling back the curtain to explain what they “mean” in a mathematical sense. The explanations of computational systems have a similar quality, although several of the later chapters feel rather too complicated for their comparatively simple conclusions. On the other hand, the topics that aren’t about math or computers (or the shorter bits on workings of DNA) are introduced in a disappointingly cursory way that mostly consists of handwaving and pictures. Those latter sections lack depth and often betray strikingly little familiarity with or respect for the topic in question.&lt;/p&gt;
&lt;p&gt;To give an egregious but illustrative example: Hofstadter mentions the experimental composer John Cage on a number of occasions, often bringing up Cage’s modernist and aleatoric work as a counterpoint to the meticulously tightly-constructed melodies of Bach. Hofstadter is unsurprisingly negative about Cage’s work, and usually characterizes it as avant-garde social commentary masquerading as music, and at one point a dialogue wryly suggests that John Cage might belong in a zoo. John Cage is most famous—or most infamous—for his piece &lt;a href=&quot;https://en.wikipedia.org/wiki/4%E2%80%B233%E2%80%B3&quot;&gt;4’33&quot;&lt;/a&gt;, which requires that a performer or group of performers walk onto stage and do not play their instruments for four minutes and thirty-three seconds. (It properly consists of three individual “movements” of non-playing whose lengths have been inconsistently specified across various editions of the score.) Hofstadter brings this piece up in a dialogue:&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;Tortoise: […John Cage] has composed many celebrated pieces, such as &lt;em&gt;4’33&quot;&lt;/em&gt;, a three-movement piece consisting of silences of different lengths. It’s wonderfully expressive—if you like that sort of thing.&lt;br/&gt;Achilles: I can see where if I were in a loud and brash café I might gladly pay to hear Cage’s &lt;em&gt;4’33&quot;&lt;/em&gt; on a jukebox. It might afford some relief!&lt;br/&gt;Tortoise: Right—who wants to hear the racket of clinking dishes and jangling silverware?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Tortoise’s (and Hofstadter’s) explanation of Cage’s piece is fairly typical of explanations given of the piece: that is, four minutes and thirty-three seconds of silence. But this is, according to Cage’s intentions, a strictly incorrect interpretation of what he was trying to do! Cage’s actual intention in creating &lt;em&gt;4’33&quot;&lt;/em&gt; was not to depict pure silence, but rather to force listeners in an auditorium to pay attention to the quiet and subtle sounds which they usually ignore when they listen to music. To make this painfully explicit, here is a quote from Cage about the original premiere of &lt;em&gt;4’33&quot;&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;They missed the point. There’s no such thing as silence. What they thought was silence, because they didn’t know how to listen, was full of accidental sounds. You could hear the wind stirring outside during the first movement. During the second, raindrops began pattering the roof, and during the third the people themselves made all kinds of interesting sounds as they talked or walked out.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Consequently, when Achilles and Tortoise agree that they’d rather hear silence than the sounds of a café, they’re getting the point of _4’33“_ exactly backwards: a performance of &lt;em&gt;4’33&quot;&lt;/em&gt; in a café should ideally compel you to listen to the”racket of clinking dishes and jangling silverware&quot; with more awareness than usual!&lt;/p&gt;
&lt;p&gt;As I said, this isn’t an uncommon misunderstanding of John Cage’s intentions, and reasonable people can and do differ as to whether _4’33“_ is a reasonable execution of that intention, or if that intention is reasonable in the first place. However, even with a charitable reading of &lt;em&gt;Gödel, Escher, Bach&lt;/em&gt;, it’s clear that Hofstadter isn’t disputing Cage’s artistic intention: instead, he doesn’t seem to know what sort of artistic intention Cage actually &lt;em&gt;has&lt;/em&gt;, preferring to read his own ideas about social commentary into Cage’s work. His understanding of Cage and of the musical context in which Cage works is marked by a lack of context, a lack of deep engagement with the ideas there, and most importantly, a lack of &lt;em&gt;respect&lt;/em&gt;. In the preface to my edition, he claims that he had,”…unambiguously heaped scorn on Cage’s music, albeit in a somewhat respectful manner,&quot; but there’s very little respect or willingness to meet Cage on Cage’s own terms here, only guarded derision, and that lack of engagement ends up weakening every section that tries to discuss John Cage in particular and modernist music in general.&lt;/p&gt;
&lt;p&gt;This sort of cursory engagement with the cultural features of the book ends up undermining one of the book’s major selling points: I had originally seen it as the work of a polymath effortlessly weaving fields together into a multifaceted but uniform whole, but in reality, areas that are more than a step or two outside Hofstadter’s areas of expertise (computer science, formal logic, some of the more mathematically rigorous bits of cognitive science) are at best shallow, and at worst are “…heaping scorn…” on things Hofstadter doesn’t understand and doesn’t appear to want to understand.&lt;/p&gt;
&lt;p&gt;Despite the relatively surface-level interaction Hofstadter has with the world outside of mathematics and computers, he nevertheless loves to drop in thick, multilayered references to such topics in every cranny he can find. The central two characters in the dialogues are Achilles and Tortoise, borrowed directly from Lewis Carroll’s story above (which in turn borrowed them from the famous paradoxes of the Greek philosopher &lt;a href=&quot;https://en.wikipedia.org/wiki/Zeno%27s_paradoxes&quot;&gt;Zeno&lt;/a&gt;), and a Crab and a Genie show up on occasion as well. Their names are regularly abbreviated to a single letter, which means you can’t help but notice that those letters happen to map to the names of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Nucleobase&quot;&gt;nucleobases&lt;/a&gt; that appear in DNA—adenine, thymine, cytosine, and guanine. All the dialogues have sing-song names that are usually inspired by music, such as &lt;em&gt;Sonata for Unaccompanied Achilles&lt;/em&gt; or &lt;em&gt;Canon by Intervallic Augmentation&lt;/em&gt; or &lt;em&gt;Birthday Cantatatata&lt;/em&gt;. Off-hand mentions of people and places are often wry and unexplained cultural allusions: a typical example is that, at one point in a conversation about popcorn, Tortoise awkwardly shoehorns in the story of a “Schönberg factory” in Vienna that outraged consumers by stopping production of a delicious tonic in favor of a boring cereal, this being a nod to the &lt;a href=&quot;https://en.wikipedia.org/wiki/Arnold_Schoenberg&quot;&gt;Viennese composer Arnold Schoenberg&lt;/a&gt;’s transition from traditional melodic compositions to experimental atonal pieces, a nod that never comes up elsewhere in the text of merits any explanation.&lt;/p&gt;
&lt;p&gt;I will admit right away that I personally find these heaps of unnecessary nods more tedious than interesting or endearing. There’s a lot of &lt;em&gt;reference&lt;/em&gt;, but very little of it &lt;em&gt;means&lt;/em&gt; anything. Occasionally, a dialogue will use these references to actually explain something—one dialogue is written in the form of a &lt;a href=&quot;https://en.wikipedia.org/wiki/Crab_canon&quot;&gt;crab canon&lt;/a&gt;, and thus is identical when read forward or backward, as a memorable way of explaining that form of &lt;a href=&quot;https://en.wikipedia.org/wiki/Canon_(music)&quot;&gt;musical canon&lt;/a&gt;—but most of the musical or biological or literary allusions are there really for their own sake. These things are rarely being commented on, or discussed in interesting context, or connected to other ideas. Instead, these ideas simply appear because this is a book in which ideas appear, interrupting the text for a shoehorned cameo, like Stan Lee in a comic book movie. Why do the characters’ names map to nucleobases? I suspect if you asked Hofstadter, he’d claim it’s because one of the themes of the book is that all these ideas are connected (in the titular “golden braid”), but this kind of reference doesn’t actually &lt;em&gt;connect&lt;/em&gt; anything to anything: it merely presents things adjacent to each other. It’s all flavor, no substance.&lt;/p&gt;
&lt;p&gt;This might seem unfair, so I’ll give a very specific but pervasive instance of this sort of meaningless flavor. Many parts of the book invoke Zen, which is a school of Buddhism that originated in China and has spread to several other Asian countries but, in the Western mind, is usually associated with Japan. (We do, after all, know this school by its Japanese name &lt;em&gt;Zen&lt;/em&gt; and not by its Chinese name &lt;em&gt;Chán&lt;/em&gt;, its Korean name &lt;em&gt;Sean&lt;/em&gt;, or its Vietnamese name &lt;em&gt;Thiền&lt;/em&gt;.) Hofstadter’s idea of Zen is a substance-less cliché: it consists almost entirely of faux-Eastern “Oriental” aesthetics and some handwaving about &lt;em&gt;kōans&lt;/em&gt; (which are stories used in Zen practice for teaching and meditation) without really delving into any particular aspect of actual Zen thought or practice. There are lots of &lt;em&gt;references&lt;/em&gt; to it—for example, he names a theorem &lt;code&gt;MUMON&lt;/code&gt;, after the Japanese name of Zen master &lt;a href=&quot;https://en.wikipedia.org/wiki/Wumen_Huikai&quot;&gt;Wúmén Huìkāi&lt;/a&gt;, as part of a vague and largely pun-based connection to one of Wúmén’s collected kōans—but none of those references have any substantial connection to the history or practice of Zen. In reality, Zen is a religious sect with history and cultural context and a complicated, multifaceted conversation that has been carried on throughout centuries. In Hofstadter’s telling, Zen is just some funny nonsensical stories from Japan.&lt;/p&gt;
&lt;p&gt;The edition I have includes a preface in which Hofstadter talks, twenty years after the book’s release, about the book itself, its reception, and its legacy, and he goes out of his way to complain about a negative review of the book which accused him of being a hippie trying to popularize Zen. Hofstadter objects to this review because&lt;/p&gt;
&lt;blockquote readability=&quot;14&quot;&gt;
&lt;p&gt;As I declare at the start of Chapter 9, I find Zen not only confusing and silly, but on a very deep level utterly inimical to my core beliefs. However, I also find Zen’s silliness—especially when it gets &lt;em&gt;really&lt;/em&gt; silly—quite amusing, even refreshing, and it was simply fun for me to sprinkle a bit of Eastern spice into my basically very Western casserole. However, my having sprinkled little traces of Zen here and there does not mean that I am a Zen monk in sheep’s clothing.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this passage, Hofstadter openly admits to exactly the charge I’m bringing: that his inclusion of Zen is all about clichéd aesthetics (“Eastern spice”) and not at all about any of its substance—in this case, because he apparently doesn’t seem to think it has any!&lt;/p&gt;
&lt;p&gt;What Hofstadter doesn’t admit to, but what I would argue, is that the &lt;em&gt;whole book&lt;/em&gt; does this with almost every non-mathematical topic it tackles. His explanations of mathematics-adjacent topics do have substance and are often reasonably well-explained, but every time he branches out, he doesn’t seem to realize that he’s regurgitating shallow, half-misunderstood cliché: his discussions of modern art and music are, as I mentioned before, deeply lacking in this regard, but he name-checks plenty of artists, musicians, and writers with a high school understanding of who they were and what they did, preferring to pepper the text with photos of wacky paintings, drawing he made of letters that are made up of other letters, and tales of half-understood &lt;em&gt;kōans&lt;/em&gt;. They’re all spice: his “casserole” is a few insubstantial layers of food underneath inch-thick layers of spices.&lt;/p&gt;
&lt;p&gt;This also presents a problem with the entire underlying &lt;em&gt;program&lt;/em&gt; of the book: it’s supposed to present examples of a common important idea—self-reference—resurfacing throughout various disparate areas, including mathematics and computation and art and music, but while this idea is well-motivated in the parts about mathematics and computation, but because most of the other topics the book tackles end up being just shallow aesthetics, then the “deep connections” there can only be present in shallow aesthetic ways. This was, for me, the ultimate breakdown of the promise of the book, as the grand unifying theme—the titular “eternal golden braid” of self-referential structures across domains—was only capable of unifying a few problem domains, as the rest of those connections were pretty but ultimately insubstantial.&lt;/p&gt;
&lt;p&gt;While rereading bits of the book in order to write this post, I flipped through it at random and came across the photos marked as &lt;em&gt;Figure 81&lt;/em&gt;, which in my copy at least appears on pages 490 and 491. These pages contain photos of television screens that are in turn displaying geometric images that result from pointing a camera at the screen: infinite turning shapes, nested and sweeping frames, eventually deforming into twirling light patterns. They are described in captions, beginning with plain descriptions like, “What happens when you rotate the camera,” and gradually becoming more florid, with captions like, “The galaxy has burned itself out, and become—a black hole!” The actual caption beneath these photos says the following:&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;Twelve self-engulfing TV screens. I would have included one more, had 13 not been prime.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;These photos are fun! They feel especially endearing in 2018 because of the late-70’s television depicted, and they depict a fun experiment that I did as a child as soon as I got my hands on my parents’ bulky camcorder. The captions, however, add very little, and the final comment (“…had 13 not been prime”) includes a bit of extra unnecessary whimsy that seems to wink at the reader but adds absolutely no meaning. Like so much of the book, it seems to hint at something grander while not signifying anything in particular. The photos themselves might be a fun illustration of &lt;em&gt;something&lt;/em&gt;, but they’re not a particularly deep illustration of anything, and their inclusion here (surrounded by several pages of Achilles and Tortoise pontificating about the notion of “self-engulfing”) doesn’t bring any more enlightenment than when I first pointed a camcorder at a TV when I was four.&lt;/p&gt;
&lt;p&gt;“A fun illustration of &lt;em&gt;something&lt;/em&gt;,” is pretty much as far as the book goes: it hints at grand unifying patterns, but the pattern it finds is just the abstract notion of self-reference, and then it keeps bringing it up, making a few unnecessary references, showing some pictures, and asking, “Isn’t that &lt;em&gt;cool&lt;/em&gt;? Isn’t that &lt;em&gt;weird&lt;/em&gt;?” It’ll give a perfectly competent (if somewhat verbose) description of formal systems, but as soon as it tries to venture connections to other domains, or to explain more complicated or nuanced details, it turns out that the only connections it can draw consist of vigorous handwaving. The whole book boils down to Hofstadter giving a competent lecture on logic, intimating the existence of an eternal golden braid, and then pointing at some fun photos of televisions.&lt;/p&gt;
</description>
<pubDate>Thu, 05 Jul 2018 07:34:19 +0000</pubDate>
<dc:creator>DyslexicAtheist</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.infinitenegativeutility.com/2018/7/why-i-dont-love-godel-escher-bach</dc:identifier>
</item>
<item>
<title>WebSub: Open protocol for distributed pub–sub communication on the internet</title>
<link>https://www.w3.org/TR/websub/</link>
<guid isPermaLink="true" >https://www.w3.org/TR/websub/</guid>
<description>&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;/&gt;&lt;meta name=&quot;generator&quot; content=&quot;ReSpec 19.0.1&quot;/&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1, shrink-to-fit=no&quot;/&gt;&lt;meta lang=&quot;&quot; property=&quot;dc:language&quot; content=&quot;en&quot;/&gt;&lt;title&gt;WebSub&lt;/title&gt;&lt;link rel=&quot;pingback&quot; href=&quot;https://webmention.io/w3c/xmlrpc&quot;/&gt;&lt;link rel=&quot;webmention&quot; href=&quot;https://webmention.io/w3c/webmention&quot;/&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://www.w3.org/StyleSheets/TR/2016/W3C-REC&quot; type=&quot;text/css&quot;/&gt;&lt;link rel=&quot;canonical&quot; href=&quot;https://www.w3.org/TR/websub/&quot;/&gt;&lt;meta name=&quot;description&quot; content=&quot;WebSub provides a common mechanism for communication between publishers of any kind of Web content and their subscribers, based on HTTP web hooks. Subscription requests are relayed through hubs, which validate and verify the request. Hubs then distribute new and updated content to subscribers when it becomes available. WebSub was previously known as PubSubHubbub.&quot;/&gt;&lt;/head&gt;&lt;body aria-busy=&quot;false&quot; class=&quot;h-entry&quot; id=&quot;readabilityBody&quot; readability=&quot;108.69197952218&quot;&gt;

&lt;section id=&quot;abstract&quot; class=&quot;introductory&quot; readability=&quot;7&quot;&gt;&lt;h2 id=&quot;abstract-0&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;WebSub provides a common mechanism for communication between publishers of any kind of Web content and their subscribers, based on HTTP web hooks. Subscription requests are relayed through hubs, which validate and verify the request. Hubs then distribute new and updated content to subscribers when it becomes available. WebSub was previously known as PubSubHubbub.&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;sotd&quot; class=&quot;introductory&quot; readability=&quot;22.218731820826&quot;&gt;&lt;h2 id=&quot;status-of-this-document&quot;&gt;Status of This Document&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;This section describes the status of this document at the time of its publication. Other documents may supersede this document. A list of current &lt;abbr title=&quot;World Wide Web Consortium&quot;&gt;W3C&lt;/abbr&gt; publications and the latest revision of this technical report can be found in the &lt;a href=&quot;https://www.w3.org/TR/&quot;&gt;&lt;abbr title=&quot;World Wide Web Consortium&quot;&gt;W3C&lt;/abbr&gt; technical reports index&lt;/a&gt; at https://www.w3.org/TR/.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This document was published by the &lt;a href=&quot;https://www.w3.org/Social/WG&quot;&gt;Social Web Working Group&lt;/a&gt; as a Recommendation. Comments regarding this document are welcome. All interested parties are invited to provide implementation and bug reports and other comments through the Working Group's &lt;a href=&quot;https://github.com/w3c/websub/issues&quot;&gt;Issue tracker&lt;/a&gt;. These will be discussed by the &lt;a href=&quot;http://www.w3.org/wiki/SocialCG&quot;&gt;Social Web Community Group&lt;/a&gt; and considered in any future versions of this specification.&lt;/p&gt;
&lt;p&gt;Please see the Working Group's &lt;a href=&quot;https://websub.net/implementation-reports&quot;&gt;implementation report&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This document has been reviewed by &lt;abbr title=&quot;World Wide Web Consortium&quot;&gt;W3C&lt;/abbr&gt; Members, by software developers, and by other &lt;abbr title=&quot;World Wide Web Consortium&quot;&gt;W3C&lt;/abbr&gt; groups and interested parties, and is endorsed by the Director as a &lt;abbr title=&quot;World Wide Web Consortium&quot;&gt;W3C&lt;/abbr&gt; Recommendation. It is a stable document and may be used as reference material or cited from another document. &lt;abbr title=&quot;World Wide Web Consortium&quot;&gt;W3C&lt;/abbr&gt;'s role in making the Recommendation is to draw attention to the specification and to promote its widespread deployment. This enhances the functionality and interoperability of the Web.&lt;/p&gt;
&lt;p&gt;This document was produced by a group operating under the &lt;a href=&quot;https://www.w3.org/Consortium/Patent-Policy/&quot;&gt;&lt;abbr title=&quot;World Wide Web Consortium&quot;&gt;W3C&lt;/abbr&gt; Patent Policy&lt;/a&gt;. &lt;abbr title=&quot;World Wide Web Consortium&quot;&gt;W3C&lt;/abbr&gt; maintains a &lt;a href=&quot;https://www.w3.org/2004/01/pp-impl/72531/status&quot; rel=&quot;disclosure&quot;&gt;public list of any patent disclosures&lt;/a&gt; made in connection with the deliverables of the group; that page also includes instructions for disclosing a patent. An individual who has actual knowledge of a patent which the individual believes contains &lt;a href=&quot;https://www.w3.org/Consortium/Patent-Policy/#def-essential&quot;&gt;Essential Claim(s)&lt;/a&gt; must disclose the information in accordance with &lt;a href=&quot;https://www.w3.org/Consortium/Patent-Policy/#sec-Disclosure&quot;&gt;section 6 of the &lt;abbr title=&quot;World Wide Web Consortium&quot;&gt;W3C&lt;/abbr&gt; Patent Policy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This document is governed by the &lt;a id=&quot;w3c_process_revision&quot; href=&quot;https://www.w3.org/2017/Process-20170301/&quot;&gt;1 March 2017 &lt;abbr title=&quot;World Wide Web Consortium&quot;&gt;W3C&lt;/abbr&gt; Process Document&lt;/a&gt;.&lt;/p&gt;
&lt;/section&gt;&lt;nav id=&quot;toc&quot;&gt;&lt;h2 class=&quot;introductory&quot; id=&quot;table-of-contents&quot;&gt;Table of Contents&lt;/h2&gt;
&lt;ol class=&quot;toc&quot;&gt;&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#definitions&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;1.&lt;/span&gt; Definitions&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#high-level-protocol-flow&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;2.&lt;/span&gt; High-level protocol flow&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#conformance&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.&lt;/span&gt; Conformance&lt;/a&gt;
&lt;ol class=&quot;toc&quot;&gt;&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#conformance-classes&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.1&lt;/span&gt; Conformance Classes&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#candidate-recommendation-exit-criteria&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.2&lt;/span&gt; Candidate Recommendation Exit Criteria&lt;/a&gt;
&lt;ol class=&quot;toc&quot;&gt;&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#publisher&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.2.1&lt;/span&gt; Publisher&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#subscriber&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.2.2&lt;/span&gt; Subscriber&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#hub&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.2.3&lt;/span&gt; Hub&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#independent&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.2.4&lt;/span&gt; Independent&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#interoperable&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.2.5&lt;/span&gt; Interoperable&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#feature&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.2.6&lt;/span&gt; Feature&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#discovery&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;4.&lt;/span&gt; Discovery&lt;/a&gt;
&lt;ol class=&quot;toc&quot;&gt;&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#content-negotiation&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;4.1&lt;/span&gt; Content Negotiation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#subscribing-and-unsubscribing&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;5.&lt;/span&gt; Subscribing and Unsubscribing&lt;/a&gt;
&lt;ol class=&quot;toc&quot;&gt;&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#subscriber-sends-subscription-request&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;5.1&lt;/span&gt; Subscriber Sends Subscription Request&lt;/a&gt;
&lt;ol class=&quot;toc&quot;&gt;&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#subscription-parameter-details&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;5.1.1&lt;/span&gt; Subscription Parameter Details&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#subscription-response-details&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;5.1.2&lt;/span&gt; Subscription Response Details&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#subscription-validation&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;5.2&lt;/span&gt; Subscription Validation&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#hub-verifies-intent&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;5.3&lt;/span&gt; Hub Verifies Intent of the Subscriber&lt;/a&gt;
&lt;ol class=&quot;toc&quot;&gt;&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#verification-details&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;5.3.1&lt;/span&gt; Verification Details&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#publishing&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;6.&lt;/span&gt; Publishing&lt;/a&gt;
&lt;ol class=&quot;toc&quot;&gt;&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#subscription-migration&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;6.1&lt;/span&gt; Subscription Migration&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#content-distribution&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;7.&lt;/span&gt; Content Distribution&lt;/a&gt;
&lt;ol class=&quot;toc&quot;&gt;&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#signing-content&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;7.1&lt;/span&gt; Authenticated Content Distribution&lt;/a&gt;
&lt;ol class=&quot;toc&quot;&gt;&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#recognized-algorithm-names&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;7.1.1&lt;/span&gt; Recognized algorithm names&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#signature-validation&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;7.1.2&lt;/span&gt; Signature validation&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#security-considerations&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;8.&lt;/span&gt; Security Considerations&lt;/a&gt;
&lt;ol class=&quot;toc&quot;&gt;&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#discovery-0&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;8.1&lt;/span&gt; Discovery&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#subscriptions&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;8.2&lt;/span&gt; Subscriptions&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#distribution&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;8.3&lt;/span&gt; Distribution&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#security-and-privacy-review&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;8.4&lt;/span&gt; Security and Privacy Review&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#acknowledgements&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;A.&lt;/span&gt; Acknowledgements&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#change-log&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;B.&lt;/span&gt; Change Log&lt;/a&gt;
&lt;ol class=&quot;toc&quot;&gt;&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#changes-from-03-october-2017-pr-to-this-version&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;B.1&lt;/span&gt; Changes from 03 October 2017 PR to this version&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#changes-from-11-april-2017-cr-to-03-october-2017-pr&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;B.2&lt;/span&gt; Changes from 11 April 2017 CR to 03 October 2017 PR&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#changes-from-24-november-wd-to-11-april-2017-cr&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;B.3&lt;/span&gt; Changes from 24 November WD to 11 April 2017 CR&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#changes-from-20-october-fpwd-to-24-november-2016&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;B.4&lt;/span&gt; Changes from 20 October FPWD to 24 November 2016&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#references&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;C.&lt;/span&gt; References&lt;/a&gt;
&lt;ol class=&quot;toc&quot;&gt;&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#normative-references&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;C.1&lt;/span&gt; Normative references&lt;/a&gt;&lt;/li&gt;
&lt;li class=&quot;tocline&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#informative-references&quot; class=&quot;tocxref&quot;&gt;&lt;span class=&quot;secno&quot;&gt;C.2&lt;/span&gt; Informative references&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/nav&gt;&lt;section id=&quot;definitions&quot;&gt;&lt;h2 id=&quot;x1-definitions&quot;&gt;&lt;span class=&quot;secno&quot;&gt;1.&lt;/span&gt; Definitions&lt;/h2&gt;
&lt;dl&gt;&lt;dt&gt;&lt;dfn data-dfn-type=&quot;dfn&quot; id=&quot;dfn-topic&quot;&gt;Topic&lt;/dfn&gt;&lt;/dt&gt;
&lt;dd&gt;An HTTP [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC7230&quot;&gt;RFC7230&lt;/a&gt;&lt;/cite&gt;] (or HTTPS [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC2818&quot;&gt;RFC2818&lt;/a&gt;&lt;/cite&gt;]) resource URL. The unit to which one can subscribe to changes.&lt;/dd&gt;
&lt;dt&gt;&lt;dfn data-dfn-type=&quot;dfn&quot; id=&quot;dfn-hub-the-hub&quot;&gt;Hub (&quot;the hub&quot;)&lt;/dfn&gt;&lt;/dt&gt;
&lt;dd&gt;The server (URL [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-URL&quot;&gt;URL&lt;/a&gt;&lt;/cite&gt;]) which implements both sides of this protocol. Any hub &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; implement its own policies on who can use it.&lt;/dd&gt;
&lt;dt&gt;&lt;dfn data-dfn-type=&quot;dfn&quot; id=&quot;dfn-publisher&quot;&gt;Publisher&lt;/dfn&gt;&lt;/dt&gt;
&lt;dd&gt;An owner of a topic. Notifies the hub when the topic feed has been updated. As in almost all pubsub systems, the publisher is unaware of the subscribers, if any. Other pubsub systems might call the publisher the &quot;source&quot;.&lt;/dd&gt;
&lt;dt&gt;&lt;dfn data-dfn-type=&quot;dfn&quot; id=&quot;dfn-subscriber&quot;&gt;Subscriber&lt;/dfn&gt;&lt;/dt&gt;
&lt;dd&gt;An entity (person or program) that wants to be notified of changes on a topic. The subscriber must be directly network-accessible and is identified by its Subscriber Callback URL.&lt;/dd&gt;
&lt;dt&gt;&lt;dfn data-dfn-type=&quot;dfn&quot; id=&quot;dfn-subscription&quot;&gt;Subscription&lt;/dfn&gt;&lt;/dt&gt;
&lt;dd&gt;A unique relation to a topic by a subscriber that indicates it should receive updates for that topic. A subscription's unique key is the tuple (Topic URL, Subscriber Callback URL). Subscriptions may (at the hub's decision) have expiration times akin to DHCP leases which must be periodically renewed.&lt;/dd&gt;
&lt;dt&gt;&lt;dfn data-dfn-type=&quot;dfn&quot; id=&quot;dfn-subscriber-callback-url&quot;&gt;Subscriber Callback URL&lt;/dfn&gt;&lt;/dt&gt;
&lt;dd&gt;The URL [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-URL&quot;&gt;URL&lt;/a&gt;&lt;/cite&gt;] at which a subscriber wishes to receive content distribution requests.&lt;/dd&gt;
&lt;dt&gt;&lt;dfn data-dfn-type=&quot;dfn&quot; id=&quot;dfn-event&quot;&gt;Event&lt;/dfn&gt;&lt;/dt&gt;
&lt;dd&gt;An event that causes updates to multiple topics. For each event that happens (e.g. &quot;Brad posted to the Linux Community.&quot;), multiple topics could be affected (e.g. &quot;Brad posted.&quot; and &quot;Linux community has new post&quot;). Publisher events cause topics to be updated and the hub looks up all subscriptions for affected topics, delivering the content to subscribers.&lt;/dd&gt;
&lt;dt&gt;&lt;dfn data-dfn-type=&quot;dfn&quot; id=&quot;dfn-content-distribution-notification&quot;&gt;Content Distribution Notification&lt;/dfn&gt; / &lt;dfn data-dfn-type=&quot;dfn&quot; id=&quot;dfn-content-distribution-request&quot;&gt;(Content Distribution Request)&lt;/dfn&gt;&lt;/dt&gt;
&lt;dd&gt;A payload describing how a topic's contents have changed, or the full updated content. Depending on the topic's content type, the difference (or &quot;delta&quot;) may be computed by the hub and sent to all subscribers.&lt;/dd&gt;
&lt;/dl&gt;&lt;/section&gt;&lt;section id=&quot;high-level-protocol-flow&quot; readability=&quot;3.6906077348066&quot;&gt;&lt;h2 id=&quot;x2-high-level-protocol-flow&quot;&gt;&lt;span class=&quot;secno&quot;&gt;2.&lt;/span&gt; High-level protocol flow&lt;/h2&gt;
&lt;p&gt;(This section is non-normative.)&lt;/p&gt;
&lt;img src=&quot;https://www.w3.org/TR/websub/websub-overview.svg&quot; alt=&quot;WebSub Protocol Flow Diagram&quot;/&gt;&lt;ul&gt;&lt;li&gt;Subscribers discover the hub of a topic URL, and makes a POST to one or more of the advertised hubs in order to receive updates when the topic changes.&lt;/li&gt;
&lt;li&gt;Publishers notify their hub(s) URLs when their topic(s) change.&lt;/li&gt;
&lt;li&gt;When the hub identifies a change in the topic, it sends a content distribution notification to all registered subscribers.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Earlier versions of this protocol were called PubSubHubbub:&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;conformance&quot; readability=&quot;16.607208872458&quot;&gt;&lt;h2 id=&quot;x3-conformance&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.&lt;/span&gt; Conformance&lt;/h2&gt;
&lt;p&gt;The key words &quot;&lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt;&quot;, &quot;&lt;em class=&quot;rfc2119&quot; title=&quot;MUST NOT&quot;&gt;MUST NOT&lt;/em&gt;&quot;, &quot;&lt;em class=&quot;rfc2119&quot; title=&quot;REQUIRED&quot;&gt;REQUIRED&lt;/em&gt;&quot;, &quot;&lt;em class=&quot;rfc2119&quot; title=&quot;SHALL&quot;&gt;SHALL&lt;/em&gt;&quot;, &quot;&lt;em class=&quot;rfc2119&quot; title=&quot;SHALL NOT&quot;&gt;SHALL NOT&lt;/em&gt;&quot;, &quot;&lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt;&quot;, &quot;&lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD NOT&quot;&gt;SHOULD NOT&lt;/em&gt;&quot;, &quot;&lt;em class=&quot;rfc2119&quot; title=&quot;RECOMMENDED&quot;&gt;RECOMMENDED&lt;/em&gt;&quot;, &quot;&lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt;&quot;, and &quot;&lt;em class=&quot;rfc2119&quot; title=&quot;OPTIONAL&quot;&gt;OPTIONAL&lt;/em&gt;&quot; in this document are to be interpreted as described in [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC2119&quot;&gt;RFC2119&lt;/a&gt;&lt;/cite&gt;].&lt;/p&gt;
&lt;section id=&quot;conformance-classes&quot; readability=&quot;3.6109725685786&quot;&gt;&lt;h3 id=&quot;x3-1-conformance-classes&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.1&lt;/span&gt; Conformance Classes&lt;/h3&gt;
&lt;p&gt;WebSub describes three roles: publishers, subscribers and hubs. This section describes the conformance criteria for each role.&lt;/p&gt;
&lt;h3 id=&quot;publishers&quot;&gt;Publishers&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;A conforming publisher &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; advertise topic and hub URLs for a given resource URL as described in &lt;a href=&quot;https://www.w3.org/TR/websub/#discovery&quot;&gt;Discovery&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;subscribers&quot;&gt;Subscribers&lt;/h3&gt;
&lt;p&gt;A conforming subscriber:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; support each discovery mechanism in the specified order to discover the topic and hub URLs as described in &lt;a href=&quot;https://www.w3.org/TR/websub/#discovery&quot;&gt;Discovery&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; send a subscription request as described in &lt;a href=&quot;https://www.w3.org/TR/websub/#subscriber-sends-subscription-request&quot;&gt;Subscriber Sends Subscription Request&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; request a specific lease duration&lt;/li&gt;
&lt;li&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; include a secret in the subscription request, and if it does, then &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; use the secret to verify the signature in the &lt;a href=&quot;https://www.w3.org/TR/websub/#authenticated-content-distribution&quot;&gt;content distribution request&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; acknowledge a content distribution request with an HTTP 2xx status code.&lt;/li&gt;
&lt;li&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; request that a subscription is deactivated using the &quot;unsubscribe&quot; mechanism.&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;hubs&quot;&gt;Hubs&lt;/h4&gt;
&lt;p&gt;A conforming hub:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; accept a subscription request with the parameters &lt;code&gt;hub.callback&lt;/code&gt;, &lt;code&gt;hub.mode&lt;/code&gt; and &lt;code&gt;hub.topic&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; accept a subscription request with a &lt;code&gt;hub.secret&lt;/code&gt; parameter.&lt;/li&gt;
&lt;li&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; respect the requested lease duration in subscription requests.&lt;/li&gt;
&lt;li&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; allow subscribers to re-request already active subscriptions.&lt;/li&gt;
&lt;li&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; support unsubscription requests.&lt;/li&gt;
&lt;li&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; send content distribution requests with a matching content type of the topic URL. (See &lt;a href=&quot;https://www.w3.org/TR/websub/#content-negotiation&quot;&gt;Content Negotiation&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; reduce the payload of the content distribution to a diff of the contents for supported formats as described in &lt;a href=&quot;https://www.w3.org/TR/websub/#content-distribution&quot;&gt;Content Distribution&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; send a &lt;code&gt;X-Hub-Signature&lt;/code&gt; header if the subscription was made with a &lt;code&gt;hub.secret&lt;/code&gt; as described in &lt;a href=&quot;https://www.w3.org/TR/websub/#authenticated-content-distribution&quot;&gt;Authenticated Content Distribution&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/section&gt;&lt;section id=&quot;candidate-recommendation-exit-criteria&quot; readability=&quot;21.792767732962&quot;&gt;&lt;h3 id=&quot;x3-2-candidate-recommendation-exit-criteria&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.2&lt;/span&gt; Candidate Recommendation Exit Criteria&lt;/h3&gt;
&lt;p&gt;This specification exited the CR stage with at least two independent, interoperable implementations of each feature. Each feature may have been implemented by a different set of products. There was no requirement that all features be implemented by a single product. For the purposes of this criterion, we define the following terms:&lt;/p&gt;
&lt;section id=&quot;publisher&quot; readability=&quot;2.7&quot;&gt;&lt;h4 id=&quot;x3-2-1-publisher&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.2.1&lt;/span&gt; Publisher&lt;/h4&gt;
&lt;p&gt;A WebSub Publisher is an implementation that advertises a topic and hub URL on one or more resource URLs. The conformance criteria are described in &lt;a href=&quot;https://www.w3.org/TR/websub/#conformance-classes&quot;&gt;Conformance Classes&lt;/a&gt; above.&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;subscriber&quot; readability=&quot;5.9023668639053&quot;&gt;&lt;h4 id=&quot;x3-2-2-subscriber&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.2.2&lt;/span&gt; Subscriber&lt;/h4&gt;
&lt;p&gt;A WebSub Subscriber is an implementation that discovers the hub and topic URL given a resource URL, subscribes to updates at the hub, and accepts content distribution requests from the hub. The subscriber &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; support &lt;a href=&quot;https://www.w3.org/TR/websub/#authenticated-content-distribution&quot;&gt;authenticated content distribution&lt;/a&gt;. The conformance criteria are described in &lt;a href=&quot;https://www.w3.org/TR/websub/#conformance-classes&quot;&gt;Conformance Classes&lt;/a&gt; above.&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;hub&quot; readability=&quot;5.4927835051546&quot;&gt;&lt;h4 id=&quot;x3-2-3-hub&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.2.3&lt;/span&gt; Hub&lt;/h4&gt;
&lt;p&gt;A WebSub Hub is an implementation that handles subscription requests and distributes the content to subscribers when the corresponding topic URL has been updated. Hubs &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; support subscription requests with a secret and deliver &lt;a href=&quot;https://www.w3.org/TR/websub/#authenticated-content-distribution&quot;&gt;authenticated requests&lt;/a&gt; when requested. Hubs &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; deliver the full contents of the topic URL in the request, and &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; reduce the payload to a diff if the content type supports it. The conformance criteria are described in &lt;a href=&quot;https://www.w3.org/TR/websub/#conformance-classes&quot;&gt;Conformance Classes&lt;/a&gt; above.&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;independent&quot; readability=&quot;6&quot;&gt;&lt;h4 id=&quot;x3-2-4-independent&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.2.4&lt;/span&gt; Independent&lt;/h4&gt;
&lt;p&gt;Each implementation must be developed by a different party and cannot share, reuse, or derive from code used by another qualifying implementation. Sections of code that have no bearing on the implementation of this specification are exempt from this requirement.&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;interoperable&quot; readability=&quot;6&quot;&gt;&lt;h4 id=&quot;x3-2-5-interoperable&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.2.5&lt;/span&gt; Interoperable&lt;/h4&gt;
&lt;p&gt;A Subscriber and Hub implementation are considered interoperable for a specific feature when the Hub takes the defined action that the Subscriber requests, the Subscriber gets the expected response from a Hub according to the feature, and the Hub sends the expected response to the Subscriber.&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;feature&quot; readability=&quot;3&quot;&gt;&lt;h4 id=&quot;x3-2-6-feature&quot;&gt;&lt;span class=&quot;secno&quot;&gt;3.2.6&lt;/span&gt; Feature&lt;/h4&gt;
&lt;p&gt;For the purposes of evaluating exit criteria, each of the following is considered a feature:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Discovering the hub and topic URLs by looking at the HTTP headers of the resource URL.&lt;/li&gt;
&lt;li&gt;Discovering the hub and topic URLs by looking at the contents of the resource URL as an XML document.&lt;/li&gt;
&lt;li&gt;Discovering the hub and topic URLs by looking at the contents of the resource URL as an HTML document.&lt;/li&gt;
&lt;li&gt;Subscribing to the hub with a callback URL.&lt;/li&gt;
&lt;li&gt;Subscribing to the hub and requesting a specific lease duration.&lt;/li&gt;
&lt;li&gt;Subscribing to the hub with a secret and handling authenticated content distribution.&lt;/li&gt;
&lt;li&gt;Requesting that a subscription is deactivated by sending an unsubscribe request.&lt;/li&gt;
&lt;li&gt;The Subscriber acknowledges a pending subscription on a validation request.&lt;/li&gt;
&lt;li&gt;The Subscriber rejects a subscription validation request for an invalid topic URL.&lt;/li&gt;
&lt;li&gt;The Subscriber returns an HTTP 2xx response when the payload is delivered.&lt;/li&gt;
&lt;li&gt;The Subscriber verifies the signature for authenticated content distribution requests.&lt;/li&gt;
&lt;li&gt;The Subscriber rejects the distribution request if the signature does not validate.&lt;/li&gt;
&lt;li&gt;The Subscriber rejects the distribution request when no signature is present if the subscription was made with a secret.&lt;/li&gt;
&lt;li&gt;The Hub respects the requested lease duration during a subscription request.&lt;/li&gt;
&lt;li&gt;The Hub allows Subscribers to re-request already active subscriptions, extending the lease duration.&lt;/li&gt;
&lt;li&gt;The Hub sends the full contents of the topic URL in the distribution request.&lt;/li&gt;
&lt;li&gt;The Hub sends a diff of the topic URL for the formats that support it.&lt;/li&gt;
&lt;li&gt;The Hub sends a valid signature for subscriptions that were made with a secret.&lt;/li&gt;
&lt;/ul&gt;&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section id=&quot;discovery&quot; readability=&quot;28.676837357389&quot;&gt;&lt;h2 id=&quot;x4-discovery&quot;&gt;&lt;span class=&quot;secno&quot;&gt;4.&lt;/span&gt; Discovery&lt;/h2&gt;
&lt;p&gt;The discovery mechanism aims at identifying at least 2 URLs.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;The URL of one or more hubs designated by the publisher. If more than one hub URL is specified, it is expected that the publisher notifies each hub, so the subscriber may subscribe to one or more of them.&lt;/li&gt;
&lt;li&gt;The canonical URL for the topic to which subscribers are expected to use for subscriptions.&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;note&quot; readability=&quot;12&quot;&gt;
&lt;p&gt;&lt;span&gt;Note&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;&quot;&gt;Publishers may wish to advertise and publish to more than one hub for fault tolerance and redundancy. If one hub fails to propagate an update to the document, then using multiple independent hub is a way to increase the liklihood of delivery to subscribers. As such, subscribers may subscribe to one or more of the advertised hubs.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The protocol currently supports the following discovery mechanisms. Publishers &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; implement at least one of them:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Link Headers [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC5988&quot;&gt;RFC5988&lt;/a&gt;&lt;/cite&gt;]: the publisher &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; include at least one Link Header [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC5988&quot;&gt;RFC5988&lt;/a&gt;&lt;/cite&gt;] with &lt;samp&gt;rel=hub&lt;/samp&gt; (a hub link header) as well as exactly one Link Header [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC5988&quot;&gt;RFC5988&lt;/a&gt;&lt;/cite&gt;] with &lt;samp&gt;rel=self&lt;/samp&gt; (the self link header)&lt;/li&gt;
&lt;li&gt;If the topic is an XML based feed, publishers &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; use embedded link elements as described in Appendix B of Web Linking [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC5988&quot;&gt;RFC5988&lt;/a&gt;&lt;/cite&gt;]. Similarly, for HTML pages, publishers &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; use embedded link elements as described in Appendix A of Web Linking [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC5988&quot;&gt;RFC5988&lt;/a&gt;&lt;/cite&gt;].&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;note&quot; readability=&quot;10&quot;&gt;
&lt;p&gt;&lt;span&gt;Note&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;&quot;&gt;Since &lt;samp&gt;&amp;lt;link&amp;gt;&lt;/samp&gt; has been limited to being placed in the &lt;samp&gt;&amp;lt;head&amp;gt;&lt;/samp&gt; for many years, some consuming code might only check the &lt;samp&gt;&amp;lt;head&amp;gt;&lt;/samp&gt;. Therefore it is more robust to place the &lt;samp&gt;&amp;lt;link&amp;gt;&lt;/samp&gt; tags only in the HTML &lt;samp&gt;&amp;lt;head&amp;gt;&lt;/samp&gt; rather than in the &lt;samp&gt;&amp;lt;body&amp;gt;&lt;/samp&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;example&quot; readability=&quot;10&quot;&gt;
&lt;p&gt;&lt;span&gt;Example 1&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&quot;hljs http&quot; aria-busy=&quot;false&quot; aria-live=&quot;polite&quot;&gt;
&lt;span class=&quot;hljs-keyword&quot;&gt;GET&lt;/span&gt; &lt;span class=&quot;hljs-string&quot;&gt;/feed&lt;/span&gt; HTTP/1.1
&lt;span class=&quot;hljs-attribute&quot;&gt;Host&lt;/span&gt;: example.com

&lt;span class=&quot;http&quot;&gt;HTTP/1.1 &lt;span class=&quot;hljs-number&quot;&gt;200&lt;/span&gt; Ok
&lt;span class=&quot;hljs-attribute&quot;&gt;Content-type&lt;/span&gt;: text/html
&lt;span class=&quot;hljs-attribute&quot;&gt;Link&lt;/span&gt;: &amp;lt;https://hub.example.com/&amp;gt;; rel=&quot;hub&quot;
&lt;span class=&quot;hljs-attribute&quot;&gt;Link&lt;/span&gt;: &amp;lt;http://example.com/feed&amp;gt;; rel=&quot;self&quot;

&lt;span class=&quot;xml&quot;&gt;&lt;span class=&quot;hljs-meta&quot;&gt;&amp;lt;!doctype html&amp;gt;&lt;/span&gt;
&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;html&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;head&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;link&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;rel&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;hub&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;href&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;https://hub.example.com/&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;link&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;rel&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;self&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;href&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;http://example.com/feed&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;head&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;body&lt;/span&gt;&amp;gt;&lt;/span&gt;
    ...
  &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;body&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;html&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;When perfoming discovery, subscribers &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; implement all three discovery mechanisms in the following order, stopping at the first match:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Issue a GET or HEAD request to retrieve the topic URL. Subscribers &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; check for HTTP Link headers first.&lt;/li&gt;
&lt;li&gt;In the absence of HTTP Link headers, and if the topic is an XML based feed or an HTML page, subscribers &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; check for embedded link elements.&lt;/li&gt;
&lt;/ol&gt;&lt;section id=&quot;content-negotiation&quot; readability=&quot;50.765901639344&quot;&gt;&lt;h3 id=&quot;x4-1-content-negotiation&quot;&gt;&lt;span class=&quot;secno&quot;&gt;4.1&lt;/span&gt; Content Negotiation&lt;/h3&gt;
&lt;p&gt;For practical purposes, it is important that the &lt;samp&gt;rel=self&lt;/samp&gt; URL only offers a single representation. As the hub has no way of knowing what Media Type ([&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC6838&quot;&gt;RFC6838&lt;/a&gt;&lt;/cite&gt;]) or language may have been requested by the subscriber upon discovery, it would not be able to deliver the content using the appropriate representation of the document.&lt;/p&gt;
&lt;p&gt;It is, however, possible to perform content negotiation by returning an appropriate &lt;samp&gt;rel=self&lt;/samp&gt; URL according to the HTTP headers used in the initial discovery request. For example, a request to &lt;samp&gt;/feed&lt;/samp&gt; with an &lt;samp&gt;Accept&lt;/samp&gt; header containing &lt;samp&gt;application/json&lt;/samp&gt; could return a &lt;samp&gt;rel=self&lt;/samp&gt; value of &lt;samp&gt;/feed.json&lt;/samp&gt;.&lt;/p&gt;
&lt;p&gt;The example below illustrates how a topic URL can return different &lt;samp&gt;Link&lt;/samp&gt; headers depending on the &lt;samp&gt;Accept&lt;/samp&gt; header that was sent.&lt;/p&gt;
&lt;div class=&quot;example&quot; readability=&quot;9&quot;&gt;
&lt;p&gt;&lt;span&gt;Example 2&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&quot;hljs http&quot; aria-busy=&quot;false&quot; aria-live=&quot;polite&quot;&gt;
&lt;span class=&quot;hljs-keyword&quot;&gt;GET&lt;/span&gt; &lt;span class=&quot;hljs-string&quot;&gt;/feed&lt;/span&gt; HTTP/1.1
&lt;span class=&quot;hljs-attribute&quot;&gt;Host&lt;/span&gt;: example.com
&lt;span class=&quot;hljs-attribute&quot;&gt;Accept&lt;/span&gt;: application/json

&lt;span class=&quot;http&quot;&gt;HTTP/1.1 &lt;span class=&quot;hljs-number&quot;&gt;200&lt;/span&gt; Ok
&lt;span class=&quot;hljs-attribute&quot;&gt;Content-type&lt;/span&gt;: application/json
&lt;span class=&quot;hljs-attribute&quot;&gt;Link&lt;/span&gt;: &amp;lt;/feed.json&amp;gt;; rel=&quot;self&quot;
&lt;span class=&quot;hljs-attribute&quot;&gt;Link&lt;/span&gt;: &amp;lt;https://hub.example.com/&amp;gt;; rel=&quot;hub&quot;

&lt;span class=&quot;json&quot;&gt;{
  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;items&quot;&lt;/span&gt;: [...]
}&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;example&quot; readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;span&gt;Example 3&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&quot;hljs http&quot; aria-busy=&quot;false&quot; aria-live=&quot;polite&quot;&gt;
&lt;span class=&quot;hljs-keyword&quot;&gt;GET&lt;/span&gt; &lt;span class=&quot;hljs-string&quot;&gt;/feed&lt;/span&gt; HTTP/1.1
&lt;span class=&quot;hljs-attribute&quot;&gt;Host&lt;/span&gt;: example.com
&lt;span class=&quot;hljs-attribute&quot;&gt;Accept&lt;/span&gt;: text/html

&lt;span class=&quot;http&quot;&gt;HTTP/1.1 &lt;span class=&quot;hljs-number&quot;&gt;200&lt;/span&gt; Ok
&lt;span class=&quot;hljs-attribute&quot;&gt;Content-type&lt;/span&gt;: text/html
&lt;span class=&quot;hljs-attribute&quot;&gt;Link&lt;/span&gt;: &amp;lt;/feed.html&amp;gt;; rel=&quot;self&quot;
&lt;span class=&quot;hljs-attribute&quot;&gt;Link&lt;/span&gt;: &amp;lt;https://hub.example.com/&amp;gt;; rel=&quot;hub&quot;

&lt;span class=&quot;xml&quot;&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;html&lt;/span&gt;&amp;gt;&lt;/span&gt;
...&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Similarly, the technique can also be used to return a different &lt;samp&gt;rel=self&lt;/samp&gt; URL depending on the language requested by the &lt;samp&gt;Accept-Language&lt;/samp&gt; header.&lt;/p&gt;
&lt;div class=&quot;example&quot; readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;span&gt;Example 4&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&quot;hljs http&quot; aria-busy=&quot;false&quot; aria-live=&quot;polite&quot;&gt;
&lt;span class=&quot;hljs-keyword&quot;&gt;GET&lt;/span&gt; &lt;span class=&quot;hljs-string&quot;&gt;/feed&lt;/span&gt; HTTP/1.1
&lt;span class=&quot;hljs-attribute&quot;&gt;Host&lt;/span&gt;: example.com
&lt;span class=&quot;hljs-attribute&quot;&gt;Accept-Language&lt;/span&gt;: de-DE

&lt;span class=&quot;http&quot;&gt;HTTP/1.1 &lt;span class=&quot;hljs-number&quot;&gt;200&lt;/span&gt; Ok
&lt;span class=&quot;hljs-attribute&quot;&gt;Content-type&lt;/span&gt;: text/html

&lt;span class=&quot;http&quot;&gt;&lt;span class=&quot;hljs-attribute&quot;&gt;Link&lt;/span&gt;: &amp;lt;/feed-de.json&amp;gt;; rel=&quot;self&quot;
&lt;span class=&quot;hljs-attribute&quot;&gt;Link&lt;/span&gt;: &amp;lt;https://hub.example.com/&amp;gt;; rel=&quot;hub&quot;

&lt;span class=&quot;json&quot;&gt;{
  &lt;span class=&quot;hljs-attr&quot;&gt;&quot;items&quot;&lt;/span&gt;: [...]
}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section id=&quot;subscribing-and-unsubscribing&quot; readability=&quot;34.101684952978&quot;&gt;&lt;h2 id=&quot;x5-subscribing-and-unsubscribing&quot;&gt;&lt;span class=&quot;secno&quot;&gt;5.&lt;/span&gt; Subscribing and Unsubscribing&lt;/h2&gt;
&lt;p&gt;Subscribing to a topic URL consists of four parts that may occur immediately in sequence or have a delay.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Subscriber requests a subscription at the hub&lt;/li&gt;
&lt;li&gt;The hub validates the subscription with the publisher (&lt;em class=&quot;rfc2119&quot; title=&quot;OPTIONAL&quot;&gt;OPTIONAL&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;The hub confirms the subscription was actually requested by the subscriber&lt;/li&gt;
&lt;li&gt;The hub periodically reconfirms the subscription is still active (&lt;em class=&quot;rfc2119&quot; title=&quot;OPTIONAL&quot;&gt;OPTIONAL&lt;/em&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Unsubscribing works in the same way, except with a single parameter changed to indicate the desire to unsubscribe. Also, the Hub will not validate unsubscription requests with the publisher.&lt;/p&gt;
&lt;section id=&quot;subscriber-sends-subscription-request&quot; readability=&quot;41.982114676486&quot;&gt;&lt;h3 id=&quot;x5-1-subscriber-sends-subscription-request&quot;&gt;&lt;span class=&quot;secno&quot;&gt;5.1&lt;/span&gt; Subscriber Sends Subscription Request&lt;/h3&gt;
&lt;p&gt;Subscription is initiated by the subscriber making an HTTPS or HTTP POST [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC7231&quot;&gt;RFC7231&lt;/a&gt;&lt;/cite&gt;] request to the hub URL. This request &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; have a Content-Type header of &lt;samp&gt;application/x-www-form-urlencoded&lt;/samp&gt; (described in Section 4.10.22.6 [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-HTML5&quot;&gt;HTML5&lt;/a&gt;&lt;/cite&gt;]), &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; use UTF-8 [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-Encoding&quot;&gt;Encoding&lt;/a&gt;&lt;/cite&gt;] as the document character encoding, and &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; use the following parameters in its body, formatted accordingly:&lt;/p&gt;
&lt;dl&gt;&lt;dt&gt;hub.callback&lt;/dt&gt;
&lt;dd&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;REQUIRED&quot;&gt;REQUIRED&lt;/em&gt;. The subscriber's callback URL where content distribution notifications should be delivered. The callback URL &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; be an unguessable URL that is unique per subscription. ([&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-capability-urls&quot;&gt;capability-urls&lt;/a&gt;&lt;/cite&gt;])&lt;/dd&gt;
&lt;dt&gt;hub.mode&lt;/dt&gt;
&lt;dd&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;REQUIRED&quot;&gt;REQUIRED&lt;/em&gt;. The literal string &quot;subscribe&quot; or &quot;unsubscribe&quot;, depending on the goal of the request.&lt;/dd&gt;
&lt;dt&gt;hub.topic&lt;/dt&gt;
&lt;dd&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;REQUIRED&quot;&gt;REQUIRED&lt;/em&gt;. The topic URL that the subscriber wishes to subscribe to or unsubscribe from. Note that this &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; be the &quot;self&quot; URL found during the discovery step, which may be different from the URL that was used to make the discovery request.&lt;/dd&gt;
&lt;dt&gt;hub.lease_seconds&lt;/dt&gt;
&lt;dd&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;OPTIONAL&quot;&gt;OPTIONAL&lt;/em&gt;. Number of seconds for which the subscriber would like to have the subscription active, given as a positive decimal integer. Hubs &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; choose to respect this value or not, depending on their own policies, and &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; set a default value if the subscriber omits the parameter. This parameter &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; be present for unsubscription requests and &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; be ignored by the hub in that case.&lt;/dd&gt;
&lt;dt&gt;hub.secret&lt;/dt&gt;
&lt;dd&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;OPTIONAL&quot;&gt;OPTIONAL&lt;/em&gt;. A subscriber-provided cryptographically random unique secret string that will be used to compute an HMAC digest for &lt;a href=&quot;https://www.w3.org/TR/websub/#authenticated-content-distribution&quot;&gt;authorized content distribution&lt;/a&gt;. If not supplied, the HMAC digest will not be present for content distribution requests. This parameter &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; only be specified when the request was made over HTTPS [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC2818&quot;&gt;RFC2818&lt;/a&gt;&lt;/cite&gt;]. This parameter &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; be less than 200 bytes in length.&lt;/dd&gt;
&lt;/dl&gt;&lt;p&gt;Subscribers &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; also include additional HTTP [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC7230&quot;&gt;RFC7230&lt;/a&gt;&lt;/cite&gt;] request parameters, as well as HTTP [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC7230&quot;&gt;RFC7230&lt;/a&gt;&lt;/cite&gt;] Headers if they are required by the hub.&lt;/p&gt;
&lt;p&gt;Hubs &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; ignore additional request parameters they do not understand.&lt;/p&gt;
&lt;p&gt;Hubs &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; allow subscribers to re-request subscriptions that are already activated. Each subsequent request to a hub to subscribe or unsubscribe &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; override the previous subscription state for a specific topic URL and callback URL combination, but only once the action is verified (&lt;a href=&quot;https://www.w3.org/TR/websub/#hub-verifies-intent&quot;&gt;Section 4.3&lt;/a&gt;). If verification fails, the subscription state &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; be left unchanged. This is required so subscribers can renew their subscriptions before the lease seconds period is over without any interruption. The subscriber &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; use a new hub.secret value in a future subscription, and &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; make a new subscription without a hub.secret.&lt;/p&gt;
&lt;section id=&quot;subscription-parameter-details&quot; readability=&quot;18.338566552901&quot;&gt;&lt;h4 id=&quot;x5-1-1-subscription-parameter-details&quot;&gt;&lt;span class=&quot;secno&quot;&gt;5.1.1&lt;/span&gt; Subscription Parameter Details&lt;/h4&gt;
&lt;p&gt;The topic and callback URLs &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; use HTTP [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC7230&quot;&gt;RFC7230&lt;/a&gt;&lt;/cite&gt;] or HTTPS [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC2818&quot;&gt;RFC2818&lt;/a&gt;&lt;/cite&gt;] schemes. The topic URL &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; be the one advertised by the publisher in a Self Link Header during the discovery phase. (See &lt;a href=&quot;https://www.w3.org/TR/websub/#discovery&quot;&gt;Section 3&lt;/a&gt; ). Hubs &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; refuse subscriptions if the topic URL does not correspond to the one advertised by the publisher. The topic URL can otherwise be free-form following the URL spec [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-URL&quot;&gt;URL&lt;/a&gt;&lt;/cite&gt;]. Hubs &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; always decode non-reserved characters for these URL parameters; see section 1.2 on &lt;em&gt;&quot;Percent-encoded bytes&quot;&lt;/em&gt; in [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-URL&quot;&gt;URL&lt;/a&gt;&lt;/cite&gt;].&lt;/p&gt;
&lt;p&gt;The callback URL &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; be an unguessable unique URL ([&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-capability-urls&quot;&gt;capability-urls&lt;/a&gt;&lt;/cite&gt;]) and &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; use HTTPS [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC7230&quot;&gt;RFC7230&lt;/a&gt;&lt;/cite&gt;]. The callback URL acts as authentication from the hub to the subscriber when confirming subscriptions and delivering the content. Additionally, the callback &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; be unique (not re-used for multiple hubs) and changed when subscriptions are renewed.&lt;/p&gt;
&lt;p&gt;The callback URL &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; contain arbitrary query string parameters (e.g., &lt;samp&gt;?foo=bar&amp;amp;red=fish&lt;/samp&gt;). Hubs &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; preserve the query string during subscription verification by appending new parameters to the end of the list using the &lt;samp&gt;&amp;amp;&lt;/samp&gt; (ampersand) character to join. Existing parameters with names that overlap with those used by verification requests will not be overwritten. When sending the content distribution request, the hub will make a POST request to the callback URL including any query string parameters in the URL portion of the request, not as POST body parameters.&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;subscription-response-details&quot; readability=&quot;23.260172626387&quot;&gt;&lt;h4 id=&quot;x5-1-2-subscription-response-details&quot;&gt;&lt;span class=&quot;secno&quot;&gt;5.1.2&lt;/span&gt; Subscription Response Details&lt;/h4&gt;
&lt;p&gt;If the hub URL supports WebSub and is able to handle the subscription or unsubscription request, it &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; respond to a subscription request with an HTTP [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC7231&quot;&gt;RFC7231&lt;/a&gt;&lt;/cite&gt;] 202 &quot;Accepted&quot; response to indicate that the request was received and will now be verified (&lt;a href=&quot;https://www.w3.org/TR/websub/#hub-verifies-intent&quot;&gt;Section 4.3&lt;/a&gt; ) and validated (&lt;a href=&quot;https://www.w3.org/TR/websub/#subscription-validation&quot;&gt;Section 4.2&lt;/a&gt; ) by the hub. The hub &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; perform the verification and validation of intent as soon as possible.&lt;/p&gt;
&lt;p&gt;If a hub finds any errors in the subscription request, an appropriate HTTP [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC7231&quot;&gt;RFC7231&lt;/a&gt;&lt;/cite&gt;] error response code (4xx or 5xx) &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; be returned. In the event of an error, hubs &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; return a description of the error in the response body as plain text, used to assist the client developer in understanding the error. This is not meant to be shown to the end user. Hubs &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; decide to reject some callback URLs or topic URLs based on their own policies (e.g., domain authorization, topic URL port numbers). However, since verification and validation of intent are asynchronous steps that logically begin after the HTTP response has been returned, the HTTP response &lt;em class=&quot;rfc2119&quot; title=&quot;MUST NOT&quot;&gt;MUST NOT&lt;/em&gt; depend on the process or outcome of verification or validation.&lt;/p&gt;
&lt;p&gt;If the hub URL is not able to handle subscription or unsubscription requests, it &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; redirect to another hub which supports WebSub. It does so by yielding an HTTP [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC7231&quot;&gt;RFC7231&lt;/a&gt;&lt;/cite&gt;] 307 (temporary redirect) or 308 (permanent redirect) response. It &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; also include at least a HTTP [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC7230&quot;&gt;RFC7230&lt;/a&gt;&lt;/cite&gt;] Location Header containing a preferred URL reference for the hub to use by the subscriber. The subscriber is expected to retry the subscription or unsubscription at the new hub URL.&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section id=&quot;subscription-validation&quot; readability=&quot;15.405147759771&quot;&gt;&lt;h3 id=&quot;x5-2-subscription-validation&quot;&gt;&lt;span class=&quot;secno&quot;&gt;5.2&lt;/span&gt; Subscription Validation&lt;/h3&gt;
&lt;p&gt;Subscriptions &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; be validated by the Hubs who may require more details to accept or refuse a subscription. The Hub &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; also check with the publisher whether the subscription should be accepted.&lt;/p&gt;
&lt;p&gt;If (and when) the subscription is accepted, the hub &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; perform the &lt;a href=&quot;https://www.w3.org/TR/websub/#hub-verifies-intent&quot;&gt;verification of intent&lt;/a&gt; of the subscriber.&lt;/p&gt;
&lt;p&gt;If (and when) the subscription is denied, the hub &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; inform the subscriber by sending an HTTP [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC7231&quot;&gt;RFC7231&lt;/a&gt;&lt;/cite&gt;] (or HTTPS [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC2818&quot;&gt;RFC2818&lt;/a&gt;&lt;/cite&gt;]) GET request to the subscriber's callback URL as given in the subscription request. This request has the following query string arguments appended (format described in Section 4 of [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-URL&quot;&gt;URL&lt;/a&gt;&lt;/cite&gt;]):&lt;/p&gt;
&lt;dl&gt;&lt;dt&gt;hub.mode&lt;/dt&gt;
&lt;dd&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;REQUIRED&quot;&gt;REQUIRED&lt;/em&gt;. The literal string &quot;denied&quot;.&lt;/dd&gt;
&lt;dt&gt;hub.topic&lt;/dt&gt;
&lt;dd&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;REQUIRED&quot;&gt;REQUIRED&lt;/em&gt;. The topic URL given in the corresponding subscription request.&lt;/dd&gt;
&lt;dt&gt;hub.reason&lt;/dt&gt;
&lt;dd&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;OPTIONAL&quot;&gt;OPTIONAL&lt;/em&gt;. The hub may include a reason for which the subscription has been denied.&lt;/dd&gt;
&lt;/dl&gt;&lt;p&gt;The subscription &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; be denied by the hub at any point (even if it was previously accepted). The Subscriber &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; then consider that the subscription is not possible anymore.&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;hub-verifies-intent&quot; readability=&quot;19.79443254818&quot;&gt;&lt;h3 id=&quot;x5-3-hub-verifies-intent-of-the-subscriber&quot;&gt;&lt;span class=&quot;secno&quot;&gt;5.3&lt;/span&gt; Hub Verifies Intent of the Subscriber&lt;/h3&gt;
&lt;p&gt;In order to prevent an attacker from creating unwanted subscriptions on behalf of a subscriber (or unsubscribing desired ones), a hub must ensure that the subscriber did indeed send the subscription request.&lt;/p&gt;
&lt;p&gt;The hub verifies a subscription request by sending an HTTP [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC7231&quot;&gt;RFC7231&lt;/a&gt;&lt;/cite&gt;] (or HTTPS [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC2818&quot;&gt;RFC2818&lt;/a&gt;&lt;/cite&gt;]) GET request to the subscriber's callback URL as given in the subscription request. This request has the following query string arguments appended (format described in Section 4 of [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-URL&quot;&gt;URL&lt;/a&gt;&lt;/cite&gt;]):&lt;/p&gt;
&lt;dl&gt;&lt;dt&gt;&lt;samp&gt;hub.mode&lt;/samp&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;REQUIRED&quot;&gt;REQUIRED&lt;/em&gt;. The literal string &quot;&lt;samp&gt;subscribe&lt;/samp&gt;&quot; or &quot;&lt;samp&gt;unsubscribe&lt;/samp&gt;&quot;, which matches the original request to the hub from the subscriber.&lt;/dd&gt;
&lt;dt&gt;&lt;samp&gt;hub.topic&lt;/samp&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;REQUIRED&quot;&gt;REQUIRED&lt;/em&gt;. The topic URL given in the corresponding subscription request.&lt;/dd&gt;
&lt;dt&gt;&lt;samp&gt;hub.challenge&lt;/samp&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;REQUIRED&quot;&gt;REQUIRED&lt;/em&gt;. A hub-generated, random string that &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; be echoed by the subscriber to verify the subscription.&lt;/dd&gt;
&lt;dt&gt;&lt;samp&gt;hub.lease_seconds&lt;/samp&gt;&lt;/dt&gt;
&lt;dd&gt;&lt;em class=&quot;rfc2119&quot; title=&quot;REQUIRED&quot;&gt;REQUIRED&lt;/em&gt;/&lt;em class=&quot;rfc2119&quot; title=&quot;OPTIONAL&quot;&gt;OPTIONAL&lt;/em&gt;. The hub-determined number of seconds that the subscription will stay active before expiring, measured from the time the verification request was made from the hub to the subscriber. Hubs &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; supply this parameter when &lt;samp&gt;hub.mode&lt;/samp&gt; is set to &quot;subscribe&quot;. This parameter &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; be present when &lt;samp&gt;hub.mode&lt;/samp&gt; is &quot;unsubscribe&quot; and &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; be ignored by subscribers in that case.&lt;/dd&gt;
&lt;/dl&gt;&lt;section id=&quot;verification-details&quot; readability=&quot;21.856074766355&quot;&gt;&lt;h4 id=&quot;x5-3-1-verification-details&quot;&gt;&lt;span class=&quot;secno&quot;&gt;5.3.1&lt;/span&gt; Verification Details&lt;/h4&gt;
&lt;p&gt;The subscriber &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; confirm that the &lt;samp&gt;hub.topic&lt;/samp&gt; corresponds to a pending subscription or unsubscription that it wishes to carry out. If so, the subscriber &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; respond with an HTTP success (2xx) code with a response body equal to the &lt;samp&gt;hub.challenge&lt;/samp&gt; parameter. If the subscriber does not agree with the action, the subscriber &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; respond with a 404 &quot;Not Found&quot; response.&lt;/p&gt;
&lt;p&gt;The hub &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; consider other server response codes (3xx, 4xx, 5xx) to mean that the verification request has failed. If the subscriber returns an HTTP [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC7231&quot;&gt;RFC7231&lt;/a&gt;&lt;/cite&gt;] success (2xx) but the content body does not match the &lt;samp&gt;hub.challenge&lt;/samp&gt; parameter, the hub &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; also consider verification to have failed.&lt;/p&gt;
&lt;p&gt;Hubs &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; make the &lt;samp&gt;hub.lease_seconds&lt;/samp&gt; equal to the value the subscriber passed in their subscription request but &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; change the value depending on the hub's policies. To sustain a subscription, the subscriber &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; re-request the subscription on the hub before &lt;samp&gt;hub.lease_seconds&lt;/samp&gt; seconds has elapsed.&lt;/p&gt;
&lt;p&gt;Hubs &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; enforce lease expirations, and &lt;em class=&quot;rfc2119&quot; title=&quot;MUST NOT&quot;&gt;MUST NOT&lt;/em&gt; issue perpetual lease durations.&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;div class=&quot;note&quot; readability=&quot;12&quot;&gt;
&lt;p&gt;&lt;span&gt;Note&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;&quot;&gt;The spec uses GET vs POST to differentiate between the confirmation/denial of the subscription request and delivering the content. While this is not considered &quot;best practice&quot; from a web architecture perspective, it does make implementation of the callback URL simpler. Since the POST body of the content distribution request may be any arbitrary content type and only includes the actual content of the document, using the GET vs POST distinction to switch between handling these two modes makes implementations simpler.&lt;/p&gt;
&lt;/div&gt;
&lt;/section&gt;&lt;section id=&quot;publishing&quot; readability=&quot;11.423952975753&quot;&gt;&lt;h2 id=&quot;x6-publishing&quot;&gt;&lt;span class=&quot;secno&quot;&gt;6.&lt;/span&gt; Publishing&lt;/h2&gt;
&lt;p&gt;The publisher &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; inform the hubs it previously designated when a topic has been updated. The hub and the publisher can agree on any mechanism, as long as the hub is eventually able send the updated payload to the subscribers.&lt;/p&gt;
&lt;div class=&quot;note&quot; readability=&quot;9.6564885496183&quot;&gt;
&lt;p&gt;&lt;span&gt;Note&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;&quot;&gt;The specific mechanism for the publisher to inform the hub is left unspecified. For example, some existing public hubs &lt;a href=&quot;https://documentation.superfeedr.com/publishers.html#ping&quot;&gt;[1]&lt;/a&gt; &lt;a href=&quot;https://pubsubhubbub.appspot.com/&quot;&gt;[2]&lt;/a&gt; &lt;a href=&quot;https://switchboard.p3k.io/docs&quot;&gt;[3]&lt;/a&gt; ask publishers to send a POST request with the keys &lt;span&gt;hub.mode=&quot;publish&quot;&lt;/span&gt; and &lt;span&gt;hub.url=(the URL of the resource that was updated)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;section id=&quot;subscription-migration&quot; readability=&quot;8&quot;&gt;&lt;h3 id=&quot;x6-1-subscription-migration&quot;&gt;&lt;span class=&quot;secno&quot;&gt;6.1&lt;/span&gt; Subscription Migration&lt;/h3&gt;
&lt;p&gt;If the publisher wishes to migrate existing subscriptions to a new topic URL, it can do so using HTTP redirects.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;The previous topic URL should send a redirect to the new topic URL. This will provide a seamless transition for any HTTP client that did not use WebSub but instead was polling the topic URL.&lt;/li&gt;
&lt;li&gt;When existing WebSub subscriptions expire, subscribers will attempt to renew the subscription. The first step of renewing a subscription is to fetch the topic URL, which means the subscriber will encounter the redirect and end up at the new topic URL.&lt;/li&gt;
&lt;li&gt;At the new topic URL, the subscriber will see the new &lt;code&gt;rel=self&lt;/code&gt; URL and the new hub, and will subscribe to the new topic URL at the new hub.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;This does not require any participation on the part of the previous hub, and works whether or not the publisher changes hubs as well.&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;section id=&quot;content-distribution&quot; readability=&quot;55.1403122498&quot;&gt;&lt;h2 id=&quot;x7-content-distribution&quot;&gt;&lt;span class=&quot;secno&quot;&gt;7.&lt;/span&gt; Content Distribution&lt;/h2&gt;
&lt;p&gt;A content distribution request is sent from the Hub to the Subscriber when new content is available for a topic URL. The request is an HTTP [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC7231&quot;&gt;RFC7231&lt;/a&gt;&lt;/cite&gt;] (or HTTPS [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC2818&quot;&gt;RFC2818&lt;/a&gt;&lt;/cite&gt;]) POST request from the hub to the subscriber's callback URL. The HTTP body of the POST request &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; include the payload of the content distribution notification. The content distribution request &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; have a &lt;samp&gt;Content-Type&lt;/samp&gt; Header corresponding to the &lt;samp&gt;Content-Type&lt;/samp&gt; of the topic, and &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; contain the full contents of the topic URL, with an exception allowed as described below.&lt;/p&gt;
&lt;p&gt;For Atom ([&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC4287&quot;&gt;RFC4287&lt;/a&gt;&lt;/cite&gt;]) and RSS ([&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RSS-2.0&quot;&gt;RSS-2.0&lt;/a&gt;&lt;/cite&gt;]) feeds, the hub &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; remove already-delivered &lt;code&gt;atom:entry&lt;/code&gt; or &lt;code&gt;rss:item&lt;/code&gt; elements from the feed.&lt;/p&gt;
&lt;p&gt;The request &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; include at least one Link Header [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC5988&quot;&gt;RFC5988&lt;/a&gt;&lt;/cite&gt;] with &lt;samp&gt;rel=hub&lt;/samp&gt; pointing to a Hub associated with the topic being updated. It &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; also include one Link Header [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC5988&quot;&gt;RFC5988&lt;/a&gt;&lt;/cite&gt;] with &lt;samp&gt;rel=self&lt;/samp&gt; set to the canonical URL of the topic being updated. The Hub &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; combine these headers into a single Link Header [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC5988&quot;&gt;RFC5988&lt;/a&gt;&lt;/cite&gt;]. All these URLs are those resulting from the discovery process (&lt;a href=&quot;https://www.w3.org/TR/websub/#discovery&quot;&gt;Section 3&lt;/a&gt;). The subscriber &lt;em class=&quot;rfc2119&quot; title=&quot;MUST NOT&quot;&gt;MUST NOT&lt;/em&gt; use these Link headers to identify the subscription corresponding to the content distribution request, because the Link headers are metadata associated with the topic content, not with any particular subscription. For example, the topic URL in the content distribution request may be different from the topic URL that was originally subscribed to.&lt;/p&gt;
&lt;p&gt;The subscriber's callback URL &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; return an HTTP [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC7231&quot;&gt;RFC7231&lt;/a&gt;&lt;/cite&gt;] 2xx response code to indicate a success. The subscriber's callback URL &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; return an HTTP 410 code to indicate that the subscription has been deleted, and the hub &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; terminate the subscription if it receives that code as a response. The hub &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; consider all other subscriber response codes as failures; that means subscribers &lt;em class=&quot;rfc2119&quot; title=&quot;MUST NOT&quot;&gt;MUST NOT&lt;/em&gt; use HTTP redirects for moving subscriptions. Subscribers &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; respond to content distribution requests as quickly as possible; their success response code &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; only indicate receipt of the message, not acknowledgment that it was successfully processed by the subscriber. The response body from the subscriber &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; be ignored by the hub. Hubs &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; retry content distribution requests up to self-imposed limits on the number of times and the overall time period to retry. When the failing delivery exceeds the hub's limits, the hub stops attempting to deliver that nofication. The hub &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; keep the subscription active until the end of the lease duration, and if a new update is published to the topic, &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; continue to retry delivery to the previously-failing subscriber.&lt;/p&gt;
&lt;section id=&quot;authenticated-content-distribution&quot; readability=&quot;41.689808917197&quot;&gt;&lt;h3 id=&quot;signing-content&quot;&gt;&lt;span class=&quot;secno&quot;&gt;7.1&lt;/span&gt; Authenticated Content Distribution&lt;/h3&gt;
&lt;p&gt;If the subscriber supplied a value for &lt;samp&gt;hub.secret&lt;/samp&gt; in their subscription request, the hub &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; generate an HMAC signature of the payload and include that signature in the request headers of the content distribution request. The &lt;samp&gt;X-Hub-Signature&lt;/samp&gt; header's value &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; be in the form &lt;samp&gt;method=signature&lt;/samp&gt; where &lt;samp&gt;method&lt;/samp&gt; is one of the recognized algorithm names and &lt;samp&gt;signature&lt;/samp&gt; is the hexadecimal representation of the signature. The signature &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; be computed using the HMAC algorithm [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC6151&quot;&gt;RFC6151&lt;/a&gt;&lt;/cite&gt;] with the request body as the data and the &lt;samp&gt;hub.secret&lt;/samp&gt; as the key.&lt;/p&gt;
&lt;section id=&quot;recognized-algorithm-names&quot; readability=&quot;10.887417218543&quot;&gt;&lt;h4 id=&quot;x7-1-1-recognized-algorithm-names&quot;&gt;&lt;span class=&quot;secno&quot;&gt;7.1.1&lt;/span&gt; Recognized algorithm names&lt;/h4&gt;
&lt;p&gt;The following algorithms are the initially registered algorithm names, based on the contents of the [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-FIPS-PUB-180-4&quot;&gt;FIPS-PUB-180-4&lt;/a&gt;&lt;/cite&gt;] registry at the time of publishing.&lt;/p&gt;
&lt;dl&gt;&lt;dt&gt;sha1&lt;/dt&gt;
&lt;dd&gt;The SHA-1 algorithm as specified in Section 6.1 of [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-FIPS-PUB-180-4&quot;&gt;FIPS-PUB-180-4&lt;/a&gt;&lt;/cite&gt;]&lt;/dd&gt;
&lt;dt&gt;sha256&lt;/dt&gt;
&lt;dd&gt;The SHA-256 algorithm as specified in Section 6.2 of [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-FIPS-PUB-180-4&quot;&gt;FIPS-PUB-180-4&lt;/a&gt;&lt;/cite&gt;]&lt;/dd&gt;
&lt;dt&gt;sha384&lt;/dt&gt;
&lt;dd&gt;The SHA-384 algorithm as specified in Section 6.5 of [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-FIPS-PUB-180-4&quot;&gt;FIPS-PUB-180-4&lt;/a&gt;&lt;/cite&gt;]&lt;/dd&gt;
&lt;dt&gt;sha512&lt;/dt&gt;
&lt;dd&gt;The SHA-512 algorithm as specified in Section 6.4 of [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-FIPS-PUB-180-4&quot;&gt;FIPS-PUB-180-4&lt;/a&gt;&lt;/cite&gt;]&lt;/dd&gt;
&lt;/dl&gt;&lt;p&gt;In the future, an extension may be specified allowing subscribers to indicate which algorithms they can use for validation. As of this writing, most hubs sign with SHA-1, despite its known cryptographic weakness, in order to be interoperable with older subscribers.&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;signature-validation&quot; readability=&quot;12.730769230769&quot;&gt;&lt;h4 id=&quot;x7-1-2-signature-validation&quot;&gt;&lt;span class=&quot;secno&quot;&gt;7.1.2&lt;/span&gt; Signature validation&lt;/h4&gt;
&lt;p&gt;When subscribers receive a content distribution request with the &lt;samp&gt;X-Hub-Signature&lt;/samp&gt; header specified, they &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; recompute the signature with the shared secret using the same method (provided in the &lt;samp&gt;X-Hub-Signature&lt;/samp&gt; header) as the hub. If the signature does not match, subscribers &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; locally ignore the message as invalid. Subscribers &lt;em class=&quot;rfc2119&quot; title=&quot;MAY&quot;&gt;MAY&lt;/em&gt; still acknowledge this request with a 2xx response code in order to be able to process the message asynchronously and/or prevent brute-force attempts of the signature. Using this technique along with HTTPS [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC2818&quot;&gt;RFC2818&lt;/a&gt;&lt;/cite&gt;] for subscription requests enables simple subscribers to receive authenticated content distribution requests from hubs without the need for subscribers to run an HTTPS [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC2818&quot;&gt;RFC2818&lt;/a&gt;&lt;/cite&gt;] server.&lt;/p&gt;
&lt;p&gt;Please note however that this signature only ensures that the payload was not forged. Since the request also includes headers, these should not be considered as safe by the subscriber, unless of course the subscriber uses HTTPS [&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-RFC2818&quot;&gt;RFC2818&lt;/a&gt;&lt;/cite&gt;] callbacks.&lt;/p&gt;
&lt;/section&gt;&lt;/section&gt;&lt;/section&gt;&lt;section id=&quot;security-considerations&quot; readability=&quot;25.819861431871&quot;&gt;&lt;h2 id=&quot;x8-security-considerations&quot;&gt;&lt;span class=&quot;secno&quot;&gt;8.&lt;/span&gt; Security Considerations&lt;/h2&gt;
&lt;p&gt;Here is a summary of security considerations. It is important to note that WebSub is a server-to-server protocol which relies only on HTTP. It is strongly recommended to use HTTPS for all requests.&lt;/p&gt;
&lt;section id=&quot;discovery-0&quot; readability=&quot;9&quot;&gt;&lt;h3 id=&quot;x8-1-discovery&quot;&gt;&lt;span class=&quot;secno&quot;&gt;8.1&lt;/span&gt; Discovery&lt;/h3&gt;
&lt;p&gt;The decision about whether a subscriber should look for &lt;samp&gt;&amp;lt;link&amp;gt;&lt;/samp&gt; elements inside a page's &lt;samp&gt;&amp;lt;body&amp;gt;&lt;/samp&gt; (as well as the &lt;samp&gt;&amp;lt;head&amp;gt;&lt;/samp&gt;) is not straightforward, and there is currently no clear consensus. One reason to ignore the &lt;samp&gt;&amp;lt;body&amp;gt;&lt;/samp&gt; during discovery is that some web sites might (perhaps accidentally) allow users to post content containing &lt;samp&gt;&amp;lt;link&amp;gt;&lt;/samp&gt; elements, though the working group does not know of any specific examples of such sites. If WebSub discovery uses such &lt;samp&gt;&amp;lt;link&amp;gt;&lt;/samp&gt; elements, a user contributing to such sites could potentially maliciously cause all subscribers to use an alternate hub which later delivers malicious content. Given this potential attack, it may be prudent to do discovery only in the &lt;samp&gt;&amp;lt;head&amp;gt;&lt;/samp&gt; of HTML documents.&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;subscriptions&quot; readability=&quot;14&quot;&gt;&lt;h3 id=&quot;x8-2-subscriptions&quot;&gt;&lt;span class=&quot;secno&quot;&gt;8.2&lt;/span&gt; Subscriptions&lt;/h3&gt;
&lt;p&gt;First, subscribers &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; always favor the HTTPS URL for hubs (even if the URL is advertised as HTTP). Second, subscribers &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; use unique unguessable capability URLs for the callbacks, as well as make them available via HTTPS. Finally, subscribers &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; use a &lt;samp&gt;hub.secret&lt;/samp&gt; when subscribing to allow signature of the content distribution.&lt;/p&gt;
&lt;p&gt;Hubs &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; enforce short lived &lt;samp&gt;hub.lease_seconds&lt;/samp&gt; (10 days is a good default). When performing intent verification, the hub &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; use a random, single-use &lt;samp&gt;hub.challenge&lt;/samp&gt;.&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;distribution&quot; readability=&quot;20&quot;&gt;&lt;h3 id=&quot;x8-3-distribution&quot;&gt;&lt;span class=&quot;secno&quot;&gt;8.3&lt;/span&gt; Distribution&lt;/h3&gt;
&lt;p&gt;The Hub &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; use the exact callback used by the subscriber (including the use of HTTPS). Hubs &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; sign their requests using the &lt;samp&gt;hub.secret&lt;/samp&gt; supplied by subscribers if requested.&lt;/p&gt;
&lt;p&gt;If the subscriber included a hub.secret in the subscription request, the subscriber &lt;em class=&quot;rfc2119&quot; title=&quot;SHOULD&quot;&gt;SHOULD&lt;/em&gt; validate the hub's provided signature, and if they do so, they &lt;em class=&quot;rfc2119&quot; title=&quot;MUST&quot;&gt;MUST&lt;/em&gt; use the server's stated signature mechanism, and discard requests which fail the test.&lt;/p&gt;
&lt;p&gt;If a subscriber does not use a secure callback URL (HTTPS), or if it is suspected that the TLS transport between the hub and subscriber may be compromised, then the integrity of the content delivery notification is only protected by the &lt;samp&gt;hub.secret&lt;/samp&gt; and the hashing algorithm used. In this case, an appropriate hashing algorithm should be used based on the security requirements of the application. As SHA-1 has been demonstrated to be compromised as of the date of this publication, a minimum of SHA-256 should be used.&lt;/p&gt;
&lt;/section&gt;&lt;section id=&quot;security-and-privacy-review&quot; readability=&quot;2.952178533475&quot;&gt;&lt;h3 id=&quot;x8-4-security-and-privacy-review&quot;&gt;&lt;span class=&quot;secno&quot;&gt;8.4&lt;/span&gt; Security and Privacy Review&lt;/h3&gt;
&lt;p&gt;These questions provide an overview of security and privacy considerations for this specification as guided by Self-Review Questionnaire: Security and Privacy ([&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-security-privacy-questionnaire&quot;&gt;security-privacy-questionnaire&lt;/a&gt;&lt;/cite&gt;]).&lt;/p&gt;
&lt;dl&gt;&lt;dt&gt;Does this specification deal with personally-identifiable information?&lt;/dt&gt;
&lt;dd&gt;The only potentially personally-identifiable information involved are topic and callback URLs.&lt;/dd&gt;
&lt;dt&gt;Does this specification deal with high-value data?&lt;/dt&gt;
&lt;dd&gt;No, there is no authentication or other credentials involved.&lt;/dd&gt;
&lt;dt&gt;Does this specification introduce new state for an origin that persists across browsing sessions?&lt;/dt&gt;
&lt;dd&gt;No.&lt;/dd&gt;
&lt;dt&gt;Does this specification expose persistent, cross-origin state to the web?&lt;/dt&gt;
&lt;dd&gt;The WebSub subscriber should create a resource with information about the topic to which it subscribes.&lt;/dd&gt;
&lt;dt&gt;Does this specification expose any other data to an origin that it doesn't currently have access to?&lt;/dt&gt;
&lt;dd&gt;No.&lt;/dd&gt;
&lt;dt&gt;Does this specification enable new script execution/loading mechanisms?&lt;/dt&gt;
&lt;dd&gt;No.&lt;/dd&gt;
&lt;dt&gt;Does this specification allow an origin access to a user's location?&lt;/dt&gt;
&lt;dd&gt;No.&lt;/dd&gt;
&lt;dt&gt;Does this specification allow an origin access to sensors on a user's device?&lt;/dt&gt;
&lt;dd&gt;No.&lt;/dd&gt;
&lt;dt&gt;Does this specification allow an origin access to aspects of a user's local computing environment?&lt;/dt&gt;
&lt;dd&gt;No.&lt;/dd&gt;
&lt;dt&gt;Does this specification allow an origin access to other devices?&lt;/dt&gt;
&lt;dd&gt;No.&lt;/dd&gt;
&lt;dt&gt;Does this specification allow an origin some measure of control over a user agent's native UI?&lt;/dt&gt;
&lt;dd&gt;No.&lt;/dd&gt;
&lt;dt&gt;Does this specification expose temporary identifiers to the web?&lt;/dt&gt;
&lt;dd&gt;No.&lt;/dd&gt;
&lt;dt&gt;Does this specification distinguish between behavior in first-party and third-party contexts?&lt;/dt&gt;
&lt;dd&gt;No.&lt;/dd&gt;
&lt;dt&gt;How should this specification work in the context of a user agent's &quot;incognito&quot; mode?&lt;/dt&gt;
&lt;dd&gt;WebSub is a server to server protocol, in which &quot;incognito&quot; mode does not have a meaning.&lt;/dd&gt;
&lt;dt&gt;Does this specification persist data to a user's local device?&lt;/dt&gt;
&lt;dd&gt;No.&lt;/dd&gt;
&lt;dt&gt;Does this specification allow downgrading default security characteristics?&lt;/dt&gt;
&lt;dd&gt;No.&lt;/dd&gt;
&lt;/dl&gt;&lt;/section&gt;&lt;/section&gt;&lt;section class=&quot;appendix informative&quot; id=&quot;acknowledgements&quot; readability=&quot;14.141935483871&quot;&gt;&lt;h2 id=&quot;a-acknowledgements&quot;&gt;&lt;span class=&quot;secno&quot;&gt;A.&lt;/span&gt; Acknowledgements&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;This section is non-normative.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The editors wish to thank the authors of PubSubHubbub, the IndieWeb community, and other implementers for their support, encouragement and enthusiasm. In particular, the editors wish to thank &lt;a href=&quot;https://bradfitz.com/&quot;&gt;Brad Fitzpatrick&lt;/a&gt;, &lt;a href=&quot;http://www.onebigfluke.com/&quot;&gt;Brett Slatkin&lt;/a&gt;, &lt;a href=&quot;http://martin.atkins.me.uk/&quot;&gt;Martin Atkins&lt;/a&gt;, &lt;a href=&quot;http://rhiaro.co.uk/&quot;&gt;Amy Guy&lt;/a&gt;, &lt;a href=&quot;https://barryfrost.com/&quot;&gt;Barry Frost&lt;/a&gt;, &lt;a href=&quot;https://ben.thatmustbe.me/&quot;&gt;Benjamin Roberts&lt;/a&gt;, &lt;a href=&quot;https://zeonfederated.com/&quot;&gt;Eugen Rochko&lt;/a&gt;, &lt;a href=&quot;https://github.com/twitch-jordanpotter&quot;&gt;Jordan Potter&lt;/a&gt;, &lt;a href=&quot;https://notiz.blog/&quot;&gt;Matthias Pfefferle&lt;/a&gt;, &lt;a href=&quot;https://unicyclic.com/mal/&quot;&gt;Malcolm Blaney&lt;/a&gt;, &lt;a href=&quot;https://ma.rtendevri.es/&quot;&gt;Marten de Vries&lt;/a&gt;, &lt;a href=&quot;http://hawke.org/sandro/&quot;&gt;Sandro Hawke&lt;/a&gt;, &lt;a href=&quot;http://tantek.com/&quot;&gt;Tantek Çelik&lt;/a&gt;, and &lt;a href=&quot;https://eighty-twenty.org/&quot;&gt;Tony Garnock-Jones&lt;/a&gt;.&lt;/p&gt;
&lt;/section&gt;&lt;section class=&quot;appendix informative&quot; id=&quot;change-log&quot; readability=&quot;1.9911326078194&quot;&gt;&lt;h2 id=&quot;b-change-log&quot;&gt;&lt;span class=&quot;secno&quot;&gt;B.&lt;/span&gt; Change Log&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;This section is non-normative.&lt;/em&gt;&lt;/p&gt;
&lt;section id=&quot;changes-from-03-october-2017-pr-to-this-version&quot;&gt;&lt;h3 id=&quot;b-1-changes-from-03-october-2017-pr-to-this-version&quot;&gt;&lt;span class=&quot;secno&quot;&gt;B.1&lt;/span&gt; Changes from 03 October 2017 PR to this version&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Added link to content negotiation section from corresponding item in conformance criteria&lt;/li&gt;
&lt;li&gt;Updated reference name from &quot;WHATWG-URL&quot; to &quot;[&lt;cite&gt;&lt;a class=&quot;bibref&quot; href=&quot;https://www.w3.org/TR/websub/#bib-URL&quot;&gt;URL&lt;/a&gt;&lt;/cite&gt;]&quot;, but does not change the actual reference.&lt;/li&gt;
&lt;li&gt;Rephrase sentence on hub URL discovery to better clarify which URLs are being talked about, and use &quot;notify&quot; instead of &quot;ping&quot;&lt;/li&gt;
&lt;li&gt;Correct &quot;mime-type&quot; to &quot;Media Type&quot; and add informative reference to RFC.&lt;/li&gt;
&lt;li&gt;Rephrase summary of &quot;subscribing and unsubscribing&quot; to explicitly mention the actor of each step&lt;/li&gt;
&lt;li&gt;Clarify sending the POST request to the subscriber's callback URL&lt;/li&gt;
&lt;li&gt;Add reference to HTTPS when previously only HTTP was mentioned in cases where an HTTPS URL may be used&lt;/li&gt;
&lt;li&gt;Clarify when hub.lease_seconds parameter is required or optional&lt;/li&gt;
&lt;li&gt;Reword section on subscription migration to make it more clear&lt;/li&gt;
&lt;li&gt;Move note about publisher-&amp;gt;hub notification outside of the subscription migration section&lt;/li&gt;
&lt;li&gt;Remove references to &quot;notification&quot; as a standalone term, replaced by &quot;content distribution request&quot; or &quot;content distribution notification&quot; as appropriate&lt;/li&gt;
&lt;li&gt;Update CR exit criteria text to past tense&lt;/li&gt;
&lt;li&gt;Added explanatory text about why a publisher may advertise multiple hubs&lt;/li&gt;
&lt;li&gt;Replaced sentence in section 8 to better describe the situation &quot;the topic URL in the content distribution request may be different from the topic URL that was originally subscribed to&quot;&lt;/li&gt;
&lt;li&gt;Dropped at-risk limitation of the link tag in the head&lt;/li&gt;
&lt;li&gt;Added security consideration for discovery related to link rel discovery in body vs head&lt;/li&gt;
&lt;li&gt;Dropped unused feature of the hub rejecting the subscription and providing an alternate topic URL&lt;/li&gt;
&lt;li&gt;Added sequence diagram in high-level overview section, and minor updates to phrasing of that section&lt;/li&gt;
&lt;li&gt;Added acknowledgements&lt;/li&gt;
&lt;li&gt;Note that hubs may set a default value for lease_seconds&lt;/li&gt;
&lt;/ul&gt;&lt;/section&gt;&lt;section id=&quot;changes-from-11-april-2017-cr-to-03-october-2017-pr&quot;&gt;&lt;h3 id=&quot;b-2-changes-from-11-april-2017-cr-to-03-october-2017-pr&quot;&gt;&lt;span class=&quot;secno&quot;&gt;B.2&lt;/span&gt; Changes from 11 April 2017 CR to 03 October 2017 PR&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Adds informative guidelines for how publishers can migrate subscribers to a new topic URL&lt;/li&gt;
&lt;li&gt;Allow subscribers to reject invalid signatures with response codes other than 2xx&lt;/li&gt;
&lt;li&gt;Suggest subscribers return HTTP 410 if a subscription has been deleted&lt;/li&gt;
&lt;li&gt;Add informative note about the lack of specification of publisher-hub relationship&lt;/li&gt;
&lt;li&gt;Drop at-risk &lt;code&gt;.host-meta&lt;/code&gt; discovery feature due to lack of implementations (&lt;a href=&quot;https://github.com/w3c/websub/issues/97&quot;&gt;Issue #97&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Add text to note the subscriber's &lt;code&gt;hub.secret&lt;/code&gt; should be cryptographically random and unique&lt;/li&gt;
&lt;li&gt;Clarify that failed delivery of notifications should not delete the subscription before the lease duration ends (&lt;a href=&quot;https://github.com/w3c/websub/issues/119&quot;&gt;Issue #119&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Replaced note about referring to FIPS document for algorithm extensions with a note that says a proper WebSub extension should be defined in the future that enables negotiation of the hashing algorithm between subscribers and hubs&lt;/li&gt;
&lt;li&gt;Add example of returning a different rel=self URL depending on the HTTP &lt;code&gt;Accept-Language&lt;/code&gt; header&lt;/li&gt;
&lt;li&gt;Add a note in Security Considerations about the hashing algorithm protecting against a compromised TLS channel&lt;/li&gt;
&lt;li&gt;Clarify security consideration section regarding signature validation&lt;/li&gt;
&lt;li&gt;Moved &quot;at risk&quot; section out of the &quot;sotd&quot; section which was causing a respec error&lt;/li&gt;
&lt;li&gt;Replaced hyperlink to FIPS PUB 180-4 with an in-page reference&lt;/li&gt;
&lt;/ul&gt;&lt;/section&gt;&lt;section id=&quot;changes-from-24-november-wd-to-11-april-2017-cr&quot;&gt;&lt;h3 id=&quot;b-3-changes-from-24-november-wd-to-11-april-2017-cr&quot;&gt;&lt;span class=&quot;secno&quot;&gt;B.3&lt;/span&gt; Changes from 24 November WD to 11 April 2017 CR&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Clarified wording on supported algorithms for authenticated distribution&lt;/li&gt;
&lt;li&gt;Only allow &lt;code&gt;&amp;lt;link&amp;gt;&lt;/code&gt; tags in the HTML &amp;lt;head&amp;gt; element&lt;/li&gt;
&lt;li&gt;Added conformance criteria and CR exit criteria&lt;/li&gt;
&lt;li&gt;Added examples of discovery request and response&lt;/li&gt;
&lt;li&gt;Added example of using different &lt;code&gt;rel=self&lt;/code&gt; URLs to support content negotiation&lt;/li&gt;
&lt;li&gt;Added a security considerations section&lt;/li&gt;
&lt;li&gt;Updated references to WHATWG-URL instead of HTML 4&lt;/li&gt;
&lt;li&gt;Replaced abstract with updated description&lt;/li&gt;
&lt;/ul&gt;&lt;/section&gt;&lt;section id=&quot;changes-from-20-october-fpwd-to-24-november-2016&quot;&gt;&lt;h3 id=&quot;b-4-changes-from-20-october-fpwd-to-24-november-2016&quot;&gt;&lt;span class=&quot;secno&quot;&gt;B.4&lt;/span&gt; Changes from 20 October FPWD to 24 November 2016&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Added informative reference to previous versions of the spec, PubSubHubbub 0.3 and 0.4&lt;/li&gt;
&lt;li&gt;Split discovery section into separate publisher and subscriber sections&lt;/li&gt;
&lt;li&gt;Clarify that publishers can use any available discovery method, and subscribers must support all&lt;/li&gt;
&lt;li&gt;Marked host-meta discovery method At Risk due to no known implementations, and fixed reference to Host Meta spec instead of the previous reference to Well-Known&lt;/li&gt;
&lt;li&gt;Recommend using Capability URLs as the subscriber's callback URLs for security and authenticating the notification delivery&lt;/li&gt;
&lt;li&gt;Recommend not reusing callback URLs on subscription renewals&lt;/li&gt;
&lt;li&gt;Clarify that the &lt;code&gt;hub.topic&lt;/code&gt; must be the &lt;code&gt;self&lt;/code&gt; URL that was discovered&lt;/li&gt;
&lt;li&gt;Dropped the recommendation of including the &lt;code&gt;From&lt;/code&gt; header on subscription requests&lt;/li&gt;
&lt;li&gt;Clarify that the hub response to subscription requests must not depend on the verification or validation&lt;/li&gt;
&lt;li&gt;Hubs must enforce lease expirations&lt;/li&gt;
&lt;li&gt;Clarify that the notification payload should contain the full contents of the topic URL&lt;/li&gt;
&lt;li&gt;Recommend that hubs should retry failed notification delivery up to self-imposed limits&lt;/li&gt;
&lt;li&gt;Clarify that future defined signature methods in FIPS PUB 180-4 are allowed&lt;/li&gt;
&lt;li&gt;Added informative note about the use of GET vs POST at the callback URL&lt;/li&gt;
&lt;li&gt;Renamed the spec to WebSub&lt;/li&gt;
&lt;/ul&gt;&lt;/section&gt;&lt;/section&gt;&lt;section id=&quot;references&quot; class=&quot;appendix&quot;&gt;&lt;h2 id=&quot;c-references&quot;&gt;&lt;span class=&quot;secno&quot;&gt;C.&lt;/span&gt; References&lt;/h2&gt;
&lt;section id=&quot;normative-references&quot;&gt;&lt;h3 id=&quot;c-1-normative-references&quot;&gt;&lt;span class=&quot;secno&quot;&gt;C.1&lt;/span&gt; Normative references&lt;/h3&gt;
&lt;dl class=&quot;bibliography&quot;&gt;&lt;dt id=&quot;bib-Encoding&quot;&gt;[Encoding]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;https://encoding.spec.whatwg.org/&quot;&gt;&lt;cite&gt;Encoding Standard&lt;/cite&gt;&lt;/a&gt;. Anne van Kesteren. WHATWG. Living Standard. URL: &lt;a href=&quot;https://encoding.spec.whatwg.org/&quot;&gt;https://encoding.spec.whatwg.org/&lt;/a&gt;&lt;/dd&gt;
&lt;dt id=&quot;bib-HTML5&quot;&gt;[HTML5]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;https://www.w3.org/TR/html5/&quot;&gt;&lt;cite&gt;HTML5&lt;/cite&gt;&lt;/a&gt;. Ian Hickson; Robin Berjon; Steve Faulkner; Travis Leithead; Erika Doyle Navara; Theresa O'Connor; Silvia Pfeiffer. W3C. 28 October 2014. W3C Recommendation. URL: &lt;a href=&quot;https://www.w3.org/TR/html5/&quot;&gt;https://www.w3.org/TR/html5/&lt;/a&gt;&lt;/dd&gt;
&lt;dt id=&quot;bib-RFC2119&quot;&gt;[RFC2119]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;https://tools.ietf.org/html/rfc2119&quot;&gt;&lt;cite&gt;Key words for use in RFCs to Indicate Requirement Levels&lt;/cite&gt;&lt;/a&gt;. S. Bradner. IETF. March 1997. Best Current Practice. URL: &lt;a href=&quot;https://tools.ietf.org/html/rfc2119&quot;&gt;https://tools.ietf.org/html/rfc2119&lt;/a&gt;&lt;/dd&gt;
&lt;dt id=&quot;bib-RFC2818&quot;&gt;[RFC2818]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;https://tools.ietf.org/html/rfc2818&quot;&gt;&lt;cite&gt;HTTP Over TLS&lt;/cite&gt;&lt;/a&gt;. E. Rescorla. IETF. May 2000. Informational. URL: &lt;a href=&quot;https://tools.ietf.org/html/rfc2818&quot;&gt;https://tools.ietf.org/html/rfc2818&lt;/a&gt;&lt;/dd&gt;
&lt;dt id=&quot;bib-RFC5988&quot;&gt;[RFC5988]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;https://tools.ietf.org/html/rfc5988&quot;&gt;&lt;cite&gt;Web Linking&lt;/cite&gt;&lt;/a&gt;. M. Nottingham. IETF. October 2010. Proposed Standard. URL: &lt;a href=&quot;https://tools.ietf.org/html/rfc5988&quot;&gt;https://tools.ietf.org/html/rfc5988&lt;/a&gt;&lt;/dd&gt;
&lt;dt id=&quot;bib-RFC6151&quot;&gt;[RFC6151]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;https://tools.ietf.org/html/rfc6151&quot;&gt;&lt;cite&gt;Updated Security Considerations for the MD5 Message-Digest and the HMAC-MD5 Algorithms&lt;/cite&gt;&lt;/a&gt;. S. Turner; L. Chen. IETF. March 2011. Informational. URL: &lt;a href=&quot;https://tools.ietf.org/html/rfc6151&quot;&gt;https://tools.ietf.org/html/rfc6151&lt;/a&gt;&lt;/dd&gt;
&lt;dt id=&quot;bib-RFC7230&quot;&gt;[RFC7230]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;https://tools.ietf.org/html/rfc7230&quot;&gt;&lt;cite&gt;Hypertext Transfer Protocol (HTTP/1.1): Message Syntax and Routing&lt;/cite&gt;&lt;/a&gt;. R. Fielding, Ed.; J. Reschke, Ed.. IETF. June 2014. Proposed Standard. URL: &lt;a href=&quot;https://tools.ietf.org/html/rfc7230&quot;&gt;https://tools.ietf.org/html/rfc7230&lt;/a&gt;&lt;/dd&gt;
&lt;dt id=&quot;bib-RFC7231&quot;&gt;[RFC7231]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;https://tools.ietf.org/html/rfc7231&quot;&gt;&lt;cite&gt;Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content&lt;/cite&gt;&lt;/a&gt;. R. Fielding, Ed.; J. Reschke, Ed.. IETF. June 2014. Proposed Standard. URL: &lt;a href=&quot;https://tools.ietf.org/html/rfc7231&quot;&gt;https://tools.ietf.org/html/rfc7231&lt;/a&gt;&lt;/dd&gt;
&lt;dt id=&quot;bib-URL&quot;&gt;[URL]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;https://url.spec.whatwg.org/&quot;&gt;&lt;cite&gt;URL Standard&lt;/cite&gt;&lt;/a&gt;. Anne van Kesteren. WHATWG. Living Standard. URL: &lt;a href=&quot;https://url.spec.whatwg.org/&quot;&gt;https://url.spec.whatwg.org/&lt;/a&gt;&lt;/dd&gt;
&lt;/dl&gt;&lt;/section&gt;&lt;section id=&quot;informative-references&quot;&gt;&lt;h3 id=&quot;c-2-informative-references&quot;&gt;&lt;span class=&quot;secno&quot;&gt;C.2&lt;/span&gt; Informative references&lt;/h3&gt;
&lt;dl class=&quot;bibliography&quot;&gt;&lt;dt id=&quot;bib-capability-urls&quot;&gt;[capability-urls]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;https://www.w3.org/TR/capability-urls/&quot;&gt;&lt;cite&gt;Good Practices for Capability URLs&lt;/cite&gt;&lt;/a&gt;. Jeni Tennison. W3C. 18 February 2014. W3C Working Draft. URL: &lt;a href=&quot;https://www.w3.org/TR/capability-urls/&quot;&gt;https://www.w3.org/TR/capability-urls/&lt;/a&gt;&lt;/dd&gt;
&lt;dt id=&quot;bib-FIPS-PUB-180-4&quot;&gt;[FIPS-PUB-180-4]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;http://dx.doi.org/10.6028/NIST.FIPS.180-4&quot;&gt;&lt;cite&gt;Secure Hash Standard (SHS)&lt;/cite&gt;&lt;/a&gt;. National Institute of Standards and Technology. U.S. Department of Commerce. URL: &lt;a href=&quot;http://dx.doi.org/10.6028/NIST.FIPS.180-4&quot;&gt;http://dx.doi.org/10.6028/NIST.FIPS.180-4&lt;/a&gt;&lt;/dd&gt;
&lt;dt id=&quot;bib-PubSubHubbub-Core-0.3&quot;&gt;[PubSubHubbub-Core-0.3]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;https://pubsubhubbub.github.io/PubSubHubbub/pubsubhubbub-core-0.3.html&quot;&gt;&lt;cite&gt;PubSubHubbub Core 0.3 -- Working Draft&lt;/cite&gt;&lt;/a&gt;. B. Fitzpatrick; B. Slatkin; M. Atkins.URL: &lt;a href=&quot;https://pubsubhubbub.github.io/PubSubHubbub/pubsubhubbub-core-0.3.html&quot;&gt;https://pubsubhubbub.github.io/PubSubHubbub/pubsubhubbub-core-0.3.html&lt;/a&gt;&lt;/dd&gt;
&lt;dt id=&quot;bib-PubSubHubbub-Core-0.4&quot;&gt;[PubSubHubbub-Core-0.4]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;https://pubsubhubbub.github.io/PubSubHubbub/pubsubhubbub-core-0.4.html&quot;&gt;&lt;cite&gt;PubSubHubbub Core 0.4 -- Working Draft&lt;/cite&gt;&lt;/a&gt;. B. Fitzpatrick; B. Slatkin; M. Atkins; J. Genestoux.URL: &lt;a href=&quot;https://pubsubhubbub.github.io/PubSubHubbub/pubsubhubbub-core-0.4.html&quot;&gt;https://pubsubhubbub.github.io/PubSubHubbub/pubsubhubbub-core-0.4.html&lt;/a&gt;&lt;/dd&gt;
&lt;dt id=&quot;bib-RFC4287&quot;&gt;[RFC4287]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;https://tools.ietf.org/html/rfc4287&quot;&gt;&lt;cite&gt;The Atom Syndication Format&lt;/cite&gt;&lt;/a&gt;. M. Nottingham, Ed.; R. Sayre, Ed.. IETF. December 2005. Proposed Standard. URL: &lt;a href=&quot;https://tools.ietf.org/html/rfc4287&quot;&gt;https://tools.ietf.org/html/rfc4287&lt;/a&gt;&lt;/dd&gt;
&lt;dt id=&quot;bib-RFC6838&quot;&gt;[RFC6838]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;https://tools.ietf.org/html/rfc6838&quot;&gt;&lt;cite&gt;Media Type Specifications and Registration Procedures&lt;/cite&gt;&lt;/a&gt;. N. Freed; J. Klensin; T. Hansen. IETF. January 2013. Best Current Practice. URL: &lt;a href=&quot;https://tools.ietf.org/html/rfc6838&quot;&gt;https://tools.ietf.org/html/rfc6838&lt;/a&gt;&lt;/dd&gt;

&lt;dd&gt;&lt;a href=&quot;http://www.rssboard.org/rss-specification&quot;&gt;&lt;cite&gt;RSS 2.0&lt;/cite&gt;&lt;/a&gt;. Dave Winer. RSS Board. Stable. URL: &lt;a href=&quot;http://www.rssboard.org/rss-specification&quot;&gt;http://www.rssboard.org/rss-specification&lt;/a&gt;&lt;/dd&gt;
&lt;dt id=&quot;bib-security-privacy-questionnaire&quot;&gt;[security-privacy-questionnaire]&lt;/dt&gt;
&lt;dd&gt;&lt;a href=&quot;https://www.w3.org/TR/security-privacy-questionnaire/&quot;&gt;&lt;cite&gt;Self-Review Questionnaire: Security and Privacy&lt;/cite&gt;&lt;/a&gt;. Mike West. W3C. 10 December 2015. W3C Note. URL: &lt;a href=&quot;https://www.w3.org/TR/security-privacy-questionnaire/&quot;&gt;https://www.w3.org/TR/security-privacy-questionnaire/&lt;/a&gt;&lt;/dd&gt;
&lt;/dl&gt;&lt;/section&gt;&lt;/section&gt;&lt;p role=&quot;navigation&quot; id=&quot;back-to-top&quot;&gt;&lt;a href=&quot;https://www.w3.org/TR/websub/#toc&quot;&gt;&lt;abbr title=&quot;Back to Top&quot;&gt;↑&lt;/abbr&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/body&gt;</description>
<pubDate>Thu, 05 Jul 2018 06:22:48 +0000</pubDate>
<dc:creator>dgellow</dc:creator>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.w3.org/TR/websub/</dc:identifier>
</item>
<item>
<title>WhatsApp sends Cease and Desists for apps that use native Android APIs</title>
<link>https://www.xda-developers.com/whatsapp-sends-cease-desist-apps-native-android-api/</link>
<guid isPermaLink="true" >https://www.xda-developers.com/whatsapp-sends-cease-desist-apps-native-android-api/</guid>
<description>&lt;div readability=&quot;99.505070993915&quot;&gt;

&lt;p class=&quot;dropcap&quot;&gt;&lt;a href=&quot;https://forum.xda-developers.com/t/whatsapp&quot;&gt;WhatsApp&lt;/a&gt; is one of the most popular applications available on smartphones to date with &lt;a href=&quot;https://www.xda-developers.com/whatsapp-billion-active-users/&quot;&gt;over a billion active users per day&lt;/a&gt;. Bought by Facebook back in 2014 for $19 billion, skeptics feared how the application would be managed from there on out. Fortunately for users, it seems that little has changed despite some &lt;a href=&quot;https://www.xda-developers.com/whatsapp-founder-leaves-company/&quot;&gt;concerning developments behind the scenes&lt;/a&gt;. Unfortunately for developers, there’s been one area where we wish the company had changed: their stance towards third-party developers. The company is sending out a new round of Cease and Desist letters to independent Android app developers, but this time their claims have a lot less merit.&lt;/p&gt;
&lt;div class=&quot;wpappbox wpappbox-e0aecd39a441560c700bbf62b6f94e8b googleplay colorful simple&quot;&gt;
&lt;div class=&quot;qrcode&quot;&gt;&lt;img src=&quot;https://chart.googleapis.com/chart?cht=qr&amp;amp;chl=https%3A%2F%2Fplay.google.com%2Fstore%2Fapps%2Fdetails%3Fid%3Dcom.whatsapp&amp;amp;chs=200x200&amp;amp;chld=L|0&quot; alt=&quot;WhatsApp Messenger&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;appicon&quot;&gt;&lt;a target=&quot;_blank&quot; rel=&quot;nofollow&quot; href=&quot;https://play.google.com/store/apps/details?id=com.whatsapp&quot;&gt;&lt;img src=&quot;https://lh3.ggpht.com/mp86vbELnqLi2FzvhiKdPX31_oiTRLNyeK8x4IIrbF5eD1D5RdnVwjQP0hwMNR_JdA=s180&quot; alt=&quot;WhatsApp Messenger&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;div class=&quot;appdetails&quot;&gt;


&lt;div class=&quot;price&quot;&gt;&lt;span&gt;Price: Free&lt;/span&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2&gt;What’s up with WhatsApp?&lt;/h2&gt;
&lt;p&gt;WhatsApp is one of the largest services on the planet so it’s no surprise to see them aggressively protect their brand by preventing abuse of their platform. That’s perfectly fine and why we can understand why the company previously &lt;a href=&quot;https://www.xda-developers.com/cease-and-desist-whatsapp-sucks-and-you-cant-help-it/&quot;&gt;went after third-party clients&lt;/a&gt; even if we don’t agree with the decision. Applications that use a service’s APIs are walking a tightrope because the service can change their API’s Terms of Service whenever they want to kill third-party clients (so long as they inform users of any changes). Developers of third-party Twitter clients &lt;a href=&quot;https://www.xda-developers.com/twitter-new-api-third-party-clients/&quot;&gt;know this all too well&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But that’s not what’s happening this time. A legal firm representing WhatsApp has sent Cease and Desist letters to at least two independent Android app developers – the developers behind &lt;a href=&quot;https://medium.com/@lowcarbrob/cease-desist-can-using-androids-notification-listener-violate-another-apps-t-c-s-9bdd8d06059a&quot;&gt;Can’t Talk&lt;/a&gt; and &lt;a href=&quot;https://www.reddit.com/r/Android/comments/8v9pb4/whatsapp_sent_me_a_cease_and_desist_letter_for/&quot;&gt;DirectChat&lt;/a&gt; – demanding that they remove functionality from their app or face litigation. Neither of these applications uses any code from or interfacing with the WhatsApp service. Rather, these applications utilize standard Android APIs, Notification Listener and Direct Reply, to function. Thus, the demands to strip these apps of any functionality related to WhatsApp is dubious at best, and malicious at worst.&lt;/p&gt;
&lt;p&gt;You can view a redacted version of the Cease and Desist letter below that the developers received from the legal firm representing WhatsApp. &lt;em&gt;XDA-Developers&lt;/em&gt; can confirm the authenticity of the original letter. We have reached out to WhatsApp’s parent company, Facebook, for comment.&lt;/p&gt;
&lt;div id=&quot;attachment_224186&quot; class=&quot;wp-caption aligncenter&quot;&gt;&lt;img class=&quot;size-full wp-image-224186&quot; src=&quot;https://www1-lw.xda-cdn.com/files/2018/07/whatsapp-cease-and-desist.jpg&quot; alt=&quot;WHATSAPP&quot; width=&quot;843&quot; height=&quot;889&quot; srcset=&quot;https://www1-lw.xda-cdn.com/files/2018/07/whatsapp-cease-and-desist.jpg 843w, https://www1-lw.xda-cdn.com/files/2018/07/whatsapp-cease-and-desist-284x300.jpg 284w, https://www1-lw.xda-cdn.com/files/2018/07/whatsapp-cease-and-desist-768x810.jpg 768w&quot; sizes=&quot;(max-width: 843px) 100vw, 843px&quot;/&gt;&lt;p class=&quot;wp-caption-text&quot;&gt;Source: &lt;a href=&quot;https://www.reddit.com/r/Android/comments/8vkqtk/follow_up_whatsapp_cease_and_desist_full_letter/&quot;&gt;Reddit&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Breaking down the Cease and Desist letter&lt;/h2&gt;
&lt;p&gt;There are a number of claims made by the letter which does not accurately reflect the functionality of each application with respect to their WhatsApp integrations. Let’s break down some of these claims:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;“You agreed to these Terms of Service by installing, accessing, or using the WhatsApp Services.”
&lt;ul&gt;&lt;li&gt;Neither of these applications uses any APIs from the service. Further, the developers never agreed to the Terms of Service in the first place because they aren’t using any of their APIs.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;“Reverse engineer, alter, modify, create derivative works from, decompile, or extract code from the WhatsApp Services.”
&lt;ul&gt;&lt;li&gt;Neither of these applications is WhatsApp specific and make use of native Android APIs rather than any code from WhatsApp itself.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;“Gain or attempt to gain unauthorized access to the WhatsApp Services or systems.”
&lt;ul&gt;&lt;li&gt;By that logic, Android itself violates the ToS as it processes each notification and keeps a log of notifications.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;“Collect the information of or about WhatsApp’s users in any impermissible or unauthorized manner”
&lt;ul&gt;&lt;li&gt;The users explicitly download and install this app on their own.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;“Sell, resell, rent, or charge for the WhatsApp Services”
&lt;ul&gt;&lt;li&gt;The apps do not rent or sell access to the service. Both apps can’t function unless the original WhatsApp application is installed.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Nearly every claim in the letter is faulty or is too vague to address how the apps violate these terms. Nevermind the fact that none of the developers behind these apps agreed to any ToS in the first place, making these agreements moot anyway. The letter does state that the list of alleged violations is non-exhaustive, though. Unless there is a term not covered here that these applications violated, then we fail to see how these apps violate the ToS. Even the use of the WhatsApp brand name in the Play Store description for each app &lt;em&gt;might&lt;/em&gt; violate their trademark and not the ToS.&lt;/p&gt;
&lt;p&gt;The developers have seven days to comply or they will presumably face a lawsuit. Can’t Talk has already been removed from the Play Store while the developer evaluates their options, while the DirectChat app is still available but may be altered to remove access to the WhatsApp integration. Removal of the integration would deal a major blow to each app since the majority of their users are likely using these apps for that specific integration – WhatsApp has over a billion active users each day after all.&lt;/p&gt;
&lt;h2&gt;Applications that received Cease and Desist letters&lt;/h2&gt;
&lt;h3&gt;Can’t Talk&lt;/h3&gt;
&lt;div id=&quot;gallery-2&quot; class=&quot;gallery galleryid-224181 gallery-columns-2 gallery-size-medium&quot;&gt;
&lt;dl class=&quot;gallery-item&quot;&gt;&lt;dt class=&quot;gallery-icon portrait&quot;&gt;&lt;a href=&quot;https://www1-lw.xda-cdn.com/files/2018/07/Cant-Talk-App-2.png&quot; title=&quot;&quot; data-rl_title=&quot;&quot; data-rl_caption=&quot;&quot; data-rel=&quot;lightbox-gallery-2&quot;&gt;&lt;img width=&quot;169&quot; height=&quot;300&quot; src=&quot;https://www1-lw.xda-cdn.com/files/2018/07/Cant-Talk-App-2-169x300.png&quot; class=&quot;attachment-medium size-medium rl-gallery-link&quot; alt=&quot;WhatsApp Cease and Desist&quot; srcset=&quot;https://www1-lw.xda-cdn.com/files/2018/07/Cant-Talk-App-2-169x300.png 169w, https://www1-lw.xda-cdn.com/files/2018/07/Cant-Talk-App-2-576x1024.png 576w, https://www1-lw.xda-cdn.com/files/2018/07/Cant-Talk-App-2.png 675w&quot; sizes=&quot;(max-width: 169px) 100vw, 169px&quot;/&gt;&lt;/a&gt;&lt;/dt&gt;
&lt;/dl&gt;&lt;dl class=&quot;gallery-item&quot;&gt;&lt;dt class=&quot;gallery-icon portrait&quot;&gt;&lt;a href=&quot;https://www1-lw.xda-cdn.com/files/2018/07/Cant-Talk-App-1.png&quot; title=&quot;&quot; data-rl_title=&quot;&quot; data-rl_caption=&quot;&quot; data-rel=&quot;lightbox-gallery-2&quot;&gt;&lt;img width=&quot;169&quot; height=&quot;300&quot; src=&quot;https://www1-lw.xda-cdn.com/files/2018/07/Cant-Talk-App-1-169x300.png&quot; class=&quot;attachment-medium size-medium rl-gallery-link&quot; alt=&quot;WhatsApp Cease and Desist&quot; srcset=&quot;https://www1-lw.xda-cdn.com/files/2018/07/Cant-Talk-App-1-169x300.png 169w, https://www1-lw.xda-cdn.com/files/2018/07/Cant-Talk-App-1-576x1024.png 576w, https://www1-lw.xda-cdn.com/files/2018/07/Cant-Talk-App-1.png 675w&quot; sizes=&quot;(max-width: 169px) 100vw, 169px&quot;/&gt;&lt;/a&gt;&lt;/dt&gt;
&lt;/dl&gt;&lt;br/&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://forum.xda-developers.com/android/apps-games/app-talk-office-everything-t3634507&quot;&gt;Can’t Talk&lt;/a&gt;‘s premise is &lt;a href=&quot;https://www.xda-developers.com/cant-talk-auto-reply-whatsapp-slack/&quot;&gt;simple&lt;/a&gt;. All it does is automatically reply to people when you aren’t around, making use of the quick reply (RemoteInput) API native to Android. If you’re driving a car, watching a movie, or simply don’t want to talk at the time, then the application can reply for you with a preset message. It can also send a text to somebody who tried to call you as well. It’s a paid application if you want to support more than SMS and calls, such as WhatsApp, Slack, and a lot more. Basically, any messaging service that allows you to send a quick reply via the notification you can use Can’t Talk with.&lt;/p&gt;
&lt;h3&gt;DirectChat&lt;/h3&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter size-large wp-image-224340&quot; src=&quot;https://www1-lw.xda-cdn.com/files/2018/07/DirectChat-Feature-Image-1024x497.png&quot; alt=&quot;DirectChat&quot; width=&quot;900&quot; height=&quot;437&quot; srcset=&quot;https://www1-lw.xda-cdn.com/files/2018/07/DirectChat-Feature-Image-1024x497.png 1024w, https://www1-lw.xda-cdn.com/files/2018/07/DirectChat-Feature-Image-300x146.png 300w, https://www1-lw.xda-cdn.com/files/2018/07/DirectChat-Feature-Image-768x373.png 768w, https://www1-lw.xda-cdn.com/files/2018/07/DirectChat-Feature-Image.png 1200w&quot; sizes=&quot;(max-width: 900px) 100vw, 900px&quot;/&gt;&lt;/p&gt;

&lt;p&gt;DirectChat is another useful application. It works just like Facebook Messenger’s chat bubbles but it supports a lot of different applications too. It feeds your chats into another window where you can then reply back as well. Its most popular usage was probably with WhatsApp.&lt;/p&gt;
&lt;div class=&quot;wpappbox wpappbox-d58d7b091eb23d8a364fab9076089e6f googleplay colorful simple&quot;&gt;
&lt;div class=&quot;qrcode&quot;&gt;&lt;img src=&quot;https://chart.googleapis.com/chart?cht=qr&amp;amp;chl=https%3A%2F%2Fplay.google.com%2Fstore%2Fapps%2Fdetails%3Fid%3Dnet.uniquegem.directchat&amp;amp;chs=200x200&amp;amp;chld=L|0&quot; alt=&quot;DirectChat (ChatHeads for All)&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;appicon&quot;&gt;&lt;a target=&quot;_blank&quot; rel=&quot;nofollow&quot; href=&quot;https://play.google.com/store/apps/details?id=net.uniquegem.directchat&quot;&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/_S3EL_gDVYB_HqlFycNzogNXJmTLwKmBx9FIal0T8TgMKDh1ZIBNedVy1r2YCqjLxA=s180&quot; alt=&quot;DirectChat (ChatHeads for All)&quot;/&gt;&lt;/a&gt;&lt;/div&gt;

&lt;div class=&quot;appdetails&quot;&gt;


&lt;div class=&quot;price&quot;&gt;&lt;span&gt;Price: Free&lt;/span&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2&gt;What happens next?&lt;/h2&gt;
&lt;p&gt;The takedown of these applications for use of native Android APIs sets a dangerous precedent for future takedowns by large companies. If this continues, what’s stopping WhatsApp from demanding the takedown of &lt;strong&gt;any&lt;/strong&gt; notification manager application, regardless of its specific use for WhatsApp. Independent app developers don’t have the resources to combat these claims so most just give in. We’ll be following the situation closely and will update you if we hear back from either Facebook/WhatsApp, the affected developers, or another party involved in this situation.&lt;/p&gt;


&lt;/div&gt;&lt;p&gt;Want more posts like this delivered to your inbox? Enter your email to be subscribed to our newsletter.&lt;/p&gt;</description>
<pubDate>Thu, 05 Jul 2018 04:48:33 +0000</pubDate>
<dc:creator>mimerme</dc:creator>
<og:type>article</og:type>
<og:title>WhatsApp sends Cease &amp; Desists for apps that use native Android APIs</og:title>
<og:description>WhatsApp has sent out cease and desist letters to some developers claiming they violate the service's ToS despite using native Android APIs.</og:description>
<og:url>https://www.xda-developers.com/whatsapp-sends-cease-desist-apps-native-android-api/</og:url>
<og:image>https://www1-lw.xda-cdn.com/files/2017/11/WhatsApp.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.xda-developers.com/whatsapp-sends-cease-desist-apps-native-android-api/</dc:identifier>
</item>
<item>
<title>How to crawl a quarter billion webpages in 40 hours (2012)</title>
<link>http://www.michaelnielsen.org/ddi/how-to-crawl-a-quarter-billion-webpages-in-40-hours/</link>
<guid isPermaLink="true" >http://www.michaelnielsen.org/ddi/how-to-crawl-a-quarter-billion-webpages-in-40-hours/</guid>
<description>&lt;p&gt;More precisely, I crawled 250,113,669 pages for just under 580 dollars in 39 hours and 25 minutes, using 20 Amazon EC2 machine instances.&lt;/p&gt;
&lt;p&gt;I carried out this project because (among several other reasons) I wanted to understand what resources are required to crawl a small but non-trivial fraction of the web. In this post I describe some details of what I did. Of course, there’s nothing especially new: I wrote a vanilla (distributed) crawler, mostly to teach myself something about crawling and distributed computing. Still, I learned some lessons that may be of interest to a few others, and so in this post I describe what I did. The post also mixes in some personal working notes, for my own future reference.&lt;/p&gt;
&lt;p&gt;What does it mean to crawl a non-trivial fraction of the web? In fact, the notion of a “non-trivial fraction of the web” isn’t well defined. Many websites generate pages dynamically, in response to user input – for example, Google’s search results pages are dynamically generated in response to the user’s search query. Because of this it doesn’t make much sense to say there are so-and-so many billion or trillion pages on the web. This, in turn, makes it difficult to say precisely what is meant by “a non-trivial fraction of the web”. However, as a reasonable proxy for the size of the web we can use the number of webpages indexed by large search engines. According to this &lt;a href=&quot;http://www.youtube.com/watch?v=modXC5IWTJI&amp;amp;feature=player_detailpage#t=175s&quot;&gt;presentation&lt;/a&gt; by Googler &lt;a href=&quot;http://research.google.com/people/jeff/&quot;&gt;Jeff Dean&lt;/a&gt;, as of November 2010 Google was indexing “tens of billions of pages”. (Note that the &lt;a href=&quot;http://googleblog.blogspot.com/2008/07/we-knew-web-was-big.html&quot;&gt;number of urls&lt;/a&gt; is in the trillions, apparently because of duplicated page content, and multiple urls pointing to the same content.) The now-defunct search engine &lt;a href=&quot;http://en.wikipedia.org/wiki/Cuil&quot;&gt;Cuil&lt;/a&gt; claimed to index &lt;a href=&quot;http://searchengineland.com/cuil-launches-can-this-search-start-up-really-best-google-14459&quot;&gt;120 billion pages&lt;/a&gt;. By comparison, a quarter billion is, obviously, very small. Still, it seemed to me like an encouraging start.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Code:&lt;/strong&gt; Originally I intended to make the crawler code available under an open source license at GitHub. However, as I better understood the cost that crawlers impose on websites, I began to have reservations. My crawler is designed to be polite and impose relatively little burden on any single website, but could (like many crawlers) easily be modified by thoughtless or malicious people to impose a heavy burden on sites. Because of this I’ve decided to postpone (possibly indefinitely) releasing the code.&lt;/p&gt;
&lt;p&gt;There’s a more general issue here, which is this: who gets to crawl the web? Relatively few sites exclude crawlers from companies such as Google and Microsoft. But there are a &lt;em&gt;lot&lt;/em&gt; of crawlers out there, many of them without much respect for the needs of individual siteowners. Quite reasonably, many siteowners take an aggressive approach to shutting down activity from less well-known crawlers. A possible side effect is that if this becomes too common at some point in the future, then it may impede the development of useful new services, which need to crawl the web. A possible long-term solution may be services like &lt;a href=&quot;http://commoncrawl.org/&quot;&gt;Common Crawl&lt;/a&gt;, which provide access to a common corpus of crawl data.&lt;/p&gt;
&lt;p&gt;I’d be interested to hear other people’s thoughts on this issue.&lt;/p&gt;
&lt;p&gt;(&lt;em&gt;Later update:&lt;/em&gt; I get regular email asking me to send people my code. Let me pre-emptively say: I decline these requests.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Architecture:&lt;/strong&gt; Here’s the basic architecture:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://michaelnielsen.org/ddi/wp-content/uploads/2012/08/quarter_billion_page_crawl_big_picture.png&quot; width=&quot;440px&quot;/&gt;&lt;/p&gt;
&lt;p&gt;The master machine (my laptop) begins by downloading &lt;a href=&quot;http://www.alexa.com&quot;&gt;Alexa’s&lt;/a&gt; list of the &lt;a href=&quot;http://s3.amazonaws.com/alexa-static/top-1m.csv.zip&quot;&gt;top million domains&lt;/a&gt;. These were used both as a domain whitelist for the crawler, and to generate a starting list of seed urls.&lt;/p&gt;
&lt;p&gt;The domain whitelist was partitioned across the 20 EC2 machine instances in the crawler. This was done by numbering the instances &lt;img src=&quot;http://s0.wp.com/latex.php?latex=0%2C+1%2C+2%2C+%5Cldots%2C+19&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;0, 1, 2, \ldots, 19&quot; title=&quot;0, 1, 2, \ldots, 19&quot; class=&quot;latex&quot;/&gt; and then allocating the domain &lt;tt&gt;domain&lt;/tt&gt; to instance number &lt;tt&gt;hash(domain) % 20&lt;/tt&gt;, where &lt;tt&gt;hash&lt;/tt&gt; is the standard Python hash function.&lt;/p&gt;
&lt;p&gt;Deployment and management of the cluster was handled using &lt;a href=&quot;http://www.fabfile.org/&quot;&gt;Fabric&lt;/a&gt;, a well-documented and nicely designed Python library which streamlines the use of ssh over clusters of machines. I managed the connection to Amazon EC2 using a &lt;a href=&quot;https://github.com/mnielsen/ec2_tools&quot;&gt;set of Python scripts&lt;/a&gt; I wrote, which wrap the &lt;a href=&quot;https://github.com/boto/boto&quot;&gt;boto&lt;/a&gt; library.&lt;/p&gt;
&lt;p&gt;I used 20 Amazon EC2 &lt;a href=&quot;http://aws.amazon.com/ec2/instance-types/&quot;&gt;extra large&lt;/a&gt; instances, running Ubuntu 11.04 (Natty Narwhal) under the &lt;a href=&quot;http://thecloudmarket.com/image/ami-68ad5201--ubuntu-images-ubuntu-natty-11-04-amd64-server-20110426&quot;&gt;ami-68ad5201 Amazon machine image&lt;/a&gt; provided by Canonical. I used the extra large instance after testing on several instance types; the extra large instances provided (marginally) more pages downloaded per dollar spent. I used the US East (North Virginia) region, because it’s the least expensive of Amazon’s regions (along with the US West, Oregon region).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Single instance architecture:&lt;/strong&gt; Each instance further partitioned its domain whitelist into 141 separate blocks of domains, and launched 141 Python threads, with each thread responsible for crawling the domains in one block. Here’s how it worked (details below):&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://michaelnielsen.org/ddi/wp-content/uploads/2012/08/quarter_billion_page_crawl_single_instance.png&quot; width=&quot;440px&quot;/&gt;&lt;/p&gt;
&lt;p&gt;The reason for using threads is that the Python standard library uses blocking I/O to handle http network connections. This means that a single-threaded crawler would spend most of its time idling, usually waiting on the network connection of the remote machine being crawled. It’s much better to use a multi-threaded crawler, which can make fuller use of the resources available on an EC2 instance. I chose the number of crawler threads (141) empirically: I kept increasing the number of threads until the speed of the crawler started to saturate. With this number of threads the crawler was using a considerable fraction of the CPU capacity available on the EC2 instance. My informal testing suggested that it was CPU which was the limiting factor, but that I was not so far away from the network and disk speed becoming bottlenecks; in this sense, the EC2 extra large instance was a good compromise. Memory useage was never an issue. It’s possible that for this reason EC2’s high-CPU extra large instance type would have been a better choice; I only experimented with this instance type with early versions of the crawler, which were more memory-limited.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How domains were allocated across threads:&lt;/strong&gt; The threads were numbered &lt;img src=&quot;http://s0.wp.com/latex.php?latex=0%2C+1%2C+%5Cldots%2C+140&amp;amp;bg=ffffff&amp;amp;fg=000000&amp;amp;s=0&quot; alt=&quot;0, 1, \ldots, 140&quot; title=&quot;0, 1, \ldots, 140&quot; class=&quot;latex&quot;/&gt;, and domains were allocated on the basis of the Python hash function, to thread number &lt;tt&gt;hash(domain) % 141&lt;/tt&gt; (similar to the allocation across machines in the cluster). Once the whitelisted domains / seed urls were allocated to threads, the crawl was done in a simple breadth-first fashion, i.e., for each seed url we download the corresponding web page, extract the linked urls, and check each url to see: (a) whether the extracted url is a fresh url which has not already been seen and added to the url frontier; and (b) whether the extracted url is in the same seed domain as the page which has just been crawled. If both these conditions are met, the url is added to the url frontier for the current thread, otherwise the url is discarded. With this architecture we are essentially carrying out a very large number of independent crawls of the whitelisted domains obtained from Alexa.&lt;/p&gt;
&lt;p&gt;Note that this architecture also ensures that if, for example, we are crawling a page from TechCrunch, and extract from that page a link to the Huffington Post, then the latter link will be discarded, even though the Huffington Post is in our domain whitelist. The only links added to the url frontier will be those that point back to TechCrunch itself. The reason we avoid adding dealing with (whitelisted) external links is because: (a) it may require communication between different EC2 instances, which would substantially complicate the crawler; and, more importantly, (b) in practice, most sites have lots of internal links, and so it’s unlikely that this policy means the crawler is missing much.&lt;/p&gt;
&lt;p&gt;One advantage of allocating all urls from the same domain to the same crawler thread is that it makes it much easier to crawl politely, since no more than one connection to a site will be open at any given time. In particular, this ensures that we won’t be hammering any given domain with many simultaneous connections from different threads (or different machines).&lt;/p&gt;
&lt;h3&gt;Problems for the author&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;For some very large and rapidly changing websites it may be necessary to open multiple simultaneous connections in order for the crawl to keep up with the changes on the site. How can we decide when that is appropriate?&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;How the url frontiers work:&lt;/strong&gt; A &lt;em&gt;separate&lt;/em&gt; url frontier file was maintained for each domain. This was simply a text file, with each line containing a single url to be crawled; initially, the file contains just a single line, with the seed url for the domain. I spoke above of the url frontier for a thread; that frontier can be thought of as the combination of all the url frontier files for domains being crawled by that thread.&lt;/p&gt;
&lt;p&gt;Each thread maintained a connection to a &lt;a href=&quot;http://redis.io/&quot;&gt;redis&lt;/a&gt; server. For each domain being crawled by the thread a redis key-value pair was used to keep track of the current position in the url frontier file for that domain. I used redis (and the &lt;a href=&quot;https://github.com/andymccurdy/redis-py/&quot;&gt;Python bindings&lt;/a&gt;) to store this information in a fashion that was both persistent and fast to look up. The persistence was important because it meant that the crawler could be stopped and started at will, without losing track of where it was in the url frontier.&lt;/p&gt;
&lt;p&gt;Each thread also maintained a dictionary whose keys were the (hashed) domains for that thread. The corresponding values were the next time it would be polite to crawl that domain. This value was set to be 70 seconds after the last time the domain was crawled, to ensure that domains weren’t getting hit too often. The crawler thread simply iterated over the keys in this dictionary, looking for the next domain it was polite to crawl. Once it found such a domain it then extracted the next url from the url frontier for that domain, and went about downloading that page. If the url frontier was exhausted (some domains run out of pages to crawl) then the domain key was removed from the dictionary. One limitation of this design was that when restarting the crawler each thread had to identify again which domains had already been exhausted and should be deleted from the dictionary. This slowed down the restart a little, and is something I’d modify if I were to do further work with the crawler.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Use of a Bloom filter:&lt;/strong&gt; I used a &lt;a href=&quot;http://en.wikipedia.org/wiki/Bloom_filter&quot;&gt;Bloom filter&lt;/a&gt; to keep track of which urls had already been seen and added to the url frontier. This enabled a very fast check of whether or not a new candidate url should be added to the url frontier, with only a low probability of erroneously adding a url that had already been added. This was done using &lt;a href=&quot;http://mike.axiak.net/&quot;&gt;Mike Axiak&lt;/a&gt;‘s very nice C-based &lt;a href=&quot;https://github.com/axiak/pybloomfiltermmap&quot;&gt;pybloomfiltermmap&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update:&lt;/em&gt; Jeremy McLain &lt;a href=&quot;http://www.michaelnielsen.org/ddi/how-to-crawl-a-quarter-billion-webpages-in-40-hours/#comment-6379&quot;&gt;points out in comments&lt;/a&gt; that I’ve got this backward, and that with a Bloom filter there is a low probability “that you will never crawl certain URLs because your bloom filter is telling you they have already been crawled when in fact they have not.” A better (albeit slightly slower) solution would be to simply store all the URLs, and check directly.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Anticipated versus unanticipated errors:&lt;/strong&gt; Because the crawler ingests input from external sources, it needs to deal with many potential errors. By design, there are two broad classes of error: &lt;em&gt;anticipated errors&lt;/em&gt; and &lt;em&gt;unanticipated errors&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Anticipated errors are things like a page failing to download, or timing out, or containing unparseable input, or a &lt;tt&gt;robots.txt&lt;/tt&gt; file disallowing crawling of a page. When anticipated errors arise, the crawler writes the error to a (per-thread) informational log (the “info log” in the diagram above), and continues in whatever way is appropriate. For example, if the &lt;tt&gt;robots.txt&lt;/tt&gt; file disallows crawling then we simply continue to the next url in the url frontier.&lt;/p&gt;
&lt;p&gt;Unanticipated errors are errors which haven’t been anticipated and designed for. Rather than the crawler falling over, the crawler simply logs the error (to the “critical log” in the diagram above), and moves on to the next url in the url frontier. At the same time, the crawler tracks how many unanticipated errors have occurred in close succession. If many unanticipated errors occur in close succession it usually indicates that some key piece of infrastructure has failed. Because of this, if there are too many unanticipated errors in close succession, the crawler shuts down entirely.&lt;/p&gt;
&lt;p&gt;As I was developing and testing the crawler, I closely followed the unanticipated errors logged in the critical log. This enabled me to understand many of the problems faced by the crawler. For example, early on in development I found that sometimes the html for a page would be so badly formed that the html parser would have little choice but to raise an exception. As I came to understand such errors I would rewrite the crawler code so such errors become anticipated errors that were handled as gracefully as possible. Thus, the natural tendency during development was for unanticipated errors to become anticipated errors.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Domain and subdomain handling:&lt;/strong&gt; As mentioned above, the crawler works by doing lots of parallel intra-domain crawls. This works well, but a problem arises because of the widespread use of subdomains. For example, if we start at the seed url &lt;tt&gt;http://barclays.com&lt;/tt&gt; and crawl only urls within the &lt;tt&gt;barclays.com&lt;/tt&gt; domain, then we quickly run out of urls to crawl. The reason is that most of the internal links on the &lt;tt&gt;barclays.com&lt;/tt&gt; site are actually to &lt;tt&gt;group.barclays.com&lt;/tt&gt;, not &lt;tt&gt;barclays.com&lt;/tt&gt;. Our crawler should also add urls from the latter domain to the url frontier for &lt;tt&gt;barclays.com&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;We resolve this by stripping out all subdomains, and working with the stripped domains when deciding whether to add a url to the url frontier. Removing subdomains turns out to be a surprisingly hard problem, because of variations in the way domain names are formed. Fortunately, the problem seems to be well solved using &lt;a href=&quot;https://twitter.com/Bluu&quot;&gt;John Kurkowski’s&lt;/a&gt; &lt;a href=&quot;https://github.com/john-kurkowski/tldextract&quot;&gt;tldextract library&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;On the representation of the url frontier:&lt;/strong&gt; I noted above that a separate url frontier file was maintained for each domain. In an early version of the code, each crawler thread had a url frontier maintained as a &lt;em&gt;single&lt;/em&gt; flat text file. As a crawler thread read out lines in the file, it would crawl those urls, and append any new urls found to the end of the file.&lt;/p&gt;
&lt;p&gt;This approach seemed natural to me, but organizing the url frontier files on a per-thread (rather than per-domain) basis caused a surprising number of problems. As the crawler thread moved through the file to find the next url to crawl, the crawler thread would encounter urls belonging to domains that were not yet polite to crawl because they’d been crawled too recently. My initial strategy was simply to append such urls to the end of the file, so they would be found again later. Unfortunately, there were often a &lt;em&gt;lot&lt;/em&gt; of such urls in a row – consecutive urls often came from the same domain (since they’d been extracted from the same page). And so this strategy caused the file for the url frontier to grow very rapidly, eventually consuming most disk space.&lt;/p&gt;
&lt;p&gt;Exacerbating this problem, this approach to the url frontier caused an unforseen “domain clumping problem”. To understand this problem, imagine that the crawler thread encountered (say) 20 consecutive urls from a single domain. It might crawl the first of these, extracting (say) 20 extra urls to append to the end of the url frontier. But the next 19 urls would all be skipped over, since it wouldn’t yet be polite to crawl them, and they’d also be appended to the end of the url frontier. Now we have 39 urls from the same domain at the end of the url frontier. But when the crawler thread gets to those, we may well have the same process repeat – leading to a clump of 58 urls from the same domain at the end of the file. And so on, leading to very long runs of urls from the same domain. This consumes lots of disk space, and also slows down the crawler, since the crawler thread may need to examine a large number of urls before it finds a new url it’s okay to crawl.&lt;/p&gt;
&lt;p&gt;These problems could have been solved in various ways; moving to the per-domain url frontier file was how I chose to address the problems, and it seemed to work well.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Choice of number of threads:&lt;/strong&gt; I mentioned above that the number of crawler threads (141) was chosen empirically. However, there is an important constraint on that number, and in particular its relationship to the number (20) of EC2 instances being used. Suppose that instead of 141 threads I’d used (say) 60 threads. This would create a problem. To see why, note that any domain allocated to instance number 7 (say) would necessarily satisfy &lt;tt&gt;hash(domain) % 20 = 7&lt;/tt&gt;. This would imply that &lt;tt&gt;hash(domain) % 60 = 7&lt;/tt&gt; or 27 or 47, and as a consequence all the domains would be allocated to just one of three crawler threads (thread numbers 7, 27 and 47), while the other 57 crawler threads would lie idle, defeating the purpose of using multiple threads.&lt;/p&gt;
&lt;p&gt;One way to solve this problem would be to use two &lt;a href=&quot;http://en.wikipedia.org/wiki/K-independent_hashing&quot;&gt;independent&lt;/a&gt; hash functions to allocate domains to EC2 instances and crawler threads. However, an even simpler way of solving the problem is to choose the number of crawler threads to be coprime to the number of EC2 instances. This coprimality ensures that domains will be allocated reasonably evenly across both instance and threads. (I won’t prove this here, but it can be proved with a little effort). It is easily checked that 141 and 20 are coprime.&lt;/p&gt;
&lt;p&gt;Note, incidentally, that Python’s &lt;tt&gt;hash&lt;/tt&gt; is not a true hash function, in the sense that it doesn’t guarantee that the domains will be spread evenly across EC2 instances. It turns out that Python’s &lt;tt&gt;hash&lt;/tt&gt; takes similar key strings to similar hash values. I talk more about this point (with examples) in the fifth paragraph of &lt;a href=&quot;http://michaelnielsen.org/blog/consistent-hashing/&quot;&gt;this post&lt;/a&gt;. However, I found empirically that &lt;tt&gt;hash&lt;/tt&gt; seems to spread domains evenly enough across instances, and so I didn’t worry about using a better (but slower) hash function, like those available through Python’s &lt;tt&gt;hashlib&lt;/tt&gt; library.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Use of Python:&lt;/strong&gt; All my code was written in Python. Initially, I wondered if Python might be too slow, and create bottlenecks in the crawling. However, profiling the crawler showed that most time was spent either (a) managing network connections and downloading data; or (b) parsing the resulting webpages. The parsing of the webpages was being done using &lt;a href=&quot;http://lxml.de/&quot;&gt;lxml&lt;/a&gt;, a Python binding to fast underlying C libraries. It didn’t seem likely to be easy to speed that up, and so I concluded that Python was likely not a particular bottleneck in the crawling.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Politeness:&lt;/strong&gt; The crawler used Python’s &lt;a href=&quot;http://docs.python.org/library/robotparser.html&quot;&gt;robotparser library&lt;/a&gt; in order to observe the &lt;a href=&quot;http://www.robotstxt.org/&quot;&gt;robots exclusion protocol&lt;/a&gt;. As noted above, I also imposed an absolute 70-second minimum time interval between accesses to any given domain. In practice, the mean time between accesses was more like 3-4 minutes.&lt;/p&gt;
&lt;p&gt;In initial test runs of the crawler I got occasional emails from webmasters asking for an explanation of why I was crawling their site. Because of this, in the crawler’s &lt;a href=&quot;http://en.wikipedia.org/wiki/User_agent&quot;&gt;User-agent&lt;/a&gt; I included a link to a &lt;a href=&quot;http://michaelnielsen.org/blog/oss-bot/&quot;&gt;webpage&lt;/a&gt; explaining the purpose of my crawler, how to exclude it from a site, and what steps I was taking to crawl politely. This was (I presume) both helpful to webmasters and also helpful to me, for it reduced the number of inquiries. A handful of people asked me to exclude their sites from the crawl, and I complied quickly.&lt;/p&gt;
&lt;h3&gt;Problems for the author&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;Because my crawl didn’t take too long, the &lt;tt&gt;robots.txt&lt;/tt&gt; file was downloaded just once for each domain, at the beginning of the crawl. In a longer crawl, how should we decide how long to wait between downloads of &lt;tt&gt;robots.txt&lt;/tt&gt;?&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Truncation:&lt;/strong&gt; The crawler truncates large webpages rather than downloading the full page. It does this in part because it’s necessary – it really wouldn’t surprise me if someone has a terabyte html file sitting on a server somewhere – and in part because for many applications it will be of more interest to focus on earlier parts of the page.&lt;/p&gt;
&lt;p&gt;What’s a reasonable threshold for truncation? According to &lt;a href=&quot;http://code.google.com/speed/articles/web-metrics.html&quot;&gt;this report&lt;/a&gt; from Google, as of May 2010 the average network size of a webpage from a top site is 312.04 kb. However, that includes images, scripts and stylesheets, which the crawler ignores. If you ignore the images and so on, then the average network size drops to just 33.66 kb.&lt;/p&gt;
&lt;p&gt;However, that number of 33.66 kb is for content which may be served compressed over the network. Our truncation will be based on the uncompressed size. Unfortunately, the Google report doesn’t tell us what the average size of the uncompressed content is. However, we can get an estimate of this, since Google reports that the average uncompressed size of the &lt;em&gt;total&lt;/em&gt; page (including images and so on) is 477.26 kb, while the average network size is 312.04 kb.&lt;/p&gt;
&lt;p&gt;Assuming that this compression ratio is typical, we estimate that the average uncompressed size of the content the crawler downloads is 51 kb. In the event, I experimented with several truncation settings, and found that a truncation threshold of 200 kilobytes enabled me to download the great majority of webpages in their entirety, while addressing the problem of very large html files mentioned above. (Unfortunately, I didn’t think to check what the &lt;em&gt;actual&lt;/em&gt; average uncompressed size was, my mistake.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Storage:&lt;/strong&gt; I stored all the data using EC2’s built-in &lt;a href=&quot;http://docs.amazonwebservices.com/AWSEC2/latest/UserGuide/InstanceStorage.html&quot;&gt;instance storage&lt;/a&gt; – 1.69 Terabytes for the extra-large instances I was using. This storage is non-persistent, and so any data stored on an instance will vanish when that instance is terminated. Now, for many kinds of streaming or short-term analysis of data this would be adequate – indeed, it might not even be necessary to store the data at all. But, of course, for many applications of a crawl this approach is not appropriate, and the instance storage should be supplemented with something more permanent, such as S3. For my purposes using the instance storage seemed fine.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Price:&lt;/strong&gt; The price broke down into two components: (1) 512 dollars for the use of the 20 extra-large EC2 instances for 40 hours; and (2) about 65 dollars for a little over 500 gigabytes of outgoing bandwidth, used to make http requests. Note that Amazon does not charge for incoming bandwidth (a good thing, too!) It would be interesting to compare these costs to the (appropriately amortized) costs of using other cloud providers, or self-hosting.&lt;/p&gt;
&lt;p&gt;Something I didn’t experiment with is the use of Amazon’s &lt;a href=&quot;http://aws.amazon.com/ec2/spot-instances/&quot;&gt;spot instances&lt;/a&gt;, where you can bid to use Amazon’s unused EC2 capacity. I didn’t think of doing this until just as I was about to launch the crawl. When I went to look at the spot instance pricing history, I discovered to my surprise that the spot instance prices are often a factor of 10 or so lower than the prices for on-demand instances! Factoring in the charges for outgoing bandwidth, this means it may be possible to use spot instances to do a similar crawl for 120 dollars or so, a factor of five savings. I considered switching, but ultimately decided against it, thinking that it might take 2 or 3 days work to properly understand the implications of switching, and to get things working exactly as I wanted. Admittedly, it’s possible that it would have taken much less time, in which case I missed an opportunity to trade some money for just a little extra time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Improvements to the crawler architecture:&lt;/strong&gt; Let me finish by noting a few ways it’d be interesting to improve the current crawler:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;For many long-running applications the crawler would need a smart crawl policy so that it knows when and how to re-crawl a page. According to a &lt;a href=&quot;http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//people/jeff/WSDM09-keynote.pdf&quot;&gt;presentation&lt;/a&gt; from &lt;a href=&quot;http://research.google.com/people/jeff/&quot;&gt;Jeff Dean&lt;/a&gt;, Google’s mean time to index a new page is now just minutes. I don’t know how that works, but imagine that notification protocols such as &lt;a href=&quot;http://code.google.com/p/pubsubhubbub/&quot;&gt;pubsubhubbub&lt;/a&gt; play an important role. It’d be good to change the crawler so that it’s pubsubhubbub aware.&lt;/li&gt;
&lt;li&gt;The crawler currently uses a threaded architecture. Another quite different approach is to use an &lt;a href=&quot;http://www.google.com/#sclient=psy-ab&amp;amp;hl=en&amp;amp;site=&amp;amp;source=hp&amp;amp;q=event-driven+crawler&amp;amp;fp=1&quot;&gt;evented architecture&lt;/a&gt;. What are the pros and cons of a multi-threaded versus an evented architecture?&lt;/li&gt;
&lt;li&gt;The instances in the cluster are configured using fabric and shell scripts to install programs such as redis, pybloomfilter, and so on. This is slow and not completely reliable. Is there a better way of doing this? Creating my own EC2 AMI? Configuration management software such as &lt;a href=&quot;http://www.opscode.com/chef/&quot;&gt;Chef&lt;/a&gt; and &lt;a href=&quot;http://puppetlabs.com/&quot;&gt;Puppet&lt;/a&gt;? I considered using one of the latter, but deferred it because of the upfront cost of learning the systems.&lt;/li&gt;
&lt;li&gt;Logging is currently done using Python’s &lt;tt&gt;logging&lt;/tt&gt; module. Unfortunately, I’m finding this is not well-adapted to Python’s threading. Is there a better solution?&lt;/li&gt;
&lt;li&gt;The crawler was initially designed for crawling in a batch environment, where it is run and then terminates. I’ve since modified it so that it can be stopped, modifications made, and restarted. It’d be good to add instrumentation so it can be modified more dynamically, in real time.&lt;/li&gt;
&lt;li&gt;Many interesting research papers have been published about crawling. I read or skimmed quite a few while writing my crawler, but ultimately used only a few of the ideas; just getting the basics right proved challenging enough. In future iterations it’d be useful to look at this work again and to incorporate the best ideas. Good starting points include a &lt;a href=&quot;http://nlp.stanford.edu/IR-book/html/htmledition/web-crawling-and-indexes-1.html&quot;&gt;chapter&lt;/a&gt; in the book by Manning, Raghavan and Sch\”utze, and a &lt;a href=&quot;http://infolab.stanford.edu/~olston/publications/crawling_survey.pdf&quot;&gt;survey paper&lt;/a&gt; by Olston and Najork. Existing open source crawlers such as &lt;a href=&quot;https://webarchive.jira.com/wiki/display/Heritrix/Heritrix&quot;&gt;Heritrix&lt;/a&gt; and &lt;a href=&quot;http://nutch.apache.org/&quot;&gt;Nutch&lt;/a&gt; would also be interesting to look at in more depth.&lt;/li&gt;
&lt;/ul&gt;</description>
<pubDate>Thu, 05 Jul 2018 03:51:31 +0000</pubDate>
<dc:creator>allenleein</dc:creator>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.michaelnielsen.org/ddi/how-to-crawl-a-quarter-billion-webpages-in-40-hours/</dc:identifier>
</item>
<item>
<title>Draw This: a polaroid camera that draws cartoons</title>
<link>http://danmacnish.com/2018/07/01/draw-this/</link>
<guid isPermaLink="true" >http://danmacnish.com/2018/07/01/draw-this/</guid>
<description>&lt;p&gt;&lt;img class=&quot;aligncenter size-large wp-image-172&quot; src=&quot;http://danmacnish.com/wp-content/uploads/2018/07/raspi-camera-cartoons-1024x644.jpg&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;377&quot; srcset=&quot;http://danmacnish.com/wp-content/uploads/2018/07/raspi-camera-cartoons-1024x644.jpg 1024w, http://danmacnish.com/wp-content/uploads/2018/07/raspi-camera-cartoons-300x189.jpg 300w, http://danmacnish.com/wp-content/uploads/2018/07/raspi-camera-cartoons-768x483.jpg 768w, http://danmacnish.com/wp-content/uploads/2018/07/raspi-camera-cartoons-1240x780.jpg 1240w, http://danmacnish.com/wp-content/uploads/2018/07/raspi-camera-cartoons-508x319.jpg 508w&quot; sizes=&quot;(max-width: 600px) 100vw, 600px&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Draw This&lt;/em&gt; is a polaroid camera that draws cartoons.&lt;/p&gt;
&lt;p&gt;The polaroid camera is a classic that still delights today. There is something eternally amusing about a physical, unique image, that is uniquely different to digital. Playing with neural networks for object recognition one day, I wondered if I could take the concept of a polaroid one step further, and ask the camera to re-interpret the image, printing out a cartoon instead of a faithful photograph.&lt;/p&gt;

&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;One of the fun things about this re-imagined polaroid is that you never get to see the original image. You point, and shoot – and out pops a cartoon; the camera’s best interpretation of what it saw. The result is always a surprise. A food selfie of a healthy salad might turn into a enormous hotdog, or a photo with friends might be photobombed by a goat.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter size-large wp-image-175&quot; src=&quot;http://danmacnish.com/wp-content/uploads/2018/07/back-of-cam2-1024x1005.jpg&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;589&quot; srcset=&quot;http://danmacnish.com/wp-content/uploads/2018/07/back-of-cam2-1024x1005.jpg 1024w, http://danmacnish.com/wp-content/uploads/2018/07/back-of-cam2-300x294.jpg 300w, http://danmacnish.com/wp-content/uploads/2018/07/back-of-cam2-768x754.jpg 768w, http://danmacnish.com/wp-content/uploads/2018/07/back-of-cam2-1240x1217.jpg 1240w, http://danmacnish.com/wp-content/uploads/2018/07/back-of-cam2-508x499.jpg 508w&quot; sizes=&quot;(max-width: 600px) 100vw, 600px&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter size-large wp-image-173&quot; src=&quot;http://danmacnish.com/wp-content/uploads/2018/07/front-with-cartoons-967x1024.jpg&quot; alt=&quot;&quot; width=&quot;600&quot; height=&quot;635&quot; srcset=&quot;http://danmacnish.com/wp-content/uploads/2018/07/front-with-cartoons-967x1024.jpg 967w, http://danmacnish.com/wp-content/uploads/2018/07/front-with-cartoons-283x300.jpg 283w, http://danmacnish.com/wp-content/uploads/2018/07/front-with-cartoons-768x813.jpg 768w, http://danmacnish.com/wp-content/uploads/2018/07/front-with-cartoons-1240x1313.jpg 1240w, http://danmacnish.com/wp-content/uploads/2018/07/front-with-cartoons-508x538.jpg 508w, http://danmacnish.com/wp-content/uploads/2018/07/front-with-cartoons.jpg 1518w&quot; sizes=&quot;(max-width: 600px) 100vw, 600px&quot;/&gt;&lt;/p&gt;
&lt;p&gt;The camera is a mash up of a neural network for object recognition, the google quickdraw dataset, a thermal printer, and a raspberry pi. Initially, I began with some experiments on my laptop. I set up an image processing pipeline in python to take pre-captured images and recognise the objects in them, &lt;a href=&quot;https://ai.googleblog.com/2017/06/supercharge-your-computer-vision-models.html&quot;&gt;using pre-trained models from google&lt;/a&gt;. At the same time, I explored &lt;a href=&quot;https://github.com/googlecreativelab/quickdraw-dataset&quot;&gt;the quickdraw dataset&lt;/a&gt;, and mapped the categories available in the dataset with the categories recognisable by the image processor. After writing some code to patch the two together, wrapping the lot in a docker image, and cobbling together some electronics, interspersed with some hair pulling moments of frustration, the camera was ready.&lt;/p&gt;
&lt;p&gt;The outcome was a really fun way to get in to creative applications for neural networks. If you would like to make your own &lt;a href=&quot;https://github.com/danmacnish/cartoonify&quot;&gt;you can find code + instructions on github&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>Thu, 05 Jul 2018 03:12:39 +0000</pubDate>
<dc:creator>neuhaus</dc:creator>
<dc:language>en-AU</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://danmacnish.com/2018/07/01/draw-this/</dc:identifier>
</item>
<item>
<title>FWD:Everyone</title>
<link>https://fwdeveryone.com/</link>
<guid isPermaLink="true" >https://fwdeveryone.com/</guid>
<description>[unable to retrieve full-text content]&lt;p&gt;Article URL: &lt;a href=&quot;https://fwdeveryone.com/&quot;&gt;https://fwdeveryone.com/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Comments URL: &lt;a href=&quot;https://news.ycombinator.com/item?id=17460519&quot;&gt;https://news.ycombinator.com/item?id=17460519&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Points: 208&lt;/p&gt;&lt;p&gt;# Comments: 129&lt;/p&gt;</description>
<pubDate>Thu, 05 Jul 2018 02:25:21 +0000</pubDate>
<dc:creator>petethomas</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://fwdeveryone.com/</dc:identifier>
</item>
</channel>
</rss>