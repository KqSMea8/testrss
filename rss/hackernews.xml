<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=hnrss.org%2Fnewest%3Fpoints%3D200&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://hnrss.org/newest?points=200" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dhnrss.org%252Fnewest%253Fpoints%253D200%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>Hacker News: Newest</title>
<link>https://news.ycombinator.com/newest</link>
<description>Hacker News RSS</description>
<item>
<title>Why Google Stores Billions of Lines of Code in a Single Repository (2016)</title>
<link>https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext</link>
<guid isPermaLink="true" >https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext</guid>
<description>&lt;p&gt;&lt;span class=&quot;label&quot;&gt;Contributed articles&lt;/span&gt;


&lt;/p&gt;&lt;div id=&quot;articleFullText&quot; readability=&quot;764.16455740538&quot;&gt;&lt;span class=&quot;byline&quot;&gt;By Rachel Potvin, Josh Levenberg&lt;br/&gt;Communications of the ACM, July 2016, Vol. 59 No. 7, Pages 78-87&lt;br/&gt;10.1145/2854146&lt;br/&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#comments&quot;&gt;Comments (3)&lt;/a&gt;&lt;/span&gt;


&lt;div class=&quot;imageWithCaptionLeft&quot; id=&quot;asset-24065&quot; readability=&quot;7&quot;&gt;&lt;img alt=&quot;Why Google Stores Billions of Lines of Code in a Single Repository, illustration&quot; src=&quot;https://cacm.acm.org/system/assets/0002/4065/062016_CACMpg79_Why-Google.large.jpg?1476779499&amp;amp;1466529917&quot; title=&quot;Why Google Stores Billions of Lines of Code in a Single Repository, illustration&quot;/&gt;&lt;p class=&quot;credit&quot;&gt;Credit: Iwona Usakiewicz / Andrij Borys Associates&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Early Google employees decided to work with a shared codebase managed through a centralized source control system. This approach has served Google well for more than 16 years, and today the vast majority of Google's software assets continues to be stored in a single, shared repository. Meanwhile, the number of Google software developers has steadily increased, and the size of the Google codebase has grown exponentially (see &lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#F1&quot;&gt;Figure 1&lt;/a&gt;). As a result, the technology used to host the codebase has also evolved significantly.&lt;/p&gt;
&lt;p class=&quot;totop&quot;&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#PageTop&quot;&gt;Back to Top&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Key Insights&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/ins01.gif&quot; border=&quot;0&quot; vspace=&quot;5&quot; hspace=&quot;5&quot; alt=&quot;ins01.gif&quot;/&gt;&lt;/p&gt;
&lt;p&gt;This article outlines the scale of that codebase and details Google's custom-built monolithic source repository and the reasons the model was chosen. Google uses a homegrown version-control system to host one large codebase visible to, and used by, most of the software developers in the company. This centralized system is the foundation of many of Google's developer workflows. Here, we provide background on the systems and workflows that make feasible managing and working productively with such a large repository. We explain Google's &quot;trunk-based development&quot; strategy and the support systems that structure workflow and keep Google's codebase healthy, including software for static analysis, code cleanup, and streamlined code review.&lt;/p&gt;
&lt;p class=&quot;totop&quot;&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#PageTop&quot;&gt;Back to Top&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Google-Scale&lt;/h3&gt;
&lt;p&gt;Google's monolithic software repository, which is used by 95% of its software developers worldwide, meets the definition of an ultra-large-scale&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#R4&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; system, providing evidence the single-source repository model can be scaled successfully.&lt;/p&gt;
&lt;p&gt;The Google codebase includes approximately one billion files and has a history of approximately 35 million commits spanning Google's entire 18-year existence. The repository contains 86TB&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#FNA&quot;&gt;a&lt;/a&gt;&lt;/sup&gt; of data, including approximately two billion lines of code in nine million unique source files. The total number of files also includes source files copied into release branches, files that are deleted at the latest revision, configuration files, documentation, and supporting data files; see the table here for a summary of Google's repository statistics from January 2015.&lt;/p&gt;
&lt;p&gt;In 2014, approximately 15 million lines of code were changed&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#FNB&quot;&gt;b&lt;/a&gt;&lt;/sup&gt; in approximately 250,000 files in the Google repository on a weekly basis. The Linux kernel is a prominent example of a large open source software repository containing approximately 15 million lines of code in 40,000 files.&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#R14&quot;&gt;14&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Google's codebase is shared by more than 25,000 Google software developers from dozens of offices in countries around the world. On a typical workday, they commit 16,000 changes to the codebase, and another 24,000 changes are committed by automated systems. Each day the repository serves billions of file read requests, with approximately 800,000 queries per second during peak traffic and an average of approximately 500,000 queries per second each workday. Most of this traffic originates from Google's distributed build-and-test systems.&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#FNC&quot;&gt;c&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#F2&quot;&gt;Figure 2&lt;/a&gt; reports the number of unique human committers per week to the main repository, January 2010-July 2015. &lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#F3&quot;&gt;Figure 3&lt;/a&gt; reports commits per week to Google's main repository over the same time period. The line for total commits includes data for both the interactive use case, or human users, and automated use cases. Larger dips in both graphs occur during holidays affecting a significant number of employees (such as Christmas Day and New Year's Day, American Thanksgiving Day, and American Independence Day).&lt;/p&gt;
&lt;p&gt;In October 2012, Google's central repository added support for Windows and Mac users (until then it was Linux-only), and the existing Windows and Mac repository was merged with the main repository. Google's tooling for repository merges attributes all historical changes being merged to their original authors, hence the corresponding bump in the graph in &lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#F2&quot;&gt;Figure 2&lt;/a&gt;. The effect of this merge is also apparent in &lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#F1&quot;&gt;Figure 1&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The commits-per-week graph shows the commit rate was dominated by human users until 2012, at which point Google switched to a custom-source-control implementation for hosting the central repository, as discussed later. Following this transition, automated commits to the repository began to increase. Growth in the commit rate continues primarily due to automation.&lt;/p&gt;
&lt;p&gt;Managing this scale of repository and activity on it has been an ongoing challenge for Google. Despite several years of experimentation, Google was not able to find a commercially available or open source version-control system to support such scale in a single repository. The Google proprietary system that was built to store, version, and vend this codebase is code-named Piper.&lt;/p&gt;
&lt;p class=&quot;totop&quot;&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#PageTop&quot;&gt;Back to Top&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Background&lt;/h3&gt;
&lt;p&gt;Before reviewing the advantages and disadvantages of working with a monolithic repository, some background on Google's tooling and workflows is needed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Piper and CitC&lt;/strong&gt;. Piper stores a single large repository and is implemented on top of standard Google infrastructure, originally Bigtable,&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#R2&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; now Spanner.&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#R3&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; Piper is distributed over 10 Google data centers around the world, relying on the Paxos&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#R6&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; algorithm to guarantee consistency across replicas. This architecture provides a high level of redundancy and helps optimize latency for Google software developers, no matter where they work. In addition, caching and asynchronous operations hide much of the network latency from developers. This is important because gaining the full benefit of Google's cloud-based toolchain requires developers to be online.&lt;/p&gt;
&lt;p&gt;Google relied on one primary Perforce instance, hosted on a single machine, coupled with custom caching infrastructure&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#R1&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; for more than 10 years prior to the launch of Piper. Continued scaling of the Google repository was the main motivation for developing Piper.&lt;/p&gt;
&lt;p&gt;Since Google's source code is one of the company's most important assets, security features are a key consideration in Piper's design. Piper supports file-level access control lists. Most of the repository is visible to all Piper users;&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#FND&quot;&gt;d&lt;/a&gt;&lt;/sup&gt; however, important configuration files or files including business-critical algorithms can be more tightly controlled. In addition, read and write access to files in Piper is logged. If sensitive data is accidentally committed to Piper, the file in question can be purged. The read logs allow administrators to determine if anyone accessed the problematic file before it was removed.&lt;/p&gt;
&lt;p&gt;In the Piper workflow (see &lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#F4&quot;&gt;Figure 4&lt;/a&gt;), developers create a local copy of files in the repository before changing them. These files are stored in a workspace owned by the developer. A Piper workspace is comparable to a working copy in Apache Subversion, a local clone in Git, or a client in Perforce. Updates from the Piper repository can be pulled into a workspace and merged with ongoing work, as desired (see &lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#F5&quot;&gt;Figure 5&lt;/a&gt;). A snapshot of the workspace can be shared with other developers for review. Files in a workspace are committed to the central repository only after going through the Google code-review process, as described later.&lt;/p&gt;
&lt;p&gt;Most developers access Piper through a system called Clients in the Cloud, or CitC, which consists of a cloud-based storage backend and a Linux-only FUSE&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#R13&quot;&gt;13&lt;/a&gt;&lt;/sup&gt; file system. Developers see their workspaces as directories in the file system, including their changes overlaid on top of the full Piper repository. CitC supports code browsing and normal Unix tools with no need to clone or sync state locally. Developers can browse and edit files anywhere across the Piper repository, and only modified files are stored in their workspace. This structure means CitC workspaces typically consume only a small amount of storage (an average workspace has fewer than 10 files) while presenting a seamless view of the entire Piper codebase to the developer.&lt;/p&gt;
&lt;p&gt;All writes to files are stored as snapshots in CitC, making it possible to recover previous stages of work as needed. Snapshots may be explicitly named, restored, or tagged for review.&lt;/p&gt;
&lt;p&gt;CitC workspaces are available on any machine that can connect to the cloud-based storage system, making it easy to switch machines and pick up work without interruption. It also makes it possible for developers to view each other's work in CitC workspaces. Storing all in-progress work in the cloud is an important element of the Google workflow process. Working state is thus available to other tools, including the cloud-based build system, the automated test infrastructure, and the code browsing, editing, and review tools.&lt;/p&gt;
&lt;p&gt;Several workflows take advantage of the availability of uncommitted code in CitC to make software developers working with the large codebase more productive. For instance, when sending a change out for code review, developers can enable an auto-commit option, which is particularly useful when code authors and reviewers are in different time zones. When the review is marked as complete, the tests will run; if they pass, the code will be committed to the repository without further human intervention. The Google code-browsing tool CodeSearch supports simple edits using CitC workspaces. While browsing the repository, developers can click on a button to enter edit mode and make a simple change (such as fixing a typo or improving a comment). Then, without leaving the code browser, they can send their changes out to the appropriate reviewers with auto-commit enabled.&lt;/p&gt;
&lt;p&gt;Piper can also be used without CitC. Developers can instead store Piper workspaces on their local machines. Piper also has limited interoperability with Git. Over 80% of Piper users today use CitC, with adoption continuing to grow due to the many benefits provided by CitC.&lt;/p&gt;
&lt;p&gt;Piper and CitC make working productively with a single, monolithic source repository possible at the scale of the Google codebase. The design and architecture of these systems were both heavily influenced by the trunk-based development paradigm employed at Google, as described here.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Trunk-based development&lt;/strong&gt;. Google practices trunk-based development on top of the Piper source repository. The vast majority of Piper users work at the &quot;head,&quot; or most recent, version of a single copy of the code called &quot;trunk&quot; or &quot;mainline.&quot; Changes are made to the repository in a single, serial ordering. The combination of trunk-based development with a central repository defines the monolithic codebase model. Immediately after any commit, the new code is visible to, and usable by, all other developers. The fact that Piper users work on a single consistent view of the Google codebase is key for providing the advantages described later in this article.&lt;/p&gt;
&lt;p&gt;Trunk-based development is beneficial in part because it avoids the painful merges that often occur when it is time to reconcile long-lived branches. Development on branches is unusual and not well supported at Google, though branches are typically used for releases. Release branches are cut from a specific revision of the repository. Bug fixes and enhancements that must be added to a release are typically developed on mainline, then cherry-picked into the release branch (see &lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#F6&quot;&gt;Figure 6&lt;/a&gt;). Due to the need to maintain stability and limit churn on the release branch, a release is typically a snapshot of head, with an optional small number of cherry-picks pulled in from head as needed. Use of long-lived branches with parallel development on the branch and mainline is exceedingly rare.&lt;/p&gt;
&lt;hr align=&quot;center&quot; width=&quot;50%&quot;/&gt;&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p align=&quot;center&quot;&gt;&lt;em&gt;Piper and CitC make working productively with a single, monolithic source repository possible at the scale of the Google codebase.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr align=&quot;center&quot; width=&quot;50%&quot;/&gt;&lt;p&gt;When new features are developed, both new and old code paths commonly exist simultaneously, controlled through the use of conditional flags. This technique avoids the need for a development branch and makes it easy to turn on and off features through configuration updates rather than full binary releases. While some additional complexity is incurred for developers, the merge problems of a development branch are avoided. Flag flips make it much easier and faster to switch users off new implementations that have problems. This method is typically used in project-specific code, not common library code, and eventually flags are retired so old code can be deleted. Google uses a similar approach for routing live traffic through different code paths to perform experiments that can be tuned in real time through configuration changes. Such A/B experiments can measure everything from the performance characteristics of the code to user engagement related to subtle product changes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Google workflow&lt;/strong&gt;. Several best practices and supporting systems are required to avoid constant breakage in the trunk-based development model, where thousands of engineers commit thousands of changes to the repository on a daily basis. For instance, Google has an automated testing infrastructure that initiates a rebuild of all affected dependencies on almost every change committed to the repository. If a change creates widespread build breakage, a system is in place to automatically undo the change. To reduce the incidence of bad code being committed in the first place, the highly customizable Google &quot;presubmit&quot; infrastructure provides automated testing and analysis of changes before they are added to the codebase. A set of global presubmit analyses are run for all changes, and code owners can create custom analyses that run only on directories within the codebase they specify. A small set of very low-level core libraries uses a mechanism similar to a development branch to enforce additional testing before new versions are exposed to client code.&lt;/p&gt;
&lt;p&gt;An important aspect of Google culture that encourages code quality is the expectation that all code is reviewed before being committed to the repository. Most developers can view and propose changes to files anywhere across the entire codebase—with the exception of a small set of highly confidential code that is more carefully controlled. The risk associated with developers changing code they are not deeply familiar with is mitigated through the code-review process and the concept of code ownership. The Google codebase is laid out in a tree structure. Each and every directory has a set of owners who control whether a change to files in their directory will be accepted. Owners are typically the developers who work on the projects in the directories in question. A change often receives a detailed code review from one developer, evaluating the quality of the change, and a commit approval from an owner, evaluating the appropriateness of the change to their area of the codebase.&lt;/p&gt;
&lt;p&gt;Code reviewers comment on aspects of code quality, including design, functionality, complexity, testing, naming, comment quality, and code style, as documented by the various language-specific Google style guides.&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#FNE&quot;&gt;e&lt;/a&gt;&lt;/sup&gt; Google has written a code-review tool called Critique that allows the reviewer to view the evolution of the code and comment on any line of the change. It encourages further revisions and a conversation leading to a final &quot;Looks Good To Me&quot; from the reviewer, indicating the review is complete.&lt;/p&gt;
&lt;p&gt;Google's static analysis system (Tricorder&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#R10&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;) and presubmit infrastructure also provide data on code quality, test coverage, and test results automatically in the Google code-review tool. These computationally intensive checks are triggered periodically, as well as when a code change is sent for review. Tricorder also provides suggested fixes with one-click code editing for many errors. These systems provide important data to increase the effectiveness of code reviews and keep the Google codebase healthy.&lt;/p&gt;
&lt;p&gt;A team of Google developers will occasionally undertake a set of wide-reaching code-cleanup changes to further maintain the health of the codebase. The developers who perform these changes commonly separate them into two phases. With this approach, a large backward-compatible change is made first. Once it is complete, a second smaller change can be made to remove the original pattern that is no longer referenced. A Google tool called Rosie&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#FNF&quot;&gt;f&lt;/a&gt;&lt;/sup&gt; supports the first phase of such large-scale cleanups and code changes. With Rosie, developers create a large patch, either through a find-and-replace operation across the entire repository or through more complex refactoring tools. Rosie then takes care of splitting the large patch into smaller patches, testing them independently, sending them out for code review, and committing them automatically once they pass tests and a code review. Rosie splits patches along project directory lines, relying on the code-ownership hierarchy described earlier to send patches to the appropriate reviewers.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#F7&quot;&gt;Figure 7&lt;/a&gt; reports the number of changes committed through Rosie on a monthly basis, demonstrating the importance of Rosie as a tool for performing large-scale code changes at Google. Using Rosie is balanced against the cost incurred by teams needing to review the ongoing stream of simple changes Rosie generates. As Rosie's popularity and usage grew, it became clear some control had to be established to limit Rosie's use to high-value changes that would be distributed to many reviewers, rather than to single atomic changes or rejected. In 2013, Google adopted a formal large-scale change-review process that led to a decrease in the number of commits through Rosie from 2013 to 2014. In evaluating a Rosie change, the review committee balances the benefit of the change against the costs of reviewer time and repository churn. We later examine this and similar trade-offs more closely.&lt;/p&gt;
&lt;p&gt;In sum, Google has developed a number of practices and tools to support its enormous monolithic codebase, including trunk-based development, the distributed source-code repository Piper, the workspace client CitC, and workflow-support-tools Critique, CodeSearch, Tricorder, and Rosie. We discuss the pros and cons of this model here.&lt;/p&gt;
&lt;p class=&quot;totop&quot;&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#PageTop&quot;&gt;Back to Top&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Analysis&lt;/h3&gt;
&lt;p&gt;This section outlines and expands upon both the advantages of a monolithic codebase and the costs related to maintaining such a model at scale.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Advantages&lt;/strong&gt;. Supporting the ultra-large-scale of Google's codebase while maintaining good performance for tens of thousands of users is a challenge, but Google has embraced the monolithic model due to its compelling advantages.&lt;/p&gt;
&lt;p&gt;Most important, it supports:&lt;/p&gt;
&lt;ul class=&quot;acm&quot;&gt;&lt;li&gt;Unified versioning, one source of truth;&lt;/li&gt;
&lt;li&gt;Extensive code sharing and reuse;&lt;/li&gt;
&lt;li&gt;Simplified dependency management;&lt;/li&gt;
&lt;li&gt;Atomic changes;&lt;/li&gt;
&lt;li&gt;Large-scale refactoring;&lt;/li&gt;
&lt;li&gt;Collaboration across teams;&lt;/li&gt;
&lt;li&gt;Flexible team boundaries and code ownership; and&lt;/li&gt;
&lt;li&gt;Code visibility and clear tree structure providing implicit team namespacing.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;A single repository provides unified versioning and a single source of truth. There is no confusion about which repository hosts the authoritative version of a file. If one team wants to depend on another team's code, it can depend on it directly. The Google codebase includes a wealth of useful libraries, and the monolithic repository leads to extensive code sharing and reuse.&lt;/p&gt;
&lt;p&gt;The Google build system&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#R5&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; makes it easy to include code across directories, simplifying dependency management. Changes to the dependencies of a project trigger a rebuild of the dependent code. Since all code is versioned in the same repository, there is only ever one version of the truth, and no concern about independent versioning of dependencies.&lt;/p&gt;
&lt;p&gt;Most notably, the model allows Google to avoid the &quot;diamond dependency&quot; problem (see &lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#F8&quot;&gt;Figure 8&lt;/a&gt;) that occurs when A depends on B and C, both B and C depend on D, but B requires version D.1 and C requires version D.2. In most cases it is now impossible to build A. For the base library D, it can become very difficult to release a new version without causing breakage, since all its callers must be updated at the same time. Updating is difficult when the library callers are hosted in different repositories.&lt;/p&gt;
&lt;p&gt;In the open source world, dependencies are commonly broken by library updates, and finding library versions that all work together can be a challenge. Updating the versions of dependencies can be painful for developers, and delays in updating create technical debt that can become very expensive. In contrast, with a monolithic source tree it makes sense, and is easier, for the person updating a library to update all affected dependencies at the same time. The technical debt incurred by dependent systems is paid down immediately as changes are made. Changes to base libraries are instantly propagated through the dependency chain into the final products that rely on the libraries, without requiring a separate sync or migration step.&lt;/p&gt;
&lt;p&gt;Note the diamond-dependency problem can exist at the source/API level, as described here, as well as between binaries.&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#R12&quot;&gt;12&lt;/a&gt;&lt;/sup&gt; At Google, the binary problem is avoided through use of static linking.&lt;/p&gt;
&lt;p&gt;The ability to make atomic changes is also a very powerful feature of the monolithic model. A developer can make a major change touching hundreds or thousands of files across the repository in a single consistent operation. For instance, a developer can rename a class or function in a single commit and yet not break any builds or tests.&lt;/p&gt;
&lt;p&gt;The availability of all source code in a single repository, or at least on a centralized server, makes it easier for the maintainers of core libraries to perform testing and performance benchmarking for high-impact changes before they are committed. This approach is useful for exploring and measuring the value of highly disruptive changes. One concrete example is an experiment to evaluate the feasibility of converting Google data centers to support non-x86 machine architectures.&lt;/p&gt;
&lt;p&gt;With the monolithic structure of the Google repository, a developer never has to decide where the repository boundaries lie. Engineers never need to &quot;fork&quot; the development of a shared library or merge across repositories to update copied versions of code. Team boundaries are fluid. When project ownership changes or plans are made to consolidate systems, all code is already in the same repository. This environment makes it easy to do gradual refactoring and reorganization of the codebase. The change to move a project and update all dependencies can be applied atomically to the repository, and the development history of the affected code remains intact and available.&lt;/p&gt;
&lt;p&gt;Another attribute of a monolithic repository is the layout of the codebase is easily understood, as it is organized in a single tree. Each team has a directory structure within the main tree that effectively serves as a project's own namespace. Each source file can be uniquely identified by a single string—a file path that optionally includes a revision number. Browsing the codebase, it is easy to understand how any source file fits into the big picture of the repository.&lt;/p&gt;
&lt;p&gt;The Google codebase is constantly evolving. More complex codebase modernization efforts (such as updating it to C++11 or rolling out performance optimizations&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#R9&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;) are often managed centrally by dedicated codebase maintainers. Such efforts can touch half a million variable declarations or function-call sites spread across hundreds of thousands of files of source code. Because all projects are centrally stored, teams of specialists can do this work for the entire company, rather than require many individuals to develop their own tools, techniques, or expertise.&lt;/p&gt;
&lt;p&gt;As an example of how these benefits play out, consider Google's Compiler team, which ensures developers at Google employ the most up-to-date toolchains and benefit from the latest improvements in generated code and &quot;debuggability.&quot; The monolithic repository provides the team with full visibility of how various languages are used at Google and allows them to do codebase-wide cleanups to prevent changes from breaking builds or creating issues for developers. This greatly simplifies compiler validation, thus reducing compiler release cycles and making it possible for Google to safely do regular compiler releases (typically more than 20 per year for the C++ compilers).&lt;/p&gt;
&lt;p&gt;Using the data generated by performance and regression tests run on nightly builds of the entire Google codebase, the Compiler team tunes default compiler settings to be optimal. For example, due to this centralized effort, Google's Java developers all saw their garbage collection (GC) CPU consumption decrease by more than 50% and their GC pause time decrease by 10%–40% from 2014 to 2015. In addition, when software errors are discovered, it is often possible for the team to add new warnings to prevent reoccurrence. In conjunction with this change, they scan the entire repository to find and fix other instances of the software issue being addressed, before turning to new compiler errors. Having the compiler-reject patterns that proved problematic in the past is a significant boost to Google's overall code health.&lt;/p&gt;
&lt;p&gt;Storing all source code in a common version-control repository allows codebase maintainers to efficiently analyze and change Google's source code. Tools like Refaster&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#R11&quot;&gt;11&lt;/a&gt;&lt;/sup&gt; and ClangMR&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#R15&quot;&gt;15&lt;/a&gt;&lt;/sup&gt; (often used in conjunction with Rosie) make use of the monolithic view of Google's source to perform high-level transformations of source code. The monolithic codebase captures all dependency information. Old APIs can be removed with confidence, because it can be proven that all callers have been migrated to new APIs. A single common repository vastly simplifies these tools by ensuring atomicity of changes and a single global view of the entire repository at any given time.&lt;/p&gt;
&lt;hr align=&quot;center&quot; width=&quot;50%&quot;/&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p align=&quot;center&quot;&gt;&lt;em&gt;An important aspect of Google culture that encourages code quality is the expectation that all code is reviewed before being committed to the repository.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr align=&quot;center&quot; width=&quot;50%&quot;/&gt;&lt;p&gt;&lt;strong&gt;Costs and trade-offs&lt;/strong&gt;. While important to note a monolithic codebase in no way implies monolithic software design, working with this model involves some downsides, as well as trade-offs, that must be considered.&lt;/p&gt;
&lt;p&gt;These costs and trade-offs fall into three categories:&lt;/p&gt;
&lt;ul class=&quot;acm&quot;&gt;&lt;li&gt;Tooling investments for both development and execution;&lt;/li&gt;
&lt;li&gt;Codebase complexity, including unnecessary dependencies and difficulties with code discovery; and&lt;/li&gt;
&lt;li&gt;Effort invested in code health.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;In many ways the monolithic repository yields simpler tooling since there is only one system of reference for tools working with source. However, it is also necessary that tooling scale to the size of the repository. For instance, Google has written a custom plug-in for the Eclipse integrated development environment (IDE) to make working with a massive codebase possible from the IDE. Google's code-indexing system supports static analysis, cross-referencing in the code-browsing tool, and rich IDE functionality for Emacs, Vim, and other development environments. These tools require ongoing investment to manage the ever-increasing scale of the Google codebase.&lt;/p&gt;
&lt;p&gt;Beyond the investment in building and maintaining scalable tooling, Google must also cover the cost of running these systems, some of which are very computationally intensive. Much of Google's internal suite of developer tools, including the automated test infrastructure and highly scalable build infrastructure, are critical for supporting the size of the monolithic codebase. It is thus necessary to make trade-offs concerning how frequently to run this tooling to balance the cost of execution vs. the benefit of the data provided to developers.&lt;/p&gt;
&lt;p&gt;The monolithic model makes it easier to understand the structure of the codebase, as there is no crossing of repository boundaries between dependencies. However, as the scale increases, code discovery can become more difficult, as standard tools like &lt;code&gt;grep&lt;/code&gt; bog down. Developers must be able to explore the codebase, find relevant libraries, and see how to use them and who wrote them. Library authors often need to see how their APIs are being used. This requires a significant investment in code search and browsing tools. However, Google has found this investment highly rewarding, improving the productivity of all developers, as described in more detail by Sadowski et al.&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#R9&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Access to the whole codebase encourages extensive code sharing and reuse. Some would argue this model, which relies on the extreme scalability of the Google build system, makes it too easy to add dependencies and reduces the incentive for software developers to produce stable and well-thought-out APIs.&lt;/p&gt;
&lt;p&gt;Due to the ease of creating dependencies, it is common for teams to not think about their dependency graph, making code cleanup more error-prone. Unnecessary dependencies can increase project exposure to downstream build breakages, lead to binary size bloating, and create additional work in building and testing. In addition, lost productivity ensues when abandoned projects that remain in the repository continue to be updated and maintained.&lt;/p&gt;
&lt;p&gt;Several efforts at Google have sought to rein in unnecessary dependencies. Tooling exists to help identify and remove unused dependencies, or dependencies linked into the product binary for historical or accidental reasons, that are not needed. Tooling also exists to identify underutilized dependencies, or dependencies on large libraries that are mostly unneeded, as candidates for refactoring.&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#R7&quot;&gt;7&lt;/a&gt;&lt;/sup&gt; One such tool, Clipper, relies on a custom Java compiler to generate an accurate cross-reference index. It then uses the index to construct a reachability graph and determine what classes are never used. Clipper is useful in guiding dependency-refactoring efforts by finding targets that are relatively easy to remove or break up.&lt;/p&gt;
&lt;hr align=&quot;center&quot; width=&quot;50%&quot;/&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p align=&quot;center&quot;&gt;&lt;em&gt;A developer can make a major change touching hundreds or thousands of files across the repository in a single consistent operation.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr align=&quot;center&quot; width=&quot;50%&quot;/&gt;&lt;p&gt;Dependency-refactoring and cleanup tools are helpful, but, ideally, code owners should be able to prevent unwanted dependencies from being created in the first place. In 2011, Google started relying on the concept of API visibility, setting the default visibility of new APIs to &quot;private.&quot; This forces developers to explicitly mark APIs as appropriate for use by other teams. A lesson learned from Google's experience with a large monolithic repository is such mechanisms should be put in place as soon as possible to encourage more hygienic dependency structures.&lt;/p&gt;
&lt;p&gt;The fact that most Google code is available to all Google developers has led to a culture where some teams expect other developers to read their code rather than providing them with separate user documentation. There are pros and cons to this approach. No effort goes toward writing or keeping documentation up to date, but developers sometimes read more than the API code and end up relying on underlying implementation details. This behavior can create a maintenance burden for teams that then have trouble deprecating features they never meant to expose to users.&lt;/p&gt;
&lt;p&gt;This model also requires teams to collaborate with one another when using open source code. An area of the repository is reserved for storing open source code (developed at Google or externally). To prevent dependency conflicts, as outlined earlier, it is important that only one version of an open source project be available at any given time. Teams that use open source software are expected to occasionally spend time upgrading their codebase to work with newer versions of open source libraries when library upgrades are performed.&lt;/p&gt;
&lt;p&gt;Google invests significant effort in maintaining code health to address some issues related to codebase complexity and dependency management. For instance, special tooling automatically detects and removes dead code, splits large refactorings and automatically assigns code reviews (as through Rosie), and marks APIs as deprecated. Human effort is required to run these tools and manage the corresponding large-scale code changes. A cost is also incurred by teams that need to review an ongoing stream of simple refactorings resulting from codebase-wide clean-ups and centralized modernization efforts.&lt;/p&gt;
&lt;p class=&quot;totop&quot;&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#PageTop&quot;&gt;Back to Top&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Alternatives&lt;/h3&gt;
&lt;p&gt;As the popularity and use of distributed version control systems (DVCSs) like Git have grown, Google has considered whether to move from Piper to Git as its primary version-control system. A team at Google is focused on supporting Git, which is used by Google's Android and Chrome teams outside the main Google repository. The use of Git is important for these teams due to external partner and open source collaborations.&lt;/p&gt;
&lt;p&gt;The Git community strongly suggests and prefers developers have more and smaller repositories. A Git-clone operation requires copying all content to one's local machine, a procedure incompatible with a large repository. To move to Git-based source hosting, it would be necessary to split Google's repository into thousands of separate repositories to achieve reasonable performance. Such reorganization would necessitate cultural and workflow changes for Google's developers. As a comparison, Google's Git-hosted Android codebase is divided into more than 800 separate repositories.&lt;/p&gt;
&lt;p&gt;Given the value gained from the existing tools Google has built and the many advantages of the monolithic codebase structure, it is clear that moving to more and smaller repositories would not make sense for Google's main repository. The alternative of moving to Git or any other DVCS that would require repository splitting is not compelling for Google.&lt;/p&gt;
&lt;p&gt;Current investment by the Google source team focuses primarily on the ongoing reliability, scalability, and security of the in-house source systems. The team is also pursuing an experimental effort with Mercurial,&lt;sup&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#FNG&quot;&gt;g&lt;/a&gt;&lt;/sup&gt; an open source DVCS similar to Git. The goal is to add scalability features to the Mercurial client so it can efficiently support a codebase the size of Google's. This would provide Google's developers with an alternative of using popular DVCS-style workflows in conjunction with the central repository. This effort is in collaboration with the open source Mercurial community, including contributors from other companies that value the monolithic source model.&lt;/p&gt;
&lt;p class=&quot;totop&quot;&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#PageTop&quot;&gt;Back to Top&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Google chose the monolithic-source-management strategy in 1999 when the existing Google codebase was migrated from CVS to Perforce. Early Google engineers maintained that a single repository was strictly better than splitting up the codebase, though at the time they did not anticipate the future scale of the codebase and all the supporting tooling that would be built to make the scaling feasible.&lt;/p&gt;
&lt;p&gt;Over the years, as the investment required to continue scaling the centralized repository grew, Google leadership occasionally considered whether it would make sense to move from the monolithic model. Despite the effort required, Google repeatedly chose to stick with the central repository due to its advantages.&lt;/p&gt;
&lt;p&gt;The monolithic model of source code management is not for everyone. It is best suited to organizations like Google, with an open and collaborative culture. It would not work well for organizations where large parts of the codebase are private or hidden between groups.&lt;/p&gt;
&lt;p&gt;At Google, we have found, with some investment, the monolithic model of source management can scale successfully to a codebase with more than one billion files, 35 million commits, and thousands of users around the globe. As the scale and complexity of projects both inside and outside Google continue to grow, we hope the analysis and workflow described in this article can benefit others weighing decisions on the long-term structure for their codebases.&lt;/p&gt;
&lt;p class=&quot;totop&quot;&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#PageTop&quot;&gt;Back to Top&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Acknowledgments&lt;/h3&gt;
&lt;p&gt;We would like to recognize all current and former members of the Google Developer Infrastructure teams for their dedication in building and maintaining the systems referenced in this article, as well as the many people who helped in reviewing the article; in particular: Jon Perkins and Ingo Walther, the current Tech Leads of Piper; Kyle Lippincott and Crutcher Dunnavant, the current and former Tech Leads of CitC; Hyrum Wright, Google's large-scale refactoring guru; and Chris Colohan, Caitlin Sadowski, Morgan Ames, Rob Siemborski, and the Piper and CitC development and support teams for their insightful review comments.&lt;/p&gt;
&lt;p class=&quot;totop&quot;&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#PageTop&quot;&gt;Back to Top&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;article-references&quot; readability=&quot;185.42950179095&quot;&gt;
&lt;h3 class=&quot;known-headings&quot;&gt;References&lt;/h3&gt;
&lt;p&gt;1. Bloch, D. &lt;em&gt;Still All on One Server: Perforce at Scale&lt;/em&gt;. Google White Paper, 2011; &lt;a href=&quot;http://info.perforce.com/rs/perforce/images/GoogleWhitePaper-StillAllonOneServer-PerforceatScale.pdf&quot;&gt;http://info.perforce.com/rs/perforce/images/GoogleWhitePaper-StillAllonOneServer-PerforceatScale.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2. Chang, F., Dean, J., Ghemawat, S., Hsieh, W.C., Wallach, D.A., Burrows, M., Chandra, T., Fikes, A., and Gruber, R.E. Bigtable: A distributed storage system for structured data. &lt;em&gt;ACM Transactions on Computer Systems 26&lt;/em&gt;, 2 (June 2008).&lt;/p&gt;
&lt;p&gt;3. Corbett, J.C., Dean, J., Epstein, M., Fikes, A., Frost, C., Furman, J., Ghemawat, S., Gubarev, A., Heiser, C., Hochschild, P. et al. Spanner: Google's globally distributed database. &lt;em&gt;ACM Transactions on Computer Systems 31&lt;/em&gt;, 3 (Aug. 2013).&lt;/p&gt;
&lt;p&gt;4. Gabriel, R.P., Northrop, L., Schmidt, D.C., and Sullivan, K. Ultra-large-scale systems. In &lt;em&gt;Companion to the 21st ACM SIGPLAN Symposium on Object-Oriented Programming Systems, Languages, and Applications&lt;/em&gt; (Portland, OR, Oct. 22-26). ACM Press, New York, 2006, 632–634.&lt;/p&gt;
&lt;p&gt;5. Kemper, C. Build in the Cloud: How the Build System works. Google Engineering Tools blog post, 2011; &lt;a href=&quot;https://google-engtools.blogspot.com/2011/08/build-in-cloud-how-build-system-works.html&quot;&gt;http://google-engtools.blogspot.com/2011/08/build-in-cloud-how-build-system-works.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;6. Lamport, L. Paxos made simple. &lt;em&gt;ACM Sigact News 32&lt;/em&gt;, 4 (Nov. 2001), 18–25.&lt;/p&gt;
&lt;p&gt;7. Morgenthaler, J.D., Gridnev, M., Sauciuc, R., and Bhansali, S. Searching for build debt: Experiences managing technical debt at Google. In &lt;em&gt;Proceedings of the Third International Workshop on Managing Technical Debt&lt;/em&gt; (Zürich, Switzerland, June 2-9). IEEE Press Piscataway, NJ, 2012, 1–6.&lt;/p&gt;
&lt;p&gt;8. Ren, G., Tune, E., Moseley, T., Shi, Y., Rus, S., and Hundt, R. Google-wide profiling: A continuous profiling infrastructure for data centers. &lt;em&gt;IEEE Micro 30&lt;/em&gt;, 4 (2010), 65–79.&lt;/p&gt;
&lt;p&gt;9. Sadowski, C., Stolee, K., and Elbaum, S. How developers search for code: A case study. In &lt;em&gt;Proceedings of the 10&lt;sup&gt;th&lt;/sup&gt; Joint Meeting on Foundations of Software Engineering&lt;/em&gt; (Bergamo, Italy, Aug. 30-Sept. 4). ACM Press, New York, 2015, 191–201.&lt;/p&gt;
&lt;p&gt;10. Sadowski, C., van Gogh, J., Jaspan, C., Soederberg, E., and Winter, C. Tricorder: Building a program analysis ecosystem. In &lt;em&gt;Proceedings of the 37&lt;sup&gt;th&lt;/sup&gt; International Conference on Software Engineering, Vol. 1&lt;/em&gt; (Firenze, Italy, May 16-24). IEEE Press Piscataway, NJ, 2015, 598–608.&lt;/p&gt;
&lt;p&gt;11. Wasserman, L. Scalable, example-based refactorings with Refaster. In &lt;em&gt;Proceedings of the 2013 ACM Workshop on Refactoring Tools&lt;/em&gt; (Indianapolis, IN, Oct. 26-31). ACM Press, New York, 2013, 25–28.&lt;/p&gt;
&lt;p&gt;12. Wikipedia. Dependency hell. Accessed Jan. 20, 2015; &lt;a href=&quot;https://en.wikipedia.org/w/index.php?title=Dependency_hell&amp;amp;oldid=634636715&quot;&gt;http://en.wikipedia.org/w/index.php?title=Dependency_hell&amp;amp;oldid=634636715&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;13. Wikipedia. Filesystem in userspace. Accessed June, 4, 2015; &lt;a href=&quot;https://en.wikipedia.org/w/index.php?title=Filesystem_in_Userspace&amp;amp;oldid=664776514&quot;&gt;http://en.wikipedia.org/w/index.php?title=Filesystem_in_Userspace&amp;amp;oldid=664776514&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;14. Wikipedia. Linux kernel. Accessed Jan. 20, 2015; &lt;a href=&quot;https://en.wikipedia.org/w/index.php?title=Linux_kernel&amp;amp;oldid=643170399&quot;&gt;http://en.wikipedia.org/w/index.php?title=Linux_kernel&amp;amp;oldid=643170399&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;15. Wright, H.K., Jasper, D., Klimek, M., Carruth, C., and Wan, Z. Large-scale automated refactoring using ClangMR. In &lt;em&gt;Proceedings of the IEEE International Conference on Software Maintenance&lt;/em&gt; (Eindhoven, The Netherlands, Sept. 22-28). IEEE Press, 2013, 548–551.&lt;/p&gt;
&lt;/div&gt;
&lt;p class=&quot;totop&quot;&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#PageTop&quot;&gt;Back to Top&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;article-authorinfo&quot; readability=&quot;30.68449197861&quot;&gt;
&lt;h3 class=&quot;known-headings&quot;&gt;Authors&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Rachel Potvin&lt;/strong&gt; (&lt;a href=&quot;http://delivery.acm.org/10.1145/2860000/2854146/mailto:rpotvin@google.com&quot;&gt;&lt;span class=&quot;__cf_email__&quot; data-cfemail=&quot;cab8baa5bebca3a48aada5a5ada6afe4a9a5a7&quot;&gt;[email protected]&lt;/span&gt;&lt;/a&gt;) is an engineering manager at Google, Mountain View, CA.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Josh Levenberg&lt;/strong&gt; (&lt;a href=&quot;http://delivery.acm.org/10.1145/2860000/2854146/mailto:joshl@google.com&quot;&gt;&lt;span class=&quot;__cf_email__&quot; data-cfemail=&quot;d1bbbea2b9bd91b6bebeb6bdb4ffb2bebc&quot;&gt;[email protected]&lt;/span&gt;&lt;/a&gt;) is a software engineer at Google, Mountain View, CA.&lt;/p&gt;
&lt;/div&gt;
&lt;p class=&quot;totop&quot;&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#PageTop&quot;&gt;Back to Top&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;article-footnotes&quot; readability=&quot;23.553191489362&quot;&gt;
&lt;h3 class=&quot;known-headings&quot;&gt;Footnotes&lt;/h3&gt;
&lt;p&gt;a. Total size of uncompressed content, excluding release branches.&lt;/p&gt;
&lt;p&gt;b. Includes only reviewed and committed code and excludes commits performed by automated systems, as well as commits to release branches, data files, generated files, open source files imported into the repository, and other non-source-code files.&lt;/p&gt;
&lt;p&gt;c. Google open sourced a subset of its internal build system; see &lt;a href=&quot;http://www.bazel.io&quot;&gt;http://www.bazel.io&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;d. Over 99% of files stored in Piper are visible to all full-time Google engineers.&lt;/p&gt;
&lt;p&gt;e. &lt;a href=&quot;https://github.com/google/styleguide&quot;&gt;https://github.com/google/styleguide&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;f. The project name was inspired by Rosie the robot maid from the TV series &quot;The Jetsons.&quot;&lt;/p&gt;
&lt;p&gt;g. &lt;a href=&quot;http://mercurial.selenic.com/&quot;&gt;http://mercurial.selenic.com/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p class=&quot;totop&quot;&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#PageTop&quot;&gt;Back to Top&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;article-figures&quot; readability=&quot;46&quot;&gt;
&lt;h3 class=&quot;known-headings&quot;&gt;Figures&lt;/h3&gt;
&lt;p class=&quot;ThumbnailParagraph&quot;&gt;&lt;a href=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/figs/f1.jpg&quot; class=&quot;ThumbnailLink&quot;&gt;&lt;img src=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/thumbs/f1.jpg&quot; border=&quot;0&quot; alt=&quot;F1&quot;/&gt;&lt;/a&gt;Figure 1. Millions of changes committed to Google's central repository over time.&lt;/p&gt;
&lt;p class=&quot;ThumbnailParagraph&quot;&gt;&lt;a href=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/figs/f2.jpg&quot; class=&quot;ThumbnailLink&quot;&gt;&lt;img src=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/thumbs/f2.jpg&quot; border=&quot;0&quot; alt=&quot;F2&quot;/&gt;&lt;/a&gt;Figure 2. Human committers per week.&lt;/p&gt;
&lt;p class=&quot;ThumbnailParagraph&quot;&gt;&lt;a href=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/figs/f3.jpg&quot; class=&quot;ThumbnailLink&quot;&gt;&lt;img src=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/thumbs/f3.jpg&quot; border=&quot;0&quot; alt=&quot;F3&quot;/&gt;&lt;/a&gt;Figure 3. Commits per week.&lt;/p&gt;
&lt;p class=&quot;ThumbnailParagraph&quot;&gt;&lt;a href=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/figs/f4.jpg&quot; class=&quot;ThumbnailLink&quot;&gt;&lt;img src=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/thumbs/f4.jpg&quot; border=&quot;0&quot; alt=&quot;F4&quot;/&gt;&lt;/a&gt;Figure 4. Piper workflow.&lt;/p&gt;
&lt;p class=&quot;ThumbnailParagraph&quot;&gt;&lt;a href=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/figs/f5.jpg&quot; class=&quot;ThumbnailLink&quot;&gt;&lt;img src=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/thumbs/f5.jpg&quot; border=&quot;0&quot; alt=&quot;F5&quot;/&gt;&lt;/a&gt;Figure 5. Piper team logo &quot;Piper is Piper expanded recursively;&quot; design source: Kirrily Anderson.&lt;/p&gt;
&lt;p class=&quot;ThumbnailParagraph&quot;&gt;&lt;a href=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/figs/f6.jpg&quot; class=&quot;ThumbnailLink&quot;&gt;&lt;img src=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/thumbs/f6.jpg&quot; border=&quot;0&quot; alt=&quot;F6&quot;/&gt;&lt;/a&gt;Figure 6. Release branching model.&lt;/p&gt;
&lt;p class=&quot;ThumbnailParagraph&quot;&gt;&lt;a href=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/figs/f7.jpg&quot; class=&quot;ThumbnailLink&quot;&gt;&lt;img src=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/thumbs/f7.jpg&quot; border=&quot;0&quot; alt=&quot;F7&quot;/&gt;&lt;/a&gt;Figure 7. Rosie commits per month.&lt;/p&gt;
&lt;p class=&quot;ThumbnailParagraph&quot;&gt;&lt;a href=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/figs/f8.jpg&quot; class=&quot;ThumbnailLink&quot;&gt;&lt;img src=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/thumbs/f8.jpg&quot; border=&quot;0&quot; alt=&quot;F8&quot;/&gt;&lt;/a&gt;Figure 8. Diamond dependency problem.&lt;/p&gt;
&lt;/div&gt;
&lt;p class=&quot;totop&quot;&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#PageTop&quot;&gt;Back to Top&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;article-tables&quot; readability=&quot;33&quot;&gt;
&lt;h3 class=&quot;known-headings&quot;&gt;Tables&lt;/h3&gt;
&lt;p class=&quot;ThumbnailParagraph&quot;&gt;&lt;a href=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/figs/ut1.jpg&quot; class=&quot;ThumbnailLink&quot;&gt;&lt;img src=&quot;http://deliveryimages.acm.org/10.1145/2860000/2854146/thumbs/ut1.jpg&quot; border=&quot;0&quot; alt=&quot;UT1&quot;/&gt;&lt;/a&gt;Table. Google repository statistics, January 2015.&lt;/p&gt;
&lt;/div&gt;
&lt;p class=&quot;totop&quot;&gt;&lt;a href=&quot;https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext#PageTop&quot;&gt;Back to top&lt;/a&gt;&lt;/p&gt;
&lt;div id=&quot;article-permission&quot; readability=&quot;32&quot;&gt;
&lt;hr class=&quot;Separator&quot;/&gt;
&lt;p&gt;Copyright held by the authors&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The Digital Library is published by the Association for Computing Machinery. Copyright © 2016 ACM, Inc.&lt;/p&gt;

&lt;hr class=&quot;thick&quot;/&gt;
&lt;h2&gt;Comments&lt;/h2&gt;
&lt;hr class=&quot;solid&quot;/&gt;&lt;h5&gt;Robert Fink&lt;/h5&gt;
&lt;span class=&quot;byline&quot;&gt;June 28, 2016 02:16&lt;/span&gt;
&lt;p&gt;I'm curious to understand the interplay of the source code model (monolithic repository vs many repositories) and the deployment model, in particular when considering continuous deployment vs. explicit releases.&lt;br/&gt;- My understanding is that Google services are compiled&amp;amp;deployed from trunk; what does this mean for database migrations (e.g., schema upgrades), in particular when different instances of the same service are maintained by different teams: How do you coordinate such distributed data migrations in the face of more or less continuous upgrades of binaries? There there isn't a notion of a released, stable version of a package, do you require effectively infinite backwards-compatibility?&lt;br/&gt;- Similarly, when a service is deployed from today's trunk, but a dependent service is still running on last week's trunk, how is API compatibility guaranteed between those services?&lt;/p&gt;
&lt;p&gt;It seems that stringent contracts for cross-service API and schema compatibility need to be in place to prevent breakages as a result from live upgrades?&lt;/p&gt;
&lt;p&gt;Curious to hear your thoughts, thanks!&lt;br/&gt;Robert&lt;/p&gt;
&lt;hr class=&quot;solid&quot;/&gt;&lt;h5&gt;Ed Chi&lt;/h5&gt;
&lt;span class=&quot;byline&quot;&gt;June 30, 2016 11:13&lt;/span&gt;
&lt;p&gt;Teams can package up their own binaries that run in production data centers.&lt;/p&gt;
&lt;p&gt;There is effectively a SLA between the team that publish the binary and the clients that uses them. If you don't like the SLA (including backwards compatibility), you are free to compile your own binary package to run in production.&lt;/p&gt;
&lt;p&gt;Migration is usually done in a three step process: announce, new code and move over, then deprecate old code by deletion.&lt;/p&gt;
&lt;hr class=&quot;solid&quot;/&gt;&lt;h5&gt;Kevin Schultz&lt;/h5&gt;
&lt;span class=&quot;byline&quot;&gt;July 12, 2016 01:10&lt;/span&gt;
&lt;p&gt;Section &quot;Background&quot;, paragraph five, states: &quot;Updates from the Piper repository can be pulled into a workspace and merged with ongoing work, as desired (see Figure 5).&quot;&lt;/p&gt;
&lt;p&gt;However, Figure 5 seems to link to &quot;Piper team logo &quot;Piper is Piper expanded recursively;&quot; design source: Kirrily Anderson.&quot;&lt;/p&gt;
&lt;p&gt;Please clarify; thank you.&lt;/p&gt;
&lt;hr class=&quot;thick&quot;/&gt;&lt;p class=&quot;view-all&quot;&gt;Displaying &lt;strong&gt;all 3&lt;/strong&gt; comments&lt;/p&gt;
&lt;/div&gt;</description>
<pubDate>Tue, 24 Jul 2018 22:11:50 +0000</pubDate>
<dc:creator>bwag</dc:creator>
<og:type>article</og:type>
<og:url>https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext</og:url>
<og:title>Why Google Stores Billions of Lines of Code in a Single Repository</og:title>
<og:image>https://cacm.acm.org/system/assets/0002/4065/062016_CACMpg79_Why-Google.large.jpg?1476779499&amp;1466529917</og:image>
<og:description>Google's monolithic repository provides a common source of truth for tens of thousands of developers around the world.</og:description>
<dc:format>text/html</dc:format>
<dc:identifier>https://cacm.acm.org/magazines/2016/7/204032-why-google-stores-billions-of-lines-of-code-in-a-single-repository/fulltext</dc:identifier>
</item>
<item>
<title>To Remember, the Brain Must Actively Forget</title>
<link>https://www.quantamagazine.org/to-remember-the-brain-must-actively-forget-20180724/</link>
<guid isPermaLink="true" >https://www.quantamagazine.org/to-remember-the-brain-must-actively-forget-20180724/</guid>
<description>&lt;p&gt;Going along with all that variety is now a growing appreciation that forgetting — the functional loss of memories — may also come in diverse forms. Past theories about forgetting mostly emphasized relatively passive processes in which the loss of memories was a consequence of the physical traces of those memories (what some researchers refer to as “engrams”) naturally breaking down or becoming harder to access; those engrams may typically be interconnections between brain cells that prompt them to fire in a certain way. This forgetting process could involve the spontaneous decay of connections between neurons that encode a memory, the random death of those neurons, the failure of systems that would normally help to consolidate and stabilize new memories, or the loss of context cues or other factors that might make it hard to retrieve a memory.&lt;/p&gt;
&lt;p&gt;Now, however, researchers are paying much more attention to mechanisms that actively erase or hide those memory engrams.&lt;/p&gt;
&lt;h2&gt;Intrinsic Forgetting&lt;/h2&gt;
&lt;p&gt;One form of active forgetting that scientists formally &lt;a href=&quot;https://www.cell.com/neuron/fulltext/S0896-6273(17)30498-1&quot;&gt;identified in 2017&lt;/a&gt; is called intrinsic forgetting. It involves a certain subset of cells in the brain — which &lt;a href=&quot;http://www.scripps.edu/davis/&quot;&gt;Ronald Davis&lt;/a&gt; and &lt;a href=&quot;https://life.tsinghua.edu.cn/publish/smkx/11529/2018/20180519052257296107340/20180519052257296107340_.html&quot;&gt;Yi Zhong&lt;/a&gt;, who wrote the paper that introduced the idea, casually call “forgetting cells” — that degrade the engrams in memory cells.&lt;/p&gt;
&lt;p&gt;This idea emerged after Davis, a neuroscientist at the Scripps Research Institute in Jupiter, Florida, and his colleagues reported giving fruit flies mild electric shocks while exposing them to an odor. The flies quickly &lt;a href=&quot;https://doi.org/10.1016/j.neuron.2016.05.010&quot;&gt;learned to avoid the smell&lt;/a&gt;, associating it with the shock.&lt;/p&gt;

&lt;p&gt;Davis and his colleagues looked at a certain set of neurons in the brains of the fruit flies that continuously release the neurotransmitter dopamine onto others called mushroom body neurons. They found that dopamine plays a dual role in both forming and forgetting memories. After Davis and his colleagues trained the flies, they blocked dopamine release onto the mushroom body cells and found that the flies’ memory scores were twice as high when they were tested three hours later.&lt;/p&gt;
&lt;p&gt;The explanation that Davis and his team proposed is that after a new memory forms, the dopamine-based forgetting mechanism begins to erase it. Davis thinks this erasure happens because the cells reverse the structural changes that created the memory engram. The cells’ natural inclination is to go back to how they were before they learned the memory — that is, unless the thought is somehow recognized as being important. Then the engram is preserved through some sort of consolidation process, which maintains a balance between what is learned and forgotten.&lt;/p&gt;
&lt;p&gt;“Maybe the brain is designed to forget information,” Davis said. Somewhere in the brain, he noted, there may be some sort of judge that tells it to override the forgetting process when it comes across something worth remembering in the long run.&lt;/p&gt;
&lt;p&gt;Zhong, a neuroscientist at Tsinghua University in Beijing, and his team have also successfully manipulated forgetting in mice. &lt;a href=&quot;http://dx.doi.org/10.1016/j.cub.2016.06.056&quot;&gt;In 2016 they found&lt;/a&gt; that the inhibition of a specific protein called Rac1 in the hippocampal neurons prolonged the retention of memories from less than 72 hours to at least 120 hours in many cases. Increasing the activity of Rac1 reduced the life of memories to less than 24 hours. Earlier work by Zhong’s group had shown that Rac1 was similarly involved in &lt;a href=&quot;http://dx.doi.org/doi:10.1016/j.cell.2009.12.044&quot;&gt;several forms of forgetting&lt;/a&gt; in fruit flies.&lt;/p&gt;
&lt;p&gt;As Davis and Zhong argued in &lt;a href=&quot;http://dx.doi.org/10.1016/j.neuron.2017.05.039&quot;&gt;their jointly written 2017 review&lt;/a&gt;, all those findings suggested that cellular processes mediated by dopamine and Rac1 constantly erode newly formed memories. “From this perspective,” they wrote, “forgetting as mediated by intrinsic forgetting mechanisms may be the default state of the brain; intrinsic forgetting may operate chronically at a low level to slowly remove each newly acquired memory, although its strength may be regulated by internal or external factors.”&lt;/p&gt;
&lt;h2&gt;New Neurons and Old Memories&lt;/h2&gt;
&lt;p&gt;Another cellular process that seems to cause its own form of forgetting is neurogenesis, the birth of new neurons in the brain.&lt;/p&gt;
&lt;p&gt;The connection of neurogenesis to memory and forgetting is complicated. Previous studies have shown that neurogenesis can be important to the formation of new memories: In tests on lab animals, drugs that inhibit neurogenesis in the hippocampus can interfere with new memory formation, and drugs that enhance neurogenesis seem to help with learning new tasks if they are given before the learning process.&lt;/p&gt;

&lt;p&gt;But the effects aren’t all positive for memory, as &lt;a href=&quot;http://www.neuroscience.utoronto.ca/faculty/list/frankland.htm&quot;&gt;Paul Frankland&lt;/a&gt;, a neuroscientist at the University of Toronto and the &lt;a href=&quot;http://www.franklandlab.com/&quot;&gt;Hospital for Sick Children&lt;/a&gt;, and his colleagues &lt;a href=&quot;http://science.sciencemag.org/content/344/6184/598.long&quot;&gt;discovered&lt;/a&gt; while working with mice.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://dx.doi.org/10.1016/j.tins.2013.05.002&quot;&gt;In their experiment&lt;/a&gt;, they first allowed the mice to create a memory by training at a task. Hours later, with drugs, they raised the level of neurogenesis in the animals to test whether the integration of new neurons in the hippocampus would affect the stability of that already stored memory. When Frankland’s team tested the mice about a month later, their recall of the training was much worse than that of mice that had not had the later neurogenesis boost.&lt;/p&gt;
&lt;p&gt;Frankland suspects that neurogenesis can complicate the challenge of retrieving prior memories from the hippocampus. If the added neural wiring overlaps with the circuitry holding older memories, it may damage the older engrams or make it harder to isolate the old memories from newer ones. He likened the problem to electronics repair: “If you go in and start rewiring something,” Frankland said, “any information stored in that circuit might be degraded.”&lt;/p&gt;

&lt;p&gt;One piece of evidence that supports his theory came from follow-up work &lt;a href=&quot;http://doi.org/10.1523/JNEUROSCI.3126-17.2018&quot;&gt;published earlier this year&lt;/a&gt; which showed that the harmful effect of hippocampal neurogenesis is worse for relatively recent memories. Much older memories do not seem to be hurt by it. Frankland’s explanation is that older memories are less sensitive to this effect because the brain gradually transfers important memories from the hippocampus to the cortex for long-term storage. Neurogenesis in the hippocampus today is therefore more disruptive for memories from a week ago than for those from months or years ago.&lt;/p&gt;
&lt;p&gt;Indeed, Frankland noted that the forgetting produced by remodeling of the hippocampal circuits through neurogenesis happens more slowly than the intrinsic forgetting based on dopamine and Rac1 that Davis and Yi observed: It takes several weeks for newly formed neurons to create new connections — and to contribute to the forgetting processes at work.&lt;/p&gt;
&lt;h2&gt;What Happens to Forgotten Memories?&lt;/h2&gt;
&lt;p&gt;When memories are forgotten by whatever mechanism, what happens to them? Are all traces of them eliminated? Or do they persist in some form unavailable to us?&lt;/p&gt;
&lt;p&gt;A set of answers that seems to apply to at least some types of memory came from &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/29246980&quot;&gt;work published last year&lt;/a&gt; by &lt;a href=&quot;http://www2.dom.edu/departments/neuroscience/faculty/robert-calin-jageman&quot;&gt;Robert Calin-Jageman&lt;/a&gt; and &lt;a href=&quot;http://www2.dom.edu/departments/biologicalsciences/faculty/irina-calin-jageman&quot;&gt;Irina Calin-Jageman&lt;/a&gt;, husband-and-wife researchers who run a &lt;a href=&quot;https://calin-jageman.homeip.net/lab/&quot;&gt;behavioral neuroscience laboratory at Dominican University&lt;/a&gt; in River Forest, Illinois. The pair, who have been studying how sea slugs form memories for a decade, recently switched their attention to the neurobiology of how the animals forget.&lt;/p&gt;

&lt;p&gt;In the first stage of their experiments, the Calin-Jagemans “sensitized” sea slugs to electric shocks on one side of their body, but not on the other. In effect, they taught the sea slugs to show a bigger reflexive response on the trained side of their body. They then let the sea slugs forget this learned response over a one-week rest period, so that their responses to shocks were symmetrical again.&lt;/p&gt;
&lt;p&gt;Then the researchers jogged the sea slugs’ memory with another round of moderate shocks. The day after this reminder, they saw that the side of the animals that had previously been sensitized was again reacting more than the untrained side. This difference showed that some fragment of the memory persisted in the animal’s brain. “The animal has changed its behavior because the nervous system has encoded that previous painful experience,” according to Robert Calin-Jageman.&lt;/p&gt;

&lt;p&gt;“This suggests that there was some fragment of the previous sensitization memory still existing on the trained side,” he said, which hinted “that there must have been something latent in the brain” that preserved the association. Even after a week — a significant part of a sea slug’s one-year lifespan — the brain is still not back to the way it was before it acquired the memory. “Our results support the idea that it’s not just passive decay of memories,” said Irina Calin-Jageman. “Everything isn’t just gradually, completely gone.”&lt;/p&gt;
&lt;p&gt;To find out more about what survived the forgetting process, the Calin-Jagemans and their colleagues looked at gene expression on both sides of the animals’ brains, paying particular attention to about 1,200 genes that previous research had linked to memory storage in sea slugs. Eleven of those genes, they discovered, were still active on one side of the animals’ brains but not on the other, even after the animals had apparently forgotten about the shock.&lt;/p&gt;
&lt;p&gt;Why those 11 genes were active and what function they were serving are still unknowns. It’s not even certain that their activity directly relates to the forgotten memory; researchers would have to manipulate these genes to find out. But the possibility that excites the Calin-Jagemans is that those genes were connected to the memory — either in maintaining some remnant of the engram or in erasing it.&lt;/p&gt;
</description>
<pubDate>Tue, 24 Jul 2018 20:34:52 +0000</pubDate>
<dc:creator>digital55</dc:creator>
<og:title>To Remember, the Brain Must Actively Forget | Quanta Magazine</og:title>
<og:type>article</og:type>
<og:url>https://www.quantamagazine.org/to-remember-the-brain-must-actively-forget-20180724/</og:url>
<og:image>https://d2r55xnwy6nx47.cloudfront.net/uploads/2018/07/Forgetting_FB_1200.jpg</og:image>
<dc:format>text/html</dc:format>
<dc:identifier>https://www.quantamagazine.org/to-remember-the-brain-must-actively-forget-20180724/</dc:identifier>
</item>
<item>
<title>YC’s 2018 Summer Reading List</title>
<link>https://blog.ycombinator.com/ycs-2018-summer-reading-list/</link>
<guid isPermaLink="true" >https://blog.ycombinator.com/ycs-2018-summer-reading-list/</guid>
<description>&lt;p&gt;&lt;a href=&quot;https://news.ycombinator.com/item?id=17513576&quot;&gt;A post about summer reading&lt;/a&gt; on Hacker News inspired us to put a list together for 2018. Here’s what we’ve been reading.&lt;/p&gt;
&lt;hr/&gt;&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Path-Power-Years-Lyndon-Johnson/dp/0679729453&quot;&gt;The Years of Lyndon Johnson&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Path-Power-Years-Lyndon-Johnson/dp/0679729453&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Years-of-Lyndon-Johnson.jpg&quot; alt=&quot;The Years of Lyndon Johnson&quot; width=&quot;334&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102657&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Years-of-Lyndon-Johnson.jpg 334w, https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Years-of-Lyndon-Johnson-201x300.jpg 201w&quot; sizes=&quot;(max-width: 334px) 100vw, 334px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“As in many of the best books of history I’ve read, the author (Caro) makes an argument larger than LBJ and tells a story that can’t be encompassed by any one person or sequence of events. His writing is some of the best I’ve read. His analysis of the man, his time, and the structure of power shifted the way I look at the world.” &lt;strong&gt;– Aaron Harris&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/H-Hawk-Helen-Macdonald/dp/0802124739/&quot;&gt;H is for Hawk&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/H-Hawk-Helen-Macdonald/dp/0802124739/&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/H-is-for-Hawk.jpg&quot; alt=&quot;H is for Hawk&quot; width=&quot;329&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102658&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/H-is-for-Hawk.jpg 329w, https://blog.ycombinator.com/wp-content/uploads/2018/07/H-is-for-Hawk-198x300.jpg 198w&quot; sizes=&quot;(max-width: 329px) 100vw, 329px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“A powerful memoir about loss, grief, and the fluidity of sanity, obsession, and madness. Macdonald’s descriptions of the world and of her mind blur the line between poetry and prose.” &lt;strong&gt;– Aaron Harris&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Three-Body-Problem-Cixin-Liu/dp/0765382032&quot;&gt;The Three Body Problem&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Three-Body-Problem-Cixin-Liu/dp/0765382032&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Three-Body.jpg&quot; alt=&quot;The Three Body Problem&quot; width=&quot;331&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102668&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Three-Body.jpg 331w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Three-Body-199x300.jpg 199w&quot; sizes=&quot;(max-width: 331px) 100vw, 331px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“The first book in a science fiction trilogy about a group of scientists who have given up on humanity and look to alien civilization to redefine human life on earth.” &lt;strong&gt;– Cadran Cowansage&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Parable-Sower-Earthseed-Octavia-Butler/dp/0446675504&quot;&gt;Parable of the Sower&lt;/a&gt; and &lt;a href=&quot;https://www.amazon.com/Parable-Talents-Earthseed-Octavia-Butler/dp/0446675784&quot;&gt;Parable of the Talents&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Parable-Sower-Earthseed-Octavia-Butler/dp/0446675504&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Parable-of-the-Sower.jpg&quot; alt=&quot;Parable of the Sower&quot; width=&quot;324&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102669&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Parable-of-the-Sower.jpg 324w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Parable-of-the-Sower-195x300.jpg 195w&quot; sizes=&quot;(max-width: 324px) 100vw, 324px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“A two-book science fiction series about the collapse of society and one woman’s journey to survive and spread her new belief system.” &lt;strong&gt;– Cadran Cowansage&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Crake-MaddAddam-Trilogy-Margaret-Atwood/dp/0385721676/&quot;&gt;Oryx and Crake&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Crake-MaddAddam-Trilogy-Margaret-Atwood/dp/0385721676&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Oryx-and-Crake.jpg&quot; alt=&quot;Oryx and Crake&quot; width=&quot;324&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102670&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Oryx-and-Crake.jpg 324w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Oryx-and-Crake-195x300.jpg 195w&quot; sizes=&quot;(max-width: 324px) 100vw, 324px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“A novel about a post-apocalyptic world where a man must coexist with genetically-engineered humans as he recounts the story of how the world imploded.” &lt;strong&gt;– Cadran Cowansage&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Taming-Sun-Innovations-Harness-Energy/dp/0262037688&quot;&gt;Taming the Sun: Innovations to Harness Solar Energy and Power the Planet&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Taming-Sun-Innovations-Harness-Energy/dp/0262037688&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Taming-the-Sun.jpg&quot; alt=&quot;taming the sun&quot; width=&quot;333&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102648&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Taming-the-Sun.jpg 333w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Taming-the-Sun-200x300.jpg 200w&quot; sizes=&quot;(max-width: 333px) 100vw, 333px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“Solar is very clearly our next major source of energy. The problem with solar is that it’s only sunny during the day and not every day. Without the right policies in place and cheap energy storage we phase a risk that solar growth will very soon tap out.” &lt;strong&gt;– Gustaf Alstromer&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Clean-Meat-Growing-Without-Revolutionize/dp/1501189085&quot;&gt;Clean Meat: How Growing Meat Without Animals Will Revolutionize Dinner and the World&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Clean-Meat-Growing-Without-Revolutionize/dp/1501189085&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Clean-Meat.jpg&quot; alt=&quot;Clean Meat&quot; width=&quot;331&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102649&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Clean-Meat.jpg 331w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Clean-Meat-199x300.jpg 199w&quot; sizes=&quot;(max-width: 331px) 100vw, 331px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“Science have already proven we can grow all kinds of animal protein in labs. This book is the founding story of a revolution that will how we eat and the planet forever.” &lt;strong&gt;– Gustaf Alstromer&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/High-Growth-Handbook-Elad-Gil/dp/1732265100/&quot;&gt;High Growth Handbook&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/High-Growth-Handbook-Elad-Gil/dp/1732265100/&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/High-Growth-Handbook.jpg&quot; alt=&quot;High Growth Handbook&quot; width=&quot;338&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102650&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/High-Growth-Handbook.jpg 338w, https://blog.ycombinator.com/wp-content/uploads/2018/07/High-Growth-Handbook-203x300.jpg 203w&quot; sizes=&quot;(max-width: 338px) 100vw, 338px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“Elad Gil is maybe the most successful recent angel investor in Silicon Valley and have written the best blog for startup founders and I’ve been a follower of his writing since the beginning.” &lt;strong&gt;– Gustaf Alstromer&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Lathe-Heaven-Ursula-K-Guin/dp/1416556966&quot;&gt;The Lathe of Heaven&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Lathe-Heaven-Ursula-K-Guin/dp/1416556966&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Lathe-of-Heaven.jpg&quot; alt=&quot;The Lathe of Heaven&quot; width=&quot;323&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102652&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Lathe-of-Heaven.jpg 323w, https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Lathe-of-Heaven-194x300.jpg 194w&quot; sizes=&quot;(max-width: 323px) 100vw, 323px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“Ursula LeGuin’s early scifi novel that succinctly explores the morality of absolute power, and the relation between our personal power and sense of responsibility for others. The setting is a drama between therapist and patient that begins to affect reality in strange ways.” &lt;strong&gt;– Joe Betts-Lacroix&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Golden-Notebook-Novel-Doris-Lessing/dp/0061582484/&quot;&gt;The Golden Notebook&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Golden-Notebook-Novel-Doris-Lessing/dp/0061582484/&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Golden-Notebook.jpg&quot; alt=&quot;The Golden Notebook&quot; width=&quot;343&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102653&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Golden-Notebook.jpg 343w, https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Golden-Notebook-206x300.jpg 206w&quot; sizes=&quot;(max-width: 343px) 100vw, 343px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“An intimate portrayal of the interior experience of a woman. Almost certainly autobiographical to some degree, it is a joy to follow her brilliant mind, and torturous to feel the conflicts between her wants and the realities of what she can have, both in her relationships and her political idealism.” &lt;strong&gt;– Joe Betts-Lacroix&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Wizard-Oz-Other-Narcissists-Relationship/dp/0972072837&quot;&gt;The Wizard of Oz and Other Narcissists&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Wizard-Oz-Other-Narcissists-Relationship/dp/0972072837&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Wizard-of-Oz-and-Other-Narcissists.jpg&quot; alt=&quot;The Wizard of Oz and Other Narcissists&quot; width=&quot;333&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102654&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Wizard-of-Oz-and-Other-Narcissists.jpg 333w, https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Wizard-of-Oz-and-Other-Narcissists-200x300.jpg 200w&quot; sizes=&quot;(max-width: 333px) 100vw, 333px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“A pragmatic little book on how to handle interactions with people who have narcissistic personality disorder, a DSM-V classification fitting about 1% of the population. Useful even if all you learn from it is how to spot them.” &lt;strong&gt;– Joe Betts-Lacroix&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Dark-Forest-Remembrance-Earths-Past/dp/0765386690/&quot;&gt;The Dark Forest (Remembrance of Earth’s Past)&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Dark-Forest-Remembrance-Earths-Past/dp/0765386690/&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Dark-Forest.jpg&quot; alt=&quot;&quot; width=&quot;330&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102651&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Dark-Forest.jpg 330w, https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Dark-Forest-198x300.jpg 198w&quot; sizes=&quot;(max-width: 330px) 100vw, 330px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“Book 2 of The Three Body Problem is great! I love the concept of a ‘wallfacer’ who has to solve a complex multi-year problem entirely in their own mind. First book was ok but long and confusing.” &lt;strong&gt;– Eric Migicovsky&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.wnycstudios.org/story/border-trilogy-part-1/&quot;&gt;Radiolab: Border Trilogy&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.wnycstudios.org/story/border-trilogy-part-1/&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Radiolab.jpg&quot; alt=&quot;Radiolab&quot; width=&quot;1860&quot; height=&quot;1240&quot; class=&quot;aligncenter size-full wp-image-1102656&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Radiolab.jpg 1860w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Radiolab-300x200.jpg 300w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Radiolab-768x512.jpg 768w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Radiolab-1024x683.jpg 1024w&quot; sizes=&quot;(max-width: 1860px) 100vw, 1860px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“Features Jason De Leon’s book, &lt;a href=&quot;https://www.amazon.com/Land-Open-Graves-California-Anthropology/dp/0520282752/&quot;&gt;Land of Open Graves&lt;/a&gt;. Does a really great job walking through how the US/Mexico border/immigration policies came to be the way they are now. Very moving podcast episode broken into three parts.” &lt;strong&gt;– Adele Gower&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Untethered-Soul-Journey-Beyond-Yourself/dp/1572245379&quot;&gt;The Untethered Soul&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Untethered-Soul-Journey-Beyond-Yourself/dp/1572245379&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Untethered-Soul.jpg&quot; alt=&quot;The Untethered Soul&quot; width=&quot;333&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102659&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Untethered-Soul.jpg 333w, https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Untethered-Soul-200x300.jpg 200w&quot; sizes=&quot;(max-width: 333px) 100vw, 333px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“This book does a nice job of repackaging Eastern philosophy concepts in words that appeal to the hyperational Westerner mindset.” &lt;strong&gt;– Daniel Gross&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Endure-Curiously-Elastic-Limits-Performance/dp/0062499866&quot;&gt;Endure: Mind, Body, and the Curiously Elastic Limits of Human Performance&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Endure-Curiously-Elastic-Limits-Performance/dp/0062499866&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Endure.jpg&quot; alt=&quot;Endure&quot; width=&quot;333&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102660&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Endure.jpg 333w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Endure-200x300.jpg 200w&quot; sizes=&quot;(max-width: 333px) 100vw, 333px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“If you like any form of endurance cardio, this book will be like crack candy for you. Warning: it’s fairly Gladwellian in style, which some may find displeasing.” &lt;strong&gt;– Daniel Gross&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Finite-Infinite-Games-James-Carse/dp/1476731713&quot;&gt;Finite and Infinite Games&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Finite-Infinite-Games-James-Carse/dp/1476731713&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Finite-and-Infinite-Games.jpg&quot; alt=&quot;Finite and Infinite Games&quot; width=&quot;328&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102661&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Finite-and-Infinite-Games.jpg 328w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Finite-and-Infinite-Games-197x300.jpg 197w&quot; sizes=&quot;(max-width: 328px) 100vw, 328px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“It’s hard to rationally explain the benefits of this book, but I find that many who read it really enjoy it. It gets you in the mode of thinking long term. And it provides a powerful shared language with those who read it (‘play the infinite game’).” &lt;strong&gt;– Daniel Gross&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/House-Getty-Russell-Miller/dp/1448204356&quot;&gt;The House of Getty&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/House-Getty-Russell-Miller/dp/1448204356&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-House-of-Getty.jpg&quot; alt=&quot;The House of Getty&quot; width=&quot;326&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102662&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-House-of-Getty.jpg 326w, https://blog.ycombinator.com/wp-content/uploads/2018/07/The-House-of-Getty-196x300.jpg 196w&quot; sizes=&quot;(max-width: 326px) 100vw, 326px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“Like all American titans, John Paul Getty is a mixed bag. He’s by no means perfect, but he was an undeniable empire builder. If you enjoyed reading about JP Morgan or John Rockefeller, you’ll enjoy this one as well.” &lt;strong&gt;– Daniel Gross&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Lost-Shangri-Mitchell-Zuckoff/dp/0061988359&quot;&gt;Lost in Shangri La&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Lost-Shangri-Mitchell-Zuckoff/dp/0061988359&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Lost-In-Shangri-La.jpg&quot; alt=&quot;&quot; width=&quot;332&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102663&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Lost-In-Shangri-La.jpg 332w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Lost-In-Shangri-La-200x300.jpg 200w&quot; sizes=&quot;(max-width: 332px) 100vw, 332px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“An awesome page turner based on a true story.” &lt;strong&gt;– Daniel Gross&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.gimletmedia.com/startup/arlan-hamilton-1-silicon-valley-by-invite-only&quot;&gt;Startup by Gimlet&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.gimletmedia.com/startup/arlan-hamilton-1-silicon-valley-by-invite-only&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/startup.jpeg&quot; alt=&quot;Startup&quot; width=&quot;330&quot; height=&quot;330&quot; class=&quot;aligncenter size-full wp-image-1102685&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/startup.jpeg 750w, https://blog.ycombinator.com/wp-content/uploads/2018/07/startup-150x150.jpeg 150w, https://blog.ycombinator.com/wp-content/uploads/2018/07/startup-300x300.jpeg 300w&quot; sizes=&quot;(max-width: 330px) 100vw, 330px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“It is interesting to hear someone from no experience break into this small cottage industry of Venture Capital in Silicon Valley. Note: I’m a small LP in Backstage.” &lt;strong&gt;– Holly Liu&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Dollars-Sense-Misthink-Money-Smarter/dp/006265120X&quot;&gt;Dollars and Sense&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Dollars-Sense-Misthink-Money-Smarter/dp/006265120X&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Dollars-and-Sense.jpg&quot; alt=&quot;Dollars and Sense&quot; width=&quot;331&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102686&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Dollars-and-Sense.jpg 331w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Dollars-and-Sense-199x300.jpg 199w&quot; sizes=&quot;(max-width: 331px) 100vw, 331px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“Interesting book on how we make financial decisions that are far from rationale. Why we will walk an extra mile to save $4 on coffee but not even flinch when we lose $50 at the casinos.” &lt;strong&gt;– Holly Liu&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Help-Kathryn-Stockett/dp/0425232204/&quot;&gt;The Help&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Help-Kathryn-Stockett/dp/0425232204&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Help.jpg&quot; alt=&quot;&quot; width=&quot;306&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102687&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Help.jpg 306w, https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Help-184x300.jpg 184w&quot; sizes=&quot;(max-width: 306px) 100vw, 306px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“This is just a great summer favorite read from a while ago, told in a time where racial lines looked different, from the eyes of two perspectives with destinies that intertwine more than they know as they help each other tell their stories.” &lt;strong&gt;– Holly Liu&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Eat-Sleep-Poop-Common-Sense/dp/1439117063&quot;&gt;Eat Sleep Poop&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Eat-Sleep-Poop-Common-Sense/dp/1439117063&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Eat-Sleep-Poop.jpg&quot; alt=&quot;Eat Sleep Poop&quot; width=&quot;331&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102664&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Eat-Sleep-Poop.jpg 331w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Eat-Sleep-Poop-199x300.jpg 199w&quot; sizes=&quot;(max-width: 331px) 100vw, 331px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“Great infant book for first time parents. Written by a doctor after having kids so provides well balanced practical advice.” &lt;strong&gt;– Michael Seibel&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Ready-Player-One-Ernest-Cline/dp/0307887448/&quot;&gt;Ready Player One&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Ready-Player-One-Ernest-Cline/dp/0307887448/&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Ready-Player-One.jpg&quot; alt=&quot;Ready Player One&quot; width=&quot;324&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102665&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Ready-Player-One.jpg 324w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Ready-Player-One-195x300.jpg 195w&quot; sizes=&quot;(max-width: 324px) 100vw, 324px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“This is the VR dream I had as a kid – taken to the next step.” &lt;strong&gt;– Michael Seibel&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Powerhouse-Untold-Hollywoods-Creative-Artists/dp/0062441388&quot;&gt;Powerhouse: The Untold Story of Hollywood’s Creative Artists Agency&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Powerhouse-Untold-Hollywoods-Creative-Artists/dp/0062441388&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Powerhouse.jpg&quot; alt=&quot;Powerhouse&quot; width=&quot;332&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102666&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Powerhouse.jpg 332w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Powerhouse-200x300.jpg 200w&quot; sizes=&quot;(max-width: 332px) 100vw, 332px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“An interesting history of the largest talent agency in the world.” &lt;strong&gt;– Michael Seibel&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Undoing-Project-Friendship-Changed-Minds/dp/0393354776&quot;&gt;The Undoing Project: A Friendship That Changed Our Minds&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Undoing-Project-Friendship-Changed-Minds/dp/0393354776&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Undoing-Project.jpg&quot; alt=&quot;The Undoing Project&quot; width=&quot;333&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102667&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Undoing-Project.jpg 333w, https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Undoing-Project-200x300.jpg 200w&quot; sizes=&quot;(max-width: 333px) 100vw, 333px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“The book is the story of the collaboration between Danny Kahneman, the Nobel Prize winning psychologist and author with Amos Tversky – and the extraordinary way they forced economists to completely rethink how human beings actually make decisions.” &lt;strong&gt;– Geoff Ralston&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Mind-Napoleon-Selection-Written-Spoken/dp/0231085230&quot;&gt;Mind of Napoleon: A Selection of His Written and Spoken Words&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Mind-Napoleon-Selection-Written-Spoken/dp/0231085230&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Mind-of-Napoleon.jpg&quot; alt=&quot;Mind of Napoleon&quot; width=&quot;336&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102672&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Mind-of-Napoleon.jpg 336w, https://blog.ycombinator.com/wp-content/uploads/2018/07/The-Mind-of-Napoleon-202x300.jpg 202w&quot; sizes=&quot;(max-width: 336px) 100vw, 336px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“An incredible primary-source portrait on a brilliant (but obviously deeply flawed) individual. Broadly applicable thoughts.” &lt;strong&gt;– Sam Altman&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Mans-Search-Meaning-Viktor-Frankl/dp/080701429X&quot;&gt;Man’s Search for Meaning&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Mans-Search-Meaning-Viktor-Frankl/dp/080701429X/&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Mans-Search-for-Meaning.jpg&quot; alt=&quot;Man's Search for Meaning&quot; width=&quot;309&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102673&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Mans-Search-for-Meaning.jpg 309w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Mans-Search-for-Meaning-186x300.jpg 186w&quot; sizes=&quot;(max-width: 309px) 100vw, 309px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“I first read this book years ago but it didn’t really resonate with me at the time. Last year, feeling somewhat despondent about the state of the world, I read the book again and found it to be tremendously helpful, the most important book I read all year.” &lt;strong&gt;– Paul Buchheit&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=8CrOL-ydFMI&quot;&gt;This is Water&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;iframe width=&quot;100%&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/8CrOL-ydFMI&quot; frameborder=&quot;0&quot; allow=&quot;autoplay; encrypted-media&quot; allowfullscreen=&quot;&quot;&gt;[embedded content]&lt;/iframe&gt;&lt;/p&gt;
&lt;p&gt;“David Foster Wallace’s commencement speech at Kenyon College. &lt;a href=&quot;http://bulletin-archive.kenyon.edu/x4280.html&quot;&gt;Transcript here&lt;/a&gt;. A helpful reminder on the importance of monitoring your thoughts.” &lt;strong&gt;– Craig Cannon&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Change-Your-Mind-Consciousness-Transcendence/dp/1594204225&quot;&gt;How to Change Your Mind&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Change-Your-Mind-Consciousness-Transcendence/dp/1594204225&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/How-to-Change-Your-Mind.jpg&quot; alt=&quot;How to Change Your Mind&quot; width=&quot;329&quot; height=&quot;499&quot; class=&quot;aligncenter size-full wp-image-1102675&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/How-to-Change-Your-Mind.jpg 329w, https://blog.ycombinator.com/wp-content/uploads/2018/07/How-to-Change-Your-Mind-198x300.jpg 198w&quot; sizes=&quot;(max-width: 329px) 100vw, 329px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“There’s been a wave of new writing and research on psychedelics since we released the podcast with &lt;a href=&quot;https://blog.ycombinator.com/researching-psilocybins-effects-on-depression-dr-rosalind-watts/&quot;&gt;Rosalind Watts on Psilocybin therapy&lt;/a&gt;. Pollan applies a healthy dose of science to a subject that’s often only described in woo-woo California terms.” &lt;strong&gt;– Craig Cannon&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;br/&gt;&lt;strong&gt;&lt;a href=&quot;https://www.amazon.com/Shoe-Dog-Memoir-Creator-Nike-ebook/dp/B0176M1A44&quot;&gt;Shoe Dog&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;/center&gt;
&lt;p&gt;&lt;a href=&quot;https://www.amazon.com/Shoe-Dog-Memoir-Creator-Nike-ebook/dp/B0176M1A44&quot;&gt;&lt;img src=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Shoe-Dog.jpg&quot; alt=&quot;Shoe Dog&quot; width=&quot;324&quot; height=&quot;500&quot; class=&quot;aligncenter size-full wp-image-1102676&quot; srcset=&quot;https://blog.ycombinator.com/wp-content/uploads/2018/07/Shoe-Dog.jpg 324w, https://blog.ycombinator.com/wp-content/uploads/2018/07/Shoe-Dog-194x300.jpg 194w&quot; sizes=&quot;(max-width: 324px) 100vw, 324px&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;“One of my favorite reads in a long time. Captivating story that takes you play-by-play in Nike’s ascension from a 22 year old’s unfleshed idea to a huge national brand. Great portrayal of how far grit, relentlessness, and creativity can get you.” &lt;strong&gt;– Matt Bogrand&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 24 Jul 2018 19:26:44 +0000</pubDate>
<dc:creator>craigcannon</dc:creator>
<og:title>YC’s 2018 Summer Reading List</og:title>
<og:url>https://blog.ycombinator.com/ycs-2018-summer-reading-list/</og:url>
<og:type>article</og:type>
<og:description>Our 2018 summer reading list. Featuring: Shoe Dog, How to Change Your Mind, Man's Search for Meaning, Mind of Napoleon, The Undoing Project, Powerhouse, Radiolab: Border Trilogy, Parable of the Sower, The Lathe of Heaven, H is for Hawk, and others.</og:description>
<og:image>https://blog.ycombinator.com/wp-content/uploads/2018/07/YCs-2018-Summer-Reading-List.png</og:image>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.ycombinator.com/ycs-2018-summer-reading-list/</dc:identifier>
</item>
<item>
<title>Apple releases software fix for MacBook Pro slowdown</title>
<link>https://sixcolors.com/post/2018/07/apple-releases-software-fix-for-macbook-pro-slowdown/</link>
<guid isPermaLink="true" >https://sixcolors.com/post/2018/07/apple-releases-software-fix-for-macbook-pro-slowdown/</guid>
<description>&lt;div class=&quot;column1&quot; readability=&quot;8&quot;&gt;
&lt;h3&gt;By Jason Snell&lt;/h3&gt;
&lt;p class=&quot;dateline&quot;&gt;July 24, 2018 10:00 AM PT&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;column2&quot; readability=&quot;42.105517241379&quot;&gt;

&lt;p&gt;&lt;img src=&quot;https://sixcolors.com/images/content/2018/macbook-speed-2018-6c.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;After a week of controversy following the posting of &lt;a href=&quot;https://www.youtube.com/watch?v=Dx8J125s4cg&quot;&gt;a video that claimed the new 15-inch MacBook Pro could experience massive slowdowns&lt;/a&gt;, Apple on Tuesday acknowledged that the slowdowns exist—and that they’re caused by a bug in the thermal management software of all the 2018 MacBook Pro models. That bug has been fixed in a software update that Apple says it’s pushing out to all 2018 MacBook Pro users as of Tuesday morning.&lt;/p&gt;
&lt;p&gt;Here’s the official Apple statement, furnished to Six Colors by an Apple spokesperson:&lt;/p&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;Following extensive performance testing under numerous workloads, we’ve identified that there is a missing digital key in the firmware that impacts the thermal management system and could drive clock speeds down under heavy thermal loads on the new MacBook Pro. A bug fix is included in today’s macOS High Sierra 10.13.6 Supplemental Update and is recommended. We apologize to any customer who has experienced less than optimal performance on their new systems. Customers can expect the new 15-inch MacBook Pro to be up to 70% faster, and the 13-inch MacBook Pro with Touch Bar to be up to 2X faster, as shown in the performance results on our website.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After YouTuber Dave Lee posted his video showing his new Core i9 MacBook Pro slowing to a crawl while exporting video from Adobe Premiere, as well as &lt;a href=&quot;https://9to5mac.com/2018/07/18/how-macbook-pro-throttles-with-final-cut-pro-x/&quot;&gt;reports that the processor on the new MacBook Pros was being throttled all the way down to 800MHz&lt;/a&gt;, the company launched an investigation (and contacted Lee for more information about his specific project and settings). Apple’s own internal performance testing hadn’t triggered the issue, which turns out to &lt;em&gt;not&lt;/em&gt; be app specific—Premiere, you’re out of the penalty box—and tends to affect heavy workloads that take place over an extended period of time.&lt;/p&gt;
&lt;p&gt;The good news is, this doesn’t appear to be evidence that &lt;a href=&quot;https://twitter.com/marcoarment/status/1019610632218439686&quot;&gt;Apple’s laptop design is incapable of handling fast chips&lt;/a&gt;, but that someone at Apple had a bad day and failed to include a specific digital key that caused a cascade of bad behaviors in some very specific circumstances. (All laptops throttle the performance of processors in order to regulate temperature, of course, but it’s not supposed to happen to anywhere near the extent seen in Lee’s video.)&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://support.apple.com/kb/DL1973?locale=en_US&quot;&gt;Tuesday’s Supplemental Update&lt;/a&gt; doesn’t seem to have any impact on performance—all of Apple’s previous claims (up to 70 percent of a speed boost on the 15-inch model versus last year’s version, and 2x the performance on the 13-inch compared to last year’s model) are still accurate. When given an opportunity to re-run his tests after applying the fix, Lee should find that his MacBook Pro is now clearly faster than last year’s model.&lt;/p&gt;

&lt;p&gt;[&lt;em&gt;If you appreciate articles like this one, help us continue doing Six Colors (and get some fun benefits) by &lt;a href=&quot;https://sixcolors.com/subscribe/&quot;&gt;becoming a Six Colors subscriber&lt;/a&gt;.&lt;/em&gt;]&lt;/p&gt;
&lt;/div&gt;
</description>
<pubDate>Tue, 24 Jul 2018 17:16:21 +0000</pubDate>
<dc:creator>shawndumas</dc:creator>
<og:title>Apple releases software fix for MacBook Pro slowdown</og:title>
<og:url>https://sixcolors.com/post/2018/07/apple-releases-software-fix-for-macbook-pro-slowdown/</og:url>
<og:type>article</og:type>
<og:image>https://sixcolors.com/images/content/2018/macbook-speed-2018-6c.jpg</og:image>
<og:description> After a week of controversy following the posting of a video that claimed the new 15-inch MacBook Pro could experience massive slowdowns, Apple on Tuesday acknowledged that the slowdowns exist—and that they’re caused by a bug in the therma...</og:description>
<dc:language>en-us</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://sixcolors.com/post/2018/07/apple-releases-software-fix-for-macbook-pro-slowdown/</dc:identifier>
</item>
<item>
<title> Google announces Cloud Build, its new continuous integration platform</title>
<link>https://techcrunch.com/2018/07/24/google-announces-cloud-build-its-new-continuous-integration-continuous-delivery-platform/</link>
<guid isPermaLink="true" >https://techcrunch.com/2018/07/24/google-announces-cloud-build-its-new-continuous-integration-continuous-delivery-platform/</guid>
<description>&lt;p&gt;It used to be that developers built applications with long lead times and development cycles. There was always plenty of time to prepare, but in today’s continuous delivery/continuous deployment (CI/CD) world, new versions could be going out every day. That requires a CI/CD framework, and today at &lt;a class=&quot;crunchbase-link&quot; href=&quot;https://www.crunchbase.com/organization/google/&quot; target=&quot;_blank&quot; data-type=&quot;organization&quot; data-entity=&quot;google&quot;&gt;Google&lt;/a&gt; Next in San Francisco, the company &lt;a href=&quot;https://cloud.google.com/cloud-build/&quot;&gt;announced Cloud Build, its new CI/CD framework&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As Google describes it, Cloud Build is the company’s “fully-managed Continuous Integration/Continuous Delivery (CI/CD) platform that lets you build, test, and deploy software quickly, at scale.”&lt;/p&gt;
&lt;p&gt;Cloud Build works across a variety of environments including VMs, serverless, Kubernetes, or Firebase. What’s more it supports Docker containers and it gives developers or operations the flexibility to build, test and deploy in an increasingly automated fashion.&lt;/p&gt;
&lt;p&gt;Google will allow you to use triggers to deploy, so that when certain conditions are met, the update will launch automatically. You can identify vulnerabilities in your packages before you deploy and you can build locally and deploy in the cloud if you so choose.&lt;/p&gt;
&lt;p&gt;If there are problems, Cloud Build provides analytics and insights to let you debug via build errors and warnings and filter those warnings to easily identify slow builds or those with other issues you want to see before deploying live.&lt;/p&gt;
&lt;p&gt;Google is offering a free version of Cloud Build with up to 120 build minutes per day at no cost. Additional build minutes will be billed at $0.0034 per minute.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://techcrunch.com/tag/google-cloud-next-2018&quot;&gt;&lt;img src=&quot;https://techcrunch.com/wp-content/uploads/2018/07/google-cloud-next-2018-banner.png&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 24 Jul 2018 16:55:20 +0000</pubDate>
<dc:creator>AnatMl2</dc:creator>
<og:title>Google announces Cloud Build, its new continuous integration and delivery platform</og:title>
<og:description>It used to be that developers built applications with long lead times and development cycles. There was always plenty of time to prepare, but in today’s continuous delivery/continuous deployment (CI/CD) world, new versions could be going out every day. That requires a CI/CD framework, and tod…</og:description>
<og:image>https://techcrunch.com/wp-content/uploads/2018/07/GettyImages-697538599-1.jpg?w=600</og:image>
<og:url>http://social.techcrunch.com/2018/07/24/google-announces-cloud-build-its-new-continuous-integration-continuous-delivery-platform/</og:url>
<og:type>article</og:type>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://techcrunch.com/2018/07/24/google-announces-cloud-build-its-new-continuous-integration-continuous-delivery-platform/</dc:identifier>
</item>
<item>
<title>Knative – Kubernetes-based platform to manage modern serverless workloads</title>
<link>https://cloud.google.com/knative/</link>
<guid isPermaLink="true" >https://cloud.google.com/knative/</guid>
<description>&lt;header class=&quot;cloud-hero&quot;&gt;&lt;div class=&quot;cloud-grid cloud-grid__no-gap cloud-hero__content&quot;&gt;
&lt;div class=&quot; cloud-grid__col is-12 cloud-hero__1up-content is-1__large--offset is-8__large&quot;&gt;
&lt;div class=&quot;content-set&quot;&gt;

&lt;p&gt;Kubernetes-based platform to build, deploy, and manage modern serverless workloads.&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;&lt;div class=&quot;cloud-section--border cloud-section&quot;&gt;
&lt;div class=&quot;cloud-section__spacer&quot;&gt;
&lt;section class=&quot;cloud-copy&quot;&gt;&lt;div class=&quot;cloud-grid--alternate cloud-copy__inner cloud-copy--60-40 cloud-grid--vertical-center&quot;&gt;
&lt;div class=&quot;cloud-grid__col cloud-copy--right cloud-grid__col--horizontal-center is-4 is-8--offset is-7__large--offset&quot;&gt;&lt;img src=&quot;https://cloud.google.com/images/knative/essential-base-primitives-for-all.png&quot; srcset=&quot;https://cloud.google.com/images/knative/essential-base-primitives-for-all_2x.png 2x&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-grid__col is-1__large--offset cloud-copy__text is-7 is-6__large&quot;&gt;
&lt;h2 class=&quot;cloud-headline2&quot;&gt;Essential base primitives for all&lt;/h2&gt;
&lt;p&gt;Knative provides a set of middleware components that are essential to build modern, source-centric, and container-based applications that can run anywhere: on premises, in the cloud, or even in a third-party data center. Knative components are built on Kubernetes and codify the best practices shared by successful real-world Kubernetes based frameworks. It enables developers to focus just on writing interesting code, without worrying about the “boring but difficult” parts of building, deploying, and managing an application.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-section__spacer&quot;&gt;
&lt;section class=&quot;cloud-copy&quot;&gt;&lt;div class=&quot;cloud-grid--alternate cloud-copy__inner cloud-copy--60-40 cloud-grid--vertical-center&quot;&gt;
&lt;div class=&quot;cloud-grid__col is-1__large--offset cloud-grid__col--horizontal-center is-4&quot;&gt;&lt;img src=&quot;https://cloud.google.com/images/knative/developer-friendly-software.png&quot; srcset=&quot;https://cloud.google.com/images/knative/developer-friendly-software_2x.png 2x&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-grid__col cloud-copy__text is-7 is-5--offset is-6__large&quot;&gt;
&lt;h3 class=&quot;cloud-headline3&quot;&gt;Developer-friendly software&lt;/h3&gt;
&lt;p&gt;Knative offers a set of reusable components that focus on solving many mundane but difficult tasks such as orchestrating source-to-container workflows, routing and managing traffic during deployment, auto-scaling your workloads, or binding running services to eventing ecosystems. Developers can even use familiar idioms, languages, and frameworks to deploy any workload: functions, applications, or containers.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-section__spacer&quot;&gt;
&lt;section class=&quot;cloud-copy&quot;&gt;&lt;div class=&quot;cloud-grid--alternate cloud-copy__inner cloud-copy--60-40 cloud-grid--vertical-center&quot;&gt;
&lt;div class=&quot;cloud-grid__col cloud-copy--right cloud-grid__col--horizontal-center is-4 is-8--offset is-7__large--offset&quot;&gt;&lt;img src=&quot;https://cloud.google.com/images/knative/supports-popular-development-patterns.png&quot; srcset=&quot;https://cloud.google.com/images/knative/supports-popular-development-patterns_2x.png 2x&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-grid__col is-1__large--offset cloud-copy__text is-7 is-6__large&quot;&gt;
&lt;h3 class=&quot;cloud-headline3&quot;&gt;Supports popular development patterns&lt;/h3&gt;
&lt;p&gt;Knative focuses on an idiomatic developer experience. It supports common development patterns such as GitOps, DockerOps, ManualOps, as well as tools and frameworks such as Django, Ruby on Rails, Spring, and many more.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-section__spacer&quot;&gt;
&lt;section class=&quot;cloud-copy&quot;&gt;&lt;div class=&quot;cloud-grid--alternate cloud-copy__inner cloud-copy--60-40 cloud-grid--vertical-center&quot;&gt;
&lt;div class=&quot;cloud-grid__col is-1__large--offset cloud-grid__col--horizontal-center is-4&quot;&gt;&lt;img src=&quot;https://cloud.google.com/images/knative/best-of-both-worlds.png&quot; srcset=&quot;https://cloud.google.com/images/knative/best-of-both-worlds_2x.png 2x&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-grid__col cloud-copy__text is-7 is-5--offset is-6__large&quot;&gt;
&lt;h3 class=&quot;cloud-headline3&quot;&gt;Best of both worlds: Flexibility and control&lt;/h3&gt;
&lt;p&gt;Knative is designed to plug easily into existing build and CI/CD toolchains. By focusing on open-source-first technologies that run anywhere, on any cloud, on any infrastructure supported by Kubernetes, enterprises are free to move their workloads wherever they run best. This offers the flexibility and control customers need to adapt the system to their own unique requirements.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-section__spacer&quot;&gt;
&lt;section class=&quot;cloud-copy&quot;&gt;&lt;div class=&quot;cloud-grid--alternate cloud-copy__inner cloud-copy--60-40 cloud-grid--vertical-center&quot;&gt;
&lt;div class=&quot;cloud-grid__col cloud-copy--right cloud-grid__col--horizontal-center is-4 is-8--offset is-7__large--offset&quot;&gt;&lt;img src=&quot;https://cloud.google.com/images/knative/operator-friendly.png&quot; srcset=&quot;https://cloud.google.com/images/knative/operator-friendly_2x.png 2x&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-grid__col is-1__large--offset cloud-copy__text is-7 is-6__large&quot;&gt;
&lt;h3 class=&quot;cloud-headline3&quot;&gt;Operator-friendly&lt;/h3&gt;
&lt;p&gt;Knative is designed to be run as a service by all major cloud providers. Google currently works with industry leaders such as Pivotal, IBM, SAP, and many others to create the building blocks that will best suit the needs of developers. Knative powers real world workloads and is also compatible with other cutting edge technologies such as Kubernetes and Istio.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;&lt;/div&gt;
&lt;div&gt;
&lt;section class=&quot;cloud-copy&quot;&gt;&lt;div class=&quot;cloud-grid--alternate cloud-copy__inner cloud-copy--60-40 cloud-grid--vertical-center&quot;&gt;
&lt;div class=&quot;cloud-grid__col is-1__large--offset cloud-grid__col--horizontal-center is-4&quot;&gt;&lt;img src=&quot;https://cloud.google.com/images/knative/kubernetes-engine.png&quot; srcset=&quot;https://cloud.google.com/images/knative/kubernetes-engine_2x.png 2x&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-grid__col cloud-copy__text is-7 is-5--offset is-6__large&quot;&gt;
&lt;h3 class=&quot;cloud-headline3&quot;&gt;Run your serverless workloads on Kubernetes Engine&lt;/h3&gt;
&lt;p&gt;You can now run your serverless workloads on Google Kubernetes Engine (GKE) by enabling the serverless add-on. Powered by Knative, the serverless add-on helps developers orchestrate builds, serving, and events with a single click, enabling the benefits of an idiomatic developer experience with the flexibility and control of GKE.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cloud-section--border&quot;&gt;
&lt;section class=&quot;cloud-pricing cloud-pricing--table&quot;&gt;&lt;div class=&quot;cloud-grid&quot;&gt;
&lt;div class=&quot;cloud-grid__col is-12 is-10__large is-1__large--offset&quot;&gt;
&lt;div class=&quot;cloud-pricing__header&quot;&gt;
&lt;h3 class=&quot;cloud-headline3&quot;&gt;Knative features&lt;/h3&gt;
&lt;/div&gt;

&lt;div class=&quot;cloud-pricing__table&quot;&gt;
&lt;div class=&quot;cloud-table-wrapper devsite-table-wrapper&quot;&gt;
&lt;table class=&quot;cloud-table cloud-body-text&quot;&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Feature Name&lt;/th&gt;
&lt;th&gt;Feature Description&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Serving&lt;/td&gt;
&lt;td&gt;Scale to zero, request-driven compute model&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Build&lt;/td&gt;
&lt;td&gt;Cloud-native source to container orchestration&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Events&lt;/td&gt;
&lt;td&gt;Universal subscription, delivery and management of events&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Serverless add-on on GKE&lt;/td&gt;
&lt;td&gt;Enable GCP managed serverless stack on Kubernetes&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;&lt;/div&gt;
&lt;div&gt;
&lt;section class=&quot;cloud-quote cloud-quote--yellow&quot;&gt;&lt;div class=&quot;cloud-quote__tile cloud-grid cloud-grid__no-gap&quot;&gt;
&lt;blockquote class=&quot;cloud-quote__tile-body is-12 is-9__large&quot;&gt;
&lt;p class=&quot;cloud-quote__quote cloud-quote-text&quot;&gt;Knative helps our developers focus on building the business logic rather than worrying about building low-level platform capabilities such as build, deploy, autoscaling, monitoring, and observability. For example, our T-Mobile store locator app developed in Java/Vert.x was easy to migrate to GCP using Knative. We did that in just a sprint as Knative provided lot of platform-level capabilities that our developers did not have to build.&lt;/p&gt;
&lt;cite class=&quot;cloud-quote__author cloud-body-text__small&quot;&gt;Ram Gopinathan, Principal Technology Architect, T-Mobile&lt;/cite&gt;&lt;/blockquote&gt;
&lt;div class=&quot;cloud-quote__resources is-12 is-3__large&quot;&gt;
&lt;div class=&quot;cloud-quote__resource cloud-quote__resource--logo&quot;&gt;&lt;img alt=&quot;Customer Name&quot; src=&quot;https://cloud.google.com/images/knative/t-mobile-icon.png&quot; srcset=&quot;https://cloud.google.com/images/knative/t-mobile-icon_2x.png 2x&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/section&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-section--border cloud-section&quot;&gt;

&lt;div class=&quot;cloud-card__container cloud-card__container--3up&quot;&gt;
&lt;div class=&quot;cloud-card&quot;&gt;
&lt;div class=&quot;cloud-card__icon cloud-card__top&quot;&gt;&lt;img src=&quot;https://cloud.google.com/images/knative/install-knative-icon.svg&quot; alt=&quot;&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-card__content&quot;&gt;
&lt;h4 class=&quot;cloud-headline4&quot;&gt;Install Knative&lt;/h4&gt;
&lt;p class=&quot;cloud-body-text__small&quot;&gt;Installation guide for the latest version of Knative using pre-built images&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cloud-card&quot;&gt;
&lt;div class=&quot;cloud-card__icon cloud-card__top&quot;&gt;&lt;img src=&quot;https://cloud.google.com/images/knative/knative-docs-icon.svg&quot; alt=&quot;&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-card__content&quot;&gt;
&lt;h4 class=&quot;cloud-headline4&quot;&gt;Knative Docs&lt;/h4&gt;
&lt;p class=&quot;cloud-body-text__small&quot;&gt;Get a quick overview of Knative and its components&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cloud-card&quot;&gt;
&lt;div class=&quot;cloud-card__icon cloud-card__top&quot;&gt;&lt;img src=&quot;https://cloud.google.com/images/knative/developer-resources-icon.svg&quot; alt=&quot;&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-card__content&quot;&gt;
&lt;h4 class=&quot;cloud-headline4&quot;&gt;Developer resources&lt;/h4&gt;
&lt;p class=&quot;cloud-body-text__small&quot;&gt;Hello world code samples for popular languages&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cloud-card&quot;&gt;
&lt;div class=&quot;cloud-card__icon cloud-card__top&quot;&gt;&lt;img src=&quot;https://cloud.google.com/images/knative/knative-build-icon.svg&quot; alt=&quot;&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-card__content&quot;&gt;
&lt;h4 class=&quot;cloud-headline4&quot;&gt;Knative build&lt;/h4&gt;
&lt;p class=&quot;cloud-body-text__small&quot;&gt;Source to container build and orchestration of workflows&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cloud-card&quot;&gt;
&lt;div class=&quot;cloud-card__icon cloud-card__top&quot;&gt;&lt;img src=&quot;https://cloud.google.com/images/knative/build-templates-icon.svg&quot; alt=&quot;&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-card__content&quot;&gt;
&lt;h4 class=&quot;cloud-headline4&quot;&gt;Build templates&lt;/h4&gt;
&lt;p class=&quot;cloud-body-text__small&quot;&gt;Choose from a library of build templates&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cloud-card&quot;&gt;
&lt;div class=&quot;cloud-card__icon cloud-card__top&quot;&gt;&lt;img src=&quot;https://cloud.google.com/images/knative/eventing-icon.svg&quot; alt=&quot;&quot;/&gt;&lt;/div&gt;
&lt;div class=&quot;cloud-card__content&quot;&gt;
&lt;h4 class=&quot;cloud-headline4&quot;&gt;Eventing&lt;/h4&gt;
&lt;p class=&quot;cloud-body-text__small&quot;&gt;Specification and implementation of Knative event binding and delivery&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cloud-section--border cloud-section&quot;&gt;
&lt;div class=&quot;cloud-text-center cloud-section__spacer&quot;&gt;
&lt;h2 class=&quot;cloud-headline2&quot;&gt;Community Resources&lt;/h2&gt;
&lt;/div&gt;
&lt;div class=&quot;cloud-card__container&quot;&gt;
&lt;div class=&quot;cloud-card&quot;&gt;
&lt;div class=&quot;cloud-card__content&quot;&gt;
&lt;h4 class=&quot;cloud-headline4&quot;&gt;Join the conversation&lt;/h4&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cloud-card&quot;&gt;
&lt;div class=&quot;cloud-card__content&quot;&gt;
&lt;h4 class=&quot;cloud-headline4&quot;&gt;Contribute today&lt;/h4&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;div class=&quot;cloud-card&quot;&gt;
&lt;div class=&quot;cloud-card__content&quot;&gt;
&lt;h4 class=&quot;cloud-headline4&quot;&gt;Get the latest news&lt;/h4&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cloud-button__set cloud-text-center cloud-section--border cloud-section&quot;&gt;&lt;a href=&quot;https://github.com/knative/&quot; class=&quot;cloud-button cloud-button--primary&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;VIEW GITHUB REPO&lt;/a&gt; &lt;a href=&quot;https://docs.google.com/forms/d/e/1FAIpQLSdG5cCIiHhkW7srw9MWvdiLEsLXwJES1R3lnKgAn-opy3_iuQ/viewform&quot; class=&quot;cloud-button cloud-button--secondary&quot; track-type=&quot;navigateTo&quot; track-name=&quot;earlyAdopterProgram&quot; track-metadata-eventdetail=&quot;bottom&quot; track-metadata-position=&quot;bottom&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;TRY GKE SERVERLESS ADD-ON&lt;/a&gt;&lt;/div&gt;
</description>
<pubDate>Tue, 24 Jul 2018 16:12:11 +0000</pubDate>
<dc:creator>dankohn1</dc:creator>
<og:type>website</og:type>
<og:url>https://cloud.google.com/knative/</og:url>
<og:title>Knative - Built on Kubernetes and Istio  |  Google Cloud</og:title>
<og:description>Knative is a Google-sponsored industry-wide project to establish the best building blocks for creating modern, Kubernetes-native cloud-based software</og:description>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://cloud.google.com/knative/</dc:identifier>
</item>
<item>
<title>Portable Cloud Programming with Go Cloud</title>
<link>https://blog.golang.org/go-cloud</link>
<guid isPermaLink="true" >https://blog.golang.org/go-cloud</guid>
<description>&lt;p class=&quot;date&quot;&gt;24 July 2018&lt;/p&gt;
&lt;h4 id=&quot;TOC_1.&quot;&gt;Introduction&lt;/h4&gt;
&lt;p&gt;Today, the Go team at Google is releasing a new open source project, &lt;a href=&quot;https://github.com/google/go-cloud&quot; target=&quot;_blank&quot;&gt;Go Cloud&lt;/a&gt;, a library and tools for developing on the &lt;a href=&quot;https://cloud.google.com/open-cloud/&quot; target=&quot;_blank&quot;&gt;open cloud&lt;/a&gt;. With this project, we aim to make Go the language of choice for developers building portable cloud applications.&lt;/p&gt;
&lt;p&gt;This post explains why we started this project, the details of how Go Cloud works, and how to get involved.&lt;/p&gt;
&lt;h4 id=&quot;TOC_2.&quot;&gt;Why portable cloud programming? Why now?&lt;/h4&gt;
&lt;p&gt;We estimate there are now &lt;a href=&quot;https://research.swtch.com/gophercount&quot; target=&quot;_blank&quot;&gt;over one million&lt;/a&gt; Go developers worldwide. Go powers many of the most critical cloud infrastructure projects, including Kubernetes, Istio, and Docker. Companies like Lyft, Capital One, Netflix and &lt;a href=&quot;https://github.com/golang/go/wiki/GoUsers&quot; target=&quot;_blank&quot;&gt;many more&lt;/a&gt; are depending on Go in production. Over the years, we've found that developers love Go for cloud development because of its efficiency, productivity, built-in concurrency, and low latency.&lt;/p&gt;
&lt;p&gt;As part of our work to support Go's rapid growth, we have been interviewing teams who work with Go to understand how they use the language and how the Go ecosystem can improve further. One common theme with many organizations is the need for portability across cloud providers. These teams want to deploy robust applications in &lt;a href=&quot;https://en.wikipedia.org/wiki/Cloud_computing#Multicloud&quot; target=&quot;_blank&quot;&gt;multi-cloud&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Cloud_computing#Hybrid_cloud&quot; target=&quot;_blank&quot;&gt;hybrid-cloud&lt;/a&gt; environments, and migrate their workloads between cloud providers without significant changes to their code.&lt;/p&gt;
&lt;p&gt;To achieve this, some teams attempt to decouple their applications from provider-specific APIs in order to produce simpler and more portable code. However the short-term pressure to ship features means teams often sacrifice longer-term efforts toward portability. As a result, most Go applications running in the cloud are tightly coupled to their initial cloud provider.&lt;/p&gt;
&lt;p&gt;As an alternative, teams can use Go Cloud, a set of open generic cloud APIs, to write simpler and more portable cloud applications. Go Cloud also sets the foundation for an ecosystem of portable cloud libraries to be built on top of these generic APIs. Go Cloud makes it possible for teams to meet their feature development goals while also preserving the long-term flexibility for multi-cloud and hybrid-cloud architectures. Go Cloud applications can also migrate to the cloud providers that best meet their needs.&lt;/p&gt;
&lt;h4 id=&quot;TOC_3.&quot;&gt;What is Go Cloud?&lt;/h4&gt;
&lt;p&gt;We have identified common services used by cloud applications and have created generic APIs to work across cloud providers. Today, Go Cloud is launching with blob storage, MySQL database access, runtime configuration, and an HTTP server configured with request logging, tracing, and health checking. Go Cloud offers support for Google Cloud Platform (GCP) and Amazon Web Services (AWS). We plan to work with cloud industry partners and the Go community to add support for additional cloud providers very soon.&lt;/p&gt;
&lt;p&gt;Go Cloud aims to develop vendor-neutral generic APIs for the most-used services across cloud providers such that deploying a Go application on another cloud is simple and easy. Go Cloud also lays the foundation for other open source projects to write cloud libraries that work across providers. Community feedback, from all types of developers at all levels, will inform the priority of future APIs in Go Cloud.&lt;/p&gt;
&lt;h4 id=&quot;TOC_4.&quot;&gt;How does it work?&lt;/h4&gt;
&lt;p&gt;At the core of Go Cloud is a collection of generic APIs for portable cloud programming. Let's look at an example of using blob storage. You can use the generic type &lt;a href=&quot;https://godoc.org/github.com/google/go-cloud/blob#Bucket&quot; target=&quot;_blank&quot;&gt;&lt;code&gt;*blob.Bucket&lt;/code&gt;&lt;/a&gt; to copy a file from a local disk to a cloud provider. Let's start by opening an S3 bucket using the included &lt;a href=&quot;https://godoc.org/github.com/google/go-cloud/blob/s3blob&quot; target=&quot;_blank&quot;&gt;s3blob package&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&quot;code&quot; readability=&quot;16&quot;&gt;
&lt;pre&gt;
// setupBucket opens an AWS bucket.
func setupBucket(ctx context.Context) (*blob.Bucket, error) {
    // Obtain AWS credentials.
    sess, err := session.NewSession(&amp;amp;aws.Config{
        Region: aws.String(&quot;us-east-2&quot;),
    })
    if err != nil {
        return nil, err
    }
    // Open a handle to s3://go-cloud-bucket.
    return s3blob.OpenBucket(ctx, sess, &quot;go-cloud-bucket&quot;)
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Once a program has a &lt;code&gt;*blob.Bucket&lt;/code&gt;, it can create a &lt;code&gt;*blob.Writer&lt;/code&gt;, which implements &lt;code&gt;io.Writer&lt;/code&gt;. From there, the program can use the &lt;code&gt;*blob.Writer&lt;/code&gt; to write data to the bucket, checking that &lt;code&gt;Close&lt;/code&gt; does not report an error.&lt;/p&gt;
&lt;div class=&quot;code&quot; readability=&quot;21&quot;&gt;
&lt;pre&gt;
ctx := context.Background()
b, err := setupBucket(ctx)
if err != nil {
    log.Fatalf(&quot;Failed to open bucket: %v&quot;, err)
}
data, err := ioutil.ReadFile(&quot;gopher.png&quot;)
if err != nil {
    log.Fatalf(&quot;Failed to read file: %v&quot;, err)
}
w, err := b.NewWriter(ctx, &quot;gopher.png&quot;, nil)
if err != nil {
    log.Fatalf(&quot;Failed to obtain writer: %v&quot;, err)
}
_, err = w.Write(data)
if err != nil {
    log.Fatalf(&quot;Failed to write to bucket: %v&quot;, err)
}
if err := w.Close(); err != nil {
    log.Fatalf(&quot;Failed to close: %v&quot;, err)
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Notice how the logic of using the bucket does not refer to AWS S3. Go Cloud makes swapping out cloud storage a matter of changing the function used to open the &lt;code&gt;*blob.Bucket&lt;/code&gt;. The application could instead use Google Cloud Storage by constructing a &lt;code&gt;*blob.Bucket&lt;/code&gt; using &lt;a href=&quot;https://godoc.org/github.com/google/go-cloud/blob/gcsblob#OpenBucket&quot; target=&quot;_blank&quot;&gt;&lt;code&gt;gcsblob.OpenBucket&lt;/code&gt;&lt;/a&gt; without changing the code that copies the file:&lt;/p&gt;
&lt;div class=&quot;code&quot; readability=&quot;18&quot;&gt;
&lt;pre&gt;
// setupBucket opens a GCS bucket.
func setupBucket(ctx context.Context) (*blob.Bucket, error) {
    // Open GCS bucket.
    creds, err := gcp.DefaultCredentials(ctx)
    if err != nil {
        return nil, err
    }
    c, err := gcp.NewHTTPClient(gcp.DefaultTransport(), gcp.CredentialsTokenSource(creds))
    if err != nil {
        return nil, err
    }
    // Open a handle to gs://go-cloud-bucket.
    return gcsblob.OpenBucket(ctx, &quot;go-cloud-bucket&quot;, c)
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While different steps are needed to access buckets on different cloud providers, the resulting type used by your application is the same: &lt;code&gt;*blob.Bucket&lt;/code&gt;. This isolates application code from cloud-specific code. To increase interoperability with existing Go libraries, Go Cloud leverages established interfaces like &lt;code&gt;io.Writer&lt;/code&gt;, &lt;code&gt;io.Reader&lt;/code&gt;, and &lt;code&gt;*sql.DB&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The setup code needed to access cloud services tends to follow a pattern: higher abstractions are constructed from more basic abstractions. While you could write this code by hand, Go Cloud automates this with &lt;strong&gt;Wire&lt;/strong&gt;, a tool that generates cloud-specific setup code for you. The &lt;a href=&quot;https://github.com/google/go-cloud/tree/master/wire&quot; target=&quot;_blank&quot;&gt;Wire documentation&lt;/a&gt; explains how to install and use the tool and the &lt;a href=&quot;https://github.com/google/go-cloud/tree/master/samples/guestbook&quot; target=&quot;_blank&quot;&gt;Guestbook sample&lt;/a&gt; shows Wire in action.&lt;/p&gt;
&lt;h4 id=&quot;TOC_5.&quot;&gt;How can I get involved and learn more?&lt;/h4&gt;
&lt;p&gt;To get started, we recommend following &lt;a href=&quot;https://github.com/google/go-cloud/tree/master/samples/tutorial&quot; target=&quot;_blank&quot;&gt;the tutorial&lt;/a&gt; and then trying to build an application yourself. If you're already using AWS or GCP, you can try migrating parts of your existing application to use Go Cloud. If you're using a different cloud provider or an on-premise service, you can extend Go Cloud to support it by implementing the driver interfaces (like &lt;a href=&quot;https://godoc.org/github.com/google/go-cloud/blob/driver#Bucket&quot; target=&quot;_blank&quot;&gt;&lt;code&gt;driver.Bucket&lt;/code&gt;&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;We appreciate any and all input you have about your experience. &lt;a href=&quot;https://github.com/google/go-cloud&quot; target=&quot;_blank&quot;&gt;Go Cloud's&lt;/a&gt; development is conducted on GitHub. We are looking forward to contributions, including pull requests. &lt;a href=&quot;https://github.com/google/go-cloud/issues/new&quot; target=&quot;_blank&quot;&gt;File an issue&lt;/a&gt; to tell us what could be better or what future APIs the project should support. For updates and discussion about the project, join &lt;a href=&quot;https://groups.google.com/forum/#!forum/go-cloud&quot; target=&quot;_blank&quot;&gt;the project's mailing list&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The project requires contributors to sign the same Contributor License Agreement as that of the Go project. Read the &lt;a href=&quot;https://github.com/google/go-cloud/blob/master/CONTRIBUTING.md&quot; target=&quot;_blank&quot;&gt;contribution guidelines&lt;/a&gt; for more details. Please note, Go Cloud is covered by the Go &lt;a href=&quot;https://github.com/google/go-cloud/blob/master/CODE_OF_CONDUCT.md&quot; target=&quot;_blank&quot;&gt;Code of Conduct&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Thank you for taking the time to learn about Go Cloud, we are excited to work with you to make Go the language of choice for developers building portable cloud applications.&lt;/p&gt;
&lt;p class=&quot;author&quot;&gt;By Eno Compton and Cassandra Salisbury&lt;/p&gt;
</description>
<pubDate>Tue, 24 Jul 2018 15:38:41 +0000</pubDate>
<dc:creator>ArmandGrillet</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://blog.golang.org/go-cloud</dc:identifier>
</item>
<item>
<title>The Free Stack – Running Your Application for Free on AWS</title>
<link>http://p.agnihotry.com/post/the_free_stack_aws/</link>
<guid isPermaLink="true" >http://p.agnihotry.com/post/the_free_stack_aws/</guid>
<description>&lt;div class=&quot;box&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;img itemprop=&quot;thumbnail&quot; src=&quot;https://res.cloudinary.com/pagnihotry/image/upload/v1532367462/pagnihotry/AWS_logo.png&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;We live in interesting times. The cloud offerings from Amazon, Google and Microsoft have led to a situation where world-class infrastructure is available to startups and solopreneurs for very cheap, and most of the times, they can even get started for free.&lt;/p&gt;
&lt;p&gt;While standing up a business, it is critical to have a lean operation with a performant, stable and scalable product. This reduces user churn and increases retention. It is important that the online service you provide has high uptime without costing too much and reducing your runway.&lt;/p&gt;
&lt;p&gt;In this post, I outline an AWS based architecture which you can most likely run for free during at least the first 12 months and then for a few dollars per month while you build traction for your product. The cost really depends on the amount of traffic you serve and how your application is architected. But, more traffic is hopefully more revenue, which is a good problem to have!&lt;/p&gt;
&lt;p&gt;I also discuss estimating the monthly bill based on some assumptions mentioned in the following section. Hopefully, it will help you evaluate various scenarios specific to your product or service for a more predictable bill from your cloud provider.&lt;/p&gt;

&lt;p&gt;While calculating the price, I assume the website or service gets about 1,000 user sessions a day and in every session, the user makes 50 API requests and 50 requests to static assets (Images, HTML, CSS and Javascript files). The average size of static assets is 50kb, execution time of application code is less than or equal to 100ms per request and memory usage is less than or equal to 128MB per request. The average size of a read from DynamoDB is 20kb and write is 20KB per second. The total size of stored assets on S3 is 15GB and the traffic is split as approximately 50% from US &amp;amp; Canada and 50% from Europe&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;The pricing I discuss in this post is for AWS US-West (Oregon) region. The prices for other regions may vary.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;box&quot;&gt;
&lt;div class=&quot;img&quot;&gt;&lt;img itemprop=&quot;thumbnail&quot; src=&quot;https://res.cloudinary.com/pagnihotry/image/upload/v1532367730/pagnihotry/AWS_stack.png&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;ol&gt;&lt;li&gt;API Gateway&lt;/li&gt;
&lt;li&gt;Lambda&lt;/li&gt;
&lt;li&gt;DynamoDB&lt;/li&gt;
&lt;li&gt;S3&lt;/li&gt;
&lt;li&gt;CloudFront&lt;/li&gt;
&lt;li&gt;DNS &amp;amp; Route 53&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;api-gateway&quot;&gt;API Gateway&lt;/h2&gt;
&lt;p&gt;API Gateway is the service to create APIs to access AWS resources. In this setup, API Gateway is used to invoke a function in AWS Lambda. This service forwards the request parameters to AWS Lambda which then, executes the application code and returns a response that is forwarded to the user.&lt;/p&gt;
&lt;p&gt;Usage for this service is calculated as a mix of the number of API calls per month and the amount of data transferred.&lt;/p&gt;
&lt;p&gt;Product link: &lt;a href=&quot;https://aws.amazon.com/api-gateway/&quot;&gt;https://aws.amazon.com/api-gateway/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;pricing&quot;&gt;Pricing&lt;/h3&gt;
&lt;h4 id=&quot;free-tier-12-months&quot;&gt;Free Tier - 12 Months&lt;/h4&gt;
&lt;p&gt;This service offers 1 million API calls/month in its Free Tier, which means it can support 666 user sessions per day in the Free Tier assuming each user makes about 50 API calls in a session. The Free Tier for this service expires after 12 months.&lt;/p&gt;
&lt;h4 id=&quot;after-free-tier&quot;&gt;After Free Tier&lt;/h4&gt;
&lt;p&gt;After the 12 month Free Tier expires, AWS charges $3.50 per million calls and $0.09/GB for first 10 TB. If you expect 1,000 user sessions a day making 50 requests with an average data transfer of 50KB, it adds up to 1.5 Million API calls and 75GB of data transfer per month. Which should cost $12 per month (&lt;code&gt;1.5M*$3.50/M + 75GB*$0.09/GB = $5.25 + $6.75&lt;/code&gt;) .&lt;/p&gt;
&lt;p&gt;More on pricing: &lt;a href=&quot;https://aws.amazon.com/api-gateway/pricing/&quot;&gt;https://aws.amazon.com/api-gateway/pricing/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;aws-lambda&quot;&gt;AWS Lambda&lt;/h2&gt;
&lt;p&gt;Lambda is the serverless offering of AWS where you can implement functions that are invoked by the API Gateway. The code can be edited inline or uploaded to S3. The usage for this service is defined as a mix of 2 things: number of requests and duration.&lt;/p&gt;
&lt;p&gt;The number of requests is pretty straightforward. Where it can get interesting is the duration which is measured in GB-seconds. To calculate GB-seconds for your application, you would multiply the memory usage to the time taken by a request to execute. This is discussed more in the pricing section.&lt;/p&gt;
&lt;p&gt;AWS Lambda also enforces certain memory and time limits. This is particularly important while calculating the duration. Minimum memory usage of any function is set at 128 MB and the maximum is 3008 MB (with 64 MB increments). If the maximum memory use is exceeded, function invocation is terminated. Similarly, it also measures time in increments of 100ms with a minimum of 100ms and maximum of 300s (5 minutes) in increments of 100ms (more on Lambda limits: &lt;a href=&quot;https://docs.aws.amazon.com/lambda/latest/dg/limits.html&quot;&gt;https://docs.aws.amazon.com/lambda/latest/dg/limits.html&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Product link: &lt;a href=&quot;https://aws.amazon.com/lambda&quot;&gt;https://aws.amazon.com/lambda&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;pricing-1&quot;&gt;Pricing&lt;/h3&gt;
&lt;h4 id=&quot;free-tier&quot;&gt;Free Tier&lt;/h4&gt;
&lt;p&gt;This service is free for 1M request/month, and 400,000 GB-seconds/month of compute time. This Free Tier does not expire after 12 months.&lt;/p&gt;
&lt;p&gt;For instance, if your request executes in 60ms consuming 100MB, AWS lambda will bill you for 100ms and 128MB memory, you would be able to serve 31,250,000 requests (&lt;code&gt;400,000 GB-seconds/100ms*128MB&lt;/code&gt;). 1,000 users sessions with 50 requests a day translates to 1,500,000 requests a month which is well below the Free Tier limits.&lt;/p&gt;
&lt;h4 id=&quot;after-free-tier-1&quot;&gt;After Free Tier&lt;/h4&gt;
&lt;p&gt;Once your application makes 1M requests AWS charges $0.0000002 per request and after exceeding 400,000 GB-seconds, $0.00001667 for every GB-Second used thereafter. For instance, if your request executes in 100ms and consumes 128MB, each request takes in 0.0128 GB-Second. Cost per request comes out to be $0.000000413376 (&lt;code&gt;$0.0000002 + 0.0128*$0.00001667&lt;/code&gt;) translating to $0.413376/1M requests.&lt;/p&gt;
&lt;p&gt;More on pricing: &lt;a href=&quot;https://aws.amazon.com/lambda/pricing/&quot;&gt;https://aws.amazon.com/lambda/pricing/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;dynamodb&quot;&gt;DynamoDB&lt;/h2&gt;
&lt;p&gt;Dynamo DB is a NoSQL database offered as a service by AWS. DynamoDB defines usage in terms of read and write capacity. 1 write capacity means 1 write/second in 1 KB block and 1 read capacity means 1 strongly consistent read per second, or 2 eventually consistent reads per second in 4KB blocks. This means if you read 1 KB in 4 requests it counts as 4 reads compared to reading a bigger chunk, say 3KB in one request, which is considered 1 read.&lt;/p&gt;
&lt;p&gt;Data transfer within the same region to other AWS services is free. Reads and writes are averaged in 5 min intervals to calculate the per second values. Estimating the price for this service can get a little complicated. To get a clear picture, try to estimate the amount of the indexed data you will store and the access patterns - reads and writes per second.&lt;/p&gt;
&lt;p&gt;Product link: &lt;a href=&quot;https://aws.amazon.com/dynamodb/&quot;&gt;https://aws.amazon.com/dynamodb/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;pricing-2&quot;&gt;Pricing&lt;/h3&gt;
&lt;h4 id=&quot;free-tier-1&quot;&gt;Free Tier&lt;/h4&gt;
&lt;p&gt;In the Free Tier, AWS DynamoDB offers 25 GB of indexed storage, 25 units of write capacity and 25 units of read capacity. Data transfer is free within the same region. This Free Tier does not expire after 12 months.&lt;/p&gt;
&lt;h3 id=&quot;after-free-tier-2&quot;&gt;After Free Tier&lt;/h3&gt;
&lt;p&gt;Once you exceed the Free Tier, the following is the pricing:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;$0.00065 WCU per hour&lt;/li&gt;
&lt;li&gt;$0.00013 RCU per hour&lt;/li&gt;
&lt;li&gt;$0.25 per GB-month after 25GB&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;If you are storing 20KB user data for every user, you can store data for 1.25 million users under the Free Tier limits and $0.000025 per user thereafter.&lt;/p&gt;
&lt;p&gt;If you are reading all the 20KB of data for a user per second, strongly consistent, that is 20KB per second. It translates to 5 Read Capacity (&lt;code&gt;20KB/4KB&lt;/code&gt;), which is covered by the Free Tier and you still have 20 more read capacity to spare. For every additional user read per second past the Free Tier, it will cost $0.468 per month (&lt;code&gt;5RCU * (30*24)hours * $0.00013 RCU/hour&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;Similarly, for writes, 20KB write per second translates to 20 write capacity, which is also covered in Free Tier with 5 write capacity to spare. After the Free Tier, you can expect a full write of 20KB per second to cost $9.36 per month (&lt;code&gt;20 RCU * (30*24) hours * 0.00065 WCU/hour&lt;/code&gt;)&lt;/p&gt;
&lt;p&gt;Most of the applications are read heavy, which means that they do more reads than writes, in the above example we assumed 1 write for every read.&lt;/p&gt;
&lt;p&gt;More on pricing: &lt;a href=&quot;https://aws.amazon.com/dynamodb/pricing/&quot;&gt;https://aws.amazon.com/dynamodb/pricing/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;s3&quot;&gt;S3&lt;/h2&gt;
&lt;p&gt;AWS S3 can be used to store static content like HTML, CSS, JS files or code for lambda function. The usage for this service is defined in terms of Storage used in GB, number of requests and data transferred in GB/month.&lt;/p&gt;
&lt;p&gt;Product link: &lt;a href=&quot;https://aws.amazon.com/s3/&quot;&gt;https://aws.amazon.com/s3/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;pricing-3&quot;&gt;Pricing&lt;/h3&gt;
&lt;h4 id=&quot;free-tier-12-months-1&quot;&gt;Free Tier - 12 months&lt;/h4&gt;
&lt;p&gt;Free Tier for S3 includes 5 GB of Amazon S3 storage in the Standard Storage class, 20,000 Get Requests, 2,000 Put Requests, and 15 GB of data transfer out each month. This Free Tier expires after 12 months. The data transfer to CloudFront is free. So, if you use CloudFront as a CDN, as proposed in this architecture, your S3 costs should be $0.&lt;/p&gt;
&lt;h4 id=&quot;after-free-tier-3&quot;&gt;After Free Tier&lt;/h4&gt;
&lt;p&gt;Once the Free Tier limits are exceeded or the 12 month trial period is over, the costs are $0.023 per GB for the first 50TB. PUT, COPY, POST, or LIST Requests cost $0.005 per 1,000 requests and GET, SELECT and all other Requests cost $0.0004 per 1,000 requests. Assuming a 15GB storage, the storage cost should be $0.345 (&lt;code&gt;15GB * $0.023/GB&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;For data transfer, the transfer up to 1 GB/month to the internet is free. After that, its $0.09 per GB up to 1TB/Month. But, the transfer to AWS CloudFront is completely free without any limits. So, if you serve the static assets with CloudFront as CDN in front of S3, you do not pay anything for data transfer to CloudFront. The CloudFront pricing is discussed in the next section.&lt;/p&gt;
&lt;p&gt;More on pricing: &lt;a href=&quot;https://aws.amazon.com/s3/pricing&quot;&gt;https://aws.amazon.com/s3/pricing&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;cloudfront&quot;&gt;CloudFront&lt;/h2&gt;
&lt;p&gt;CloudFront is Amazon’s Content Distribution Network. This is meant to deliver static assets to users substantially faster compared to directly accessing from S3. The usage for this service is defined in terms of data transferred out and the number of requests served.&lt;/p&gt;
&lt;p&gt;The pricing for this service varies with regions. This is elaborated more in the following section on pricing.&lt;/p&gt;
&lt;p&gt;Product link: &lt;a href=&quot;https://aws.amazon.com/CloudFront/&quot;&gt;https://aws.amazon.com/CloudFront/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;pricing-4&quot;&gt;Pricing&lt;/h3&gt;
&lt;h4 id=&quot;free-tier-12-months-2&quot;&gt;Free Tier - 12 Months.&lt;/h4&gt;
&lt;p&gt;In the Free Tier, AWS offers 50 GB Data Transfer Out and 2,000,000 HTTP and HTTPS Requests each month. Free Tier expires after 1 year.&lt;/p&gt;
&lt;p&gt;If an average user session for you means about 50 requests of an average asset size 50KB per asset, you have 50 requests per session and 2.5MB data transfer per session. With this Free Tier, you can easily scale up to 20,000 user sessions per month, about 666 user sessions per day, before exhausting your data transfer limits.&lt;/p&gt;
&lt;p&gt;The average asset size discussed here is the average of images, JS, CSS, HTML, and other assets like fonts that you may serve. To run a lean operation it is important to trim down the assets to be exactly what is needed in your application. In addition to saving you cost it has a much bigger impact of improved user experience with faster load times.&lt;/p&gt;
&lt;h4 id=&quot;after-free-tier-4&quot;&gt;After Free Tier&lt;/h4&gt;
&lt;p&gt;After your run out of Free Tier limits or at the end of your free trial, following is the pricing plan for AWS CloudFront.&lt;/p&gt;
&lt;p&gt;First 10 TB / month&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;United States &amp;amp; Canada&lt;/th&gt;
&lt;th&gt;Europe&lt;/th&gt;
&lt;th&gt;South Africa&lt;/th&gt;
&lt;th&gt;Japan, Hong Kong, Philippines, S. Korea, Singapore &amp;amp; Taiwan&lt;/th&gt;
&lt;th&gt;India&lt;/th&gt;
&lt;th&gt;Australia&lt;/th&gt;
&lt;th&gt;South America&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;$0.085&lt;/td&gt;
&lt;td&gt;$0.085&lt;/td&gt;
&lt;td&gt;$0.110&lt;/td&gt;
&lt;td&gt;$0.140&lt;/td&gt;
&lt;td&gt;$0.170&lt;/td&gt;
&lt;td&gt;$0.140&lt;/td&gt;
&lt;td&gt;$0.250&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Request Pricing for All HTTP Methods (per 10,000)&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Type of request&lt;/th&gt;
&lt;th&gt;United States &amp;amp; Canada&lt;/th&gt;
&lt;th&gt;Europe&lt;/th&gt;
&lt;th&gt;South Africa&lt;/th&gt;
&lt;th&gt;Japan, Hong Kong, Philippines, S. Korea, Singapore &amp;amp; Taiwan&lt;/th&gt;
&lt;th&gt;India&lt;/th&gt;
&lt;th&gt;Australia&lt;/th&gt;
&lt;th&gt;South America&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;HTTP&lt;/td&gt;
&lt;td&gt;$0.0075&lt;/td&gt;
&lt;td&gt;$0.0090&lt;/td&gt;
&lt;td&gt;$0.0090&lt;/td&gt;
&lt;td&gt;$0.0090&lt;/td&gt;
&lt;td&gt;$0.0090&lt;/td&gt;
&lt;td&gt;$0.0090&lt;/td&gt;
&lt;td&gt;$0.0160&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;HTTPS&lt;/td&gt;
&lt;td&gt;$0.0100&lt;/td&gt;
&lt;td&gt;$0.0120&lt;/td&gt;
&lt;td&gt;$0.0120&lt;/td&gt;
&lt;td&gt;$0.0120&lt;/td&gt;
&lt;td&gt;$0.0120&lt;/td&gt;
&lt;td&gt;$0.0125&lt;/td&gt;
&lt;td&gt;$0.0220&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Based on this pricing, extending the above example, if you get 1,000 user sessions a day making about 50 requests per session and the average size of assets is 50KB, it comes out to be about 75GB per month (&lt;code&gt;1,000 users * 50 assets * 50kB/asset * 30 days&lt;/code&gt;). With a traffic split assuming 50% from US &amp;amp; Canada and 50% from Europe, it costs about $7.61 a month or $8.03 for HTTPS. If you stay at 50GB/month it costs $5.08/month or $5.35 for HTTPS, which is cheap if you take into account that with this set up you provide content delivery around the world with the same or similar latency as Amazon, Hulu, King, Supercell, etc.&lt;/p&gt;
&lt;p&gt;More on pricing: &lt;a href=&quot;https://aws.amazon.com/CloudFront/pricing&quot;&gt;https://aws.amazon.com/CloudFront/pricing&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;dns-route-53&quot;&gt;DNS &amp;amp; Route 53&lt;/h2&gt;
&lt;p&gt;If you are running a small to medium sized application, the DNS service for any Domain registrar should just work. I prefer Google domains for this as they provide a clean interface which is easy to manage and just works. This gets you 10 million lookups per year (&lt;a href=&quot;https://support.google.com/domains/answer/6010092?hl=en&quot;&gt;https://support.google.com/domains/answer/6010092?hl=en&lt;/a&gt;) which is little over 27,000 per day. Seems pretty adequate for getting started and scaling up to a decent size.&lt;/p&gt;
&lt;p&gt;Once you get to a point where these limits start becoming a bottleneck, you can easily reconfigure it to use AWS Route 53.&lt;/p&gt;
&lt;p&gt;Product link: &lt;a href=&quot;https://aws.amazon.com/route53&quot;&gt;https://aws.amazon.com/route53&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;pricing-5&quot;&gt;Pricing&lt;/h3&gt;
&lt;p&gt;Route 53 does not offer a Free Tier. To set up routing for one domain, it costs $0.50 to create a hosted zone and $0.400 per million queries for the first 1 billion queries/month. If you decide using this service instead of a Domain registrar offered DNS service, you will likely pay less than $0.90 per month for our 1,000 user session per month example.&lt;/p&gt;
&lt;p&gt;More on pricing: &lt;a href=&quot;https://aws.amazon.com/route53/pricing/&quot;&gt;https://aws.amazon.com/route53/pricing/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;final-bill&quot;&gt;Final Bill!&lt;/h2&gt;
&lt;p&gt;Based on our assumption of 1,000 user sessions per day with average static assets 50KB, each session consisting of 50 assets requests and 50 API calls, following is the bill you can expect.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Service&lt;/th&gt;
&lt;th&gt;First 12 months&lt;/th&gt;
&lt;th&gt;After 12 months&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;&lt;tbody readability=&quot;1&quot;&gt;&lt;tr&gt;&lt;td&gt;API Gateway&lt;/td&gt;
&lt;td&gt;$4&lt;/td&gt;
&lt;td&gt;$12&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Lambda&lt;/td&gt;
&lt;td&gt;$0&lt;/td&gt;
&lt;td&gt;$0&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;DynamoDB&lt;/td&gt;
&lt;td&gt;$0&lt;/td&gt;
&lt;td&gt;$0&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;S3&lt;/td&gt;
&lt;td&gt;$0.23&lt;/td&gt;
&lt;td&gt;$0.35&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;CloudFront(HTTP/HTTPS)&lt;/td&gt;
&lt;td&gt;$2.12 / $2.12&lt;/td&gt;
&lt;td&gt;$7.61 / $8.03&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;DNS &amp;amp; Route 53&lt;/td&gt;
&lt;td&gt;$0&lt;/td&gt;
&lt;td&gt;$0&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;Total(CloudFront HTTP / HTTPS)&lt;/td&gt;
&lt;td&gt;$6.35&lt;/td&gt;
&lt;td&gt;$19.96 / $20.38&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;You can see here, all the cost during the first 12 months is coming from S3, CloudFront and API Gateway. You will have $0 bill in first 12 months if your S3 storage is below 5GB, CloudFront traffic stays below 50GB/Month and API Gateway requests are less than 1 million a month, or you get 666 user sessions a month compared to the 1,000 user sessions I picked while running these calculations.&lt;/p&gt;
&lt;h2 id=&quot;gotchas-tradeoffs-and-warnings&quot;&gt;Gotchas, Tradeoffs, and Warnings&lt;/h2&gt;
&lt;ol readability=&quot;17.784722222222&quot;&gt;&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;The above architecture is a general recommendation that should work for most applications.&lt;/strong&gt; You may need to tweak this or introduce pieces to get more optimal performance. For example, if you are doing something like banking you will need to add a relational database using the RDS service. If you are streaming video/audio, you will have to rethink this. Delivering game assets would require some intelligent caching on the client as well. This will work for a lot of cases, but not all.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;&lt;strong&gt;DynamoDB is a NoSQL database.&lt;/strong&gt; If your application requires a relational database, look at AWS RDS Sevice. It offers t2.micro for free during the first 12 months. It is fine for development. However, I will not recommend using it in production.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;&lt;strong&gt;AWS Lambda has a cold start problem.&lt;/strong&gt; If your function suddenly gets a lot of traffic or has not received any traffic for some time, the first request can take a while (seconds) to respond. There are various ways out there to handle this. You should build timeouts in your client to handle this gracefully. Additionally, you could also set up a CloudWatch schedule to poke your function so that it stays alive.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.86792452830189&quot;&gt;
&lt;p&gt;&lt;strong&gt;This post does not discuss usage of a caching layer.&lt;/strong&gt; AWS ElastiCache (&lt;a href=&quot;https://aws.amazon.com/elasticache/&quot;&gt;https://aws.amazon.com/elasticache/&lt;/a&gt;) provides Memcached and Redis as a service. Using this can considerably decrease your response times depending on the data access patterns of your application.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;4&quot;&gt;
&lt;p&gt;&lt;strong&gt;One piece of modern architecture that is not discussed here is the asynchronous execution of jobs.&lt;/strong&gt; If you are doing something that takes a while to process, say querying an external service or some data crunching it is best done by queuing the job using AWS SQS and making that data available to the user in the following request, this translates in a better user experience compared to user watching a loading screen on the app waiting for the response.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;&lt;strong&gt;One very important point is all these services are pay per use.&lt;/strong&gt; You should set up CloudWatch alarms to monitor your usage and stay on top of it. You don’t want to end up with a huge bill because you made a bunch of requests or your lambda functions kept running for longer than they should. Set up throttling, email alerts based on usage and monitor at least daily for discrepancies.&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1.6722891566265&quot;&gt;
&lt;p&gt;&lt;strong&gt;Consider looking at AWS CloudWatch and AWS CloudTrail.&lt;/strong&gt; AWS CloudWatch (&lt;a href=&quot;https://aws.amazon.com/cloudwatch/&quot;&gt;https://aws.amazon.com/cloudwatch/&lt;/a&gt;) allows you to set up alarms for usage on various services that can help you prevent downtime or detect overage in your usage. AWS CloudTrail (&lt;a href=&quot;https://aws.amazon.com/cloudtrail/&quot;&gt;https://aws.amazon.com/cloudtrail/&lt;/a&gt;) helps to track user activity and API usage. This is very useful in debugging or auditing the changes made to your cloud resources.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;While looking at all the offerings from the cloud provider you pick, I will recommend that try not to set your self up for vendor lock-in. This means using AWS specific features that don’t work outside can pose a future risk to move away from AWS. If you use AWS Cognito for authentication, make sure you think about how to move away from it, if need be, in case their roadmap and yours don’t align. For instance, if you need Google login and they don’t have one, you may be stuck!&lt;/p&gt;
&lt;p&gt;I would also like to bring it up again that &lt;strong&gt;monitor your AWS usage using CloudWatch alarms.&lt;/strong&gt; If you don’t have proper limits in place, you may end up with a huge unexpected bill.&lt;/p&gt;
&lt;p&gt;Finally, now that we have also talked about estimating pricing based on traffic, feel free to play around with the AWS calculator. You can enter your expected parameters to generate a monthly bill that can help you understand what you may pay based on the usage that you expect: &lt;a href=&quot;https://calculator.s3.amazonaws.com/index.html&quot;&gt;https://calculator.s3.amazonaws.com/index.html&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 24 Jul 2018 14:44:46 +0000</pubDate>
<dc:creator>pagnihotry</dc:creator>
<og:title>The Free Stack - Running your application for free on AWS</og:title>
<og:description>We live in interesting times. The cloud offerings from Amazon, Google and Microsoft have led to a situation where world-class infrastructure is available to startups and solopreneurs for very cheap, and most of the times, they can even get started for free.</og:description>
<og:image>http://p.agnihotry.com/images/avatar-icon.jpeg</og:image>
<og:url>http://p.agnihotry.com/post/the_free_stack_aws/</og:url>
<og:type>website</og:type>
<dc:language>en</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://p.agnihotry.com/post/the_free_stack_aws/</dc:identifier>
</item>
<item>
<title>Hackers Breached Virginia Bank Twice in Eight Months, Stole $2.4M</title>
<link>https://krebsonsecurity.com/2018/07/hackers-breached-virginia-bank-twice-in-eight-months-stole-2-4m/</link>
<guid isPermaLink="true" >https://krebsonsecurity.com/2018/07/hackers-breached-virginia-bank-twice-in-eight-months-stole-2-4m/</guid>
<description>&lt;p&gt;Hackers used phishing emails to break into a Virginia bank in two separate cyber intrusions over an eight-month period, making off with more than $2.4 million total. Now the financial institution is suing its insurance provider for refusing to fully cover the losses.&lt;/p&gt;
&lt;p&gt;According to a lawsuit filed last month in the Western District of Virginia, the first heist took place in late May 2016, after an employee at &lt;strong&gt;The National Bank of Blacksburg&lt;/strong&gt; fell victim to a targeted phishing email.&lt;/p&gt;
&lt;div id=&quot;attachment_44494&quot; class=&quot;wp-caption aligncenter&quot; readability=&quot;32&quot;&gt;&lt;img class=&quot;wp-image-44494 size-full&quot; src=&quot;https://krebsonsecurity.com/wp-content/uploads/2018/07/nbob.png&quot; alt=&quot;&quot; width=&quot;540&quot; height=&quot;553&quot; /&gt;&lt;p class=&quot;wp-caption-text&quot;&gt;Photo copyright: Kerri Farley&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The email allowed the intruders to install malware on the victim’s PC and to compromise a second computer at the bank that had access to the &lt;a href=&quot;https://www.firstdata.com/en_us/products/financial-institutions/debit-processing-atm-and-network/star-network.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;STAR Network&lt;/a&gt;, a system run by financial industry giant &lt;strong&gt;First Data&lt;/strong&gt; that the bank uses to handle debit card transactions for customers. That second computer had the ability to manage National Bank customer accounts and their use of ATMs and bank cards.&lt;/p&gt;
&lt;p&gt;Armed with this access, the bank says, hackers were able to disable and alter anti-theft and anti-fraud protections, such as 4-digit personal identification numbers (PINs), daily withdrawal limits, daily debit card usage limits, and fraud score protections.&lt;/p&gt;
&lt;p&gt;National Bank said the first breach began Saturday, May 28, 2016 and continued through the following Monday. Normally, the bank would be open on a Monday, but that particular Monday was &lt;a href=&quot;https://en.wikipedia.org/wiki/Memorial_Day&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Memorial Day&lt;/a&gt;, a federal holiday in the United States. The hackers used hundreds of ATMs across North America to dispense funds from customer accounts. All told, the perpetrators stole more than $569,000 in that incident.&lt;/p&gt;
&lt;p&gt;Following the 2016 breach, National Bank hired cybersecurity forensics firm &lt;strong&gt;Foregenix&lt;/strong&gt; to investigate. The company determined the hacking tools and activity appeared to come from Russian-based Internet addresses.&lt;/p&gt;
&lt;p&gt;In June of 2016, National Bank implemented additional security protocols, as recommended by FirstData. These protocols are known as “&lt;a href=&quot;https://chargeback.com/velocity-checks-fraud-prevention/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;velocity rules&lt;/a&gt;” and were put in place to help the bank flag specific types of repeated transaction patterns that happen within a short period of time&lt;/p&gt;
&lt;p&gt;But just eight months later — in January 2017 according to the lawsuit — hackers broke in to the bank’s systems once more, again gaining access to the financial institution’s systems via a phishing email.&lt;/p&gt;
&lt;p&gt;This time not only did the intruders regain access to the bank’s STAR Network, they also managed to compromise a workstation that had access to &lt;strong&gt;Navigator&lt;/strong&gt;, which is software used by National Bank to manage credits and debits to customer accounts.&lt;/p&gt;
&lt;p&gt;Prior to executing the second heist, the hackers used the bank’s Navigator system to fraudulently credit more than $2 million to various National Bank accounts. As with the first incident, the intruders executed their heist on a weekend. Between Jan. 7 and 9, 2017, the hackers modified or removed critical security controls and withdrew the fraudulent credits using hundreds of ATMs.&lt;/p&gt;
&lt;p&gt;All the while, the intruders used the bank’s systems to actively monitor customer accounts from which the funds were being withdrawn. At the conclusion of the 2017 heist, the hackers used their access to delete evidence of fraudulent debits from customer accounts. The bank’s total reported loss from that breach was $1,833,984.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Verizon&lt;/strong&gt; was hired to investigate the 2017 attack, and according to the bank Verizon’s forensics experts concluded that the tools and servers used by the hackers were of Russian origin. The lawsuit notes &lt;em&gt;the company determined that it was likely the same group of attackers responsible for both intrusions&lt;/em&gt;. Verizon also told the bank that the malware the attackers used to gain their initial foothold at the bank in the 2017 breach was embedded in a &lt;a href=&quot;https://blog.barkly.com/what-is-macro-malware-2017&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;booby-trapped&lt;/a&gt; &lt;strong&gt;Microsoft Word&lt;/strong&gt; document.&lt;span id=&quot;more-44451&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h4&gt;THE LAWSUIT&lt;/h4&gt;
&lt;p&gt;In &lt;a href=&quot;https://krebsonsecurity.com/wp-content/uploads/2018/07/1-main.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;its lawsuit&lt;/a&gt; (PDF), National Bank says it had an insurance policy with &lt;a href=&quot;https://www.everestre.com/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Everest National Insurance Company&lt;/a&gt; for two types of coverage or “riders” to protect it against cybercrime losses. The first was a “computer and electronic crime” (C&amp;amp;E) rider that had a single loss limit liability of $8 million, with a $125,000 deductible.&lt;/p&gt;
&lt;p&gt;The second was a “debit card rider” which provided coverage for losses which result directly from the use of lost, stolen or altered debit cards or counterfeit cards. That policy has a single loss limit of liability of $50,000, with a $25,000 deductible and an aggregate limit of $250,000.&lt;/p&gt;
&lt;p&gt;According to the lawsuit, in June 2018 Everest determined both the 2016 and 2017 breaches were covered exclusively by the debit card rider, and not the $8 million C&amp;amp;E rider. The insurance company said the bank could not recover lost funds under the C&amp;amp;E rider because of two “exclusions” in that rider which spell out circumstances under which the insurer will not provide reimbursement.&lt;/p&gt;
&lt;p&gt;The first of those exclusions rules out coverage for any loss “resulting directly or indirectly from the use or purported use of credit, debit, charge, access, convenience, or other cards . . . (1) in obtaining credit or funds, or (2) in gaining access to automated mechanical devices which, on behalf of the Insured, disburse Money, accept deposits, cash checks, drafts or similar Written instruments or make credit card loans . . ..”&lt;/p&gt;
&lt;p&gt;The second exclusion in the C&amp;amp;E rider negates coverage for “loss involving automated mechanical devices which, on behalf of the Insured, disburse Money, accept deposits, cash checks, drafts or similar Written instruments or make credit card loans . . ..”&lt;/p&gt;
&lt;p&gt;“In its Coverage Determination, Everest further determined that the 2016 Intrusion and the 2017 Intrusion were a single event, and thus, pursuant to the Debit Card Rider, National Bank’s total coverage under the Bond was $50,000.00 for both intrusions,” the bank said in its lawsuit.&lt;/p&gt;
&lt;p&gt;Everest National Insurance Company did not respond to requests for comment. But on July 20 it &lt;a href=&quot;https://krebsonsecurity.com/wp-content/uploads/2018/07/everest-response.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;filed a response&lt;/a&gt; (PDF) to the bank’s claims, alleging that National Bank has not accurately characterized the terms of its coverage or fully explained the basis for Everest’s coverage decision.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Charisse Castagnoli&lt;/strong&gt;, an adjunct professor with &lt;a href=&quot;https://www.jmls.edu/academics/ip-privacy/advisory-board.php&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;The John Marshall Law School&lt;/a&gt;, said the bank’s claim appears to be based on a legal concept known as “&lt;a href=&quot;https://en.wikipedia.org/wiki/Proximate_cause&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;proximate cause&lt;/a&gt;,” a claim that usually includes the telltale term “but for,” as this lawsuit does throughout.&lt;/p&gt;
&lt;p&gt;“Proximate cause tries to get at where’s the legal liability associated with the original element that caused the loss,” Castagnoli said. “Take the example of a car crash victim whose master cylinder in the vehicle ran out of fluid and as a result the driver ran a red light and hit another car. The driver at fault might make the claim in a lawsuit against the car maker ‘but for your failure to manufacture this part correctly, this accident wouldn’t have occurred.'”&lt;/p&gt;
&lt;p&gt;In this case, Castagnoli said what the bank seems to be claiming is that the Debit Card Rider shouldn’t apply because — &lt;strong&gt;but for&lt;/strong&gt; the computer hacking — the losses wouldn’t have occurred. Indeed, the bank’s lawsuit claims: “All losses related to the 2017 Intrusion were the result of and would not have been possible but for the hacking of National Bank’s Computer Systems which resulted in the entering or changing of Electronic Data and Computer Programs within the Computer Systems.”&lt;/p&gt;
&lt;p&gt;“Therefore, even though the losses were physically sustained  through ATM extractions, the Debit Card Rider limits shouldn’t apply because that kind of a rider doesn’t contemplate the dynamic changes in credit limits, and overrides of fraud monitoring, were only possible through &lt;strong&gt;computer hacking&lt;/strong&gt; to which the C&amp;amp;E Rider should apply,” Castagnoli explained.&lt;/p&gt;
&lt;p&gt;The bank’s complaint against Everest notes that the financial institution doesn’t yet know for sure how the thieves involved in the 2017 breach extracted funds. In previous such schemes (known as “&lt;a href=&quot;https://krebsonsecurity.com/2011/08/coordinated-atm-heist-nets-thieves-13m/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;unlimited cashouts&lt;/a&gt;“), the fraudsters orchestrating the intrusion recruit armies of “money mules” — usually street criminals who are given cloned debit cards and stolen or fabricated PINs along with instructions on where and when to withdraw funds.&lt;/p&gt;
&lt;p&gt;Castagnoli said establishing and proving these fine lines of proximate cause can be very difficult in insurance claims.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;pullquote pqleft&quot;&gt;“While it is fairly easy to write a policy around data breach liability, when it comes to actual intrusions and managing intrusions, it’s a wild wild west,” she said.&lt;/span&gt; “The policies and definitions they use are not consistent across carriers.”&lt;/p&gt;
&lt;p&gt;Castagnoli advises companies contemplating cyber insurance policies to closely scrutinize their policies and riders, and find an expert who can help craft a policy that is tailored for the insured.&lt;/p&gt;
&lt;p&gt;“The serious brokers who are out there selling cyber insurance all say the same thing: Have an expert help you to write your policy,” she said. “It’s mind-numbingly complicated and we don’t have standard language in insurance policies that help insurance clients decide what policy is right for them.”&lt;/p&gt;
&lt;p&gt;She added that although there have been a handful of cases where cyber insurance providers have denied coverage to the insured, most of those disputes have been settled out of court.&lt;/p&gt;
&lt;p&gt;“This is a rapidly growing area and a profit center for a lot of insurance companies,” Castagnoli said. “But there is not a lot of published case law on this, and you have to wonder if something public comes out like this what it’s going to do to the reputation of the industry.”&lt;/p&gt;


&lt;p class=&quot;small&quot;&gt;Tags: &lt;a href=&quot;https://krebsonsecurity.com/tag/atm-fraud/&quot; rel=&quot;tag&quot;&gt;ATM fraud&lt;/a&gt;, &lt;a href=&quot;https://krebsonsecurity.com/tag/ce-rider/&quot; rel=&quot;tag&quot;&gt;C&amp;amp;E rider&lt;/a&gt;, &lt;a href=&quot;https://krebsonsecurity.com/tag/charisse-castagnoli/&quot; rel=&quot;tag&quot;&gt;Charisse Castagnoli&lt;/a&gt;, &lt;a href=&quot;https://krebsonsecurity.com/tag/everest-national-insurance-company/&quot; rel=&quot;tag&quot;&gt;Everest National Insurance Company&lt;/a&gt;, &lt;a href=&quot;https://krebsonsecurity.com/tag/first-data/&quot; rel=&quot;tag&quot;&gt;First Data&lt;/a&gt;, &lt;a href=&quot;https://krebsonsecurity.com/tag/foregenix/&quot; rel=&quot;tag&quot;&gt;Foregenix&lt;/a&gt;, &lt;a href=&quot;https://krebsonsecurity.com/tag/john-marshall-law-school/&quot; rel=&quot;tag&quot;&gt;John Marshall Law School&lt;/a&gt;, &lt;a href=&quot;https://krebsonsecurity.com/tag/microsoft-word/&quot; rel=&quot;tag&quot;&gt;Microsoft Word&lt;/a&gt;, &lt;a href=&quot;https://krebsonsecurity.com/tag/national-bank-of-blacksburg/&quot; rel=&quot;tag&quot;&gt;National Bank of Blacksburg&lt;/a&gt;, &lt;a href=&quot;https://krebsonsecurity.com/tag/navigator/&quot; rel=&quot;tag&quot;&gt;Navigator&lt;/a&gt;, &lt;a href=&quot;https://krebsonsecurity.com/tag/star-network/&quot; rel=&quot;tag&quot;&gt;STAR Network&lt;/a&gt;, &lt;a href=&quot;https://krebsonsecurity.com/tag/verizon/&quot; rel=&quot;tag&quot;&gt;Verizon&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;postmetadata alt&quot;&gt;&lt;small&gt;This entry was posted on Tuesday, July 24th, 2018 at 9:38 am and is filed under &lt;a href=&quot;https://krebsonsecurity.com/category/data-breaches/&quot; rel=&quot;category tag&quot;&gt;Data Breaches&lt;/a&gt;. You can follow any comments to this entry through the &lt;a href=&quot;https://krebsonsecurity.com/2018/07/hackers-breached-virginia-bank-twice-in-eight-months-stole-2-4m/feed/&quot;&gt;RSS 2.0&lt;/a&gt; feed. You can skip to the end and leave a comment. Pinging is currently not allowed.&lt;/small&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 24 Jul 2018 13:45:51 +0000</pubDate>
<dc:creator>uptown</dc:creator>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://krebsonsecurity.com/2018/07/hackers-breached-virginia-bank-twice-in-eight-months-stole-2-4m/</dc:identifier>
</item>
<item>
<title>EU fines Asus, Denon-Marantz, Philips and Pioneer $130M for online price fixing</title>
<link>https://techcrunch.com/2018/07/24/eu-fines-asus-denon-marantz-philips-and-pioneer-130m-for-online-price-fixing/</link>
<guid isPermaLink="true" >https://techcrunch.com/2018/07/24/eu-fines-asus-denon-marantz-philips-and-pioneer-130m-for-online-price-fixing/</guid>
<description>&lt;p&gt;The European Union’s antitrust authorities have &lt;a href=&quot;http://europa.eu/rapid/press-release_IP-18-4601_en.htm&quot;&gt;issued&lt;/a&gt; a series of penalties, fining consumer electronics companies Asus, Denon &amp;amp; Marantz, Philips and Pioneer more than &lt;span lang=&quot;EN-GB&quot;&gt;€110 million&lt;/span&gt; (~$130M) in four separate decisions for imposing fixed or minimum resale prices on their online retailers in breach of EU competition rules.&lt;/p&gt;
&lt;p&gt;It says the four companies engaged in so-called “fixed or minimum resale price maintenance (RPM)” by restricting the ability of their online retailers to set their own retail prices for widely used consumer electronics products — such as kitchen appliances, notebooks and hi-fi products.&lt;/p&gt;
&lt;p&gt;Asus has been hit with the largest fine (&lt;span lang=&quot;EN-GB&quot;&gt;€&lt;/span&gt;63.5M), followed by Philips (&lt;span lang=&quot;EN-GB&quot;&gt;€&lt;/span&gt;29.8M). The other two fines were &lt;span lang=&quot;EN-GB&quot;&gt;€&lt;/span&gt;10.1M for Pioneer, and &lt;span lang=&quot;EN-GB&quot;&gt;€&lt;/span&gt;7.7M for Denon &amp;amp; Marantz.&lt;/p&gt;
&lt;p&gt;The Commission found the manufacturers put pressure on ecommerce outlets who offered their products at low prices, writing: “&lt;span&gt;If those retailers did not follow the prices requested by manufacturers, they faced threats or sanctions such as blocking of supplies. Many, including the biggest online retailers, use pricing algorithms which automatically adapt retail prices to those of competitors. In this way, the pricing restrictions imposed on low pricing online retailers typically had a broader impact on overall online prices for the respective consumer electronics products.”&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;It also notes that use of “sophisticated monitoring tools” by the manufacturers allowed them to “effectively track resale price setting in the distribution network and to intervene swiftly in case of price decreases”.&lt;/p&gt;
&lt;p&gt;“The price interventions limited effective price competition between retailers and led to higher prices with an immediate effect on consumers,” it added.&lt;/p&gt;
&lt;p&gt;In particular, Asus, was found to have monitored the resale price of retailers for certain computer hardware and electronics products such as notebooks and displays — and to have done so in two EU Member States (Germany and France), between 2011 and 2014.&lt;/p&gt;
&lt;p&gt;While Denon &amp;amp; &lt;a class=&quot;crunchbase-link&quot; href=&quot;https://www.crunchbase.com/organization/marantz/&quot; target=&quot;_blank&quot; data-type=&quot;organization&quot; data-entity=&quot;marantz&quot;&gt;Marantz&lt;/a&gt; was found to have engaged in “resale price maintenance” with respect to audio and video consumer products such as headphones and speakers of the brands Denon, Marantz and Boston Acoustics in Germany and the Netherlands between 2011 and 2015.&lt;/p&gt;
&lt;p&gt;Philips was found to have done the same in France between the end of 2011 and 2013 — but for a range of consumer electronics products, including kitchen appliances, coffee machines, vacuum cleaners, home cinema and home video systems, electric toothbrushes, hair driers and trimmers.&lt;/p&gt;
&lt;p&gt;In Pioneer’s case, the resale price maintenance covered products including home theatre devices, iPod speakers, speaker sets and hi-fi products.&lt;/p&gt;
&lt;p&gt;The Commission said the company also limited the ability of its retailers to sell-cross border to EU consumers in other Member States in order to sustain different resale prices in different Member States, for example by blocking orders of retailers who sold cross-border. Its conduct lasted from the beginning of 2011 to the end of 2013 and concerned 12 countries (Germany, France, Italy, the United Kingdom, Spain, Portugal, Sweden, Finland, Denmark, Belgium, the Netherlands and Norway).&lt;/p&gt;
&lt;p&gt;In all four cases, the Commission said the level of fines were reduced — 50% in the case of Pioneer; and 40% for each of the others — due to the companies’ co-operation with its investigations, specifying that they had provided evidence with “significant added value” and had “expressly acknowledg[ed] the facts and the infringements of EU antitrust rules”.&lt;/p&gt;
&lt;p&gt;Commenting in a statement, commissioner &lt;a class=&quot;crunchbase-link&quot; href=&quot;https://www.crunchbase.com/person/margrethe-vestager/&quot; target=&quot;_blank&quot; data-type=&quot;person&quot; data-entity=&quot;margrethe-vestager&quot;&gt;Margrethe Vestager,&lt;/a&gt; who heads up the bloc’s competition policy, said: &lt;em&gt;“&lt;/em&gt;The online commerce market is growing rapidly and is now worth over 500 billion euros in Europe every year. More than half of Europeans now shop online. As a result of the actions taken by these four companies, millions of European consumers faced higher prices for kitchen appliances, hair dryers, notebook computers, headphones and many other products. This is illegal under EU antitrust rules. Our decisions today show that EU competition rules serve to protect consumers where companies stand in the way of more price competition and better choice.”&lt;/p&gt;
&lt;p&gt;We’ve reached out to all the companies for comment.&lt;/p&gt;
&lt;p&gt;The fines follow the Commission’s ecommerce sector inquiry, which reported in &lt;a href=&quot;http://europa.eu/rapid/press-release_IP-17-1261_en.htm&quot;&gt;May 2017&lt;/a&gt;, and showed that resale-price related restrictions are by far the most widespread restrictions of competition in ecommerce markets, making competition enforcement in this area a priority — as part of the EC’s wider Digital Single Market strategy.&lt;/p&gt;
&lt;p&gt;The Commission further notes that the sector inquiry shed light on the increased use of automatic software applied by retailers for price monitoring and price setting.&lt;/p&gt;
&lt;p&gt;Separate investigations were launched in &lt;a href=&quot;http://europa.eu/rapid/press-release_IP-17-201_en.htm&quot;&gt;February 2017&lt;/a&gt; and &lt;a href=&quot;http://europa.eu/rapid/press-release_IP-17-1646_en.htm&quot;&gt;June 2017&lt;/a&gt; to assess if certain online sales practices are preventing, in breach of EU antitrust rules, consumers from enjoying cross-border choice and from being able to buy products and services online at competitive prices. The Commission adds that those investigations are ongoing.&lt;/p&gt;
&lt;p&gt;Commenting on today’s EC decision, a spokesman for Philips told us: “Since the start of the EC investigation in late 2013, which Philips reported in its Annual Reports, the company has fully cooperated with the EC. Philips initiated an internal investigation and addressed the matter in 2014.”&lt;/p&gt;
&lt;p&gt;“It is good that we can now leave this case behind us, and focus on the positive impact that our products and solutions can have on people,” he added. “Let me please stress that Philips attaches prime importance to full compliance with all applicable laws, rules and regulations. Being a responsible company, everyone in Philips is expected to always act with integrity. Philips rigorously enforces compliance of its General Business Principles throughout the company. Philips has a zero tolerance policy towards non-compliance in relation to breaches of its General Business Principles.”&lt;/p&gt;
&lt;p&gt;Anticipating the decision of the EC, he said the company had already recognized a &lt;a href=&quot;https://www.philips.com/a-w/about/news/archive/standard/news/press/2018/20180706-philips-provides-update-on-european-commission-investigation.html&quot;&gt;&lt;span lang=&quot;EN-GB&quot;&gt;€&lt;/span&gt;30M provision in its Q2 2018&lt;/a&gt;.&lt;/p&gt;
</description>
<pubDate>Tue, 24 Jul 2018 13:19:33 +0000</pubDate>
<dc:creator>Ours90</dc:creator>
<og:title>EU fines Asus, Denon &amp; Marantz, Philips and Pioneer $130M for online price fixing</og:title>
<og:description>The European Union’s antitrust authorities have issued a series of penalties, fining consumer electronics companies Asus, Denon &amp; Marantz, Philips and Pioneer more than €110 million (~$130M) in four separate decisions for imposing fixed or minimum resale prices on their online retailers i…</og:description>
<og:image>https://techcrunch.com/wp-content/uploads/2012/01/asus-design-award_2011_eeepc-flare-1025-1225.jpg?w=711</og:image>
<og:url>http://social.techcrunch.com/2018/07/24/eu-fines-asus-denon-marantz-philips-and-pioneer-130m-for-online-price-fixing/</og:url>
<og:type>article</og:type>
<dc:language>en-US</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>https://techcrunch.com/2018/07/24/eu-fines-asus-denon-marantz-philips-and-pioneer-130m-for-online-price-fixing/</dc:identifier>
</item>
</channel>
</rss>