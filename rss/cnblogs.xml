<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Effective Java 第三版——38.  使用接口模拟可扩展的枚举 - 林本托</title>
<link>http://www.cnblogs.com/IcanFixIt/p/8824754.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/IcanFixIt/p/8824754.html</guid>
<description>&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;Tips&lt;br/&gt;《Effective Java, Third Edition》一书英文版已经出版，这本书的第二版想必很多人都读过，号称Java四大名著之一，不过第二版2009年出版，到现在已经将近8年的时间，但随着Java 6，7，8，甚至9的发布，Java语言发生了深刻的变化。&lt;br/&gt;在这里第一时间翻译成中文版。供大家学习分享之用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/4366140-ca5216df5c1029f6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;Effective Java, Third Edition&quot;/&gt;&lt;/p&gt;

&lt;p&gt;在几乎所有方面，枚举类型都优于本书第一版中描述的类型安全模式[Bloch01]。 从表面上看，一个例外涉及可扩展性，这在原始模式下是可能的，但不受语言结构支持。 换句话说，使用该模式，有可能使一个枚举类型扩展为另一个; 使用语言功能特性，它不能这样做。 这不是偶然的。 大多数情况下，枚举的可扩展性是一个糟糕的主意。 令人困惑的是，扩展类型的元素是基类型的实例，反之亦然。 枚举基本类型及其扩展的所有元素没有好的方法。 最后，可扩展性会使设计和实现的很多方面复杂化。&lt;/p&gt;
&lt;p&gt;也就是说，对于可扩展枚举类型至少有一个有说服力的用例，这就是操作码（ operation codes），也称为opcodes。 操作码是枚举类型，其元素表示某些机器上的操作，例如条目 34中的&lt;code&gt;Operation&lt;/code&gt;类型，它表示简单计算器上的功能。 有时需要让API的用户提供他们自己的操作，从而有效地扩展API提供的操作集。&lt;/p&gt;
&lt;p&gt;幸运的是，使用枚举类型有一个很好的方法来实现这种效果。基本思想是利用枚举类型可以通过为opcode类型定义一个接口，并实现任意接口。例如，这里是来自条目 34的&lt;code&gt;Operation&lt;/code&gt;类型的可扩展版本：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;// Emulated extensible enum using an interface
public interface Operation {
    double apply(double x, double y);
}


public enum BasicOperation implements Operation {
    PLUS(&quot;+&quot;) {
        public double apply(double x, double y) { return x + y; }
    },
    MINUS(&quot;-&quot;) {
        public double apply(double x, double y) { return x - y; }
    },
    TIMES(&quot;*&quot;) {
        public double apply(double x, double y) { return x * y; }
    },
    DIVIDE(&quot;/&quot;) {
        public double apply(double x, double y) { return x / y; }
    };
    private final String symbol;


    BasicOperation(String symbol) {
        this.symbol = symbol;
    }


    @Override public String toString() {
        return symbol;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;虽然枚举类型（&lt;code&gt;BasicOperation&lt;/code&gt;）不可扩展，但接口类型（&lt;code&gt;Operation&lt;/code&gt;）是可以扩展的，并且它是用于表示API中的操作的接口类型。 你可以定义另一个实现此接口的枚举类型，并使用此新类型的实例来代替基本类型。 例如，假设想要定义前面所示的操作类型的扩展，包括指数运算和余数运算。 你所要做的就是编写一个实现&lt;code&gt;Operation&lt;/code&gt;接口的枚举类型：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;// Emulated extension enum
public enum ExtendedOperation implements Operation {
    EXP(&quot;^&quot;) {
        public double apply(double x, double y) {
            return Math.pow(x, y);
        }
    },
    REMAINDER(&quot;%&quot;) {
        public double apply(double x, double y) {
            return x % y;
        }
    };

    private final String symbol;

    ExtendedOperation(String symbol) {
        this.symbol = symbol;
    }

    @Override public String toString() {
        return symbol;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;只要API编写为接口类型（&lt;code&gt;Operation&lt;/code&gt;），而不是实现（&lt;code&gt;BasicOperation&lt;/code&gt;），现在就可以在任何可以使用基本操作的地方使用新操作。请注意，不必在枚举中声明&lt;code&gt;apply&lt;/code&gt;抽象方法，就像您在具有实例特定方法实现的非扩展枚举中所做的那样（第162页）。 这是因为抽象方法（&lt;code&gt;apply&lt;/code&gt;）是接口（&lt;code&gt;Operation&lt;/code&gt;）的成员。&lt;/p&gt;
&lt;p&gt;不仅可以在任何需要“基本枚举”的地方传递“扩展枚举”的单个实例，而且还可以传入整个扩展枚举类型，并使用其元素。 例如，这里是第163页上的一个测试程序版本，它执行之前定义的所有扩展操作：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public static void main(String[] args) {
    double x = Double.parseDouble(args[0]);
    double y = Double.parseDouble(args[1]);
    test(ExtendedOperation.class, x, y);
}


private static &amp;lt;T extends Enum&amp;lt;T&amp;gt; &amp;amp; Operation&amp;gt; void test(
        Class&amp;lt;T&amp;gt; opEnumType, double x, double y) {
    for (Operation op : opEnumType.getEnumConstants())
        System.out.printf(&quot;%f %s %f = %f%n&quot;,
                          x, op, y, op.apply(x, y));
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意，扩展的操作类型的类字面文字（&lt;code&gt;ExtendedOperation.class&lt;/code&gt;）从&lt;code&gt;main&lt;/code&gt;方法里传递给了&lt;code&gt;test&lt;/code&gt;方法，用来描述扩展操作的集合。这个类的字面文字用作限定的类型令牌（条目 33）。&lt;code&gt;opEnumType&lt;/code&gt;参数中复杂的声明（&lt;code&gt;&amp;lt;T extends Enum&amp;lt;T&amp;gt; &amp;amp; Operation&amp;gt; Class&amp;lt;T&amp;gt;&lt;/code&gt;）确保了Class对象既是枚举又是&lt;code&gt;Operation&lt;/code&gt;的子类，这正是遍历元素和执行每个元素相关联的操作时所需要的。&lt;/p&gt;
&lt;p&gt;第二种方式是传递一个&lt;code&gt;Collection&amp;lt;? extends Operation&amp;gt;&lt;/code&gt;，这是一个限定通配符类型（条目 31），而不是传递了一个class对象：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public static void main(String[] args) {
    double x = Double.parseDouble(args[0]);
    double y = Double.parseDouble(args[1]);
    test(Arrays.asList(ExtendedOperation.values()), x, y);
}

private static void test(Collection&amp;lt;? extends Operation&amp;gt; opSet,
        double x, double y) {
    for (Operation op : opSet)
        System.out.printf(&quot;%f %s %f = %f%n&quot;,
                          x, op, y, op.apply(x, y));
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;生成的代码稍微不那么复杂，&lt;code&gt;tes&lt;/code&gt;t方法灵活一点：它允许调用者将多个实现类型的操作组合在一起。另一方面，也放弃了在指定操作上使用&lt;code&gt;EnumSe&lt;/code&gt;t(条目 36)和&lt;code&gt;EnumMap&lt;/code&gt;(条目 37)的能力。&lt;/p&gt;
&lt;p&gt;上面的两个程序在运行命令行输入参数4和2时生成以下输出：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;4.000000 ^ 2.000000 = 16.000000
4.000000 % 2.000000 = 0.000000&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用接口来模拟可扩展枚举的一个小缺点是，实现不能从一个枚举类型继承到另一个枚举类型。如果实现代码不依赖于任何状态，则可以使用默认实现(条目 20)将其放置在接口中。在我们的&lt;code&gt;Operation&lt;/code&gt;示例中，存储和检索与操作关联的符号的逻辑必须在&lt;code&gt;BasicOperation&lt;/code&gt;和&lt;code&gt;ExtendedOperation&lt;/code&gt;中重复。在这种情况下，这并不重要，因为很少的代码是冗余的。如果有更多的共享功能，可以将其封装在辅助类或静态辅助方法中，以消除代码冗余。&lt;/p&gt;
&lt;p&gt;该条目中描述的模式在Java类库中有所使用。例如，&lt;code&gt;java.nio.file.LinkOption&lt;/code&gt;枚举类型实现了&lt;code&gt;CopyOption&lt;/code&gt;和&lt;code&gt;OpenOption&lt;/code&gt;接口。&lt;/p&gt;
&lt;p&gt;总之，&lt;strong&gt;虽然不能编写可扩展的枚举类型，但是你可以编写一个接口来配合实现接口的基本的枚举类型，来对它进行模拟&lt;/strong&gt;。这允许客户端编写自己的枚举（或其它类型）来实现接口。如果API是根据接口编写的，那么在任何使用基本枚举类型实例的地方，都可以使用这些枚举类型实例。&lt;/p&gt;
</description>
<pubDate>Fri, 13 Apr 2018 15:30:00 +0000</pubDate>
<dc:creator>林本托</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/IcanFixIt/p/8824754.html</dc:identifier>
</item>
<item>
<title>深入理解.net - 1.继承的本质 - Nuss</title>
<link>http://www.cnblogs.com/Nuss/p/8748666.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Nuss/p/8748666.html</guid>
<description>&lt;p&gt;最近偶然看到这个博客&lt;strong&gt;&lt;a href=&quot;http://www.cnblogs.com/anytao/archive/2007/04/06/must_net_00.html&quot;&gt;你必须知道的.net&lt;/a&gt;&lt;/strong&gt;，作者6的飞起啊，干货十足，还是07年写的。。。写的也很赞，评论更精彩，在此强烈推荐一波，看的感觉就像沙漠里发现了绿洲一样，很兴奋，意犹未尽，迫不及待的看完一篇再看下一篇，但是知识还是需要整理，沉淀的，那就写博客吧，于是有了接下来的文章。本文将通过看此书和相关博客以及结合自己目前的理解所写，如有不对之处，欢迎指正。&lt;/p&gt;
&lt;h2 id=&quot;对象的创建过程&quot;&gt;对象的创建过程&lt;/h2&gt;
&lt;p&gt;要了解继承的本质首先我们要清楚一个对象的创建过程，这里有个 Chicken 类：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class Chicken 
{
    private  string type = &quot;Chicken&quot;;
    
    public Chicken()
    {
    }
    
    public void ShowType()
    {            
        Console.WriteLine($&quot;Type is {type}&quot;);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当我们需要使用这个类的时候，我们通常是这样写的：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Chicken chicken = new Chicken(); &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;它是如何工作的呢？先上图：&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1142573/201804/1142573-20180410235844089-990915058.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;具体过程如下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;首先执行的是 &quot;Chicken chicken&quot; 语句，即线程栈Stack上声明了一个Chicken类型的引用chicken，此时值为null，Stack上内存分配由高到低地址开始创建， 而Heap上则相反；&lt;/li&gt;
&lt;li&gt;执行 &quot;new Chicken()&quot; ，new 操作符会在托管堆（具体在GCH：Garbage Collection Heap）上申请创建实例的内存空间，初始化类的字段（Feild）信息，并调用构造函数。结合上图，实例在GCHeap创建的详细过程如下：
&lt;ul&gt;&lt;li&gt;对象实例地址的开始4个字节为SyncBlockIndex，指向SyncEntryTable,存储的是多线程同步的一些信息，详细内容可查看文章末尾参考连接；&lt;/li&gt;
&lt;li&gt;紧接着是TypeHandle,指向的是Loader Heap（加载器堆） 中的MethodTable，而MethodTable中存储该类型的静态字段，方法表以及实现的接口等信息，从这里我们也就清楚了，一个类不管实例成员有多少，static成员和方法信息只存储一份在内存中，并先于实例创建，使用的时候则通过TypeHandle到MethodTable查找，并编译成cpu指令，存储在内存中，以后再使用时则直接执行该指令即可。&lt;/li&gt;
&lt;li&gt;初始完SyncBlockIndex和TypeHandle，则加载Chicken类型的字段信息，本文初始的也就是type字段（&lt;em&gt;字符串信息的存储比较特殊实际存储模型&lt;a href=&quot;http://www.cnblogs.com/artech/archive/2010/10/18/1855122.html&quot;&gt;详见此链接&lt;/a&gt;&lt;/em&gt;），另外强调的是属性不在此处初始，属性本质上还是 **_Get/**_Set方法；&lt;/li&gt;
&lt;li&gt;初始完字段后，则调用构造函数Chicken(),并返回this。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;3.最后将this赋值给Stack上的chicken引用类型，即chicken维护一个指向heap上Chicken实例的指针，实际stact上的chicken存储的是GCHeap上实例存储的地址；&lt;/p&gt;
&lt;h2 id=&quot;继承的本质&quot;&gt;继承的本质&lt;/h2&gt;
&lt;p&gt;如果你看到这里，那说明你已经对一个对象的创建过程有了清晰的认识。回归主题那继承的本质是什么？先别急，下面我们写一个 Animal 类，让上文中的Chicken类继承它，并重写父类中的ShowType方法，&lt;em&gt;本示例代码参考书中示例略微有所调整&lt;/em&gt;代码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class Animal 
{
    private string type =&quot;Animal&quot;;

    public Animal()
    {

    }

    public virtual void ShowType()
    {
        Console.WriteLine($&quot;Type is {type}&quot;);
    }
}
public class Chicken : Animal
{
    public string type = &quot;Chicken&quot;;

    public Chicken()
    {
    }
    
    public override void ShowType()
    {            
        Console.WriteLine($&quot;Type is {type}&quot;);
    }
    
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;那么这个时候我们去执行 Chicken chicken = new Chicken(); 发生了什么呢？&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1142573/201804/1142573-20180413223703596-252994622.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;根据上图我们可以很直观的看出（此处暂时不考虑Object）：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;首先会先初始化chicken.type 字段，然后调用Chicken 构造函数；&lt;/li&gt;
&lt;li&gt;此时编译器发现还有父类则去为父类Animal 申请内存，即初始Animal.type 字段，然后调用Animal的构造函数；因为所有类型都是继承自System.Object 所以实际上会一直遍历到Object类型；此外从这个过程中我们也可以发现子类是可以继承父类私有成员信息，即chicken可以继承Animal的type字段，字段存储顺序是父类在前子类在后，跟踪截图如下：&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1142573/201804/1142573-20180413230547440-1689873228.png&quot;/&gt;&lt;/li&gt;
&lt;li&gt;Animal()方法体执行完后，然后在执行Chicken()的方法体。&lt;/li&gt;
&lt;li&gt;此处额外说下关于方法的加载，在继承过程子类会将父类中的方法copy一份，并将重写的方法覆盖掉父类中的方法，这也就为多态提供了基础。&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;最后&quot;&gt;最后&lt;/h2&gt;
&lt;p&gt;写这篇博客参考了不少其它牛人的博客，发现关于这块往深里东西还有很多，如AppDomain应用程序域，ManagerHeap可以分多种不同的类型，GC对不同的Heap处理规则也是不同的，近期也会持续分享相关内容。写博文期间内容也不断反复调整了几轮，希望在此我都表达清楚了，限于篇幅主要内容还是关于对象和继承的本质过程，内容基本上也都是根据自己的理解写出来的，难免有疏漏的地方，如有不对的对方还请指出，那将是我不断进步的源泉:-)。&lt;/p&gt;
&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
</description>
<pubDate>Fri, 13 Apr 2018 15:25:00 +0000</pubDate>
<dc:creator>Nuss</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/Nuss/p/8748666.html</dc:identifier>
</item>
<item>
<title>换个视角来看git命令与代码库发生网络交互报错事件 - 滴水微澜</title>
<link>http://www.cnblogs.com/zhou--fei/p/8824660.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zhou--fei/p/8824660.html</guid>
<description>&lt;p&gt;　　git的一系列命令中像 clone、pull、push等与代码库发生网络交互时，可能报下面的错误信息&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;fatal: remote error: CAPTCHA required
Your Stash account has been marked as requiring a CAPTCHA to be solved before
you may login again. This is typically caused by too many attempts to login
&lt;/span&gt;&lt;span&gt;with&lt;/span&gt;&lt;span&gt; an incorrect password. The required CAPTCHA prevents your SCM client from
accessing Stash until it is solved, even &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; you enter your password correctly.

If you are currently logged &lt;/span&gt;&lt;span&gt;in&lt;/span&gt;&lt;span&gt; to Stash via a browser you may need to logout
and then log back &lt;/span&gt;&lt;span&gt;in&lt;/span&gt; &lt;span&gt;in&lt;/span&gt; order to clear the CAPTCHA.
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　从报错信息来看，大概的意思是：“你的容器账号在登陆之前需要进行验证，这是因为登陆时太多的密码错误造成的。虽然你当前输入的密码正确，但是这个验证码拒绝客户端访问容器直到这个问题解决。”&lt;/p&gt;
&lt;p&gt;　　这个问题如何解决呢？&lt;/p&gt;
&lt;p&gt;　　这里面提到了一个单词“ CAPTCHA”意思是验证。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/826860/201804/826860-20180413225837019-1577356254.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　上面提到的“验证”是否就是图中的验证码概念呢？&lt;/p&gt;
&lt;p&gt;　　我们来逻辑推测一把。&lt;/p&gt;
&lt;p&gt;　　以clone为例子，git执行clone命令，首先需要有可以到代码库中访问代码的权利。我们平时在网页登陆时一般都是通过填写用户名＋密码。不过当网页在登陆时密码连续多次输入错误，下面就会出现“验证码”图片让我们点击。我写到这里是不是恍然明白了什么？没错，这个“ CAPTCHA”就是在git访问代码库时出现的“验证码图片”。惊喜不惊喜，意外不惊喜。原来我们平时使用的命令走的路子也是和我们手动页面操作一样。&lt;/p&gt;
&lt;p&gt;　　知道这个原因后，我们修改报错就迎刃而解了。这里我们采用最直观，看起来与这个报错不相关的方式。“1.打开登陆网页，输入正确的用户名＋密码登陆进去。2.退出登陆。重新再输入正确的用户名＋密码登陆进去。”如此这两次操作，就可以保证再次在页面登陆时，不会弹出“验证码图片”。此时再执行git clone命令。报错消失。顺利拿到了想要的代码。&lt;/p&gt;

</description>
<pubDate>Fri, 13 Apr 2018 15:19:00 +0000</pubDate>
<dc:creator>滴水微澜</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/zhou--fei/p/8824660.html</dc:identifier>
</item>
<item>
<title>使用生成器把Kafka写入速度提高1000倍 - 青南</title>
<link>http://www.cnblogs.com/xieqiankun/p/use_yield_correctly.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xieqiankun/p/use_yield_correctly.html</guid>
<description>&lt;hr/&gt;&lt;p&gt;title: 使用生成器把Kafka写入速度提高1000倍&lt;br/&gt;toc: true&lt;br/&gt;comment: true&lt;br/&gt;date: 2018-04-13 21:35:09&lt;br/&gt;tags: ['Python', '经验']&lt;br/&gt;category: ['Python']&lt;br/&gt;---&lt;/p&gt;
&lt;p&gt;通过本文你会知道Python里面什么时候用yield最合适。本文不会给你讲生成器是什么，所以你需要先了解Python的yield，再来看本文。&lt;/p&gt;
&lt;h2 id=&quot;疑惑&quot;&gt;疑惑&lt;/h2&gt;
&lt;p&gt;多年以前，当我刚刚开始学习Python协程的时候，我看到绝大多数的文章都举了一个生产者-消费者的例子，用来表示在生产者内部可以随时调用消费者，达到和多线程相同的效果。这里凭记忆简单还原一下当年我看到的代码：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; time


&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; consumer():
    product &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;cf&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;:
        &lt;span class=&quot;cf&quot;&gt;if&lt;/span&gt; product &lt;span class=&quot;op&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;None&lt;/span&gt;:
            &lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'consumer: {}'&lt;/span&gt;.&lt;span class=&quot;bu&quot;&gt;format&lt;/span&gt;(product))
        product &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;cf&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;None&lt;/span&gt;


&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; producer():
    c &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; consumer()
    &lt;span class=&quot;bu&quot;&gt;next&lt;/span&gt;(c)
    &lt;span class=&quot;cf&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;op&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;):
        c.send(i)

start &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; time.time()
producer()
end &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; time.time()
&lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt;(f&lt;span class=&quot;st&quot;&gt;'直到把所有数据塞入Kafka，一共耗时：{end - start}秒'&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;运行效果如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7sbpmp.com1.z0.glb.clouddn.com/2018-04-13-23-05-55.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这些文章的说法，就像统一好了口径一样，说这样写可以减少线程切换开销，从而大大提高程序的运行效率。但是当年我始终想不明白，这种写法与直接调用函数有什么区别，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7sbpmp.com1.z0.glb.clouddn.com/2018-04-13-21-51-37.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;直到后来我需要操作Kafka的时候，我明白了使用yield的好处。&lt;/p&gt;
&lt;h2 id=&quot;探索&quot;&gt;探索&lt;/h2&gt;
&lt;p&gt;为了便于理解，我会把实际场景做一些简化，以方便说明事件的产生发展和解决过程。事件的起因是我需要把一些信息写入到Kafka中，我的代码一开始是这样的：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; time
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; pykafka &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; KafkaClient

client &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; KafkaClient(hosts&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&quot;127.0.0.1:9092&quot;&lt;/span&gt;)
topic &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; client.topics[b&lt;span class=&quot;st&quot;&gt;'test'&lt;/span&gt;]


&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; consumer(product):
    &lt;span class=&quot;cf&quot;&gt;with&lt;/span&gt; topic.get_producer(delivery_reports&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;) &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; producer:
        producer.produce(&lt;span class=&quot;bu&quot;&gt;str&lt;/span&gt;(product).encode())


&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; feed():
    &lt;span class=&quot;cf&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;op&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;):
        consumer(i)


start &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; time.time()
feed()
end &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; time.time()
&lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt;(f&lt;span class=&quot;st&quot;&gt;'直到把所有数据塞入Kafka，一共耗时：{end - start}秒'&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这段代码的运行效果如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7sbpmp.com1.z0.glb.clouddn.com/witoutyield1.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;写入10条数据需要100秒，这样的龟速显然是有问题的。问题就出在这一句代码：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;cf&quot;&gt;with&lt;/span&gt; topic.get_producer(delivery_reports&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;) &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; producer&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;获得Kafka生产者对象是一个非常耗费时间的过程，每获取一次都需要10秒钟才能完成。所以写入10个数据就获取十次生产者对象。这消耗的100秒主要就是在获取生产者对象，而真正写入数据的时间短到可以忽略不计。&lt;/p&gt;
&lt;p&gt;由于生产者对象是可以复用的，于是我对代码作了一些修改：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; time
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; pykafka &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; KafkaClient

client &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; KafkaClient(hosts&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&quot;127.0.0.1:9092&quot;&lt;/span&gt;)
topic &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; client.topics[b&lt;span class=&quot;st&quot;&gt;'test'&lt;/span&gt;]
products &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; []


&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; consumer(product_list):
    &lt;span class=&quot;cf&quot;&gt;with&lt;/span&gt; topic.get_producer(delivery_reports&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;) &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; producer:
        &lt;span class=&quot;cf&quot;&gt;for&lt;/span&gt; product &lt;span class=&quot;op&quot;&gt;in&lt;/span&gt; product_list:
            producer.produce(&lt;span class=&quot;bu&quot;&gt;str&lt;/span&gt;(product).encode())


&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; feed():
    &lt;span class=&quot;cf&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;op&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;):
        products.append(i)
    consumer(products)


start &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; time.time()
feed()
end &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; time.time()
&lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt;(f&lt;span class=&quot;st&quot;&gt;'直到把所有数据塞入Kafka，一共耗时：{end - start}秒'&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;首先把所有数据存放在一个列表中，最后再一次性给consumer函数。在一个Kafka生产者对象中展开列表，再把数据一条一条塞入Kafka。这样由于只需要获取一次生产者对象，所以需要耗费的时间大大缩短，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7sbpmp.com1.z0.glb.clouddn.com/witoutyield2.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这种写法在数据量小的时候是没有问题的，但数据量一旦大起来，如果全部先放在一个列表里面的话，服务器内存就爆了。&lt;/p&gt;
&lt;p&gt;于是我又修改了代码。每100条数据保存一次，并清空暂存的列表：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; time
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; pykafka &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; KafkaClient

client &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; KafkaClient(hosts&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&quot;127.0.0.1:9092&quot;&lt;/span&gt;)
topic &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; client.topics[b&lt;span class=&quot;st&quot;&gt;'test'&lt;/span&gt;]


&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; consumer(product_list):
    &lt;span class=&quot;cf&quot;&gt;with&lt;/span&gt; topic.get_producer(delivery_reports&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;) &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; producer:
        &lt;span class=&quot;cf&quot;&gt;for&lt;/span&gt; product &lt;span class=&quot;op&quot;&gt;in&lt;/span&gt; product_list:
            producer.produce(&lt;span class=&quot;bu&quot;&gt;str&lt;/span&gt;(product).encode())


&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; feed():
    products &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; []
    &lt;span class=&quot;cf&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;op&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1003&lt;/span&gt;):
        products.append(i)
        &lt;span class=&quot;cf&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;len&lt;/span&gt;(products) &lt;span class=&quot;op&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;:
            consumer(products)
            products &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; []

    &lt;span class=&quot;cf&quot;&gt;if&lt;/span&gt; products:
        consumer(products)


start &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; time.time()
feed()
end &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; time.time()
&lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt;(f&lt;span class=&quot;st&quot;&gt;'直到把所有数据塞入Kafka，一共耗时：{end - start}秒'&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;由于最后一轮循环可能无法凑够100条数据，所以&lt;code&gt;feed&lt;/code&gt;函数里面，循环结束以后还需要判断&lt;code&gt;products&lt;/code&gt;列表是否为空，如果不为空，还要再消费一次。这样的写法，在上面这段代码中，一共1003条数据，每100条数据获取一次生产者对象，那么需要获取11次生产者对象，耗时至少为110秒。&lt;/p&gt;
&lt;p&gt;显然，要解决这个问题，最直接的办法就是减少获取Kafka生产者对象的次数并最大限度复用生产者对象。如果读者举一反三的能力比较强，那么根据开关文件的两种写法：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;12&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# 写法一&lt;/span&gt;
&lt;span class=&quot;cf&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;open&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'test.txt'&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;'w'&lt;/span&gt;, encoding&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'utf-8'&lt;/span&gt;) &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; f:
    f.write(&lt;span class=&quot;st&quot;&gt;'xxx'&lt;/span&gt;)
    
&lt;span class=&quot;co&quot;&gt;# 写法二&lt;/span&gt;
f &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;open&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'test.txt'&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;'w'&lt;/span&gt;, encoding&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'utf-8'&lt;/span&gt;)
f.write(&lt;span class=&quot;st&quot;&gt;'xxx'&lt;/span&gt;)
f.close()&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;可以推测出获取Kafka生产者对象的另一种写法：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# 写法二&lt;/span&gt;
producer &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; topic.get_producer(delivery_reports&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;)
producer.produce(b&lt;span class=&quot;st&quot;&gt;'xxxx'&lt;/span&gt;)
producer.close()&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这样一来，只要获取一次生产者对象并把它作为全局变量就可以一直使用了。&lt;/p&gt;
&lt;p&gt;然而，pykafka的官方文档中使用的是第一种写法，通过上下文管理器&lt;code&gt;with&lt;/code&gt;来获得生产者对象。暂且不论第二种方式是否会报错，只从写法上来说，第二种方式必需要手动关闭对象。开发者经常会出现开了忘记关的情况，从而导致很多问题。而且如果中间出现了异常，使用上下文管理器的第一种方式会自动关闭生产者对象，但第二种方式仍然需要开发者手动关闭。&lt;/p&gt;
&lt;h2 id=&quot;函数vs生成器&quot;&gt;函数VS生成器&lt;/h2&gt;
&lt;p&gt;但是如果使用第一种方式，怎么能在一个上下文里面接收生产者传进来的数据呢？这个时候才是yield派上用场的时候。&lt;/p&gt;
&lt;p&gt;首先需要明白，使用yield以后，函数就变成了一个生成器。生成器与普通函数的不同之处可以通过下面两段代码来进行说明：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; funciton(i):
    &lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'进入'&lt;/span&gt;)
    &lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt;(i)
    &lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'结束'&lt;/span&gt;)

&lt;span class=&quot;cf&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;op&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;):
    funciton(i)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;运行效果如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7sbpmp.com1.z0.glb.clouddn.com/2018-04-13-22-29-40.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;函数在被调用的时候，函数会从里面的第一行代码一直运行到某个&lt;code&gt;return&lt;/code&gt;或者函数的最后一行才会退出。&lt;/p&gt;
&lt;p&gt;而生成器可以从中间开始运行，从中间跳出。例如下面的代码：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; generator():
    &lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'进入'&lt;/span&gt;)
    i &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;cf&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;:
        &lt;span class=&quot;cf&quot;&gt;if&lt;/span&gt; i &lt;span class=&quot;op&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;None&lt;/span&gt;:
            &lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt;(i)
        &lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'跳出'&lt;/span&gt;)
        i &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;cf&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;None&lt;/span&gt;

g &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; generator()
&lt;span class=&quot;bu&quot;&gt;next&lt;/span&gt;(g)
&lt;span class=&quot;cf&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;op&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;):
    g.send(i)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;运行效果如下图所示。&lt;br/&gt;&lt;img src=&quot;http://7sbpmp.com1.z0.glb.clouddn.com/2018-04-13-23-09-43.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从图中可以看到，&lt;code&gt;进入&lt;/code&gt;只打印了一次。代码运行到&lt;code&gt;i = yield None&lt;/code&gt;后就跳到外面，外面的数据可以通过&lt;code&gt;g.send(i)&lt;/code&gt;的形式传进生成器，生成器内部拿到外面传进来的数据以后继续执行下一轮&lt;code&gt;while&lt;/code&gt;循环，打印出被传进来的内容，然后到&lt;code&gt;i = yield None&lt;/code&gt;的时候又跳出。如此反复。&lt;/p&gt;
&lt;p&gt;所以回到最开始的Kafka问题。如果把&lt;code&gt;with topic.get_producer(delivery_reports=True) as producer&lt;/code&gt;写在上面这一段代码的&lt;code&gt;print('进入')&lt;/code&gt;这个位置上，那岂不是只需要获取一次Kafka生产者对象，然后就可以一直使用了？&lt;/p&gt;
&lt;p&gt;根据这个逻辑，设计如下代码：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; time
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; pykafka &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; KafkaClient

client &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; KafkaClient(hosts&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&quot;127.0.0.1:9092&quot;&lt;/span&gt;)
topic &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; client.topics[b&lt;span class=&quot;st&quot;&gt;'test'&lt;/span&gt;]


&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; consumer():
    &lt;span class=&quot;cf&quot;&gt;with&lt;/span&gt; topic.get_producer(delivery_reports&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;) &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; producer:
        &lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'init finished..'&lt;/span&gt;)
        next_data &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;''&lt;/span&gt;
        &lt;span class=&quot;cf&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;:
            &lt;span class=&quot;cf&quot;&gt;if&lt;/span&gt; next_data:
                producer.produce(&lt;span class=&quot;bu&quot;&gt;str&lt;/span&gt;(next_data).encode())
            next_data &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;cf&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;


&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; feed():
    c &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; consumer()
    &lt;span class=&quot;bu&quot;&gt;next&lt;/span&gt;(c)
    &lt;span class=&quot;cf&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;op&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;range&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1000&lt;/span&gt;):
        c.send(i)

start &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; time.time()
feed()
end &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; time.time()
&lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt;(f&lt;span class=&quot;st&quot;&gt;'直到把所有数据塞入Kafka，一共耗时：{end - start}秒'&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这一次直接插入1000条数据，总共只需要10秒钟，相比于每插入一次都获取一次Kafka生产者对象的方法，效率提高了1000倍。运行效果如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7sbpmp.com1.z0.glb.clouddn.com/withyield.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;后记&quot;&gt;后记&lt;/h2&gt;
&lt;p&gt;读者如果仔细对比第一段代码和最后一段代码，就会发现他们本质上是一回事。但是第一段代码，也就是网上很多人讲yield的时候举的生产者-消费者的例子之所以会让人觉得毫无用处，就在于他们的消费者几乎就是秒运行，这样看不出和函数调用的差别。而我最后这一段代码，它的消费者分成两个部分，第一部分是获取Kafka生产者对象，这个过程非常耗时；第二部分是把数据通过Kafka生产者对象插入Kafka，这一部分运行速度极快。在这种情况下，使用生成器把这个消费者代码分开，让耗时长的部分只运行一次，让耗时短的反复运行，这样就能体现出生成器的优势。&lt;/p&gt;
</description>
<pubDate>Fri, 13 Apr 2018 15:17:00 +0000</pubDate>
<dc:creator>青南</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/xieqiankun/p/use_yield_correctly.html</dc:identifier>
</item>
<item>
<title>Lintcode375 Clone Binary Tree solution 题解 - bokeyyy</title>
<link>http://www.cnblogs.com/ccccnnnblog/p/8824696.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ccccnnnblog/p/8824696.html</guid>
<description>&lt;div readability=&quot;44.86432160804&quot;&gt;
&lt;p&gt;&lt;strong&gt;【题目描述】&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; For the given binary tree, return a &lt;strong&gt;deep copy &lt;/strong&gt;of it.&lt;/p&gt;
&lt;p&gt;深度复制一个二叉树,给定一个二叉树，返回一个他的&lt;strong&gt;克隆品&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;【题目链接】&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://link.jianshu.com/?t=http://www.lintcode.com/en/problem/clone-binary-tree/&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;www.lintcode.com/en/problem/clone-binary-tree/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;【题目解析】&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;假设有如下链表：&lt;/p&gt;
&lt;p&gt;|---------------|&lt;/p&gt;
&lt;p&gt;|                 v&lt;/p&gt;
&lt;p&gt;1  --&amp;gt; 2 --&amp;gt; 3 --&amp;gt; 4&lt;/p&gt;
&lt;p&gt;节点1的random指向了3。首先我们可以通过next遍历链表，依次拷贝节点，并将其添加到原节点后面，如下：&lt;/p&gt;
&lt;p&gt;|-----------------------------|&lt;/p&gt;
&lt;p&gt;|                                   v&lt;/p&gt;
&lt;p&gt;1  --&amp;gt; 1' --&amp;gt; 2 --&amp;gt; 2' --&amp;gt; 3 --&amp;gt; 3' --&amp;gt; 4 --&amp;gt; 4'&lt;/p&gt;
&lt;p&gt;          |                          ^&lt;/p&gt;
&lt;p&gt;          |----------------------|&lt;/p&gt;
&lt;p&gt;因为我们只是简单的复制了random指针，所以新的节点的random指向的仍然是老的节点，譬如上面的1和1'都是指向的3。&lt;/p&gt;
&lt;p&gt;调整新的节点的random指针，对于上面例子来说，我们需要将1'的random指向3'，其实也就是原先random指针的next节点。&lt;/p&gt;
&lt;p&gt;|------------------------------|&lt;/p&gt;
&lt;p&gt;|                                   v&lt;/p&gt;
&lt;p&gt;1  --&amp;gt; 1' --&amp;gt; 2 --&amp;gt; 2' --&amp;gt; 3 --&amp;gt; 3' --&amp;gt; 4 --&amp;gt; 4'&lt;/p&gt;
&lt;p&gt;          |                                  ^&lt;/p&gt;
&lt;p&gt;          |----------------------------|&lt;/p&gt;
&lt;p&gt;最后，拆分链表，就可以得到深拷贝的链表了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;【参考答案】&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://link.jianshu.com/?t=http://www.jiuzhang.com/solutions/clone-binary-tree/&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;www.jiuzhang.com/solutions/clone-binary-tree/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
<pubDate>Fri, 13 Apr 2018 15:14:00 +0000</pubDate>
<dc:creator>bokeyyy</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/ccccnnnblog/p/8824696.html</dc:identifier>
</item>
<item>
<title>Spring(2)——Spring IoC 详解 - 我没有三颗心脏</title>
<link>http://www.cnblogs.com/wmyskxz/p/8824597.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wmyskxz/p/8824597.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/7896890-34e6864b15c793ec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;spring-ioc-概述&quot;&gt;Spring IoC 概述&lt;/h2&gt;
&lt;h4 id=&quot;iocinverse-of-control控制反转&quot;&gt;IoC：Inverse of Control（控制反转）&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;读作&lt;strong&gt;“反转控制”&lt;/strong&gt;，更好理解，不是什么技术，而是一种&lt;strong&gt;设计思想&lt;/strong&gt;，就是&lt;strong&gt;将原本在程序中手动创建对象的控制权，交由Spring框架来管理。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;正控：&lt;/strong&gt;若要使用某个对象，需要&lt;strong&gt;自己去负责对象的创建&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;反控：&lt;/strong&gt;若要使用某个对象，只需要&lt;strong&gt;从 Spring 容器中获取需要使用的对象，不关心对象的创建过程&lt;/strong&gt;，也就是把&lt;strong&gt;创建对象的控制权反转给了Spring框架&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;好莱坞法则：&lt;/strong&gt;Don’t call me ,I’ll call you&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;一个例子&quot;&gt;一个例子&lt;/h4&gt;
&lt;p&gt;控制反转显然是一个抽象的概念，我们举一个鲜明的例子来说明。&lt;/p&gt;
&lt;p&gt;在现实生活中，人们要用到一样东西的时候，第一反应就是去找到这件东西，比如想喝新鲜橙汁，在没有饮品店的日子里，最直观的做法就是：买果汁机、买橙子，然后准备开水。值得注意的是：这些都是你自己&lt;strong&gt;“主动”创造&lt;/strong&gt;的过程，也就是说一杯橙汁需要你自己创造。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/7896890-e460070aba0d8ab0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然而到了今时今日，由于饮品店的盛行，当我们想喝橙汁时，第一想法就转换成了找到饮品店的联系方式，通过电话等渠道描述你的需要、地址、联系方式等，下订单等待，过一会儿就会有人送来橙汁了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/7896890-5cebd72ddc461d18.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;请注意你并没有“主动”去创造橙汁&lt;/strong&gt;，橙汁是由饮品店创造的，而不是你，然而也完全达到了你的要求，甚至比你创造的要好上那么一些。&lt;/p&gt;
&lt;h4 id=&quot;spring-ioc-阐述&quot;&gt;Spring IoC 阐述&lt;/h4&gt;
&lt;p&gt;这就是一种控制反转的理念，上述的例子已经很好的说明了问题，我们再来描述一下控制反转的概念：&lt;strong&gt;控制反转是一种通过描述（在 Java 中可以是 XML 或者注解）并通过第三方（Spring）去产生或获取特定对象的方式。&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;好处：&lt;/strong&gt;&lt;br/&gt;降低对象之间的耦合&lt;br/&gt;我们不需要理解一个类的具体实现，只需要知道它有什么用就好了（直接向 IoC 容器拿）&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;主动创建的模式中，责任归于开发者，而在被动的模式下，责任归于 IoC 容器，&lt;strong&gt;基于这样的被动形式，我们就说对象被控制反转了。（也可以说是反转了控制）&lt;/strong&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;spring-ioc-容器&quot;&gt;Spring IoC 容器&lt;/h2&gt;
&lt;p&gt;Spring 会提供 &lt;strong&gt;IoC 容器&lt;/strong&gt;来管理和容纳我们所开发的各种各样的 Bean，并且我们可以从中获取各种发布在 Spring IoC 容器里的 Bean，并且&lt;strong&gt;通过描述&lt;/strong&gt;可以得到它。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/7896890-5b59278f85cd6086.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;spring-ioc-容器的设计&quot;&gt;Spring IoC 容器的设计&lt;/h4&gt;
&lt;p&gt;Spring IoC 容器的设计主要是基于以下两个接口：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;BeanFactory&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ApplicationContext&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;其中 ApplicationContext 是 BeanFactory 的子接口之一，换句话说：&lt;strong&gt;BeanFactory 是 Spring IoC 容器所定义的最底层接口，&lt;/strong&gt;而 ApplicationContext 是其最高级接口之一，并对 BeanFactory 功能做了许多的扩展，所以在&lt;strong&gt;绝大部分的工作场景下&lt;/strong&gt;，都会使用 ApplicationContext 作为 Spring IoC 容器。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/7896890-539d3860abb6b3f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;ApplicationContext 继承关系&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;beanfactory&quot;&gt;BeanFactory&lt;/h4&gt;
&lt;p&gt;从上图中我们可以几乎看到， BeanFactory 位于设计的最底层，它提供了 Spring IoC 最底层的设计，为此，我们先来看看该类中提供了哪些方法：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/7896890-ec7f8eb4cc563216.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot;/&gt;&lt;/p&gt;
&lt;p&gt;由于这个接口的重要性，所以有必要在这里作一下简短的说明：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;【getBean】 对应了多个方法来获取配置给 Spring IoC 容器的 Bean。&lt;br/&gt;① 按照类型拿 bean：&lt;br/&gt;&lt;code&gt;bean = (Bean) factory.getBean(Bean.class);&lt;/code&gt;&lt;br/&gt;&lt;strong&gt;注意：&lt;/strong&gt;要求在 Spring 中只配置了一个这种类型的实例，否则报错。（如果有多个那 Spring 就懵了，不知道该获取哪一个）&lt;br/&gt;② 按照 bean 的名字拿 bean:&lt;br/&gt;&lt;code&gt;bean = (Bean) factory.getBean(&quot;beanName&quot;);&lt;/code&gt;&lt;br/&gt;&lt;strong&gt;注意：&lt;/strong&gt;这种方法不太安全，IDE 不会检查其安全性（关联性）&lt;br/&gt;③ 按照名字和类型拿 bean：&lt;strong&gt;（推荐）&lt;/strong&gt;&lt;br/&gt;&lt;code&gt;bean = (Bean) factory.getBean(&quot;beanName&quot;, Bean.class);&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;【isSingleton】 用于判断是否单例，如果判断为真，其意思是该 Bean 在容器中是作为一个唯一单例存在的。而【isPrototype】则相反，如果判断为真，意思是当你从容器中获取 Bean，容器就为你生成一个新的实例。&lt;br/&gt;&lt;strong&gt;注意：&lt;/strong&gt;在默认情况下，【isSingleton】为 ture，而【isPrototype】为 false&lt;/li&gt;
&lt;li&gt;关于 type 的匹配，这是一个按 Java 类型匹配的方式&lt;/li&gt;
&lt;li&gt;【getAliases】方法是获取别名的方法&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这就是 Spring IoC 最底层的设计，所有关于 Spring IoC 的容器将会遵守它所定义的方法。&lt;/p&gt;
&lt;h4 id=&quot;applicationcontext&quot;&gt;ApplicationContext&lt;/h4&gt;
&lt;p&gt;根据 ApplicationContext 的类继承关系图，可以看到 ApplicationContext 接口扩展了许许多多的接口，因此它的功能十分强大，所以在实际应用中常常会使用到的是 ApplicationContext 接口，因为 BeanFactory 的方法和功能较少，而 ApplicationContext 的方法和功能较多。&lt;/p&gt;
&lt;p&gt;通过&lt;a href=&quot;https://www.jianshu.com/p/1af66a499f49&quot;&gt;上一篇 IoC 的例子&lt;/a&gt;，我们来认识一个 ApplicationContext 的子类——ClassPathXmlApplicationContext。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;先在【src】目录下创建一个 【bean.xml】 文件：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;
&amp;lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;
       xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
       xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&amp;gt;
    &amp;lt;!-- 通过 xml 方式装配 bean --&amp;gt;
    &amp;lt;bean name=&quot;source&quot; class=&quot;pojo.Source&quot;&amp;gt;
        &amp;lt;property name=&quot;fruit&quot; value=&quot;橙子&quot;/&amp;gt;
        &amp;lt;property name=&quot;sugar&quot; value=&quot;多糖&quot;/&amp;gt;
        &amp;lt;property name=&quot;size&quot; value=&quot;超大杯&quot;/&amp;gt;
    &amp;lt;/bean&amp;gt;
&amp;lt;/beans&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;ol&gt;&lt;li&gt;这里定义了一个 bean ，这样 Spring IoC 容器在初始化的时候就能找到它们，然后使用 ClassPathXmlApplicationContext 容器就可以将其初始化：&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code&gt;ApplicationContext context = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);
Source source = (Source) context.getBean(&quot;source&quot;, Source.class);

System.out.println(source.getFruit());
System.out.println(source.getSugar());
System.out.println(source.getSize());&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样就会使用 Application 的实现类 ClassPathXmlApplicationContext 去初始化 Spring IoC 容器，然后开发者就可以通过 IoC 容器来获取资源了啦！&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;关于 Spring Bean 的装配以及一些细节，会在下一篇文章中讲到&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;applicationcontext-常见实现类&quot;&gt;ApplicationContext 常见实现类：&lt;/h4&gt;
&lt;p&gt;1.&lt;strong&gt;ClassPathXmlApplicationContext：&lt;/strong&gt;&lt;br/&gt;读取classpath中的资源&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;ApplicationContext ctx = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;2:&lt;strong&gt;FileSystemXmlApplicationContext:-&lt;/strong&gt;&lt;br/&gt;读取指定路径的资源&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;ApplicationContext ac = new FileSystemXmlApplicationContext(&quot;c:/applicationContext.xml&quot;);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;3.&lt;strong&gt;XmlWebApplicationContext:&lt;/strong&gt;&lt;br/&gt;需要在Web的环境下才可以运行&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;XmlWebApplicationContext ac = new XmlWebApplicationContext(); // 这时并没有初始化容器
ac.setServletContext(servletContext); // 需要指定ServletContext对象
ac.setConfigLocation(&quot;/WEB-INF/applicationContext.xml&quot;); // 指定配置文件路径，开头的斜线表示Web应用的根目录
ac.refresh(); // 初始化容器&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;beanfactory-和-applicationcontext-的区别&quot;&gt;BeanFactory 和 ApplicationContext 的区别：&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;BeanFactory：&lt;/strong&gt;是Spring中最底层的接口，只提供了最简单的IoC功能,负责配置，创建和管理bean。&lt;br/&gt;在应用中，一般不使用 BeanFactory，而推荐使用ApplicationContext（应用上下文），原因如下。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ApplicationContext：&lt;/strong&gt;&lt;br/&gt;1.继承了 BeanFactory，拥有了基本的 IoC 功能；&lt;br/&gt;2.除此之外，ApplicationContext 还提供了以下功能：&lt;br/&gt;① 支持国际化；&lt;br/&gt;② 支持消息机制；&lt;br/&gt;③ 支持统一的资源加载；&lt;br/&gt;④ 支持AOP功能；&lt;/li&gt;
&lt;/ul&gt;&lt;hr/&gt;&lt;h2 id=&quot;spring-ioc-的容器的初始化和依赖注入&quot;&gt;Spring IoC 的容器的初始化和依赖注入&lt;/h2&gt;
&lt;p&gt;虽然 Spring IoC 容器的生成十分的复杂，但是大体了解一下 Spring IoC 初始化的过程还是必要的。这对于理解 Spring 的一系列行为是很有帮助的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;Bean 的定义和初始化在 Spring IoC 容器是两大步骤，它是先定义，然后初始化和依赖注入的。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Bean 的定义分为 3 步：&lt;/strong&gt;&lt;br/&gt;1.Resource 定位&lt;br/&gt;Spring IoC 容器先根据开发者的配置，进行资源的定位，在 Spring 的开发中，通过 XML 或者注解都是十分常见的方式，定位的内容是由开发者提供的。&lt;br/&gt;2.BeanDefinition 的载入&lt;br/&gt;这个时候只是将 Resource 定位到的信息，保存到 Bean 定义（BeanDefinition）中，此时并不会创建 Bean 的实例&lt;br/&gt;3.BeanDefinition 的注册&lt;br/&gt;这个过程就是将 BeanDefinition 的信息发布到 Spring IoC 容器中&lt;br/&gt;&lt;strong&gt;注意：&lt;/strong&gt;此时仍然没有对应的 Bean 的实例。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;做完了以上 3 步，Bean 就在 Spring IoC 容器中被定义了，而没有被初始化，更没有完成依赖注入，也就是没有注入其配置的资源给 Bean，那么它还不能完全使用。&lt;/p&gt;
&lt;p&gt;对于初始化和依赖注入，Spring Bean 还有一个配置选项——&lt;strong&gt;【lazy-init】&lt;/strong&gt;，其含义就是&lt;strong&gt;是否初始化 Spring Bean&lt;/strong&gt;。在没有任何配置的情况下，它的默认值为 default，实际值为 false，也就是 &lt;strong&gt;Spring IoC 默认会自动初始化 Bean&lt;/strong&gt;。如果将其设置为 true，那么只有当我们使用 Spring IoC 容器的 getBean 方法获取它时，它才会进行 Bean 的初始化，完成依赖注入。&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;ioc-是如何实现的&quot;&gt;IoC 是如何实现的&lt;/h2&gt;
&lt;p&gt;最后我们简单说说IoC是如何实现的。想象一下如果我们自己来实现这个依赖注入的功能，我们怎么来做？ 无外乎：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;读取标注或者配置文件，看看JuiceMaker依赖的是哪个Source，拿到类名&lt;/li&gt;
&lt;li&gt;使用反射的API，基于类名实例化对应的对象实例&lt;/li&gt;
&lt;li&gt;将对象实例，通过构造函数或者 setter，传递给 JuiceMaker&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;我们发现其实自己来实现也不是很难，Spring实际也就是这么做的。这么看的话其实IoC就是一个工厂模式的升级版！当然要做一个成熟的IoC框架，还是非常多细致的工作要做，Spring不仅提供了一个已经成为业界标准的Java IoC框架，还提供了更多强大的功能，所以大家就别去造轮子啦！希望了解IoC更多实现细节不妨通过学习Spring的源码来加深理解！&lt;/p&gt;
&lt;blockquote readability=&quot;4.7305936073059&quot;&gt;
&lt;p&gt;引用地址：&lt;a href=&quot;https://link.jianshu.com/?t=https%3A%2F%2Fwww.tianmaying.com%2Ftutorial%2Fspring-ioc&quot;&gt;这里&lt;/a&gt;&lt;br/&gt;【参考资料】:《Java EE 互联网轻量级框架整合开发》、《Spring 实战（第四版）》&lt;br/&gt;【好文推荐】：&lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzAxOTc0NzExNg==&amp;amp;mid=2665513179&amp;amp;idx=1&amp;amp;sn=772226a5be436a0d08197c335ddb52b8&amp;amp;scene=21#wechat_redirect&quot;&gt;①Spring 的本质系列(1) -- 依赖注入&lt;/a&gt;、 &lt;a href=&quot;https://www.tianmaying.com/tutorial/spring-ioc&quot;&gt;②Spring的IoC原理&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;3.3290322580645&quot;&gt;
&lt;hr/&gt;&lt;p&gt;欢迎转载，转载请注明出处！&lt;br/&gt;@我没有三颗心脏&lt;br/&gt;CSDN博客：&lt;a href=&quot;http://blog.csdn.net/qq939419061&quot; class=&quot;uri&quot;&gt;http://blog.csdn.net/qq939419061&lt;/a&gt;&lt;br/&gt;简书：&lt;a href=&quot;http://www.jianshu.com/u/a40d61a49221&quot; class=&quot;uri&quot;&gt;http://www.jianshu.com/u/a40d61a49221&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Fri, 13 Apr 2018 14:52:00 +0000</pubDate>
<dc:creator>我没有三颗心脏</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/wmyskxz/p/8824597.html</dc:identifier>
</item>
<item>
<title>关于CORS跨域问题的理解 - 如是说</title>
<link>http://www.cnblogs.com/lishanlei/p/8823823.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/lishanlei/p/8823823.html</guid>
<description>&lt;p&gt;因为这段时间一个项目前后端分别部署在不同服务器的需要,抽空学习了一下CORS问题,不足之处,欢迎指教.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;什么是CORS&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;CORS是一个w3c标准,全称是&quot;跨域资源共享&quot;(Cross-origin resource sharing),但一个请求url的协议,域名,端口三者之间任意与当前页面地址不同即为跨域.它允许阅览器向跨源服务器发送XMLHttpRequest请求,从而客服AJAX只能同源使用的限制.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;CORS简介&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;浏览器默认的安全限制为同源策略，即JavaScript或Cookie只能访问&lt;strong&gt;同源&lt;/strong&gt;（相同协议，相同域名，相同端口）下的内容。但由于跨域访问资源需要，出现了CORS机制，这种机制让web服务器能跨站访问控制，使跨站数据传输更安全。CORS需要阅览器和服务器同时支持，目前，主流的阅览器都支持cors。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1201942/201804/1201942-20180413161539028-1424877000.png&quot; alt=&quot;&quot; width=&quot;1016&quot; height=&quot;314&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;CORS的两种请求方式&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;浏览器将CORS请求分为两类：简单请求和非简单请求&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;一  简单请求&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.1 区分条件：&lt;/p&gt;
&lt;p&gt;只要满足一下两大条件，属于简单请求：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
（1) 请求方法是以下三种方法之一：
        HEAD
        GET
        POST
（2）HTTP的头信息不超出以下几种字段：
        Accept
        Accept-Language
        Content-Language
        Last-Event-ID
        Content-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain        
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;不同时满足上面两个条件，就是非简单请求&lt;/p&gt;
&lt;p&gt;1.2 简单请求的基本流程&lt;/p&gt;
&lt;p&gt;浏览器直接发送CORS跨域请求，并在header信息中增加一个&lt;strong&gt;Origin&lt;/strong&gt;字段，表明这是一个跨域的请求。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
    &amp;lt;script&amp;gt;
        var url = 'http://www.lishanlei.cn/CorsTest/CorsTest.php';
        var xhr = new XMLHttpRequest();
        xhr.open('get', url, true);
        // xhr.setRequestHeader('X-Custom-Header', 'value');
        xhr.send();
    &amp;lt;/script&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在上面的代码中以get形式向www.lishanlei.cn进行跨域访问。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1201942/201804/1201942-20180413164504589-1345131255.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上面的头信息Origin字段用来说明本次请求来自哪个源(协议+域名+端口)。服务器根据这个值，决定是否同意这次请求。如果&lt;strong&gt;Origin&lt;/strong&gt;指定的源，不在许可范围内，服务器会返回一个正常的HTTP回应，浏览器收到这个回应发现这个回应的头信息没有包含Access-Control-Allow-Origin字段，就知道错了，从而会抛出一个错误，被&lt;strong&gt;XMLHttpRequest&lt;/strong&gt;的&lt;strong&gt;onerror&lt;/strong&gt;回调函数捕获。注意这种错误无法通过状态码识别，此时HTTP回应的状态码可能是200&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdn.net/20180413165637273?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpc2hhbmxlaWxpeGlu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img-blog.csdn.net/20180413165708341?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpc2hhbmxlaWxpeGlu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如果Origin指定的域名在许可范围内，服务器返回的响应会多出几个头信息字段&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdn.net/20180413173721243?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpc2hhbmxlaWxpeGlu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Access-Control-Allow-Origin&lt;/strong&gt;：该字段是必须的，其值可能是请求时Origin字段的值，也可能是一个*，表示接受任意域名请求。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Access-Control-Allow-Credentials&lt;/strong&gt;:该字段可选，其值类型是布尔型，表示是否允许发送Cookie。默认情况下Cookie不包括在CORS请求中。当设为true时表示服务器明确许可，Cookie可以包含在请求中一起发送给服务器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Access-Control-Allow-Headers&lt;/strong&gt;:该字段必须，它是一个都好分割的字符串，表明服务器支持的所有头信息字段&lt;/p&gt;
&lt;p&gt;1.3 &lt;strong&gt;withCredentials&lt;/strong&gt;属性&lt;/p&gt;
&lt;p&gt;默认情况下，CORS请求默认不发送Cookie和Http认证信息，如果要把Cookie发送到服务器，首先要指定Access-Control-Alloe-Credentials字段，另一方面，需要在AJAX请求中打开withCredentials属性&lt;/p&gt;
&lt;pre class=&quot;html&quot;&gt;
var xml = new XMLHttpRequest();
xml.withCredentials = true;
&lt;/pre&gt;
&lt;p&gt;如果没有设置该属性为&lt;strong&gt;true&lt;/strong&gt;，即使服务器统一发送Cookie，浏览器也不会发送。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdn.net/20180413201327870?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpc2hhbmxlaWxpeGlu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70&quot; alt=&quot;&quot; height=&quot;400&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当该属性设置为true时，即需要发送Cookie那么在服务器中Access-Control-Allow-Origin就&lt;span&gt;不能设置成*&lt;/span&gt;,必须指定吗明确的与请求一致的域名，同时，Cookie依然遵循同源政策。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdn.net/20180413174626338?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpc2hhbmxlaWxpeGlu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;二  非简单请求&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当不同时满足区分条件的，就是非简单请求。&lt;/p&gt;
&lt;p&gt;2.1 预检请求&lt;/p&gt;
&lt;p&gt;非简单请求的CORS请求，会在正式通信前进行一次Http查询请求，又称预检请求。&lt;/p&gt;
&lt;p&gt;浏览器先请求服务器，当前网页所在域名是否在服务器许可名单中以及可以使用那些HTTP动词和头信息字段，当客户端得到肯定答复时，浏览器才会正式发出XMLHttpRequest请求。&lt;/p&gt;
&lt;pre class=&quot;html&quot;&gt;
var url = 'http://www.lishanlei.cn/CorsTest/CorsTest.php';
var xhr = new XMLHttpRequest();
xhr.open('PUT', url, true);
xhr.setRequestHeader('X-Custom-Header', 'value');
xhr.send();
&lt;/pre&gt;
&lt;p&gt;上面代码中，请求方式是&lt;strong&gt;PUT&lt;/strong&gt;，并发送一个自定义头信息X-custom-Header,但在服务器的头信息中没有包含X-custom-Header,故浏览器报错，只进行了一次预检请求。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdn.net/20180413181217473?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpc2hhbmxlaWxpeGlu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdn.net/20180413181254320?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpc2hhbmxlaWxpeGlu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;设置header中的Access-Control-Allow-Headers字段：&lt;/p&gt;
&lt;pre class=&quot;html&quot;&gt;
header('Access-Control-Allow-Headers:x-requested-with,content-type,X-Custom-Header');
&lt;/pre&gt;
&lt;p&gt;再次访问&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdn.net/20180413195624256?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpc2hhbmxlaWxpeGlu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;浏览器发现这是一个非简单请求，自动发出一个预检请求，要求服务其确认这样的请求，下面是这个预检请求的HTTP头信息：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdn.net/20180413195843448?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpc2hhbmxlaWxpeGlu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;预检请求用的请求方法是&lt;strong&gt;OPTIONS&lt;/strong&gt;,表示这个请求是用来询问的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Access-Control-Request-Method&lt;/strong&gt;:该字段是必须的，用来列出浏览器的CORS请求会用到哪些HTTP方法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Access-Control-Request-Headers&lt;/strong&gt;:该字段是一个逗号分割的字符串，指定浏览器CORS请求会额外发送的头信息字段。&lt;/p&gt;
&lt;p&gt;2.2预检请求的回应&lt;/p&gt;
&lt;p&gt;当服务其收到预检请求后，检查了Origin,Access-Control-Request-Method等信息字段后，如果没有问题，则确认允许跨源请求，就可以做出了回应。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img-blog.csdn.net/20180413200449436?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpc2hhbmxlaWxpeGlu/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Access-Control-Allow-Methods&lt;/strong&gt;:该字段必须，其值是逗号分隔的一个字符串，表明服务器支持的所有跨域请求的方法。这是为了避免多次预检请求。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Access-Control-Max-Age&lt;/strong&gt;:该字段是可选的，用来指定本次预检请求的有效期，单位是秒。Access-Control-Max-Age:20,即允许缓存该条回应20秒，再此期间不用发出另一条预检请求&lt;/p&gt;
&lt;p&gt;如果浏览器否定了预检请求，会返回一个正常的HTTP回应，但是没有任何CORS相关的头信息字段。浏览器此时会认定服务器不同意预检请求，触发一个错误，被&lt;strong&gt;XMLHttpRequest&lt;/strong&gt;的&lt;strong&gt;onerror&lt;/strong&gt;回调函数捕获。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;服务器端处理机制&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;服务器对于跨域请求的处理流程如下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;首先查看http头部有无origin字段；&lt;/li&gt;
&lt;li&gt;如果没有，或者不允许，当成普通请求；&lt;/li&gt;
&lt;li&gt;如果有且是允许的，再看是否是preflight(method=OPTIONS);&lt;/li&gt;
&lt;li&gt;如果不是preflight(简单请求)，返回Allow-Origin,Allow-Credential等字段，并返回正常内容；&lt;/li&gt;
&lt;li&gt;如果是preflight(非简单请求)，返回Allow-Headers,Allow-Methods等；&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;配置CORS规则&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;一  apache上配置CORS规则&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Apache需要使用mod_headers模块来激活HTTP头设置，默认是激活的，只需要修改Apache配置文件中的/etc/apache2/sites-available/000-default.conf&lt;/p&gt;
&lt;pre class=&quot;html&quot;&gt;
1 开启模块 
sudo a2enmod headers 
2 编辑配置文件 
sudo vi /etc/apache2/sites-available/000-default.conf 
3 在虚拟主机Directory设置下添加 
Header set Access-Control-Allow-Origin *
&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;与JSONP的比较&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;CORS和JSONP都是为了使web浏览器能够跨源请求，使用目的相同，但是比JSONP更强大。JSONP只支持GET请求，而CORS支持所有类型的HTTP请求，不过JSONP的优势在于支持老式浏览器以及可以向不支持CORS的网站跨源请求。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;参考博文&lt;/span&gt;&lt;/strong&gt;：&lt;span&gt;&lt;strong&gt;http://www.ruanyifeng.com/blog/2016/04/cors.html&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;                 https://blog.csdn.net/u014344668/article/details/54948546&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 13 Apr 2018 12:51:00 +0000</pubDate>
<dc:creator>如是说</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/lishanlei/p/8823823.html</dc:identifier>
</item>
<item>
<title>Docker 基础技术之 Linux namespace 源码分析 - bakari</title>
<link>http://www.cnblogs.com/bakari/p/8823642.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/bakari/p/8823642.html</guid>
<description>&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/bakari/p/8560437.html&quot;&gt;上篇&lt;/a&gt;我们从进程 clone 的角度，结合代码简单分析了 Linux 提供的 6 种 namespace，本篇从源码上进一步分析 Linux namespace，让你对 Docker namespace 的隔离机制有更深的认识。我用的是 Linux-4.1.19 的版本，由于 namespace 模块更新都比较少，所以，只要 3.0 以上的版本都是差不多的。&lt;/p&gt;
&lt;h3 id=&quot;从内核进程描述符-task_struct-开始切入&quot;&gt;从内核进程描述符 task_struct 开始切入&lt;/h3&gt;
&lt;p&gt;由于 Linux namespace 是用来做进程资源隔离的，所以在进程描述符中，一定有 namespace 所对应的信息，我们可以从这里开始切入代码。&lt;/p&gt;
&lt;p&gt;首先找到描述进程信息 task_struct，找到指向 namespace 的结构 struct *nsproxy（sched.h）：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;struct task_struct {
......
/* namespaces */
struct nsproxy *nsproxy;
......
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中 nsproxy 结构体定义在 nsproxy.h 中：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;/*
* A structure to contain pointers to all per-process
* namespaces - fs (mount), uts, network, sysvipc, etc.
*
* 'count' is the number of tasks holding a reference.
* The count for each namespace, then, will be the number
* of nsproxies pointing to it, not the number of tasks.
*
* The nsproxy is shared by tasks which share all namespaces.
* As soon as a single namespace is cloned or unshared, the
* nsproxy is copied.
*/
struct nsproxy {
 atomic_t count;
 struct uts_namespace *uts_ns;
 struct ipc_namespace *ipc_ns;
 struct mnt_namespace *mnt_ns;
 struct pid_namespace *pid_ns;
 struct net        *net_ns;
};
extern struct nsproxy init_nsproxy;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个结构是被所有 namespace 所共享的，只要一个 namespace 被 clone 了，nsproxy 也会被 clone。注意到，由于 user namespace 是和其他 namespace 耦合在一起的，所以没出现在上述结构中。&lt;/p&gt;
&lt;p&gt;同时，nsproxy.h 中还定义了一些对 namespace 的操作，包括 copy_namespaces 等。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;int copy_namespaces(unsigned long flags, struct task_struct *tsk);
void exit_task_namespaces(struct task_struct *tsk);
void switch_task_namespaces(struct task_struct *tsk, struct nsproxy *new);
void free_nsproxy(struct nsproxy *ns);
int unshare_nsproxy_namespaces(unsigned long, struct nsproxy **,
 struct fs_struct *);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;task_struct，nsproxy，几种 namespace 之间的关系如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/431521/201804/431521-20180413192120081-1220838717.png&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;各个-namespace-的初始化&quot;&gt;各个 namespace 的初始化&lt;/h3&gt;
&lt;p&gt;在各个 namespace 结构定义下都有个 init 函数，nsproxy 也有个 init_nsproxy 函数，init_nsproxy 在 task 初始化的时候会被初始化，附带的，init_nsproxy 中定义了各个 namespace 的 init 函数，如下：&lt;/p&gt;
&lt;p&gt;在 init_task 函数中（init_task.h）:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;/*
*  INIT_TASK is used to set up the first task table, touch at
* your own risk!. Base=0, limit=0x1fffff (=2MB)
*/
#define INIT_TASK(tsk)  \
{
......
 .nsproxy  = &amp;amp;init_nsproxy,        
......
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;继续跟进 init_nsproxy，在 nsproxy.c 中：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;struct nsproxy init_nsproxy = {
 .count      = ATOMIC_INIT(1),
 .uts_ns      = &amp;amp;init_uts_ns,
#if defined(CONFIG_POSIX_MQUEUE) || defined(CONFIG_SYSVIPC)
 .ipc_ns      = &amp;amp;init_ipc_ns,
#endif
 .mnt_ns      = NULL,
 .pid_ns_for_children  = &amp;amp;init_pid_ns,
#ifdef CONFIG_NET
 .net_ns      = &amp;amp;init_net,
#endif
};&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可见，init_nsproxy 中，对 uts, ipc, pid, net 都进行了初始化，但 mount 却没有。&lt;/p&gt;
&lt;h3 id=&quot;创建新的-namespace&quot;&gt;创建新的 namespace&lt;/h3&gt;
&lt;p&gt;初始化完之后，下面看看如何创建一个新的 namespace，通过前面的文章，我们知道是通过 clone 函数来完成的，在 Linux kernel 中，fork/vfork() 对 clone 进行了封装。如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#ifdef __ARCH_WANT_SYS_FORK
SYSCALL_DEFINE0(fork)
{
#ifdef CONFIG_MMU
 return do_fork(SIGCHLD, 0, 0, NULL, NULL);
#else
 /* can not support in nommu mode */
 return -EINVAL;
#endif
}
#endif

#ifdef __ARCH_WANT_SYS_VFORK
SYSCALL_DEFINE0(vfork)
{
 return do_fork(CLONE_VFORK | CLONE_VM | SIGCHLD, 0,
     0, NULL, NULL);
}
#endif

#ifdef __ARCH_WANT_SYS_CLONE
#ifdef CONFIG_CLONE_BACKWARDS
SYSCALL_DEFINE5(clone, unsigned long, clone_flags, unsigned long, newsp,
    int __user *, parent_tidptr,
    int, tls_val,
    int __user *, child_tidptr)
#elif defined(CONFIG_CLONE_BACKWARDS2)
SYSCALL_DEFINE5(clone, unsigned long, newsp, unsigned long, clone_flags,
    int __user *, parent_tidptr,
    int __user *, child_tidptr,
    int, tls_val)
#elif defined(CONFIG_CLONE_BACKWARDS3)
SYSCALL_DEFINE6(clone, unsigned long, clone_flags, unsigned long, newsp,
   int, stack_size,
   int __user *, parent_tidptr,
   int __user *, child_tidptr,
   int, tls_val)
#else
SYSCALL_DEFINE5(clone, unsigned long, clone_flags, unsigned long, newsp,
    int __user *, parent_tidptr,
    int __user *, child_tidptr,
    int, tls_val)
#endif
{
 return do_fork(clone_flags, newsp, 0, parent_tidptr, child_tidptr);
}
#endif&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到，无论是 fork() 还是 vfork()，最终都会调用到 do_fork() 函数：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;/*
*  Ok, this is the main fork-routine.
*
* It copies the process, and if successful kick-starts
* it and waits for it to finish using the VM if required.
*/
long do_fork(unsigned long clone_flags,
       unsigned long stack_start,
       unsigned long stack_size,
       int __user *parent_tidptr,
       int __user *child_tidptr)
{
 // 创建进程描述符指针
 struct task_struct *p;
 int trace = 0;
 long nr;

 /*
  * Determine whether and which event to report to ptracer.  When
  * called from kernel_thread or CLONE_UNTRACED is explicitly
  * requested, no event is reported; otherwise, report if the event
  * for the type of forking is enabled.
  */
 if (!(clone_flags &amp;amp; CLONE_UNTRACED)) {
   if (clone_flags &amp;amp; CLONE_VFORK)
     trace = PTRACE_EVENT_VFORK;
   else if ((clone_flags &amp;amp; CSIGNAL) != SIGCHLD)
     trace = PTRACE_EVENT_CLONE;
   else
     trace = PTRACE_EVENT_FORK;

   if (likely(!ptrace_event_enabled(current, trace)))
     trace = 0;
 }

 // 复制进程描述符，返回值是 task_struct
 p = copy_process(clone_flags, stack_start, stack_size,
      child_tidptr, NULL, trace);
 /*
  * Do this prior waking up the new thread - the thread pointer
  * might get invalid after that point, if the thread exits quickly.
  */
 if (!IS_ERR(p)) {
   struct completion vfork;
   struct pid *pid;

   trace_sched_process_fork(current, p);

   // 得到新进程描述符的 pid
   pid = get_task_pid(p, PIDTYPE_PID);
   nr = pid_vnr(pid);

   if (clone_flags &amp;amp; CLONE_PARENT_SETTID)
     put_user(nr, parent_tidptr);

   // 调用 vfork() 方法，完成相关的初始化工作  
   if (clone_flags &amp;amp; CLONE_VFORK) {
     p-&amp;gt;vfork_done = &amp;amp;vfork;
     init_completion(&amp;amp;vfork);
     get_task_struct(p);
   }

   // 将新进程加入到调度器中，为其分配 CPU，准备执行
   wake_up_new_task(p);

   // fork() 完成，子进程开始运行，并让 ptrace 跟踪
   /* forking complete and child started to run, tell ptracer */
   if (unlikely(trace))
     ptrace_event_pid(trace, pid);

   // 如果是 vfork()，将父进程加入等待队列，等待子进程完成
   if (clone_flags &amp;amp; CLONE_VFORK) {
     if (!wait_for_vfork_done(p, &amp;amp;vfork))
       ptrace_event_pid(PTRACE_EVENT_VFORK_DONE, pid);
   }

   put_pid(pid);
 } else {
   nr = PTR_ERR(p);
 }
 return nr;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;do_fork() 首先调用 copy_process 将父进程信息复制给子进程，然后调用 vfork() 完成相关的初始化工作，接着调用 wake_up_new_task() 将进程加入调度器中，为之分配 CPU。最后，等待子进程退出。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;copy_process():&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;static struct task_struct *copy_process(unsigned long clone_flags,
         unsigned long stack_start,
         unsigned long stack_size,
         int __user *child_tidptr,
         struct pid *pid,
         int trace)
{
 int retval;
 // 创建进程描述符指针
 struct task_struct *p;

 // 检查 clone flags 的合法性，比如 CLONE_NEWNS 与 CLONE_FS 是互斥的
 if ((clone_flags &amp;amp; (CLONE_NEWNS|CLONE_FS)) == (CLONE_NEWNS|CLONE_FS))
   return ERR_PTR(-EINVAL);

 if ((clone_flags &amp;amp; (CLONE_NEWUSER|CLONE_FS)) == (CLONE_NEWUSER|CLONE_FS))
   return ERR_PTR(-EINVAL);

 /*
  * Thread groups must share signals as well, and detached threads
  * can only be started up within the thread group.
  */
 if ((clone_flags &amp;amp; CLONE_THREAD) &amp;amp;&amp;amp; !(clone_flags &amp;amp; CLONE_SIGHAND))
   return ERR_PTR(-EINVAL);

 /*
  * Shared signal handlers imply shared VM. By way of the above,
  * thread groups also imply shared VM. Blocking this case allows
  * for various simplifications in other code.
  */
 if ((clone_flags &amp;amp; CLONE_SIGHAND) &amp;amp;&amp;amp; !(clone_flags &amp;amp; CLONE_VM))
   return ERR_PTR(-EINVAL);

 /*
  * Siblings of global init remain as zombies on exit since they are
  * not reaped by their parent (swapper). To solve this and to avoid
  * multi-rooted process trees, prevent global and container-inits
  * from creating siblings.
  */
  // 比如CLONE_PARENT时得检查当前signal flags是否为SIGNAL_UNKILLABLE，防止kill init进程。
 if ((clone_flags &amp;amp; CLONE_PARENT) &amp;amp;&amp;amp;
       current-&amp;gt;signal-&amp;gt;flags &amp;amp; SIGNAL_UNKILLABLE)
   return ERR_PTR(-EINVAL);

 /*
  * If the new process will be in a different pid or user namespace
  * do not allow it to share a thread group or signal handlers or
  * parent with the forking task.
  */
 if (clone_flags &amp;amp; CLONE_SIGHAND) {
   if ((clone_flags &amp;amp; (CLONE_NEWUSER | CLONE_NEWPID)) ||
       (task_active_pid_ns(current) !=
       current-&amp;gt;nsproxy-&amp;gt;pid_ns_for_children))
     return ERR_PTR(-EINVAL);
 }

 retval = security_task_create(clone_flags);
 if (retval)
   goto fork_out;

 retval = -ENOMEM;
 // 复制当前的 task_struct
 p = dup_task_struct(current);
 if (!p)
   goto fork_out;

 ftrace_graph_init_task(p);

 rt_mutex_init_task(p);

#ifdef CONFIG_PROVE_LOCKING
 DEBUG_LOCKS_WARN_ON(!p-&amp;gt;hardirqs_enabled);
 DEBUG_LOCKS_WARN_ON(!p-&amp;gt;softirqs_enabled);
#endif
 retval = -EAGAIN;

 // 检查进程是否超过限制，由 OS 定义
 if (atomic_read(&amp;amp;p-&amp;gt;real_cred-&amp;gt;user-&amp;gt;processes) &amp;gt;=
     task_rlimit(p, RLIMIT_NPROC)) {
   if (p-&amp;gt;real_cred-&amp;gt;user != INIT_USER &amp;amp;&amp;amp;
       !capable(CAP_SYS_RESOURCE) &amp;amp;&amp;amp; !capable(CAP_SYS_ADMIN))
     goto bad_fork_free;
 }
 current-&amp;gt;flags &amp;amp;= ~PF_NPROC_EXCEEDED;

 retval = copy_creds(p, clone_flags);
 if (retval &amp;lt; 0)
   goto bad_fork_free;

 /*
  * If multiple threads are within copy_process(), then this check
  * triggers too late. This doesn't hurt, the check is only there
  * to stop root fork bombs.
  */
 retval = -EAGAIN;
 // 检查进程数是否超过 max_threads，由内存大小定义
 if (nr_threads &amp;gt;= max_threads)
   goto bad_fork_cleanup_count;

 // ......

 // 初始化 io 计数器
 task_io_accounting_init(&amp;amp;p-&amp;gt;ioac);
 acct_clear_integrals(p);

 // 初始化 CPU 定时器
 posix_cpu_timers_init(p);

 // ......

 // 初始化进程数据结构，并为进程分配 CPU，进程状态设置为 TASK_RUNNING
 /* Perform scheduler related setup. Assign this task to a CPU. */
 retval = sched_fork(clone_flags, p);
 
 if (retval)
   goto bad_fork_cleanup_policy;

 retval = perf_event_init_task(p);
 if (retval)
   goto bad_fork_cleanup_policy;
 retval = audit_alloc(p);
 if (retval)
   goto bad_fork_cleanup_perf;
 /* copy all the process information */
 // 复制所有进程信息，包括文件系统，信号处理函数、信号、内存管理等
 shm_init_task(p);
 retval = copy_semundo(clone_flags, p);
 if (retval)
   goto bad_fork_cleanup_audit;
 retval = copy_files(clone_flags, p);
 if (retval)
   goto bad_fork_cleanup_semundo;
 retval = copy_fs(clone_flags, p);
 if (retval)
   goto bad_fork_cleanup_files;
 retval = copy_sighand(clone_flags, p);
 if (retval)
   goto bad_fork_cleanup_fs;
 retval = copy_signal(clone_flags, p);
 if (retval)
   goto bad_fork_cleanup_sighand;
 retval = copy_mm(clone_flags, p);
 if (retval)
   goto bad_fork_cleanup_signal;
 // !!! 复制 namespace
 retval = copy_namespaces(clone_flags, p);
 if (retval)
   goto bad_fork_cleanup_mm;
 retval = copy_io(clone_flags, p);
 if (retval)
   goto bad_fork_cleanup_namespaces;
 // 初始化子进程内核栈
 retval = copy_thread(clone_flags, stack_start, stack_size, p);
 if (retval)
   goto bad_fork_cleanup_io;
 // 为新进程分配新的 pid
 if (pid != &amp;amp;init_struct_pid) {
   pid = alloc_pid(p-&amp;gt;nsproxy-&amp;gt;pid_ns_for_children);
   if (IS_ERR(pid)) {
     retval = PTR_ERR(pid);
     goto bad_fork_cleanup_io;
   }
 }

 // ......

 // 返回新进程 p
 return p;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;copy_process 主要分为三步：首先调用 dup_task_struct() 复制当前的进程描述符信息 task_struct，为新进程分配新的堆栈，第二步调用 sched_fork() 初始化进程数据结构，为其分配 CPU，把进程状态设置为 TASK_RUNNING，最后一步就是调用 copy_namespaces() 复制 namesapces。我们重点关注最后一步 copy_namespaces()：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;/*
* called from clone.  This now handles copy for nsproxy and all
* namespaces therein.
*/
int copy_namespaces(unsigned long flags, struct task_struct *tsk)
{
 struct nsproxy *old_ns = tsk-&amp;gt;nsproxy;
 struct user_namespace *user_ns = task_cred_xxx(tsk, user_ns);
 struct nsproxy *new_ns;

 if (likely(!(flags &amp;amp; (CLONE_NEWNS | CLONE_NEWUTS | CLONE_NEWIPC |
           CLONE_NEWPID | CLONE_NEWNET)))) {
   get_nsproxy(old_ns);
   return 0;
 }

 if (!ns_capable(user_ns, CAP_SYS_ADMIN))
   return -EPERM;

 /*
  * CLONE_NEWIPC must detach from the undolist: after switching
  * to a new ipc namespace, the semaphore arrays from the old
  * namespace are unreachable.  In clone parlance, CLONE_SYSVSEM
  * means share undolist with parent, so we must forbid using
  * it along with CLONE_NEWIPC.
  */
 if ((flags &amp;amp; (CLONE_NEWIPC | CLONE_SYSVSEM)) ==
   (CLONE_NEWIPC | CLONE_SYSVSEM)) 
   return -EINVAL;

 new_ns = create_new_namespaces(flags, tsk, user_ns, tsk-&amp;gt;fs);
 if (IS_ERR(new_ns))
   return  PTR_ERR(new_ns);

 tsk-&amp;gt;nsproxy = new_ns;
 return 0;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可见，copy_namespace() 主要基于“旧的” namespace 创建“新的” namespace，核心函数在于 create_new_namespaces：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;/*
* Create new nsproxy and all of its the associated namespaces.
* Return the newly created nsproxy.  Do not attach this to the task,
* leave it to the caller to do proper locking and attach it to task.
*/
static struct nsproxy *create_new_namespaces(unsigned long flags,
 struct task_struct *tsk, struct user_namespace *user_ns,
 struct fs_struct *new_fs)
{
 struct nsproxy *new_nsp;
 int err;

// 创建新的 nsproxy
 new_nsp = create_nsproxy();
 if (!new_nsp)
   return ERR_PTR(-ENOMEM);

//创建 mnt namespace
 new_nsp-&amp;gt;mnt_ns = copy_mnt_ns(flags, tsk-&amp;gt;nsproxy-&amp;gt;mnt_ns, user_ns, new_fs);
 if (IS_ERR(new_nsp-&amp;gt;mnt_ns)) {
   err = PTR_ERR(new_nsp-&amp;gt;mnt_ns);
   goto out_ns;
 }
//创建 uts namespace
 new_nsp-&amp;gt;uts_ns = copy_utsname(flags, user_ns, tsk-&amp;gt;nsproxy-&amp;gt;uts_ns);
 if (IS_ERR(new_nsp-&amp;gt;uts_ns)) {
   err = PTR_ERR(new_nsp-&amp;gt;uts_ns);
   goto out_uts;
 }
//创建 ipc namespace
 new_nsp-&amp;gt;ipc_ns = copy_ipcs(flags, user_ns, tsk-&amp;gt;nsproxy-&amp;gt;ipc_ns);
 if (IS_ERR(new_nsp-&amp;gt;ipc_ns)) {
   err = PTR_ERR(new_nsp-&amp;gt;ipc_ns);
   goto out_ipc;
 }
//创建 pid namespace
 new_nsp-&amp;gt;pid_ns_for_children =
   copy_pid_ns(flags, user_ns, tsk-&amp;gt;nsproxy-&amp;gt;pid_ns_for_children);
 if (IS_ERR(new_nsp-&amp;gt;pid_ns_for_children)) {
   err = PTR_ERR(new_nsp-&amp;gt;pid_ns_for_children);
   goto out_pid;
 }
//创建 network namespace
 new_nsp-&amp;gt;net_ns = copy_net_ns(flags, user_ns, tsk-&amp;gt;nsproxy-&amp;gt;net_ns);
 if (IS_ERR(new_nsp-&amp;gt;net_ns)) {
   err = PTR_ERR(new_nsp-&amp;gt;net_ns);
   goto out_net;
 }

 return new_nsp;
// 出错处理
out_net:
 if (new_nsp-&amp;gt;pid_ns_for_children)
   put_pid_ns(new_nsp-&amp;gt;pid_ns_for_children);
out_pid:
 if (new_nsp-&amp;gt;ipc_ns)
   put_ipc_ns(new_nsp-&amp;gt;ipc_ns);
out_ipc:
 if (new_nsp-&amp;gt;uts_ns)
   put_uts_ns(new_nsp-&amp;gt;uts_ns);
out_uts:
 if (new_nsp-&amp;gt;mnt_ns)
   put_mnt_ns(new_nsp-&amp;gt;mnt_ns);
out_ns:
 kmem_cache_free(nsproxy_cachep, new_nsp);
 return ERR_PTR(err);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在create_new_namespaces()中，分别调用 create_nsproxy(), create_utsname(), create_ipcs(), create_pid_ns(), create_net_ns(), create_mnt_ns() 来创建 nsproxy 结构，uts，ipcs，pid，mnt，net。&lt;/p&gt;
&lt;p&gt;具体的函数我们就不再分析，基本到此为止，我们从子进程创建，到子进程相关的信息的初始化，包括文件系统，CPU，内存管理等，再到各个 namespace 的创建，都走了一遍，下面附上 namespace 创建的代码流程图。&lt;/p&gt;
&lt;p&gt;具体流程图和更多的细节（包括各个 namespace 的创建过程）大家可以关注我的公众号阅读，那里的阅读体验会更好一些。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;PS：对云计算感兴趣的小伙伴可以关注我的微信公众号：aCloudDeveloper，专注云计算领域，坚持分享干货。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/431521/201804/431521-20180413192536235-2018078149.jpg&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 13 Apr 2018 12:34:00 +0000</pubDate>
<dc:creator>bakari</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/bakari/p/8823642.html</dc:identifier>
</item>
<item>
<title>区块链3.0：拥抱EOS - 一面千人</title>
<link>http://www.cnblogs.com/Evsward/p/eos-intro.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Evsward/p/eos-intro.html</guid>
<description>&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;EOS是当下最火的区块链技术，被社会广泛看好为下一代区块链3.0。不同于以太坊的学习，EOS的主语言是C++，本文作为EOS研究的首篇文章，重点介绍EOS的创新点，它的周边生态，各种概念原理的解释，以及它被看好的原因。而针对EOS的源码学习，原理实现以及并行的C++语言的快速学习与掌握，我会在接下来制定一系列学习计划一一付诸实现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;关键字：EOS，DAPP，石墨烯技术，构建本地节点，公链映射，选举，EOS链配置，术语解释&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;EOS.IO 是由block.one开发的一个基于区块链结构设计的能够支持水平和垂直扩展的去中心化应用的平台。它就像是一个完整的操作系统，可以在上面构建各种应用。EOS.IO提供了账户、认证、数据库，异步通信以及跨平台跨集群的定时应用。它有望支持每秒百万级交易，完全零费率，并可以快速且容易地部署去中心化应用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;以上是我对官方定义的理解，通过这个定义，我们可以抽离出最主要内容，就是EOS的核心竞争力是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;tps：百万级&lt;/li&gt;
&lt;li&gt;gas = 0&lt;/li&gt;
&lt;li&gt;Dapp更加容易高效地被部署&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;正如在之前的文章中的分析，下一代区块链不是ico，肯定是大规模的各行各业的Dapp的雄起，就像当年互联网革了传统行业的命一样，所以，能够做好大型商业应用的基建工作的公链就是未来区块链的宠儿。目前，呼喊着百万级tps，手续费为0，快速部署Dapp的EOS无疑切中了所有的要点。&lt;/p&gt;
&lt;p&gt;下面针对一些名词进行一个解释，以防止混淆：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;EOS，目前指的是基于ERC20在以太坊上发行的代币，用于block.one公司开发软件与社区运营。&lt;/li&gt;
&lt;li&gt;EOS.IO，是由block.one开发的可构建公链的软件源代码。&lt;/li&gt;
&lt;li&gt;EOS platform，采用了EOS.IO软件构建的公链平台。&lt;/li&gt;
&lt;li&gt;Dapp，这里指的是未来在EOS公链平台上基于EOS.IO软件开发部署的去中心化应用。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;eos&quot;&gt;EOS&lt;/h2&gt;
&lt;p&gt;EOS目前是以太坊ERC20的一个Token，很多看好EOS未来的朋友已经大量买入了此Token（包括我身边很多同事），已成为以太坊Token体系中最强势的一支。在即将到来的5月底，不出意外地话，EOS.IO公链将如期上线，届时，EOS持有者将会通过某种映射方式将资产转移到该公链上。&lt;/p&gt;
&lt;h3 id=&quot;eos私募分配机制&quot;&gt;EOS私募分配机制&lt;/h3&gt;
&lt;p&gt;例如，一个周期我计划发放20枚EOS。在这期间，Bob贡献了4个ETH，而Alice贡献了1个ETH，此周期结束。那么总ETH募集量为5ETH，对应发放一个EOS的等价价值为0.25ETH，因此，Bob会得到16枚EOS，而Alice会获得4枚EOS。&lt;/p&gt;
&lt;p&gt;所以，当你花费ETH或者BTC参与了EOS私募，一定是等到它一个周期结束才会进行锚定核算，你才会收到EOS token。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;有个有意思的是，在EOS官方问答上，它不允许美国公民、实体将EOS当做一种投机性产品购买，当然了，因为区块链的匿名性，EOS这么说并没有什么意义，估计只是做个态度，对了官方也不建议EOS买卖，但你也控制不了OTC和交易所（总之，EOS是戏精）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;另外，block.one为了保证它们不会购买EOS，不会为投资人支付股息，也不会发起任何形式的回购来操纵币盘，它们打算进行一个独立的第三方审计，将会发布一个独立审计报告提供进一步的保证。&lt;/p&gt;
&lt;h3 id=&quot;eos上eos-platform的映射机制&quot;&gt;EOS上EOS platform的映射机制&lt;/h3&gt;
&lt;p&gt;上面讲到了，EOS是存在于以太坊的代币，那么当EOS公链平台推出以后，如何转移这些代币到EOS公币呢？上面我也提到过是通过某种映射方法。那么下面就来具体说说是如何映射的。&lt;/p&gt;
&lt;p&gt;2018年6月1日，22:59:59，也就是EOS代币最终的发放周期结束前的23小时倒计时，EOS将被锁定交易，不可被交易。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;思考，通过上面的总结作为未来研究EOS的经验，官方讲的内容有多少是做戏，有多少只是提议，毕竟我们是在区块链行业，它无法做到对个人节点行为的控制。所以就以上这句话来讲，它如何控制以太坊EOS代币的交易锁定？我想它是控制不了的，因为交易所和OTC都不会听它的，它最多只是能通过智能合约控制代币发放周期而已。因此，要时刻保持独立思考能力，不要人云亦云，被人洗脑。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们继续来分析，在上面这个时间点，EOS token的发放将会完成，任何人通过EOS.IO源码启动一个EOS platform的，将能够生成一个JSON文件会映射EOS的公钥为以太坊的EOS token账户的余额。&lt;/p&gt;
&lt;p&gt;block.one是EOS.IO公链源码的开发者，它不会配置或启动任何EOS平台，block.one将不会控制何时，如何或者EOS.IO软件是否被使用或实现，或者如何，何时以及是否启动一个EOS platform。因此，您不应该期望，也不能保证您现在或将来会收到任何其他加密token或数字资产（不想对EOS代币负责）。&lt;/p&gt;
&lt;h2 id=&quot;webassembly&quot;&gt;WebAssembly&lt;/h2&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;WebAssembly(缩写Wasm)是一种基于堆栈的虚拟机的二进制指令格式。Wasm设计作为一个便携式的针对高级语言的编译器，例如C/C++/Rust，使各种客户端或服务端应用程序都能够在web中部署。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;目前Wasm支持Firefox，chrome，IE以及Safari浏览器。WebAssembly技术是在浏览器中不同于JS的另一种存在，但由于C++的高效，Wasm的效率可能会比JS更高，它就是在浏览器中运行C++程序的意思，目前WebAssembly比较好的编译器是LLVM。&lt;/p&gt;
&lt;h2 id=&quot;石墨烯技术&quot;&gt;石墨烯技术&lt;/h2&gt;
&lt;p&gt;石墨烯技术是新一代的区块链技术，基于DPOS共识算法。目前市场上流行的区块链阵营有三种，一种是第一代以比特币为主的生态体系，他们是基于POW共识，纯粹的去中心化，基于p2p的加密数字货币技术；第二种就是以以太坊构成的生态体系，主要以基于智能合约的ERC20的代币体系，他们是基于POW共识，目前以太坊正准备切换到POW+POS的多共识体系；第三种就是进化到目前最强劲的石墨烯技术生态体系，它是基于DPOS（股份授权证明共识），支持高并发，高性能等大规模工业级商业场景的基础设施，诞生了BTS（BitShare）开源商业系统，Steem去中心化社交网络平台以及EOS。&lt;strong&gt;未来会针对石墨烯技术以及DPOS共识做一个专门的博文调查。&lt;/strong&gt;，目前我们看到的石墨烯技术的几个显著特点是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;转账速度特别快&lt;/li&gt;
&lt;li&gt;吞吐量tps极高&lt;/li&gt;
&lt;li&gt;安全性很高，没有原生bug出现&lt;/li&gt;
&lt;li&gt;功能强大，应用性极高&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;防御机制&quot;&gt;防御机制&lt;/h2&gt;
&lt;p&gt;第一代比特币体系是非常安全的，但瓶颈很多。相比之下，第二代的以太坊有很多独特的创新点，例如智能合约，然而它历史遭受攻击的次数和影响范围都非常严重。最后说基于石墨烯技术的EOS，它是通过个人持有币的数量进行资源分配（包括存储空间、网络带宽以及算力），没有足够币是无法发起攻击的，而如果大量购币攻击，则相当于已经成为房东却要砸自家房子，是得不偿失的行为。所以EOS在防御攻击方面是具备天然免疫力的。&lt;/p&gt;
&lt;h2 id=&quot;分叉的处理&quot;&gt;分叉的处理&lt;/h2&gt;
&lt;p&gt;由于出块权被牢牢掌握在21个超级节点的手里，如果其中某个节点作恶的话是很容易被追踪到的，这个节点作恶的表现可能是在它出块的轮次人为造成了一个分叉，此时，需要21个节点中的15个节点进行确认，通过确认的这一区块被认为是主链上不可逆的一个块，任何不存在该块的都会被看做无效。这样就避免了分叉的可能。&lt;/p&gt;
&lt;h2 id=&quot;dapp&quot;&gt;DApp&lt;/h2&gt;
&lt;p&gt;EOS通过石墨烯基础技术，再加上自身的优化，可以达到百万级tps，同时不同于以太坊停留在Paas（平台即服务）的属性，EOS开拓思路增加了SaaS（软件即服务）的能力，加入了Dapp通用的账号体系、权限身份认证、异步通信、自描述数据库、自描述接口以及上面提到的WebAssembly浏览器客户端部署工具包，总之，拥有这一切优势的EOS将真正成为了未来工业级应用的平台。&lt;/p&gt;
&lt;p&gt;不过我们也要感谢以太坊提供的智能合约和Dapp的思想，在EOS得到了广泛而有效地发扬，我们可以开发自己的Dapp部署在EOS上，通过持币数量来获得对应比例的资源（包括存储空间，网络带宽以及算力），这是革了AWS SAAS和PaaS的命（恐怕未来AWS只有提供云计算基础设施的市场了）。&lt;/p&gt;
&lt;h2 id=&quot;超级节点的选举机制&quot;&gt;超级节点的选举机制&lt;/h2&gt;
&lt;p&gt;不同于&lt;a href=&quot;http://www.cnblogs.com/Evsward/p/clique.html#%E5%85%AD-%E5%9F%BA%E4%BA%8E%E6%8A%95%E7%A5%A8%E7%9A%84%E8%AE%A4%E8%AF%81%E7%BB%93%E7%82%B9%E7%9A%84%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6&quot;&gt;以太坊POA&lt;/a&gt;，因为以太坊的POA是基于非常小场景的私链或者联盟链的，这与大规模对外公开的公链EOS的场景是不同的。不过在我还未研究过EOS源码的当下来看，DPOS的超级节点的选举以及出块的机制与POA如出一辙。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;用户节点通过rpc接口进行投票，这里面不同的地方是：EOS是通过持币数量来决定手里有几票（这也是权益证明的精髓所在），而以太坊POA只是一个节点一票的形式。&lt;/li&gt;
&lt;li&gt;节点被选举成功，以太坊POA是没有确定数量限制的，随时按照全网投票与票数清零以后的每一轮投票结果去增删超级节点。而EOS则不同，超级节点目前只有21个，在整个投票周期结束以后，排名前21位即胜任。&lt;/li&gt;
&lt;li&gt;超级节点的要求不同，以太坊POA的认证节点与普通节点并非有任何差别。而EOS的超级节点则不同，这21个超级节点必须符合非常高的性能要求以及运维能力，社区规模等。&lt;/li&gt;
&lt;li&gt;机会均等概念在EOS超级节点中仍然是存在的，不过当一个超级节点出块方面出现问题，在一定规则下会被丢弃，然后重新选出新的节点替代它作为超级节点的身份。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;eos术语解释&quot;&gt;EOS术语解释&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;Account，账户&lt;/li&gt;
&lt;li&gt;Authority，权力&lt;/li&gt;
&lt;li&gt;Block，缩写Blk，每个区块可包含0个或多个交易，以及一个对前置区块的加密连接。不可逆。&lt;/li&gt;
&lt;li&gt;DAC，分权自治集体，或者是分权自治公司。&lt;/li&gt;
&lt;li&gt;DAO，分权自治组织&lt;/li&gt;
&lt;li&gt;Deferred Transaction，缩写defTx，延期交易。该交易是有智能合约所创建，会在未来的某个时间被执行。这个交易也能够创建另一个在其之后的交易。因此，延期交易可以创建无限循环的顺序交易。用户授权一个延期交易必须指定到执行的时刻拥有足够的带宽，存储来执行预期交易。&lt;/li&gt;
&lt;li&gt;DLTs，分布式账本技术。一种分布式账本（也被称作共享式账本），它是一个基于复制、共享以及同步数字化资产的跨站点、跨国家、跨机构的共识。&lt;/li&gt;
&lt;li&gt;DPoS，授权权益证明。此外，也可以代表民主即权益证明。DPoS是共识算法的一种，即区块生产者能够针对交易或区块的真实性，可验证，不可逆等特性达成共识的一种方法。&lt;/li&gt;
&lt;li&gt;Key pair，缩写keys，一个密钥对，包括公钥和其对应的私钥。&lt;/li&gt;
&lt;li&gt;larimer，一种EOS的计量单位，等于0.0001 EOS。（性质如同以太坊中的Wei）&lt;/li&gt;
&lt;li&gt;Master Password，用于解锁，或解密一个钱包文件的密码。&lt;/li&gt;
&lt;li&gt;Action，一个对区块链的改变动作。可以是一个或这多个动作组成一个交易。&lt;/li&gt;
&lt;li&gt;Non-Producing Node，非生产节点，也可以被理解为普通节点。这是一个完整的区块链节点，但它智能观察和验证区块，以及只能维护自己本地区块链的拷贝。一个普通节点可以在一个“备用池”中，通过投票流程称为生产节点（具备出块权的超级节点）一个超级节点，也会被投票出局，成为一个普通节点。但是值得注意的是，大多数普通节点并不在“备用池”中。&lt;/li&gt;
&lt;li&gt;Oracle，在区块链和智能合约的上下文中，它是一个代理，被智能合约使用用来找到和验证实际发生的并提交这个信息到区块链上。&lt;/li&gt;
&lt;li&gt;peer-to-peer,p2p，对等计算或网络是一个分布式应用程序架构，在对等环境下，它被分去为任务或者是工作量。对等节点是拥有等价权限，在应用程序中的参与机会均等。他们组成了点对点的网络节点。&lt;/li&gt;
&lt;li&gt;Permission，加权的，安全机制，通过评估它的签名权力来确定一个信息是否被正确授权。&lt;/li&gt;
&lt;li&gt;Private Key，用来签名交易的私钥。&lt;/li&gt;
&lt;li&gt;Public Key，缩写pub key，公钥，会在交易间被传输。&lt;/li&gt;
&lt;li&gt;Scope，作用域，智能合约的作用域，智能合约智能写入他们同一个作用域的自己的其他合约，而只能够读取其他作用域的合约。&lt;/li&gt;
&lt;li&gt;Smart Contract, 智能合约，一个计算机协议，旨在促进、验证或执行谈判。&lt;/li&gt;
&lt;li&gt;Standby Pool，100个全节点的集合，渴望被选中为21个超级节点之一，他们实际上已经拥有了超级节点的能力，无论何时链需要替换一个超级节点时，就会从备用池中选择。&lt;/li&gt;
&lt;li&gt;Transaction，缩写Tx，Txn。它有事务的含义，一般我们称作交易。它是一个完整的原子的区块链的变化，一个或多个消息的组合，在EOS中通常是由一个智能合约来执行。&lt;/li&gt;
&lt;li&gt;Wallet，钱包，会生成一个加密钱包文件或是通过客户端来管理，例如cleos。它管理了私钥以及用一个安全的方式去促进交易的签名。钱包可以被锁定或解锁。&lt;/li&gt;
&lt;li&gt;Block Producer, 缩写bp。21个超级节点之一，是目前正在出块轮次的那个超级节点。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;构建本地环境&quot;&gt;构建本地环境&lt;/h2&gt;
&lt;p&gt;EOS三个组件：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;nodeos：服务端区块链节点组件&lt;/li&gt;
&lt;li&gt;cleos：命令行接口，与区块链交互，管理钱包，管理账户，在区块链上调用方法。（很重要，相当于以太坊web3）&lt;/li&gt;
&lt;li&gt;keosd：管理EOSIO钱包的组件。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;接下来，我们将构建这些EOSIO组件，并将它们部署在一个主机，通过单个节点对网络(testnet)进行测试与配置。&lt;/p&gt;
&lt;h3 id=&quot;构建源码&quot;&gt;构建源码&lt;/h3&gt;
&lt;h4 id=&quot;获取源码&quot;&gt;获取源码&lt;/h4&gt;
&lt;p&gt;recursive参数会将所有子组件自动克隆下来，最终我们会在本地得到全部完整的源码。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;git clone https://github.com/EOSIO/eos --recursive&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;自动构建源码&quot;&gt;自动构建源码。&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;cd eos &amp;amp;&amp;amp; ./eosio_build.sh&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;构建时间较长，最终构建成功的页面如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[100%] Built target cleos
Scanning dependencies of target nodeos
[100%] Building CXX object programs/nodeos/CMakeFiles/nodeos.dir/main.cpp.o
[100%] Linking CXX executable chain_test
[100%] Linking CXX executable nodeos
[100%] Built target chain_test
[100%] Built target nodeos


     _______  _______  _______ _________ _______
    (  ____ \(  ___  )(  ____ \\__   __/(  ___  )
    | (    \/| (   ) || (    \/   ) (   | (   ) |
    | (__    | |   | || (_____    | |   | |   | |
    |  __)   | |   | |(_____  )   | |   | |   | |
    | (      | |   | |      ) |   | |   | |   | |
    | (____/\| (___) |/\____) |___) (___| (___) |
    (_______/(_______)\_______)\_______/(_______)

    EOS.IO has been successfully built. 0:32:57

    To verify your installation run the following commands:

    /home/liuwenbin/opt/mongodb/bin/mongod -f /home/liuwenbin/opt/mongodb/mongod.conf &amp;amp;
    cd /home/liuwenbin/eos/build; make test

    For more information:
    EOS.IO website: https://eos.io
    EOS.IO Telegram channel @ https://t.me/EOSProject
    EOS.IO resources: https://eos.io/resources/
    EOS.IO wiki: https://github.com/EOSIO/eos/wiki
&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;手动构建源码&quot;&gt;手动构建源码&lt;/h3&gt;
&lt;h4 id=&quot;安装开发工具包&quot;&gt;安装开发工具包&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;sudo apt-get update
wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key|sudo apt-key add -
sudo apt-get install clang-4.0 lldb-4.0 libclang-4.0-dev cmake make \
                     libbz2-dev libssl-dev libgmp3-dev \
                     autotools-dev build-essential \
                     libbz2-dev libicu-dev python-dev \
                     autoconf libtool git mongodb&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;wget 下载llvm-key出错，可以按照提示加入参数--no-check-certificate搞定。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;依赖&quot;&gt;依赖&lt;/h4&gt;
&lt;p&gt;基于我本机是Ubuntu16.04，除了使用上面的自动编译以外，也可以手动安装，不怕折磨的话。&lt;/p&gt;
&lt;p&gt;目前EOS当前版本的依赖包括：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Clang 4.0.0&lt;/li&gt;
&lt;li&gt;CMake 3.5.1&lt;/li&gt;
&lt;li&gt;Boost 1.66&lt;/li&gt;
&lt;li&gt;OpenSSL&lt;/li&gt;
&lt;li&gt;LLVM 4.0&lt;/li&gt;
&lt;li&gt;secp256k1-zkp (Cryptonomex branch)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;依赖安装请参照&lt;a href=&quot;https://github.com/EOSIO/eos/wiki/Local-Environment#manualdepubuntu&quot;&gt;官方文档&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;跑单元测试&quot;&gt;跑单元测试&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;cd build &amp;amp;&amp;amp; make test&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这一步是为了验证源码功能完整度，耗时也较久。&lt;/p&gt;
&lt;h3 id=&quot;安装命令&quot;&gt;安装命令&lt;/h3&gt;
&lt;pre&gt;
&lt;code&gt;sudo make install&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;命令会被安装在/usr/local。执行完这个命令以后，我们可以在系统任何位置进行命令启用。&lt;/p&gt;
&lt;h2 id=&quot;启动一个单独节点&quot;&gt;启动一个单独节点&lt;/h2&gt;
&lt;p&gt;构建完成后，会在build/programs/目录中出现nodeos文件夹，这是我们要启动节点的工具。通过以下命令启动你自己的独立节点区块链&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd programs/nodeos &amp;amp;&amp;amp; ./nodeos -e -p eosio --plugin eosio::wallet_api_plugin --plugin eosio::chain_api_plugin --plugin eosio::account_history_api_plugin &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这条命令中，可执行文件./nodeos后面有很多参数，好看的是后面的plugin是启动时对插件的配置，剩下的参数配置我们会在接下来介绍到。启动以后，日志打印出来相关信息：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;liuwenbin@liuwenbin-H81M-DS2:~/work/CLionProjects/github.com/eos/build/programs/nodeos$ ./nodeos -e -p eosio --plugin eosio::wallet_api_plugin --plugin eosio::c
hain_api_plugin --plugin eosio::account_history_api_plugin 
3054170ms thread-0   wallet_plugin.cpp:41          plugin_initialize    ] initializing wallet plugin
3054170ms thread-0   http_plugin.cpp:141           plugin_initialize    ] host: 127.0.0.1 port: 8888 
3054170ms thread-0   http_plugin.cpp:144           plugin_initialize    ] configured http to listen on 127.0.0.1:8888
3054170ms thread-0   chain_plugin.cpp:99           plugin_initialize    ] initializing chain plugin
3054170ms thread-0   net_plugin.cpp:2628           plugin_initialize    ] Initialize net plugin
3054170ms thread-0   net_plugin.cpp:2644           plugin_initialize    ] Setting net_plugin logging level to info
3054170ms thread-0   net_plugin.cpp:2669           plugin_initialize    ] host: 0.0.0.0 port: 9876 
3054170ms thread-0   net_plugin.cpp:2745           plugin_initialize    ] my node_id is 86aa711400110362b7a94d9468fc45bdbfa8887a3bdaf9502dbea59694179b09
3054170ms thread-0   main.cpp:90                   main                 ] nodeos version 96ee0325
3054170ms thread-0   main.cpp:91                   main                 ] eosio root is /home/liuwenbin/.local/share
3054170ms thread-0   http_plugin.cpp:213           plugin_startup       ] start listening for http requests
3054170ms thread-0   wallet_api_plugin.cpp:70      plugin_startup       ] starting wallet_api_plugin
3054170ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/wallet/create
3054170ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/wallet/get_public_keys
3054170ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/wallet/import_key
3054170ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/wallet/list_keys
3054170ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/wallet/list_wallets
3054170ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/wallet/lock
3054170ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/wallet/lock_all
3054170ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/wallet/open
3054170ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/wallet/set_timeout
3054170ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/wallet/sign_transaction
3054170ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/wallet/unlock
3054170ms thread-0   chain_plugin.cpp:178          plugin_startup       ] 
 generating default genesis file /home/liuwenbin/.local/share/eosio/nodeos/config/genesis.json
3054209ms thread-0   chain_plugin.cpp:208          plugin_startup       ] starting chain in read/write mode
3054209ms thread-0   chain_plugin.cpp:213          plugin_startup       ] Blockchain started; head block is #0, genesis timestamp is 2018-03-01T12:00:00.000
3054209ms thread-0   chain_api_plugin.cpp:62       plugin_startup       ] starting chain_api_plugin
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/chain/abi_bin_to_json
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/chain/abi_json_to_bin
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/chain/get_account
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/chain/get_block
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/chain/get_code
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/chain/get_currency_balance
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/chain/get_currency_stats
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/chain/get_info
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/chain/get_required_keys
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/chain/get_table_rows
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/chain/push_block
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/chain/push_transaction
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/chain/push_transactions
3054209ms thread-0   account_history_api_plugin.cpp:45 plugin_startup       ] starting account_history_api_plugin
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/account_history/get_controlled_accounts
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/account_history/get_key_accounts
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/account_history/get_transaction
3054209ms thread-0   http_plugin.cpp:242           add_handler          ] add api url: /v1/account_history/get_transactions
3054209ms thread-0   net_plugin.cpp:2757           plugin_startup       ] starting listener, max clients is 25
3054209ms thread-0   producer_plugin.cpp:161       plugin_startup       ] producer plugin:  plugin_startup() begin
3054209ms thread-0   producer_plugin.cpp:166       plugin_startup       ] Launching block production for 1 producers.

*******************************
*                             *
*   ------ NEW CHAIN ------   *
*   -  Welcome to EOSIO!  -   *
*   -----------------------   *
*                             *
*******************************

Your genesis seems to have an old timestamp
Please consider using the --genesis-timestamp option to give your genesis a recent timestamp

3054209ms thread-0   producer_plugin.cpp:176       plugin_startup       ] producer plugin:  plugin_startup() end
eosio generated block bd1a5181... #1 @ 2018-04-13T02:50:54.500 with 0 trxs, lib: 0
eosio generated block a8c18ba3... #2 @ 2018-04-13T02:50:55.000 with 0 trxs, lib: 1
eosio generated block 1e4c703f... #3 @ 2018-04-13T02:50:55.500 with 0 trxs, lib: 2
eosio generated block d4c29cd4... #4 @ 2018-04-13T02:50:56.000 with 0 trxs, lib: 3
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面来逐一分析一下这个日志内容，可以看出EOS启动私链节点是通过插件实现的，在启动私链前，要对插件进行初始化配置，启动各依赖组件处理器。下面来列举一下主要插件内容：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;wallet_plugin，钱包管理相关，启动阶段只出现过一次，说明它的功能主要依赖启动后的操作，而在启动期间需要做的配置很少。&lt;/li&gt;
&lt;li&gt;wallet_api_plugin，依赖于wallet_plugin，出现一次，应该是提供外部调用与钱包交互的接口服务。&lt;/li&gt;
&lt;li&gt;http_plugin，启动阶段大量出现的插件，说明在准备期，针对HTTP的配置和添加接口服务非常多。配置包括url，端口，监听。接口服务包括钱包相关，链相关，账户相关的一系列api地址。&lt;/li&gt;
&lt;li&gt;chain_plugin，链插件配置，出现了几次，除了初始化启动以外，还有针对链数据读取模式的配置为read/write模式，生成创世块配置文件genesis.json，以及展示了创世区块的各种属性信息。&lt;/li&gt;
&lt;li&gt;chain_api_plugin，同样的，依赖于chain_plugin，提供外部调用链相关操作的接口服务。&lt;/li&gt;
&lt;li&gt;net_plugin，网络插件，出现了几次，是对网络节点的基本配置，包括网络日志的级别为info，本地网络监听端口，生成节点id。最后启动监听器，并设置了以该网络节点为服务器的客户端最多能够连入25个。&lt;/li&gt;
&lt;li&gt;main，主插件，对eosio这整个软件的一个主要插件，配置了eosio的版本以及展示了eosio工作的本地root地址。&lt;/li&gt;
&lt;li&gt;account_history_api_plugin，顾名思义，账户历史接口插件，估计是与账户历史相关的供外部调用的接口服务。&lt;/li&gt;
&lt;li&gt;producer_plugin，区块生产者插件，插件启动。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;以上出现的所有插件亦可理解为组件。&lt;/p&gt;
&lt;p&gt;接着看日志，提示我创世块时间戳过时，可以通过一个参数来修改，下面我尝试修改一下，在以上启动命令加入了参数，重新启动：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;--genesis-timestamp 2018-04-13T12:00:00.000&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;重新启动以后，打印出来的日志中，前面的都是相同的，我们从producer_plugin贴出来是：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;862009ms thread-0   producer_plugin.cpp:161       plugin_startup       ] producer plugin:  plugin_startup() begin
862009ms thread-0   producer_plugin.cpp:166       plugin_startup       ] Launching block production for 1 producers.
862009ms thread-0   producer_plugin.cpp:176       plugin_startup       ] producer plugin:  plugin_startup() end
862501ms thread-0   fork_database.cpp:77          _push_block          ] Number of missed blocks: 2783
eosio generated block 8e2a6ce1... #34 @ 2018-04-13T03:14:22.500 with 0 trxs, lib: 33
eosio generated block eb5e67b9... #35 @ 2018-04-13T03:14:23.000 with 0 trxs, lib: 34
eosio generated block 5aa06ff6... #36 @ 2018-04-13T03:14:23.500 with 0 trxs, lib: 35
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到，那个关于创世块时间戳的提示已经消失，producer_plugin插件启动开始与完毕。接下来就是&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;fork_database程序，推送区块，报出了消失区块好2783。TODO：这一行还待未来分析解决。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;接下来就是正常出块了，由于我们本地启动的节点一定是具备出块权的（目前只有一个节点未涉及共识），这些块是不包含任何交易信息的，出块速度很快。&lt;/p&gt;
&lt;h3 id=&quot;停止&quot;&gt;停止&lt;/h3&gt;
&lt;p&gt;断开私链直接按下复制键（Ctrl+C）即可，日志中也有体现：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;eosio generated block de403b91... #37 @ 2018-04-13T03:14:24.000 with 0 trxs, lib: 36
eosio generated block f40f0e68... #38 @ 2018-04-13T03:14:24.500 with 0 trxs, lib: 37
eosio generated block c1b717d0... #39 @ 2018-04-13T03:14:25.000 with 0 trxs, lib: 38
865075ms thread-0   net_plugin.cpp:2771           plugin_shutdown      ] shutdown..
865075ms thread-0   net_plugin.cpp:2774           plugin_shutdown      ] close acceptor
865075ms thread-0   net_plugin.cpp:2777           plugin_shutdown      ] close 0 connections
865075ms thread-0   net_plugin.cpp:2785           plugin_shutdown      ] exit shutdown&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到私链停止时，都是通过net_plugin插件来操作，操作的方法是与plugin_startup对应的plugin_shutdown，步骤为：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;开始关闭的标识&lt;/li&gt;
&lt;li&gt;关闭接收器acceptor&lt;/li&gt;
&lt;li&gt;关闭连接&lt;/li&gt;
&lt;li&gt;完成私链停止工作，退出shutdown程序&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;以上内容在未来的源码分析中均会涉及。&lt;/p&gt;
&lt;h3 id=&quot;配置&quot;&gt;配置&lt;/h3&gt;
&lt;p&gt;EOS环境启动以后，可以在本地目录：~/.local/share/eosio/nodeos/ 找到链相关文件：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;liuwenbin@liuwenbin-H81M-DS2:~/.local/share/eosio/nodeos$ tree
.
├── config
│   ├── config.ini
│   └── genesis.json
└── data
    ├── blocks
    │   ├── blocks.index
    │   └── blocks.log
    └── shared_mem
        ├── shared_memory.bin
        └── shared_memory.meta

4 directories, 6 files
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;根目录下包含config和data两个目录，data目录中存储了区块运行时数据，日志以及共享内存相关数据，我们重点来看config文件夹中的内容：&lt;/p&gt;
&lt;h4 id=&quot;genesis.json&quot;&gt;genesis.json&lt;/h4&gt;
&lt;pre&gt;
&lt;code&gt;{
  &quot;initial_timestamp&quot;: &quot;2018-03-01T12:00:00.000&quot;,
  &quot;initial_key&quot;: &quot;EOS6MRyAjQq8ud7hVNYcfnVPJqcVpscN5So8BhtHuGYqET5GDW5CV&quot;,
  &quot;initial_configuration&quot;: {
    &quot;base_per_transaction_net_usage&quot;: 100,
    &quot;base_per_transaction_cpu_usage&quot;: 500,
    &quot;base_per_action_cpu_usage&quot;: 1000,
    &quot;base_setcode_cpu_usage&quot;: 2097152,
    &quot;per_signature_cpu_usage&quot;: 100000,
    &quot;per_lock_net_usage&quot;: 32,
    &quot;context_free_discount_cpu_usage_num&quot;: 20,
    &quot;context_free_discount_cpu_usage_den&quot;: 100,
    &quot;max_transaction_cpu_usage&quot;: 10485760,
    &quot;max_transaction_net_usage&quot;: 104857,
    &quot;max_block_cpu_usage&quot;: 104857600,
    &quot;target_block_cpu_usage_pct&quot;: 1000,
    &quot;max_block_net_usage&quot;: 1048576,
    &quot;target_block_net_usage_pct&quot;: 1000,
    &quot;max_transaction_lifetime&quot;: 3600,
    &quot;max_transaction_exec_time&quot;: 0,
    &quot;max_authority_depth&quot;: 6,
    &quot;max_inline_depth&quot;: 4,
    &quot;max_inline_action_size&quot;: 4096,
    &quot;max_generated_transaction_count&quot;: 16
  },
  &quot;initial_chain_id&quot;: &quot;0000000000000000000000000000000000000000000000000000000000000000&quot;
}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到初始化时间戳，初始化key，以及初始链id，链配置。其中链配置又包含了基础每笔交易的网络使用size、cpu使用size，每个方法、每个setcode、每个签名的cpu使用size，每个锁的网络使用size，空闲期间的cpu使用度折扣上下文，交易的cpu、网络使用度的最大值，区块的最大网络使用size，目标区块的网络使用size，交易最大存活生命周期长度、执行时间，权限深度的最大值，最大内联深度，最大内联操作size，交易的最大生成数量。&lt;/p&gt;
&lt;p&gt;上面对genesis.json创世块描述文件进行了平铺直叙，我们可以看到，链时间，链key，链id都比较常见，而细致入微到标识了每个方法、每个签名等等的资源分配，这是很令人惊奇的。说明了&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;EOS对资源的控制是非常看中的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;config.ini&quot;&gt;config.ini&lt;/h4&gt;
&lt;p&gt;这是一个全局配置文件，就像java的property文件一样。这里面的配置会被细分到是由哪一个插件来使用的，例如针对http_plugin配置的地址端口号等等，我们也可以通过手动修改这些配置来控制链的一些表现。config.ini这个全局配置文件就是开放给外部人员，作为各种功能的静态变量配置，功能开关等工具使用。下面针对配置项逐一分析：&lt;/p&gt;
&lt;h5 id=&quot;属于account_history_plugin插件的配置&quot;&gt;属于account_history_plugin插件的配置&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;filter_on_accounts：功能是实现仅追踪配置值的账户产生的交易，默认注释掉该配置项，意思是不设过滤器，追踪所有交易。&lt;/li&gt;
&lt;li&gt;get-transactions-time-limit：执行单个get_transactions调用的执行时间，单位是豪妙，默认值为3（意思是3毫秒读不到就丢弃）&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;属于chain_plugin插件的配置&quot;&gt;属于chain_plugin插件的配置&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;genesis-json，指定创世块配置文件位置，默认值是“genesis.json”&lt;/li&gt;
&lt;li&gt;genesis-timestamp，复写初始化创世块时间戳，我们上面不是在启动命令中通过加入--genesis-timestamp参数来配置该值了么，在这里配置以后重启会是相同的效果。默认值是注释掉，启动时时间戳一般会过时。&lt;/li&gt;
&lt;li&gt;block-log-dir：是区块日志的存储位置，绝对路径或者应用程序的相对路径。&lt;/li&gt;
&lt;li&gt;checkpoint：是一对区块高度+区块id，用来作为检查点。默认注释掉，不设置检查点。（检查点的使用会在之后介绍,TODO）&lt;/li&gt;
&lt;li&gt;max-reversible-block-time：允许可逆区块在被确认为无效之前存在的时间，默认为-1，不允许出现可逆区块。&lt;/li&gt;
&lt;li&gt;max-pending-transaction-time：允许pending交易在无效之前的执行时间，默认为-1，不允许出现pending的交易。&lt;/li&gt;
&lt;li&gt;max-defered-transaction-time：允许延迟执行交易到区块的推送时间，默认值20，&lt;/li&gt;
&lt;li&gt;wasm-runtime：复写默认的WebAssembly的runtime。默认是注释掉（TODO:啥意思）&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;属于faucet_testnet_plugin配置&quot;&gt;属于faucet_testnet_plugin配置&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;faucet-create-interval-ms：创建账户的间隔，默认1秒钟。&lt;/li&gt;
&lt;li&gt;faucet-name：创建账户的创建器的名字。默认就是faucet。&lt;/li&gt;
&lt;li&gt;faucet-private-key：公钥，WIF(TODO：解释WIF)私钥，用于faucet创建账户签名。默认值是在源码下载时指定的，我们可以通过&lt;a href=&quot;https://eosfans.io/tools/generate/&quot;&gt;工具&lt;/a&gt;自己更改。&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;属于http_plugin配置&quot;&gt;属于http_plugin配置&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;http-server-address：本地IP端口，用于监听进入的http连接。默认值为127.0.0.1:8888&lt;/li&gt;
&lt;li&gt;access-control-allow-origin：允许访问控制，每个请求会返回一个确定的access-control-allow-origin。默认注释掉，不设置特殊访问限制。&lt;/li&gt;
&lt;li&gt;access-control-allow-headers：同上，只是不是http请求的origin控制了，而是通过http头来控制。默认也注释掉，不设置特殊访问限制。&lt;/li&gt;
&lt;li&gt;access-control-allow-credentials：如果有特殊的访问限制证书则返回true。默认值为flase，不设限。&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;属于mongo_db_plugin配置&quot;&gt;属于mongo_db_plugin配置&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;mongodb-queue-size：nodeos和mongodb组件线程之间的队列大小。默认值为256。&lt;/li&gt;
&lt;li&gt;mongodb-uri：MongoDB的uri连接字符串，如果不配置则该mongodb组件是未被激活的，而使用默认的‘EOS’数据库。默认值不配置。&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;属于net_plugin配置&quot;&gt;属于net_plugin配置&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;p2p-listen-endpoint：实际的主机加端口，用来监听进来的p2p连接。默认值为0.0.0.0:9876&lt;/li&gt;
&lt;li&gt;p2p-server-address：一个外部访问的主机加端口，用于标识当前节点。默认使用上面的p2p-listen-endpoint配置。&lt;/li&gt;
&lt;li&gt;p2p-peer-address：公共的对等节点的端点位置，提供外部连接。使用多重p2p-peer-address选项作为构成网络的需要。默认值是注释掉，不设置p2p相关配置。（TODO，p2p网络设置测试）&lt;/li&gt;
&lt;li&gt;agent-name：在对等节点之间，用于标识一个节点而设置的名字。&lt;/li&gt;
&lt;li&gt;allowed-connection：连接许可，可选值包括
&lt;ul&gt;&lt;li&gt;any：允许所有连接，不设限制。&lt;/li&gt;
&lt;li&gt;producers：仅允许区块生产者连接，节点key是不需要的。&lt;/li&gt;
&lt;li&gt;specified：配置节点key作为特殊连接，可以与producers节点key重复（要配置多个的时候可以不适用producers，而用这个，否则没意义）&lt;/li&gt;
&lt;li&gt;none：谁都不允许连入。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;peer-key：可选项，允许连接的节点公钥。可以被多次使用。默认值是注释掉，不使用该配置项。&lt;/li&gt;
&lt;li&gt;peer-private-key：公钥，WIF私钥元组，可被指定多次。默认注释掉，不使用。&lt;/li&gt;
&lt;li&gt;log-level-net-plugin：日志级别包括all,debug,info,warn,error,off，这个不说了&lt;/li&gt;
&lt;li&gt;max-clients：接收连接的客户端的最大数量，设为0的话表示没有限制。默认25个。&lt;/li&gt;
&lt;li&gt;connection-cleanup-period：在清理死连接之前，等待的秒数。默认值是30s。&lt;/li&gt;
&lt;li&gt;network-version-match：准确匹配对等网络版本。&lt;/li&gt;
&lt;li&gt;sync-fetch-span：同步获取量，同步时，从任何个人节点取回作为一个chunk（大块）的区块数量，默认是100个。&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;属于producer_plugin配置&quot;&gt;属于producer_plugin配置&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;enable-stale-production：陈旧生产能力。即使链是陈旧的，也能够出块。默认值是false，不允许陈旧链（TODO:什么是陈旧链）&lt;/li&gt;
&lt;li&gt;required-participation：必须参与出块。必须参与按序出块的区块生产者的百分比。默认值是33。至少33%的区块生产者是要参与到按序出块的。&lt;/li&gt;
&lt;li&gt;producer-name：producer的ID，受节点控制。可能多次指定。默认值是注释掉，不使用。&lt;/li&gt;
&lt;li&gt;private-key：私钥，公钥，WIF私钥元组，可以指定多次。默认值已有，可以修改。&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;属于wallet_plugin配置&quot;&gt;属于wallet_plugin配置&lt;/h5&gt;
&lt;ul&gt;&lt;li&gt;wallet-dir：钱包文件的路径，绝对路径或者应用程序的相对路径。默认值是当前路径“.”&lt;/li&gt;
&lt;li&gt;unlock-timeout：解锁钱包的超时时间，单位是秒。钱包在没有活动一段时间以后会自动上锁，这些活动可来自于任何钱包命令，例如list-wallet等。默认是注释掉，没有超时时间，不自动上锁。&lt;/li&gt;
&lt;li&gt;eosio-key：在钱包创建时，eosio秘钥将被自动导入，默认是注释掉，先不设置，因为我吗是新创建钱包，未通过现有钱包导入。&lt;/li&gt;
&lt;li&gt;plugin：激活插件，可以被特殊指定多次。默认是注释掉，没有特例，是插件都好使。&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;配置中出现的所有time的单位一般都是毫秒。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;启动命令参数&quot;&gt;启动命令参数&lt;/h3&gt;
&lt;h4 id=&quot;配置文件加启动命令&quot;&gt;配置文件加启动命令&lt;/h4&gt;
&lt;p&gt;上面我们通过命令&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; ./nodeos -e -p eosio --genesis-timestamp 2018-04-13T12:00:00.000 --plugin eosio::wallet_api_plugin --plugin eosio::chain_api_plugin --plugin eosio::account_history_api_plugin &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动了本地EOS环境。下面我们针对这个启动脚本的使用参数进行学习：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;-e：enable-stale-production，参加上面config.ini的相关说明。设置以后相当于true。&lt;/li&gt;
&lt;li&gt;-p：producer-name，给定了一个名字“eosio”用于出块者名字。&lt;/li&gt;
&lt;li&gt;--plugin：就是config.ini最后一个配置字段。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;所以我在config.ini针对以上命令进行静态配置。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;enable-stale-production = true
producer-name = eosio&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;plugin的配置方式：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# Load the block producer plugin, so you can produce blocks
plugin = eosio::producer_plugin
# Wallet plugin
plugin = eosio::wallet_api_plugin
# As well as API and HTTP plugins
plugin = eosio::chain_api_plugin
plugin = eosio::http_plugin
# This will be used by the validation step below, to view account history
plugin = eosio::account_history_api_plugin&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;配置结束以后，由于上面我们也执行了命令安装（sudo make install）,下面我们可以直接在任何位置使用命令&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;nodeos&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;即可启动与之前命令相同的EOS本地环境。&lt;/p&gt;
&lt;h4 id=&quot;指定配置文件地址&quot;&gt;指定配置文件地址&lt;/h4&gt;
&lt;p&gt;我们可以在机器中维护多套config.ini 以及 genesis.json文件，然后启动EOS环境时通过参数&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;--config-dir：指定地址用来加载配置文件，绝对路径或应用程序相对路径。&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;指定运行时数据地址&quot;&gt;指定运行时数据地址&lt;/h4&gt;
&lt;p&gt;我们也可以通过启动参数指定运行时数据的存储位置。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;--data-dir：指定地址用来存放运行时数据，日志以及共享内存相关数据，绝对路径或应用程序相对路径。&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其实config-dir和data-dir就是映射的上面的~/.local/share/eosio/nodeos/的内容，我在上面使用树形结构列举了出来，他们通过启动参数均可指定新的位置。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;本文是EOS的入门手册，介绍了EOS基本概念和术语解释，包括发展历史，私募、代币、公链映射方案，选举机制、Dapp以及防御机制，最后对本地环境进行了构建，包括自动和手动的，以及启动参数，结合分析了链的各种插件的配置参数，语义。接下来我分三个大步来加深自身的EOS的专业度：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;下一步我将通过两篇文章重点快速学习C++语言基础&lt;/li&gt;
&lt;li&gt;然后通过一到两篇文章继续EOS的分析研究，会根据官方文档从智能合约、开发工具、交互工具、账户钱包权限模块去进一步介绍EOS，同时会加入对RPC的使用研究&lt;/li&gt;
&lt;li&gt;再下一步我会根据EOS白皮书的结构，结合源码去具体分析EOS各个插件的实现、区块通信、DPOS共识算法，账户管理，并发，Token，治理，脚本与虚拟机&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;参考资料&quot;&gt;参考资料&lt;/h2&gt;
&lt;p&gt;EOS官方文档&lt;/p&gt;

</description>
<pubDate>Fri, 13 Apr 2018 12:19:00 +0000</pubDate>
<dc:creator>一面千人</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/Evsward/p/eos-intro.html</dc:identifier>
</item>
<item>
<title>Linux下内存问题检测神器：Valgrind - Madcola</title>
<link>http://www.cnblogs.com/skyfsm/p/8823170.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/skyfsm/p/8823170.html</guid>
<description>&lt;p&gt;在写大型C/C++工程时难免会发生内存泄漏现象，系统编程中一个重要的方面就是有效地处理与内存相关的问题。你的工作越接近系统，你就需要面对越多的内存问题。有时这些问题非常琐碎，而更多时候它会演变成一个调试内存问题的恶梦。 常见的内存问题一共七种：1. 动态内存泄露；2. 资源泄露，比如文件指针不关闭；3. 动态内存越界；4.数组内存越界；5.动态内存double free；6.使用野指针，即未初始化的指针；7.释放野指针，即未初始化的指针。&lt;/p&gt;
&lt;p&gt;内存问题非常难定位，对于小工程来说，简单去检查代码中new和delete的匹配对数就基本能定位到问题，但是一旦代码量上升到以万单位时，仅靠肉眼检查来定位问题那就非常困难了，所以我们需要利用工具帮助我们找出问题所在。在Linux系统下内存检测工具首推Valgrind，一款非常好用的开源内存管理框架。Valgrind其实是一个工具集，内存错误检测只是它众多功能的一个，但我们用得最多的功能正是它——memcheck。&lt;/p&gt;
&lt;p&gt;该工具可以检测下列与内存相关的问题 :&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;未释放内存的使用&lt;/li&gt;
&lt;li&gt;对释放后内存的读/写&lt;/li&gt;
&lt;li&gt;对已分配内存块尾部的读/写&lt;/li&gt;
&lt;li&gt;内存泄露&lt;/li&gt;
&lt;li&gt;不匹配的使用malloc/new/new[] 和 free/delete/delete[]&lt;/li&gt;
&lt;li&gt;重复释放内存&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;首先安装Valgrind非常简单：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;//valgrind下载：
http://valgrind.org/downloads/valgrind-3.12.0.tar.bz2

valgrind安装：
1. tar -jxvf valgrind-3.12.0.tar.bz2
2. cd valgrind-3.12.0
3. ./configure
4. make
5. sudo make install&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;下面开始讲解Valgrind的应用场景。&lt;/p&gt;
&lt;p&gt;注意: 下面讨论的所有测试代码都应该使用gcc/g++并且加上-g选项。&lt;/p&gt;
&lt;h2 id=&quot;使用未初始化的内存使用野指针&quot;&gt;1. 使用未初始化的内存（使用野指针）&lt;/h2&gt;
&lt;p&gt;这里我们定义了一个指针p，但并未给他开辟空间，即他是一个野指针，但我们却使用它了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193554002-1364573355.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Valgrind检测出我们程序使用了未初始化的变量，但并未检测出内存泄漏。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193604735-1875378577.jpg&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;在内存被释放后进行读写使用野指针&quot;&gt;2.在内存被释放后进行读/写（使用野指针）&lt;/h2&gt;
&lt;p&gt;p所指向的内存被释放了，p变成了野指针，但是我们却继续使用这片内存。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193613574-1154240221.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Valgrind检测出我们使用了已经free掉的内存，并给出这片内存是哪里分配哪里释放的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193624421-247811116.jpg&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;从已分配内存块的尾部进行读写动态内存越界&quot;&gt;3.从已分配内存块的尾部进行读/写（动态内存越界）&lt;/h2&gt;
&lt;p&gt;我们动态地分配了一段数组，但我们在访问个数组时发生了越界读写，程序crash掉。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193638871-928305119.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Valgrind检测出越界的位置。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193651410-2101563201.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;注意：Valgrind不检查静态分配数组的使用情况！所以对静态分配的数组，Valgrind表示无能为力！比如下面的例子，程序crash掉，我们却不知道为什么。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193706246-508790416.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193716994-628209858.jpg&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;内存泄漏&quot;&gt;4.内存泄漏&lt;/h2&gt;
&lt;p&gt;内存泄漏的原因在于没有成对地使用malloc/free和new/delete，比如下面的例子。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193726929-641784050.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Valgrind会给出程序中malloc和free的出现次数以判断是否发生内存泄漏，比如对上面的程序运行memcheck，Valgrind的记录显示上面的程序用了1次malloc，却调用了0次free，明显发生了内存泄漏！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193738724-1869262186.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上面提示了我们可以使用--leak-check=full进一步获取内存泄漏的信息，比如malloc和free的具体行号。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193750769-1501914916.jpg&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;不匹配地使用mallocnewnew-和-freedeletedelete&quot;&gt;5. 不匹配地使用malloc/new/new[] 和 free/delete/delete[]&lt;/h2&gt;
&lt;p&gt;正常使用new/delete和malloc/free是这样子的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193802975-763647802.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193817047-1922627647.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;而不匹配地使用malloc/new/new[] 和 free/delete/delete[]则会被提示mismacth：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193830425-1531404607.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193844415-122107118.jpg&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;两次释放内存&quot;&gt;6.两次释放内存&lt;/h2&gt;
&lt;p&gt;double free的情况同样是根据malloc/free的匹配对数来体现的，比如free多了一次，Valgrind也会提示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193909777-1273155147.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1093303/201804/1093303-20180413193923068-1690539405.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当然，Valgrind也不是万能的。Valgrind也有无法找到问题的时候，有些问题只能通过不断的review代码找到了症结。发现问题，解决问题，毕竟是末流。最好的方法，就是不引入内存问题。这可以通过良好的代码风格和设计来实现的。&lt;/p&gt;
</description>
<pubDate>Fri, 13 Apr 2018 11:40:00 +0000</pubDate>
<dc:creator>Madcola</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/skyfsm/p/8823170.html</dc:identifier>
</item>
</channel>
</rss>