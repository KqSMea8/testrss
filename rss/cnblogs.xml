<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>一文带你读懂深度学习之Deepmind WaveNet模型和Keras实现 - SeanLiao</title>
<link>http://www.cnblogs.com/seanliao/p/9595536.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/seanliao/p/9595536.html</guid>
<description>&lt;p&gt;本文主要通俗讲述WaveNet的基本模型和Keras代码理解，以帮助和我一样刚刚入坑并难以理解其代码的小白。&lt;/p&gt;
&lt;p&gt;作者：SeanLiao&lt;/p&gt;
&lt;p&gt;Blog：https://www.cnblogs.com/seanliao/&lt;/p&gt;
&lt;p&gt;原创博文，转载请注明来源。&lt;/p&gt;
&lt;h2&gt;一. 什么是WaveNet?&lt;/h2&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;简单来说，WaveNet是一种生成模型，类似VAE、GAN等，WaveNet最大的特点是可以直接生成raw audio的模型，由2017年DeepMind提出，在TTS(文字转语音)任务上可以达到state-of-art的效果。&lt;/p&gt;
&lt;p&gt;此外WaveNet也可以用来做生成文字、生成图片、语音识别等。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1274464/201809/1274464-20180905222748779-2143685375.png&quot; alt=&quot;&quot; width=&quot;593&quot; height=&quot;309&quot;/&gt;&lt;/p&gt;
&lt;p&gt;WaveNet的具体相关可以参考以下资料：&lt;/p&gt;
&lt;p&gt;Ref :&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://deepmind.com/blog/wavenet-generative-model-raw-audio/&quot; target=&quot;_blank&quot;&gt;DeepMind WaveNet Blog &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/basveeling/wavenet&quot; target=&quot;_blank&quot;&gt;Keras实现代码&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1609.03499.pdf&quot; target=&quot;_blank&quot;&gt;WaveNet论文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;窃以为，学习一种网络结构应该结合论文和代码，而理解模型的基础首先是知道模型的输入输出。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DeepMind博客上的动图非常清楚地展示了这个模型的工作过程。一定要看！体会！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;WaveNet的网络结构并不复杂，说白了其实就是一类变种CNN。但是介绍WaveNet的各种文章只对WaveNet的结构夸夸其谈，丝毫没有涉及模型的输入输出到底是什么，对小白非常不友好。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本文着重介绍WaveNet keras实现代码中的输入数据组织。&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;二. 模型的运作过程&lt;/h2&gt;
&lt;p&gt;　　这里不谈模型的原理和结构（实际上只要理解了CNN，理解WaveNet非常容易）。我们先谈谈WaveNet到底“做了什么”？&lt;/p&gt;
&lt;p&gt;　　由于我不知道怎么上传动图，大家可以到DeepMind博客上查看那张动图。再结合下图论文的原文：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1274464/201809/1274464-20180905224211591-170671344.png&quot; alt=&quot;&quot; width=&quot;813&quot; height=&quot;141&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　简单来说，模型的核心是 &lt;strong&gt;对给定的输入序列(x_1, x_2, x_3, x_4, ..., x_n) ， 每次要根据之前的x_1 ~ x_n来预测x_n+1。然后将x_n+1添加在输入序列，再由x_2 ~ x_n+1得到 x_n+1&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;　　由此 我们就可以由一个原始的序列(x_1, x_2, x_3, x_4, ..., x_n) 作为输入，按此模型进行构建，&lt;strong&gt;可以生成任意长度的序列！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　那么疑问来了，代码怎么实现呢？&lt;/strong&gt;博主实在讨厌冗长的Tensorflow代码，于是在github上找到了这个比较多Star的Keras版本代码，clone下来并成功运行后开始分析。&lt;strong/&gt;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;三. Keras代码中数据的组织&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;　　&lt;/strong&gt;本文开头引用给出的Keras代码写得非常好，尤其是自定义层部分。由于封装得比较高级，对小白而言看懂还是有点困难的。下面我就拿其代码来进行简单的分析。&lt;/p&gt;
&lt;p&gt;　　首先我们要注意到论文中的这部分。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1274464/201809/1274464-20180905225833430-2002805708.png&quot; alt=&quot;&quot; width=&quot;773&quot; height=&quot;186&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　这样的话，代码就应该很明白了。 还是不懂？ 没关系，下面举个简单的例子。&lt;/p&gt;
&lt;p&gt;　　对于一个序列 “我是超级大帅哥”。 假如取长度为2 步长为1 作为数据进行输入和训练。&lt;/p&gt;
&lt;p&gt;　　则训练时第一次输入模型的数据：x1 = 我是 ， 输出y1 = 是超&lt;/p&gt;
&lt;p&gt;　　第二次：x2 =  是超， y2 = 超级；&lt;/p&gt;
&lt;p&gt;　　第三次： x3 = 超级， y3 = 级大&lt;/p&gt;
&lt;p&gt;　　……&lt;/p&gt;
&lt;p&gt;　　而当训练完毕，使用训练好的模型生成数据时，送入x1 = 我是，理想情况是得到y1 = 是超&lt;/p&gt;
&lt;p&gt;　　只要不断的将输出送到输入再进行预测，就有可能得到一个完整的序列“我是超级大帅哥”！&lt;/p&gt;
&lt;p&gt;　　（别跟我你到这里还搞不懂模型的输入输出是什么......）&lt;/p&gt;
&lt;p&gt;　　那么对于图片和文字的情况呢？这里不做讲解（因为我也还没去看啊喂...），大家可以看看论文原文和github上的tensorflow代码。&lt;/p&gt;
&lt;p&gt;　　如果到这部分都看懂了，好的，其实代码实现也很容易理解，读者请先简单地阅读一遍所有代码，下面对输入输出数据的组织做简单的分析总结。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;模型的输入&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;一段长度为&lt;/span&gt;fragment_length&lt;span&gt;的音频数据&lt;/span&gt;&lt;span&gt;,&lt;/span&gt; &lt;span&gt;设为&lt;/span&gt;&lt;span&gt;audio[begin : begin + fragment_length]&lt;/span&gt;&lt;/p&gt;

&lt;h3&gt;&lt;strong&gt;&lt;span&gt;模型的输出&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;相邻于输入数据的下一段&lt;/span&gt;fragment_length&lt;span&gt;长的音频序列。步长为&lt;/span&gt;&lt;span&gt;fragment_stride&lt;/span&gt;&lt;span&gt;，输出为&lt;/span&gt;&lt;span&gt;audio[ begin + fragment_stride : begin + fragment_stride + fragment_length ]&lt;/span&gt;&lt;/p&gt;

&lt;h3&gt;&lt;strong&gt;&lt;span&gt;输入数据的处理&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;h3&gt;&lt;span&gt;1. 对单个音频的处理有：&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;a) &lt;span&gt;读取音频。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;b) &lt;span&gt;声道处理&lt;/span&gt;(&lt;span&gt;原代码为单声道音频&lt;/span&gt;&lt;span&gt;)。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;c) &lt;span&gt;转化为浮点数（这里应该是进行了一个缩放到&lt;/span&gt;0~1&lt;span&gt;之间），&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;代码如下：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;def&lt;/span&gt;&lt;span&gt; wav_to_float(x):
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;try&lt;/span&gt;&lt;span&gt;:
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt;         max_value =&lt;span&gt; np.iinfo(x.dtype).max
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;         min_value =&lt;span&gt; np.iinfo(x.dtype).min
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;     &lt;span&gt;except&lt;/span&gt;&lt;span&gt;:
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;         max_value =&lt;span&gt; np.finfo(x.dtype).max
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;         min_value =&lt;span&gt; np.iinfo(x.dtype).min
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;     x = x.astype(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;float64&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, casting=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;safe&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;     x -=&lt;span&gt; min_value
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;     x /= ((max_value - min_value) / 2&lt;span&gt;.)
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;     x -= 1&lt;span&gt;.
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt; x
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;d) &lt;span&gt;转化为&lt;/span&gt;ulaw&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;编码&lt;/strong&gt;，使用&lt;/span&gt;&lt;span&gt;ulaw&lt;/span&gt;&lt;span&gt;编码的原因是原始音频数据是&lt;/span&gt;&lt;span&gt;16bit&lt;/span&gt;&lt;span&gt;的，则生成的时候一个帧音频有&lt;/span&gt;&lt;span&gt;2^16&lt;/span&gt;&lt;span&gt;个输出值（输出节点数），再进行&lt;/span&gt;&lt;span&gt;softmax&lt;/span&gt;&lt;span&gt;取值，这样的话代价高昂而且数据点取值范围太大会影响准确率。所以对原始的音频数据进行了&lt;/span&gt;&lt;span&gt;ulaw&lt;/span&gt;&lt;span&gt;编码（可参考：&lt;/span&gt;&lt;a href=&quot;https://blog.csdn.net/wzying25/article/details/79398055)&quot;&gt;&lt;span&gt;https://blog.csdn.net/wzying25/article/details/79398055&lt;/span&gt;&lt;span&gt;)&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;e) resample&lt;span&gt;到目标采样率。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;f) &lt;span&gt;转化为&lt;/span&gt;uint8&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;数据, &lt;/strong&gt;代码如下：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;def&lt;/span&gt;&lt;span&gt; float_to_uint8(x):
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;     x += 1&lt;span&gt;.
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;     x /= 2&lt;span&gt;.
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;     uint8_max_value = np.iinfo(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;uint8&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;).max
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt;     x *=&lt;span&gt; uint8_max_value
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt;     x = x.astype(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;uint8&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;7&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt; x
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;span&gt;单个音频处理的完整代码如下：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;def&lt;/span&gt;&lt;span&gt; process_wav(desired_sample_rate, filename, use_ulaw):
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     &lt;span&gt;#&lt;/span&gt;&lt;span&gt; print('reading wavfile...',filename)&lt;/span&gt;
&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;    with warnings.catch_warnings():
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt;         &lt;span&gt;#&lt;/span&gt;&lt;span&gt; warnings.simplefilter(&quot;error&quot;)  # 提升警告等级？会导致np.fromstring报错&lt;/span&gt;
&lt;span&gt; 5&lt;/span&gt;         channels =&lt;span&gt; scipy.io.wavfile.read(filename)
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;     file_sample_rate, audio =&lt;span&gt; channels
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt;     audio =&lt;span&gt; ensure_mono(audio)
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;     audio =&lt;span&gt; wav_to_float(audio)
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;     &lt;span&gt;if&lt;/span&gt;&lt;span&gt; use_ulaw:
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;         audio =&lt;span&gt; ulaw(audio)
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;     audio =&lt;span&gt; ensure_sample_rate(desired_sample_rate, file_sample_rate, audio)
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;     audio =&lt;span&gt; float_to_uint8(audio)
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt; audio
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;span&gt; 2. &lt;strong&gt;组织成模型的输入数据&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;a) &lt;span&gt;将同一个说话人的音频经过&lt;/span&gt;1&lt;span&gt;中的处理后进行拼接，形成一个&lt;/span&gt;&lt;span&gt;full_sequences。&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;b) &lt;/strong&gt;&lt;span&gt;&lt;strong&gt;划分测试集&lt;/strong&gt;，代码中将&lt;/span&gt;full_sequences&lt;span&gt;按&lt;/span&gt;&lt;span&gt;9 : 1&lt;/span&gt;&lt;span&gt;进行切分，后&lt;/span&gt;&lt;span&gt;0.1&lt;/span&gt;&lt;span&gt;部分加入测试集。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;c) &lt;span&gt;对&lt;/span&gt;full_sequences&lt;span&gt;，以&lt;/span&gt;&lt;span&gt;fragment_stride&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;进行分割&lt;/strong&gt;，长度为&lt;/span&gt;&lt;span&gt;fragment_length&lt;/span&gt;&lt;span&gt;（这里只记录序列开始的坐标。得到若干个音频子序列。代码如下：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;43&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;def&lt;/span&gt;&lt;span&gt; fragment_indices(full_sequences, fragment_length, batch_size, fragment_stride, nb_output_bins):
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;     &lt;span&gt;for&lt;/span&gt; seq_i, sequence &lt;span&gt;in&lt;/span&gt;&lt;span&gt; enumerate(full_sequences):
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;         &lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt; range(0, sequence.shape[0] -&lt;span&gt; fragment_length, fragment_stride):
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;             &lt;span&gt;yield&lt;/span&gt;&lt;span&gt; seq_i, i
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt;         &lt;span&gt;#&lt;/span&gt;&lt;span&gt; i为input sequence的起点 seq_i为音频文件的id&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;d) &lt;span&gt;生成&lt;/span&gt;batch&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;。&lt;/strong&gt;由&lt;/span&gt;&lt;span&gt;c&lt;/span&gt;&lt;span&gt;得到一个&lt;/span&gt;&lt;span&gt;full_sequence&lt;/span&gt;&lt;span&gt;的全部子序列列表。然后按&lt;/span&gt;&lt;span&gt;batch_size&lt;/span&gt;&lt;span&gt;进行划分。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
batches = cycle(partition_all(batch_size, indices)) &lt;span&gt;#&lt;/span&gt;&lt;span&gt; indices为列表&lt;/span&gt;
&lt;span&gt;for&lt;/span&gt; batch &lt;span&gt;in&lt;/span&gt;&lt;span&gt; batches:
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; len(batch) &amp;lt;&lt;span&gt; batch_size:
        &lt;/span&gt;&lt;span&gt;continue&lt;/span&gt;
    &lt;span&gt;yield&lt;/span&gt;&lt;span&gt; np.array(
        [one_hot(full_sequences[e[0]][e[&lt;/span&gt;1]:e[1] + fragment_length]) &lt;span&gt;for&lt;/span&gt; e &lt;span&gt;in&lt;/span&gt; batch], dtype=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;uint8&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;), np.array(
        [one_hot(full_sequences[e[0]][e[&lt;/span&gt;1] + 1:e[1] + fragment_length + 1]) &lt;span&gt;for&lt;/span&gt; e &lt;span&gt;in&lt;/span&gt; batch], dtype=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;uint8&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;e) &lt;span&gt;此时数据点的取值为&lt;/span&gt;0~255&lt;span&gt;，转换为&lt;/span&gt;&lt;span&gt;onehot&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;编码&lt;/strong&gt;，则输入数据变成了一个二维张量，此时喂入模型即可。相邻的两个子序列前者为输入，后者为输出。&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;model的定义和原理待续。&lt;/p&gt;
&lt;p&gt;还有一个简单的实现Keras WaveNet Demo正在赶工……完成后会附上&lt;/p&gt;
&lt;p&gt;实际上，用代码实现模型最头疼的部分就是输入数据的组织，本文以上已经介绍完毕。对于Keras而言已经把网络结构搭建简化得非常容易了。只要理解了模型的原理，实现起来就很容易了。&lt;/p&gt;

</description>
<pubDate>Wed, 05 Sep 2018 15:24:00 +0000</pubDate>
<dc:creator>SeanLiao</dc:creator>
<og:description>本文主要通俗讲述WaveNet的基本模型和Keras代码理解，以帮助和我一样刚刚入坑并难以理解其代码的小白。 作者：SeanLiao Blog：https://www.cnblogs.com/sean</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/seanliao/p/9595536.html</dc:identifier>
</item>
<item>
<title>第一篇：docker 简单入门（一） - 思维空间</title>
<link>http://www.cnblogs.com/fourspace/p/9595514.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/fourspace/p/9595514.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;本篇目录&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;span&gt;写在最前面的话&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;docker概念介绍&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;镜像的概念、容器的概念&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;docker的安装介绍&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;写在最前面的话&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　大家好，首先跟大家说声对不起，我班门弄斧了，我本身是做系统开发,使用的语言是C#和JAVA这两类，再多了的编程语言真的是没有精力去学习。docker这门应用技能断断续续的学习着，不精通。是能说我熟悉它，我能使用它。我能简单理解它。所有接下来如果有哪里有写错的地方，大家可以留言给我，如果我看到了，会验证且更正的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　我粗略拟定了一个学习总纲，最终的目标是学习大数据研发，分布式架构这类。我不知道我学习的方向是否正确，接下来的课程整理，我会往这边靠。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　最后感谢大家。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;docker 概念介绍&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　我个人理解的docker技术，就是一个运行的容器，怎么理解？所谓运行的容器，就是系统或者程序所需要的一切必要条件，比如当你运行jar或者war的时候，一句“Hello World”，我们需要什么？需要的是jvm，是jre，那这个时候我们只要jvm，jre足够的内存、cpu、网卡等等，我们的代码就可以在任何地方跑起来。这个时候，有人可能会问，它和虚拟机有什么区别？确实很多人都会拿着虚拟机和docker做对比，那么虚拟机需要的是一个OS(操作系统)，在虚拟出来的操作系统上，我们可以做任何事情。但是大家注意了，如果我只是想要运行一段程序，就安装一个虚拟机，是不是很浪费，而且虚拟机也是很耗物理机器的资源。&lt;/p&gt;
&lt;p&gt;　　所以，虚拟机它是这样子的【OS】-&amp;gt;【Hyper】-&amp;gt;【Guest OS】-&amp;gt;【bin/libs】-&amp;gt;【apps】。&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　　而，docker它是这样的【OS】-&amp;gt;【docker engine】-&amp;gt;【bin/libs】-&amp;gt;【apps】。&lt;/p&gt;
&lt;p&gt;　　所以通过对比，大家可以清晰的看到两者的区别docker engine 可以与系统隔离同时保持通信。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;镜像的概念、容器的概念&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　通过上面对docker概念的介绍，我们了解到，docker的守护进程可以很好的将容器内部运行和容器外部执行进行隔离，互不干扰。那么我们怎么写出第一句Hello World呢？我们需要了解两个概念，镜像（image)、容器(container).&lt;/p&gt;
&lt;p&gt;　　我理解下来，容器=镜像+可读写区。什么意思？说白了一点就是，容器就是镜像的运行场所，这个场所为容器提供所必须的可读写区域。就好比，小婴儿在妈妈肚子里面，婴儿好比image，而妈妈的肚子就是container，为小婴儿提供活动的空间和所需的养分。&lt;/p&gt;
&lt;p&gt;　　所以，&lt;span&gt;镜像只是一些只读的文件，而容器就是只读文件+可读写区域&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;docker的安装介绍&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　简单说说，不如实际做做。在做的过程中就可以深刻体会了，凡事都有个过程，不要理会概念和原理，我们可以先模仿，先使用，再反过来看原理。就算理解错了也没关系，因为如果一开始你就懂原理，那docker就是你创造出来的了。哈哈，所以边学边调整原理的认识。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　那么，在开始之前我们来确认下环境，这个非常重要，很重要。首先第一，不要用mac系统，不要用mac系统，不要用mac系统，重要的事情说三遍，因为&lt;span&gt;mac它不是liunx内核&lt;span&gt;。mac的很多命令都是封装的，你无法知道内部的一些信息。它会给你一些莫名其妙的错误提示。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;　　其次，不推荐使用Windows，至于为什么，我也不清楚，只是我在windows下使用docker，会很不习惯。很变扭很鸡肋，感兴趣的可以尝试一下。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;　　最后，推荐Ubuntu或则CentOS，很好用。我使用的是Ubuntu，虽然我没有全部掌握它的命令和参数，但是我使用下来，还是觉得很方便。很好用，有的时候可能比windows还会好点。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;　　当然以上都是我个人的观点，大家可以根据喜好选择系统环境，以后不做说明，文章内出现的系统都为ubuntu.那怎么安装操作系统环境我这里就不讲了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　进入到系统中，在桌面上，右击，选择【打开终端】&lt;/p&gt;
&lt;p&gt;　　查看docker版本&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://images2018.cnblogs.com/blog/349671/201809/349671-20180905225048136-2071815200.png&quot; alt=&quot;&quot; width=&quot;579&quot; height=&quot;451&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　当然，如果你没有安装docker，就不会出现版本号信息，&lt;/p&gt;
&lt;p&gt;　　在安装之前，我需要需要做一件事情，由于政治、历史原因，砸门国家有个墙非常厉害，长城防火墙对吧，所以在获取docker的时候，我们需要设置下镜像加速。&lt;/p&gt;
&lt;p&gt;　　在命令中输入【sudo vim /etc/docker/daemon.json】，如果提示&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://images2018.cnblogs.com/blog/349671/201809/349671-20180905230204207-181325354.png&quot; alt=&quot;&quot; width=&quot;485&quot; height=&quot;36&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　不要害怕，运行【sudo apt install vim】我们来安装下这个vim命令就可以了。&lt;/p&gt;
&lt;p&gt;　　接上文，在运行完【sudo vim /etc/docker/daemon.json】之后，打开编辑&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://images2018.cnblogs.com/blog/349671/201809/349671-20180905230439144-2008109078.png&quot; alt=&quot;&quot; width=&quot;468&quot; height=&quot;58&quot;/&gt;我们用网易的镜像加速，保存好，我们就可以快乐的准备安装docker了。&lt;/p&gt;
&lt;p&gt;　　使用【sudo &lt;span class=&quot;pln&quot;&gt;wget &lt;span class=&quot;pun&quot;&gt;-&lt;span class=&quot;pln&quot;&gt;qO&lt;span class=&quot;pun&quot;&gt;- &lt;span class=&quot;pln&quot;&gt;https&lt;span class=&quot;pun&quot;&gt;:&lt;span class=&quot;com&quot;&gt;//get.docker.com/ | sh】静静等待就行，提示安装成功之后【sudo service docker start】启动一下服务。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;com&quot;&gt;　　最后，我们再使用上面的查看docker版本的方法查看下docker版本。就可以了。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;com&quot;&gt;　　docker的安装有很多方式，不是很难。大家可能会对命令有点陌生，还是那句话，坚持和习惯。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;以上是我简单的总结，适合快速入门或者想了解下docker的朋友，希望你们能够喜欢。&lt;/p&gt;
&lt;p&gt;以后会不定期更新此类文章，如果转载，请注明出处。&lt;/p&gt;
&lt;p&gt;邮箱:　　wuyun151@163.com　　wuyunlong.著&lt;/p&gt;
&lt;p class=&quot;prettyprint prettyprinted&quot;&gt; &lt;/p&gt;



&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 05 Sep 2018 15:18:00 +0000</pubDate>
<dc:creator>思维空间</dc:creator>
<og:description>工作这么多年，从来没有认真整理过自己的知识。这么多年来，很多时候都忙于生活，包括现在也是一样。 所谓技术牛人，只是你比别人先了解，并且你比别人了解的更为深入，仅此而已。所以当我看到很多拽的不行，</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/fourspace/p/9595514.html</dc:identifier>
</item>
<item>
<title>图的表示、深度广度遍历算法及其应用 - 蒙面的普罗米修斯</title>
<link>http://www.cnblogs.com/datasnail/p/9595517.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/datasnail/p/9595517.html</guid>
<description>&lt;p&gt;世间的一切对象都可化为节点；世间一切关系都可化为节点间的一条线；从而组成了如梦幻泡影的图。将来的环球必定是图的世界。&lt;/p&gt;
&lt;h3 id=&quot;一图的表示&quot;&gt;一、图的表示&lt;/h3&gt;
&lt;p&gt;图有有向图和无向图，表示方法一般有邻接表、邻接矩阵等方法，无向图和有向图都可以用这两种方法表示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.datasnail.cn/postimg/algorithm_graph/graphs.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图1. 图的例子&lt;sup&gt;[1]&lt;/sup&gt;&lt;/p&gt;
&lt;h4 id=&quot;邻接表&quot;&gt;1、邻接表&lt;/h4&gt;
&lt;p&gt;在邻接表中，对于每个顶点u，使用一个链表把所有与u相邻的点点串起来，并标记这个集合为adj(u)。举个栗子如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.datasnail.cn/postimg/algorithm_graph/adj.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图2. 邻接表表示图的例子&lt;sup&gt;[1]&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;在真正操作图进行实验的时候，一般也都使用邻接矩阵表示，例如要存储图1中的有向图，可以直接用一个csv或者txt文件，存储内容如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;5,14
1,3,2,5,4
2,3,1,5,3
3,2,2,4
4,3,1,5,3
5,3,4,1,2&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上述文件就是第一行存储了总共的节点数量、边的数量；接下来的每一行就是此顶点的id和邻居的id，并且第2位数字存储了该节点总共有多少邻居节点；为了进一步的操作简单，可以把原有的节点id映射为从0到n，没有边的节点用0补充，此时行号和id相等了，访问起来更加迅速。这样存储的好处是需要较少的内存就可以完成，而且操作简单。&lt;/p&gt;
&lt;h4 id=&quot;邻接矩阵&quot;&gt;2、邻接矩阵&lt;/h4&gt;
&lt;p&gt;邻接矩阵顾名思义就是用一个n*n的矩阵，存储各节点之间的关系，空间复杂度$O(n^2)$，这样存储在一些矩阵运算的时候较为方便，例如转置。图1中两图的邻接矩阵如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://www.datasnail.cn/postimg/algorithm_graph/matrix.png&quot;/&gt;&lt;br/&gt;图3. 邻接矩阵表示图的例子&lt;sup&gt;[1]&lt;/sup&gt;&lt;/p&gt;
&lt;h3 id=&quot;二图周游算法&quot;&gt;二、图周游算法&lt;/h3&gt;
&lt;h4 id=&quot;广度优先遍历&quot;&gt;1、广度优先遍历&lt;/h4&gt;
&lt;p&gt;图的广度遍历顾名思义就是访问图中节点的时候，优先在广度上进行遍历；也就是访问到某节点A时，优先访问完A的所有邻居节点&lt;strong&gt;[节点的访问顺序并没有做要求，在具体的问题中此处可以定义访问顺序]&lt;/strong&gt;，再继续访问邻居的邻居，直接看代码：&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;#过程中主要是做三件事：颜色、距离、父节点
BFS(G(V,E),s)
    #初始化
    for each vertex u in V-{s}
        color[u] &amp;lt;- White
        d[u]&amp;lt;-∞
        pai[u]&amp;lt;-None
    endfor
    #处理开始节点
    color[s]&amp;lt;-Gray
    d[s]&amp;lt;-0
    pai[s]&amp;lt;-None
    
    #初始化队列
    Q&amp;lt;-Queue()
    Enqueue(Q,s)
    
    #开始广度访问图
    while not Q.empyt():
        u&amp;lt;-Dequeue(Q)
        for each v in Adj[u]:
            if color[v] = White #检查颜色是否为白色，即没有被访问过
                color[v] &amp;lt;- Gray #颜色，变颜色为灰色
                d[v]&amp;lt;-d[u]+1 #距离
                pai[v]&amp;lt;-u  #父节点
            endif
        endfor
    color[u]&amp;lt;-Black
    endwhile
    End    &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;应用：&lt;/strong&gt;&lt;br/&gt;无向图二着色问题，无奇回路&amp;lt;=&amp;gt;可以二着色&amp;lt;=&amp;gt;可以分为二部图&lt;/p&gt;
&lt;h4 id=&quot;深度优先遍历&quot;&gt;2、深度优先遍历&lt;/h4&gt;
&lt;p&gt;深度优先搜索是从某一顶点开始访问，然后访问他的邻居，与BFS不同的是，当深度优先搜索从某个顶点u访问他的邻居时，只选择其中的一个还未被访问的邻居v，然后暂时弃u的其他邻居于不顾，而从新的儿子节点v去访问v的邻居。当v出发的访问全部完成后，DFS回到u，然后再访问u的第二个邻居，以此类推。这里有个动画就好了，可是我不会画。&lt;br/&gt;深度优先遍历，迭代方法的伪代码：&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;DFS(G(V,E))
    #初始化访问控制的颜色，父节点
    for each vetex u in V
        color[u] = White
        pai[u]=None
    endfor

    #最开始，时间为0
    time &amp;lt;- 0
    
    #对于每个节点进行一次深度优先遍历，防止图节点间不连通
    for each vetex u in V:
        if color[u]=While:
            then DFS-visit(u)
        endif
    endfor
    End
#对节点s，进行深度优先遍历
DFS-Visit(s):

    color[s] &amp;lt;- Gray
    time = time + 1
    d[s]&amp;lt;-time
    #如果访问到节点s的邻居节点，那么对其邻居节点迭代进行深度优先遍历
    for each v in Adj[s]:
        if color[v] = White
            pai[v]&amp;lt;-s
            DFS-Visit(v)
        endif
    endfor
    color[s]&amp;lt;-Black
    f[s]&amp;lt;-time&amp;lt;-time+1
    End&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;区间套定理&quot;&gt;&lt;strong&gt;2.1 区间套定理：&lt;/strong&gt;&lt;/h4&gt;
&lt;h4 id=&quot;白路径定理&quot;&gt;&lt;strong&gt;2.2 白路径定理：&lt;/strong&gt;&lt;/h4&gt;
&lt;h4 id=&quot;拓扑排序&quot;&gt;&lt;strong&gt;2.3 拓扑排序：&lt;/strong&gt;&lt;/h4&gt;
&lt;h4 id=&quot;无回路有向图中最长路径问题&quot;&gt;&lt;strong&gt;2.4 无回路有向图中最长路径问题：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;一些应用问题需要找到图中的最短或者最长的&lt;strong&gt;简单路径&lt;/strong&gt;(不含回路的路径），图往往是加权的。但是&lt;span&gt;&lt;strong&gt;对于任意图，找一条最长路径是NPC问题，即使这个图是不加权的图&lt;/strong&gt;&lt;/span&gt;。然而只有这个图是无回路的图时，不论是有向图还是无向图，加权还是不加权图，都可以在线性时间$O(|V|+|E|)=O(n+m)$。细心的我可能发现了，&lt;strong&gt;无回路的图就是棵树或者森林啊&lt;/strong&gt;，两个顶点之间要么不连通，要不然就只有唯一的一条路径。&lt;/p&gt;
&lt;h4 id=&quot;强连通分支&quot;&gt;&lt;strong&gt;&lt;span id=&quot;stronglyconnectedcomponent&quot;&gt;2.5 强连通分支：&lt;/span&gt;&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;定义1： 如果一个有向图中任意一顶点都有一条通向其他任一顶点的路径，那么这个&lt;span&gt;&lt;strong&gt;有向图&lt;/strong&gt;&lt;/span&gt;称为&lt;strong&gt;强连通图&lt;/strong&gt;（strongly connected graph）&lt;br/&gt;定义2： &lt;span&gt;&lt;strong&gt;有向图&lt;/strong&gt;&lt;/span&gt;G，其&lt;strong&gt;隐含的无向图&lt;/strong&gt;$G'$是指把G中的每条边的方向都去掉后所得到的无向图。&lt;br/&gt;定义3： 如果一个&lt;span&gt;&lt;strong&gt;有向图&lt;/strong&gt;&lt;/span&gt;G所隐含的无向图$G'$是个连通图，那么有向图G称为&lt;strong&gt;弱连通图&lt;/strong&gt;（weakly connected graph）&lt;br/&gt;定义4： 如果一个&lt;span&gt;&lt;strong&gt;有向图&lt;/strong&gt;&lt;/span&gt;的子图是个强连通图，则成为&lt;strong&gt;强连通子图&lt;/strong&gt;（strongly connected subgraph）&lt;br/&gt;定义5： 如果一个&lt;span&gt;&lt;strong&gt;有向图&lt;/strong&gt;&lt;/span&gt;的强连通子图已最大，即不能在加入其他任何一个顶点而仍然强连通，那么这个子图称为&lt;strong&gt;强连通分支&lt;/strong&gt;（strongly connected component）&lt;br/&gt;&lt;strong&gt;这里强连通分支包含于强连通子图内。&lt;/strong&gt;&lt;br/&gt;定义6： &lt;strong&gt;有向图的强连通分支问题&lt;/strong&gt;就是把一个有向图的顶点划分为不相交的若干个强连通分支。&lt;/p&gt;
&lt;h3 id=&quot;三参考文献&quot;&gt;三、参考文献&lt;/h3&gt;
&lt;p&gt;[1] 沈孝钧. 计算机算法基础 : Essentials of computer algorithms[M]. 机械工业出版社, 2014.&lt;/p&gt;
</description>
<pubDate>Wed, 05 Sep 2018 15:18:00 +0000</pubDate>
<dc:creator>蒙面的普罗米修斯</dc:creator>
<og:description>世间的一切对象都可化为节点；世间一切关系都可化为节点间的一条线；从而组成了如梦幻泡影的图。将来的环球必定是图的世界。 一、图的表示 图有有向图和无向图，表示方法一般有邻接表、邻接矩阵等方法，无向图和有</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/datasnail/p/9595517.html</dc:identifier>
</item>
<item>
<title>Python机器学习笔记：利用Keras进行多类分类 - 战争热诚</title>
<link>http://www.cnblogs.com/wj-1314/p/9591369.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wj-1314/p/9591369.html</guid>
<description>&lt;p&gt;　　Keras是一个用于深度学习的Python库，它包含高效的数值库Theano和TensorFlow。&lt;/p&gt;&lt;p&gt;　　本文的目的是学习如何从csv中加载数据并使其可供Keras使用，如何用神经网络建立多类分类的数据进行建模，如何使用scikit-learn评估Keras神经网络模型。&lt;/p&gt;&lt;p&gt;　　（前言是整理别人博客的笔记https://blog.csdn.net/qq_22238533/article/details/77774223）&lt;/p&gt;&lt;p&gt;　　一般情况下，我们所认识的lr模型是一个二分类的模型，但是能否用lr进行多分类任务呢？答案当然是可以的。&lt;/p&gt;&lt;p&gt;　　　不过我们需要注意的是，我们有许多种思想利用lr来进行分类&lt;/p&gt;&lt;p&gt;　　既然天然的lr是用来做二分类，那么我们很自然地想到把多分类划分为多个二分类的任务。&lt;/p&gt;&lt;p&gt;　假如某个分类中有N个类别，我们将这N个类别进行两两配对（两两配对后转化为二分类问题）。那么我们可以得到&lt;img src=&quot;https://img-blog.csdn.net/20170901162649098&quot; alt=&quot;&quot; width=&quot;78&quot; height=&quot;49&quot;/&gt;个二分类器。（简单解释一下，相当于在N个类别里面抽2个）&lt;/p&gt;&lt;p&gt;　　&lt;span&gt;&lt;span&gt;在本文学习中，我们将使用&lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Iris&quot; target=&quot;_blank&quot;&gt;鸢尾&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Iris&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;span&gt;花数据集&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;的标准机器学习问题&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　这个数据集经过深入研究，是在神经网络上练习的一个很好的问题，因为所有4个输入变量都是数字的，并且具有相同的厘米级别。&lt;/span&gt;&lt;span&gt;每个实例描述观察到的花测量的属性，输出变量是特定的鸢尾种类。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　这是一个多类别的分类问题，意味着有两个以上的类需要预测，实际上有三种花种。&lt;/span&gt;&lt;span&gt;这是用神经网络练习的一个重要问题类型，因为三个类值需要专门的处理。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　鸢尾花数据集是一个充分研究的问题，我们可以&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;http://www.is.umk.pl/projects/rules.html#Iris&quot;&gt;&lt;span&gt;&lt;span&gt;期望&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;a href=&quot;http://www.is.umk.pl/projects/rules.html#Iris&quot;&gt;&lt;span&gt;实现模型精度&lt;/span&gt;&lt;/a&gt;&lt;span&gt;为在95％至97％的范围内，这为开发我们的模型提供了一个很好的目标。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　您可以&lt;/span&gt;&lt;span&gt;从UCI机器学习库&lt;/span&gt;&lt;/span&gt;&lt;a href=&quot;http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&quot;&gt;&lt;span&gt;&lt;span&gt;下载鸢尾花数据集&lt;/span&gt;&lt;/span&gt;&lt;/a&gt;&lt;span&gt;&lt;span&gt;，并将其放在当前工作目录中，文件&lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;名为&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt; “ &lt;/span&gt;&lt;em&gt;&lt;span&gt;iris.csv&lt;/span&gt;&lt;/em&gt;&lt;span&gt;”。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;div readability=&quot;635&quot;&gt;
&lt;pre class=&quot;brush:csharp;collapse:true;;gutter:true;&quot;&gt;
5.1,3.5,1.4,0.2,Iris-setosa
4.9,3.0,1.4,0.2,Iris-setosa
4.7,3.2,1.3,0.2,Iris-setosa
4.6,3.1,1.5,0.2,Iris-setosa
5.0,3.6,1.4,0.2,Iris-setosa
5.4,3.9,1.7,0.4,Iris-setosa
4.6,3.4,1.4,0.3,Iris-setosa
5.0,3.4,1.5,0.2,Iris-setosa
4.4,2.9,1.4,0.2,Iris-setosa
4.9,3.1,1.5,0.1,Iris-setosa
5.4,3.7,1.5,0.2,Iris-setosa
4.8,3.4,1.6,0.2,Iris-setosa
4.8,3.0,1.4,0.1,Iris-setosa
4.3,3.0,1.1,0.1,Iris-setosa
5.8,4.0,1.2,0.2,Iris-setosa
5.7,4.4,1.5,0.4,Iris-setosa
5.4,3.9,1.3,0.4,Iris-setosa
5.1,3.5,1.4,0.3,Iris-setosa
5.7,3.8,1.7,0.3,Iris-setosa
5.1,3.8,1.5,0.3,Iris-setosa
5.4,3.4,1.7,0.2,Iris-setosa
5.1,3.7,1.5,0.4,Iris-setosa
4.6,3.6,1.0,0.2,Iris-setosa
5.1,3.3,1.7,0.5,Iris-setosa
4.8,3.4,1.9,0.2,Iris-setosa
5.0,3.0,1.6,0.2,Iris-setosa
5.0,3.4,1.6,0.4,Iris-setosa
5.2,3.5,1.5,0.2,Iris-setosa
5.2,3.4,1.4,0.2,Iris-setosa
4.7,3.2,1.6,0.2,Iris-setosa
4.8,3.1,1.6,0.2,Iris-setosa
5.4,3.4,1.5,0.4,Iris-setosa
5.2,4.1,1.5,0.1,Iris-setosa
5.5,4.2,1.4,0.2,Iris-setosa
4.9,3.1,1.5,0.1,Iris-setosa
5.0,3.2,1.2,0.2,Iris-setosa
5.5,3.5,1.3,0.2,Iris-setosa
4.9,3.1,1.5,0.1,Iris-setosa
4.4,3.0,1.3,0.2,Iris-setosa
5.1,3.4,1.5,0.2,Iris-setosa
5.0,3.5,1.3,0.3,Iris-setosa
4.5,2.3,1.3,0.3,Iris-setosa
4.4,3.2,1.3,0.2,Iris-setosa
5.0,3.5,1.6,0.6,Iris-setosa
5.1,3.8,1.9,0.4,Iris-setosa
4.8,3.0,1.4,0.3,Iris-setosa
5.1,3.8,1.6,0.2,Iris-setosa
4.6,3.2,1.4,0.2,Iris-setosa
5.3,3.7,1.5,0.2,Iris-setosa
5.0,3.3,1.4,0.2,Iris-setosa
7.0,3.2,4.7,1.4,Iris-versicolor
6.4,3.2,4.5,1.5,Iris-versicolor
6.9,3.1,4.9,1.5,Iris-versicolor
5.5,2.3,4.0,1.3,Iris-versicolor
6.5,2.8,4.6,1.5,Iris-versicolor
5.7,2.8,4.5,1.3,Iris-versicolor
6.3,3.3,4.7,1.6,Iris-versicolor
4.9,2.4,3.3,1.0,Iris-versicolor
6.6,2.9,4.6,1.3,Iris-versicolor
5.2,2.7,3.9,1.4,Iris-versicolor
5.0,2.0,3.5,1.0,Iris-versicolor
5.9,3.0,4.2,1.5,Iris-versicolor
6.0,2.2,4.0,1.0,Iris-versicolor
6.1,2.9,4.7,1.4,Iris-versicolor
5.6,2.9,3.6,1.3,Iris-versicolor
6.7,3.1,4.4,1.4,Iris-versicolor
5.6,3.0,4.5,1.5,Iris-versicolor
5.8,2.7,4.1,1.0,Iris-versicolor
6.2,2.2,4.5,1.5,Iris-versicolor
5.6,2.5,3.9,1.1,Iris-versicolor
5.9,3.2,4.8,1.8,Iris-versicolor
6.1,2.8,4.0,1.3,Iris-versicolor
6.3,2.5,4.9,1.5,Iris-versicolor
6.1,2.8,4.7,1.2,Iris-versicolor
6.4,2.9,4.3,1.3,Iris-versicolor
6.6,3.0,4.4,1.4,Iris-versicolor
6.8,2.8,4.8,1.4,Iris-versicolor
6.7,3.0,5.0,1.7,Iris-versicolor
6.0,2.9,4.5,1.5,Iris-versicolor
5.7,2.6,3.5,1.0,Iris-versicolor
5.5,2.4,3.8,1.1,Iris-versicolor
5.5,2.4,3.7,1.0,Iris-versicolor
5.8,2.7,3.9,1.2,Iris-versicolor
6.0,2.7,5.1,1.6,Iris-versicolor
5.4,3.0,4.5,1.5,Iris-versicolor
6.0,3.4,4.5,1.6,Iris-versicolor
6.7,3.1,4.7,1.5,Iris-versicolor
6.3,2.3,4.4,1.3,Iris-versicolor
5.6,3.0,4.1,1.3,Iris-versicolor
5.5,2.5,4.0,1.3,Iris-versicolor
5.5,2.6,4.4,1.2,Iris-versicolor
6.1,3.0,4.6,1.4,Iris-versicolor
5.8,2.6,4.0,1.2,Iris-versicolor
5.0,2.3,3.3,1.0,Iris-versicolor
5.6,2.7,4.2,1.3,Iris-versicolor
5.7,3.0,4.2,1.2,Iris-versicolor
5.7,2.9,4.2,1.3,Iris-versicolor
6.2,2.9,4.3,1.3,Iris-versicolor
5.1,2.5,3.0,1.1,Iris-versicolor
5.7,2.8,4.1,1.3,Iris-versicolor
6.3,3.3,6.0,2.5,Iris-virginica
5.8,2.7,5.1,1.9,Iris-virginica
7.1,3.0,5.9,2.1,Iris-virginica
6.3,2.9,5.6,1.8,Iris-virginica
6.5,3.0,5.8,2.2,Iris-virginica
7.6,3.0,6.6,2.1,Iris-virginica
4.9,2.5,4.5,1.7,Iris-virginica
7.3,2.9,6.3,1.8,Iris-virginica
6.7,2.5,5.8,1.8,Iris-virginica
7.2,3.6,6.1,2.5,Iris-virginica
6.5,3.2,5.1,2.0,Iris-virginica
6.4,2.7,5.3,1.9,Iris-virginica
6.8,3.0,5.5,2.1,Iris-virginica
5.7,2.5,5.0,2.0,Iris-virginica
5.8,2.8,5.1,2.4,Iris-virginica
6.4,3.2,5.3,2.3,Iris-virginica
6.5,3.0,5.5,1.8,Iris-virginica
7.7,3.8,6.7,2.2,Iris-virginica
7.7,2.6,6.9,2.3,Iris-virginica
6.0,2.2,5.0,1.5,Iris-virginica
6.9,3.2,5.7,2.3,Iris-virginica
5.6,2.8,4.9,2.0,Iris-virginica
7.7,2.8,6.7,2.0,Iris-virginica
6.3,2.7,4.9,1.8,Iris-virginica
6.7,3.3,5.7,2.1,Iris-virginica
7.2,3.2,6.0,1.8,Iris-virginica
6.2,2.8,4.8,1.8,Iris-virginica
6.1,3.0,4.9,1.8,Iris-virginica
6.4,2.8,5.6,2.1,Iris-virginica
7.2,3.0,5.8,1.6,Iris-virginica
7.4,2.8,6.1,1.9,Iris-virginica
7.9,3.8,6.4,2.0,Iris-virginica
6.4,2.8,5.6,2.2,Iris-virginica
6.3,2.8,5.1,1.5,Iris-virginica
6.1,2.6,5.6,1.4,Iris-virginica
7.7,3.0,6.1,2.3,Iris-virginica
6.3,3.4,5.6,2.4,Iris-virginica
6.4,3.1,5.5,1.8,Iris-virginica
6.0,3.0,4.8,1.8,Iris-virginica
6.9,3.1,5.4,2.1,Iris-virginica
6.7,3.1,5.6,2.4,Iris-virginica
6.9,3.1,5.1,2.3,Iris-virginica
5.8,2.7,5.1,1.9,Iris-virginica
6.8,3.2,5.9,2.3,Iris-virginica
6.7,3.3,5.7,2.5,Iris-virginica
6.7,3.0,5.2,2.3,Iris-virginica
6.3,2.5,5.0,1.9,Iris-virginica
6.5,3.0,5.2,2.0,Iris-virginica
6.2,3.4,5.4,2.3,Iris-virginica
5.9,3.0,5.1,1.8,Iris-virginica
&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　我们从导入本文需要的所有类和函数开始。其中包括需要Keras的功能，还包括来自&lt;a href=&quot;http://pandas.pydata.org/&quot; target=&quot;_blank&quot;&gt;pandas&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;的数据加载以及来自scikit-learn的数据准备和模型评估。&lt;/p&gt;&lt;p&gt;　　这对于确保我们可以再次精确地实现从该模型获得的结果非常重要，它确保可以再现训练神经网络模型的随机过程。&lt;/p&gt;&lt;p&gt;&lt;span&gt;　　可以直接加载数据集。&lt;/span&gt;&lt;span&gt;因为输出变量包含字符串，所以最容易使用pandas加载数据。&lt;/span&gt;&lt;span&gt;然后我们可以将属性（列）拆分为输入变量（X）和输出变量（Y）。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　当使用神经网络对多类分类问题进行建模时，优良作法是将包含每个类值的值的向量的输出属性重新整形为一个矩阵，每个类值都有一个布尔值，以及给定实例是否具有该值是否有类值。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　例如：在这个问题中，三个&lt;span&gt;类值是Iris-setosa，Iris-versicolor和Iris-virginica。&lt;/span&gt;&lt;span&gt;如果我们有观察结果：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;　　多类分类问题本质上可以分解为多个二分类问题，而解决二分类问题的方法有很多。这里我们利用Keras机器学习框架中的ANN（artificial neural network）来解决多分类问题。这里我们采用的例子是著名的UCI Machine Learning Repository中的鸢尾花数据集（&lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Iris&quot;&gt;iris flower dataset&lt;/a&gt;）。&lt;br/&gt;　　多类分类问题与二类分类问题类似，需要将类别变量（categorical function）的输出标签转化为数值变量。这个问题在二分类的时候直接转换为（0，1）（输出层采用&lt;a href=&quot;https://en.wikipedia.org/wiki/Sigmoid_function&quot;&gt;sigmoid函数&lt;/a&gt;）或（-1，1）（输出层采用&lt;a href=&quot;https://en.wikipedia.org/wiki/Hyperbolic_function&quot;&gt;tanh函数&lt;/a&gt;）。类似的，在多分类问题中我们将转化为虚拟变量（dummy variable）：即用one hot encoding方法将输出标签的向量（vector）转化为只在出现对应标签的那一列为1，其余为0的布尔矩阵。以我们所用的鸢尾花数据为例：&lt;/p&gt;&lt;p&gt; 　　注意这里不要将label直接转化成数值变量，如1,2,3，这样的话与其说是预测问题更像是回归预测的问题，后者的难度比前者大。（当类别比较多的时候输出值的跨度就会比较大，此时输出层的激活函数就只能用linear）&lt;/p&gt;&lt;p&gt;&lt;span&gt;我们可以通过首先使用scikit-learn类LabelEncoder将字符串一致地编码为整数来完成此操作。&lt;/span&gt;&lt;span&gt;然后使用Keras函数to_categorical（）将整数向量转换为一个热编码&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　Keras库提供了包装类，允许您在scikit-learn中使用Keras开发的神经网络模型。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　Keras中有一个KerasClassifier类，可用作scikit-learn中的Estimator，它是库中基本类型的模型。&lt;/span&gt;&lt;span&gt;KerasClassifier将函数的名称作为参数。&lt;/span&gt;&lt;span&gt;该函数必须返回构建的神经网络模型，为训练做好准备。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　下面是一个函数，它将为鸢尾花分类问题创建一个基线神经网络。&lt;/span&gt;&lt;span&gt;它创建了一个简单的完全连接的网络，其中一个隐藏层包含8个神经元。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　隐藏层使用整流器激活功能，这是一种很好的做法。&lt;/span&gt;&lt;span&gt;因为我们对鸢尾花数据集使用了单热编码，所以输出层必须创建3个输出值，每个类一个。&lt;/span&gt;&lt;span&gt;具有最大值的输出值将被视为模型预测的类。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　请注意，我们&lt;/span&gt;&lt;span&gt;在输出层&lt;/span&gt;&lt;span&gt;使用“ &lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;softmax&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt; ”激活功能。&lt;/span&gt;&lt;span&gt;这是为了确保输出值在0和1的范围内，并且可以用作预测概率。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　最后，网络使用具有对数损失函数的高效Adam梯度下降优化算法，&lt;/span&gt;&lt;span&gt;在Keras中&lt;/span&gt;&lt;span&gt;称为“ &lt;/span&gt;&lt;/span&gt;&lt;em&gt;&lt;span&gt;&lt;span&gt;categorical_crossentropy&lt;/span&gt;&lt;/span&gt;&lt;/em&gt;&lt;span&gt;&lt;span&gt; ”。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　我们还可以在构造KerasClassifier类中传递参数，该类将传递给内部用于训练神经网络的fit（）函数。&lt;/span&gt;&lt;span&gt;在这里，我们将时期数量传递为200，批量大小为5，以便在训练模型时使用。&lt;/span&gt;&lt;span&gt;通过将verbose设置为0，在训练时也会关闭调试。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://keras.io/&quot;&gt;Keras&lt;/a&gt;是基于Theano或Tensorflow底层开发的简单模块化的神经网络框架，因此用Keras搭建网络结构会比Tensorflow更加简单。这里我们将使用Keras提供的&lt;a href=&quot;https://keras.io/scikit-learn-api/#wrappers-for-the-scikit-learn-api&quot;&gt;KerasClassifier&lt;/a&gt;类，这个类可以在scikit-learn包中作为Estimator使用,故利用这个类我们就可以方便的调用sklearn包中的一些函数进行数据预处理和结果评估（此为sklearn包中模型(model)的基本类型）。&lt;br/&gt;　　对于网络结构，我们采用3层全向连接的，输入层有4个节点，隐含层有10个节点，输出层有3个节点的网络。其中，隐含层的激活函数为relu（&lt;a href=&quot;https://en.wikipedia.org/wiki/Rectifier_(neural_networks)&quot;&gt;rectifier&lt;/a&gt;），输出层的激活函数为&lt;a href=&quot;https://en.wikipedia.org/wiki/Softmax_function&quot;&gt;softmax&lt;/a&gt;。损失函数则相应的选择&lt;a href=&quot;https://keras.io/objectives/#usage-of-objectives&quot;&gt;categorical_crossentropy&lt;/a&gt;(此函数来着theano或tensorflow，具体可以参见&lt;a href=&quot;http://deeplearning.net/software/theano/library/tensor/nnet/nnet.html#theano.tensor.nnet.nnet.categorical_crossentropy&quot;&gt;这里&lt;/a&gt;)（二分类的话一般选择activation=‘sigmoid’， loss=‘binary_crossentropy’）。&lt;br/&gt;&lt;strong&gt;　　PS：&lt;/strong&gt;对于多类分类网络结构而言，增加中间隐含层能够提升训练精度，但是所需的计算时间和空间会增大，因此需要测试选择一个合适的数目，这里我们设为10；此外，每一层的舍弃率（dropout）也需要相应调整（太高容易欠拟合，太低容易过拟合），这里我们设为0.2。&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　scikit-learn具有使用一套技术评估模型的出色能力。&lt;/span&gt;&lt;span&gt;评估机器学习模型的黄金标准是k倍交叉验证。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　首先，我们可以定义模型评估程序。&lt;/span&gt;&lt;span&gt;在这里，我们将折叠数设置为10（一个很好的默认值）并在分区之前对数据进行洗牌。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　现在我们可以使用10倍交叉验证程序（kfold）在我们的数据集（X和dummy_y）上评估我们的模型（估计器）。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;　　评估模型仅需要大约10秒钟，并返回一个对象，该对象描述了对数据集的每个分割的10个构建模型的评估。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt; 　　&lt;span&gt;结果总结为数据集上模型精度的均值和标准差。&lt;/span&gt;&lt;span&gt;这是对看不见的数据的模型性能的合理估计。&lt;/span&gt;&lt;span&gt;对于这个问题，它也属于已知的最佳结果范围。&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;在这篇文章中，我们学习了如何使用Keras Python库开发和评估神经网络以进行深度学习。学习了以下知识：&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;</description>
<pubDate>Wed, 05 Sep 2018 15:00:00 +0000</pubDate>
<dc:creator>战争热诚</dc:creator>
<og:description>Keras是一个用于深度学习的Python库，它包含高效的数值库Theano和TensorFlow。 本文的目的是学习如何从csv中加载数据并使其可供Keras使用，如何用神经网络建立多类分类的数据进</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/wj-1314/p/9591369.html</dc:identifier>
</item>
<item>
<title>一起学Hadoop——TotalOrderPartitioner类实现全局排序 - summer哥</title>
<link>http://www.cnblogs.com/airnew/p/9595385.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/airnew/p/9595385.html</guid>
<description>&lt;p&gt;Hadoop排序，从大的范围来说有两种排序，一种是按照key排序，一种是按照value排序。如果按照value排序，只需在map函数中将key和value对调，然后在reduce函数中在对调回去。从小范围来说排序又分成部分排序，全局排序，辅助排序，二次排序等。本文介绍如何在Hadoop中实现全局排序。&lt;/p&gt;

&lt;p&gt;全局排序，就是说在一个MapReduce程序产生的输出文件中，所有的结果都是按照某个策略进行排序的，例如降序还是升序。MapReduce只能保证一个分区内的数据是key有序的，一个分区对应一个reduce，因此只有一个reduce就保证了数据全局有序，但是这样又不能用到Hadoop集群的优势。&lt;/p&gt;

&lt;p&gt;对于多个reduce如何保证数据的全局排序呢？通常的做法是按照key值分区，通过MapReduce的默认分区函数HashPartition将不同范围的key发送到不同的reduce处理，例如一个文件中有key值从1到10000的数据，我们使用两个分区，将1到5000的key发送到partition1，然后由reduce1处理，5001到10000的key发动到partition2然后由reduce2处理，reduce1中的key是按照1到5000的升序排序，reduce2中的key是按照5001到10000的升序排序，这样就保证了整个MapReduce程序的全局排序。但是这样做有两个缺点：&lt;/p&gt;
&lt;p&gt;1、当数据量大时会出现OOM。&lt;/p&gt;
&lt;p&gt;2、会出现数据倾斜。&lt;/p&gt;

&lt;p&gt;Hadoop提供TotalOrderPartitioner类用于实现全局排序的功能，并且解决了OOM和数据倾斜的问题。&lt;/p&gt;
&lt;p&gt;TotalOrderPartitioner类提供了数据采样器，对key值进行部分采样，然后按照采样结果寻找key值的最佳分割点，将key值均匀的分配到不同的分区中。&lt;/p&gt;
&lt;p&gt;TotalOrderPartitioner 类提供了三个采样器，分别是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;SplitSampler 分片采样器，从数据分片中采样数据，该采样器不适合已经排好序的数据&lt;/li&gt;
&lt;li&gt;RandomSampler随机采样器，按照设置好的采样率从一个数据集中采样&lt;/li&gt;
&lt;li&gt;IntervalSampler间隔采样机，以固定的间隔从分片中采样数据，对于已经排好序的数据效果非常好。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;三个采样器都实现了K[] getSample(InputFormat&amp;lt;K,V&amp;gt; inf, Job job)方法，该方法返回的是K[]数组，数组中存放的是根据采样结果返回的key值，即分隔点，MapRdeuce就是根据K[]数组的长度N生成N-1个分区partition数量，然后按照分割点的范围将对应的数据发送到对应的分区中。&lt;/p&gt;

&lt;p&gt;下面介绍使用TotalOrderPartitioner类实现全局排序的功能。代码如下：&lt;/p&gt;
&lt;p&gt; Map类:&lt;/p&gt;
&lt;div readability=&quot;11.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; TotalSortMap &lt;span&gt;extends&lt;/span&gt; Mapper&amp;lt;Text, Text, Text, IntWritable&amp;gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;    @Override
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;     &lt;span&gt;protected&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; map(Text key, Text value,
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;                        Context context) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; IOException, InterruptedException {
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt;         context.write(key, &lt;span&gt;new&lt;/span&gt;&lt;span&gt; IntWritable(Integer.parseInt(key.toString())));
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;7&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Reduce类:&lt;/p&gt;
&lt;div readability=&quot;22.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; TotalSortReduce &lt;span&gt;extends&lt;/span&gt; Reducer&amp;lt;Text, IntWritable, IntWritable, NullWritable&amp;gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;    @Override
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;     &lt;span&gt;protected&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; reduce(Text key, Iterable&amp;lt;IntWritable&amp;gt;&lt;span&gt; values,
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;                           Context context) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; IOException, InterruptedException {
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt;         &lt;span&gt;for&lt;/span&gt;&lt;span&gt; (IntWritable value : values)
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt; &lt;span&gt;            context.write(value, NullWritable.get());
&lt;/span&gt;&lt;span&gt;7&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;8&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;入口类：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;47&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; TotalSort &lt;span&gt;extends&lt;/span&gt; Configured &lt;span&gt;implements&lt;/span&gt;&lt;span&gt; Tool{
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; 
&lt;span&gt; 3&lt;/span&gt;     &lt;span&gt;//&lt;/span&gt;&lt;span&gt;实现一个Kye比较器，用于比较两个key的大小，将key由字符串转化为Integer，然后进行比较。&lt;/span&gt;
&lt;span&gt; 4&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; KeyComparator &lt;span&gt;extends&lt;/span&gt;&lt;span&gt; WritableComparator {
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;         &lt;span&gt;protected&lt;/span&gt;&lt;span&gt; KeyComparator() {
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;             &lt;span&gt;super&lt;/span&gt;(Text.&lt;span&gt;class&lt;/span&gt;, &lt;span&gt;true&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; 
&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;        @Override
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;         &lt;span&gt;public&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt; compare(WritableComparable writableComparable1, WritableComparable writableComparable2) {
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; num1 =&lt;span&gt; Integer.parseInt(writableComparable1.toString());
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;             &lt;span&gt;int&lt;/span&gt; num2 =&lt;span&gt; Integer.parseInt(writableComparable2.toString());
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt; 
&lt;span&gt;14&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt; num1 -&lt;span&gt; num2;
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;        }
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; &lt;span&gt;    @Override
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;int&lt;/span&gt; run(String[] args) &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; Exception {
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;         Configuration conf = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Configuration();
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt;         conf.set(&quot;mapreduce.totalorderpartitioner.naturalorder&quot;, &quot;false&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt;         Job job = Job.getInstance(conf, &quot;Total Sort app&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt;         job.setJarByClass(TotalSort.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt; 
&lt;span&gt;24&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;设置读取文件的路径，都是从HDFS中读取。读取文件路径从脚本文件中传进来&lt;/span&gt;
&lt;span&gt;25&lt;/span&gt;         FileInputFormat.addInputPath(job,&lt;span&gt;new&lt;/span&gt; Path(args[0&lt;span&gt;]));
&lt;/span&gt;&lt;span&gt;26&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;设置mapreduce程序的输出路径，MapReduce的结果都是输入到文件中&lt;/span&gt;
&lt;span&gt;27&lt;/span&gt;         FileOutputFormat.setOutputPath(job,&lt;span&gt;new&lt;/span&gt; Path(args[1&lt;span&gt;]));
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt;         job.setInputFormatClass(KeyValueTextInputFormat.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;设置比较器，用于比较数据的大小，然后按顺序排序，该例子主要用于比较两个key的大小&lt;/span&gt;
&lt;span&gt;30&lt;/span&gt;         job.setSortComparatorClass(KeyComparator.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;31&lt;/span&gt;         job.setNumReduceTasks(3);&lt;span&gt;//&lt;/span&gt;&lt;span&gt;设置reduce数量&lt;/span&gt;
&lt;span&gt;32&lt;/span&gt; 
&lt;span&gt;33&lt;/span&gt;         job.setMapOutputKeyClass(Text.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;34&lt;/span&gt;         job.setMapOutputValueClass(IntWritable.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;35&lt;/span&gt;         job.setOutputKeyClass(IntWritable.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;36&lt;/span&gt;         job.setOutputValueClass(NullWritable.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;37&lt;/span&gt; 
&lt;span&gt;38&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;设置保存partitions文件的路径&lt;/span&gt;
&lt;span&gt;39&lt;/span&gt;         TotalOrderPartitioner.setPartitionFile(job.getConfiguration(), &lt;span&gt;new&lt;/span&gt; Path(args[2&lt;span&gt;]));
&lt;/span&gt;&lt;span&gt;40&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;key值采样，0.01是采样率，&lt;/span&gt;
&lt;span&gt;41&lt;/span&gt;         InputSampler.Sampler&amp;lt;Text, Text&amp;gt; sampler = &lt;span&gt;new&lt;/span&gt; InputSampler.RandomSampler&amp;lt;&amp;gt;(0.01, 1000, 100&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;42&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;将采样数据写入到分区文件中&lt;/span&gt;
&lt;span&gt;43&lt;/span&gt; &lt;span&gt;        InputSampler.writePartitionFile(job, sampler);
&lt;/span&gt;&lt;span&gt;44&lt;/span&gt; 
&lt;span&gt;45&lt;/span&gt;         job.setMapperClass(TotalSortMap.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;46&lt;/span&gt;         job.setReducerClass(TotalSortReduce.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;47&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;设置分区类。&lt;/span&gt;
&lt;span&gt;48&lt;/span&gt;         job.setPartitionerClass(TotalOrderPartitioner.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;49&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt; job.waitForCompletion(&lt;span&gt;true&lt;/span&gt;) ? 0 : 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;50&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;51&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; main(String[] args)&lt;span&gt;throws&lt;/span&gt;&lt;span&gt; Exception{
&lt;/span&gt;&lt;span&gt;52&lt;/span&gt; 
&lt;span&gt;53&lt;/span&gt;         &lt;span&gt;int&lt;/span&gt; exitCode = ToolRunner.run(&lt;span&gt;new&lt;/span&gt;&lt;span&gt; TotalSort(), args);
&lt;/span&gt;&lt;span&gt;54&lt;/span&gt; &lt;span&gt;        System.exit(exitCode);
&lt;/span&gt;&lt;span&gt;55&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;56&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;生成测试数据的代码如下：&lt;/p&gt;
&lt;div readability=&quot;10&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; #!/bin/&lt;span&gt;bash
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;do&lt;/span&gt;
&lt;span&gt;3&lt;/span&gt; &lt;span&gt;for&lt;/span&gt; k &lt;span&gt;in&lt;/span&gt; $(&lt;span&gt;seq&lt;/span&gt; &lt;span&gt;1&lt;/span&gt; &lt;span&gt;10000&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; &lt;span&gt;echo&lt;/span&gt;&lt;span&gt; $RANDOM;
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; &lt;span&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;将上面代码保存成create_data.sh，然后执行&lt;/p&gt;
&lt;div readability=&quot;12&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;sh&lt;/span&gt; create_data.&lt;span&gt;sh&lt;/span&gt; &amp;gt; test_data.txt
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;会生成一个test_data.txt的文本文件，文本中的内容是一行一个随机数字&lt;/p&gt;
&lt;p&gt;将test_data.txt上传到HDFS中：&lt;/p&gt;
&lt;div readability=&quot;12.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
hadoop fs -put test_data.txt /data/
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;将上面的实现全局排序的代码打成一个jar包，然后通过shell文件执行。&lt;/p&gt;
&lt;p&gt;执行MapReduce代码的脚本如下：&lt;/p&gt;
&lt;div readability=&quot;12&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; /usr/local/src/hadoop-&lt;span&gt;2.6&lt;/span&gt;.&lt;span&gt;1&lt;/span&gt;/bin/&lt;span&gt;hadoop jar TotalSort.jar \
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; hdfs:&lt;span&gt;//&lt;/span&gt;&lt;span&gt;hadoop-master:8020/data/test_data1.txt \&lt;/span&gt;
&lt;span&gt;3&lt;/span&gt; hdfs:&lt;span&gt;//&lt;/span&gt;&lt;span&gt;hadoop-master:8020/total_sort_output \&lt;/span&gt;
&lt;span&gt;4&lt;/span&gt; hdfs:&lt;span&gt;//&lt;/span&gt;&lt;span&gt;hadoop-master:8020/total_sort_partitions&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;看下运行结果，我们只需要看part-r-00000的尾10行和part-r-00001的头10行数据，只要它们收尾相接就证明是全局有序的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/110616/201809/110616-20180905224426046-373314217.png&quot; alt=&quot;&quot; width=&quot;647&quot; height=&quot;300&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面有几个坑要注意，大家不要踩：&lt;/p&gt;
&lt;div&gt;
&lt;ol readability=&quot;8&quot;&gt;&lt;li readability=&quot;-2&quot;&gt;数据的输入类型必须使用KeyValueTextInputFormat类而不是TextInputFormat类，因为hadoop采样器是对key值采样，而TextInputFormat的key是位置偏移量，value存放的是每行的输入数据，对该key采样没有任何意义。KeyValueTextInputFormat的key存放的是输入数据，对key采样才能更好的划分分区。用法：
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
job.setInputFormatClass(KeyValueTextInputFormat.&lt;span&gt;class&lt;/span&gt;);
&lt;/pre&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;使用代码conf.set(&quot;mapreduce.totalorderpartitioner.naturalorder&quot;, &quot;false&quot;)设置分区的排序策略，否则是每个分区内有序，而不是全局有序。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;采样器只能是Text,Text类型：InputSampler.Sampler&amp;lt;Text, Text&amp;gt;，否则会报&lt;span&gt;Exception in thread &quot;main&quot; java.io.IOException: wrong key class: org.apache.hadoop.io.Text is not class org.apache.hadoop.io.LongWritable&lt;/span&gt;这个错误。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;job.setMapOutputKeyClass(Text.class)和job.setMapOutputValueClass(IntWritable.class)这两行代码必须在InputSampler.Sampler&amp;lt;Text, Text&amp;gt; sampler = new InputSampler.RandomSampler&amp;lt;&amp;gt;(0.01, 1000, 100);这行代码之前调用，否则会报&lt;span&gt;Exception in thread &quot;main&quot; java.io.IOException: wrong key class: org.apache.hadoop.io.Text is not class org.apache.hadoop.io.LongWritable&lt;/span&gt;错误。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;调用setSortComparatorClass方法设置排序类，对key进行排序。job.setSortComparatorClass(KeyComparator.class);类似例子中的KeyComparator类。否则是按照字典序进行排序。MapReduce默认输出的key是字符类型时，默认是按照字典序排序。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;


&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;

</description>
<pubDate>Wed, 05 Sep 2018 14:52:00 +0000</pubDate>
<dc:creator>summer哥</dc:creator>
<og:description>Hadoop排序，从大的范围来说有两种排序，一种是按照key排序，一种是按照value排序。如果按照value排序，只需在map函数中将key和value对调，然后在reduce函数中在对调回去。从小</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/airnew/p/9595385.html</dc:identifier>
</item>
<item>
<title>跟厂长学PHP7内核（五）：系统分析生命周期 - 了不起的厂长</title>
<link>http://www.cnblogs.com/enochzzg/p/9595417.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/enochzzg/p/9595417.html</guid>
<description>&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;上篇文章讲述了模块初始化阶段之前的准备工作，本篇我来详细介绍PHP生命周期的五个阶段。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我们先来看一下该阶段的每个函数的作用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://p13vfrwta.bkt.clouddn.com/%E6%A8%A1%E5%9D%97%E5%88%9D%E5%A7%8B%E5%8C%96%E9%98%B6%E6%AE%B5.png&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;sapi_initialize_request_empty函数&quot;&gt;1.1、sapi_initialize_request_empty函数&lt;/h2&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;// main/SAPI.c
SAPI_API void sapi_initialize_empty_request(void)
{
    SG(server_context) = NULL;
    SG(request_info).request_method = NULL;
    SG(request_info).auth_digest = SG(request_info).auth_user = SG(request_info).auth_password = NULL;
    SG(request_info).content_type_dup = NULL;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个函数主要为前面定义的SG宏中的成员变量进行初始化。&lt;/p&gt;
&lt;h2 id=&quot;sapi_activate函数&quot;&gt;1.2、sapi_activate函数&lt;/h2&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;// main/SAPI.c
SAPI_API void sapi_activate(void)
{
    zend_llist_init(&amp;amp;SG(sapi_headers).headers, sizeof(sapi_header_struct), (void (*)(void *)) sapi_free_header, 0);
    SG(sapi_headers).send_default_content_type = 1;
    SG(sapi_headers).http_status_line = NULL;
    SG(sapi_headers).mimetype = NULL;
    SG(headers_sent) = 0;
    ......
    /* Handle request method */
    if (SG(server_context)) {
        ......

        if (sapi_module.activate) {
            sapi_module.activate();
        }
    }
    if (sapi_module.input_filter_init) {
        sapi_module.input_filter_init();
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;函数的前半部分主要还是对SG宏的成员变量进行初始化。后半部分先是调用了&lt;code&gt;sapi_module_struct&lt;/code&gt;内部实现的&lt;code&gt;activate&lt;/code&gt;函数，又调用了&lt;code&gt;input_filter_init&lt;/code&gt;函数，但是在CLI模式并没有实现这两个函数，只是返回了NULL。代码如下：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;NULL,                           /* activate */&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;php_output_startup函数&quot;&gt;1.3、php_output_startup函数&lt;/h2&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//main/output.c
PHPAPI void php_output_startup(void)
{
    ZEND_INIT_MODULE_GLOBALS(output, php_output_init_globals, NULL);
    zend_hash_init(&amp;amp;php_output_handler_aliases, 8, NULL, NULL, 1);
    zend_hash_init(&amp;amp;php_output_handler_conflicts, 8, NULL, NULL, 1);
    zend_hash_init(&amp;amp;php_output_handler_reverse_conflicts, 8, NULL, reverse_conflict_dtor, 1);
    php_output_direct = php_output_stdout;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们先来看&lt;code&gt;ZEND_INIT_MODULE_GLOBALS&lt;/code&gt;宏做了什么事情：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;#define ZEND_INIT_MODULE_GLOBALS(module_name, globals_ctor, globals_dtor)   \
    globals_ctor(&amp;amp;module_name##_globals);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;由代码得知，该宏只是做了一层替换，替换后的内容为：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;php_output_init_globals(&amp;amp;output_globals);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;那&lt;code&gt;php_output_init_globals&lt;/code&gt;函数又做了什么呢？&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//main/output.c
static inline void php_output_init_globals(zend_output_globals *G)
{
    ZEND_TSRMLS_CACHE_UPDATE();
    memset(G, 0, sizeof(*G));
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;该函数通过&lt;code&gt;memset&lt;/code&gt;函数对&lt;code&gt;output_globals&lt;/code&gt;进行了内存相关的初始化，我们可以在&lt;code&gt;main/php_output.h&lt;/code&gt;中的155行找到它的宏定义OG。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//main/php_output.h
# define OG(v) (output_globals.v)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;OG对应的结构体是&lt;code&gt;php_output_init_globals&lt;/code&gt;的入参&lt;code&gt;zend_output_globals&lt;/code&gt;，在这里花了些时间，因为没找到定义在哪里，最后发现它也是通过宏定义替换得来的，代码如下：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//main/php_output.h
ZEND_BEGIN_MODULE_GLOBALS(output)
    zend_stack handlers;
    php_output_handler *active;
    php_output_handler *running;
    const char *output_start_filename;
    int output_start_lineno;
    int flags;
ZEND_END_MODULE_GLOBALS(output)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;看似是定义了一个结构体，但是代码中又出现了两个宏，我们再来瞅瞅这两个宏是干嘛的：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//Zend/zend_API.h
#define ZEND_BEGIN_MODULE_GLOBALS(module_name)      \
    typedef struct _zend_##module_name##_globals {
#define ZEND_END_MODULE_GLOBALS(module_name)        \
    } zend_##module_name##_globals;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;原来只是做了个替换而已，替换后的代码如下：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//这个是意淫出来的代码
typedef struct _zend_output_globals {
    zend_stack handlers;
    php_output_handler *active;
    php_output_handler *running;
    const char *output_start_filename;
    int output_start_lineno;
    int flags;
} zend_output_globals&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这才是&lt;code&gt;zend_output_globals&lt;/code&gt;最纯粹的定义，写的很是骚气，差点看断片。这样看来我们的OG宏对应的就是这个结构体了，姑且认为它是PHP输出相关的结构体。我们继续往下看：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;zend_hash_init(&amp;amp;php_output_handler_aliases, 8, NULL, NULL, 1);
zend_hash_init(&amp;amp;php_output_handler_conflicts, 8, NULL, NULL, 1);
zend_hash_init(&amp;amp;php_output_handler_reverse_conflicts, 8, NULL, reverse_conflict_dtor, 1);
php_output_direct = php_output_stdout;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来又对三个HashTable进行了初始化，初始化完成后，将&lt;code&gt;php_output_direct&lt;/code&gt;指针指向了&lt;code&gt;php_output_stdout&lt;/code&gt;函数。&lt;code&gt;php_output_stdout&lt;/code&gt;函数的作用是调用fwrite函数，输出字符串到stdout中。代码如下：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//main/output.c
static size_t php_output_stdout(const char *str, size_t str_len)
{
    fwrite(str, 1, str_len, stdout);
    return str_len;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;php_startup_ticks函数&quot;&gt;1.4、php_startup_ticks函数&lt;/h2&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;int php_startup_ticks(void)
{
    zend_llist_init(&amp;amp;PG(tick_functions), sizeof(struct st_tick_function), NULL, 1);
    return SUCCESS;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里又出现了一个PG宏，来看下它的定义&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;# define PG(v) (core_globals.v)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;PG对应的结构体是&lt;code&gt;core_globals&lt;/code&gt;，&lt;code&gt;core_globals&lt;/code&gt;又对应&lt;code&gt;_php_core_globals&lt;/code&gt;，代码如下&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;extern ZEND_API struct _php_core_globals core_globals;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;php_core_globals顾名思义，就是php核心的全局变量，定义很多PHP相关的参数，比如内存上限、是否显示错误信息、上传文件大小限制、输入输出编码、禁用的函数等等，这里不再赘述，感兴趣的同学可以去看一下源码。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//main/php_globals.h
struct _php_core_globals {
    zend_bool implicit_flush;

    zend_long output_buffering;

    zend_bool sql_safe_mode;
    zend_bool enable_dl;
    ......
};&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;而&lt;code&gt;php_startup_ticks&lt;/code&gt;函数就是对PG宏的成员变量&lt;code&gt;tick_functions&lt;/code&gt;进行初始化。&lt;/p&gt;
&lt;h2 id=&quot;gc_globals_ctor函数&quot;&gt;1.5、gc_globals_ctor函数&lt;/h2&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;ZEND_API void gc_globals_ctor(void)
{
    gc_globals_ctor_ex(&amp;amp;gc_globals);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里又出现了一个&lt;code&gt;gc_globals&lt;/code&gt;，它是与垃圾回收相关的结构体，这段代码是对&lt;code&gt;gc_globals&lt;/code&gt;进行初始化。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//Zend/zend_gc.c
typedef struct _zend_gc_globals {
    zend_bool         gc_enabled;
    zend_bool         gc_active;
    zend_bool         gc_full;

    gc_root_buffer   *buf;              /* preallocated arrays of buffers   */
    ......

} zend_gc_globals;&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;zend_startup函数&quot;&gt;1.6、zend_startup函数&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;++start_memory_manager++&lt;/strong&gt;：初始化内存管理器，对结构体&lt;code&gt;alloc_globals&lt;/code&gt;进行初始化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;++virtual_cwd_startup++&lt;/strong&gt;：virtual_cwd_startup初始化了cwd_globals，根据源码可以看出成员变量都与realpath_cache有关，realpath_cache是什么呢？我们平时在写代码的时候，经常会使用include、include_once、require、require_once等语句导入文件，如果每次使用这些语句都要去对应的目录中寻找目标文件，势必会降低性能，所以官方加入了缓存，以便PHP再次使用时不必到include_path中查找，加快PHP的执行速度。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//Zend/zend_virtual_cwd.c
typedef struct _virtual_cwd_globals {
    cwd_state cwd;
    zend_long                   realpath_cache_size;
    zend_long                   realpath_cache_size_limit;
    zend_long                   realpath_cache_ttl;
    realpath_cache_bucket *realpath_cache[1024];
} virtual_cwd_globals;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;++&lt;strong&gt;zend_startup_extensions_mechanism&lt;/strong&gt;++。启动扩展机制，初始化&lt;code&gt;zend_extensions&lt;/code&gt;结构体。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;int zend_startup_extensions_mechanism()
{
    /* Startup extensions mechanism */
    zend_llist_init(&amp;amp;zend_extensions, sizeof(zend_extension), (void (*)(void *)) zend_extension_dtor, 1);
    last_resource_number = 0;
    return SUCCESS;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;++提供编译与执行入口++&lt;/strong&gt;。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;zend_compile_file = compile_file;
zend_execute_ex = execute_ex;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;++zend_init_opcodes_handlers++&lt;/strong&gt;。初始化Zend虚拟机的handler&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;++初始化CG、EG++&lt;/strong&gt;。初始化CG(function_table)、CG(class_table)、CG(auto_globals)、EG(zend_constants)。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;GLOBAL_FUNCTION_TABLE = (HashTable *) malloc(sizeof(HashTable));
GLOBAL_CLASS_TABLE = (HashTable *) malloc(sizeof(HashTable));
GLOBAL_AUTO_GLOBALS_TABLE = (HashTable *) malloc(sizeof(HashTable));
GLOBAL_CONSTANTS_TABLE = (HashTable *) malloc(sizeof(HashTable));&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;++&lt;strong&gt;ini_scanner_globals_ctor&lt;/strong&gt;++。初始化&lt;code&gt;ini_scanner_globals&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;++&lt;strong&gt;php_scanner_globals_ctor&lt;/strong&gt;++。初始化&lt;code&gt;language_scanner_globals&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;++zend_set_default_compile_time_values++&lt;/strong&gt;。设置了编译相关的配置。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//Zend/zend.c
static void zend_set_default_compile_time_values(void) /* {{{ */
{
    /* default compile-time values */
    CG(short_tags) = short_tags_default;
    CG(compiler_options) = compiler_options_default;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;++&lt;strong&gt;EG(error_reporting)&lt;/strong&gt;++。EG宏就是&lt;code&gt;executor_globals&lt;/code&gt;，Zend执行器相关的全局变量，在这里对我们熟知的&lt;code&gt;error_reporting&lt;/code&gt;进行配置。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//Zend/zend_globals.h
struct _zend_executor_globals {
    zval uninitialized_zval;
    zval error_zval;

    /* symbol table cache */
    zend_array *symtable_cache[SYMTABLE_CACHE_SIZE];
    zend_array **symtable_cache_limit;
    zend_array **symtable_cache_ptr;
    ......
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;++zend_interned_strings_init++&lt;/strong&gt;。初始化内部字符串。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//Zend/zend_string.c
void zend_interned_strings_init(void)
{
#ifndef ZTS
    zend_string *str;

    zend_hash_init(&amp;amp;CG(interned_strings), 1024, NULL, _str_dtor, 1);
    ......
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;++zend_startup_builtin_functions++&lt;/strong&gt;。初始化内部函数。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//Zend/zend_builtin_functions.c
int zend_startup_builtin_functions(void) /* {{{ */
{
    zend_builtin_module.module_number = 0;
    zend_builtin_module.type = MODULE_PERSISTENT;
    return (EG(current_module) = zend_register_module_ex(&amp;amp;zend_builtin_module)) == NULL ? FAILURE : SUCCESS;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;++zend_register_standard_constants++&lt;/strong&gt;。注册常量，比如E_ERROR、E_WARNING、E_NOTICE、E_CORE_ERROR等。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//Zend/zend_constants.c
void zend_register_standard_constants(void)
{
    REGISTER_MAIN_LONG_CONSTANT(&quot;E_ERROR&quot;, E_ERROR, CONST_PERSISTENT | CONST_CS);
    REGISTER_MAIN_LONG_CONSTANT(&quot;E_RECOVERABLE_ERROR&quot;, E_RECOVERABLE_ERROR, CONST_PERSISTENT | CONST_CS);
    REGISTER_MAIN_LONG_CONSTANT(&quot;E_WARNING&quot;, E_WARNING, CONST_PERSISTENT | CONST_CS);
    ......
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;++zend_register_auto_global++&lt;/strong&gt;。将GLOBALS加入CG(auto_globals)。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//Zend/zend.c
zend_register_auto_global(zend_string_init(&quot;GLOBALS&quot;, sizeof(&quot;GLOBALS&quot;) - 1, 1), 1, php_auto_globals_create_globals);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;++zend_init_rsrc_plist++&lt;/strong&gt;。初始化持久化符号表。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;int zend_init_rsrc_plist(void)
{
    zend_hash_init_ex(&amp;amp;EG(persistent_list), 8, NULL, plist_entry_destructor, 1, 0);
    return SUCCESS;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;++zend_init_exception_op++&lt;/strong&gt;。初始化EG(exception_op)。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;++zend_init_call_trampoline_op++&lt;/strong&gt;。初始化EG(call_trampoline_op)。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;++zend_ini_startup++&lt;/strong&gt;。初始化与php.ini解析相关的变量。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//Zend/zend_ini.c
ZEND_API int zend_ini_startup(void) /* {{{ */
{
    registered_zend_ini_directives = (HashTable *) malloc(sizeof(HashTable));

    EG(ini_directives) = registered_zend_ini_directives;
    EG(modified_ini_directives) = NULL;
    EG(error_reporting_ini_entry) = NULL;
    zend_hash_init_ex(registered_zend_ini_directives, 128, NULL, free_ini_entry, 1, 0);
    return SUCCESS;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;zend_register_list_destructors_ex函数&quot;&gt;1.7、zend_register_list_destructors_ex函数&lt;/h2&gt;
&lt;p&gt;初始化析构函数&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//Zend/zend_list.c
ZEND_API int zend_register_list_destructors_ex(rsrc_dtor_func_t ld, rsrc_dtor_func_t pld, const char *type_name, int module_number)
{
    zend_rsrc_list_dtors_entry *lde;
    zval zv;

    lde = malloc(sizeof(zend_rsrc_list_dtors_entry));
    lde-&amp;gt;list_dtor_ex = ld;
    lde-&amp;gt;plist_dtor_ex = pld;
    lde-&amp;gt;module_number = module_number;
    lde-&amp;gt;resource_id = list_destructors.nNextFreeElement;
    lde-&amp;gt;type_name = type_name;
    ZVAL_PTR(&amp;amp;zv, lde);

    if (zend_hash_next_index_insert(&amp;amp;list_destructors, &amp;amp;zv) == NULL) {
        return FAILURE;
    }
    return list_destructors.nNextFreeElement-1;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;php_binary_init函数&quot;&gt;1.8、php_binary_init函数&lt;/h2&gt;
&lt;p&gt;获取PHP执行的二进制路径&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;static void php_binary_init(void)
{
    char *binary_location;
#ifdef PHP_WIN32
    binary_location = (char *)malloc(MAXPATHLEN);
    if (GetModuleFileName(0, binary_location, MAXPATHLEN) == 0) {
        free(binary_location);
        PG(php_binary) = NULL;
    }
#else
    if (sapi_module.executable_location) {
        binary_location = (char *)malloc(MAXPATHLEN);
        if (!strchr(sapi_module.executable_location, '/')) {
            char *envpath, *path;
            int found = 0;
            ......
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;php_output_register_constants函数&quot;&gt;1.9、php_output_register_constants函数&lt;/h2&gt;
&lt;p&gt;初始化输出相关的预定义常量&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//main/output.c
PHPAPI void php_output_register_constants(void)
{
    REGISTER_MAIN_LONG_CONSTANT(&quot;PHP_OUTPUT_HANDLER_START&quot;, PHP_OUTPUT_HANDLER_START, CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;PHP_OUTPUT_HANDLER_WRITE&quot;, PHP_OUTPUT_HANDLER_WRITE, CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;PHP_OUTPUT_HANDLER_FLUSH&quot;, PHP_OUTPUT_HANDLER_FLUSH, CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;PHP_OUTPUT_HANDLER_CLEAN&quot;, PHP_OUTPUT_HANDLER_CLEAN, CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;PHP_OUTPUT_HANDLER_FINAL&quot;, PHP_OUTPUT_HANDLER_FINAL, CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;PHP_OUTPUT_HANDLER_CONT&quot;, PHP_OUTPUT_HANDLER_WRITE, CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;PHP_OUTPUT_HANDLER_END&quot;, PHP_OUTPUT_HANDLER_FINAL, CONST_CS | CONST_PERSISTENT);

    REGISTER_MAIN_LONG_CONSTANT(&quot;PHP_OUTPUT_HANDLER_CLEANABLE&quot;, PHP_OUTPUT_HANDLER_CLEANABLE, CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;PHP_OUTPUT_HANDLER_FLUSHABLE&quot;, PHP_OUTPUT_HANDLER_FLUSHABLE, CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;PHP_OUTPUT_HANDLER_REMOVABLE&quot;, PHP_OUTPUT_HANDLER_REMOVABLE, CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;PHP_OUTPUT_HANDLER_STDFLAGS&quot;, PHP_OUTPUT_HANDLER_STDFLAGS, CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;PHP_OUTPUT_HANDLER_STARTED&quot;, PHP_OUTPUT_HANDLER_STARTED, CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;PHP_OUTPUT_HANDLER_DISABLED&quot;, PHP_OUTPUT_HANDLER_DISABLED, CONST_CS | CONST_PERSISTENT);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;php_rfc1867_register_constants函数&quot;&gt;1.10、php_rfc1867_register_constants函数&lt;/h2&gt;
&lt;p&gt;注册文件上传相关的预定义常量&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//main/rfc1867.c
void php_rfc1867_register_constants(void) /* {{{ */
{
    REGISTER_MAIN_LONG_CONSTANT(&quot;UPLOAD_ERR_OK&quot;,         UPLOAD_ERROR_OK, CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;UPLOAD_ERR_INI_SIZE&quot;,   UPLOAD_ERROR_A,  CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;UPLOAD_ERR_FORM_SIZE&quot;,  UPLOAD_ERROR_B,  CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;UPLOAD_ERR_PARTIAL&quot;,    UPLOAD_ERROR_C,  CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;UPLOAD_ERR_NO_FILE&quot;,    UPLOAD_ERROR_D,  CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;UPLOAD_ERR_NO_TMP_DIR&quot;, UPLOAD_ERROR_E,  CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;UPLOAD_ERR_CANT_WRITE&quot;, UPLOAD_ERROR_F,  CONST_CS | CONST_PERSISTENT);
    REGISTER_MAIN_LONG_CONSTANT(&quot;UPLOAD_ERR_EXTENSION&quot;,  UPLOAD_ERROR_X,  CONST_CS | CONST_PERSISTENT);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;php_init_config函数&quot;&gt;1.11、php_init_config函数&lt;/h2&gt;
&lt;p&gt;初始化配置文件php.ini，并通过&lt;code&gt;zend_parse_ini_file&lt;/code&gt;解析。&lt;/p&gt;
&lt;h2 id=&quot;zend_register_standard_ini_entries函数&quot;&gt;1.12、zend_register_standard_ini_entries函数&lt;/h2&gt;
&lt;p&gt;初始化ini相关的变量&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;void zend_register_standard_ini_entries(void) /* {{{ */
{
    int module_number = 0;

    REGISTER_INI_ENTRIES();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;php_startup_auto_globals函数&quot;&gt;1.13、php_startup_auto_globals函数&lt;/h2&gt;
&lt;p&gt;注册我们熟知的全局变量$_GET、$_POST、$_COOKIE等等&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//main/php_variables.c
void php_startup_auto_globals(void)
{
    zend_register_auto_global(zend_string_init(&quot;_GET&quot;, sizeof(&quot;_GET&quot;)-1, 1), 0, php_auto_globals_create_get);
    zend_register_auto_global(zend_string_init(&quot;_POST&quot;, sizeof(&quot;_POST&quot;)-1, 1), 0, php_auto_globals_create_post);
    zend_register_auto_global(zend_string_init(&quot;_COOKIE&quot;, sizeof(&quot;_COOKIE&quot;)-1, 1), 0, php_auto_globals_create_cookie);
    zend_register_auto_global(zend_string_init(&quot;_SERVER&quot;, sizeof(&quot;_SERVER&quot;)-1, 1), PG(auto_globals_jit), php_auto_globals_create_server);
    zend_register_auto_global(zend_string_init(&quot;_ENV&quot;, sizeof(&quot;_ENV&quot;)-1, 1), PG(auto_globals_jit), php_auto_globals_create_env);
    zend_register_auto_global(zend_string_init(&quot;_REQUEST&quot;, sizeof(&quot;_REQUEST&quot;)-1, 1), PG(auto_globals_jit), php_auto_globals_create_request);
    zend_register_auto_global(zend_string_init(&quot;_FILES&quot;, sizeof(&quot;_FILES&quot;)-1, 1), 0, php_auto_globals_create_files);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;php_startup_sapi_content_types函数&quot;&gt;1.14、php_startup_sapi_content_types函数&lt;/h2&gt;
&lt;p&gt;初始化针对不同内容类型的处理函数&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//main/php_content_types.c
int php_startup_sapi_content_types(void)
{
    sapi_register_default_post_reader(php_default_post_reader);
    sapi_register_treat_data(php_default_treat_data);
    sapi_register_input_filter(php_default_input_filter, NULL);
    return SUCCESS;
}&lt;/code&gt;
&lt;/pre&gt;

&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;4&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;php_output_activate()&lt;/td&gt;
&lt;td&gt;重置输出全局变量，初始化输出相关堆栈&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;zend_activate()&lt;/td&gt;
&lt;td&gt;初始化Zend引擎&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;sapi_activate()&lt;/td&gt;
&lt;td&gt;初始化SG宏，调各sapi钩子函数activate&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;zend_signal_activate()&lt;/td&gt;
&lt;td&gt;信号处理&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;zend_set_timeout()&lt;/td&gt;
&lt;td&gt;设置超时时间&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;php_hash_environment()&lt;/td&gt;
&lt;td&gt;初始化PHP请求的全局变量&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;zend_activate_modules()&lt;/td&gt;
&lt;td&gt;调用各扩展定义的request_startup钩子函数&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;php_output_activate&quot;&gt;2.1、php_output_activate&lt;/h2&gt;
&lt;p&gt;重新为output_globals分配内存，初始化与输出处理程序相关的堆栈，并将OG宏的flags设置为激活状态。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//main/output.c
PHPAPI int php_output_activate(void)
{
#ifdef ZTS
    memset((*((void ***) ZEND_TSRMLS_CACHE))[TSRM_UNSHUFFLE_RSRC_ID(output_globals_id)], 0, sizeof(zend_output_globals));
#else
    memset(&amp;amp;output_globals, 0, sizeof(zend_output_globals));
#endif

    zend_stack_init(&amp;amp;OG(handlers), sizeof(php_output_handler *));
    OG(flags) |= PHP_OUTPUT_ACTIVATED;

    return SUCCESS;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;zend_activate&quot;&gt;2.2、zend_activate&lt;/h2&gt;
&lt;p&gt;zend引擎的初始化，主要作用为重置垃圾回收、初始化编译器、初始化执行器、初始化扫描器。&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;gc_reset()&lt;/td&gt;
&lt;td&gt;重置垃圾回收&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;init_compiler()&lt;/td&gt;
&lt;td&gt;初始化编译器&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;init_executor()&lt;/td&gt;
&lt;td&gt;初始化执行器&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;startup_scanner()&lt;/td&gt;
&lt;td&gt;初始化扫描器&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h2 id=&quot;sapi_activate&quot;&gt;2.3、sapi_activate&lt;/h2&gt;
&lt;p&gt;对SG宏内的一些变量进行初始化，并调用当前sapi_module_struct中定义的钩子函数activate()以及input_filter_init()，但是在cli模式下，这两个钩子函数都没有实现，返回了null。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//main/SAPI.c
SAPI_API void sapi_activate(void)
{
    zend_llist_init(&amp;amp;SG(sapi_headers).headers, sizeof(sapi_header_struct), (void (*)(void *)) sapi_free_header, 0);
    SG(sapi_headers).send_default_content_type = 1;

    /*
    SG(sapi_headers).http_response_code = 200;
    */
    SG(sapi_headers).http_status_line = NULL;
    SG(sapi_headers).mimetype = NULL;
    SG(headers_sent) = 0;
    ZVAL_UNDEF(&amp;amp;SG(callback_func));
    SG(read_post_bytes) = 0;
    SG(request_info).request_body = NULL;
    ......
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;php_hash_environment&quot;&gt;2.4、php_hash_environment&lt;/h2&gt;
&lt;p&gt;为http_globals分配内存，初始化auto_globals，解析请求参数并存放到全局变量中。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;PHPAPI int php_hash_environment(void)
{
    memset(PG(http_globals), 0, sizeof(PG(http_globals)));
    zend_activate_auto_globals();
    if (PG(register_argc_argv)) {
        php_build_argv(SG(request_info).query_string, &amp;amp;PG(http_globals)[TRACK_VARS_SERVER]);
    }
    return SUCCESS;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;zend_activate_modules&quot;&gt;2.5、zend_activate_modules&lt;/h2&gt;
&lt;p&gt;该函数通过遍历注册在module_registry的所有模块，调用每个模块的钩子函数request_startup()进行初始化。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;ZEND_API void zend_activate_modules(void) /* {{{ */
{
    zend_module_entry **p = module_request_startup_handlers;

    while (*p) {
        zend_module_entry *module = *p;

        if (module-&amp;gt;request_startup_func(module-&amp;gt;type, module-&amp;gt;module_number)==FAILURE) {
            zend_error(E_WARNING, &quot;request_startup() for %s module failed&quot;, module-&amp;gt;name);
            exit(1);
        }
        p++;
    }
}&lt;/code&gt;
&lt;/pre&gt;

&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;2&quot;&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;compile_file()&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;open_file_for_scanning()&lt;/td&gt;
&lt;td&gt;读取PHP代码内容&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;zend_parse()&lt;/td&gt;
&lt;td&gt;词法语法分析生成AST&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;init_op_array()&lt;/td&gt;
&lt;td&gt;初始化op_array&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;zend_compile_top_stmt()&lt;/td&gt;
&lt;td&gt;将AST转换为op_array&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;pass_two()&lt;/td&gt;
&lt;td&gt;设置op_array中对应zend虚拟机的handler&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;zend_execute()&lt;/td&gt;
&lt;td&gt;执行op_array&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;执行阶段的入口是php_execute_script函数，该函数又调用了zend_execute_scripts函数，看了这段代码的同学可能会找不到上图表中所提到的compile_file()函数，其实它在模块初始化阶段就已经将compile_file赋值给了zend_compile_file。&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;//Zend/zend.c
zend_compile_file = compile_file;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行阶段调用示意图：&lt;br/&gt;&lt;img src=&quot;http://p13vfrwta.bkt.clouddn.com/php_execute_script.png&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;

&lt;p&gt;请求关闭阶段主要内容是调用各模块的关闭函数和析构函数、输出缓冲区内容、调用各扩展的钩子函数RSHUTDOWN、关闭编译器和执行器以及还原PHP配置等。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://p13vfrwta.bkt.clouddn.com/%E8%AF%B7%E6%B1%82%E5%85%B3%E9%97%AD%E9%98%B6%E6%AE%B5.png&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;

&lt;p&gt;虽然请求关闭和模块关闭看起来是两个截然不同的阶段，但阅读完源码后发现并看不出两个阶段的区别。它的主要作用是调用模块的flush函数、清理符号表、销毁全局变量、关闭内存管理和垃圾回收、关闭输出等。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://p13vfrwta.bkt.clouddn.com/php_module_shutdown.png&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 05 Sep 2018 14:51:00 +0000</pubDate>
<dc:creator>了不起的厂长</dc:creator>
<og:description>上篇文章讲述了模块初始化阶段之前的准备工作，本篇我来详细介绍PHP生命周期的五个阶段。 一、模块初始化阶段 我们先来看一下该阶段的每个函数的作用。 1.1、sapi_initialize_reques</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/enochzzg/p/9595417.html</dc:identifier>
</item>
<item>
<title>网络安全day04_VLSM、子网划分 - 老夏家的云</title>
<link>http://www.cnblogs.com/laoxiajiadeyun/p/9595394.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/laoxiajiadeyun/p/9595394.html</guid>
<description>&lt;hr/&gt;&lt;p&gt;首先，在进行子网划分的学习之前，我们先来回顾一下IP地址的相关知识，同时了解一下公有和私有IP地址：&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;在Internet上有千百万台主机，为了区分这些主机，人们给每台主机都分配了一个专门的地址，称为IP地址。Internet IP地址由NIC（Internet Network Information Center）统一负责全球地址的规划、管理；同时由Inter NIC、APNIC、RIPE三大网络信息中心具体负责美国及其它地区的IP地址分配。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在现在的网络中，IP地址分为公网IP地址和私有IP地址。公网IP是在Internet使用的IP地址，而私有IP地址则是在局域网中使用的IP地址。&lt;br/&gt;上一篇博客中我们介绍到了A、B、C、D、E五类IP地址，其中D、E类有特殊用途，所以实际我们可用的IP地址就为A、B、C三类地址，其中公有地址（Public address）由Inter NIC（Internet Network Information Center 因特网信息中心）负责。这些IP地址分配给注册并向Inter NIC提出申请的组织机构。通过它直接访问因特网。&lt;br/&gt;私有地址（Private address）属于非注册地址，专门为组织机构内部使用。&lt;br/&gt;以下列出留用的内部私有地址&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;A类：10.0.0.0--10.255.255.255
B类：172.16.0.0--172.31.255.255
C类：192.168.0.0--192.168.255.255&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;除去这些地址以外，其他的即为公有IP，所以共有IP的地址范围为：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;A类：0.0.0.1-- 9.255.255.255 &amp;amp; 11.0.0.0--126.255.255.255
B类：128.0.0.0--172.15.255.255 &amp;amp; 172.32.0.0--191.255.255.255
C类：192.0.0.0-- 192.167.255.255 &amp;amp;192.169.0.0--223.169.255.255&lt;/code&gt;
&lt;/pre&gt;
&lt;hr/&gt;&lt;h2 id=&quot;子网划分的原因&quot;&gt;子网划分的原因&lt;/h2&gt;
&lt;hr/&gt;&lt;p&gt;今天讨论的子网划分技术是在ipv4协议的基础上实施的。&lt;br/&gt;首先看一看百度对ipv4的定义：&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;IPv4，是互联网协议（Internet Protocol，IP）的第四版，也是第一个被广泛使用，构成现今互联网技术的基础的协议。1981年 Jon Postel 在RFC791中定义了IP，Ipv4可以运行在各种各样的底层网络上，比如端对端的串行数据链路(PPP协议和SLIP协议) ，卫星链路等等。局域网中最常用的是以太网。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ipv4提出来时才1981年，当时互联网并不普及，人们对于互联网的需求极小，然而随着时代的发展，互联网上网民数量的不断增加，人们对网络的需求量日趋庞大，原有的IPv4地址逐渐开始不够用了。&lt;/p&gt;
&lt;p&gt;在互联网中，我们用交换机可以组成一个局域网，一个局域网即可单独成为一个网段，两个局域网之间通信就需要使用路由器相连，路由器的功能便是用来连接不同网段设备进行通。&lt;/p&gt;
&lt;p&gt;而世界上那么多的路由器，若是全部都连在一起，现有的ipv4网段是绝对不够用的。而全世界的互联网上只能出现公有IP，&lt;strong&gt;一个网段在公网任何地方出现过一次，在其他地方就不能再次出现&lt;/strong&gt;，一旦出现就会造成互联网的网络冲突。&lt;/p&gt;
&lt;p&gt;ABC三类地址加起来也就那么多网段，我们设想一下，假如一个公司拥有着一个A类的地址网段，例如：&lt;strong&gt;&lt;code&gt;140.0.0.0/8&lt;/code&gt;&lt;/strong&gt;，这个网段里最大可容纳主机数为2^24-2=16777214，而这个公司员工可能还不到1000人，在网络资源如此紧张的情况下，这个公司如果使用这个网段就会造成资源上的极大浪费。&lt;br/&gt;所以在这样的情况下，我们就需要应用子网划分的技术对这种情况进行资源的充分利用。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;总结一下子网划分的原因：&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt;满足不同网络对IP地址的需求&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;实现网络的层次性&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;节省IP地址&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;子网划分的原理&quot;&gt;子网划分的原理&lt;/h2&gt;
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;实际就是通过改变子网掩码对IP地址进行网段的重新划分&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;vlsm-可变长子网掩码&quot;&gt;VLSM 可变长子网掩码&lt;/h3&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;VLSM(Variable Length Subnet Mask，可变长子网掩码) 是为了有效的使用无类别域间路由（CIDR）和路由汇聚(route summary)来控制路由表的大小，网络管理员使用先进的IP寻址技术，VLSM就是其中的常用方式，可以对子网进行层次化编址，以便最有效的利用现有的地址空间。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span&gt;VLSM规定了如何在一个进行了子网划分的网络中的不同部分使用不同的子网掩码。这对于网络内部不同网段需要不同大小子网的情形来说很有效。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;VLSM的作用就是在类的IP地址的基础上，&lt;strong&gt;从它们的主机号部分借出相应的位数&lt;/strong&gt;来做网络号，也就是增加网络号的位数。各类网络可以用来再划分子网的位数为：A类有二十四位可以借，B类有十六位可以借，C类有八位可以借。&lt;/p&gt;
&lt;h3 id=&quot;子网划分&quot;&gt;子网划分&lt;/h3&gt;
&lt;p&gt;这里继续用上面的140.0.0.0/8，该网段下可用主机数为16777214台，假设这个网段现在被中国买下使用，但是中国那么多的省份，每个省份都有着大量的IP需求，我应该怎么去分配这个资源呢？&lt;br/&gt;例如：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;140.0.0.1/8 - 140.0.0.255/8  北京
140.0.1.0/8 - 140.0.1.255/8  上海
140.0.2.0/8 - 140.0.2.255/8  广州
140.0.3.0/8 - 140.0.3.255/8  深圳&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;现在我们使用VLSM技术的话，可以将其划分出一些子网网段进行资源的一个合理分配，让我们看下面两个网段：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;140.1.0.0/16
140.2.0.0/16&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个和上面的网段看似不同，实际就是我们使用VLSM进行子网划分以后的结果，我们通过对主机位借位的方式，将前16位作为新IP的网段（网络号），通过这种方式，我们可以从之前的网段中分出140.0.0.0/16到140.255.0.0/16等256个新网段，这些网段就是上一个网段的子网段，通过这种形式，我们就可以对之前的网络进行重新划分，如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;140.0.0.0/16  北京
140.1.0.0/16  上海
140.2.0.0/16  广州
140.3.0.0/16  深圳
......&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上，我们就可以将之前的网段进行一个更好的划分，满足了不同的地区对于网络的需求&lt;br/&gt;那现在，北京地区已经拿到了属于自己的IP网段&lt;strong&gt;&lt;code&gt;140.0.0.0/16&lt;/code&gt;&lt;/strong&gt;,其中可用主机数为65534，那么北京地区的网络应该如何规划呢？这里我们可以继续使用VLSM对北京的网段进一步子网划分&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;140.0.0.0/24  朝阳区
140.0.1.0/24  海淀区
140.0.2.0/24  西城区
140.0.3.0/24  东城区
······&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看出来，这里我们再次对主机位借了8位用作网络位，把北京的网段也划分为了256个子网，实现了北京不同城区的网络需求。&lt;/p&gt;
&lt;p&gt;这里我们通过两次的主机借位，实现了一个A类网段的子网划分，这样的划分方式，不仅满足了不同地区对网络的需求，还可以让我们的子网划分具有很好的层次性。&lt;/p&gt;
&lt;p&gt;理想条件下，如果全世界的IP地址按照VLSM进行重新划分，在国际层次上，可以极大的提高国际带宽。例如一个上面的规划，中国使用通过划分，很好的利用好&lt;strong&gt;&lt;code&gt;140.0.0.0/16&lt;/code&gt;&lt;/strong&gt;网段，别的国家也如此，相互之间的路由规则就会简单的多。但是由于ipv4的发布时间过早，全世界的网络分配相对杂乱，导致核心路由书写时非常的复杂。&lt;/p&gt;
&lt;p&gt;接下来我们再进一步要求，当朝阳区拿到自己的网段后，朝阳区也需要分配IP地址给自己城区的不同街道或者社区，我们看看上面的网段140.0.0.0/24，前面的三个位置成网络位了，接下来怎么借位呢？&lt;br/&gt;这里我们不能将思维局限在IP地址的十进制表示方式上，实际IP地址为一个32位的二进制数&lt;br/&gt;|IP|01001100.00000000.00000000.0000000|&lt;br/&gt;|-|-|&lt;br/&gt;|子网掩码|11111111.11111111.11111111.00000000|&lt;br/&gt;所以这里朝阳区的IP网段地址实际是这样：&lt;br/&gt;&lt;span&gt;01001100.00000000.00000000&lt;/span&gt;.&lt;span&gt;0000000&lt;/span&gt;&lt;br/&gt;（&lt;span&gt;红色--&amp;gt;网络位&lt;/span&gt; &lt;span&gt;蓝色--&amp;gt;主机位&lt;/span&gt;）&lt;/p&gt;
&lt;p&gt;前面我们一直用十进制表示IP，每借一次就借用了八个二进制位，所以到了这里我们若还要进行子网划分的话，就需要将这个网段拆分为二进制来进行借位划分。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;但需要注意的是，当以十进制表示IP地址时，我们借一个数字位相当于借了8个二进制位，可划分出的子网段数为2^8=256个，但是当我们换成二进制数表达的时候，我们借一个二进制位只能划分出两个子网段。&lt;/span&gt;&lt;br/&gt;如此一来，朝阳区的IP中还有最后8个位置属于主机位，接着我们再借4个位来进行子网划分：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;A社区：01001100.00000000.00000000.0000 0000 /11111111.11111111.11111111.1111 0000
B社区：01001100.00000000.00000000.0001 0000 /11111111.11111111.11111111.1111 0000
C社区：01001100.00000000.00000000.0010 0000 /11111111.11111111.11111111.1111 0000
D社区：01001100.00000000.00000000.0011 0000 /11111111.11111111.11111111.1111 0000
·······
转为十进制表示：
A社区：140.0.0.0/28
B社区：140.0.0.16/28
C社区：140.0.0.32/28
D社区：140.0.0.48/28&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样一来就可以进一步对朝阳区的网段进行子网划分。但是需要注意的是，划分以后每个社区的网段只有4位主机位，所以每个社区的可用主机数量为：2^4-2=14台&lt;br/&gt;可以看出，每次对网段的子网划分，划分出的子网中有两个地址是无法使用的（网段地址和广播地址），所以使用子网划分的话，会减少一个网段中的可用主机数量。&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;这里对上面内容总结一下：&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;strong&gt;在进行子网划分时候，我们只能动主机位&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;对十进制的子网进行划分时，每借一个数字位就等于借了8个二进制位&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;每个子网中需要注意，网段地址和广播地址是不可用的地址&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;一个网段的可划分子网段数：2^n（n=划分时借的主机位数）&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;&lt;strong&gt;子网可用主机数的计算方式：2^n-2（n=子网主机位数）&lt;br/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;开发可变长度子网掩码的想法就是在每个子网上保留足够的主机数的同时，把一个网分成多个子网时有更大的灵活性。如果没有VLSM，一个子网掩码只能提供给一个网络。这样就限制了要求的子网数上的主机数。&lt;/p&gt;
&lt;h3 id=&quot;一个子网划分习题&quot;&gt;一个子网划分习题&lt;/h3&gt;
&lt;hr/&gt;&lt;p&gt;&lt;span&gt;&lt;strong&gt;问：将20.1.1.0/24划分为四个子网，每个子网网段，广播地址、可用ip数量&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;这里为了简写，我们将前24位以十进制位形式书写
20.1.1.00 000000
20.1.1.00 111111
子网网段：20.1.1.0/26     广播地址：20.1.1.63/26
20.1.1. 01 000000
20.1.1. 01 111111    //64-127
网段：20.1.1.64/26    广播地址：20.1.1.127/26

20.1.1. 10 000000
20.1.1. 10 111111    //128-191
网段：20.1.1.128/26    广播地址：20.1.1.191/26

20.1.1. 11 000000
20.1.1. 11 111111    //192-255
网段：20.1.1.192/26    广播地址：20.1.1.255/26

每个子网可用的ip数量都为62（2^6 - 2）

/*主机位全置0为网段，主机位全置1为广播地址，除了网段和广播地址，其他皆为可用IP地址*/&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Wed, 05 Sep 2018 14:43:00 +0000</pubDate>
<dc:creator>老夏家的云</dc:creator>
<og:description>IP子网划分 首先，在进行子网划分的学习之前，我们先来回顾一下IP地址的相关知识，同时了解一下公有和私有IP地址： 在Internet上有千百万台主机，为了区分这些主机，人们给每台主机都分配了一个专门</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/laoxiajiadeyun/p/9595394.html</dc:identifier>
</item>
<item>
<title>SpringCloud(7)---网关概念、Zuul项目搭建 - 雨点的名字</title>
<link>http://www.cnblogs.com/qdhxhz/p/9594521.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qdhxhz/p/9594521.html</guid>
<description>
&lt;h2&gt;&lt;span&gt;一、网关概念&lt;/span&gt;&lt;/h2&gt;
&lt;h4&gt;&lt;span&gt;   1、什么是路由网关&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;网关是系统的唯一对外的入口，&lt;span&gt;介于客户端和服务器端之间的中间层&lt;/span&gt;，处理非业务功能 提供路由&lt;span&gt;请求、鉴权、监控、缓存、限流等功能&lt;/span&gt;。它将&quot;1对N&quot;问题转换成了&quot;1对1”问题。&lt;/p&gt;
&lt;p&gt;通过服务路由的功能，可以在对外提供服务时，只暴露 网关中配置的调用地址，而调用方就不需要了解后端具体的微服务主机。&lt;/p&gt;
&lt;h4&gt;&lt;span&gt;  2、为什么要使用微服务网关&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;   不同的微服务一般会有不同的网络地址，而客户端可能需要调用多个服务接口才能完成一个业务需求，若让客户端直接与各个微服务通信，会有以下问题：&lt;/p&gt;
&lt;p&gt;（1）客户端会多次请求不同微服务，增加了客户端复杂性&lt;/p&gt;
&lt;p&gt;（2）存在跨域请求，处理相对复杂&lt;/p&gt;
&lt;p&gt;（3）认证复杂，每个服务都需要独立认证&lt;/p&gt;
&lt;p&gt;（4）难以重构，多个服务可能将会合并成一个或拆分成多个&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1090617/201809/1090617-20180905210245220-512410227.png&quot; alt=&quot;&quot; width=&quot;752&quot; height=&quot;300&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;&lt;span&gt;    3、网关的优点&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;   微服务网关介于服务端与客户端的中间层，所有外部服务请求都会先经过微服务网关客户只能跟微服务网关进行交互，无需调用特定微服务接口，使得开发得到简化&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1090617/201809/1090617-20180905210823038-708485043.png&quot; alt=&quot;&quot; width=&quot;755&quot; height=&quot;452&quot;/&gt;&lt;/p&gt;
&lt;p&gt;总的理解网关优点&lt;/p&gt;
&lt;p&gt;服务网关 = &lt;span&gt;路由转发 + 过滤器&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;（1）&lt;span&gt;路由转发&lt;/span&gt;：接收一切外界请求，转发到后端的微服务上去。&lt;/p&gt;
&lt;p&gt;（2）&lt;span&gt;过滤器&lt;/span&gt;：在服务网关中可以完成一系列的横切功能，例如权限校验、限流以及监控等，这些都可以通过过滤器完成（其实路由转发也是通过过滤器实现的）。&lt;/p&gt;
&lt;h4&gt;&lt;span&gt;    4、服务网关技术选型&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1090617/201809/1090617-20180905211133067-1494346492.png&quot; alt=&quot;&quot; width=&quot;559&quot; height=&quot;399&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;引入服务网关后的微服务架构如上，总体包含三部分：服务网关、open-service和service。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（1）总体流程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;       服务网关、open-service和service启动时注册到注册中心上去；&lt;/p&gt;
&lt;p&gt;用户请求时直接请求网关，网关做智能路由转发（包括服务发现，负载均衡）到open-service，这其中包含权限校验、监控、限流等操作&lt;/p&gt;
&lt;p&gt;open-service聚合内部service响应，返回给网关，网关再返回给用户&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（2）引入网关的注意点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;   增加了网关，多了一层转发（原本用户请求直接访问open-service即可），性能会下降一些（但是下降不大，通常，网关机器性能会很好，而且网关与open-service的访问通常&lt;/p&gt;
&lt;p&gt;是内网访问，速度很快）；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（3）服务网关基本功能&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;智能路由&lt;/span&gt;：接收外部一切请求，并转发到后端的对外服务open-service上去；&lt;/p&gt;
&lt;p&gt;     注意：我们只转发外部请求，服务之间的请求不走网关，这就表示全链路追踪、内部服务API监控、内部服务之间调用的容错、智能路由不能在网关完成；&lt;/p&gt;
&lt;p&gt;              当然，也可以将所有的服务调用都走网关，那么几乎所有的功能都可以集成到网关中，但是这样的话，网关的压力会很大，不堪重负。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;权限校验&lt;/span&gt;：可在微服务网关上进行认证，然后在将请求转发给微服务，无须每个微服务都进行认证，不校验服务内部的请求。服务内部的请求有必要校验吗？&lt;/p&gt;
&lt;p&gt; &lt;span&gt;API监控&lt;/span&gt;：只监控经过网关的请求，以及网关本身的一些性能指标（例如，gc等）；&lt;/p&gt;
&lt;p&gt;     &lt;span&gt;限流&lt;/span&gt;：与监控配合，进行限流操作；&lt;/p&gt;
&lt;p&gt;&lt;span&gt;API日志统一收集&lt;/span&gt;：类似于一个aspect切面，记录接口的进入和出去时的相关日志。&lt;/p&gt;

&lt;h2&gt;&lt;span&gt;二、Zuul项目搭建&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;  &lt;img src=&quot;https://images2018.cnblogs.com/blog/1090617/201809/1090617-20180905212511443-1154200461.png&quot; alt=&quot;&quot; width=&quot;961&quot; height=&quot;145&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div readability=&quot;61.44611948632&quot;&gt;
&lt;div readability=&quot;18&quot;&gt;
&lt;p&gt;      使用到的组件包括：Eureka、Feign、Zuul，包括以下四个项目：&lt;/p&gt;
&lt;p&gt;    （1）Eureka-server：   7001    注册中心&lt;/p&gt;
&lt;p&gt;    （2）product-server ：8001   商品微服务&lt;/p&gt;
&lt;p&gt;    （3）order-server ：   9001   订单微服务&lt;/p&gt;
&lt;p&gt;    （4）zuul-gateway ：   6001   Zuul网关&lt;/p&gt;
&lt;p&gt;注册中心、商品微服务、order在之前博客都已搭建，这里就不重复写。这里只写zuul-gateway微服务。&lt;/p&gt;
&lt;h4&gt;&lt;span&gt;     1、pom.xml&lt;/span&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
        &lt;span&gt;&amp;lt;!--&lt;/span&gt;&lt;span&gt;客户端jar包，这个在订单微服务，商品微服务都要添加&lt;/span&gt;&lt;span&gt;--&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;org.springframework.cloud&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;spring-cloud-starter-netflix-eureka-client&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;

        &lt;span&gt;&amp;lt;!--&lt;/span&gt;&lt;span&gt;zuuljar包&lt;/span&gt;&lt;span&gt;--&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;org.springframework.cloud&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;spring-cloud-starter-netflix-zuul&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;span&gt;   2、application.yml&lt;/span&gt;&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;span&gt;server&lt;/span&gt;:
  &lt;span&gt;port&lt;/span&gt;: &lt;/span&gt;6001

&lt;span&gt;#&lt;/span&gt;&lt;span&gt;服务的名称&lt;/span&gt;
&lt;span&gt;&lt;span&gt;spring&lt;/span&gt;:
  &lt;span&gt;application&lt;/span&gt;:
    &lt;span&gt;name&lt;/span&gt;: zuul&lt;/span&gt;-&lt;span&gt;gateway

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;指定注册中心地址&lt;/span&gt;
&lt;span&gt;&lt;span&gt;eureka&lt;/span&gt;:
  &lt;span&gt;client&lt;/span&gt;:
    &lt;span&gt;serviceUrl&lt;/span&gt;:
      &lt;span&gt;defaultZone&lt;/span&gt;: http:&lt;/span&gt;//localhost:7001/eureka/
&lt;span&gt;
#&lt;/span&gt;&lt;span&gt;自定义路由映射&lt;/span&gt;
&lt;span&gt;&lt;span&gt;zuul&lt;/span&gt;:
  &lt;span&gt;routes&lt;/span&gt;:
    &lt;span&gt;order&lt;/span&gt;&lt;/span&gt;&lt;span&gt;-service&lt;/span&gt;: /apigateway/order/**&lt;span&gt;
    product-service&lt;/span&gt;: /apigateway/product/**
  &lt;span&gt;#&lt;/span&gt;&lt;span&gt;统一入口为上面的配置，其他入口忽略&lt;/span&gt;
  &lt;span&gt;ignored-patterns&lt;/span&gt;: /*-service/**
  &lt;span&gt;#&lt;/span&gt;&lt;span&gt;忽略整个服务，对外提供接口&lt;/span&gt;
  &lt;span&gt;ignored-services&lt;/span&gt;: order-service
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;span&gt;     3、SpringBoot启动类&lt;/span&gt;&lt;/h4&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;@SpringBootApplication
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;加上网关注解&lt;/span&gt;
&lt;span&gt;@EnableZuulProxy
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ZuulServerApplication {
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; main(String[] args) {
        SpringApplication.run(ZuulServerApplication.&lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt;, args);
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;    &lt;span&gt;4、测试&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;（1）直接订单服务调商品服务&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1090617/201809/1090617-20180905214914776-109308983.png&quot; alt=&quot;&quot; width=&quot;589&quot; height=&quot;229&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; (2)通过Zuul网关实现订单接口调商品服务&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://images2018.cnblogs.com/blog/1090617/201809/1090617-20180905215908270-736215453.png&quot; alt=&quot;&quot; width=&quot;591&quot; height=&quot;187&quot;/&gt;&lt;/p&gt;
&lt;h4&gt;&lt;span&gt;      5、注意些细节&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;     （1）url不能重复，否则会覆盖&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
    order-service:    &lt;span&gt;/apigateway/order/**&lt;/span&gt;
    product-service:&lt;span&gt;  &lt;span&gt;/apigateway/product/**&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;   &lt;/span&gt;（2）通过zuul后，request中的cookie值获取不到，那是因为网关给过滤掉了。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
    @RequestMapping(&quot;list&quot;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; list(@RequestParam(&quot;user_id&quot;)&lt;span&gt;int&lt;/span&gt; userId, @RequestParam(&quot;product_id&quot;) &lt;span&gt;int&lt;/span&gt;&lt;span&gt; productId, HttpServletRequest request){
        String token &lt;/span&gt;= request.getHeader(&quot;token&quot;&lt;span&gt;);
        String cookie &lt;/span&gt;= request.getHeader(&quot;cookie&quot;&lt;span&gt;);
       &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;会发现token值能够获取，cookie无法获取，原因是因为网关会过滤掉敏感词&lt;/span&gt;
        System.out.println(&quot;token=&quot;+&lt;span&gt;token);
        System.out.println(&lt;/span&gt;&quot;cookie=&quot;+&lt;span&gt;cookie);
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    想要不过滤掉cookie值那么在配置里配置&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;span&gt;zuul&lt;/span&gt;:
  &lt;span&gt;#处理http请求头为空的问题&lt;/span&gt;
  &lt;span&gt;sensitive&lt;/span&gt;&lt;/span&gt;&lt;span&gt;-headers&lt;/span&gt;:
&lt;/pre&gt;&lt;/div&gt;
&lt;h4&gt;&lt;span&gt;      6、问题&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt; 自己遇到两个问题记录下，后期再来思考解决。&lt;/p&gt;
&lt;p&gt;1、现在通过订单服务地址可以直接访问订单微服务，如何配置成订单微服务不能直接服务，只能通过网关访问。&lt;/p&gt;
&lt;p&gt;  思考，是不是以后订单微服务配置到内网就不会有这个问题了。&lt;/p&gt;
&lt;p&gt;2、当我的订单服务调商品服务异常时，直接访问订单微服务熔断降级能够完成，通过网关竟然直接报异常了。&lt;/p&gt;
&lt;p&gt;我在商品微服务相关接口添加：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt;睡眠两秒，微服务默认一秒就超时，所以会到降级方法&lt;/span&gt;
TimeUnit.SECONDS.sleep(2);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1090617/201809/1090617-20180905220643366-675214280.png&quot; alt=&quot;&quot; width=&quot;701&quot; height=&quot;160&quot;/&gt;&lt;/p&gt;
&lt;p&gt;直接调订单服务，降级信息返回正常。如果通过网关访问。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1090617/201809/1090617-20180905220801706-1974286813.png&quot; alt=&quot;&quot; width=&quot;713&quot; height=&quot;237&quot;/&gt;&lt;/p&gt;
&lt;p&gt;返回的是异常，这不是很蛋疼吗，总是有解决办法让降级信息返回来的，以后解决来再来写。&lt;/p&gt;

&lt;h3&gt;&lt;span&gt;参考&lt;/span&gt;&lt;/h3&gt;
&lt;p class=&quot;title&quot;&gt;&lt;a href=&quot;https://www.jianshu.com/p/29e9c91e3f3e&quot; target=&quot;_blank&quot;&gt;Spring Cloud：服务网关 Zuul&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;title&quot;&gt; &lt;/p&gt;
&lt;p&gt;&lt;span&gt; 我只是偶尔安静下来，对过去的种种思忖一番。那些曾经的旧时光里即便有过天真愚钝，也不值得谴责。毕竟，往后的日子，还很长。不断鼓励自己，&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; 天一亮，又是崭新的起点，又是未知的征程（上校9）&lt;/span&gt;&lt;/p&gt;



&lt;/div&gt;
</description>
<pubDate>Wed, 05 Sep 2018 14:29:00 +0000</pubDate>
<dc:creator>雨点的名字</dc:creator>
<og:description>SpringCloud(7) 网关概念、Zuul项目搭建 一、网关概念 1、什么是路由网关 网关是系统的唯一对外的入口，介于客户端和服务器端之间的中间层，处理非业务功能 提供路由请求、鉴权、监控、缓存</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/qdhxhz/p/9594521.html</dc:identifier>
</item>
<item>
<title>五种回归方法的比较 - Jin_liang</title>
<link>http://www.cnblogs.com/jin-liang/p/9551759.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/jin-liang/p/9551759.html</guid>
<description>
&lt;p&gt;&lt;span&gt;　引言&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　线性和逻辑回归通常是人们为机器学习和数据科学学习的第一个建模算法。 两者都很棒，因为它们易于使用和解释。 然而，它们固有的简单性也有一些缺点，在许多情况下它们并不是回归模型的最佳选择。 实际上有几种不同类型的回归，每种都有自己的优点和缺点。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　在这篇文章中，我们将讨论5种最常见的回归算法及其属性，同时评估他们的性能。 最后，希望让您更全面地了解回归模型！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　目录&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;线性回归&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;多项式回归&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;岭回归&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;套索回归&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;弹性网络回归&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;hr/&gt;
&lt;p&gt;&lt;span&gt;　　回归是一种用于建模和分析变量之间关系的技术，通常是它们如何结合并且与一起产生特定结果相关。 线性回归指的是完全由线性变量组成的回归模型。 从简单的情况开始，单变量线性回归是一种技术，用于使用线性模型对单个输入自变量和输出因变量之间的关系进行建模。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　更一般的情况是多变量线性回归，其中为多个独立输入变量（特征变量）和输出因变量之间的关系创建模型。 模型保持线性，输出是输入变量的线性组合。 我们可以建模多变量线性回归，如下所示：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1345004/201808/1345004-20180828235210103-1309136038.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　其中a_n是系数，X_n是变量，b是偏差。 我们可以看到，此函数不包含任何非线性，因此仅适用于对线性可分离数据进行建模，因为我们只是使用系数权重a_n来加权每个特征变量X_n的重要性。 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;关于线性回归的几个关键点：&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;&lt;span&gt;建模快速简便，当要建模的关系不是非常复杂且没有大量数据时尤其有用。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;非常直观地理解和解释。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;线性回归对异常值非常敏感。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;span&gt;python实例：&lt;/span&gt;&lt;/p&gt;

&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;43&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
import numpy as np
import pandas as pd
from sklearn import datasets
from sklearn import metrics

data=datasets.load_boston()# load data

#定义评估函数
def evaluation(y_true,y_pred,index_name=['OLS']):
    df=pd.DataFrame(index=[index_name],columns=['平均绝对误差','均方误差','r2'])
    df['平均绝对误差']=metrics.mean_absolute_error(y_true, y_pred).round(4)
    df['均方误差']=metrics.mean_squared_error(y_true,y_pred)
    df['r2']=metrics.r2_score(y_true,y_pred)
    return df
&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
df=pd.DataFrame(data.data,columns=data.feature_names)

target=pd.DataFrame(data.target,columns=['MEDV'])
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;　　简单的可视化分析：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;40&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style=&quot;whitegrid&quot;, color_codes=True)


g=sns.pairplot(data[list(data.columns)[:5]], hue='ZN',palette=&quot;husl&quot;,diag_kind=&quot;hist&quot;,size=2.5)
for ax in g.axes.flat: 
    plt.setp(ax.get_xticklabels(), rotation=45)
plt.tight_layout()
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;img src=&quot;https://images2018.cnblogs.com/blog/1345004/201809/1345004-20180905212531559-649798200.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;特征的相关系数图：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;47&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
cm = np.corrcoef(data[list(data.columns)[:5]].values.T)   #corrcoef方法按行计算皮尔逊相关系数,cm是对称矩阵
#使用np.corrcoef(a)可计算行与行之间的相关系数,np.corrcoef(a,rowvar=0)用于计算各列之间的相关系数,输出为相关系数矩阵。
sns.set(font_scale=1.5)   #font_scale设置字体大小
cols=list(data.columns)[:5]
hm = sns.heatmap(cm,cbar=True,annot=True,square=True,fmt='.2f',annot_kws={'size': 15},yticklabels=cols,xticklabels=cols)
# plt.tight_layout()
# plt.savefig('./figures/corr_mat.png', dpi=300)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;img src=&quot;https://images2018.cnblogs.com/blog/1345004/201809/1345004-20180905212639015-1313580620.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; 用statsmodels模块的OLS&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
import statsmodels.api as sm

X=df[df.columns].values
y=target['MEDV'].values

#add constant
X=sm.add_constant(X)

# build model
model=sm.OLS(y,X).fit()

prediction=model.predict(X)

print(model.summary())
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　&lt;span&gt;　也可以用sklearn模块：&lt;/span&gt;&lt;/p&gt;

&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
from sklearn import linear_model

lm = linear_model.LinearRegression()
model = lm.fit(X,y)

y_pred = lm.predict(X)

lm.score(X,y)

#系数
lm.coef_
#截距
lm.intercept_&lt;p&gt;evaluation(y,y_pred)
&lt;/p&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;img src=&quot;https://images2018.cnblogs.com/blog/1345004/201809/1345004-20180905213046099-1990029922.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt; 　　当我们想要创建一个适合处理非线性可分数据的模型时，我们需要使用多项式回归。 在这种回归技术中，最佳拟合线不是直线。 它是一条适合数据点的曲线。 对于多项式回归，一些自变量的幂大于1.例如：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1345004/201809/1345004-20180905213235901-432154052.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们可以让一些变量具有指数，其他变量没有指数，并且还为每个变量选择我们想要的精确指数。 但是，选择每个变量的精确指数自然需要了解数据如何与输出相关。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;note：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;能够建模非线性可分离数据; 线性回归不能做到这一点。 它通常更灵活，可以建立一些相当复杂的关系。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;完全控制特征变量的建模（指定要设置）。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;需要仔细设计。 需要一些数据知识才能选择最佳指数。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;如果指数选择不当，容易过度拟合&lt;/span&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;python实例：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
from sklearn.preprocessing import PolynomialFeatures

poly_reg = PolynomialFeatures(degree = 4)
X_Poly = poly_reg.fit_transform(X)

lin_reg_2 =linear_model.LinearRegression()
lin_reg_2.fit(X_Poly, y)


y_pred=lin_reg_2.predict(poly_reg.fit_transform(X))

evaluation(y,y_pred,index_name=['poly_reg'])
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;img src=&quot;https://images2018.cnblogs.com/blog/1345004/201809/1345004-20180905213647915-511405346.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;可以看到，误差很小，r2很大，模型已经过拟合。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;　　在特征变量之间存在高共线性的情况下，标准线性或多项式回归将失败。 共线性是独立变量之间存在近线性关系。 高共线性的存在可以通过几种不同的方式确定：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;即使理论上该变量应该与Y高度相关，回归系数也不显着。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;添加或删除X特征变量时，回归系数会发生显着变化。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;X特征变量具有高成对相关性（检查相关矩阵）。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;我们首先可以看一下标准线性回归的优化函数，以获得有关岭回归如何帮助的一些见解：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://images2018.cnblogs.com/blog/1345004/201809/1345004-20180905213929727-1669376198.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;其中X代表特征变量，w代表权重，y代表实际值。 岭回归是一种补救措施，用于缓解回归模型中预测变量之间的共线性。 由于特征变量存在共线性，因此最终回归模型具有高方差。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;为了缓解这个问题，Ridge Regression为变量添加了一个小的平方偏差因子：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1345004/201809/1345004-20180905214138168-745965012.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在模型中引入少量偏差，但大大减小了方差。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;note：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;该回归的假设与最小二乘回归类似，但没有正态性假设。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;它会缩小系数的值，但不会达到零，这表明没有特征选择功能&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt; python实例：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;37&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
from sklearn.linear_model import Ridge

ridge_reg = Ridge(alpha=1, solver=&quot;cholesky&quot;)
ridge_reg.fit(X, y)

y_pred=ridge_reg.predict(X

evaluation(y,y_pred,index_name='ridge_reg')
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;img src=&quot;https://images2018.cnblogs.com/blog/1345004/201809/1345004-20180905214410672-498016290.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;　　套索回归与岭回归非常相似，因为两种技术都具有相同的前提。 我们再次为回归优化函数添加一个偏置项，以减少共线性的影响，从而减小模型方差。 然而，不是使用像岭回归那样的平方偏差，而套索回归使用绝对值偏差：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1345004/201809/1345004-20180905214547833-521187978.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Ridge和Lasso回归之间存在一些差异，这些差异基本上可以回归到L2和L1正则化的属性差异：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;内置特征选择：经常被提及为L1范数的有用属性，而L2范数则不然。这实际上是L1范数的结果，它倾向于产生稀疏系数。例如，假设模型有100个系数，但只有10个系数具有非零系数，这实际上是说“其他90个预测变量在预测目标值方面毫无用处”。 L2范数产生非稀疏系数，因此不具有此属性。因此，可以说Lasso回归做了一种“参数选择”，因为未选择的特征变量的总权重为0。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;稀疏性：指矩阵（或向量）中只有极少数条目为非零。 L1范数具有产生许多具有零值的系数或具有很少大系数的非常小的值的特性。这与Lasso执行一种特征选择的前一点相关联。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;计算效率：L1范数没有解析解，但L2有。在计算上可以有效地计算L2范数解。然而，L1范数具有稀疏性属性，允许它与稀疏算法一起使用，这使得计算在计算上更有效。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
from sklearn.linear_model import Lasso

lasso_reg = Lasso(alpha=0.1)
lasso_reg.fit(X, y)
y_pred=lasso_reg.predict(X)
evaluation(y,y_pred,index_name='lasso_reg')
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;img src=&quot;https://images2018.cnblogs.com/blog/1345004/201809/1345004-20180905214942894-919554761.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;　　ElasticNet是Lasso和Ridge Regression技术的混合体。 它使用L1和L2正则化来考虑两种技术的影响：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1345004/201809/1345004-20180905215041173-1740503604.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在Lasso和Ridge之间进行权衡的一个实际优势是：它允许Elastic-Net在旋转下继承Ridge的一些稳定性。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;note：&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;它在高度相关的变量的情况下鼓励群体效应，而不是像Lasso那样将其中的一些归零。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;所选变量的数量没有限制。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt; python实例：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
enet_reg = linear_model.ElasticNet(l1_ratio=0.7)

enet_reg.fit(X,y)

y_pred=enet_reg.predict(X)
evaluation(y,y_pred,index_name='enet_reg ')
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　&lt;img src=&quot;https://images2018.cnblogs.com/blog/1345004/201809/1345004-20180905215233013-1983314124.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;　　这篇文章简单总结了5种常见类型的回归及其属性。 所有这些回归正则化方法（Lasso，Ridge和ElasticNet）在数据集中变量之间的高维度和多重共线性的情况下都能很好地工作。 希望对大家有帮助！&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Wed, 05 Sep 2018 13:54:00 +0000</pubDate>
<dc:creator>Jin_liang</dc:creator>
<og:description>引言 线性和逻辑回归通常是人们为机器学习和数据科学学习的第一个建模算法。 两者都很棒，因为它们易于使用和解释。 然而，它们固有的简单性也有一些缺点，在许多情况下它们并不是回归模型的最佳选择。 实际上有</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/jin-liang/p/9551759.html</dc:identifier>
</item>
<item>
<title>Redis学习二：Redis入门介绍 - pony1223</title>
<link>http://www.cnblogs.com/pony1223/p/9594964.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/pony1223/p/9594964.html</guid>
<description>&lt;h2&gt;1.是什么&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Redis:REmote DIctionary Server(远程字典服务器) &lt;/strong&gt;是完全开源免费的，用C语言编写的，遵守BSD协议，&lt;strong&gt;是一个高性能的(key/value)分布式内存数据库&lt;/strong&gt;，基于内存运行并支持持久化的NoSQL数据库，是当前最热门的NoSql数据库之一,也被人们称为数据结构服务器。&lt;/p&gt;
&lt;p&gt;Redis 与其他 key - value 缓存产品（memcached）有以下三个特点：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1）持久化：Redis支持数据的持久化&lt;/strong&gt;，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2）丰富数据结构：Redis不仅仅支持简单的key-value类型的数据&lt;/strong&gt;，同时还提供list，set，zset，hash等数据结构的存储&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3）数据备份：Redis支持数据的备份&lt;/strong&gt;，即master-slave模式的数据备份&lt;/p&gt;
&lt;h2&gt;2.能干嘛&lt;/h2&gt;
&lt;p&gt;1）内存存储和持久化：redis支持异步将内存中的数据写到硬盘上，同时不影响继续服务&lt;/p&gt;
&lt;p&gt;2）取最新N个数据的操作，如：可以将最新的10条评论的ID放在Redis的List集合里面&lt;/p&gt;
&lt;p&gt;3）模拟类似于HttpSession这种需要设定过期时间的功能&lt;/p&gt;
&lt;p&gt;4）发布、订阅消息系统&lt;/p&gt;
&lt;p&gt;5）定时器、计数器&lt;/p&gt;
&lt;h2&gt;3.去哪下&lt;/h2&gt;
&lt;p&gt;Http://redis.io/&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905212017594-43819892.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Http://www.redis.cn/&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905212036252-497910023.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;4.怎么玩&lt;/h2&gt;
&lt;p&gt;1 数据类型、基本操作和配置&lt;/p&gt;
&lt;p&gt;2 持久化和复制，RDB/AOF&lt;/p&gt;
&lt;p&gt;3 事务的控制&lt;/p&gt;
&lt;p&gt;4. 复制&lt;/p&gt;
&lt;p&gt;。。。 。。。&lt;/p&gt;

&lt;h2&gt;1.VMWare虚拟机的安装&lt;/h2&gt;
&lt;h2&gt;2.CentOS或者RedHad5的安装&lt;/h2&gt;
&lt;p&gt;1）如何查看自己的linux是32位还是64位&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905212329114-637602866.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;getconf LONG_BIT&lt;br/&gt;返回是多少就是几位&lt;/p&gt;
&lt;p&gt;2）假如出现了不支持虚拟化的问题&lt;/p&gt;
&lt;p&gt;我的笔记本cpu是64位的，操作系统也是64位的，问题应该如虚拟机右下角提示所说，&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905212439439-648649800.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;是“宿主机BIOS设置中的硬件虚拟化被禁用了。”&lt;br/&gt;需要打开笔记本BIOS中的IVT对虚拟化的支持。&lt;br/&gt;找到菜单“Security”–“System Security”，&lt;br/&gt;将Virtualization Technology(VTx)和Virtualization Technology DirectedI/O(VTd)设置为 Enabled。&lt;br/&gt;保存并退出BIOS设置，重启电脑，&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905212451992-1755469604.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905212456767-1935283653.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905212503584-1770403968.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;3.VMTools的安装&lt;/h2&gt;
&lt;h2&gt;4.设置共享目录&lt;/h2&gt;
&lt;h2&gt;5.上述环境都OK后开始进行Redis的服务器安装配置&lt;/h2&gt;

&lt;h2&gt;1.Windows版安装&lt;/h2&gt;
&lt;p&gt;Window 下安装&lt;br/&gt;下载地址：https://github.com/dmajkic/redis/downloads&lt;br/&gt;下载到的Redis支持32bit和64bit。根据自己实际情况选择，将64bit的内容cp到自定义盘符安装目录取名redis。 如 C:\reids&lt;br/&gt;打开一个cmd窗口 使用cd命令切换目录到 C:\redis 运行 redis-server.exe redis.conf 。&lt;br/&gt;如果想方便的话，可以把redis的路径加到系统的环境变量里，这样就省得再输路径了，后面的那个redis.conf可以省略，&lt;br/&gt;如果省略，会启用默认的。输入之后，会显示如下界面：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905212649633-1492263298.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这时候另启一个cmd窗口，原来的不要关闭，不然就无法访问服务端了。&lt;br/&gt;切换到redis目录下运行 redis-cli.exe -h 127.0.0.1 -p 6379 。&lt;br/&gt;设置键值对 set myKey abc&lt;br/&gt;取出键值对 get myKey&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905212701578-1869995290.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;说明：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905212726981-297712446.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;基本都会使用Linux&lt;/p&gt;
&lt;h2&gt;2.Linux版安装&lt;/h2&gt;
&lt;p&gt;1)下载获得redis-3.0.4.tar.gz后将它放入我们的Linux目录/opt&lt;/p&gt;
&lt;p&gt;2)/opt目录下，解压命令:tar -zxvf redis-3.0.4.tar.gz&lt;/p&gt;
&lt;p&gt;3)解压完成后出现文件夹：redis-3.0.4&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905213458760-1164411653.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;4)进入目录:cd redis-3.0.4&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905213530753-2035033766.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;5)在redis-3.0.4目录下执行make命令&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905213632735-1671328771.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;6)如果make完成后继续执行make install&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905213700646-1080645399.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;7)查看默认安装目录：usr/local/bin&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905213719349-1980505024.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Redis-benchmark:性能测试工具，可以在自己本子运行，看看自己本子性能如何&lt;/p&gt;
&lt;p&gt;Redis-check-aof：修复有问题的AOF文件，rdb和aof后面讲&lt;/p&gt;
&lt;p&gt;Redis-check-dump：修复有问题的dump.rdb文件&lt;/p&gt;
&lt;p&gt;Redis-cli：客户端，操作入口&lt;/p&gt;
&lt;p&gt;Redis-sentinel：redis集群使用&lt;/p&gt;
&lt;p&gt;Redis-server：Redis服务器启动命令&lt;/p&gt;
&lt;p&gt;8)启动&lt;/p&gt;
&lt;p&gt;修改redis.conf文件将里面的daemonize no 改成 yes，让服务在后台启动&lt;/p&gt;
&lt;p&gt;将默认的redis.conf拷贝到自己定义好的一个路径下，比如/myconf&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905213904380-16853832.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905213923282-633200350.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;/usr/local/bin目录下运行redis-server，运行拷贝出存放了自定义conf文件目录下的redis.conf文件&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905214013701-1983688151.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;关闭&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/401339/201809/401339-20180905214028152-569849226.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;单实例关闭：redis-cli shutdown&lt;/p&gt;
&lt;p&gt;多实例关闭，指定端口关闭:redis-cli -p 6379 shutdown&lt;/p&gt;

&lt;h2&gt; 1.单进程&lt;/h2&gt;
&lt;p&gt;单进程模型来处理客户端的请求。对读写等事件的响应&lt;br/&gt;是通过对epoll函数的包装来做到的。Redis的实际处理速度完全依靠主进程的执行效率&lt;/p&gt;
&lt;p&gt;Epoll是Linux内核为处理大批量文件描述符而作了改进的epoll，是Linux下多路复用IO接口select/poll的增强版本，&lt;br/&gt;它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。&lt;/p&gt;
&lt;h2&gt;2.默认16个数据库，类似数组下表从零开始，初始默认使用零号库&lt;/h2&gt;
&lt;p&gt;设置数据库的数量，默认数据库为0，可以使用SELECT &amp;lt;dbid&amp;gt;命令在连接上指定数据库id&lt;br/&gt;databases 16&lt;/p&gt;
&lt;h2&gt;3.Select命令切换数据库&lt;/h2&gt;
&lt;h2&gt;4.Dbsize查看当前数据库的key的数量&lt;/h2&gt;
&lt;h2&gt;5.Flushdb：清空当前库&lt;/h2&gt;
&lt;h2&gt;6.Flushall；通杀全部库&lt;/h2&gt;
&lt;h2&gt;7.统一密码管理，16个库都是同样密码，要么都OK要么一个也连接不上&lt;/h2&gt;
&lt;h2&gt;8.Redis索引都是从零开始&lt;/h2&gt;
&lt;h2&gt;9.为什么默认端口是6379&lt;/h2&gt;
&lt;p&gt;6379在是手机按键上MERZ对应的号码，而MERZ取自意大利歌女&lt;a href=&quot;http://it.wikipedia.org/wiki/Alessia_Merz&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Alessia Merz&lt;/a&gt;的名字。MERZ长期以来被antirez及其朋友当作愚蠢的代名词。&lt;span class=&quot;wp_keywordlink_affiliate&quot;&gt;&lt;a title=&quot;查看 Redis 的全部文章&quot; href=&quot;http://blog.nosqlfan.com/tags/redis&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;Redis&lt;/a&gt;作者antirez同学在twitter上说将在下一篇博文中向大家解释为什么他选择&lt;span class=&quot;wp_keywordlink_affiliate&quot;&gt;&lt;a title=&quot;查看 6379 的全部文章&quot; href=&quot;http://blog.nosqlfan.com/tags/6379&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;6379&lt;/a&gt;作为&lt;span class=&quot;wp_keywordlink_affiliate&quot;&gt;&lt;a title=&quot;查看 默认 的全部文章&quot; href=&quot;http://blog.nosqlfan.com/tags/%E9%BB%98%E8%AE%A4&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;默认&lt;/a&gt;&lt;span class=&quot;wp_keywordlink_affiliate&quot;&gt;&lt;a title=&quot;查看 端口 的全部文章&quot; href=&quot;http://blog.nosqlfan.com/tags/%E7%AB%AF%E5%8F%A3&quot; rel=&quot;nofollow&quot; target=&quot;_blank&quot;&gt;端口&lt;/a&gt;号。而现在这篇博文出炉，在解释了Redis的LRU机制之后，向大家解释了采用6379作为默认端口的原因。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;wp_keywordlink_affiliate&quot;&gt;&lt;span class=&quot;wp_keywordlink_affiliate&quot;&gt;&lt;span class=&quot;wp_keywordlink_affiliate&quot;&gt;&lt;span class=&quot;wp_keywordlink_affiliate&quot;&gt;参考资料：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;wp_keywordlink_affiliate&quot;&gt;&lt;span class=&quot;wp_keywordlink_affiliate&quot;&gt;&lt;span class=&quot;wp_keywordlink_affiliate&quot;&gt;&lt;span class=&quot;wp_keywordlink_affiliate&quot;&gt;《redis视频》尚硅谷周阳&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Wed, 05 Sep 2018 13:47:00 +0000</pubDate>
<dc:creator>pony1223</dc:creator>
<og:description>一、入门概述 1.是什么 Redis:REmote DIctionary Server(远程字典服务器) 是完全开源免费的，用C语言编写的，遵守BSD协议，是一个高性能的(key/value</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/pony1223/p/9594964.html</dc:identifier>
</item>
</channel>
</rss>