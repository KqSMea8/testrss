<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Dynamics 365 for Finance and Operation interface with AIF - lingdanglfw</title>
<link>http://www.cnblogs.com/lingdanglfw/p/8331677.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/lingdanglfw/p/8331677.html</guid>
<description>&lt;p&gt;&amp;#13;
                                    &lt;button type=&quot;button&quot; class=&quot;close&quot; data-dismiss=&quot;modal&quot;&gt;&lt;span aria-hidden=&quot;true&quot;&gt;×&lt;/span&gt;&lt;span class=&quot;sr-only&quot;&gt;Close&lt;/span&gt;&lt;/button&gt;&amp;#13;
                                    &lt;h4 class=&quot;modal-title&quot;&gt;&amp;#13;
                                        请完成人机识别验证&amp;#13;
                                    &lt;/h4&gt;&amp;#13;
                                &lt;/p&gt;
                                &lt;div class=&quot;modal-body&quot; readability=&quot;33&quot;&gt;
                                    
                                    &lt;p&gt;&amp;#13;
                                        &lt;span id=&quot;geetestLoading&quot;&gt; 验证码组件加载中,请稍后...&lt;/span&gt;&amp;#13;
                                    &lt;/p&gt;
                                &lt;/div&gt;
                            </description>
<pubDate>Mon, 22 Jan 2018 15:25:00 +0000</pubDate>
<dc:creator>lingdanglfw</dc:creator>
<dc:format>text/html</dc:format>
<dc:identifier>https://passport.cnblogs.com/user/signin?ReturnUrl=http%3A%2F%2Fwww.cnblogs.com%2Flingdanglfw%2Fp%2F8331677.html&amp;AspxAutoDetectCookieSupport=1</dc:identifier>
</item>
<item>
<title>Video Target Tracking Based on Online Learning—TLD多目标跟踪算法 - 在海一方美猴王</title>
<link>http://www.cnblogs.com/liuyihai/p/8331250.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liuyihai/p/8331250.html</guid>
<description>&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span&gt;TLD算法回顾&lt;/span&gt;        &lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;        TLD(Tracking-Learning-Detection)是一种新的单目标长时间（long term tracking）跟踪算法。该算法与传统跟踪算法的显著区别在于将传统的跟踪算法和传统的检测算法相结合来解决被跟踪目标在被跟踪过程中发生的形变、部分遮挡等问题。同时，通过一种改进的在线学习机制不断更新跟踪模块的“显著特征点”和检测模块的目标模型及相关参数，从而使得跟踪效果更加稳定、鲁棒、可靠。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;        TLD算法详细描述参见：&lt;a href=&quot;http://www.cnblogs.com/liuyihai/p/8306419.html&quot; target=&quot;_blank&quot;&gt;http://www.cnblogs.com/liuyihai/p/8306419.html&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;基于TLD的多目标跟踪框架&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;span class=&quot;fontstyle0&quot;&gt;        现实的场景中，对于一个拍摄的视频序列，只跟踪视频序列的一个目标越来越不能满足实际需求。  因&lt;span&gt;此，探讨TLD算法在多目标跟踪中的应用研究很有必要。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;与单目标跟踪相比， 多目标跟踪的整体流程依然是跟踪、检测、学习和综合&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;输出，唯一的区别是随时可以添加新的跟踪目标。 &lt;span class=&quot;fontstyle0&quot;&gt;基于以上分析，多目标跟踪算法总过程如下图&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;所示。&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1257606/201801/1257606-20180122201608865-1066216637.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;上图整个框架实现过程如下：（&lt;span class=&quot;fontstyle1&quot;&gt;1&lt;span class=&quot;fontstyle0&quot;&gt;）读入视频序列。（&lt;span class=&quot;fontstyle1&quot;&gt;2&lt;span class=&quot;fontstyle0&quot;&gt;） 用鼠标标定或者输入矩形框参数的形式定位跟踪的目标框（就是画一个矩形框）。（&lt;span class=&quot;fontstyle1&quot;&gt;3&lt;span class=&quot;fontstyle0&quot;&gt;）初始化参数，生成样本。样本用来得到检测模块的样本库。（&lt;span class=&quot;fontstyle1&quot;&gt;4&lt;span class=&quot;fontstyle0&quot;&gt;） 跟踪的目标框分别进入跟踪模块和检测模块， 通过相关条件判断在下一帧是否存在跟踪到目标。（&lt;span class=&quot;fontstyle1&quot;&gt;5&lt;span class=&quot;fontstyle0&quot;&gt;）通过学习模块反馈作用检测模块，更新检测模块的样本库。并用检测模块对跟踪模块进行更新。（&lt;span class=&quot;fontstyle1&quot;&gt;6&lt;span class=&quot;fontstyle0&quot;&gt;）对于每一帧跟踪模块和检测模块的结果在综合模块中进行处理输出定位下一帧中目标出现的位置方位。（&lt;span class=&quot;fontstyle1&quot;&gt;7&lt;span class=&quot;fontstyle0&quot;&gt;）如果在执行的过程中，添加新的目标，则重复上述过程，依次处理每一个跟踪目标，这样就实现了多个目标的跟踪。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;TLD多目标跟踪原理详解&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;strong&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;-----------------------------------------------------多目标&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;strong&gt;跟踪模块&lt;/strong&gt;---------------------------------------------&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;跟踪单个目标只需要四个参数（横坐标，纵坐标，长度，宽度）就能确定被跟踪目标的信息位置。但是跟踪多个目标时候，需要对不同目标加以区分， 所以目标矩形框的数据结构略作改变， 在以前的数据结构中添加一个序号用来表示不同的目标，这样用五个参数就可以很好地区分多个目标。如下图所示。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1257606/201801/1257606-20180122202551600-454156228.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;存在多个目标时，同一帧图像中同时存在多个目标要被跟踪，多个目标是以结构体数组的形式存放的。这时候跟踪模块需要使用LK中值流法（方法原理同TLD单目标跟踪）以循环的方式反复跟踪结构体数组中的每个目标，直到所有目标被跟踪完毕。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;strong&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;-----------------------------------------------------多目标检测&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;strong&gt;模块&lt;/strong&gt;---------------------------------------------&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;        目标检测模块也是让待测的滑动矩形框依次通过方差分类器、集合分类器和最近邻分类器，过滤掉不满足条件的滑动矩形框，找出最近似的矩形框。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1257606/201801/1257606-20180122205211897-841904283.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;      &lt;span&gt; 多目标时滑动窗口的形成过程&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;        对于单目标 &lt;span class=&quot;fontstyle2&quot;&gt;TLD &lt;span class=&quot;fontstyle0&quot;&gt;算法，滑动窗口是这样产生的。以跟踪目标框在视频中的长宽为基数， 以一定尺度比例缩放； 每缩放一次遍历一次整个图像片，最终得到大量的滑动窗口。 &lt;span class=&quot;fontstyle0&quot;&gt;每一个目标框为基数产生的滑动窗口都达到了几万个，每一帧图像多要产生滑动窗口。如果同时有多个目标，也按照这种方式分别产生各自跟踪窗口的滑动矩形框，数量将成倍增加，并且在后面检测这些窗口的时候处理速度也非常缓慢。这就导致不能用简单的循环重复实现TLD算法检测模块对多目标的检测改进。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt; 当有多个目标产生滑动矩形框时，滑动窗口成倍增加的主要原因是不同尺寸生成的滑动窗口不一致所致。 为了减少生成滑动窗口的数量，在视频序列中跟踪多个目标的时，让标定的跟踪目标矩形框间长宽比固定，这样生成的滑动窗口是与初始目标框成比例缩放的。 那么处理每一帧视频时，不同的跟踪目标只需要生成一次滑动窗口便可。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;        &lt;span class=&quot;fontstyle0&quot;&gt;宽度和长度归一化过程具体如下：&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;        a)计算出第一个被跟踪的目标框的宽度和长度的比率，如下式所示&lt;span class=&quot;fontstyle1&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;，&lt;span class=&quot;fontstyle2&quot;&gt;w&lt;span class=&quot;fontstyle1&quot;&gt;0 &lt;span class=&quot;fontstyle0&quot;&gt;表示第一个目标框的宽度， &lt;span class=&quot;fontstyle2&quot;&gt;h&lt;span class=&quot;fontstyle1&quot;&gt;0 &lt;span class=&quot;fontstyle0&quot;&gt;表示第一个目标框的高度， &lt;span class=&quot;fontstyle2&quot;&gt;p &lt;span class=&quot;fontstyle0&quot;&gt;表示宽度和长度比的值。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle1&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle1&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle1&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1257606/201801/1257606-20180122204407319-589535748.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle1&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle1&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle1&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;        b)那么对于&lt;span class=&quot;fontstyle0&quot;&gt;第n（n=2,3,...,N）个被跟踪的目标框，我们令其宽度保持不变，可以通过下式&lt;span class=&quot;fontstyle0&quot;&gt;计算出第n个被跟踪的目标框的归一化高度.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle1&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle1&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle1&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1257606/201801/1257606-20180122204644037-1238234643.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;下图给出了新添加目标后（蓝色目标），进行归一化处理后的跟踪过程：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1257606/201801/1257606-20180122204806131-1365475257.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;综上所述，当视频序列要添加新的目标的时（新目标鼠标框定的目标与第一个目标的长宽比一般不一致），根据第一个目标框的长宽比归一化处理新添加的目标，这样新添加的目标与初始的目标长宽比一致只是大小不一样。这样跟踪多个目标也只需要生成一组滑动窗口即可，计算量大大降低。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;      &lt;span&gt;  多目标时的方差滤波过程&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span class=&quot;fontstyle0&quot;&gt;        方差分类器筛选滑动窗口的依据是方差阈值，大于该阈值则通过方差分类器，小于该阈值丢弃。&lt;span class=&quot;fontstyle0&quot;&gt;图像中有多个目标时，采取如下策略确定方差阈值大小：如果只跟踪一个目标，就得到该目标的方差，然后让该目标框方差大小的一半作为方差分类器的阈值；如果存在多个目标的时候，就选择最小 &lt;span class=&quot;fontstyle0&quot;&gt;跟踪目标框方差的一半作为方差分类器的阈值。&lt;span class=&quot;fontstyle0&quot;&gt;通过上述分析得知，如果同时跟踪的目标越多，并且多个目标最大方差与最小的方差相差很大的时， 方差分类器筛选出来的滑动窗口数量较多。反之，多个目标框方差较为接近的时候，方差分类器筛选出来的滑动窗口数量相对较少。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;        &lt;span&gt;多目标时的&lt;span class=&quot;fontstyle0&quot;&gt;集合分类器&lt;/span&gt;过程&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;fontstyle0&quot;&gt;        因此， 多目标集合分类器主要完成两项工作，其一， 进一步过滤掉不符合条件的待测滑动窗口，其二，对于筛选出来窗口进行分类，使得不同滑动窗口属于不同的跟踪目标。 &lt;span class=&quot;fontstyle0&quot;&gt;随机森林有良好的特性， 多目标集合分类器依然基于随机森林。在集合分类器中，每增加一个新的目标，就以该目标框长度、 宽度、编号和方差参数条件来进行仿射变换等生成正样本。由于每一个目标框都是带有编号的，这样正样本通过随机森林时，训练出来的结果都带有编号的， 以区分其属于不同的目标。&lt;span class=&quot;fontstyle0&quot;&gt;另一个方面，上一步待测的滑动矩形框也会通过随机森林， 通过随机森林也会得到 &lt;span class=&quot;fontstyle2&quot;&gt;2bitBP &lt;span class=&quot;fontstyle0&quot;&gt;编码的特征码，根据特征码与上述训练出来的库进行对比，如果在库中比对，比对的结果满足阈值条件，则认为含有前景目标，予以保留。样本库中的样本都是根据不同目标有编号的，这样比对成功的滑动窗口就可以编号。否&lt;br/&gt;则丢弃。  &lt;span class=&quot;fontstyle0&quot;&gt;从上述过程中可以看出，一个待测窗口开始进入集合分类器的时候，是没有加以区分的，通过集合分类器后，被保留下来的滑动窗口已经带有特定编号了，并且该编号与跟踪目标框的编号是一致的。多个待测窗口通过该集合分类器后，被筛选出来的滑动窗口已经被标有不同的编号了，从而达到过滤和分类的目的。 &lt;span class=&quot;fontstyle0&quot;&gt;当然，同时跟踪多个目标时，一个待测窗口可能同时被打上多个不同编号，但他们之间并不矛盾。&lt;br/&gt;&lt;/span&gt;&lt;span&gt;       &lt;/span&gt; &lt;span&gt;多目标时的&lt;span class=&quot;fontstyle0&quot;&gt;最近邻分类器过程&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;fontstyle0&quot;&gt;        对于多个目标，最近邻分类器主要完成两个功能。其一是，将跟踪模块跟踪到的图像片与上一帧的图像片进行匹配比对，若相似度大于指定阈值则认为。最终跟踪模块跟踪的结果成功。其二是，将通过集合分类器的滑动窗口与各自的的图像片进行比对，其相似度大于一定的阈值则认为，滑动窗口时该矩形框的最终检测窗口。&lt;br/&gt;&lt;/span&gt;&lt;br/&gt;&lt;/span&gt; &lt;strong&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;-----------------------------------------------------多目标学习&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;strong&gt;模块&lt;/strong&gt;---------------------------------------------&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;span class=&quot;fontstyle0&quot;&gt;        传统的 &lt;span class=&quot;fontstyle2&quot;&gt;TLD &lt;span class=&quot;fontstyle0&quot;&gt;算法，学习模块分为在线模型和 &lt;span class=&quot;fontstyle2&quot;&gt;P-N &lt;span class=&quot;fontstyle0&quot;&gt;学习模块。因为在实验中，在上述多目标最近邻分类器已经充当了在线模型的作用，故多目标学习模块主要完成两部分的内容。其一是，最近邻样本库的训练；其二是，集合分类器的训练。扩展的多目标最近邻分类器充当了与在线模型类似的功能，故对于多个目标学习模块只需要训练更新集合分类器和最近邻分类器的总样本库。对于集合分类器中正样本产生是在添加目标的时产生的。最近邻分类器中的正样本库由各自在上一帧中跟踪到的目标加上编号生成的，负样本只有一个库，是与被跟踪目标相似度都小的图像片组成的样本。 正样本和负样本的产生来源于两部分。其一，每增加一个目标，会在样本库中添加属于该的目标的正样本和更新负样本库。其二， 每一次检测模块最终的得到的滑动窗口也会作为新的样本存入各自样本库中， 并更新负样本。 学习样本库如下图所示。&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1257606/201801/1257606-20180122211041319-991596817.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;-----------------------------------------------------多目标综合&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;strong&gt;模块&lt;/strong&gt;---------------------------------------------&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;        多目标综合模块与单目标的策略是一致的，只是这时候有多个目标，循环处理每一个目标即可。&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;TLD多目标跟踪算法源&lt;/span&gt;&lt;span&gt;码、程序安装及运行答疑&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;            &lt;span class=&quot;fontstyle0&quot;&gt;liuyihai@126.com       liuyihai@aliyun.com&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;&lt;span&gt;TLD多目标跟踪参考文献&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt; &lt;span&gt;[1]&lt;a href=&quot;http://tldvision.com/pdf/tld2_spec_sheet.pdf&quot; target=&quot;_blank&quot;&gt; http://tldvision.com/pdf/tld2_spec_sheet.pdf&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;[2]姚沛. &lt;span class=&quot;fontstyle0&quot;&gt;基于TLD多目标跟踪算法研究&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;TLD多目标跟踪演示视频&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;多动静目标跟踪：&lt;a href=&quot;http://www.miaopai.com/show/kQQI-zVHpomC-MQ7JiMaA0d1SjZeeZxpdO8ryw__.htm&quot; target=&quot;_blank&quot;&gt;http://www.miaopai.com/show/kQQI-zVHpomC-MQ7JiMaA0d1SjZeeZxpdO8ryw__.htm&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;img src=&quot;https://images2017.cnblogs.com/blog/1257606/201801/1257606-20180122212913990-1566057918.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle1&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle1&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle1&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle2&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;&lt;span class=&quot;fontstyle0&quot;&gt;无人机航拍多目标跟踪&lt;/span&gt; ：&lt;a href=&quot;http://www.miaopai.com/show/HCOagxw0V4cSOxNHeLdLK6nC3MKric8lOHdXmg__.htm&quot; target=&quot;_blank&quot;&gt;http://www.miaopai.com/show/HCOagxw0V4cSOxNHeLdLK6nC3MKric8lOHdXmg__.htm&lt;/a&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://images2017.cnblogs.com/blog/1257606/201801/1257606-20180122220551256-29294662.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;博文预告&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span&gt; &lt;strong&gt;下一篇博文将详细讲述深度学习（人工智能）算法在视频目标跟踪中的应用情形-----欢迎阅读&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 22 Jan 2018 13:34:00 +0000</pubDate>
<dc:creator>在海一方美猴王</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/liuyihai/p/8331250.html</dc:identifier>
</item>
<item>
<title>Dora.Interception, 一个为.NET Core度身打造的AOP框架：不一样的Interceptor定义方式 - Artech</title>
<link>http://www.cnblogs.com/artech/p/dora2-02.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/artech/p/dora2-02.html</guid>
<description>&lt;p&gt;相较于社区其他主流的AOP框架，Dora.Interception在Interceptor提供了完全不同的编程方式。我们&lt;span&gt;并没有为Interceptor定义一个接口&lt;/span&gt;，正是因为不需要实现一个预定义的接口，Dora.Interception下的Interceptor定义变得更加自由。除此之外，Interceptor的异步执行是我在设计Dora.Interception之初最为关心的问题，也就是说如果Interceptor应用的目标方法是异步的，Interceptor自身也应该被赋予异步执行的能力。接下来我们就来聊聊如果你使用了Dora.Interception，如何定义你的Interceptor。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;目录&lt;br/&gt;一、两种代理类型生成方式&lt;br/&gt;二、InterceptorDelegate&lt;br/&gt;三、定义Interceptor类型&lt;br/&gt;四、支持方法注入&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Dora.Interception采用动态生成代理类型（采用IL Emit）的方式来实现针对目标方法的拦截，具体来说我们提供了两种类型的代理类型生成方式：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果目标类型实现了某个接口，我们会让生成的代理类型实现这个接口，在代理类型中实现的接口方法会执行拦截操作，这意味着定义在接口中的所有方法都是可以被拦截的。代理对象会封装目标对象，如果需要最终调用目标方法，被封装的这个目标对象相应的方法会被调用。我们将这种形式的代理类型生成方式成为“基于接口的代码生成”。&lt;/li&gt;
&lt;li&gt;如果目标类型没有实现接口，那么生成的代理类型会直接派生于这个类型，如果定义在基类中的某个虚方法需要被拦截，我们会在代理类中通过重写该方法来执行拦截操作。针对目标方法的调用可以通过调用基类对应的方法来实现。我们将这种形式的代理类型生成方式成为“基于虚方法的代码生成”。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;AOP的核心在于将一些非业务的功能定义成相应的Interceptor，并以横切（Crosscutting）的形式注入到针对目标方法的调用过程中。换句话说，Interceptor需要拦截目标方法的执行，并在针对当前执行方法的上下文中执行被注入的操作。如果我们将方法执行的上下文定义成一个&lt;span&gt;InvocationContext&lt;/span&gt;，那么Interceptor需要执行的拦截操作就可以表示成一个&lt;span&gt;Action&amp;lt;InvocationContext&amp;gt;。&lt;/span&gt;但是我们在上面说过了，一个Interceptor应该被赋予异步执行的能力，按照基于Task的并行编程模式，Interceptor自身执行的拦截操作应该表示成一个&lt;span&gt;Func&amp;lt;InvocationContext, Task&amp;gt;&lt;/span&gt;。&lt;/p&gt;
&lt;p&gt;我们在Dora.Interception定义了如下这个抽象的InvocationContext来表示需要被拦截的方法执行上下文。它的Method和TargetMethod返回代表当前方法的MethodBase对象，如果采用基于接口的代理类型生成方式，前者表示定义在接口上的方法，后者则表示定义在目标类型上的方法。如果采用基于虚方法的代理类型生成方式，两个属性返回的是同一个对象，表示定义在被拦截类型中的方法。至于Proxy和Target则很明显，分别表示当前的代理对象和被封装的目标对象，如果采用基于虚方法的代理类型生成方式，两个属性返回同一个对象。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;  1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; InvocationContext
&lt;span&gt;  2&lt;/span&gt; {
&lt;span&gt;  3&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; MethodBase Method { &lt;span&gt;get&lt;/span&gt;; }
&lt;span&gt;  4&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; MethodBase TargetMethod { &lt;span&gt;get&lt;/span&gt;; }
&lt;span&gt;  5&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;object&lt;/span&gt; Proxy { &lt;span&gt;get&lt;/span&gt;; }
&lt;span&gt;  6&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;object&lt;/span&gt; Target { &lt;span&gt;get&lt;/span&gt;; }
&lt;span&gt;  7&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;object&lt;/span&gt;[] Arguments { &lt;span&gt;get&lt;/span&gt;; }
&lt;span&gt;  8&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;object&lt;/span&gt; ReturnValue { &lt;span&gt;get&lt;/span&gt;; &lt;span&gt;set&lt;/span&gt;; }
&lt;span&gt;  9&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;InvocationContext的Arguments表示当前方法调用的参数，既包括一般的输入参数，也包括ref/out参数。值得一提的是，Arguments属性是&lt;span&gt;可读可写的&lt;/span&gt;，也就说Interceptor可以通过修改该属性中某个元素的值进而实现修改某个参数值的目的。由于整个调用过程共享同一个InvocationContext对象，所以某个Interceptor对Arguments所作的任何修改都将影响到后续Intercecptor以及最终目标方法的执行。InvocationContext的ReturnValue表示方法调用的返回值。如果目标方法最终被调用，它的返回值将最终反映在这个属性上。这个属性是可读可写的，任意Interceptor都可以通过修改这个属性得到改变方法调用返回值的目的。&lt;/p&gt;
&lt;p&gt;由于当前方法调用的执行上下文被表示成一个InvocationContext对象，所以实现在Interceptor上的拦截操作可以表示成一个Func&amp;lt;InvocationContext, Task&amp;gt;类型的委托。不过为了编程方便，我们专门定义了如下这个对应的委托类型&lt;span&gt;InterceptDelegate&lt;/span&gt;。由于一个方法上可以同时应用多个Interceptor，那么对应一个Interceptor在完成了自身定义的拦截操作之后，它还将决定是否继续调用后续的Interceptor或者目标方法，或者说针对后续Interceptor或者目标方法的调用也属于当前拦截操作的一部分，所以我们定义了另一个委托类型InterceptorDelegate来表示一个Interceptor对象。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;  1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;delegate&lt;/span&gt; Task InterceptDelegate(InvocationContext context);
&lt;span&gt;  2&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;delegate&lt;/span&gt; InterceptDelegate InterceptorDelegate(InterceptDelegate next);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;对于表示Interceptor的InterceptorDelegate委托，它的输入和输出都是InterceptDelegate委托，Interceptor通过作为输入的InterceptDelegate委托实现针对后续Interceptor或者目标方法的调用，它返回的InterceptDelegate委托对象则体现实现的拦截操作。从这个意义上讲，&lt;span&gt;一个InterceptorDelegate委托不仅仅表示一个单一的Interceptor对象，也可以表示由多一个Interceptor组成的Interceptor Chain&lt;/span&gt;。从另一个角度讲，由于一个Interceptor已经实现了针对后续Interceptor的执行，所以&lt;span&gt;一个Interceptor本身就表示一个Interceptor Chain&lt;/span&gt;。&lt;/p&gt;

&lt;p&gt;虽然Dora.Interception在底层总是使用一个InterceptorDelegate委托表示Interceptor（Chain），为了编程上的便利，我们依然将Interceptor定义成一个类型，我们定义的Interceptor类型只需要采用如下的“约定”即可：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Interceptor类型无需实现任何的接口，我们只需要定义一个普通的&lt;span&gt;公共实例类型&lt;/span&gt;即可。&lt;/li&gt;
&lt;li&gt;Interceptor类型必须具有一个公共构造函数，并且该构造函数的第一个参数的类型必须是&lt;span&gt;InterceptDelegate&lt;/span&gt;，后者用于调用后续的Interceptor或者目标方法。&lt;/li&gt;
&lt;li&gt;除了第一个参数之外，上述这个构造函数&lt;span&gt;可以包含任意的参数定义&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;拦截功能实现在约定的InvokeAsync的方法中，这是一个返回类型为&lt;span&gt;Task&lt;/span&gt;的异步方法，它的第一个参数类型为InvocationContext。&lt;/li&gt;
&lt;li&gt;除了表示当前执行上下文的参数之外，InvokeAsync&lt;span&gt;可以包含任意的参数定义&lt;/span&gt;，但是要求这些参数能够以DI的方式来提供。&lt;/li&gt;
&lt;li&gt;当前Interceptor是否调用后续的Interceptor或者目标方法，取决于你是否调用构造函数传入的这个InterceptDelegate委托对象。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;接下来我们就通过实例演示的方式来简单介绍一下如何遵循上述的这些约定来定义我们的Interceptor类型。如下面的代码片段所示，作为Interceptor类型的FoobarInterceptor具有一个公共的实例构造函数，作为强制要求的第一个参数next表示用于调用后续Interceptor或者目标方法的InterceptDelegate委托对象。除了该参数，我们还定义了额外两个接口类型的参数，这些参数都被保存到对应的字段或者属性上。拦截操作定义在InvokeAsync方法，这个方法的方法名（InvokeAsync）、返回类型（Task）和第一个参数的类型（InvocationContext）都是我们约定的一部分。在这个方法中，我们输出Foo和Bar属性，并最终利用构造函数指定的InterceptDelegate委托对象将调用向后传递。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;  1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; FoobarInterceptor
&lt;span&gt;  2&lt;/span&gt; {
&lt;span&gt;  3&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; IFoo Foo { &lt;span&gt;get&lt;/span&gt;; }
&lt;span&gt;  4&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; IBar Bar { &lt;span&gt;get&lt;/span&gt;; }
&lt;span&gt;  5&lt;/span&gt;     &lt;span&gt;private&lt;/span&gt; InterceptDelegate _next;
&lt;span&gt;  6&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; FoobarInterceptor(InterceptDelegate next, IFoo foo, IBar bar)
&lt;span&gt;  7&lt;/span&gt;     {
&lt;span&gt;  8&lt;/span&gt;         _next = next;
&lt;span&gt;  9&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;.Foo = foo;
&lt;span&gt; 10&lt;/span&gt;         &lt;span&gt;this&lt;/span&gt;.Bar = bar;
&lt;span&gt; 11&lt;/span&gt;     }
&lt;span&gt; 12&lt;/span&gt; 
&lt;span&gt; 13&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; Task InvokeAsync(InvocationContext context)
&lt;span&gt; 14&lt;/span&gt;     {
&lt;span&gt; 15&lt;/span&gt;         Console.WriteLine(&lt;span&gt;this&lt;/span&gt;.Foo);
&lt;span&gt; 16&lt;/span&gt;         Console.WriteLine(&lt;span&gt;this&lt;/span&gt;.Bar);
&lt;span&gt; 17&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt; _next(context);
&lt;span&gt; 18&lt;/span&gt;     }
&lt;span&gt; 19&lt;/span&gt; }
&lt;span&gt; 20&lt;/span&gt; 
&lt;span&gt; 21&lt;/span&gt; 
&lt;span&gt; 22&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; FoobarAttribute : InterceptorAttribute
&lt;span&gt; 23&lt;/span&gt; {
&lt;span&gt; 24&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;override&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Use(IInterceptorChainBuilder builder)
&lt;span&gt; 25&lt;/span&gt;     {
&lt;span&gt; 26&lt;/span&gt;         builder.Use&amp;lt;FoobarInterceptor&amp;gt;(&lt;span&gt;this&lt;/span&gt;.Order);
&lt;span&gt; 27&lt;/span&gt;     }
&lt;span&gt; 28&lt;/span&gt; }
&lt;span&gt; 29&lt;/span&gt; 
&lt;span&gt; 30&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;interface&lt;/span&gt; IFoo { }
&lt;span&gt; 31&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;interface&lt;/span&gt; IBar { }
&lt;span&gt; 32&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; Foo : IFoo { }
&lt;span&gt; 33&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; Bar : IBar { }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;FoobarAttribute是用于注册FoobarInterceptor的特性，FoobarAttribute派生于InterceptorAttribute这个抽象基类，关于InterceptorAttribute以及相关Interceptor注册的类型我们将在后续的文章中进行介绍。Dora.Interception的一个显著的特征就是与.NET Core的DI实现了无缝集成，具体体现在Interceptor中所需的任何服务都可以直接采用DI的方式来提供，比如FoobarInterceptor的Foo和Bar属性对应的服务实例。如下面的代码片段所示，我们将FoobarAttribute标注到Demo类型的虚方法Invoke上。在Main方法中，我们将IFoo、IBar和Demo对应的服务注册添加到创建的ServiceCollection上，然后调用后者的BuildInterceptableServiceProvider方法创建一个具有“拦截”特性的ServiceProvider。如果由这个ServiceProvider提供的服务类型能够被拦截，它会利用相应的代理类型生成机制动态地生成对应的代理类型，并最终创建出对应的代理实例。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;  1&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; Program
&lt;span&gt;  2&lt;/span&gt; {
&lt;span&gt;  3&lt;/span&gt;     &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main()
&lt;span&gt;  4&lt;/span&gt;     {
&lt;span&gt;  5&lt;/span&gt;         var demo = &lt;span&gt;new&lt;/span&gt; ServiceCollection()
&lt;span&gt;  6&lt;/span&gt;             .AddScoped&amp;lt;IFoo, Foo&amp;gt;()
&lt;span&gt;  7&lt;/span&gt;             .AddScoped&amp;lt;IBar, Bar&amp;gt;()
&lt;span&gt;  8&lt;/span&gt;             .AddScoped&amp;lt;Demo, Demo&amp;gt;()
&lt;span&gt;  9&lt;/span&gt;             .BuildInterceptableServiceProvider()
&lt;span&gt; 10&lt;/span&gt;             .GetRequiredService&amp;lt;Demo&amp;gt;();
&lt;span&gt; 11&lt;/span&gt;         demo.Invoke();
&lt;span&gt; 12&lt;/span&gt;     }
&lt;span&gt; 13&lt;/span&gt; }
&lt;span&gt; 14&lt;/span&gt; 
&lt;span&gt; 15&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; Demo
&lt;span&gt; 16&lt;/span&gt; {
&lt;span&gt; 17&lt;/span&gt;     [Foobar]
&lt;span&gt; 18&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;virtual&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Invoke()
&lt;span&gt; 19&lt;/span&gt;     {
&lt;span&gt; 20&lt;/span&gt;         Console.WriteLine(&quot;&lt;span&gt;Demo.Invoke() is invoked&lt;/span&gt;&quot;);
&lt;span&gt; 21&lt;/span&gt;     }
&lt;span&gt; 22&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;执行上面的代码会在控制台上产生如下的输出结果，我们可以看出应用在Domo.Invoke方法上的FoobarInteceptor被正常执行，它依赖的两个服务类型Foo和Bar正好与服务注册一致。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://images2017.cnblogs.com/blog/19327/201801/19327-20180122211508397-1529223463.png&quot;&gt;&lt;img width=&quot;301&quot; height=&quot;132&quot; title=&quot;image&quot; alt=&quot;image&quot; src=&quot;http://images2017.cnblogs.com/blog/19327/201801/19327-20180122211508600-1115291213.png&quot; border=&quot;0&quot;/&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;对于面定义的FoobarInteceptor来说，它依赖的两个服务Foo和Bar实际上是通过构造器注入的方式提供的，实际上我们还具有更加简洁的方案，那就是&lt;span&gt;直接在InvokeAsync方法中对它们进行注入&lt;/span&gt;，这也是我们为什么&lt;span&gt;不为Interceptor定义接口&lt;/span&gt;的原因。如下式FoobarInteceptor最为简洁的定义方式。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;  1&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; FoobarInterceptor
&lt;span&gt;  2&lt;/span&gt; {
&lt;span&gt;  3&lt;/span&gt;     &lt;span&gt;private&lt;/span&gt; InterceptDelegate _next;
&lt;span&gt;  4&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; FoobarInterceptor(InterceptDelegate next)
&lt;span&gt;  5&lt;/span&gt;     {
&lt;span&gt;  6&lt;/span&gt;         _next = next;
&lt;span&gt;  7&lt;/span&gt;     }
&lt;span&gt;  8&lt;/span&gt; 
&lt;span&gt;  9&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; Task InvokeAsync(InvocationContext context, IFoo foo, IBar bar)
&lt;span&gt; 10&lt;/span&gt;     {
&lt;span&gt; 11&lt;/span&gt;         Console.WriteLine(foo);
&lt;span&gt; 12&lt;/span&gt;         Console.WriteLine(bar);
&lt;span&gt; 13&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt; _next(context);
&lt;span&gt; 14&lt;/span&gt;     }
&lt;span&gt; 15&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/artech/p/dora2-01.html&quot;&gt;Dora.Interception,为.NET Core度身打造的AOP框架：全新的版本&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://www.cnblogs.com/artech/p/dora2-02.html&quot;&gt;Dora.Interception, 一个为.NET Core度身打造的AOP框架：不一样的Interceptor定义方式&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 22 Jan 2018 13:15:00 +0000</pubDate>
<dc:creator>Artech</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/artech/p/dora2-02.html</dc:identifier>
</item>
<item>
<title>【Keras】基于SegNet和U-Net的遥感图像语义分割 - Madcola</title>
<link>http://www.cnblogs.com/skyfsm/p/8330882.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/skyfsm/p/8330882.html</guid>
<description>&lt;p&gt;上两个月参加了个比赛，做的是对遥感高清图像做语义分割，美其名曰“天空之眼”。这两周数据挖掘课期末project我们组选的课题也是遥感图像的语义分割，所以刚好又把前段时间做的成果重新整理和加强了一下，故写了这篇文章，记录一下用深度学习做遥感图像语义分割的完整流程以及一些好的思路和技巧。&lt;/p&gt;
&lt;h2 id=&quot;数据集&quot;&gt;数据集&lt;/h2&gt;
&lt;p&gt;首先介绍一下数据，我们这次采用的数据集是CCF大数据比赛提供的数据（2015年中国南方某城市的高清遥感图像），这是一个小数据集，里面包含了5张带标注的大尺寸RGB遥感图像（尺寸范围从3000×3000到6000×6000），里面一共标注了4类物体，植被（标记1）、建筑（标记2）、水体（标记3）、道路（标记4）以及其他(标记0)。其中，耕地、林地、草地均归为植被类，为了更好地观察标注情况，我们将其中三幅训练图片可视化如下：蓝色-水体，黄色-房屋，绿色-植被，棕色-马路。更多数据介绍可以参看&lt;a href=&quot;http://www.datafountain.cn/#/competitions/270/data-intro&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201801/1093303-20180122195923397-779118891.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;现在说一说我们的数据处理的步骤。我们现在拥有的是5张大尺寸的遥感图像，我们不能直接把这些图像送入网络进行训练，因为内存承受不了而且他们的尺寸也各不相同。因此，我们首先将他们做随机切割，即随机生成x,y坐标，然后抠出该坐标下256*256的小图，并做以下数据增强操作：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;原图和label图都需要旋转：90度，180度，270度&lt;/li&gt;
&lt;li&gt;原图和label图都需要做沿y轴的镜像操作&lt;/li&gt;
&lt;li&gt;原图做模糊操作&lt;/li&gt;
&lt;li&gt;原图做光照调整操作&lt;/li&gt;
&lt;li&gt;原图做增加噪声操作（高斯噪声，椒盐噪声）&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;这里我没有采用Keras自带的数据增广函数，而是自己使用opencv编写了相应的增强函数。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;img_w = 256  
img_h = 256  

image_sets = ['1.png','2.png','3.png','4.png','5.png']

def gamma_transform(img, gamma):
    gamma_table = [np.power(x / 255.0, gamma) * 255.0 for x in range(256)]
    gamma_table = np.round(np.array(gamma_table)).astype(np.uint8)
    return cv2.LUT(img, gamma_table)

def random_gamma_transform(img, gamma_vari):
    log_gamma_vari = np.log(gamma_vari)
    alpha = np.random.uniform(-log_gamma_vari, log_gamma_vari)
    gamma = np.exp(alpha)
    return gamma_transform(img, gamma)
    

def rotate(xb,yb,angle):
    M_rotate = cv2.getRotationMatrix2D((img_w/2, img_h/2), angle, 1)
    xb = cv2.warpAffine(xb, M_rotate, (img_w, img_h))
    yb = cv2.warpAffine(yb, M_rotate, (img_w, img_h))
    return xb,yb
    
def blur(img):
    img = cv2.blur(img, (3, 3));
    return img

def add_noise(img):
    for i in range(200): #添加点噪声
        temp_x = np.random.randint(0,img.shape[0])
        temp_y = np.random.randint(0,img.shape[1])
        img[temp_x][temp_y] = 255
    return img
    
    
def data_augment(xb,yb):
    if np.random.random() &amp;lt; 0.25:
        xb,yb = rotate(xb,yb,90)
    if np.random.random() &amp;lt; 0.25:
        xb,yb = rotate(xb,yb,180)
    if np.random.random() &amp;lt; 0.25:
        xb,yb = rotate(xb,yb,270)
    if np.random.random() &amp;lt; 0.25:
        xb = cv2.flip(xb, 1)  # flipcode &amp;gt; 0：沿y轴翻转
        yb = cv2.flip(yb, 1)
        
    if np.random.random() &amp;lt; 0.25:
        xb = random_gamma_transform(xb,1.0)
        
    if np.random.random() &amp;lt; 0.25:
        xb = blur(xb)
    
    if np.random.random() &amp;lt; 0.2:
        xb = add_noise(xb)
        
    return xb,yb

def creat_dataset(image_num = 100000, mode = 'original'):
    print('creating dataset...')
    image_each = image_num / len(image_sets)
    g_count = 0
    for i in tqdm(range(len(image_sets))):
        count = 0
        src_img = cv2.imread('./data/src/' + image_sets[i])  # 3 channels
        label_img = cv2.imread('./data/label/' + image_sets[i],cv2.IMREAD_GRAYSCALE)  # single channel
        X_height,X_width,_ = src_img.shape
        while count &amp;lt; image_each:
            random_width = random.randint(0, X_width - img_w - 1)
            random_height = random.randint(0, X_height - img_h - 1)
            src_roi = src_img[random_height: random_height + img_h, random_width: random_width + img_w,:]
            label_roi = label_img[random_height: random_height + img_h, random_width: random_width + img_w]
            if mode == 'augment':
                src_roi,label_roi = data_augment(src_roi,label_roi)
            
            visualize = np.zeros((256,256)).astype(np.uint8)
            visualize = label_roi *50
            
            cv2.imwrite(('./aug/train/visualize/%d.png' % g_count),visualize)
            cv2.imwrite(('./aug/train/src/%d.png' % g_count),src_roi)
            cv2.imwrite(('./aug/train/label/%d.png' % g_count),label_roi)
            count += 1 
            g_count += 1&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;经过上面数据增强操作后，我们得到了较大的训练集：100000张256*256的图片。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201801/1093303-20180122195951428-440236244.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;卷积神经网络&quot;&gt;卷积神经网络&lt;/h2&gt;
&lt;p&gt;面对这类图像语义分割的任务，我们可以选取的经典网络有很多，比如FCN,U-Net,SegNet,DeepLab,RefineNet,Mask Rcnn,Hed Net这些都是非常经典而且在很多比赛都广泛采用的网络架构。所以我们就可以从中选取一两个经典网络作为我们这个分割任务的解决方案。我们根据我们小组的情况，选取了U-Net和SegNet作为我们的主体网络进行实验。&lt;/p&gt;
&lt;h3 id=&quot;segnet&quot;&gt;SegNet&lt;/h3&gt;
&lt;p&gt;SegNet已经出来好几年了，这不是一个最新、效果最好的语义分割网络，但是它胜在网络结构清晰易懂，训练快速坑少，所以我们也采取它来做同样的任务。SegNet网络结构是编码器-解码器的结构，非常优雅，值得注意的是，SegNet做语义分割时通常在末端加入CRF模块做后处理，旨在进一步精修边缘的分割结果。有兴趣深究的可以看看&lt;a href=&quot;http://www.cnblogs.com/skyfsm/p/8330882.html&quot;&gt;这里&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201801/1093303-20180122200010084-939706515.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;现在讲解代码部分，首先我们先定义好SegNet的网络结构。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def SegNet():  
    model = Sequential()  
    #encoder  
    model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=(3,img_w,img_h),padding='same',activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(64,(3,3),strides=(1,1),padding='same',activation='relu'))  
    model.add(BatchNormalization())  
    model.add(MaxPooling2D(pool_size=(2,2)))  
    #(128,128)  
    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(MaxPooling2D(pool_size=(2, 2)))  
    #(64,64)  
    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(MaxPooling2D(pool_size=(2, 2)))  
    #(32,32)  
    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(MaxPooling2D(pool_size=(2, 2)))  
    #(16,16)  
    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(MaxPooling2D(pool_size=(2, 2)))  
    #(8,8)  
    #decoder  
    model.add(UpSampling2D(size=(2,2)))  
    #(16,16)  
    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(UpSampling2D(size=(2, 2)))  
    #(32,32)  
    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(UpSampling2D(size=(2, 2)))  
    #(64,64)  
    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(UpSampling2D(size=(2, 2)))  
    #(128,128)  
    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(UpSampling2D(size=(2, 2)))  
    #(256,256)  
    model.add(Conv2D(64, (3, 3), strides=(1, 1), input_shape=(3,img_w, img_h), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))  
    model.add(BatchNormalization())  
    model.add(Conv2D(n_label, (1, 1), strides=(1, 1), padding='same'))  
    model.add(Reshape((n_label,img_w*img_h)))  
    #axis=1和axis=2互换位置，等同于np.swapaxes(layer,1,2)  
    model.add(Permute((2,1)))  
    model.add(Activation('softmax'))  
    model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])  
    model.summary()  
    return model  &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后需要读入数据集。这里我们选择的验证集大小是训练集的0.25。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def get_train_val(val_rate = 0.25):
    train_url = []    
    train_set = []
    val_set  = []
    for pic in os.listdir(filepath + 'src'):
        train_url.append(pic)
    random.shuffle(train_url)
    total_num = len(train_url)
    val_num = int(val_rate * total_num)
    for i in range(len(train_url)):
        if i &amp;lt; val_num:
            val_set.append(train_url[i]) 
        else:
            train_set.append(train_url[i])
    return train_set,val_set
    
# data for training  
def generateData(batch_size,data=[]):  
    #print 'generateData...'
    while True:  
        train_data = []  
        train_label = []  
        batch = 0  
        for i in (range(len(data))): 
            url = data[i]
            batch += 1 
            #print (filepath + 'src/' + url)
            #img = load_img(filepath + 'src/' + url, target_size=(img_w, img_h))  
            img = load_img(filepath + 'src/' + url)
            img = img_to_array(img) 
            # print img
            # print img.shape  
            train_data.append(img)  
            #label = load_img(filepath + 'label/' + url, target_size=(img_w, img_h),grayscale=True)
            label = load_img(filepath + 'label/' + url, grayscale=True)
            label = img_to_array(label).reshape((img_w * img_h,))  
            # print label.shape  
            train_label.append(label)  
            if batch % batch_size==0: 
                #print 'get enough bacth!\n'
                train_data = np.array(train_data)  
                train_label = np.array(train_label).flatten()  
                train_label = labelencoder.transform(train_label)  
                train_label = to_categorical(train_label, num_classes=n_label)  
                train_label = train_label.reshape((batch_size,img_w * img_h,n_label))  
                yield (train_data,train_label)  
                train_data = []  
                train_label = []  
                batch = 0  
 
# data for validation 
def generateValidData(batch_size,data=[]):  
    #print 'generateValidData...'
    while True:  
        valid_data = []  
        valid_label = []  
        batch = 0  
        for i in (range(len(data))):  
            url = data[i]
            batch += 1  
            #img = load_img(filepath + 'src/' + url, target_size=(img_w, img_h))
            img = load_img(filepath + 'src/' + url)
            #print img
            #print (filepath + 'src/' + url)
            img = img_to_array(img)  
            # print img.shape  
            valid_data.append(img)  
            #label = load_img(filepath + 'label/' + url, target_size=(img_w, img_h),grayscale=True)
            label = load_img(filepath + 'label/' + url, grayscale=True)
            label = img_to_array(label).reshape((img_w * img_h,))  
            # print label.shape  
            valid_label.append(label)  
            if batch % batch_size==0:  
                valid_data = np.array(valid_data)  
                valid_label = np.array(valid_label).flatten()  
                valid_label = labelencoder.transform(valid_label)  
                valid_label = to_categorical(valid_label, num_classes=n_label)  
                valid_label = valid_label.reshape((batch_size,img_w * img_h,n_label))  
                yield (valid_data,valid_label)  
                valid_data = []  
                valid_label = []  
                batch = 0  &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后定义一下我们训练的过程，在这个任务上，我们把batch size定为16，epoch定为30，每次都存储最佳model(save_best_only=True),并且在训练结束时绘制loss/acc曲线，并存储起来。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def train(args): 
    EPOCHS = 30
    BS = 16
    model = SegNet()  
    modelcheck = ModelCheckpoint(args['model'],monitor='val_acc',save_best_only=True,mode='max')  
    callable = [modelcheck]  
    train_set,val_set = get_train_val()
    train_numb = len(train_set)  
    valid_numb = len(val_set)  
    print (&quot;the number of train data is&quot;,train_numb)  
    print (&quot;the number of val data is&quot;,valid_numb)
    H = model.fit_generator(generator=generateData(BS,train_set),steps_per_epoch=train_numb//BS,epochs=EPOCHS,verbose=1,  
                    validation_data=generateValidData(BS,val_set),validation_steps=valid_numb//BS,callbacks=callable,max_q_size=1)  

    # plot the training loss and accuracy
    plt.style.use(&quot;ggplot&quot;)
    plt.figure()
    N = EPOCHS
    plt.plot(np.arange(0, N), H.history[&quot;loss&quot;], label=&quot;train_loss&quot;)
    plt.plot(np.arange(0, N), H.history[&quot;val_loss&quot;], label=&quot;val_loss&quot;)
    plt.plot(np.arange(0, N), H.history[&quot;acc&quot;], label=&quot;train_acc&quot;)
    plt.plot(np.arange(0, N), H.history[&quot;val_acc&quot;], label=&quot;val_acc&quot;)
    plt.title(&quot;Training Loss and Accuracy on SegNet Satellite Seg&quot;)
    plt.xlabel(&quot;Epoch #&quot;)
    plt.ylabel(&quot;Loss/Accuracy&quot;)
    plt.legend(loc=&quot;lower left&quot;)
    plt.savefig(args[&quot;plot&quot;])&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后开始漫长的训练，训练时间接近3天，绘制出的loss/acc图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201801/1093303-20180122200128600-1120913610.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;训练loss降到0.1左右，acc可以去到0.9,但是验证集的loss和acc都没那么好，貌似存在点问题。&lt;/p&gt;
&lt;p&gt;先不管了，先看看预测结果吧。&lt;/p&gt;
&lt;p&gt;这里需要思考一下怎么预测整张遥感图像。我们知道，我们训练模型时选择的图片输入是256×256，所以我们预测时也要采用256×256的图片尺寸送进模型预测。现在我们要考虑一个问题，我们该怎么将这些预测好的小图重新拼接成一个大图呢？这里给出一个最基础的方案：先给大图做padding 0操作，得到一副padding过的大图，同时我们也生成一个与该图一样大的全0图A，把图像的尺寸补齐为256的倍数，然后以256为步长切割大图，依次将小图送进模型预测，预测好的小图则放在A的相应位置上，依次进行，最终得到预测好的整张大图（即A），再做图像切割，切割成原先图片的尺寸，完成整个预测流程。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def predict(args):
    # load the trained convolutional neural network
    print(&quot;[INFO] loading network...&quot;)
    model = load_model(args[&quot;model&quot;])
    stride = args['stride']
    for n in range(len(TEST_SET)):
        path = TEST_SET[n]
        #load the image
        image = cv2.imread('./test/' + path)
        # pre-process the image for classification
        #image = image.astype(&quot;float&quot;) / 255.0
        #image = img_to_array(image)
        h,w,_ = image.shape
        padding_h = (h//stride + 1) * stride 
        padding_w = (w//stride + 1) * stride
        padding_img = np.zeros((padding_h,padding_w,3),dtype=np.uint8)
        padding_img[0:h,0:w,:] = image[:,:,:]
        padding_img = padding_img.astype(&quot;float&quot;) / 255.0
        padding_img = img_to_array(padding_img)
        print 'src:',padding_img.shape
        mask_whole = np.zeros((padding_h,padding_w),dtype=np.uint8)
        for i in range(padding_h//stride):
            for j in range(padding_w//stride):
                crop = padding_img[:3,i*stride:i*stride+image_size,j*stride:j*stride+image_size]
                _,ch,cw = crop.shape
                if ch != 256 or cw != 256:
                    print 'invalid size!'
                    continue
                    
                crop = np.expand_dims(crop, axis=0)
                #print 'crop:',crop.shape
                pred = model.predict_classes(crop,verbose=2)  
                pred = labelencoder.inverse_transform(pred[0])  
                #print (np.unique(pred))  
                pred = pred.reshape((256,256)).astype(np.uint8)
                #print 'pred:',pred.shape
                mask_whole[i*stride:i*stride+image_size,j*stride:j*stride+image_size] = pred[:,:]

        
        cv2.imwrite('./predict/pre'+str(n+1)+'.png',mask_whole[0:h,0:w])&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;预测的效果图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201801/1093303-20180122200146006-1269356171.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;一眼看去，效果真的不错，但是仔细看一下，就会发现有个很大的问题：拼接痕迹过于明显了！那怎么解决这类边缘问题呢？很直接的想法就是缩小切割时的滑动步伐，比如我们把切割步伐改为128，那么拼接时就会有一般的图像发生重叠，这样做可以尽可能地减少拼接痕迹。&lt;/p&gt;
&lt;h3 id=&quot;u-net&quot;&gt;U-Net&lt;/h3&gt;
&lt;p&gt;对于这个语义分割任务，我们毫不犹豫地选择了U-Net作为我们的方案，原因很简单，我们参考很多类似的遥感图像分割比赛的资料，绝大多数获奖的选手使用的都是U-Net模型。在这么多的好评下，我们选择U-Net也就毫无疑问了。&lt;/p&gt;
&lt;p&gt;U-Net有很多优点，最大卖点就是它可以在小数据集上也能train出一个好的模型，这个优点对于我们这个任务来说真的非常适合。而且，U-Net在训练速度上也是非常快的，这对于需要短时间就得出结果的期末project来说也是非常合适。U-Net在网络架构上还是非常优雅的，整个呈现U形，故起名U-Net。这里不打算详细介绍U-Net结构，有兴趣的深究的可以看看论文。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201801/1093303-20180122200158397-1275935789.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;现在开始谈谈代码细节。首先我们定义一下U-Net的网络结构，这里用的deep learning框架还是Keras。&lt;/p&gt;
&lt;p&gt;注意到，我们这里训练的模型是一个多分类模型，其实更好的做法是，训练一个二分类模型（使用二分类的标签），对每一类物体进行预测，得到4张预测图，再做预测图叠加，合并成一张完整的包含4类的预测图，这个策略在效果上肯定好于一个直接4分类的模型。所以，U-Net这边我们采取的思路就是对于每一类的分类都训练一个二分类模型，最后再将每一类的预测结果组合成一个四分类的结果。&lt;/p&gt;
&lt;p&gt;定义U-Net结构，注意了，这里的loss function我们选了binary_crossentropy，因为我们要训练的是二分类模型。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def unet():
    inputs = Input((3, img_w, img_h))

    conv1 = Conv2D(32, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(inputs)
    conv1 = Conv2D(32, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(conv1)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)

    conv2 = Conv2D(64, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(pool1)
    conv2 = Conv2D(64, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(conv2)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    conv3 = Conv2D(128, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(pool2)
    conv3 = Conv2D(128, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(conv3)
    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)

    conv4 = Conv2D(256, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(pool3)
    conv4 = Conv2D(256, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(conv4)
    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)

    conv5 = Conv2D(512, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(pool4)
    conv5 = Conv2D(512, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(conv5)

    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=1)
    conv6 = Conv2D(256, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(up6)
    conv6 = Conv2D(256, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(conv6)

    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=1)
    conv7 = Conv2D(128, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(up7)
    conv7 = Conv2D(128, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(conv7)

    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=1)
    conv8 = Conv2D(64, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(up8)
    conv8 = Conv2D(64, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(conv8)

    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=1)
    conv9 = Conv2D(32, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(up9)
    conv9 = Conv2D(32, (3, 3), activation=&quot;relu&quot;, padding=&quot;same&quot;)(conv9)

    conv10 = Conv2D(n_label, (1, 1), activation=&quot;sigmoid&quot;)(conv9)
    #conv10 = Conv2D(n_label, (1, 1), activation=&quot;softmax&quot;)(conv9)

    model = Model(inputs=inputs, outputs=conv10)
    model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;读取数据的组织方式有一些改动。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;# data for training  
def generateData(batch_size,data=[]):  
    #print 'generateData...'
    while True:  
        train_data = []  
        train_label = []  
        batch = 0  
        for i in (range(len(data))): 
            url = data[i]
            batch += 1 
            img = load_img(filepath + 'src/' + url)
            img = img_to_array(img) 
            train_data.append(img)  
            label = load_img(filepath + 'label/' + url, grayscale=True) 
            label = img_to_array(label)
            #print label.shape  
            train_label.append(label)  
            if batch % batch_size==0: 
                #print 'get enough bacth!\n'
                train_data = np.array(train_data)  
                train_label = np.array(train_label)  

                yield (train_data,train_label)  
                train_data = []  
                train_label = []  
                batch = 0  
 
# data for validation 
def generateValidData(batch_size,data=[]):  
    #print 'generateValidData...'
    while True:  
        valid_data = []  
        valid_label = []  
        batch = 0  
        for i in (range(len(data))):  
            url = data[i]
            batch += 1  
            img = load_img(filepath + 'src/' + url)
            #print img
            img = img_to_array(img)  
            # print img.shape  
            valid_data.append(img)  
            label = load_img(filepath + 'label/' + url, grayscale=True)
            valid_label.append(label)  
            if batch % batch_size==0:  
                valid_data = np.array(valid_data)  
                valid_label = np.array(valid_label)  
                yield (valid_data,valid_label)  
                valid_data = []  
                valid_label = []  
                batch = 0  &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;训练：指定输出model名字和训练集位置&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;python unet.py --model unet_buildings20.h5 --data ./unet_train/buildings/&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;预测单张遥感图像时我们分别使用4个模型做预测，那我们就会得到4张mask（比如下图就是我们用训练好的buildings模型预测的结果），我们现在要将这4张mask合并成1张，那么怎么合并会比较好呢？我思路是，通过观察每一类的预测结果，我们可以从直观上知道哪些类的预测比较准确，那么我们就可以给这些mask图排优先级了，比如：priority:building&amp;gt;water&amp;gt;road&amp;gt;vegetation，那么当遇到一个像素点，4个mask图都说是属于自己类别的标签时，我们就可以根据先前定义好的优先级，把该像素的标签定为优先级最高的标签。代码思路可以参照下面的代码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201801/1093303-20180122200215381-147830523.png&quot;/&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def combind_all_mask():
    for mask_num in tqdm(range(3)):
        if mask_num == 0:
            final_mask = np.zeros((5142,5664),np.uint8)#生成一个全黑全0图像,图片尺寸与原图相同
        elif mask_num == 1:
            final_mask = np.zeros((2470,4011),np.uint8)
        elif mask_num == 2:
            final_mask = np.zeros((6116,3356),np.uint8)
        #final_mask = cv2.imread('final_1_8bits_predict.png',0)
        
        if mask_num == 0:
            mask_pool = mask1_pool
        elif mask_num == 1:
            mask_pool = mask2_pool
        elif mask_num == 2:
            mask_pool = mask3_pool
        final_name = img_sets[mask_num]
        for idx,name in enumerate(mask_pool):
            img = cv2.imread('./predict_mask/'+name,0)
            height,width = img.shape
            label_value = idx+1  #coressponding labels value
            for i in tqdm(range(height)):    #priority:building&amp;gt;water&amp;gt;road&amp;gt;vegetation
                for j in range(width):
                    if img[i,j] == 255:
                        if label_value == 2:
                            final_mask[i,j] = label_value
                        elif label_value == 3 and final_mask[i,j] != 2:
                            final_mask[i,j] = label_value
                        elif label_value == 4 and final_mask[i,j] != 2 and final_mask[i,j] != 3:
                            final_mask[i,j] = label_value
                        elif label_value == 1 and final_mask[i,j] == 0:
                            final_mask[i,j] = label_value
                        
        cv2.imwrite('./final_result/'+final_name,final_mask)           
                
                
print 'combinding mask...'
combind_all_mask()            &lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;模型融合&quot;&gt;模型融合&lt;/h2&gt;
&lt;p&gt;集成学习的方法在这类比赛中经常使用，要想获得好成绩集成学习必须做得好。在这里简单谈谈思路，我们使用了两个模型，我们模型也会采取不同参数去训练和预测，那么我们就会得到很多预测MASK图，此时 我们可以采取模型融合的思路，对每张结果图的每个像素点采取投票表决的思路，对每张图相应位置的像素点的类别进行预测，票数最多的类别即为该像素点的类别。正所谓“三个臭皮匠，胜过诸葛亮”，我们这种ensemble的思路，可以很好地去掉一些明显分类错误的像素点，很大程度上改善模型的预测能力。&lt;/p&gt;
&lt;p&gt;少数服从多数的投票表决策略代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;import numpy as np
import cv2
import argparse

RESULT_PREFIXX = ['./result1/','./result2/','./result3/']

# each mask has 5 classes: 0~4

def vote_per_image(image_id):
    result_list = []
    for j in range(len(RESULT_PREFIXX)):
        im = cv2.imread(RESULT_PREFIXX[j]+str(image_id)+'.png',0)
        result_list.append(im)
        
    # each pixel
    height,width = result_list[0].shape
    vote_mask = np.zeros((height,width))
    for h in range(height):
        for w in range(width):
            record = np.zeros((1,5))
            for n in range(len(result_list)):
                mask = result_list[n]
                pixel = mask[h,w]
                #print('pix:',pixel)
                record[0,pixel]+=1
           
            label = record.argmax()
            #print(label)
            vote_mask[h,w] = label
    
    cv2.imwrite('vote_mask'+str(image_id)+'.png',vote_mask)
        

vote_per_image(3)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;模型融合后的预测结果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201801/1093303-20180122200243959-296384411.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看出，模型融合后的预测效果确实有较大提升，明显错误分类的像素点消失了。&lt;/p&gt;
&lt;h3 id=&quot;额外的思路gan&quot;&gt;额外的思路：GAN&lt;/h3&gt;
&lt;p&gt;我们对数据方面思考得更多一些，我们针对数据集小的问题，我们有个想法：使用生成对抗网络去生成虚假的卫星地图，旨在进一步扩大数据集。我们的想法就是，使用这些虚假+真实的数据集去训练网络，网络的泛化能力肯定有更大的提升。我们的想法是根据&lt;a href=&quot;https://phillipi.github.io/pix2pix/&quot;&gt;这篇论文(pix2pix)&lt;/a&gt;来展开的，这是一篇很有意思的论文，它主要讲的是用图像生成图像的方法。里面提到了用标注好的卫星地图生成虚假的卫星地图的想法，真的让人耳目一新，我们也想根据该思路，生成属于我们的虚假卫星地图数据集。 Map to Aerial的效果是多么的震撼。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201801/1093303-20180122200259569-1429688039.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201801/1093303-20180122200312209-1732526873.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201801/1093303-20180122200326709-896300708.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;但是我们自己实现起来的效果却不容乐观（如下图所示，右面那幅就是我们生成的假图），效果不好的原因有很多，标注的问题最大，因为生成的虚假卫星地图质量不好，所以该想法以失败告终，生成的假图也没有拿去做训练。但感觉思路还是可行的，如果给的标注合适的话，还是可以生成非常像的虚假地图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201801/1093303-20180122200346053-895103023.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;对于这类遥感图像的语义分割，思路还有很多，最容易想到的思路就是，将各种语义分割经典网络都实现以下，看看哪个效果最好，再做模型融合，只要集成学习做得好，效果一般都会很不错的。我们仅靠上面那个简单思路（数据增强，经典模型搭建，集成学习），就已经可以获得比赛的TOP 1%了，当然还有一些tricks可以使效果更进一步提升，这里就不细说了，总的建模思路掌握就行。完整的代码可以在&lt;a href=&quot;https://github.com/AstarLight/Satellite-Segmentation&quot;&gt;我的github&lt;/a&gt;获取。&lt;/p&gt;
</description>
<pubDate>Mon, 22 Jan 2018 12:05:00 +0000</pubDate>
<dc:creator>Madcola</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/skyfsm/p/8330882.html</dc:identifier>
</item>
<item>
<title>SQL Server 加密案例解析 - pursuer.chen</title>
<link>http://www.cnblogs.com/chenmh/p/8309176.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/chenmh/p/8309176.html</guid>
<description>&lt;h2&gt;一、概述&lt;/h2&gt;
&lt;p&gt;加密是一种安全措施，有时候甚至是法律要求。作为攻破Windows系统的最后一道防线，通过加密可以保证在没有密钥的情况下获取备份或者物理介质变得毫无意义。&lt;/p&gt;

&lt;h2&gt;二、概念&lt;/h2&gt;
&lt;p&gt;加密层次结构&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/135426/201801/135426-20180118112658865-682290308.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;加密层次结构的每一层是如何对它下面的一层进行加密的，并且显示了最常用的加密配置。对层次结构的开始进行的访问通常受密码保护。SQL Server 用分层加密和密钥管理基础结构来加密数据。每一层都使用证书、非对称密钥和对称密钥的组合对它下面的一层进行加密。非对称密钥和对称密钥可以存储在 SQL Server 之外的可扩展密钥管理 (EKM) 模块中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&lt;/p&gt;
&lt;ul readability=&quot;5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span data-ttu-id=&quot;97b57-110&quot;&gt;为了获得最佳性能，使用对称密钥（而不是证书或非对称密钥）加密数据。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p class=&quot;x-hidden-focus&quot;&gt;&lt;span data-ttu-id=&quot;97b57-111&quot;&gt;数据库主密钥受服务主密钥保护。 &lt;span data-ttu-id=&quot;97b57-112&quot;&gt;服务主密钥由 &lt;span data-ttu-id=&quot;ca4b0-101&quot;&gt;SQL Server 安装程序创建，并且使用 Windows 数据保护 API (DPAPI) 进行加密。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span data-ttu-id=&quot;97b57-113&quot;&gt;堆叠其他层的其他加密层次结构是可能的。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span data-ttu-id=&quot;97b57-114&quot;&gt;可扩展密钥管理 (EKM) 模块将对称密钥或非对称密钥保存在 SQL Server 的外部。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span class=&quot;x-hidden-focus&quot; data-ttu-id=&quot;97b57-115&quot;&gt;透明数据加密 (TDE) 必须使用称为数据库加密密钥的对称密钥，该密钥受由 master 数据库的数据库主密钥保护的证书保护，或者受存储在 EKM 中的非对称密钥保护。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p class=&quot;x-hidden-focus&quot;&gt;&lt;span class=&quot;x-hidden-focus&quot; data-ttu-id=&quot;97b57-116&quot;&gt;服务主密钥和所有数据库主密钥是对称密钥。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;span class=&quot;x-hidden-focus&quot; data-ttu-id=&quot;97b57-116&quot;&gt;1.服务主密钥(Service Master Key)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span class=&quot;x-hidden-focus&quot; data-ttu-id=&quot;97b57-116&quot;&gt;每一个实例只有一个服务主密钥，服务主密钥用于加密数据库主密钥，服务主密钥为 SQL Server 加密层次结构的根。服务主密钥是首次需要它来加密其他密钥时自动生成的。默认情况下，服务主密钥使用 Windows 数据保护 API 和本地计算机密钥进行加密。只有创建服务主密钥的 Windows 服务帐户或有权访问服务帐户名称和密码的主体能够打开服务主密钥。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-备份服务主密钥&lt;/span&gt;
&lt;span&gt;BACKUP&lt;/span&gt; SERVICE MASTER &lt;span&gt;KEY&lt;/span&gt; &lt;span&gt;TO&lt;/span&gt; &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;D:\DECRYPTION\ServerMasterKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt; 
    ENCRYPTION &lt;/span&gt;&lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;password&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;

&lt;span&gt;--&lt;/span&gt;&lt;span&gt;--还原服务主密钥&lt;/span&gt;
&lt;span&gt;RESTORE&lt;/span&gt; SERVICE MASTER &lt;span&gt;KEY&lt;/span&gt; &lt;span&gt;FROM&lt;/span&gt; &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;D:\DECRYPTION\ServerMasterKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;
    DECRYPTION &lt;/span&gt;&lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;password&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; 
    &lt;span&gt;[&lt;/span&gt;&lt;span&gt;FORCE&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;;   &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--即使存在数据丢失的风险，也要强制替换服务主密钥。&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&lt;br/&gt;1.服务主密钥直接或间接地保护树中的所有其他密钥。如果在强制的还原过程中不能对某个相关密钥进行解密，则由该密钥所保护的数据便会丢失。&lt;br/&gt;2.重新生成加密层次结构是一种消耗大量资源的操作。您应当将该操作安排在资源需求较低的时段进行。&lt;br/&gt;3.当还原服务主密钥时，SQL Server 将对所有已使用当前服务主密钥加密的密钥和机密内容进行解密，然后使用从备份文件中加载的服务主密钥对这些密钥和机密内容进行加密。&lt;/p&gt;
&lt;h3&gt;&lt;span class=&quot;x-hidden-focus&quot; data-ttu-id=&quot;97b57-116&quot;&gt;2.数据库主密钥&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;数据库主密钥创建于对应数据库下，具体的保护对象可以参考下面的数据库范围的安全对象。如果要对数据库备份或者透明数据库加密那么需要将服务主密钥创建于Master数据库下。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;--1.创建数据库主密钥&lt;/span&gt;
&lt;span&gt;USE&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;master&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;
&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;CREATE&lt;/span&gt; MASTER &lt;span&gt;KEY&lt;/span&gt; ENCRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-2.删除数据库主密钥&lt;/span&gt;
&lt;span&gt;DROP&lt;/span&gt; MASTER &lt;span&gt;KEY&lt;/span&gt;

&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-3.备份数据库主密钥&lt;/span&gt;&lt;span&gt;
/*&lt;/span&gt;&lt;span&gt;
主密钥必须为打开状态，因此在备份主密钥之前应对其进行解密。如果主密钥使用服务主密钥进行加密，则不必显式打开。但如果主密钥仅使用密码进行加密，则必须显式打开。
建议在创建主密钥之后立即对其进行备份，并存储于另外一个安全的位置中。
&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;

&lt;span&gt;OPEN&lt;/span&gt; MASTER &lt;span&gt;KEY&lt;/span&gt; DECRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;; &lt;span&gt;--&lt;/span&gt;&lt;span&gt;-打开数据库主密钥,这里的密码为创建主密钥时设的密码&lt;/span&gt;
&lt;span&gt;BACKUP&lt;/span&gt; MASTER &lt;span&gt;KEY&lt;/span&gt; &lt;span&gt;TO&lt;/span&gt; &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;D:\DECRYPTION\MasterKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;--&lt;/span&gt;&lt;span&gt;---主密钥私钥文件&lt;/span&gt;
    ENCRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;;             &lt;span&gt;--&lt;/span&gt;&lt;span&gt;---加密主密钥私钥文件&lt;/span&gt;
&lt;span&gt;GO&lt;/span&gt; 
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-4.还原数据库主密钥&lt;/span&gt;&lt;span&gt;
/*&lt;/span&gt;&lt;span&gt;
还原主密钥之后，SQL Server 会对使用当前活动的主密钥加密的所有密钥进行解密，然后使用还原后的主密钥对这些密钥进行加密。这种大量消耗资源的操作应当安排在资源需求较低的时段执行。如果当前的数据库主密钥未打开或无法打开，或者无法对任何使用该主密钥加密的密钥进行解密，则还原操作将失败。
如果当前数据库中没有主密钥，则 RESTORE MASTER KEY 将创建一个主密钥。新的主密钥不会自动使用服务主密钥进行加密。
请仅在主密钥无法恢复或解密失败时，才使用 FORCE 选项。仅由不可恢复密钥加密的信息将会丢失。
如果主密钥通过服务主密钥进行加密，则还原后的主密钥也通过该服务主密钥进行加密(当前服务器)。
&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;RESTORE&lt;/span&gt; MASTER &lt;span&gt;KEY&lt;/span&gt;  
&lt;span&gt;FROM&lt;/span&gt; &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\MasterKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt; 
DECRYPTION &lt;/span&gt;&lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;  
ENCRYPTION &lt;/span&gt;&lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey123&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;  &lt;span&gt;--&lt;/span&gt;&lt;span&gt;-加密导出的主密钥&lt;/span&gt;&lt;span&gt;
--&lt;/span&gt;&lt;span&gt;force;        ----指定即使当前数据库主密钥未打开，或者 SQL Server 无法对使用该主密钥加密的某些私钥进行解密，RESTORE 过程也应继续执行。&lt;/span&gt;
&lt;span&gt;GO&lt;/span&gt; 

&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-5.打开数据库主密钥&lt;/span&gt;
&lt;span&gt;OPEN&lt;/span&gt; MASTER &lt;span&gt;KEY&lt;/span&gt; DECRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey123&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;  

&lt;span&gt;GO&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.数据库主密钥是指用于保护证书私钥的对称密钥以及数据库中存在的非对称密钥。当创建主密钥时，会使用 Triple DES 算法以及用户提供的密码对其进行加密。&lt;br/&gt;2.请使用服务主密钥对该主密钥的副本进行加密，并将副本存储在数据库和 master 中。通常，每当主密钥更改时，便会在不进行提示的情况下更新存储在 master 中的副本。&lt;br/&gt;3.在当前服务器下创建的数据库主密钥默认就使用了服务主密钥加密和自动解密，不必使用 OPEN MASTER KEY 语句。如果还原到了新的服务器那么服务主密钥则不存在.必须使用 OPEN MASTER KEY 语句解密数据库主密钥。一旦数据库主密钥解密后，通过使用 ALTER MASTER KEY 语句向服务器提供数据库主密钥（使用服务主密钥加密）的副本，即可拥有将来启用自动解密的选项。&lt;br/&gt;4.通过使用带 DROP ENCRYPTION BY SERVICE MASTER KEY 选项的 ALTER MASTER KEY 语句，可从自动密钥管理中排除特定数据库的数据库主密钥。然后，必须显式打开带密码的数据库主密钥。&lt;br/&gt;5.数据库主密钥使用公钥对证书、非对称密钥进行加密，使用私钥进行解密，如果在当前创建的服务器上默认自动解密，如果还原到一台新的服务上时可能需要使用OPEN MASTER KEY进行解密。&lt;/p&gt;
&lt;h3&gt;&lt;span class=&quot;x-hidden-focus&quot; data-ttu-id=&quot;97b57-116&quot;&gt;3.证书&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt; 证书使用公钥对安全对象进行加密,使用私钥进行解密,默认证书存在就自动解密。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;45&quot;&gt;
&lt;pre&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;--1.创建自我签名的证书,使用数据库主密钥进行加密证书&lt;/span&gt;
&lt;span&gt;USE&lt;/span&gt;&lt;span&gt; MASTER;
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;CREATE&lt;/span&gt;&lt;span&gt; CERTIFICATE MyCerts 
   &lt;/span&gt;&lt;span&gt;WITH&lt;/span&gt; SUBJECT &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;BackDB Records&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;, 
   EXPIRY_DATE &lt;/span&gt;&lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;10/31/2099&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;;            &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--证书过期时间，不指定开始时间默认开始时间为当前时间&lt;/span&gt;
&lt;span&gt;GO&lt;/span&gt;

&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-使用密码进行加密证书&lt;/span&gt;
&lt;span&gt;USE&lt;/span&gt;&lt;span&gt; MASTER;
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;CREATE&lt;/span&gt;&lt;span&gt; CERTIFICATE CertsByPW 
   ENCRYPTION &lt;/span&gt;&lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;CertsByPW111&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
   &lt;span&gt;WITH&lt;/span&gt; SUBJECT &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;BackDB Records&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;, 
   EXPIRY_DATE &lt;/span&gt;&lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;10/31/2099&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;;            &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--证书过期时间，不指定开始时间默认开始时间为当前时间&lt;/span&gt;
&lt;span&gt;GO&lt;/span&gt;

&lt;span&gt;--&lt;/span&gt;&lt;span&gt;--2.备份证书&lt;/span&gt;&lt;span&gt;
--&lt;/span&gt;&lt;span&gt;--警告: 用于对数据库加密密钥进行加密的证书尚未备份。应当立即备份该证书以及与该证书关联的私钥。如果该证书不可用，或者您必须在另一台服务器上还原或附加数据库，则必须对该证书和私钥均进行备份，否则将无法打开该数据库。&lt;/span&gt;
&lt;span&gt;BACKUP&lt;/span&gt; CERTIFICATE MyCerts &lt;span&gt;TO&lt;/span&gt; &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;D:\DECRYPTION\MyCerts&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--证书文件&lt;/span&gt;
    &lt;span&gt;WITH&lt;/span&gt; PRIVATE &lt;span&gt;KEY&lt;/span&gt; ( &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;D:\DECRYPTION\MyCertsKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; ,   &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--证书私钥文件&lt;/span&gt;
                       ENCRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;MyCerts123&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; ); &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--对私钥文件加密&lt;/span&gt;
&lt;span&gt;GO&lt;/span&gt;

&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-备份使用私钥进行加密的证书,必须先对私钥进行解密&lt;/span&gt;
&lt;span&gt;BACKUP&lt;/span&gt; CERTIFICATE CertsByPW &lt;span&gt;TO&lt;/span&gt; &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;D:\DECRYPTION\MyCerts&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--证书文件&lt;/span&gt;
    &lt;span&gt;WITH&lt;/span&gt; PRIVATE &lt;span&gt;KEY&lt;/span&gt; ( DECRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;CertsByPW111&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,&lt;span&gt;--&lt;/span&gt;&lt;span&gt;--解密证书&lt;/span&gt;
                       &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;D:\DECRYPTION\MyCertsKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; ,   &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--证书私钥文件&lt;/span&gt;
                       ENCRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;MyCerts123&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; ); &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--对私钥文件加密&lt;/span&gt;
&lt;span&gt;GO&lt;/span&gt;

&lt;span&gt;--&lt;/span&gt;&lt;span&gt;--3.通过备份文件创建证书,还原证书,&lt;/span&gt;
&lt;span&gt;CREATE&lt;/span&gt; CERTIFICATE MyCerts &lt;span&gt;FROM&lt;/span&gt; &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\MyCerts&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--证书文件&lt;/span&gt;
    &lt;span&gt;WITH&lt;/span&gt; PRIVATE &lt;span&gt;KEY&lt;/span&gt; ( &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\MyCertsKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; ,    &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--证书私钥文件&lt;/span&gt;
    DECRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;MyCerts123&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; );                  &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--解密私钥文件&lt;/span&gt;


&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-4.删除证书&lt;/span&gt;
&lt;span&gt;DROP&lt;/span&gt; CERTIFICATE MyCerts 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当使用数据库主密钥对私钥进行加密时，不需要 ENCRYPTION BY PASSWORD 选项。&lt;/p&gt;
&lt;p&gt;只有在使用密码对私钥进行加密时，才使用该选项。&lt;/p&gt;
&lt;p&gt;如果未指定密码，则使用数据库主密钥对证书的私钥进行加密。 如果数据库主密钥无法打开，则省略该子句会导致错误。&lt;/p&gt;
&lt;h3&gt;&lt;span class=&quot;x-hidden-focus&quot; data-ttu-id=&quot;97b57-116&quot;&gt;4.非对称密钥&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;“非对称密钥”是数据库级的安全对象实体。该实体的默认格式包含公钥和私钥。当未使用 FROM 子句执行时，CREATE ASYMMETRIC KEY 会生成新的密钥对。当使用 FROM 子句执行时，CREATE ASYMMETRIC KEY 会从文件中导入密钥对，或从程序集中导入公钥。&lt;br/&gt;默认情况下，私钥受数据库主密钥保护。如果尚未创建任何数据库主密钥，则需要使用密码保护私钥。如果不存在数据库主密钥，则可以选择性地使用密码。&lt;/p&gt;
&lt;p&gt;通常使用RSA加密算法，RSA_512、RSA_1024、RSA_2048。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-1.创建非对称密钥；非对称密钥可以由密码、数据库主密钥、EKM模块加密&lt;/span&gt;&lt;span&gt;
--&lt;/span&gt;&lt;span&gt;使用密码加密&lt;/span&gt;
&lt;span&gt;CREATE&lt;/span&gt; ASYMMETRIC &lt;span&gt;KEY&lt;/span&gt;&lt;span&gt; AsymmetricByPW
    &lt;/span&gt;&lt;span&gt;WITH&lt;/span&gt; ALGORITHM &lt;span&gt;=&lt;/span&gt; RSA_2048   &lt;span&gt;--&lt;/span&gt;&lt;span&gt;-使用RSA_2048加密算法&lt;/span&gt;
    ENCRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;AsymmetricByPW111&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;; 
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;2.通过文件创建非对称密钥&lt;/span&gt;
&lt;span&gt;CREATE&lt;/span&gt; ASYMMETRIC &lt;span&gt;KEY&lt;/span&gt;&lt;span&gt; AsymmetricByFile 
    &lt;/span&gt;&lt;span&gt;AUTHORIZATION&lt;/span&gt; Christina &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--授予Christina用户使用该非对称密钥&lt;/span&gt;
    &lt;span&gt;FROM&lt;/span&gt; &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;c:\PacSales\Managers\ChristinaCerts.tmp&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;  
    ENCRYPTION &lt;/span&gt;&lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;AsymmetricByFile111&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-3.使用数据库主密钥加密&lt;/span&gt;
&lt;span&gt;CREATE&lt;/span&gt; ASYMMETRIC &lt;span&gt;KEY&lt;/span&gt;&lt;span&gt; AsymmetricByMasterKey
    &lt;/span&gt;&lt;span&gt;WITH&lt;/span&gt; ALGORITHM &lt;span&gt;=&lt;/span&gt; RSA_2048;   &lt;span&gt;--&lt;/span&gt;&lt;span&gt;-使用RSA_2048加密算法&lt;/span&gt;

&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-4.删除非对称密钥&lt;/span&gt;
&lt;span&gt;DROP&lt;/span&gt; ASYMMETRIC &lt;span&gt;KEY&lt;/span&gt;&lt;span&gt; AsymmetricByPW
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;span class=&quot;x-hidden-focus&quot; data-ttu-id=&quot;97b57-116&quot;&gt;5.对称密钥&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;创建对称密钥时，必须至少使用以下项之一来对该对称密钥进行加密：证书、密码、对称密钥、非对称密钥或 PROVIDER。可使用上述每种类型中的多项对密钥进行加密。换言之，可以同时使用多个证书、密码、对称密钥以及非对称密钥对单个对称密钥进行加密&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;x-hidden-focus&quot; data-ttu-id=&quot;97b57-116&quot;&gt;通常使用AES算法，有AES_128、AES_192、AES_256&lt;/span&gt;&lt;/p&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;1.创建对称密钥，对称密钥可以由密码、非对称密钥、对称密钥、EKM模块加密&lt;/span&gt;&lt;span&gt;
--&lt;/span&gt;&lt;span&gt;-使用密码加密&lt;/span&gt;
&lt;span&gt;CREATE&lt;/span&gt; SYMMETRIC &lt;span&gt;KEY&lt;/span&gt;&lt;span&gt; SymmetricByPW
    &lt;/span&gt;&lt;span&gt;WITH&lt;/span&gt; ALGORITHM &lt;span&gt;=&lt;/span&gt;&lt;span&gt; AES_256
    ENCRYPTION &lt;/span&gt;&lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;SymmetricByPW111&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;注意:当使用密码（而不是数据库主密钥的公钥）对对称密钥进行加密时，便会使用 TRIPLE DES 加密算法。因此，用强加密算法（如 AES）创建的密钥本身受较弱算法的保护。&lt;/span&gt;&lt;span&gt;
--&lt;/span&gt;&lt;span&gt;-2.使用证书加密&lt;/span&gt;
&lt;span&gt;CREATE&lt;/span&gt; SYMMETRIC &lt;span&gt;KEY&lt;/span&gt;&lt;span&gt; SymmetricByCert
    &lt;/span&gt;&lt;span&gt;WITH&lt;/span&gt; ALGORITHM &lt;span&gt;=&lt;/span&gt;&lt;span&gt; AES_256
    ENCRYPTION &lt;/span&gt;&lt;span&gt;BY&lt;/span&gt;&lt;span&gt; CERTIFICATE MyCerts;

&lt;/span&gt;&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-3.删除非对称密钥&lt;/span&gt;
&lt;span&gt;DROP&lt;/span&gt; SYMMETRIC &lt;span&gt;KEY&lt;/span&gt;&lt;span&gt; TestSymmetric
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;三、安全对象&lt;/h2&gt;
&lt;p&gt;安全对象是 SQL Server 数据库引擎授权系统控制对其进行访问的资源。通过创建可以为自己设置安全性的名为“范围”的嵌套层次结构，可以将某些安全对象包含在其他安全对象中。安全对象范围有服务器、数据库和架构。&lt;/p&gt;
&lt;h3 class=&quot;heading&quot;&gt;&lt;span&gt;1.安全对象范围：服务器&lt;/span&gt;&lt;/h3&gt;
&lt;div id=&quot;sectionSection0&quot; class=&quot;section&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;包含以下安全对象：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;端点&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;登录帐户&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;数据库&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;h3 class=&quot;heading&quot;&gt;&lt;span&gt;2.安全对象范围：数据库&lt;/span&gt;&lt;/h3&gt;
&lt;div id=&quot;sectionSection1&quot; class=&quot;section&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;包含以下安全对象：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;用户&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;角色&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;应用程序角色&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;程序集&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;消息类型&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;路由&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;服务&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;远程服务绑定&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;全文目录&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;证书&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;非对称密钥&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;对称密钥&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;约定&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;架构&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;h3 class=&quot;heading&quot;&gt;&lt;span&gt;3.安全对象范围：架构&lt;/span&gt;&lt;/h3&gt;
&lt;div id=&quot;sectionSection2&quot; class=&quot;section&quot; readability=&quot;8&quot;&gt;
&lt;p&gt;包含以下安全对象：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;类型&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;XML 架构集合&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;对象&lt;/li&gt;
&lt;/ul&gt;&lt;h4 class=&quot;subHeading&quot;&gt;对象&lt;/h4&gt;
&lt;div class=&quot;subSection&quot; readability=&quot;7&quot;&gt;
&lt;p&gt;下面是对象类的成员：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;ul&gt;&lt;li&gt;聚合&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;约束&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;函数&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;过程&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;队列&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;统计信息&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;同义词&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;表&lt;/li&gt;
&lt;li&gt;视图  &lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h2&gt;四、案例 &lt;/h2&gt;
&lt;h3&gt;案例1.备份加密&lt;/h3&gt;
&lt;p&gt; 通过使用证书加密备份，如果需要在新的服务器上还原备份，先还原数据库主密钥和证书，然后就可以自动解密还原备份。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;1.备份数据库主密钥&lt;/span&gt;
&lt;span&gt;BACKUP&lt;/span&gt; MASTER &lt;span&gt;KEY&lt;/span&gt; &lt;span&gt;TO&lt;/span&gt; &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;D:\DECRYPTION\MasterKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;--&lt;/span&gt;&lt;span&gt;---主密钥私钥文件&lt;/span&gt;
    ENCRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;;             &lt;span&gt;--&lt;/span&gt;&lt;span&gt;---加密主密钥私钥文件&lt;/span&gt;
&lt;span&gt;GO&lt;/span&gt; 
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;2.备份证书&lt;/span&gt;
&lt;span&gt;BACKUP&lt;/span&gt; CERTIFICATE MyCerts &lt;span&gt;TO&lt;/span&gt; &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;D:\DECRYPTION\MyCerts&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--证书文件&lt;/span&gt;
    &lt;span&gt;WITH&lt;/span&gt; PRIVATE &lt;span&gt;KEY&lt;/span&gt; ( &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;D:\DECRYPTION\MyCertsKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; ,   &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--证书私钥文件&lt;/span&gt;
                       ENCRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;MyCerts123&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; ); &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--对私钥文件加密&lt;/span&gt;
&lt;span&gt;GO&lt;/span&gt;

&lt;span&gt;--&lt;/span&gt;&lt;span&gt;3.备份数据库&lt;/span&gt;
&lt;span&gt;USE&lt;/span&gt;&lt;span&gt; MASTER
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;BACKUP&lt;/span&gt; &lt;span&gt;DATABASE&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;EncryDb&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;    
&lt;span&gt;TO&lt;/span&gt; &lt;span&gt;DISK&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;D:\BackDB\EncryDb.bak&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;    
&lt;span&gt;WITH&lt;/span&gt;  COMPRESSION, stats &lt;span&gt;=&lt;/span&gt; &lt;span&gt;10&lt;/span&gt;&lt;span&gt;,   
    ENCRYPTION     
    (    
    ALGORITHM &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; AES_256,  
    SERVER CERTIFICATE &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; MyCerts
    )  
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt; 
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-4.在新服务器上还原数据库主密钥&lt;/span&gt;
&lt;span&gt;USE&lt;/span&gt;&lt;span&gt; MASTER
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;RESTORE&lt;/span&gt; MASTER &lt;span&gt;KEY&lt;/span&gt;  
&lt;span&gt;FROM&lt;/span&gt; &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\MasterKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt; 
DECRYPTION &lt;/span&gt;&lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;    &lt;span&gt;--&lt;/span&gt;&lt;span&gt;-解密主密钥文件&lt;/span&gt;
ENCRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey123&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;  &lt;span&gt;--&lt;/span&gt;&lt;span&gt;-加密导出的主密钥&lt;/span&gt;&lt;span&gt;
--&lt;/span&gt;&lt;span&gt;force;        ----指定即使当前数据库主密钥未打开，或者 SQL Server 无法对使用该主密钥加密的某些私钥进行解密，RESTORE 过程也应继续执行。&lt;/span&gt;
&lt;span&gt;GO&lt;/span&gt; 
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-5.在新服务器上还原证书&lt;/span&gt;
&lt;span&gt;USE&lt;/span&gt;&lt;span&gt; MASTER
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-需要先打开数据库主密钥&lt;/span&gt;
&lt;span&gt;OPEN&lt;/span&gt; MASTER &lt;span&gt;KEY&lt;/span&gt; DECRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey123&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;  
&lt;span&gt;GO&lt;/span&gt; 
&lt;span&gt;CREATE&lt;/span&gt; CERTIFICATE MyCerts &lt;span&gt;FROM&lt;/span&gt; &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\MyCerts&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--证书文件&lt;/span&gt;
    &lt;span&gt;WITH&lt;/span&gt; PRIVATE &lt;span&gt;KEY&lt;/span&gt; ( &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\MyCertsKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; ,    &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--证书私钥文件&lt;/span&gt;
    DECRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;MyCerts123&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; );                  &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--解密私钥文件&lt;/span&gt;

&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-6.在新服务器上还原数据库&lt;/span&gt;
&lt;span&gt;USE&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;master&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;  
&lt;span&gt;GO&lt;/span&gt;  
&lt;span&gt;OPEN&lt;/span&gt; MASTER &lt;span&gt;KEY&lt;/span&gt; DECRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey123&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;  
&lt;span&gt;GO&lt;/span&gt; 
&lt;span&gt;RESTORE&lt;/span&gt; &lt;span&gt;DATABASE&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;EncryDb&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;  
&lt;span&gt;FROM&lt;/span&gt;  &lt;span&gt;DISK&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\EncryDb.bak&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;   
&lt;span&gt;WITH&lt;/span&gt;  &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,  
MOVE N&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;EncryDb&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;TO&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\EncryDb.mdf&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;,     
MOVE N&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;EncryDb_log&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;TO&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\EncryDb_log.ldf&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;,    
NOUNLOAD,  STATS &lt;/span&gt;&lt;span&gt;=&lt;/span&gt; &lt;span&gt;5&lt;/span&gt;  
&lt;span&gt;GO&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;注意：在master数据库中创建数据库主密钥和证书。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果没有还原数据库主密钥和证书直接还原数据库报错如下&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/135426/201801/135426-20180120180707584-1689890846.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;案例2.TDE透明数据库加密&lt;/h3&gt;
&lt;p&gt; 通过使用证书加密数据库&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://images2017.cnblogs.com/blog/135426/201801/135426-20180122104959444-1657872570.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;步骤操作如下：&lt;/p&gt;
&lt;div&gt;
&lt;ul&gt;&lt;li&gt;创建主密钥&lt;/li&gt;
&lt;li&gt;创建或获取由主密钥保护的证书&lt;/li&gt;
&lt;li&gt;创建数据库加密密钥并通过此证书保护该密钥&lt;/li&gt;
&lt;li&gt;将数据库设置为使用加密&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;USE&lt;/span&gt;&lt;span&gt; EncryDb;
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;CREATE&lt;/span&gt; &lt;span&gt;DATABASE&lt;/span&gt; ENCRYPTION &lt;span&gt;KEY&lt;/span&gt;
&lt;span&gt;WITH&lt;/span&gt; ALGORITHM &lt;span&gt;=&lt;/span&gt;&lt;span&gt; AES_128
ENCRYPTION &lt;/span&gt;&lt;span&gt;BY&lt;/span&gt;&lt;span&gt; SERVER CERTIFICATE MyCerts;
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;USE&lt;/span&gt;&lt;span&gt; EncryDb;
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-启用数据库加密&lt;/span&gt;
&lt;span&gt;ALTER&lt;/span&gt; &lt;span&gt;DATABASE&lt;/span&gt;&lt;span&gt; EncryDb
&lt;/span&gt;&lt;span&gt;SET&lt;/span&gt; ENCRYPTION &lt;span&gt;ON&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;USE&lt;/span&gt;&lt;span&gt; EncryDb;
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-禁用数据库加密&lt;/span&gt;
&lt;span&gt;ALTER&lt;/span&gt; &lt;span&gt;DATABASE&lt;/span&gt;&lt;span&gt; EncryDb
&lt;/span&gt;&lt;span&gt;SET&lt;/span&gt; ENCRYPTION &lt;span&gt;OFF&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;1.“透明数据加密”(TDE) 可对数据和日志文件执行实时 I/O 加密和解密。这种加密使用数据库加密密钥 (DEK)，该密钥存储在数据库引导记录中以供恢复时使用。DEK 是使用存储在服务器的 master 数据库中的证书保护的对称密钥，或者是由 EKM 模块保护的非对称密钥。TDE 保护“处于休眠状态”的数据，即数据和日志文件。它提供了遵从许多法律、法规和各个行业建立的准则的能力。软件开发人员籍此可以使用 AES 和 3DES 加密算法来加密数据，且无需更改现有的应用程序。&lt;br/&gt;2.启用 TDE 时，应该立即备份证书和与证书相关联的私钥。如果证书变为不可用，或者如果必须在另一台服务器上还原或附加数据库，则必须同时具有证书和私钥的备份，否则将无法打开该数据库。即使不再对数据库启用 TDE，也应该保留加密证书或非对称密钥。即使数据库没有加密，数据库加密密钥可能也保留在数据库中，执行某些操作时可能需要访问这些加密密钥。&lt;br/&gt;3.数据库文件的加密在页级执行。已加密数据库中的页在写入磁盘之前会进行加密，在读入内存时会进行解密。TDE 不会增加已加密数据库的大小。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;注意：在master数据库中创建数据库主密钥和证书。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;测试在新的数据库中还原TDE透明加密数据库&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-备份数据库&lt;/span&gt;
&lt;span&gt;USE&lt;/span&gt;&lt;span&gt; MASTER
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;BACKUP&lt;/span&gt; &lt;span&gt;DATABASE&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;EncryDb&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;    
&lt;span&gt;TO&lt;/span&gt; &lt;span&gt;DISK&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\EncryDb0122.bak&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;    
&lt;span&gt;WITH&lt;/span&gt;  COMPRESSION, stats &lt;span&gt;=&lt;/span&gt; &lt;span&gt;10&lt;/span&gt;  

&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-在新服务器中还原数据库主密钥&lt;/span&gt;
&lt;span&gt;USE&lt;/span&gt;&lt;span&gt; MASTER
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;RESTORE&lt;/span&gt; MASTER &lt;span&gt;KEY&lt;/span&gt;  
&lt;span&gt;FROM&lt;/span&gt; &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\MasterKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt; 
DECRYPTION &lt;/span&gt;&lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;    &lt;span&gt;--&lt;/span&gt;&lt;span&gt;-解密主密钥文件&lt;/span&gt;
ENCRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey123&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;  &lt;span&gt;--&lt;/span&gt;&lt;span&gt;-加密导出的主密钥&lt;/span&gt;&lt;span&gt;
--&lt;/span&gt;&lt;span&gt;force;        ----指定即使当前数据库主密钥未打开，或者 SQL Server 无法对使用该主密钥加密的某些私钥进行解密，RESTORE 过程也应继续执行。&lt;/span&gt;
&lt;span&gt;GO&lt;/span&gt; 
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-在新服务器上还原证书&lt;/span&gt;
&lt;span&gt;USE&lt;/span&gt;&lt;span&gt; MASTER
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-需要先打开数据库主密钥&lt;/span&gt;
&lt;span&gt;OPEN&lt;/span&gt; MASTER &lt;span&gt;KEY&lt;/span&gt; DECRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey123&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;  
&lt;span&gt;GO&lt;/span&gt; 
&lt;span&gt;CREATE&lt;/span&gt; CERTIFICATE MyCerts &lt;span&gt;FROM&lt;/span&gt; &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\MyCerts&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--证书文件&lt;/span&gt;
    &lt;span&gt;WITH&lt;/span&gt; PRIVATE &lt;span&gt;KEY&lt;/span&gt; ( &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\MyCertsKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; ,    &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--证书私钥文件&lt;/span&gt;
    DECRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;MyCerts123&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; );                  &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--解密私钥文件&lt;/span&gt;


&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-还原备份&lt;/span&gt;
&lt;span&gt;USE&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;master&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;  
&lt;span&gt;GO&lt;/span&gt;  
&lt;span&gt;OPEN&lt;/span&gt; MASTER &lt;span&gt;KEY&lt;/span&gt; DECRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey123&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;  
&lt;span&gt;GO&lt;/span&gt; 
&lt;span&gt;RESTORE&lt;/span&gt; &lt;span&gt;DATABASE&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;EncryDb_20180122&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;  
&lt;span&gt;FROM&lt;/span&gt;  &lt;span&gt;DISK&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\EncryDb0122.bak&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;   
&lt;span&gt;WITH&lt;/span&gt;  &lt;span&gt;FILE&lt;/span&gt; &lt;span&gt;=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;,  
MOVE N&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;EncryDb&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;TO&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\EncryDb0122.mdf&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;,     
MOVE N&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;EncryDb_log&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; &lt;span&gt;TO&lt;/span&gt; N&lt;span&gt;'&lt;/span&gt;&lt;span&gt;C:\DECRYPTION\EncryDb0122_log.ldf&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;,    
NOUNLOAD,  STATS &lt;/span&gt;&lt;span&gt;=&lt;/span&gt; &lt;span&gt;5&lt;/span&gt;  
&lt;span&gt;GO&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;注意：经测试发现只有同数据库版本可以还原成功，在搞版本中还原提示会提示错误页，比如2014版本加密的数据库在2016版本中还原保持如下：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/135426/201801/135426-20180122194442694-103421155.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;案例3.存储过程加密&lt;/h3&gt;
&lt;p&gt;在AS前增加WITH ENCRYPTION加密选项即可&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;USE&lt;/span&gt;&lt;span&gt; EncryDb;
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;CREATE&lt;/span&gt; &lt;span&gt;PROCEDURE&lt;/span&gt;&lt;span&gt; Sptest
&lt;/span&gt;&lt;span&gt;WITH&lt;/span&gt; ENCRYPTION &lt;span&gt;--&lt;/span&gt;&lt;span&gt;-加密选项&lt;/span&gt;
&lt;span&gt;AS&lt;/span&gt;
&lt;span&gt;BEGIN&lt;/span&gt;


&lt;span&gt;END&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;注意:&lt;/span&gt;&lt;br/&gt;&lt;span&gt;1.加密前先保留存储副本，否则加密完再需要解密就很麻烦&lt;/span&gt;&lt;br/&gt;&lt;span&gt;2.加密过的存储过程不影响修改、删除，但是无法查看存储过程的定义比如:sp_helptext、生成create语句、生成alter语句等。&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;案例4.数据列加密&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;47&quot;&gt;
&lt;pre&gt;
&lt;span&gt;CREATE&lt;/span&gt; &lt;span&gt;DATABASE&lt;/span&gt;&lt;span&gt; TestDb
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;USE&lt;/span&gt; &lt;span&gt;[&lt;/span&gt;&lt;span&gt;TestDb&lt;/span&gt;&lt;span&gt;]&lt;/span&gt;
&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;CREATE&lt;/span&gt; MASTER &lt;span&gt;KEY&lt;/span&gt; ENCRYPTION &lt;span&gt;BY&lt;/span&gt; PASSWORD &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;MasterKey&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;
&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-创建证书&lt;/span&gt;
&lt;span&gt;CREATE&lt;/span&gt;&lt;span&gt; CERTIFICATE MyCerts 
   &lt;/span&gt;&lt;span&gt;WITH&lt;/span&gt; SUBJECT &lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;BackDB Records&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;, 
   EXPIRY_DATE &lt;/span&gt;&lt;span&gt;=&lt;/span&gt; &lt;span&gt;'&lt;/span&gt;&lt;span&gt;10/31/2099&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;;            &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--证书过期时间，不指定开始时间默认开始时间为当前时间&lt;/span&gt;
&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;--创建对称密钥&lt;/span&gt;
&lt;span&gt;CREATE&lt;/span&gt; SYMMETRIC &lt;span&gt;KEY&lt;/span&gt;&lt;span&gt; SymmetricByCert
    &lt;/span&gt;&lt;span&gt;WITH&lt;/span&gt; ALGORITHM &lt;span&gt;=&lt;/span&gt;&lt;span&gt; AES_256
    ENCRYPTION &lt;/span&gt;&lt;span&gt;BY&lt;/span&gt;&lt;span&gt; CERTIFICATE MyCerts;

&lt;/span&gt;&lt;span&gt;--&lt;/span&gt;&lt;span&gt;--创建测试表&lt;/span&gt;
&lt;span&gt;USE&lt;/span&gt;&lt;span&gt; TestDb;
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;DROP&lt;/span&gt; &lt;span&gt;TABLE&lt;/span&gt;&lt;span&gt; Test
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;CREATE&lt;/span&gt; &lt;span&gt;TABLE&lt;/span&gt;&lt;span&gt; Test
(Id &lt;/span&gt;&lt;span&gt;INT&lt;/span&gt; &lt;span&gt;NOT&lt;/span&gt; &lt;span&gt;NULL&lt;/span&gt;&lt;span&gt;,
Name &lt;/span&gt;&lt;span&gt;NVARCHAR&lt;/span&gt;(&lt;span&gt;30&lt;/span&gt;) &lt;span&gt;NOT&lt;/span&gt; &lt;span&gt;NULL&lt;/span&gt;&lt;span&gt;,
EncryptionName &lt;/span&gt;&lt;span&gt;varbinary&lt;/span&gt;(&lt;span&gt;500&lt;/span&gt;) &lt;span&gt;null&lt;/span&gt;&lt;span&gt;
);
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;INSERT&lt;/span&gt; &lt;span&gt;INTO&lt;/span&gt; Test(Id,Name) &lt;span&gt;VALUES&lt;/span&gt;(&lt;span&gt;1&lt;/span&gt;,&lt;span&gt;'&lt;/span&gt;&lt;span&gt;aa&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;),(&lt;span&gt;2&lt;/span&gt;,&lt;span&gt;'&lt;/span&gt;&lt;span&gt;bb&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;

&lt;span&gt;--&lt;/span&gt;&lt;span&gt;--加密列&lt;/span&gt;
&lt;span&gt;OPEN&lt;/span&gt; SYMMETRIC &lt;span&gt;KEY&lt;/span&gt;&lt;span&gt; SymmetricByCert 
     DECRYPTION &lt;/span&gt;&lt;span&gt;BY&lt;/span&gt;&lt;span&gt; CERTIFICATE MyCerts;  
&lt;/span&gt;&lt;span&gt;UPDATE&lt;/span&gt;&lt;span&gt; Test
&lt;/span&gt;&lt;span&gt;SET&lt;/span&gt; EncryptionName&lt;span&gt;=&lt;/span&gt; EncryptByKey(Key_GUID(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;SymmetricByCert&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;), Name);  
&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;

&lt;span&gt;SELECT&lt;/span&gt; &lt;span&gt;*&lt;/span&gt; &lt;span&gt;FROM&lt;/span&gt;&lt;span&gt; TEST

&lt;/span&gt;&lt;span&gt;GO&lt;/span&gt;
&lt;span&gt;--&lt;/span&gt;&lt;span&gt;-解密查询&lt;/span&gt;
&lt;span&gt;OPEN&lt;/span&gt; SYMMETRIC &lt;span&gt;KEY&lt;/span&gt;&lt;span&gt; SymmetricByCert 
     DECRYPTION &lt;/span&gt;&lt;span&gt;BY&lt;/span&gt;&lt;span&gt; CERTIFICATE MyCerts;  
&lt;/span&gt;&lt;span&gt;select&lt;/span&gt;&lt;span&gt; Id,
Name,
EncryptionName,
&lt;/span&gt;&lt;span&gt;convert&lt;/span&gt;(&lt;span&gt;nvarchar&lt;/span&gt;(&lt;span&gt;30&lt;/span&gt;), DecryptByKey(EncryptionName)) ConvertEncryptionName  &lt;span&gt;--&lt;/span&gt;&lt;span&gt;--nvarchar(30)值和明文字段类型长度保持一致 &lt;/span&gt;
&lt;span&gt;from&lt;/span&gt; test;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/135426/201801/135426-20180122194222725-161518914.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;注意：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;1.加密列的数据类型必须是nvarchar数据类型，否则解密后的结果不会和明文一致。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;2.解密过程定义的数据类型需要和明文的数据类型保持一致，包括长度也必须一致。&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;公钥和私钥的解释参考：&lt;a href=&quot;https://docs.microsoft.com/zh-cn/sql/relational-databases/security/encryption/encryption-hierarchy&quot; target=&quot;_blank&quot;&gt;http://blog.csdn.net/tanyujing/article/details/17348321&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;加密参考：&lt;a href=&quot;https://docs.microsoft.com/zh-cn/sql/relational-databases/security/encryption/encryption-hierarchy&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/zh-cn/sql/relational-databases/security/encryption/encryption-hierarchy&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;使用对称密钥加密数据：&lt;a href=&quot;https://docs.microsoft.com/zh-cn/sql/t-sql/functions/encryptbykey-transact-sql&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/zh-cn/sql/t-sql/functions/encryptbykey-transact-sql&lt;/a&gt;&lt;/p&gt;

&lt;table border=&quot;0&quot;&gt;&lt;tbody readability=&quot;1.7112676056338&quot;&gt;&lt;tr readability=&quot;6.4172535211268&quot;&gt;&lt;td readability=&quot;8.556338028169&quot;&gt;
&lt;p&gt;&lt;span&gt;备注：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;    作者：&lt;/span&gt;&lt;span&gt;&lt;a title=&quot;点击跳转到原文&quot; href=&quot;http://www.cnblogs.com/chenmh/&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;pursuer.chen&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;    博客：&lt;span&gt;&lt;a id=&quot;lnkMyHome&quot; title=&quot;点击跳转到原文&quot; href=&quot;http://www.cnblogs.com/chenmh/&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;http://www.cnblogs.com/chenmh&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;本站点所有随笔都是原创，欢迎大家转载；但转载时必须注明文章来源，且在文章开头明显处给明链接，否则保留追究责任的权利。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;《欢迎交流讨论》&lt;/span&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</description>
<pubDate>Mon, 22 Jan 2018 11:54:00 +0000</pubDate>
<dc:creator>pursuer.chen</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/chenmh/p/8309176.html</dc:identifier>
</item>
<item>
<title>跟我一起读postgresql源码(十二)——Executor(查询执行模块之——Materialization节点(下)) - 非我在</title>
<link>http://www.cnblogs.com/flying-tiger/p/8318530.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/flying-tiger/p/8318530.html</guid>
<description>&lt;p&gt;接前文，我们继续说剩下的4个Materialization节点。&lt;/p&gt;
&lt;h2 id=&quot;setop节点&quot;&gt;7.SetOp节点&lt;/h2&gt;
&lt;p&gt;SetOp节点用于处理集合操作，对应于SQL语句中的EXCEPT、INTERSECT两种集合操作，至于另一种集合操作UNION,可直接由Append节点来实现。&lt;/p&gt;
&lt;p&gt;一个SetOp节点只能处理一个集合操作（由两个集合参与），如果有多个集合操作则需要组合多个SetOp节点来实现。SetOp节点仅有一个左子节点作为输人，其左子节点是一个Append节点或者是一个Sort节点（Sort节点的子节点是一个Append节点），其低层的Append节点中只放置两个子计划用于表示参与集合操作的左集合和右集合。由于进行集合操作时需要区分元组来自哪一个子査询，因此在低层Append节点的投影操作时会为每个子计划输出元组增加一个子计划标记属性(见下面的例子)。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;postgres=# explain (select id from test_dm) except (select id from test_dm2);
                                       QUERY PLAN
-----------------------------------------------------------------------------------------
 HashSetOp Except  (cost=0.00..383303.38 rows=1000000 width=4)
   -&amp;gt;  Append  (cost=0.00..355803.34 rows=11000017 width=4)
         -&amp;gt;  Subquery Scan on &quot;*SELECT* 1&quot;  (cost=0.00..32346.00 rows=1000000 width=4)
               -&amp;gt;  Seq Scan on test_dm  (cost=0.00..22346.00 rows=1000000 width=4)
         -&amp;gt;  Subquery Scan on &quot;*SELECT* 2&quot;  (cost=0.00..323457.34 rows=10000017 width=4)
               -&amp;gt;  Seq Scan on test_dm2  (cost=0.00..223457.17 rows=10000017 width=4)
(6 行)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;SetOp有两种执行策略：排序（SETOP_SORTED)和Hash (SETOP_HASHED)。&lt;/p&gt;
&lt;ul readability=&quot;0&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;排序策略下首先利用Sort节点对Append节点返回的元组集合进行排序，然后进行交、差的集合操作；&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;Hash策略下则通过SetOp节点提供Hash表对子査询元组进行Hash分组，然后进行集合操作。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在Hash策略下，SetOp节点的左子节点就是Append节点。在SetOp执行过程中需要附加子计划标记属性，这个属性在输人元组中的偏移位置被记录在SetOp节点的flagColIdx字段中。SetOp节点的定义如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;typedef struct SetOp
{
    Plan        plan;
    SetOpCmd    cmd;            /* what to do */
    SetOpStrategy strategy;     /* how to do it */
    int         numCols;        /* number of columns to check for
                                 * duplicate-ness */
    AttrNumber *dupColIdx;      /* their indexes in the target list */
    Oid        *dupOperators;   /* equality operators to compare with */
    AttrNumber  flagColIdx;     /* where is the flag column, if any */
    int         firstFlag;      /* flag value for first input relation */
    long        numGroups;      /* estimated number of groups in input */
} SetOp;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中除了标志属性的位置外，还有用于去重的属性号数组（dupColIdx)和相应的操作符OID数组（dupOperators)等信息，这两个数组用于判断元组是否相同。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;typedef struct SetOpStatePerGroupData
{
    long        numLeft;        /* number of left-input dups in group */
    long        numRight;       /* number of right-input dups in group */
} SetOpStatePerGroupData;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;SetOp节点在执行时会对从左子节点中取到的每一个元组,会使用一个SetOpStatePerGroupData结构(该结构会在每次获取元组时复用)来存储每个元组的状态。具体地就是利用numLeft和numRight变量来记录该元组在左集合和右集合中出现的次数，然后根据集合操作命令的类型来确定该元组是否应该作为结果元组返回：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;typedef enum SetOpCmd
{
    SETOPCMD_INTERSECT,
    SETOPCMD_INTERSECT_ALL,
    SETOPCMD_EXCEPT,
    SETOPCMD_EXCEPT_ALL
} SetOpCmd;&lt;/code&gt;
&lt;/pre&gt;
&lt;ul readability=&quot;5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;1)SETOPCMD_INTERSECT:对应INTERSECT操作，最后的结果集合中不会有重复元组。其实现方式是，如果一个元组的numLeft和mimRight都大于0,则只输出一次该元组。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;2)SETOPCMD_INTERSECT_ALL:对应于INTERSECT ALL操作，最后的结果集中允许有重复元组。其实现方式是，输出该元组的次数以rmmLeft和mimRight的较小者为准。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;3)SETOPCMD_EXCEPT:对应于EXCEPT操作，表示要求返回只出现在左集合中的元组，且结果集合中不存在重复元组。如果一个元组的mimLeft大于0而mimRight等于0,则输出一次该元组。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;4)SETOPCMD_EXCEPT_ALL:对应于EXCEPT ALL操作，结果集合中允许存在重复元组。如果一个元组的numLeft不小于numRight,则输出numLeft - numRight次该元组。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;SETOP_SORTED策略的下层节点已经将需要执行的集合的操作合并在一起并进行了排序，SetOp 节点需要做的事情类似于 Group 节点：首先从下层节点获取一个分组的元组，仅缓存第一条元组，然后统计它在左右集合中的出现次数，然后通过集合操作的命令类型来决定如何返回元组。&lt;/p&gt;
&lt;p&gt;SETOP_HASHED策略的下层节点会依次返回两个子计划（对应于左右两个集合）中的元组。首先计算左集合中每个元组的Hash值，如果Hash表中没有，则插人Hash表中，否则，将其中Hash项内mimLeft计数加1。然后扫描右集合，计算Hash值后在Hash表中査找，找到则对numRight计数加1，否则，不进行任何操作。扫描完成后，会依次从Hash表中获取元组和其对应的numLeft和numRight，根据集合操作的命令类型来决定如何返回元组。&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;limit节点&quot;&gt;8.Limit节点&lt;/h2&gt;
&lt;p&gt;Limit节点主要用来处理LIMIT/OFFSET子句，它从下层节点的输出中挑选处于一定范围内的元组(见下面的例子)。该节点只有一个左子节点。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;postgres=# explain select id from test_new limit 5 ;
                            QUERY PLAN
------------------------------------------------------------------
 Limit  (cost=0.00..0.07 rows=5 width=4)
   -&amp;gt;  Seq Scan on test_new  (cost=0.00..35.50 rows=2550 width=4)
(2 行)
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Limit节点定义如下所示，它在Plan的基础上扩展定义了limitOffset和limitCount两个表达式，用于计算偏移量和需要返回元组的数量。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;typedef struct Limit
{
    Plan        plan;
    Node       *limitOffset;    /* OFFSET parameter, or NULL if none */
    Node       *limitCount;     /* COUNT parameter, or NULL if none */
} Limit;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在初始化过程中，会对Limit节点的limitOffset和limitCount两个表达式进行初始化，结果保存于LimitState节点的limitOffset和limitCount 字段中。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;typedef struct LimitState
{
    PlanState   ps;             /* its first field is NodeTag */
    ExprState  *limitOffset;    /* OFFSET parameter, or NULL if none */
    ExprState  *limitCount;     /* COUNT parameter, or NULL if none */
    int64       offset;         /* current OFFSET value */
    int64       count;          /* current COUNT, if any */
    bool        noCount;        /* if true, ignore count */
    LimitStateCond lstate;      /* state machine status, as above */
    int64       position;       /* 1-based index of last tuple returned */
    TupleTableSlot *subSlot;    /* tuple last obtained from subplan */
} LimitState;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在执行过程中，需要首先计算LimitState中的limitOffset和limitCount表达式，将结果保存于offset和count中，然后开始从下层节点获取元组，通过portion记录已获取的元组数目，跳过前offset个元组，从offset + 1个元组开始返回，并在offset + count处直接返回空元组。&lt;/p&gt;
&lt;p&gt;Limit节点的执行函数ExecLimit主要地就是根据子查询过滤获取元组，根据LIMIT节点当前的状态(LimitStateCond)做出不同的处理。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;typedef enum
{
    LIMIT_INITIAL,              /* initial state for LIMIT node */
    LIMIT_RESCAN,               /* rescan after recomputing parameters */
    LIMIT_EMPTY,                /* there are no returnable rows */
    LIMIT_INWINDOW,             /* have returned a row in the window */
    LIMIT_SUBPLANEOF,           /* at EOF of subplan (within window) */
    LIMIT_WINDOWEND,            /* stepped off end of window */
    LIMIT_WINDOWSTART           /* stepped off beginning of window */
} LimitStateCond;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们需要注意的是，当下层节点是Sort时，要做一个小小的“优化”(pass_down_bound函数):即如果指定了limit数和offset数，那么我们就知道我们到底需要多少个排序好的元组，那么Sor节点就可以采取相应的策略，选取合适的排序方法(bounded sort)，详情见Sort节点中的puttuple_common函数，同样在&lt;a href=&quot;http://www.cnblogs.com/flying-tiger/p/8120046.html&quot;&gt;这篇&lt;/a&gt;里面有。&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;windowagg节点&quot;&gt;9.WindowAgg节点&lt;/h2&gt;
&lt;p&gt;先上例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;postgres=# explain select avg(id) OVER ( PARTITION BY xxx) from test_dm;
                                  QUERY PLAN
------------------------------------------------------------------------------
 WindowAgg  (cost=122003.84..139503.84 rows=1000000 width=23)
   -&amp;gt;  Sort  (cost=122003.84..124503.84 rows=1000000 width=23)
         Sort Key: xxx
         -&amp;gt;  Seq Scan on test_dm  (cost=0.00..22346.00 rows=1000000 width=23)
(4 行)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;WindowAgg节点用于处理窗口函数，窗口函数用于在与当前元组相关的一组元组上执行相关函数计算(包括在GROUP BY中使用的聚集函数)。窗口函数的使用类似于“SELECT ..., avg (x) OVER (PARTITION BY y) FROM x;” 的方式。&lt;/p&gt;
&lt;p&gt;通常，GROUP BY子句存在时，查询无法投影非分组属性，非分组属性只能出现在聚集函数中。在实际应用中可能需要投影非分组属性，例如，表class记录了班级（cno)、民族（nation)、人数（mim),若需要统计班级中的各民族所占比例，使用GROUP BY就无法实现，如果使用窗口函数，可以使用如下语句：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;SELECT cnof nation, mim/sum(nuin) OVER (PARTITION BY cno)AS present FROM class;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的SQL语句中，将sum函数运用在与当前元组具有相同cno的一组元组上，并利用此聚合得到的总人数，计算出当前人数在总人数中的比例。这样能够实现更加灵活的函数操作，提供了更加丰富的査询方法。&lt;/p&gt;
&lt;p&gt;窗口函数与在GROUP分组中进行聚集计算的不同主要体现在SQL语义上，在聚集函数的计算上两者是相似的。窗口函数需要处理与当前元组相关联的一组元组，在实现中要保留同一划分内的所有元组，计算得到聚集函数值后，再进行相关的投影操作。因此，在实现方法上，不论是PARTITION还是GROUP都需要先将元组在分组属性上进行划分，在分组过程和聚集函数计算的实现上是相似的。&lt;/p&gt;
&lt;p&gt;WindowAgg节点实现的功能类似于Agg节点，但不同点在于窗口函数不会造成同一分组中的元组被合并为一个，因此每个元组都可以生成一个结果元组，并可包含相关的聚集运算结果。WindowAgg节点只有一个左子节点，用于提供已经在分组属性(PARTITION BY所指定的属性)上排序的元组。&lt;/p&gt;
&lt;p&gt;如下图所示，WindowAgg节点定义中包含用于存储分区函数和所对应属性号的数组 partOperalors 和 partColIdx、数组长度partNumCds以及在排序属性上判断是否相等的函数和相应的属性号数组ordlOperators 和 ordColIdx,数组长度用 ordNumCols记录。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/579102/201801/579102-20180122174810615-233540606.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;窗口函数也使用了 Agg节点的聚集函数迭代计算方法，其实现方式是在Agg节点的AGG_SORTED策略的执行中增加了缓存分组内所有元组的tuplestore结构，保存于状态节点中的buffer字段中。由于窗口函数不仅包含Agg中支持的聚集函数，还有新的窗口函数模式（能够支持随机的在分组内获取元组等），因此，在从Plan的targellist中获取WindowFimc,并将其信息初始化为perfunc指向的WindowStatePerFunc数组后，需要将传统的聚集函数构造成新的WindowSlatePerAgg链表，以便在调用聚集函数处理过程中使用与Agg节点相同的方式。&lt;/p&gt;
&lt;p&gt;初始化过程中，通过WindowAgg节点的targetlist构造funcs链表，其中包含窗口函数的表达式树。然后对funcs指向的表达式树进行初始化，构造函数相关调用信息存放于perfunc指向的数组中。对于传统的聚集函数，将在peragg中另外多初始化一个与Agg节点处理聚集函数时相同的数据结构，用于执行聚集计算。然后要对于分区判断函数和排序属性是否相等的操作函数进行初始化，分别保存于 perEqfuctions 和 ordEqfuntions 中。&lt;/p&gt;
&lt;p&gt;在执行过程中，首先初始化一个tuplestore结构用于缓存元组，使用perEqfunctions判断是否在分区内：&lt;/p&gt;
&lt;ul readability=&quot;1&quot;&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;1)如果有传统的聚集类函数，获取分区内的所有元组缓存于tuplestore中。然后计算其聚集函数值，并将该值保存在对应函数信息WindowStatePerAgg结构的resultValue中。依次获取分区每条元组，计算窗口函数，使用缓存的聚集函数结果进行投影。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;2)否则，直接扫描分区每条元组，计算该窗口函数，并对结果元组进行投影后返回。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;hr/&gt;&lt;h2 id=&quot;lockrows节点&quot;&gt;10.LockRows节点&lt;/h2&gt;
&lt;p&gt;关于这个节点，我查了下用户手册，发现它是用来支持Postgres中的行级锁，详情见&lt;a href=&quot;http://www.postgres.cn/docs/9.5/explicit-locking.html&quot; class=&quot;uri&quot;&gt;http://www.postgres.cn/docs/9.5/explicit-locking.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;上例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;postgres=# explain select id from test_new where id &amp;lt; 5 for share;
                            QUERY PLAN
------------------------------------------------------------------
 LockRows  (cost=0.00..50.38 rows=850 width=10)
   -&amp;gt;  Seq Scan on test_new  (cost=0.00..41.88 rows=850 width=10)
         Filter: (id &amp;lt; 5)
(3 行)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;LockRows节点在Plan节点的基础上扩展了两个字段，rowMarks记录的是该rowMarks节点所锁定的关系(relation)的列表；epqParam参数我们不会陌生了，它是和EvalPlanQual函数相关的，以后我们看到参数名里面有EPQ的我们就知道他就是做recheck相关的工作的参数。&lt;/p&gt;
&lt;p&gt;(关于EvalPlanQual函数，我们可以看src/backend/executor/README文件的EvalPlanQual (READ COMMITTED Update Checking)部分，或者直接EvalPlanQual的源码。)&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;typedef struct LockRows
{
    Plan        plan;
    List       *rowMarks;       /* a list of PlanRowMark's */
    int         epqParam;       /* ID of Param for EvalPlanQual re-eval */
} LockRows;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这样我们就知道，这个节点的事情很简单，就是以指定的方式(FOR SHARE/FOR UPDATE)锁住Postgres表中的一些行的操作。&lt;/p&gt;
&lt;p&gt;在初始化时，初始化LockRowsState结构。为其创建outer plan，创建为锁表而使用的工作空间(初始化lr_curtuples和lr_ntables)。根据全局状态Estate中es_rowMarks的字段，定位到每个ExecRowMark结构并为其构造ExecAuxRowMark结构，最后调用EvalPlanQualInit为其初始化EPQ(又是EPQ).&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;typedef struct LockRowsState
{
    PlanState   ps;             /* its first field is NodeTag */
    List       *lr_arowMarks;   /* List of ExecAuxRowMarks */
    EPQState    lr_epqstate;    /* for evaluating EvalPlanQual rechecks */
    HeapTuple  *lr_curtuples;   /* locked tuples (one entry per RT entry) */
    int         lr_ntables;     /* length of lr_curtuples[] array */
} LockRowsState;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在执行时，简而言之就是根据所要求的锁定的方式，锁定子节点输出的元组并将该元组返回到上层。&lt;/p&gt;
&lt;p&gt;在结束时，由于初始化了EPQ，所以结束时要额外调用EvalPlanQualEnd结束EPQ结构。&lt;/p&gt;
&lt;p&gt;Materialization节点就是这么多~&lt;/p&gt;
</description>
<pubDate>Mon, 22 Jan 2018 10:05:00 +0000</pubDate>
<dc:creator>非我在</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/flying-tiger/p/8318530.html</dc:identifier>
</item>
<item>
<title>kafka数据迁移实践 - 云加社区</title>
<link>http://www.cnblogs.com/qcloud1001/p/8330233.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qcloud1001/p/8330233.html</guid>
<description>&lt;p&gt;欢迎大家前往&lt;a href=&quot;https://cloud.tencent.com/developer&quot; target=&quot;_blank&quot;&gt;云+社区&lt;/a&gt;，获取更多腾讯海量技术实践干货哦~&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;作者：&lt;a class=&quot;author-name&quot; href=&quot;https://cloud.tencent.com/developer/user/1242474&quot;&gt;mikealzhou&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文重点介绍kafka的两类常见数据迁移方式：1、broker内部不同数据盘之间的分区数据迁移；2、不同broker之间的分区数据迁移。&lt;/p&gt;

&lt;h2&gt;1.1 背景介绍&lt;/h2&gt;
&lt;p&gt;最近，腾讯云的一个重要客户发现kafka broker内部的topic分区数据存储分布不均匀，导致部分磁盘100%耗尽，而部分磁盘只有40%的消耗量。&lt;/p&gt;
&lt;p&gt;分析原因，发现存在部分topic的分区数据过于集中在某些磁盘导致，比如，以下截图显示的/data5 数据盘。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ask.qcloudimg.com/draft/1242474/030kmta13e.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;根据分布式系统的特点，很容易想到采取数据迁移的办法，对broker内部不同数据盘的分区数据进行迁移。在进行线上集群数据迁移之前，为了保证生产集群的数据完整和安全，必须先在测试集群进行测试。&lt;/p&gt;
&lt;h2&gt;1.2 测试broker内部不同数据盘进行分区数据迁移&lt;/h2&gt;
&lt;h3&gt;1.2.1 建立测试topic并验证生产和消费正常&lt;/h3&gt;
&lt;p&gt;我们搭建的测试集群，Kafka 有三个broker，hostname分别为：tbds-172-16-16-11，tbds-172-16-16-12，tbds-172-16-16-16。每个broker配置了两块数据盘，缓存数据分别存储在 /data/kafka-logs/ 和 /data1/kafka-logs/。&lt;/p&gt;
&lt;p&gt;首先建立测试topic：&lt;/p&gt;
&lt;pre class=&quot;prism-token token language-js&quot;&gt;
&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token operator&quot;&gt;/kafka&lt;span class=&quot;token operator&quot;&gt;-topics&lt;span class=&quot;token punctuation&quot;&gt;.sh &lt;span class=&quot;token operator&quot;&gt;--create &lt;span class=&quot;token operator&quot;&gt;--zookeeper tbds&lt;span class=&quot;token number&quot;&gt;-172&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;11&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;2181 &lt;span class=&quot;token operator&quot;&gt;--replication&lt;span class=&quot;token operator&quot;&gt;-factor &lt;span class=&quot;token number&quot;&gt;2 &lt;span class=&quot;token operator&quot;&gt;--partitions &lt;span class=&quot;token number&quot;&gt;3 &lt;span class=&quot;token operator&quot;&gt;--topic test_topic&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;然后向topic生产发送500条数据，发送的时候也同时消费数据。然后查看topic的分区数据情况：&lt;/p&gt;
&lt;pre class=&quot;prism-token token language-js&quot;&gt;
GROUP    TOPIC      PARTITION   CURRENT&lt;span class=&quot;token operator&quot;&gt;-OFFSET   LOG&lt;span class=&quot;token operator&quot;&gt;-END&lt;span class=&quot;token operator&quot;&gt;-OFFSET   LAG   OWNER
groupid1 test_topic &lt;span class=&quot;token number&quot;&gt;0       &lt;span class=&quot;token number&quot;&gt;172      &lt;span class=&quot;token number&quot;&gt;172      &lt;span class=&quot;token number&quot;&gt;0      kafka&lt;span class=&quot;token operator&quot;&gt;-python&lt;span class=&quot;token number&quot;&gt;-1.3&lt;span class=&quot;token punctuation&quot;&gt;.1_tbds&lt;span class=&quot;token number&quot;&gt;-172&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;3&lt;span class=&quot;token operator&quot;&gt;/&lt;span class=&quot;token number&quot;&gt;172.16&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token number&quot;&gt;16.3
groupid1 test_topic &lt;span class=&quot;token number&quot;&gt;1       &lt;span class=&quot;token number&quot;&gt;156      &lt;span class=&quot;token number&quot;&gt;156      &lt;span class=&quot;token number&quot;&gt;0      kafka&lt;span class=&quot;token operator&quot;&gt;-python&lt;span class=&quot;token number&quot;&gt;-1.3&lt;span class=&quot;token punctuation&quot;&gt;.1_tbds&lt;span class=&quot;token number&quot;&gt;-172&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;3&lt;span class=&quot;token operator&quot;&gt;/&lt;span class=&quot;token number&quot;&gt;172.16&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token number&quot;&gt;16.3
groupid1 test_topic &lt;span class=&quot;token number&quot;&gt;2       &lt;span class=&quot;token number&quot;&gt;172      &lt;span class=&quot;token number&quot;&gt;172      &lt;span class=&quot;token number&quot;&gt;0      kafka&lt;span class=&quot;token operator&quot;&gt;-python&lt;span class=&quot;token number&quot;&gt;-1.3&lt;span class=&quot;token punctuation&quot;&gt;.1_tbds&lt;span class=&quot;token number&quot;&gt;-172&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;3&lt;span class=&quot;token operator&quot;&gt;/&lt;span class=&quot;token number&quot;&gt;172.16&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token number&quot;&gt;16.3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;发现test_topic生产和消费数据都正常。&lt;/p&gt;
&lt;h3&gt;1.2.2 将分区数据在磁盘间进行迁移&lt;/h3&gt;
&lt;p&gt;现在登录tbds-172-16-16-12这台broker节点，将test_topic的分区数据目录 /data1/kafka-logs/test_topic-0/ 移动到 /data/kafka-logs/ ：&lt;/p&gt;
&lt;pre class=&quot;prism-token token language-js&quot;&gt;
mv &lt;span class=&quot;token operator&quot;&gt;/data1&lt;span class=&quot;token operator&quot;&gt;/kafka&lt;span class=&quot;token operator&quot;&gt;-logs&lt;span class=&quot;token operator&quot;&gt;/test_topic&lt;span class=&quot;token number&quot;&gt;-0&lt;span class=&quot;token operator&quot;&gt;/ &lt;span class=&quot;token operator&quot;&gt;/data&lt;span class=&quot;token regex&quot;&gt;/kafka-logs/&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;查看 /data/kafka-logs/ 目录下，分区test_topic-0 的数据：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ask.qcloudimg.com/http-save/1242474/3vlvqs679t.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;1.2.3 再次对测试topic生产和消费数据&lt;/h3&gt;
&lt;p&gt;再次发送500条数据，同时消费数据。然后查看数据情况：&lt;/p&gt;
&lt;pre class=&quot;prism-token token language-js&quot;&gt;
GROUP    TOPIC      PARTITION   CURRENT&lt;span class=&quot;token operator&quot;&gt;-OFFSET   LOG&lt;span class=&quot;token operator&quot;&gt;-END&lt;span class=&quot;token operator&quot;&gt;-OFFSET   LAG   OWNER
groupid1 test_topic &lt;span class=&quot;token number&quot;&gt;0       &lt;span class=&quot;token number&quot;&gt;337      &lt;span class=&quot;token number&quot;&gt;337      &lt;span class=&quot;token number&quot;&gt;0      kafka&lt;span class=&quot;token operator&quot;&gt;-python&lt;span class=&quot;token number&quot;&gt;-1.3&lt;span class=&quot;token punctuation&quot;&gt;.1_tbds&lt;span class=&quot;token number&quot;&gt;-172&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;3&lt;span class=&quot;token operator&quot;&gt;/&lt;span class=&quot;token number&quot;&gt;172.16&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token number&quot;&gt;16.3
groupid1 test_topic &lt;span class=&quot;token number&quot;&gt;1       &lt;span class=&quot;token number&quot;&gt;304      &lt;span class=&quot;token number&quot;&gt;304      &lt;span class=&quot;token number&quot;&gt;0      kafka&lt;span class=&quot;token operator&quot;&gt;-python&lt;span class=&quot;token number&quot;&gt;-1.3&lt;span class=&quot;token punctuation&quot;&gt;.1_tbds&lt;span class=&quot;token number&quot;&gt;-172&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;3&lt;span class=&quot;token operator&quot;&gt;/&lt;span class=&quot;token number&quot;&gt;172.16&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token number&quot;&gt;16.3
groupid1 test_topic &lt;span class=&quot;token number&quot;&gt;2       &lt;span class=&quot;token number&quot;&gt;359      &lt;span class=&quot;token number&quot;&gt;359      &lt;span class=&quot;token number&quot;&gt;0      kafka&lt;span class=&quot;token operator&quot;&gt;-python&lt;span class=&quot;token number&quot;&gt;-1.3&lt;span class=&quot;token punctuation&quot;&gt;.1_tbds&lt;span class=&quot;token number&quot;&gt;-172&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;3&lt;span class=&quot;token operator&quot;&gt;/&lt;span class=&quot;token number&quot;&gt;172.16&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token number&quot;&gt;16.3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;再次查看tbds-172-16-16-12 这个broker节点的/data/kafka-logs/test_topic-0/ 分区目录下的数据：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ask.qcloudimg.com/http-save/1242474/pa0mjpkyk2.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;发现，从 /data1/kafka-logs/ 移动到 /data/kafka-logs/ 目录下的分区数据目录test_topic-0/（也就是编号为0的分区）缓存数据并没有增加。&lt;/p&gt;
&lt;p&gt;因为test_topic每个分区有2个replicas，因此，我找到编号为0的另外一个分区replica数据存储在tbds-172-16-16-16这台broker节点。登录tbds-172-16-16-16这个broker节点，打开编号为0的分区缓存数据目录，得到如下信息：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ask.qcloudimg.com/http-save/1242474/34ns9z5zpm.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;发现，tbds-172-16-16-16这台broker节点的分区数据目录test_topic-0/内缓存数据量是增加的，也就是缓存有再次生产发送的message数据。&lt;/p&gt;
&lt;p&gt;由此可见，经过移动之后的tbds-172-16-16-12这台broker节点的编号为0的分区数据缓存目录内，并没有新增缓存数据。与之对应的，没有做分区数据移动操作的 tbds-172-16-16-16这台broker 节点的编号为0的分区缓存数据目录内新增再次发送的数据。&lt;/p&gt;
&lt;p&gt;是不是意味着不能在broker的磁盘间移动分区数据呢？&lt;/p&gt;
&lt;h3&gt;1.2.4 调用重启大法：重启kafka&lt;/h3&gt;
&lt;p&gt;重启kafka集群，重启完成后，发现tbds-172-16-16-12这台broker节点的编号为0的分区缓存数据目录内的数据也增加到正常水平。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ask.qcloudimg.com/http-save/1242474/89hmlfu5pz.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;表明重启之后，broker的不同磁盘间迁移数据已经生效。&lt;/p&gt;
&lt;h3&gt;1.2.5 验证磁盘间迁移分区数据生效&lt;/h3&gt;
&lt;p&gt;再次向test_topic发送500条数据，同时消费数据，然后查看数据情况：&lt;/p&gt;
&lt;pre class=&quot;prism-token token language-js&quot;&gt;
GROUP    TOPIC      PARTITION   CURRENT&lt;span class=&quot;token operator&quot;&gt;-OFFSET   LOG&lt;span class=&quot;token operator&quot;&gt;-END&lt;span class=&quot;token operator&quot;&gt;-OFFSET   LAG   OWNER
groupid1 test_topic &lt;span class=&quot;token number&quot;&gt;0       &lt;span class=&quot;token number&quot;&gt;521      &lt;span class=&quot;token number&quot;&gt;521      &lt;span class=&quot;token number&quot;&gt;0      kafka&lt;span class=&quot;token operator&quot;&gt;-python&lt;span class=&quot;token number&quot;&gt;-1.3&lt;span class=&quot;token punctuation&quot;&gt;.1_tbds&lt;span class=&quot;token number&quot;&gt;-172&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;3&lt;span class=&quot;token operator&quot;&gt;/&lt;span class=&quot;token number&quot;&gt;172.16&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token number&quot;&gt;16.3
groupid1 test_topic &lt;span class=&quot;token number&quot;&gt;1       &lt;span class=&quot;token number&quot;&gt;468      &lt;span class=&quot;token number&quot;&gt;468      &lt;span class=&quot;token number&quot;&gt;0      kafka&lt;span class=&quot;token operator&quot;&gt;-python&lt;span class=&quot;token number&quot;&gt;-1.3&lt;span class=&quot;token punctuation&quot;&gt;.1_tbds&lt;span class=&quot;token number&quot;&gt;-172&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;3&lt;span class=&quot;token operator&quot;&gt;/&lt;span class=&quot;token number&quot;&gt;172.16&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token number&quot;&gt;16.3
groupid1 test_topic &lt;span class=&quot;token number&quot;&gt;2       &lt;span class=&quot;token number&quot;&gt;511      &lt;span class=&quot;token number&quot;&gt;511      &lt;span class=&quot;token number&quot;&gt;0      kafka&lt;span class=&quot;token operator&quot;&gt;-python&lt;span class=&quot;token number&quot;&gt;-1.3&lt;span class=&quot;token punctuation&quot;&gt;.1_tbds&lt;span class=&quot;token number&quot;&gt;-172&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;3&lt;span class=&quot;token operator&quot;&gt;/&lt;span class=&quot;token number&quot;&gt;172.16&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token number&quot;&gt;16.3&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;查看tbds-172-16-16-12 和 tbds-172-16-16-16 两个broker节点的test_topic-0分区数据的缓存目录：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ask.qcloudimg.com/http-save/1242474/frc8hiy5og.jpg&quot; alt=&quot;&quot;/&gt;&lt;img src=&quot;https://ask.qcloudimg.com/http-save/1242474/vr30kworng.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;发现两个replicas完全一样。&lt;/p&gt;
&lt;h2&gt;1.3 结论&lt;/h2&gt;
&lt;p&gt;Kafka broker 内部不同数据盘之间可以自由迁移分区数据目录。迁移完成后，重启kafka即可生效。&lt;/p&gt;

&lt;p&gt;当对kafka集群进行扩容之后，由于新扩容的broker没有缓存数据，容易造成系统的数据分布不均匀。因此，需要将原来集群broker的分区数据迁移到新扩容的broker节点。&lt;/p&gt;
&lt;p&gt;不同broker之间传输分区数据，可以使用kafka自带的kafka-reassign-partitions.sh脚本工具实现。&lt;/p&gt;
&lt;p&gt;我们在kafka测试集群原有的3台broker基础上，扩容1台broker。&lt;/p&gt;
&lt;h2&gt;2.1 获取test_topic的分区分布情况&lt;/h2&gt;
&lt;p&gt;执行命令：&lt;/p&gt;
&lt;pre class=&quot;prism-token token language-js&quot;&gt;
&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token operator&quot;&gt;/kafka&lt;span class=&quot;token operator&quot;&gt;-topics&lt;span class=&quot;token punctuation&quot;&gt;.sh &lt;span class=&quot;token operator&quot;&gt;--zookeeper &lt;span class=&quot;token number&quot;&gt;172.16&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token number&quot;&gt;16.11&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;2181 &lt;span class=&quot;token operator&quot;&gt;--topic test_topic &lt;span class=&quot;token operator&quot;&gt;--describe&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;可以得到test_topic的3个分区（每个分区有2份replicas）在三个broker节点的分布情况：&lt;/p&gt;
&lt;pre class=&quot;prism-token token language-js&quot;&gt;
Topic&lt;span class=&quot;token punctuation&quot;&gt;:test_topic PartitionCount&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;3 ReplicationFactor&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;2 Configs&lt;span class=&quot;token punctuation&quot;&gt;:
Topic&lt;span class=&quot;token punctuation&quot;&gt;: test_topic Partition&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;0 Leader&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1002 Replicas&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1002&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1001 Isr&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1002&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1001
Topic&lt;span class=&quot;token punctuation&quot;&gt;: test_topic Partition&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1 Leader&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1003 Replicas&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1003&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1002 Isr&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1003&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1002
Topic&lt;span class=&quot;token punctuation&quot;&gt;: test_topic Partition&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;2 Leader&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1001 Replicas&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1001&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1003 Isr&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1001&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1003&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;h2&gt;2.2 获取topic重新分区的配额文件&lt;/h2&gt;
&lt;p&gt;编写分配脚本：move_kafka_topic.json内容如下：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{&quot;topics&quot;: [{&quot;topic&quot;:&quot;test_topic&quot;}], &quot;version&quot;: 1}&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;执行分配计划生成脚本：&lt;/p&gt;
&lt;pre class=&quot;prism-token token language-js&quot;&gt;
&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token operator&quot;&gt;/kafka&lt;span class=&quot;token operator&quot;&gt;-reassign&lt;span class=&quot;token operator&quot;&gt;-partitions&lt;span class=&quot;token punctuation&quot;&gt;.sh &lt;span class=&quot;token operator&quot;&gt;--zookeeper tbds&lt;span class=&quot;token number&quot;&gt;-172&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;11&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;2181 &lt;span class=&quot;token operator&quot;&gt;--topics&lt;span class=&quot;token operator&quot;&gt;-to&lt;span class=&quot;token operator&quot;&gt;-move&lt;span class=&quot;token operator&quot;&gt;-json&lt;span class=&quot;token operator&quot;&gt;-file &lt;span class=&quot;token operator&quot;&gt;/tmp&lt;span class=&quot;token operator&quot;&gt;/move_kafka_topic&lt;span class=&quot;token punctuation&quot;&gt;.json &lt;span class=&quot;token operator&quot;&gt;--broker&lt;span class=&quot;token operator&quot;&gt;-list &lt;span class=&quot;token string&quot;&gt;&quot;1001,1002,1003,1004&quot; &lt;span class=&quot;token operator&quot;&gt;--generate&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;命令里面的broker-list填写kafka集群4个broker的id。不同kafka集群，因为部署方式不一样，选择的broker id也不一样。我们的测试集群broker id是1001,1002,1003,1004。读者需要根据自己的kafka集群设置的broker id填写。&lt;/p&gt;
&lt;p&gt;执行命令之后，得到以下结果：&lt;/p&gt;
&lt;pre class=&quot;prism-token token language-js&quot;&gt;
Current partition replica assignment #当前分区的副本分配
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;version&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;1&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partitions&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token string&quot;&gt;&quot;test_topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partition&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;0&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;replicas&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token number&quot;&gt;1002&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1001&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token string&quot;&gt;&quot;test_topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partition&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;2&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;replicas&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token number&quot;&gt;1001&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1003&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token string&quot;&gt;&quot;test_topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partition&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;1&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;replicas&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token number&quot;&gt;1003&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1002&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}
Proposed partition reassignment configuration #建议的分区配置
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;version&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;1&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partitions&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token string&quot;&gt;&quot;test_topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partition&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;0&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;replicas&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token number&quot;&gt;1001&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1002&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token string&quot;&gt;&quot;test_topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partition&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;2&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;replicas&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token number&quot;&gt;1003&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1004&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token string&quot;&gt;&quot;test_topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partition&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;1&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;replicas&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token number&quot;&gt;1002&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1003&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;Proposed partition reassignment configuration 后是根据命令行的指定的broker list生成的分区分配计划json格式。将 Proposed partition reassignment configuration的配置复制保存到一个文件中 move_kafka_topic_result.json：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;{&quot;version&quot;:1,&quot;partitions&quot;:[{&quot;topic&quot;:&quot;test_topic&quot;,&quot;partition&quot;:0,&quot;replicas&quot;:[1001,1002]},{&quot;topic&quot;:&quot;test_topic&quot;,&quot;partition&quot;:2,&quot;replicas&quot;:[1003,1004]},{&quot;topic&quot;:&quot;test_topic&quot;,&quot;partition&quot;:1,&quot;replicas&quot;:[1002,1003]}]}&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;2.3 对topic分区数据进行重新分布&lt;/h2&gt;
&lt;p&gt;执行重新分配命令：&lt;/p&gt;
&lt;pre class=&quot;prism-token token language-js&quot;&gt;
&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token operator&quot;&gt;/kafka&lt;span class=&quot;token operator&quot;&gt;-reassign&lt;span class=&quot;token operator&quot;&gt;-partitions&lt;span class=&quot;token punctuation&quot;&gt;.sh &lt;span class=&quot;token operator&quot;&gt;--zookeeper tbds&lt;span class=&quot;token number&quot;&gt;-172&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;11&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;2181 &lt;span class=&quot;token operator&quot;&gt;--reassignment&lt;span class=&quot;token operator&quot;&gt;-json&lt;span class=&quot;token operator&quot;&gt;-file &lt;span class=&quot;token operator&quot;&gt;/tmp&lt;span class=&quot;token operator&quot;&gt;/move_kafka_topic_result&lt;span class=&quot;token punctuation&quot;&gt;.json &lt;span class=&quot;token operator&quot;&gt;--execute&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;得到如下结果：&lt;/p&gt;
&lt;pre class=&quot;prism-token token language-js&quot;&gt;
Current partition replica assignment
&lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;version&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;1&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partitions&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token string&quot;&gt;&quot;test_topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partition&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;0&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;replicas&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token number&quot;&gt;1002&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1001&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token string&quot;&gt;&quot;test_topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partition&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;2&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;replicas&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token number&quot;&gt;1001&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1003&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token string&quot;&gt;&quot;test_topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partition&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;1&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;replicas&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token number&quot;&gt;1003&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1002&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}
Save &lt;span class=&quot;token keyword&quot;&gt;this to use &lt;span class=&quot;token keyword&quot;&gt;as the &lt;span class=&quot;token operator&quot;&gt;--reassignment&lt;span class=&quot;token operator&quot;&gt;-json&lt;span class=&quot;token operator&quot;&gt;-file option during rollback
Successfully started reassignment &lt;span class=&quot;token keyword&quot;&gt;of partitions &lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;version&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;1&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partitions&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token string&quot;&gt;&quot;test_topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partition&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;0&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;replicas&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token number&quot;&gt;1001&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1002&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token string&quot;&gt;&quot;test_topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partition&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;2&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;replicas&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token number&quot;&gt;1003&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1004&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token punctuation&quot;&gt;{&lt;span class=&quot;token string&quot;&gt;&quot;topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token string&quot;&gt;&quot;test_topic&quot;&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;partition&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;1&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token string&quot;&gt;&quot;replicas&quot;&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token punctuation&quot;&gt;[&lt;span class=&quot;token number&quot;&gt;1002&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1003&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}&lt;span class=&quot;token punctuation&quot;&gt;]&lt;span class=&quot;token punctuation&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;从返回结果来看，分区数据重新分布任务已经启动成功。&lt;/p&gt;
&lt;h2&gt;2.4 查看分区数据重新分布进度&lt;/h2&gt;
&lt;p&gt;检查分配的状态，执行命令：&lt;/p&gt;
&lt;pre class=&quot;prism-token token language-js&quot;&gt;
&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token operator&quot;&gt;/kafka&lt;span class=&quot;token operator&quot;&gt;-reassign&lt;span class=&quot;token operator&quot;&gt;-partitions&lt;span class=&quot;token punctuation&quot;&gt;.sh &lt;span class=&quot;token operator&quot;&gt;--zookeeper tbds&lt;span class=&quot;token number&quot;&gt;-172&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;16&lt;span class=&quot;token operator&quot;&gt;-&lt;span class=&quot;token number&quot;&gt;11&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;2181 &lt;span class=&quot;token operator&quot;&gt;--reassignment&lt;span class=&quot;token operator&quot;&gt;-json&lt;span class=&quot;token operator&quot;&gt;-file &lt;span class=&quot;token operator&quot;&gt;/tmp&lt;span class=&quot;token operator&quot;&gt;/move_kafka_topic_result&lt;span class=&quot;token punctuation&quot;&gt;.json &lt;span class=&quot;token operator&quot;&gt;--verify&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;得到结果：&lt;/p&gt;
&lt;pre class=&quot;prism-token token language-js&quot;&gt;
Status &lt;span class=&quot;token keyword&quot;&gt;of partition reassignment&lt;span class=&quot;token punctuation&quot;&gt;:
Reassignment &lt;span class=&quot;token keyword&quot;&gt;of partition &lt;span class=&quot;token punctuation&quot;&gt;[test_topic&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;0&lt;span class=&quot;token punctuation&quot;&gt;] completed successfully
Reassignment &lt;span class=&quot;token keyword&quot;&gt;of partition &lt;span class=&quot;token punctuation&quot;&gt;[test_topic&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;2&lt;span class=&quot;token punctuation&quot;&gt;] completed successfully
Reassignment &lt;span class=&quot;token keyword&quot;&gt;of partition &lt;span class=&quot;token punctuation&quot;&gt;[test_topic&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1&lt;span class=&quot;token punctuation&quot;&gt;] completed successfully&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;表明分区数据重新分步任务已经完成。&lt;/p&gt;
&lt;h2&gt;2.5 再次获取test_topic的分区分布情况&lt;/h2&gt;
&lt;p&gt;再次查看各个分区的分布情况，执行命令：&lt;/p&gt;
&lt;pre class=&quot;prism-token token language-js&quot;&gt;
&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token operator&quot;&gt;/kafka&lt;span class=&quot;token operator&quot;&gt;-topics&lt;span class=&quot;token punctuation&quot;&gt;.sh &lt;span class=&quot;token operator&quot;&gt;--zookeeper &lt;span class=&quot;token number&quot;&gt;172.16&lt;span class=&quot;token punctuation&quot;&gt;.&lt;span class=&quot;token number&quot;&gt;16.11&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;2181 &lt;span class=&quot;token operator&quot;&gt;--topic test_topic &lt;span class=&quot;token operator&quot;&gt;--describe&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;得到返回结果：&lt;/p&gt;
&lt;pre class=&quot;prism-token token language-js&quot;&gt;
Topic&lt;span class=&quot;token punctuation&quot;&gt;:test_topic PartitionCount&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;3 ReplicationFactor&lt;span class=&quot;token punctuation&quot;&gt;:&lt;span class=&quot;token number&quot;&gt;2 Configs&lt;span class=&quot;token punctuation&quot;&gt;:
Topic&lt;span class=&quot;token punctuation&quot;&gt;: test_topic Partition&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;0 Leader&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1002 Replicas&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1001&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1002 Isr&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1002&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1001
Topic&lt;span class=&quot;token punctuation&quot;&gt;: test_topic Partition&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1 Leader&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1003 Replicas&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1002&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1003 Isr&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1003&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1002
Topic&lt;span class=&quot;token punctuation&quot;&gt;: test_topic Partition&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;2 Leader&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1003 Replicas&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1003&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1004 Isr&lt;span class=&quot;token punctuation&quot;&gt;: &lt;span class=&quot;token number&quot;&gt;1003&lt;span class=&quot;token punctuation&quot;&gt;,&lt;span class=&quot;token number&quot;&gt;1004&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;p&gt;从结果看出，test_topic的分区数据已经由原来的3个broker，重新分布到4个broker。&lt;/p&gt;

&lt;p&gt;Ø Kafka broker 内部不同数据盘之间可以自由迁移分区数据目录。迁移完成后，重启kafka即可生效；&lt;/p&gt;
&lt;p&gt;Ø Kafka 不同broker之前可以迁移数据，使用kafka自带的kafka-reassign-partitions.sh脚本工具实现。&lt;/p&gt;

&lt;p&gt;我们采用本文测试的方法，对该客户的Kafka集群进行broker节点内部不同磁盘间的数据迁移，对多个topic均进行了数据迁移，最终实现磁盘间的数据缓存分布均匀化。&lt;/p&gt;
&lt;p&gt;同时，我们又对客户的kafka集群进行扩容，扩容之后采用本文描述的不同broker之间迁移分区数据方法，对多个topic均进行了数据迁移，保证新扩容节点也有缓存数据，原来的broker节点存储压力减小。&lt;/p&gt;

&lt;h2&gt;相关阅读&lt;/h2&gt;


</description>
<pubDate>Mon, 22 Jan 2018 09:35:00 +0000</pubDate>
<dc:creator>云加社区</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/qcloud1001/p/8330233.html</dc:identifier>
</item>
<item>
<title>以太坊RPC机制与API实例 - 一面千人</title>
<link>http://www.cnblogs.com/Evsward/p/ether-rpc.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Evsward/p/ether-rpc.html</guid>
<description>&lt;blockquote readability=&quot;6.480198019802&quot;&gt;
&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/Evsward/p/ethereum.html&quot;&gt;上一篇文章&lt;/a&gt;介绍了以太坊的基础知识，我们了解了web3.js的调用方式是通过以太坊RPC技术，本篇文章旨在研究如何开发、编译、运行与使用以太坊RPC接口。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;关键字：以太坊，RPC，JSON-RPC，client，server，api，web3.js，api实例，Postman&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;以太坊json-rpc-api&quot;&gt;以太坊JSON RPC API&lt;/h2&gt;
&lt;h3 id=&quot;geth命令api相关&quot;&gt;geth命令api相关&lt;/h3&gt;
&lt;p&gt;之前介绍过这些API都可以在geth console中调用，而在实际应用中，纯正完整的RPC的调用方式，&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;geth --rpc --rpcapi &quot;db,eth,net,web3,personal&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个命令可以启动http的rpc服务，当然他们都是geth命令下的，仍旧可以拼接成一个多功能的命令串，可以了解一下上一篇介绍的geth的使用情况。下面介绍一下api相关的选项参数：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;API AND CONSOLE OPTIONS:
  --rpc                  启动HTTP-RPC服务（基于HTTP的）
  --rpcaddr value        HTTP-RPC服务器监听地址(default: &quot;localhost&quot;)
  --rpcport value        HTTP-RPC服务器监听端口(default: 8545)
  --rpcapi value         指定需要调用的HTTP-RPC API接口，默认只有eth,net,web3
  --ws                   启动WS-RPC服务（基于WebService的）
  --wsaddr value         WS-RPC服务器监听地址(default: &quot;localhost&quot;)
  --wsport value         WS-RPC服务器监听端口(default: 8546)
  --wsapi value          指定需要调用的WS-RPC API接口，默认只有eth,net,web3
  --wsorigins value      指定接收websocket请求的来源
  --ipcdisable           禁掉IPC-RPC服务
  --ipcpath              指定IPC socket/pipe文件目录（明确指定路径）
  --rpccorsdomain value  指定一个可以接收请求来源的以逗号间隔的域名列表（浏览器访问的话，要强制指定该选项）
  --jspath loadScript    JavaScript根目录用来加载脚本 (default: &quot;.&quot;)
  --exec value           执行JavaScript声明
  --preload value        指定一个可以预加载到控制台的JavaScript文件，其中包含一个以逗号分隔的列表
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们在执行以上启动rpc命令时可以同时指定网络，指定节点，指定端口，指定可接收域名，甚至可以同时打开一个console，这也并不产生冲突。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;geth --rpc --rpcaddr &amp;lt;ip&amp;gt; --rpcport &amp;lt;portnumber&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们可以指定监听地址以及端口，如果不谢rpcaddr和rpcport的话，就是默认的http://localhost:8545。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;geth --rpc --rpccorsdomain &quot;http://localhost:3000&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果你要使用浏览器来访问的话，就要强制指定rpccorsdomain选项，否则的话由于JavaScript调用的同源限制，请求会失败。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;admin.startRPC(addr, port)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果已进入geth console，也可以通过这条命令添加地址和端口。&lt;/p&gt;
&lt;h3 id=&quot;postmanhttp请求api&quot;&gt;Postman，HTTP请求api&lt;/h3&gt;
&lt;p&gt;Postman是一个可以用来测试各种http请求的客户端工具，它还有其他很多用途，但这里只用它来测试上面的HTTP-RPC服务。&lt;br/&gt;&lt;img src=&quot;https://github.com/evsward/mainbase/blob/master/resource/image/restful/Postman.png?raw=true&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;看图说话，我们指定了请求地址端口，指定了HTTP POST请求方式，设置好请求为原始Json文本，请求内容为：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;{&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;method&quot;:&quot;web3_clientVersion&quot;,&quot;params&quot;:[],&quot;id&quot;:67}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;是用来请求服务器当前web3客户端版本的，然后点击&quot;Send&quot;，得到请求结果为：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;{
    &quot;jsonrpc&quot;: &quot;2.0&quot;,
    &quot;id&quot;: 67,
    &quot;result&quot;: &quot;Geth/v0.0.1-stable-930fa051/linux-amd64/go1.9.2&quot;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;以太坊go源码调用rpc&quot;&gt;以太坊Go源码调用rpc&lt;/h3&gt;
&lt;p&gt;我们就以最常用的&lt;a href=&quot;https://github.com/ethereum/wiki/wiki/JSON-RPC#eth_getbalance&quot;&gt;api：eth_getBalance&lt;/a&gt;为例，它的参数要求为：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Parameters
- DATA, 20 Bytes - address to check for balance.
- QUANTITY|TAG - integer block number, or the string &quot;latest&quot;, &quot;earliest&quot; or &quot;pending&quot;, see the default block parameter
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;该api要求的参数：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;第一个参数为需检查余额的地址&lt;/li&gt;
&lt;li&gt;第二个参数为整数区块号，或者是字符串“latest&quot;,&quot;earliest&quot;以及&quot;pending&quot;指代某个特殊的区块。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在go-ethereum项目中查找到使用位置ethclient/ethclient.go：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;func (ec *Client) BalanceAt(ctx context.Context, account common.Address, blockNumber *big.Int) (*big.Int, error) {
    var result hexutil.Big
    err := ec.c.CallContext(ctx, &amp;amp;result, &quot;eth_getBalance&quot;, account, toBlockNumArg(blockNumber))
    return (*big.Int)(&amp;amp;result), err
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;func (ec *Client) PendingBalanceAt(ctx context.Context, account common.Address) (*big.Int, error) {
    var result hexutil.Big
    err := ec.c.CallContext(ctx, &amp;amp;result, &quot;eth_getBalance&quot;, account, &quot;pending&quot;)
    return (*big.Int)(&amp;amp;result), err
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结合上面的RPC API和下面的go源码的调用，可以看到在go语言中的调用方式：要使用客户端指针类型变量调用到上下文Call的方法，传入第一个参数为上下文实例，第二个参数为一个hexutil.Big类型的结果接收变量的指针，第三个参数为调用的rpc的api接口名称，第四个和第五个为该api的参数，如上所述。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;跟踪到ec.c.CallContext，CallContext方法是ec.c对象的。&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;// Client defines typed wrappers for the Ethereum RPC API.
type Client struct {
    c *rpc.Client
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到ethclient/ethclient.go文件中将原rpc/client.go的Client结构体进行了一层包裹，这样就可以区分出来属于ethclient的方法和底层rpc/client的方法。下面贴出原始的rpc.client的结构体定义：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;// Client represents a connection to an RPC server.
type Client struct {
    idCounter   uint32
    connectFunc func(ctx context.Context) (net.Conn, error)
    isHTTP      bool

    // writeConn is only safe to access outside dispatch, with the
    // write lock held. The write lock is taken by sending on
    // requestOp and released by sending on sendDone.
    writeConn net.Conn

    // for dispatch
    close       chan struct{}
    didQuit     chan struct{}                  // closed when client quits
    reconnected chan net.Conn                  // where write/reconnect sends the new connection
    readErr     chan error                     // errors from read
    readResp    chan []*jsonrpcMessage         // valid messages from read
    requestOp   chan *requestOp                // for registering response IDs
    sendDone    chan error                     // signals write completion, releases write lock
    respWait    map[string]*requestOp          // active requests
    subs        map[string]*ClientSubscription // active subscriptions
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;ethclient经过包裹以后，可以使用本地Client变量调用rpc.client的指针变量c，从而调用其CallContext方法：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;func (c *Client) CallContext(ctx context.Context, result interface{}, method string, args ...interface{}) error {
    msg, err := c.newMessage(method, args...) // 看来CallContext还不是终点，TODO:进到newMessage方法内再看看。
    // 结果处理
    if err != nil {
        return err
    }
    // requestOp又一个结构体，封装响应参数的，包括原始请求消息，响应信息jsonrpcMessage，jsonrpcMessage也是一个结构体，封装了响应消息标准内容结构，包括版本，ID，方法，参数，错误，返回值，其中RawMessage在go源码位置json/stream.go又是一个自定义类型，属于go本身封装好的，类型是字节数组[]byte，也有自己的各种功能的方法。
    op := &amp;amp;requestOp{ids: []json.RawMessage{msg.ID}, resp: make(chan *jsonrpcMessage, 1)}

    // 通过rpc不同的渠道发送响应消息：这些渠道在上面命令部分已经介绍过，有HTTP，WebService等。
    if c.isHTTP {
        err = c.sendHTTP(ctx, op, msg)
    } else {
        err = c.send(ctx, op, msg)
    }
    if err != nil {
        return err
    }

    // TODO:对wait方法的研究
    // 对wait方法返回结果的处理
    switch resp, err := op.wait(ctx); {
    case err != nil:
        return err
    case resp.Error != nil:
        return resp.Error
    case len(resp.Result) == 0:
        return ErrNoResult
    default:
        return json.Unmarshal(resp.Result, &amp;amp;result)// 顺利将结果数据编出
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;先看wait方法，它仍旧在rpc/client.go中：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;func (op *requestOp) wait(ctx context.Context) (*jsonrpcMessage, error) {
    select {
    case &amp;lt;-ctx.Done():
        return nil, ctx.Err()
    case resp := &amp;lt;-op.resp:
        return resp, op.err
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;select的使用请参考&lt;a href=&quot;http://www.cnblogs.com/Evsward/p/go.html#select&quot;&gt;这里&lt;/a&gt;。继续正题，进入ctx.Done()，Done属于Go源码context/context.go:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;// See https://blog.golang.org/pipelines for more examples of how to use
// a Done channel for cancelation.
Done() &amp;lt;-chan struct{}&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;4.5985401459854&quot;&gt;
&lt;p&gt;想知道Done()咋回事，请转到我写的另一篇博文&lt;a href=&quot;http://www.cnblogs.com/Evsward/p/goPipeline.html&quot;&gt;Go并发模式：管道与取消&lt;/a&gt;，那里仔细分析了这一部分内容。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;从上面的源码分析我感觉go语言就是一个网状结构，从一个结构体跳进另一个结构体，它们之间谁也不属于谁，谁调用了谁就可以使用，没有显式继承extends和显式实现implements，go就是不断的封装结构体，然后增加该结构体的方法，有时候你甚至都忘记了自己程序的结构体和Go源码封装的结构体之间的界限。这就类似于面向对象分析的类，定义一个类，定义它的成员属性，写它的成员方法。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;web3与rpc的关系&quot;&gt;web3与rpc的关系&lt;/h3&gt;
&lt;p&gt;这里再多啰嗦一句，重申一下web3和rpc的关系：&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;To make your app work on Ethereum, you can use the web3 object provided by the web3.js library. Under the hood it communicates to a local node through RPC calls. web3.js works with any Ethereum node, which exposes an RPC layer.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;翻译过来就是为了让你的api工作在以太坊，你可以使用由web3.js库提供的web3对象。底层通过RPC调用本地节点进行通信。web3.js可以与以太坊任何一个节点通信，这一层就是暴露出来的RPC层。&lt;/p&gt;
&lt;h3 id=&quot;开发自己的api&quot;&gt;开发自己的api&lt;/h3&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;设定一个小需求：就是将余额数值乘以指定乘数，这个乘数是由另一个接口的参数来指定的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在ethapi中加入&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var rateFlag uint64 = 1
// Start forking command.
// Rate is the fork coin's exchange rate.
func (s *PublicBlockChainAPI) Forking(ctx context.Context, rate uint64) (uint64) {
    // attempt: store the rate info in context.
    // context.WithValue(ctx, &quot;rate&quot;, rate)
    rateFlag = rate
    rate = rate + 1
    return rate
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后在ethclient中加入&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;// Forking tool's client for the Ethereum RPC API
func (ec *Client) ForkingAt(ctx context.Context, account common.Address, rate uint64)(uint64, error){
    var result hexutil.Uint64
    err := ec.c.CallContext(ctx, &amp;amp;result, &quot;eth_forking&quot;, account, rate)
    return uint64(result), err
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;保存，make geth编译，然后在节点目录下启动&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;geth --testnet --rpc console --datadir node0&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后进入到Postman中测试，可以看到&lt;br/&gt;&lt;img src=&quot;https://github.com/evsward/mainbase/blob/master/resource/image/restful/forking.png?raw=true&quot; alt=&quot;image&quot;/&gt;&lt;br/&gt;乘数已经改为3（输出4是为了测试，实际上已在局部变量rateFlag保存了乘数3）&lt;br/&gt;然后我们再发送请求余额测试，&lt;br/&gt;&lt;img src=&quot;https://github.com/evsward/mainbase/blob/master/resource/image/restful/balance.png?raw=true&quot; alt=&quot;image&quot;/&gt;&lt;br/&gt;可以看到返回值为一串16进制数，通过转换结果为:417093750000000000000，我们原始余额为:139031250000000000000，正好三倍。&lt;/p&gt;
&lt;h3 id=&quot;rpc客户端&quot;&gt;rpc客户端&lt;/h3&gt;
&lt;p&gt;我们上面已经在rpc服务端对api进行了增加，而客户端调用采用的是Postman发送Post请求。而rpc客户端在以太坊实际上有两种：一个是刚才我们实验的，在网页中调用JSON-RPC；另一种则是geth console的形式，而关于这种形式，我还没真正搞清楚它部署的流程，只是看到了在源代码根目录下build/_workspace会在每一次make geth被copy进去所有的源码作为编译后环境，而我修改了源码文件，_workspace下文件，均未生效，可能还存在一层运行环境，我并没有修改到。但这无所谓了，因为实际应用中，我们很少去该console的内容，直接修改web3.js引入到网页即可。下面介绍一下配合上面自己的api，如何修改web3.js文件：&lt;/p&gt;
&lt;p&gt;上面讲过了web3.js的结构，是一个node.js的module结构，因此我们先决定将这个api放到eth对象下，检查eth对应的id为38，找到对象体，在methods中增加对应api调用操作，&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;var forking = new Method({
    name: 'forking',
    call: 'eth_forking',
    params: 1,
    inputFormatter: [null],
    outputFormatter: formatters.outputBigNumberFormatter
});&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后在对象体返回值部分将我们新构建的method添加进去，&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;return [
    forking,
    ...&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;改好以后，我们将该文件引用到页面中去，即可通过web3.eth.forking(3)进行调用了。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;本文介绍了rpc的概念，rpc的流行框架，以太坊使用的rpc框架为JSON-RPC。接着描述了如何启动JSON-RPC服务端，然后使用Postman来请求JSON-RPC服务端api。通过这一流程，我们仔细分析并跟踪了源码中的实现，抽丝剥茧，从最外层的JSON-RPC的调用规范到源码中外层封装的引用，到内部具体实现，期间对各种自定义结构体进行了跟踪研究，直到Go源码库中的结构体，研究了服务端从接收客户端请求到发送响应的过程。最后我们仔细研究了web3.js文件的结构并且做了一个小实验，从服务端到客户端模仿者增加了一个自定义的api。希望本文对您有所帮助。&lt;/p&gt;

</description>
<pubDate>Mon, 22 Jan 2018 09:31:00 +0000</pubDate>
<dc:creator>一面千人</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/Evsward/p/ether-rpc.html</dc:identifier>
</item>
<item>
<title>Oracle dblink - TinaCherry</title>
<link>http://www.cnblogs.com/tinazzz/p/8330105.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/tinazzz/p/8330105.html</guid>
<description>&lt;li&gt;使用 CREATE DATABASE LINK 语句来创建数据库链接。数据库链接是在一个数据库中，使您能够访问其它数据库对象的模式对象&lt;/li&gt;&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;在创建数据库链接之后，可以通过在表，视图 或 PL / SQL 对象名称后加上 &lt;code&gt;@dblink&lt;/code&gt;，来访问其他数据库中的表、视图 或 PL / SQL对象；可以使用 SELECT 语句查询其他数据库中的表或视图，也可以使用 INSERT，UPDATE，DELETE 或 LOCK TABLE 语句操作远程表和视图&lt;/p&gt;
&lt;h3 id=&quot;先决条件&quot;&gt;先决条件&lt;/h3&gt;
&lt;/li&gt;
&lt;li&gt;要创建私有 dblink，必须具有 CREATE DATABASE LINK 系统权限&lt;/li&gt;
&lt;li&gt;要创建公共 dblink，必须具有 CREATE PUBLIC DATABASE LINK 系统权限&lt;/li&gt;
&lt;li&gt;另外，必须拥有远程 Oracle 数据库的 CREATE SESSION 系统权限&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;Oracle Net 必须安装在本地和远程 Oracle 数据库上&lt;/p&gt;
&lt;h3 id=&quot;语法&quot;&gt;语法&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1187703/201801/1187703-20180122171650256-773548666.png&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;public&quot;&gt;PUBLIC&lt;/h3&gt;
&lt;/li&gt;
&lt;li&gt;指定 PUBLIC 创建公共数据库链接，所有用户可用；如果省略，那么数据库链接是私有的，只对创建者可用&lt;/li&gt;
&lt;li&gt;远程数据库上可访问的数据取决于连接到远程数据库时 dblink 使用的身份：&lt;/li&gt;
&lt;li&gt;如果指定 &lt;code&gt;CONNECT TO user IDENTIFIED BY password&lt;/code&gt;，则 dblink 使用指定的用户和密码连接&lt;/li&gt;
&lt;li&gt;如果指定 &lt;code&gt;CONNECT TO CURRENT_USER&lt;/code&gt;，那么 dblink 将根据链接的使用范围与有效的用户连接&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;如果省略这两个子句，则 dblink 将以本地连接的用户连接到远程数据库&lt;/p&gt;
&lt;h3 id=&quot;shared&quot;&gt;SHARED&lt;/h3&gt;
&lt;/li&gt;
&lt;li&gt;指定 SHARED 创建数据库链接，该链接使用从源库到目标库的单个网络连接来共享多个会话。在共享服务器配置中，共享数据库链接可以使连接到远程数据库的连接数量不会变得太大。&lt;strong&gt;共享链接通常也是公共数据库链接&lt;/strong&gt;。但是，当多个客户端访问同一个本地 schema 时，共享私有数据库链接可能会很有用，因此使用同一个私有数据库链接&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;在共享数据库链接中，源库的多个会话共享目标库上的同一个连接。一旦在目标库上建立了一个会话，该会话将从连接中解除关联，从而使该连接可用于源库上的另一个会话。为防止未经授权的会话试图通过 dblink 进行连接，在指定 SHARED 时还必须为授权使用数据库链接的用户指定 &lt;code&gt;dblink_authentication&lt;/code&gt; 子句&lt;/p&gt;
&lt;h3 id=&quot;dblink&quot;&gt;dblink&lt;/h3&gt;
&lt;/li&gt;
&lt;li&gt;指定数据库链接的完整名称或部分名称。如果仅指定数据库名称，则 Oracle 数据库隐式附加本地数据库的数据库域&lt;/li&gt;
&lt;li&gt;仅支持 ASCII 字符的 dblink，不支持多字节字符&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据库链接名称不区分大小写，并以大写的 ASCII 字符存储；如果将数据库名称指定为带引号的标识符，则引号将被忽略&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;如果 GLOBAL_NAMES 初始化参数的值是TRUE，则 dblink 必须与它所连接的数据库具有相同的名称&lt;/li&gt;
&lt;li&gt;在一个会话或 Oracle RAC 的一个实例中可以打开的最大 dblink 数取决于初始化参数OPEN_LINKS 和 OPEN_LINKS_PER_INSTANCE 的值&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;创建 dblink 的限制&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;不能在其他用户的 schema 中创建数据库链接，也不能使用 schema 的名称来限定 dblink&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;dblink 的名字中可以使用句点 &lt;code&gt;.&lt;/code&gt;，所以 Oracle 数据库将整个字符串（比如 &lt;code&gt;ralph.linktosales&lt;/code&gt;）解释为数据库链接的名字，而不是 ralph 用户有一个数据库链接 linktosales&lt;/p&gt;
&lt;h3 id=&quot;connect-to-子句&quot;&gt;CONNECT TO 子句&lt;/h3&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;CONNECT TO 子句允许您指定要用于连接到远程数据库的用户和凭证（如果有）&lt;/p&gt;
&lt;h4 id=&quot;current_user子句&quot;&gt;CURRENT_USER子句&lt;/h4&gt;
&lt;/li&gt;
&lt;li&gt;指定 CURRENT_USER 创建当前用户数据库链接（current user database link），当前用户必须是在远程数据库上具有有效帐户的全局用户&lt;/li&gt;
&lt;li&gt;如果直接使用 dblink 而不是从存储对象中使用，则 CURRENT_USER 就是所连接的用户&lt;/li&gt;
&lt;li&gt;执行使用 dblink 的存储对象（如过程，视图或触发器）时，CURRENT_USER 是拥有该存储对象的用户，而不是调用该对象的用户。例如，如果 dblink 出现在过程 scott.p（由scott 创建），并且用户 jane 调用过程 scott.p，则 CURRENT_USER 是 scott&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;但是，如果存储对象是调用者权限的函数，过程或包，则调用者的授权 ID 被用作远程用户的连接。例如，如果 dblink 出现在过程 scott.p（scott 创建的一个调用者权限过程），并且用户 Jane 调用过程 scott.p，然后 CURRENT_USER 是 jane，使用 Jane 的权限执行存储过程&lt;/p&gt;
&lt;h4 id=&quot;user-identified-by-passwd&quot;&gt;user IDENTIFIED BY passwd&lt;/h4&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;使用固定用户数据库链接（fixed user database link）指定用于连接到远程数据库的用户名和密码。如果省略此子句，则 dblink 将使用连接到数据库的用户的用户名和密码，这称为连接用户数据库链接（connected user database link）&lt;/p&gt;
&lt;h3 id=&quot;dblink_authentication&quot;&gt;dblink_authentication&lt;/h3&gt;
&lt;/li&gt;
&lt;li&gt;只有在创建共享数据库链接时（也就是说，指定了 SHARED 子句），才能指定此子句&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;指定目标实例上的用户名和密码。此子句将用户认证远到程服务器上，并且是安全所需的。指定的用户名和密码必须是远程实例上的有效用户名和密码。用户名和密码仅用于身份验证，不为该用户执行其他操作&lt;/p&gt;
&lt;h3 id=&quot;定义一个固定用户-dblink&quot;&gt;定义一个固定用户 dblink&lt;/h3&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;remote 数据库中的 hr 用户定义了一个名为 local 的固定用户数据库链接，使用 local 数据库的 hr 用户连接&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;CREATE DATABASE LINK local 
  CONNECT TO hr IDENTIFIED BY password
  USING 'local';&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;在创建这个数据库链接之后，hr 可以查询 local 数据库中 hr 的表：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;SELECT * FROM employees @ local;&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;11&quot;&gt;
&lt;p&gt;用户 hr 还可以使用 DML 语句来修改 local 数据库上 hr 用户的表数据：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;INSERT INTO employees@local
  (employee_id, last_name, email, hire_date, job_id)
  VALUES (999, 'Claus', 'sclaus@example.com', SYSDATE, 'SH_CLERK');
UPDATE jobs@local SET min_salary = 3000
  WHERE job_id = 'SH_CLERK';
DELETE FROM employees@local 
  WHERE employee_id = 999;&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;使用此固定数据库链接，remote 数据库上的 hr 用户还可以访问 local 数据库上其他用户的表。这条语句假定 hr 用户拥有 oe.customers 的 SELECT权限。该语句连接到 local 数据库的 hr 用户，然后查询 oe.customers 表：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;SELECT * FROM oe.customers@local;&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
</description>
<pubDate>Mon, 22 Jan 2018 09:26:00 +0000</pubDate>
<dc:creator>TinaCherry</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/tinazzz/p/8330105.html</dc:identifier>
</item>
<item>
<title>Redis介绍及Jedis测试 - 无涯Ⅱ</title>
<link>http://www.cnblogs.com/wlandwl/p/redis.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wlandwl/p/redis.html</guid>
<description>&lt;h3&gt;1.Redis简介&lt;/h3&gt;
&lt;p&gt;    Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串（strings）， 散列（hashes）， 列表（lists）， 集合（sets）， 有序集合（sorted sets） 与范围查询， bitmaps， hyperloglogs 和 地理空间（geospatial） 索引半径查询。 Redis 内置了 复制（replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（transactions） 和不同级别的 磁盘持久化（persistence）， 并通过 Redis哨兵（Sentinel）和自动 分区（Cluster）提供高可用性（high availability）。Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。&lt;/p&gt;
&lt;p&gt;    Redis 与其他 key - value 缓存产品有以下三个特点：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。&lt;/li&gt;
&lt;li&gt;Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。&lt;/li&gt;
&lt;li&gt;Redis支持数据的备份，即master-slave模式的数据备份。&lt;/li&gt;
&lt;/ol&gt;&lt;h3&gt;2.Redis优势&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;性能极高 – Redis能读的速度是110000次/s,写的速度是81000次/s 。&lt;/li&gt;
&lt;li&gt;丰富的数据类型 – Redis支持二进制案例的 Strings, Lists, Hashes, Sets 及 Ordered Sets 数据类型操作。&lt;/li&gt;
&lt;li&gt;原子 – Redis的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。&lt;/li&gt;
&lt;li&gt;丰富的特性 – Redis还支持 publish/subscribe, 通知, key 过期等等特性。&lt;/li&gt;
&lt;li&gt;Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。&lt;/li&gt;
&lt;/ol&gt;&lt;h3&gt;3.linux环境下安装Redis&lt;/h3&gt;
&lt;p&gt;    1.下载地址：&lt;a href=&quot;http://redis.io/download&quot; target=&quot;_blank&quot;&gt;http://redis.io/download&lt;/a&gt;，下载最新版本的linux版本Redis。&lt;/p&gt;
&lt;p&gt;    2.本教程使用的最新文档版本为 4.0.6，下载文件后，上传到linux服务器上面，并解压安装。&lt;/p&gt;
&lt;p&gt;     操作指令为：&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;com&quot;&gt;&lt;span class=&quot;pln&quot;&gt;$ tar xzf redis&lt;span class=&quot;pun&quot;&gt;-4.0.6&lt;span class=&quot;lit&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;lit&quot;&gt;.tar&lt;span class=&quot;pun&quot;&gt;.&lt;span class=&quot;pln&quot;&gt;gz     &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;com&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;lit&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;lit&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;pln&quot;&gt;$ cd redis&lt;span class=&quot;pun&quot;&gt;-&lt;span class=&quot;pln&quot;&gt;4.0.6    &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;com&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;lit&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;lit&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pln&quot;&gt;$ make &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;com&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;lit&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;lit&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;com&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;lit&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;lit&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pln&quot;&gt;    3.make成功执行完后 redis- 4.0.6目录会生成src 目录，在一次执行命令：&lt;span class=&quot;pln&quot;&gt;$ make install&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;pln&quot;&gt;         &lt;img src=&quot;https://images2017.cnblogs.com/blog/626790/201801/626790-20180118232458943-1509689652.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pln&quot;&gt;    4.启动redis服务,使用默认配置方式启动：进入到&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;com&quot;&gt;&lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;lit&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;lit&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;pln&quot;&gt;redis&lt;span class=&quot;pun&quot;&gt;-&lt;span class=&quot;pln&quot;&gt;4.0.6/src目录，执行启动命令：redis-server &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    &lt;img src=&quot;https://images2017.cnblogs.com/blog/626790/201801/626790-20180118232545881-1751387095.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;    &lt;strong&gt;注意：&lt;/strong&gt;这里直接执行Redis-server 启动的Redis服务，是在前台直接运行的(效果如上图)，也就是说，执行完该命令后，如果Linux关闭当前会话，则Redis服务也随即关闭。正常情况下，启动Redis服务需要从后台启动，并且指定启动配置文件。 &lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;strong&gt;后台启动&lt;/strong&gt;&lt;strong&gt;redis&lt;/strong&gt;&lt;strong&gt;服务&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;首先编辑conf文件，将daemonize属性改为yes（表明需要在后台运行）,并指定ip地址，开放redis端口号：6379。操作指令为：cd &lt;span class=&quot;pln&quot;&gt;&lt;span class=&quot;pun&quot;&gt;&lt;span class=&quot;com&quot;&gt;&lt;span class=&quot;pln&quot;&gt;redis&lt;span class=&quot;pun&quot;&gt;-4.0.6/ vi redis.conf&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;再次启动redis服务，并指定启动服务配置文件:  redis-server /usr/local/redis/etc/redis.conf    &lt;/li&gt;
&lt;li&gt;在防火墙中开放端口：6379&lt;/li&gt;
&lt;/ol&gt;&lt;p align=&quot;left&quot;&gt;     &lt;img src=&quot;https://images2017.cnblogs.com/blog/626790/201801/626790-20180118233151724-2098646405.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;    在本地电脑上，安装一个redis客户端连接工具，如：redisclient-win32.x86.1.5。利用连接工具可方便查看redis中设置的缓存数据，连接如图所示：   &lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/626790/201801/626790-20180118233217193-775449721.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;4.jedis操作Redis介绍&lt;/h3&gt;
&lt;p&gt;    jedis 是 Redis 官方首选的 Java 客户端开发包，上手比较容易。jedis提供了以下三种操作方式：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;单机单连接方式：此方式仅建议用于开发环境做调试用。&lt;/li&gt;
&lt;li&gt;单机连接池方式：此方式适用于仅使用单个Redis实例的场景&lt;/li&gt;
&lt;li&gt;多机分布式+连接池方式：此方式适用规模较大的系统，往往会有多个Redis实例做负载均衡。并且还实现主从备份，当主实例发生故障时，切换至从实例提供服务。现在常用方案有JedisCluster。使用JedisCluster连接使用这种方式时,默认Redis已经进行了集群处理,JedisCluster即针对整个集群的连接.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/626790/201801/626790-20180118234626193-1925481191.png&quot; alt=&quot;&quot;/&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt; jedis操作redis模式&lt;br/&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;(1)事务方式(Transactions)&lt;/p&gt;
&lt;p&gt;    所谓事务，即一个连续操作，是否执行是一个事务，要么完成，要么失败，没有中间状态。而redis的事务很简单，他主要目的是保障，一个client发起的事务中的命令可以连续的执行，而中间不会插入其他client的命令，也就是事务的连贯性。&lt;/p&gt;
&lt;p&gt;   测试截图&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://images2017.cnblogs.com/blog/626790/201801/626790-20180122162650787-455248552.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;(2)管道(Pipelining)&lt;/p&gt;
&lt;p&gt;   管道是一种两个进程之间单向通信的机制。那再redis中，为何要使用管道呢？有时候，需要采用异步的方式，一次发送多个指令，并且，不同步等待其返回结果。这样可以取得非常好的执行效率。管道模式测试代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;  @Test
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; jedisPipelined() {
        Jedis jedis &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; Jedis(&quot;192.168.210.128&quot;, 6379&lt;span&gt;);
        Pipeline pipeline &lt;/span&gt;=&lt;span&gt; jedis.pipelined();
        &lt;/span&gt;&lt;span&gt;long&lt;/span&gt; start =&lt;span&gt; System.currentTimeMillis();
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; i &amp;lt; 1000; i++&lt;span&gt;) {
            pipeline.set(&lt;/span&gt;&quot;p&quot; + i, &quot;p&quot; +&lt;span&gt; i);
        }
        List&lt;/span&gt;&amp;lt;Object&amp;gt; results =&lt;span&gt; pipeline.syncAndReturnAll();
        &lt;/span&gt;&lt;span&gt;long&lt;/span&gt; end =&lt;span&gt; System.currentTimeMillis();
        System.out.println(&lt;/span&gt;&quot;Pipelined SET: &quot; + ((end - start)/1000.0) + &quot; seconds&quot;&lt;span&gt;);
        jedis.disconnect();
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;   &lt;strong&gt;注意：&lt;/strong&gt;事务和管道都是异步模式。在事务和管道中不能同步查询结果。如下代码操作为非法操作：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
Transaction tx =&lt;span&gt; jedis.multi();  
 &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; i &amp;lt; 100000; i++&lt;span&gt;) {  
     tx.set(&lt;/span&gt;&quot;t&quot; + i, &quot;t&quot; +&lt;span&gt; i);  
 }  
   System.out.println(tx.get(&lt;/span&gt;&quot;t1000&quot;).get());  &lt;span&gt;//&lt;/span&gt;&lt;span&gt;不允许  &lt;/span&gt;
   List&amp;lt;Object&amp;gt; results = tx.exec();  
&lt;/pre&gt;&lt;/div&gt;
&lt;div readability=&quot;41&quot;&gt;
&lt;p&gt;(3)管道中调用事务&lt;/p&gt;
&lt;p&gt;    在某种需求下，需要异步执行命令，但是，又希望多个命令是有连续的，所以可采用管道加事务的调用方式。jedis是支持在管道中调用事务的。&lt;/p&gt;
&lt;p&gt;(4)分布式直连同步调用与分布式连接池同步调用&lt;/p&gt;
&lt;p&gt;    这个是分布式直接连接，并且是同步调用，每步执行都返回执行结果。如果，分布式调用代码是运行在线程中，那么分布式直连同步调用方式就不合适了，因为直连方式是非线程安全的，这个时候需使用选择连接池调用。案例代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//分布式直接链接并同步调用
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; jedisShardNormal() {  
    List&lt;/span&gt;&amp;lt;JedisShardInfo&amp;gt; shards =&lt;span&gt; Arrays.asList(  
            &lt;/span&gt;&lt;span&gt;new&lt;/span&gt; JedisShardInfo(&quot;localhost&quot;,6379&lt;span&gt;),  
            &lt;/span&gt;&lt;span&gt;new&lt;/span&gt; JedisShardInfo(&quot;localhost&quot;,6380&lt;span&gt;));  
   
    ShardedJedis sharding &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ShardedJedis(shards);  
   
    &lt;/span&gt;&lt;span&gt;long&lt;/span&gt; start =&lt;span&gt; System.currentTimeMillis();  
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; i &amp;lt; 100000; i++&lt;span&gt;) {  
        String result &lt;/span&gt;= sharding.set(&quot;sn&quot; + i, &quot;n&quot; +&lt;span&gt; i);  
    }  
    &lt;/span&gt;&lt;span&gt;long&lt;/span&gt; end =&lt;span&gt; System.currentTimeMillis();  
    System.out.println(&lt;/span&gt;&quot;Simple@Sharing SET: &quot; + ((end - start)/1000.0) + &quot; seconds&quot;&lt;span&gt;);  
   
    sharding.disconnect();  
}  
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;分布式结合线程池使用&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; jedisShardSimplePool() {  
    List&lt;/span&gt;&amp;lt;JedisShardInfo&amp;gt; shards =&lt;span&gt; Arrays.asList(  
            &lt;/span&gt;&lt;span&gt;new&lt;/span&gt; JedisShardInfo(&quot;localhost&quot;,6379&lt;span&gt;),  
            &lt;/span&gt;&lt;span&gt;new&lt;/span&gt; JedisShardInfo(&quot;localhost&quot;,6380&lt;span&gt;));  
   
    ShardedJedisPool pool &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; ShardedJedisPool(&lt;span&gt;new&lt;/span&gt;&lt;span&gt; JedisPoolConfig(), shards);  
   
    ShardedJedis one &lt;/span&gt;=&lt;span&gt; pool.getResource();  
   
    &lt;/span&gt;&lt;span&gt;long&lt;/span&gt; start =&lt;span&gt; System.currentTimeMillis();  
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; i &amp;lt; 100000; i++&lt;span&gt;) {  
        String result &lt;/span&gt;= one.set(&quot;spn&quot; + i, &quot;n&quot; +&lt;span&gt; i);  
    }  
    &lt;/span&gt;&lt;span&gt;long&lt;/span&gt; end =&lt;span&gt; System.currentTimeMillis();  
    pool.returnResource(one);  
    System.out.println(&lt;/span&gt;&quot;Simple@Pool SET: &quot; + ((end - start)/1000.0) + &quot; seconds&quot;&lt;span&gt;);  
   
    pool.destroy();  
}  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;(5)分布式直连异步调用与分布式连接池异步调用&lt;/p&gt;
&lt;p&gt;    操作与同步相对，案例代码如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt;分布式连接池异步调用测试 线程池使用&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; jedisShardPipelinedPool() {  
    List&lt;/span&gt;&amp;lt;JedisShardInfo&amp;gt; shards =&lt;span&gt; Arrays.asList(  
            &lt;/span&gt;&lt;span&gt;new&lt;/span&gt; JedisShardInfo(&quot;localhost&quot;,6379&lt;span&gt;),  
            &lt;/span&gt;&lt;span&gt;new&lt;/span&gt; JedisShardInfo(&quot;localhost&quot;,6380&lt;span&gt;));  
   
    ShardedJedisPool pool &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; ShardedJedisPool(&lt;span&gt;new&lt;/span&gt;&lt;span&gt; JedisPoolConfig(), shards);  
   
    ShardedJedis one &lt;/span&gt;=&lt;span&gt; pool.getResource();  
   
    ShardedJedisPipeline pipeline &lt;/span&gt;=&lt;span&gt; one.pipelined();  
   
    &lt;/span&gt;&lt;span&gt;long&lt;/span&gt; start =&lt;span&gt; System.currentTimeMillis();  
    &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (&lt;span&gt;int&lt;/span&gt; i = 0; i &amp;lt; 100000; i++&lt;span&gt;) {  
        pipeline.set(&lt;/span&gt;&quot;sppn&quot; + i, &quot;n&quot; +&lt;span&gt; i);  
    }  
    List&lt;/span&gt;&amp;lt;Object&amp;gt; results =&lt;span&gt; pipeline.syncAndReturnAll();  
    &lt;/span&gt;&lt;span&gt;long&lt;/span&gt; end =&lt;span&gt; System.currentTimeMillis();  
    pool.returnResource(one);  
    System.out.println(&lt;/span&gt;&quot;Pipelined@Pool SET: &quot; + ((end - start)/1000.0) + &quot; seconds&quot;&lt;span&gt;);  
    pool.destroy();  
}  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;(6)安全线程连接池(JedisPool)   &lt;/p&gt;
&lt;p&gt;   注意Jedis对象并不是线程安全的，在多线程下使用同一个Jedis对象会出现并发问题。为了避免每次使用Jedis对象时都需要重新构建，Jedis提供了&lt;code&gt;JedisPool&lt;/code&gt;。&lt;code&gt;JedisPool&lt;/code&gt;是基于Commons Pool 2实现的一个线程安全的连接池。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt;线程池模式使用测试：   &lt;/span&gt;
   JedisPoolConfig jedisPoolConfig = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; JedisPoolConfig();
    jedisPoolConfig.setMaxTotal(&lt;/span&gt;10&lt;span&gt;);
    JedisPool pool &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; JedisPool(jedisPoolConfig, &quot;localhost&quot;, 6379&lt;span&gt;);

    Jedis jedis &lt;/span&gt;= &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
    &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt;{
        jedis &lt;/span&gt;=&lt;span&gt; pool.getResource();
        jedis.set(&lt;/span&gt;&quot;pooledJedis&quot;, &quot;hello jedis pool!&quot;&lt;span&gt;);
        System.out.println(jedis.get(&lt;/span&gt;&quot;pooledJedis&quot;&lt;span&gt;));
    }&lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt;(Exception e){
        e.printStackTrace();
    }&lt;/span&gt;&lt;span&gt;finally&lt;/span&gt;&lt;span&gt; {
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;还回pool中&lt;/span&gt;
        &lt;span&gt;if&lt;/span&gt;(jedis != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;){
            jedis.close();
        }
    }
    pool.close();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;(7)多机分布式集合连接池使用&lt;/p&gt;
&lt;p&gt;    此方式适用规模较大的系统，往往会有多个Redis实例做负载均衡。并且还实现主从备份，当主实例发生故障时，切换至从备用实例提供服务。如服务器1挂掉后，可用服务器2继续支撑redis缓存处理。测试代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
**
 * Description:  多机分布式+&lt;span&gt;连接池方式：
 &lt;/span&gt;* Copyright:  2018&lt;span&gt; CSNT. All rights reserved.
 &lt;/span&gt;*&lt;span&gt; Company:CSNT
 &lt;/span&gt;*
 *&lt;span&gt; @author wangling
 &lt;/span&gt;* @version 1.0
 */
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; MultipleJedisPoolTest {

    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt;&lt;span&gt; JedisPoolConfig config;
    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt;&lt;span&gt; ShardedJedisPool sharedJedisPool;

    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt;&lt;span&gt; {
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 生成多机连接List&lt;/span&gt;
        List&amp;lt;JedisShardInfo&amp;gt; shards = &lt;span&gt;new&lt;/span&gt; ArrayList&amp;lt;JedisShardInfo&amp;gt;&lt;span&gt;();
        shards.add( &lt;/span&gt;&lt;span&gt;new&lt;/span&gt; JedisShardInfo(&quot;127.0.0.1&quot;, 6379&lt;span&gt;) );
        shards.add( &lt;/span&gt;&lt;span&gt;new&lt;/span&gt; JedisShardInfo(&quot;192.168.210.128&quot;, 6379&lt;span&gt;) );

        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 初始化连接池配置对象&lt;/span&gt;
        config = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; JedisPoolConfig();
        config.setMaxIdle(&lt;/span&gt;10&lt;span&gt;);
        config.setMaxTotal(&lt;/span&gt;30&lt;span&gt;);
        config.setMaxWaitMillis(&lt;/span&gt;2*1000&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 实例化连接池&lt;/span&gt;
        sharedJedisPool = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ShardedJedisPool(config, shards);

    }

    &lt;/span&gt;&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     * &lt;/span&gt;&lt;span&gt;@param&lt;/span&gt;&lt;span&gt; args
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; main(String[] args) {
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 从连接池获取Jedis连接&lt;/span&gt;
        ShardedJedis shardedJedisConn =&lt;span&gt; sharedJedisPool.getResource();
        shardedJedisConn.set(&lt;/span&gt;&quot;Lemon&quot;, &quot;Hello,my name is Lemon&quot;&lt;span&gt;);
        System.out.println(shardedJedisConn.get(&lt;/span&gt;&quot;Lemon&quot;&lt;span&gt;));
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 释放连接&lt;/span&gt;
&lt;span&gt;        close(shardedJedisConn, sharedJedisPool);

}
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; close(ShardedJedis shardedJedis,ShardedJedisPool sharedJedisPool){
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;(shardedJedis!=&lt;span&gt;null&lt;/span&gt; &amp;amp;&amp;amp;sharedJedisPool!=&lt;span&gt;null&lt;/span&gt;&lt;span&gt;){
            sharedJedisPool.returnResource(shardedJedis);
        }
        &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;(sharedJedisPool!=&lt;span&gt;null&lt;/span&gt;&lt;span&gt;){
            sharedJedisPool.destroy();
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;5.&lt;/strong&gt;&lt;strong&gt;Redis常用命令&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1 连接操作命令&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;quit：关闭连接（connection）&lt;/li&gt;
&lt;li&gt;auth：简单密码认证&lt;/li&gt;
&lt;li&gt;help cmd： 查看cmd帮助，例如：help quit&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;2 持久化&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;save：将数据同步保存到磁盘&lt;/li&gt;
&lt;li&gt;bgsave：将数据异步保存到磁盘&lt;/li&gt;
&lt;li&gt;lastsave：返回上次成功将数据保存到磁盘的Unix时戳&lt;/li&gt;
&lt;li&gt;shutdown：将数据同步保存到磁盘，然后关闭服务&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;3 远程服务控制&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;info：提供服务器的信息和统计&lt;/li&gt;
&lt;li&gt;monitor：实时转储收到的请求&lt;/li&gt;
&lt;li&gt;slaveof：改变复制策略设置&lt;/li&gt;
&lt;li&gt;config：在运行时配置Redis服务器&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;4 对key操作的命令&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;exists(key)：确认一个key是否存在&lt;/li&gt;
&lt;li&gt;del(key)：删除一个key&lt;/li&gt;
&lt;li&gt;type(key)：返回值的类型&lt;/li&gt;
&lt;li&gt;keys(pattern)：返回满足给定pattern的所有key&lt;/li&gt;
&lt;li&gt;randomkey：随机返回key空间的一个&lt;/li&gt;
&lt;li&gt;keyrename(oldname, newname)：重命名key&lt;/li&gt;
&lt;li&gt;dbsize：返回当前数据库中key的数目&lt;/li&gt;
&lt;li&gt;expire：设定一个key的活动时间（s）&lt;/li&gt;
&lt;li&gt;ttl：获得一个key的活动时间&lt;/li&gt;
&lt;li&gt;select(index)：按索引查询&lt;/li&gt;
&lt;li&gt;move(key, dbindex)：移动当前数据库中的key到dbindex数据库&lt;/li&gt;
&lt;li&gt;flushdb：删除当前选择数据库中的所有key&lt;/li&gt;
&lt;li&gt;flushall：删除所有数据库中的所有key&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;5 String&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;set(key, value)：给数据库中名称为key的string赋予值value&lt;/li&gt;
&lt;li&gt;get(key)：返回数据库中名称为key的string的value&lt;/li&gt;
&lt;li&gt;getset(key, value)：给名称为key的string赋予上一次的value&lt;/li&gt;
&lt;li&gt;mget(key1, key2,…, key N)：返回库中多个string的value&lt;/li&gt;
&lt;li&gt;setnx(key, value)：添加string，名称为key，值为value&lt;/li&gt;
&lt;li&gt;setex(key, time, value)：向库中添加string，设定过期时间time&lt;/li&gt;
&lt;li&gt;mset(key N, value N)：批量设置多个string的值&lt;/li&gt;
&lt;li&gt;msetnx(key N, value N)：如果所有名称为key i的string都不存在&lt;/li&gt;
&lt;li&gt;incr(key)：名称为key的string增1操作&lt;/li&gt;
&lt;li&gt;incrby(key, integer)：名称为key的string增加integer&lt;/li&gt;
&lt;li&gt;decr(key)：名称为key的string减1操作&lt;/li&gt;
&lt;li&gt;decrby(key, integer)：名称为key的string减少integer&lt;/li&gt;
&lt;li&gt;append(key, value)：名称为key的string的值附加value&lt;/li&gt;
&lt;li&gt;substr(key, start, end)：返回名称为key的string的value的子串&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;6 List&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;rpush(key, value)：在名称为key的list尾添加一个值为value的元素&lt;/li&gt;
&lt;li&gt;lpush(key, value)：在名称为key的list头添加一个值为value的 元素&lt;/li&gt;
&lt;li&gt;llen(key)：返回名称为key的list的长度&lt;/li&gt;
&lt;li&gt;lrange(key, start, end)：返回名称为key的list中start至end之间的元素&lt;/li&gt;
&lt;li&gt;ltrim(key, start, end)：截取名称为key的list&lt;/li&gt;
&lt;li&gt;lindex(key, index)：返回名称为key的list中index位置的元素&lt;/li&gt;
&lt;li&gt;lset(key, index, value)：给名称为key的list中index位置的元素赋值&lt;/li&gt;
&lt;li&gt;lrem(key, count, value)：删除count个key的list中值为value的元素&lt;/li&gt;
&lt;li&gt;lpop(key)：返回并删除名称为key的list中的首元素&lt;/li&gt;
&lt;li&gt;rpop(key)：返回并删除名称为key的list中的尾元素&lt;/li&gt;
&lt;li&gt;blpop(key1, key2,… key N, timeout)：lpop命令的block版本。&lt;/li&gt;
&lt;li&gt;brpop(key1, key2,… key N, timeout)：rpop的block版本。&lt;/li&gt;
&lt;li&gt;rpoplpush(srckey, dstkey)：返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;7 Set&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;sadd(key, member)：向名称为key的set中添加元素member&lt;/li&gt;
&lt;li&gt;srem(key, member) ：删除名称为key的set中的元素member&lt;/li&gt;
&lt;li&gt;spop(key) ：随机返回并删除名称为key的set中一个元素&lt;/li&gt;
&lt;li&gt;smove(srckey, dstkey, member) ：移到集合元素&lt;/li&gt;
&lt;li&gt;scard(key) ：返回名称为key的set的基数&lt;/li&gt;
&lt;li&gt;sismember(key, member) ：member是否是名称为key的set的元素&lt;/li&gt;
&lt;li&gt;sinter(key1, key2,…key N) ：求交集&lt;/li&gt;
&lt;li&gt;sinterstore(dstkey, (keys)) ：求交集并将交集保存到dstkey的集合&lt;/li&gt;
&lt;li&gt;sunion(key1, (keys)) ：求并集&lt;/li&gt;
&lt;li&gt;sunionstore(dstkey, (keys)) ：求并集并将并集保存到dstkey的集合&lt;/li&gt;
&lt;li&gt;sdiff(key1, (keys)) ：求差集&lt;/li&gt;
&lt;li&gt;sdiffstore(dstkey, (keys)) ：求差集并将差集保存到dstkey的集合&lt;/li&gt;
&lt;li&gt;smembers(key) ：返回名称为key的set的所有元素&lt;/li&gt;
&lt;li&gt;srandmember(key) ：随机返回名称为key的set的一个元素&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;8 Hash&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;hset(key, field, value)：向名称为key的hash中添加元素field&lt;/li&gt;
&lt;li&gt;hget(key, field)：返回名称为key的hash中field对应的value&lt;/li&gt;
&lt;li&gt;hmget(key, (fields))：返回名称为key的hash中field i对应的value&lt;/li&gt;
&lt;li&gt;hmset(key, (fields))：向名称为key的hash中添加元素field&lt;/li&gt;
&lt;li&gt;hincrby(key, field, integer)：将名称为key的hash中field的value增加integer&lt;/li&gt;
&lt;li&gt;hexists(key, field)：名称为key的hash中是否存在键为field的域&lt;/li&gt;
&lt;li&gt;hdel(key, field)：删除名称为key的hash中键为field的域&lt;/li&gt;
&lt;li&gt;hlen(key)：返回名称为key的hash中元素个数&lt;/li&gt;
&lt;li&gt;hkeys(key)：返回名称为key的hash中所有键&lt;/li&gt;
&lt;li&gt;hvals(key)：返回名称为key的hash中所有键对应的value&lt;/li&gt;
&lt;li&gt;hgetall(key)：返回名称为key的hash中所有的键（field）及其对应的value&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;6.源码下载&lt;/h3&gt;
&lt;h3&gt;7.源码下载&lt;/h3&gt;
&lt;p&gt;在Git上面下载：&lt;a href=&quot;https://github.com/wuya11/jedisDemo&quot; target=&quot;_blank&quot;&gt;https://github.com/wuya11/jedisDemo&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 22 Jan 2018 09:21:00 +0000</pubDate>
<dc:creator>无涯Ⅱ</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/wlandwl/p/redis.html</dc:identifier>
</item>
</channel>
</rss>