<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Java快速IO(ACM)必备 - ---dgw博客</title>
<link>http://www.cnblogs.com/dgwblog/p/10047565.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/dgwblog/p/10047565.html</guid>
<description>&lt;p&gt; en....&lt;/p&gt;
&lt;p&gt;无非用到的是&lt;/p&gt;
&lt;p&gt;1. new Scanner(System.in);&lt;/p&gt;
&lt;p&gt;2.new BUfferReader(new InputStreamReader(System.in);&lt;/p&gt;
&lt;p&gt;3.System.in.read() //需要转换&lt;/p&gt;
&lt;p&gt;当然1，2这两个还有许多坑要注意，比如说 next() 不会读入null字符，就一直等待，nextline() 吸收\n到缓冲区 但是不会读入，readLine 与read（）也是一样&lt;/p&gt;
&lt;p&gt;这里需要注意：in.nextInt() 接着 in.nextLine（）会出现读入空缺现象，很明显，我前面说过，nextLine会吸收\n到缓冲区&lt;/p&gt;
&lt;p&gt;贴代码：&lt;/p&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;package IO;

&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; java.io.BufferedReader;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; java.io.IOException;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; java.io.InputStream;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; java.io.InputStreamReader;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; java.util.StringTokenizer;

&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*
 * Class for buffered reading int and double values
 &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;class&lt;/span&gt;&lt;span&gt; Reader解决超时 {
    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt;&lt;span&gt; BufferedReader reader;
    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt;&lt;span&gt; StringTokenizer tokenizer;

    &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*
     * call this method to initialize reader for InputStream
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; init(InputStream input) {
        reader &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; BufferedReader(
                &lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; InputStreamReader(input));
        tokenizer &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; StringTokenizer(&lt;span&gt;&quot;&quot;&lt;/span&gt;&lt;span&gt;);
    }

    &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*
     * get next word
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
    &lt;span&gt;static&lt;/span&gt;&lt;span&gt; String next() throws IOException {
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt; (!&lt;span&gt;tokenizer.hasMoreTokens()) {
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;TODO add check for eof if necessary&lt;/span&gt;
            tokenizer = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; StringTokenizer(
                    reader.readLine());
        }
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; tokenizer.nextToken();
    }

    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt;&lt;span&gt; String nextLine()throws IOException{
        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt;(!&lt;span&gt;tokenizer.hasMoreElements()){
            tokenizer&lt;/span&gt;=&lt;span&gt;new&lt;/span&gt;&lt;span&gt; StringTokenizer(
                    reader.readLine()
            );
        }
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; tokenizer.nextToken(&lt;span&gt;&quot;\n&quot;&lt;/span&gt;&lt;span&gt;);
    }

    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt;&lt;span&gt; int nextInt() throws IOException {
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Integer.parseInt(next());
    }

    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt;&lt;span&gt; double nextDouble() throws IOException {
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Double.parseDouble(next());
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; main(String[] args) throws IOException{
        init(System.&lt;/span&gt;&lt;span&gt;in&lt;/span&gt;&lt;span&gt;);
        StringTokenizer st &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; StringTokenizer(&lt;span&gt;&quot;this is a test&quot;&lt;/span&gt;&lt;span&gt;);

        &lt;/span&gt;&lt;span&gt;while&lt;/span&gt;&lt;span&gt; (st.hasMoreTokens())

        {

            System.out.println(st.nextToken());

        }
       &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; System.out.println(next());&lt;/span&gt;
&lt;span&gt;        System.out.println(nextLine());
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

</description>
<pubDate>Fri, 30 Nov 2018 15:52:00 +0000</pubDate>
<dc:creator>---dgw博客</dc:creator>
<og:description>en.... 无非用到的是 1. new Scanner(System.in); 2.new BUfferReader(new InputStreamReader(System.in); 3.Syst</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/dgwblog/p/10047565.html</dc:identifier>
</item>
<item>
<title>JS之setTimeOut与clearTimeOut - JoeJoan</title>
<link>http://www.cnblogs.com/Joe-and-Joan/p/10047384.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Joe-and-Joan/p/10047384.html</guid>
<description>&lt;p&gt;&lt;strong&gt;小练习1：针对HTML，分别使用 setTimeout 和 setInterval 实现以下功能：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;点击按钮时，开始改变 fade-obj 的透明度，开始一个淡出（逐渐消失）动画，直到透明度为0&lt;/li&gt;
&lt;li&gt;在动画过程中，按钮的状态变为不可点击&lt;/li&gt;
&lt;li&gt;在动画结束后，按钮状态恢复，且文字变成“淡入”&lt;/li&gt;
&lt;li&gt;在 按钮显示 淡入 的状态时，点击按钮，开始一个“淡入”（逐渐出现）的动画，和上面类似按钮不可点，直到透明度完全不透明&lt;/li&gt;
&lt;li&gt;淡入动画结束后，按钮文字变为“淡出”&lt;/li&gt;
&lt;li&gt;暂时不要使用 CSS animation （以后我们再学习）&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;!&lt;/span&gt;&lt;span&gt;DOCTYPE html&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;html&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;head&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;meta &lt;/span&gt;&lt;span&gt;charset&lt;/span&gt;&lt;span&gt;=&quot;utf-8&quot;&lt;/span&gt; &lt;span&gt;/&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;title&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;与页面对话4&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;title&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;head&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;body&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;

    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;div &lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;=&quot;fade-obj&quot;&lt;/span&gt;&lt;span&gt; style&lt;/span&gt;&lt;span&gt;=&quot;width:300px;height:300px;background:#000;opacity: 1;&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;div&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;button &lt;/span&gt;&lt;span&gt;id&lt;/span&gt;&lt;span&gt;=&quot;fade-btn&quot;&lt;/span&gt;&lt;span&gt; onclick&lt;/span&gt;&lt;span&gt;=&quot;beLowOpa()&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;淡出&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;button&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;script&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;var&lt;/span&gt;&lt;span&gt; opaCount &lt;/span&gt;&lt;span&gt;=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt;&lt;span&gt; btn&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; document.getElementById(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;fade-btn&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);

        &lt;/span&gt;&lt;span&gt;function&lt;/span&gt;&lt;span&gt; beLowOpa() {
            btn.disabled &lt;/span&gt;&lt;span&gt;=&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
            opaCount &lt;/span&gt;&lt;span&gt;-=&lt;/span&gt; &lt;span&gt;0.05&lt;/span&gt;&lt;span&gt;;
            document.getElementById(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;fade-obj&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;).style.opacity &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; opaCount;
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt;&lt;span&gt; t &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; setTimeout(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;beLowOpa()&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;&lt;span&gt;100&lt;/span&gt;&lt;span&gt;);
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (opaCount &lt;/span&gt;&lt;span&gt;&amp;lt;=&lt;/span&gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;) {
                clearTimeout(t);
                btn.disabled &lt;/span&gt;&lt;span&gt;=&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
                btn.innerHTML &lt;/span&gt;&lt;span&gt;=&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;淡入&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
                btn.addEventListener(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;click&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, beHighOpa);
            }
        }
        &lt;/span&gt;&lt;span&gt;function&lt;/span&gt;&lt;span&gt; beHighOpa() {
            btn.disabled &lt;/span&gt;&lt;span&gt;=&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
            opaCount &lt;/span&gt;&lt;span&gt;+=&lt;/span&gt; &lt;span&gt;0.05&lt;/span&gt;&lt;span&gt;;
            document.getElementById(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;fade-obj&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;).style.opacity &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; opaCount;
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt;&lt;span&gt; t &lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt; setTimeout(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;beHighOpa()&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, &lt;/span&gt;&lt;span&gt;100&lt;/span&gt;&lt;span&gt;);
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;&lt;span&gt; (opaCount &lt;/span&gt;&lt;span&gt;&amp;gt;=&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;) {
                clearTimeout(t);
                btn.disabled &lt;/span&gt;&lt;span&gt;=&lt;/span&gt; &lt;span&gt;false&lt;/span&gt;&lt;span&gt;;
                btn.innerHTML &lt;/span&gt;&lt;span&gt;=&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;淡出&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
                btn.addEventListener(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;click&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, beLowOpa);
            }
        }
    &lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;script&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;body&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;

&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;html&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

</description>
<pubDate>Fri, 30 Nov 2018 15:35:00 +0000</pubDate>
<dc:creator>JoeJoan</dc:creator>
<og:description>小练习1：针对HTML，分别使用 setTimeout 和 setInterval 实现以下功能： 点击按钮时，开始改变 fade-obj 的透明度，开始一个淡出（逐渐消失）动画，直到透明度为0 在动</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/Joe-and-Joan/p/10047384.html</dc:identifier>
</item>
<item>
<title>C#编写扫雷游戏 - firefox逍遥一下</title>
<link>http://www.cnblogs.com/xu-yi/p/10047375.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xu-yi/p/10047375.html</guid>
<description>&lt;p&gt;翻看了下以前大学学习的一些小项目，突然发现有个项目比较有意思，觉得有必要把它分享出来。当然现在看来，里面有很多的不足之处，但因博主现在已经工作，没有时间再去优化。这个项目就是利用C#编写一个Windows系统下的扫雷小游戏。&lt;/p&gt;
&lt;p&gt;首先讲下扫雷小游戏的玩法：&lt;/p&gt;
&lt;p&gt;(1)扫雷就是要把所有非地雷的格子揭开即胜利；踩到地雷格子就算失败。&lt;/p&gt;
&lt;p&gt;(2)当点开的格子不是地雷区域的时候，该格子会显示一个数字，该数字表示的含义就是该格子周边有多少个地雷。&lt;/p&gt;
&lt;p&gt;(3)同时点开的如果非地雷的格子，周边连贯的非地雷区域都会自动被扫描打开，直到遇到旁边有雷区的时候停止。&lt;/p&gt;
&lt;p&gt;(4)当你判断出格子是地雷的时候，你可以使用鼠标右键将该块方格标记为雷区。当不确定的时候，你可标记个问号以待确定。&lt;/p&gt;

&lt;p&gt;下面来说下我大学时候实现这个扫雷小游戏的思路：&lt;/p&gt;
&lt;p&gt;（1）因为雷区是一个个格子联合组成的，那我们可以使用winform程序自带的系统按钮控件Button来实现雷区方格。&lt;/p&gt;
&lt;p&gt;（2）代表雷区方格的Button按钮需要实现下面几个事件：鼠标左键点击扫雷事件，鼠标右键点击标记雷区事件，鼠标右键点击标记问号区域事件。&lt;/p&gt;
&lt;p&gt;（3）为了更好的实现游戏的可玩性，增加一个自由设置地雷数量的小功能，可自行设置雷区包含的地雷数量，设置完成后，自动刷新界面，重新部署地雷。&lt;/p&gt;
&lt;p&gt;（4）我们将雷区的方格存储在一个全局的二维数组中，Form窗体在初始化的时候，自动生成面板区域的Button按钮列表。&lt;/p&gt;
&lt;p&gt;（5）为了实现每次玩游戏的时候，地雷分布不一致，我们在Button列表生成后。随机抽取出某些Button按钮作为地雷分布点，并记录该Button的雷区属性为含有地雷。&lt;/p&gt;
&lt;p&gt;（6）算法中的关键：递归算法计算雷区。当点击某个方格的时候，如果该方格是雷区，则直接Game Over,如果不是的话，则我们需要一个算法去计算旁边区域的地雷数量，以及旁边区域没有地雷的区域，当没有地雷的区域连成一片的时候，我们需要使用递归算法，去查找二维数组，找到对应的连片非雷区，将之打开。&lt;/p&gt;
&lt;p&gt; （7）如何设置方格的状态：当鼠标左键点击的方块区域非雷区的时候，我们将Button按钮的属性设置为Disabled即可呈现打开的状态。当鼠标左键打开的方格是雷区时候，此时我们可以将所有地雷区域块的Button的背景图设置为地雷图片，并播放相应的爆炸音效，弹出游戏终止界面即可。当鼠标右键标记雷区或者待确定区域的时候，只需要更改Button的背景图即可。当然上述所有点击操作，都得判断Button方格区域当前的状态值：初始化状态、已标记为待确定状态、已标记为雷区。&lt;/p&gt;
&lt;p&gt;游戏的最终效果图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/466191/201811/466191-20181130231055646-524200938.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;我们下面来剖析下几个关键点，因为代码量比较多，我就不全部详细剖析了。&lt;/p&gt;
&lt;p&gt;首先我们定义一个LeiButton类，这个类继承于系统控件Button，增加x,y,youlei三个字段，x表示二维数组的第一个索引，y表示二维数组的第二个索引值，youlei用于标记Button方块区域按钮的状态(0表示无雷，1表示有雷）。同时我们使用Button按钮类自带的一个Tag属性标记该方块区域是否被翻开。具体定义如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/466191/201811/466191-20181130230559678-1686696081.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;然后我们在窗体对象Form类中定义一些常用的变量之类，如下图，都有相应注释&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/466191/201811/466191-20181130230759874-1438653000.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面我们来看下生成Button的二维数组，即生成雷区的Button列表。我们需要在Form中添加GroupBox组件，然后将动态生成的Button列表添加到这个groupbox组件中。生成Button的二维数组方法体如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/466191/201811/466191-20181130231234873-110018145.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;生成完Button列表后，我们就开始部署地雷了，地雷随机部署到Button列表中，部署地雷的方法如下：&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/466191/201811/466191-20181130231406090-24416089.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;到了这一步，我们就应该将雷区的界面渲染出来了，这时候我们可以将上面两个方法放入窗体的Form_Load事件中即可渲染出游戏界面。如下所示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/466191/201811/466191-20181130231545270-1634978522.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们继续，下面写扫雷的算法，当鼠标左键点开某个方格的时候，如果该方格不是雷区，那我们需要计算该方格周边的地雷数量，计算方法如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/466191/201811/466191-20181130231730543-696878856.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;下面是个递归计算的核心算法，非常关键&lt;/strong&gt;。当我们点开的方格非雷区的时候，周边连片的非雷区的方格块会被打开。这一块的核心算法参考下列代码，row表示行，col表示列&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/466191/201811/466191-20181130232117190-711022334.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面我们来添加鼠标的点击事件，我这边采用的是bt_MouseUp事件来处理。点击后，我们首先判断游戏是否结束，如果没结束，则进行下列操作，获取到被点击的按钮的x,y值以及点击事件按下的键值(判断按下的是鼠标左键还是右键)。x,y值获取到了，我们就可以到Button二维数组中找到对应元素。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/466191/201811/466191-20181130232648709-889547757.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;假如点击的是鼠标左键，则我们进行扫雷操作，具体的代码如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/466191/201811/466191-20181130232901295-793206963.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如果按下的是鼠标右键，则是标记方块是雷区或者待确定区域，具体代码如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/466191/201811/466191-20181130232946004-565214535.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;最后再给出一个判断是否扫雷完毕的方法。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/466191/201811/466191-20181130233046073-140086497.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; 扫雷游戏的设计大概到此结束，中间还有很多可以优化的地方，比如将扫雷的逻辑代码抽离Form类独立出来等，这些都靠读者自行去优化了。如果有需要源码的初学者，可联系博主，博主免费赠与学习。&lt;/p&gt;
&lt;p&gt; &lt;strong&gt;最后，附上博主的IT技术学习群，欢迎各位同行入群指导交流。技术群：872894940&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Fri, 30 Nov 2018 15:34:00 +0000</pubDate>
<dc:creator>firefox逍遥一下</dc:creator>
<og:description>翻看了下以前大学学习的一些小项目，突然发现有个项目比较有意思，觉得有必要把它分享出来。当然现在看来，里面有很多的不足之处，但因博主现在已经工作，没有时间再去优化。这个项目就是利用C#编写一个Windo</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/xu-yi/p/10047375.html</dc:identifier>
</item>
<item>
<title>sau交流学习社区--在element-ui中新建FormData对象组合上传图片和文件的文件对象，同时需要携带其他参数 - saucxs</title>
<link>http://www.cnblogs.com/chengxs/p/10047376.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/chengxs/p/10047376.html</guid>
<description>&lt;p&gt;今天有一个坑，同时要上传图片和文件，而且图片要展示缩略图，文件要展示列表。&lt;/p&gt;
&lt;p&gt;我的思路是：&lt;/p&gt;
&lt;p&gt;首先，只上传附件照片，这个直接看ele的官方例子就行，不仅仅上传附件照片，还同时上传其他参数。&lt;/p&gt;
&lt;p&gt;然后，再做上传照片和文件，上传其他参数，其实也就是文件合并。&lt;/p&gt;
&lt;p&gt; 同步到sau交流学习社区：&lt;a href=&quot;https://www.mwcxs.top/page/465.html&quot; target=&quot;_blank&quot;&gt;https://www.mwcxs.top/page/465.html&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;&lt;strong&gt;一、上传照片和其他参数&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;页面样式大约就是这样的，参数有优先级，发生时间，服务单名称，服务单描述，图片附件上传。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.mwcxs.top/static/upload/pics/2018/11/30-LFQKcZSYd6u4vxrqjcVJDXU.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（一）视图部分代码&lt;/strong&gt;：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
 &amp;lt;el-form-item prop=&quot;image&quot; label=&quot;图片附件上传&quot;&amp;gt;
          &amp;lt;el-&lt;span&gt;upload
            ref&lt;/span&gt;=&quot;upload&quot;&lt;span&gt;
            :action&lt;/span&gt;=&quot;uploadAction&quot;&lt;span&gt;
            :beforeUpload&lt;/span&gt;=&quot;beforeUploadPicture&quot;&lt;span&gt;
            :on&lt;/span&gt;-change=&quot;imageChange&quot;&lt;span&gt;
            list&lt;/span&gt;-type=&quot;picture-card&quot;&lt;span&gt;
            name&lt;/span&gt;=&quot;files&quot;&lt;span&gt;
            :data&lt;/span&gt;=&quot;paramsData&quot;&lt;span&gt;
            :limit&lt;/span&gt;=&quot;3&quot;&lt;span&gt;
            multiple
            :auto&lt;/span&gt;-upload=&quot;false&quot;&lt;span&gt;
            :on&lt;/span&gt;-preview=&quot;handlePictureCardPreview&quot;&lt;span&gt;
            :on&lt;/span&gt;-remove=&quot;handleRemovePicture&quot;&amp;gt;
            &amp;lt;i class=&quot;el-icon-plus&quot;&amp;gt;&amp;lt;/i&amp;gt;
          &amp;lt;/el-upload&amp;gt;
          &amp;lt;el-dialog :visible.sync=&quot;dialogVisible&quot;&amp;gt;
            &amp;lt;img width=&quot;100%&quot; :src=&quot;dialogImageUrl&quot; alt=&quot;&quot;&amp;gt;
          &amp;lt;/el-dialog&amp;gt;
     &amp;lt;/el-form-item&amp;gt;

 &amp;lt;el-button size=&quot;mini&quot; type=&quot;primary&quot; @click=&quot;confirm()&quot;&amp;gt;确 定&amp;lt;/el-button&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;说明：&lt;/p&gt;
&lt;p&gt;1、action变量为后端图片接口的地址&lt;/p&gt;
&lt;p&gt;2、beforeUpload方法是指的上传之前触发的函数，可以用来做前端文件格式判断，文件大小判断&lt;/p&gt;
&lt;p&gt;3、on-change方法是指每次选择文件都会触发函数，可以用来前端删除和添加照片&lt;/p&gt;
&lt;p&gt;4、list-type属性指的是照片picture-card展示的方式&lt;/p&gt;
&lt;p&gt;5、name指的是上传的文件字段名，这是后端确认文件流的字段名，可以随便写&lt;/p&gt;
&lt;p&gt;6、data属性指的是上传时附带的额外参数，这是指的其他参数&lt;/p&gt;
&lt;p&gt;7、limit属性指的是上传文件的个数极限。&lt;/p&gt;
&lt;p&gt;8、multiple属性指的是可以每次多选文件，true为多选，false为单选&lt;/p&gt;
&lt;p&gt;9、auto-upload属性指的是自动上传的，true为可以自动上传，false为不可以自动上传&lt;/p&gt;
&lt;p&gt;10、on-preview方法指的是查看缩略图的方法&lt;/p&gt;
&lt;p&gt;11、on-remove方法指的是删除文件的方法&lt;/p&gt;
&lt;p&gt;12、ref绑定dom元素&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;（二）data部分代码&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;span&gt; data () {
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; {
      selectedCategorySpe: &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selectedCategory,
      serviceForm: {
        title: &lt;/span&gt;''&lt;span&gt;,
        desc: &lt;/span&gt;''&lt;span&gt;,
        priority: &lt;/span&gt;''&lt;span&gt;,
        occurDate: &lt;/span&gt;''&lt;span&gt;
      },
       dialogImageUrl: &lt;/span&gt;''&lt;span&gt;,
       dialogVisible: &lt;/span&gt;&lt;span&gt;false&lt;/span&gt;&lt;span&gt;,
      uploadAction: &lt;/span&gt;&quot;/inner/event/order/submit/submit&quot; + &quot;&amp;amp;accessToken=&quot; + &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.$store.getters.token
    }
  },&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;



&lt;p&gt;&lt;strong&gt;（三）computed部分代码&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt; computed: {
    ...mapGetters([
      &lt;/span&gt;'constConfig'&lt;span&gt;
    ]),
    paramsData: &lt;/span&gt;&lt;span&gt;function&lt;/span&gt;&lt;span&gt; () {
      let params &lt;/span&gt;=&lt;span&gt; {
        eventCategory: &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selectedCategorySpe.categoryId,
          priority: &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.serviceForm.priority,
          title: &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.serviceForm.title,
          dsc: &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.serviceForm.desc,
          occurDate: &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.serviceForm.occurDate
      }
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; params
    }
  },&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;使用computed实现实时监测paramsData的值，只要selectedCategorySpe.categoryId，serviceForm.priority，serviceForm.title&lt;/p&gt;
&lt;p&gt;，serviceForm.desc，serviceForm.occurDate中只有一个变化，都会重新计算paramsData的值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（四）methods部分方法&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;49&quot;&gt;
&lt;pre&gt;
&lt;span&gt;    beforeUploadPicture(file){
      const isImage &lt;/span&gt;= file.type == 'image/png' || file.type == 'image/jpg' ||  file.type == 'image/jpeg' || file.type == 'image/bmp' || file.type == 'image/gif' || file.type == 'image/webp'&lt;span&gt;;
      const isLt2M &lt;/span&gt;= file.size &amp;lt;  1024 * 1024 * 2&lt;span&gt;;
      &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;isImage) {
        &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.$message.error('上传只能是png,jpg,jpeg,bmp,gif,webp格式!'&lt;span&gt;);
      }
      &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;isLt2M) {
        &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.$message.error('上传图片大小不能超过 2MB!'&lt;span&gt;);
      }
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; isImage &amp;amp;&amp;amp;&lt;span&gt; isLt2M;
    },
    handlePictureCardPreview(file) {
      &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.dialogImageUrl =&lt;span&gt; file.url;
      &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.dialogVisible = &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
    },
    handleRemovePicture(file, fileList) {
      console.log(file, fileList);
    },
    imageChange(file, fileList, name) {
      console.log(file, fileList);
    },

 confirm(){
    &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.$refs.upload.submit();
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;说明:confirm使用ref的绑定的upload，紧接着调用form的表单的submit方法。这个vue已经封装好了，这时候传的参数可以看到post传递的文件对象。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.mwcxs.top/static/upload/pics/2018/11/30mSVdBl7-uafYFal-kJBVEsM6.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;h4&gt;&lt;strong&gt;二、同时上传图片和文件，并且图片可以看缩略图文件显示成列表&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;但是当你出现这样的需求的时候，一脸蒙蔽&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.mwcxs.top/static/upload/pics/2018/11/30i4RSkCRS5prTOfiAAorMEzwS.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（一）视图部分代码&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
 &amp;lt;el-form-item prop=&quot;image&quot; label=&quot;图片附件上传&quot;&amp;gt;
          &amp;lt;el-&lt;span&gt;upload
            ref&lt;/span&gt;=&quot;uploadImage&quot;&lt;span&gt;
            :action&lt;/span&gt;=&quot;uploadAction&quot;&lt;span&gt;
            :beforeUpload&lt;/span&gt;=&quot;beforeUploadPicture&quot;&lt;span&gt;
            :on&lt;/span&gt;-change=&quot;imageChange&quot;&lt;span&gt;
            list&lt;/span&gt;-type=&quot;picture-card&quot;&lt;span&gt;
            name&lt;/span&gt;=&quot;files&quot;&lt;span&gt;
            :limit&lt;/span&gt;=&quot;3&quot;&lt;span&gt;
            multiple
            :auto&lt;/span&gt;-upload=&quot;false&quot;&lt;span&gt;
            :on&lt;/span&gt;-preview=&quot;handlePictureCardPreview&quot;&lt;span&gt;
            :on&lt;/span&gt;-remove=&quot;handleRemovePicture&quot;&amp;gt;
            &amp;lt;i class=&quot;el-icon-plus&quot;&amp;gt;&amp;lt;/i&amp;gt;
          &amp;lt;/el-upload&amp;gt;
          &amp;lt;el-dialog :visible.sync=&quot;dialogVisible&quot;&amp;gt;
            &amp;lt;img width=&quot;100%&quot; :src=&quot;dialogImageUrl&quot; alt=&quot;&quot;&amp;gt;
          &amp;lt;/el-dialog&amp;gt;
        &amp;lt;/el-form-item&amp;gt;
        &amp;lt;el-form-item prop=&quot;image&quot; label=&quot;文件附件上传&quot;&amp;gt;
          &amp;lt;el-&lt;span&gt;upload
            ref&lt;/span&gt;=&quot;uploadFile&quot;&lt;span&gt;
            class&lt;/span&gt;=&quot;upload-demo&quot;&lt;span&gt;
            name&lt;/span&gt;=&quot;files&quot;&lt;span&gt;
            :on&lt;/span&gt;-change=&quot;fileChange&quot;&lt;span&gt;
            :action&lt;/span&gt;=&quot;uploadAction&quot;&lt;span&gt;
            :on&lt;/span&gt;-preview=&quot;handlePreviewFile&quot;&lt;span&gt;
            :on&lt;/span&gt;-remove=&quot;handleRemoveFile&quot;&lt;span&gt;
            :before&lt;/span&gt;-remove=&quot;beforeRemoveFile&quot;&lt;span&gt;
            multiple
            :auto&lt;/span&gt;-upload=&quot;false&quot;&lt;span&gt;
            :limit&lt;/span&gt;=&quot;3&quot;&lt;span&gt;
            :on&lt;/span&gt;-exceed=&quot;handleExceedFile&quot;&lt;span&gt;
            :file&lt;/span&gt;-list=&quot;fileList&quot;&amp;gt;
            &amp;lt;el-button size=&quot;small&quot; type=&quot;primary&quot;&amp;gt;点击上传&amp;lt;/el-button&amp;gt;
            &amp;lt;!--&amp;lt;div slot=&quot;tip&quot; class=&quot;el-upload__tip&quot;&amp;gt;只能上传文件，且不超过2M&amp;lt;/div&amp;gt;--&amp;gt;
          &amp;lt;/el-upload&amp;gt;
        &amp;lt;/el-form-item&amp;gt;

 &amp;lt;el-button size=&quot;mini&quot; type=&quot;primary&quot; @click=&quot;confirm()&quot;&amp;gt;确 定&amp;lt;/el-button&amp;gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;（2）data部分数据&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;43&quot;&gt;
&lt;pre&gt;
&lt;span&gt; data () {
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; { 
      selectedCategorySpe: &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selectedCategory,
      serviceForm: {
        title: &lt;/span&gt;''&lt;span&gt;,
        desc: &lt;/span&gt;''&lt;span&gt;,
        priority: &lt;/span&gt;''&lt;span&gt;,
        occurDate: &lt;/span&gt;''&lt;span&gt;,
      },
      images: {},
      files: {},
      dialogImageUrl: &lt;/span&gt;''&lt;span&gt;,
      dialogVisible: &lt;/span&gt;&lt;span&gt;false&lt;/span&gt;&lt;span&gt;
    }
  },&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（3）method部分数据&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;70&quot;&gt;
&lt;pre&gt;
&lt;span&gt;beforeUploadPicture(file){
     const isImage &lt;/span&gt;= file.type == 'image/png' || file.type == 'image/jpg' ||  file.type == 'image/jpeg' || file.type == 'image/bmp' || file.type == 'image/gif' || file.type == 'image/webp'&lt;span&gt;;
      const isLt2M &lt;/span&gt;= file.size &amp;lt;  1024 * 1024 * 2&lt;span&gt;;
      &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;isImage) {
        &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.$message.error('上传只能是png,jpg,jpeg,bmp,gif,webp格式!'&lt;span&gt;);
      }
      &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;isLt2M) {
        &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.$message.error('上传图片大小不能超过 2MB!'&lt;span&gt;);
      }
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; isImage &amp;amp;&amp;amp;&lt;span&gt; isLt2M;
    },
    handlePictureCardPreview(file) {
      &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.dialogImageUrl =&lt;span&gt; file.url;
      &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.dialogVisible = &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
    },
    handleRemovePicture(file, fileList) {
      console.log(file, fileList);
    },
    imageChange(file, fileList, name) {
      console.log(file, fileList);
      &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.imageList =&lt;span&gt; fileList;
&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.images[''] =&lt;span&gt; fileList;
    },

    handleRemoveFile(file, fileList) {
      console.log(file, fileList);
    },
    handlePreviewFile(file) {
      console.log(file);
    },
    handleExceedFile(files, fileList) {
      &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.$message.warning(`当前限制选择 3 个文件，本次选择了 ${files.length} 个文件，共选择了 ${files.length +&lt;span&gt; fileList.length} 个文件`);
    },
    beforeRemoveFile(file, fileList) {
      &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.$confirm(`确定移除 ${ file.name }？`);
    },
    fileChange(file,fileList) {
      console.log(file, fileList);
      &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.fileList =&lt;span&gt; fileList;

      &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.files[''] =&lt;span&gt; fileList;
    },

    confirm(){
          let wfForm &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; FormData();
          wfForm.append( &lt;/span&gt;'eventCategory',&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.selectedCategorySpe.categoryId)
          wfForm.append( &lt;/span&gt;'priority',&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.serviceForm.priority)
          wfForm.append( &lt;/span&gt;'title',&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.serviceForm.title)
          wfForm.append( &lt;/span&gt;'dsc',&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.serviceForm.desc)
          wfForm.append( &lt;/span&gt;'occurDate',&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.serviceForm.occurDate)
          Object.entries(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.images).forEach(file =&amp;gt;&lt;span&gt; {
            file[&lt;/span&gt;1].forEach(item =&amp;gt;&lt;span&gt; {
              wfForm.append(&lt;/span&gt;'files'&lt;span&gt;, item.raw)
              wfForm.append(item.name, file[&lt;/span&gt;0&lt;span&gt;])
            })
          })
          Object.entries(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.files).forEach(file =&amp;gt;&lt;span&gt; {
            file[&lt;/span&gt;1].forEach(item =&amp;gt;&lt;span&gt; {
              wfForm.append(&lt;/span&gt;'files'&lt;span&gt;, item.raw)
              wfForm.append(item.name, file[&lt;/span&gt;0&lt;span&gt;])
            })
          })
          createEventOrder(wfForm).then( res &lt;/span&gt;=&amp;gt;&lt;span&gt; {
            console.log(res, &lt;/span&gt;'res'&lt;span&gt;)
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;(res.retValue === 1&lt;span&gt;){
              &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;.$message.success( '成功创建服务单'&lt;span&gt; );
              &lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;.handleClose()
            }&lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;{

            }
          })

    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;说明一下，新建了&lt;/strong&gt;&lt;strong&gt;this.files存文件列表，this.images存图片列表。在confirm中新建一个FormData对象，使用append方法将参数变量加到数据对象中，和文件对象。最后将FormData对象传给后端。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;传递的参数截图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://www.mwcxs.top/static/upload/pics/2018/11/30xkajXJVOJlsvE5ygX6AoWIbx.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

</description>
<pubDate>Fri, 30 Nov 2018 15:34:00 +0000</pubDate>
<dc:creator>saucxs</dc:creator>
<og:description>今天有一个坑，同时要上传图片和文件，而且图片要展示缩略图，文件要展示列表。 我的思路是： 首先，只上传附件照片，这个直接看ele的官方例子就行，不仅仅上传附件照片，还同时上传其他参数。 然后，再做上传</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/chengxs/p/10047376.html</dc:identifier>
</item>
<item>
<title>ASP.Net Core开发(踩坑)指南 - 7m鱼</title>
<link>http://www.cnblogs.com/selimsong/p/10047321.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/selimsong/p/10047321.html</guid>
<description>&lt;p&gt;　　ASP.NET与ASP.NET Core很类似，但它们之间存在一些细微区别以及ASP.NET Core中新增特性的使用方法，在此之前也写过一篇简单的对比文章ASP.NET MVC应用迁移到ASP.NET Core及其异同简介，但没有进行深入的分析和介绍，在真正使用ASP.NET Core进行开发时，如果忽略这些细节可能会出现奇怪的问题，特此将这些细节进行分享。&lt;br/&gt;　　本文主要内容有：&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;注：本文基于ASP.Net Core 2.1版本，.Net Core SDK版本需要2.1.401+。长篇预警( ╯□╰ )&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;无处不在的依赖注入&lt;/h2&gt;
&lt;p&gt;　　ASP.NET与ASP.NET Core之间最大区别之一就是内置了依赖注入机制，虽然ASP.NET中也有DI机制，但没有内置容器，一般都需要使用第三方的容器来提供服务，另外依赖注入的概念也不像ASP.NET Core中这样无处不在。&lt;br/&gt;　　简单来说依赖注入的目的是为了让代码解耦以提高代码的可维护性，同时也要求代码设计符合依赖导致原则使得代码更加灵活，而其原理实际上就是在应用程序中添加一个对象容器，在应用初始化时将实际的服务“放”到容器中，然后当需要相应服务时从容器中获取，由容器来组装服务。&lt;/p&gt;
&lt;h3&gt;服务的注册&lt;/h3&gt;
&lt;p&gt;　　ASP.NET Core的Startup(注：Startup仅仅只是约定名称，实际使用是在Program类型中创建 WebHost时使用的)，该类型中包含两个方法分别是ConfigureServices和Configure，其中ConfigureServices的主要作用就是用来将服务“放”置到容器中&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130224737601-1170181466.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　代码来自：&lt;a href=&quot;https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection?view=aspnetcore-2.1&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection?view=aspnetcore-2.1&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;替换默认的依赖注入容器&lt;/h3&gt;
&lt;p&gt;　　ASP.NET Core的默认容器仅提供了构造注入功能，如果需要使用属性注入等功能或者在迁移时原有应用依赖于其它容器，那么可以通过使用第三方容器实现。&lt;br/&gt;　　将默认容器替换为其它容器仅需三步：&lt;br/&gt;　　1. 将ConfigureServices方法的返回类型改为IServiceProvider。&lt;br/&gt;　　2. 将ASP.NET Core中的服务注册到第三方容器中。&lt;br/&gt;　　3. 使用第三方容器实现IServiceProvider接口并返回。&lt;/p&gt;
&lt;p&gt;　　官方文档以Autofac为例，Autofac已经实现了ASP.NET Core服务注册到Autofac容器中，以及Autofac容器的IServiceProvider接口封装，仅需安装Autofac以及Autofac.Extensions.DependencyInjection包即可。&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130224834130-1256285150.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　详情参考：&lt;a href=&quot;https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection?view=aspnetcore-2.1#default-service-container-replacement&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection?view=aspnetcore-2.1#default-service-container-replacement&lt;/a&gt;&lt;br/&gt;　　使用windsor或其它容器可以参考：&lt;br/&gt;　　&lt;a href=&quot;https://stackoverflow.com/questions/47672614/how-to-use-windsor-ioc-in-asp-net-core-2&quot; target=&quot;_blank&quot;&gt;https://stackoverflow.com/questions/47672614/how-to-use-windsor-ioc-in-asp-net-core-2&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;将Controller注册为服务&lt;/h3&gt;
&lt;p&gt;　　虽然Controller在激活时是通过容器来获取Controller的依赖(即构造方法需要的参数)，在代码运行的时候给人一种Controller是从容器中组装的错觉，但是实际上默认情况下Controller的组装过程不是直接由容器组装的，如果要让Controller从容器组装，那么在配置MVC服务时需要通过.AddControllerAsServices()方法将Controller注册到容器中：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130224917545-1631018180.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　&lt;span&gt;　注：一般情况下是否将Controller注册为服务对Controller的开发和代码的运行并没有很大区别，但是如果当容器变更为其它容器，并且使用了容器提供的如属性注入等功能时，如果没有将Controller注册为服务，那么相应的属性注入的过程也不会被触发，简单来说就是只有将Controller注册为服务，那么实例化Controller的工作才会由容器完成，才会触发或者使用到容器提供的其它特性。&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;服务的获取&lt;/h3&gt;
&lt;p&gt;　　前面介绍了服务的注册，现在来介绍一下在ASP.NET Core中有哪些方法可以获取服务：&lt;br/&gt;　　1. Controller构造方法参数。&lt;br/&gt;　　2. 通过Controller注入IServiceProvider类型，通过IServiceProvider来获取服务：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225003455-559353874.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　3. 在Action方法或者Mvc过滤器(过滤器的上下文参数中包含HttpContext)中通过HttpContext的RequestServices对象获取服务：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225022336-1179508035.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　4. 在View上通过@inject注入服务：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225044440-369662410.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　5. 在Action方法中，通过FormServices特性注入：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225103283-1690727659.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　&lt;span&gt;　注：一般来说尽可能显式的标明类型的依赖(即通过构造参数的方式声明当前类型所依赖的组件)，上面的2和3两点分别都是通过服务提供器在方法内部来获取依赖，这样做依赖对于外界来说是不可知的，可能会对代码的可维护、可测试性等造成一定影响，这种模式被称为Service Locator模式，在开发过程中尽可能避免Service Locator模式的使用。&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;常用的服务&lt;/h3&gt;
&lt;p&gt;　　ASP.NET Core相对于ASP.NET来说取消了一些常用的静态类型，比如HttpContext、ConfigurationManager等，取而代之的是通过将类似的组件以服务的形式注册到容器中，使用时通过容易来获取相应的服务组件，这些常用的服务有：&lt;br/&gt;　　1. IHostingEnvironment：包含了环境名称、应用名称以及当前应用程序所处的根目录及Web静态内容的根目录(默认wwwroot)。&lt;br/&gt;　　2. IHttpContextAccessor：从名字可以看出，它用来访问当前请求的HttpContext。&lt;br/&gt;　　3. IConfiguration：ASP.NET Core配置信息对象。&lt;br/&gt;　　4. IServiceProvider： ASP.NET Core服务提供器。&lt;br/&gt;　　5. DbContext: 这里的DbContext指的是EFCore的DbContext，在ASP.NET Core中，EFCore的DbContext也是在ConfigureServices方法中进行配置并添加到容器，使用时直接从容器中获取(但要注意的是对于分层结构的开发风格来说，DbContext不会直接被Controller依赖，而是被Controller中依赖的业务服务类型所以来，就是说编写Controller代码的时候不会直接与DbContext发生直接交互)。&lt;/p&gt;
&lt;h2&gt;Configuration&amp;amp;Options&lt;/h2&gt;
&lt;p&gt;　　在ASP.NET的开发中，通常某个变量需要从配置文件读取，一般都是在相应类型的构造方法中，通过静态类型ConfigurationManager的AppSettings方法来读取并初始化变量。虽然ASP.NET Core也可以在类型中注入IConfiguration实例来直接读取配置文件，但该方法由于Options模式的出现已经不再建议使用，使用组件通过依赖相应的组件Options可以做到关注点分离，提高程序的灵活性、可拓展性，Options使用方法见文档：&lt;a href=&quot;https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/options?view=aspnetcore-2.1&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/options?view=aspnetcore-2.1&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;ASP.NET Core 请求管道建立&lt;/h2&gt;
&lt;p&gt;　　ASP.NET由于是基于IIS请求管道的，ASP.NET应用程序仅仅是管道中的一个处理环节，管道中还包含如身份验证、静态文件处理等环节，但ASP.NET Core不一样，它脱离了IIS处理管道，所以整个管道的建立均需要靠程序自身完成，而ASP.NET Core建立管道的代码就是Startup类型的Configure方法，该方法通过IApplicationBuilder实例来添加不同功能的中间件，通过中间件的串联形成处理管道，下图是ASP.NET Mvc模板生成的管道代码：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225203486-189694735.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　图片来自：&lt;a href=&quot;https://docs.microsoft.com/en-us/aspnet/core/fundamentals/startup?view=aspnetcore-2.1#the-configure-method&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/en-us/aspnet/core/fundamentals/startup?view=aspnetcore-2.1#the-configure-method&lt;/a&gt;&lt;br/&gt;　　该管道主要包含了错误处理(开发环境显示异常信息，其它环境跳转错误页面)中间件、静态文件处理中间件以及Mvc中间件。&lt;br/&gt;　　更多中间件可参考文档：&lt;a href=&quot;https://docs.microsoft.com/en-us/aspnet/core/fundamentals/middleware/index?view=aspnetcore-2.1&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/en-us/aspnet/core/fundamentals/middleware/index?view=aspnetcore-2.1&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;ASP.NET Core Mvc&lt;/h2&gt;
&lt;p&gt;　　ASP.NET Core Mvc与ASP.NET Mvc相比整体上区别不大，但仍然有很多细节上的变化，下面就开始一一介绍：&lt;/p&gt;
&lt;h3&gt;路由&lt;/h3&gt;
&lt;p&gt;　　路由的作用是将请求根据Url映射到“对应”的处理器上，在Mvc中请求的终点就是Controller的Action方法，而这里所谓的“对应”指的是Url与路由模板的匹配，ASP.NET Core Mvc通过以下的方式添加路由模板：&lt;/p&gt;
&lt;p&gt; 　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225242985-1260249372.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　上图中的路由模板是最常用的路由模板，使用花括号内的内容为路由参数及其默认值，Url中通过路由参数控制器名称、活动方法名称来匹配到相应控制器的活动方法。&lt;br/&gt;在注册路由时可以为相应路由添加默认值、路由参数约束以及对应路由的相关附加数据(datatokens)：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225307059-1383021551.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　路由的功能除了处理请求匹配外，还具有链接生成的功能，特别是Mvc程序的View中使用IUrlHelper或TagHelper来生成页面的超链接：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225324123-162291260.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　其生成原理是通过链接参数(如上图所示的Controller和Action)去路由表中匹配，然后使用匹配结果中的第一个路由(可能会匹配到多个路由对象，具体内容在后续Area章节介绍)来生成链接。&lt;/p&gt;
&lt;p&gt;　　更多路由信息及路由模板定义参考文档：&lt;a href=&quot;https://docs.microsoft.com/en-us/aspnet/core/fundamentals/routing?view=aspnetcore-2.1&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/en-us/aspnet/core/fundamentals/routing?view=aspnetcore-2.1&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;控制器&lt;/h3&gt;
&lt;p&gt;　　ASP.NET Core Mvc的Controller一般继承Controller类型实现，基类Controller中包含了Mvc中常用的返回方法(如Json以及View等)以及用于数据存储的ViewBag、ViewData、TempData。&lt;/p&gt;
&lt;h3&gt;Area&lt;/h3&gt;
&lt;p&gt;　　Area是Mvc应用中用来进行功能拆分或分组的一种方式，Area一般有自己的命名空间和目录结构，一般Area的默认目录结构如下：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225414758-1353193284.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　ASP.NET Core Mvc和ASP.NET Mvc中的概念和用法基本上是一致的，但也存在一些区别：&lt;br/&gt;　　1. Area下面的Controller需要使用Area特性标明当前Controller属于哪一个Area：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225437206-364187696.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;注：Area的目录结构不是必须的，只需要通过特性标记的Controller都会被正确识别，但目录结构的改变会导致无法找到View，关于View的查找路径会在后续介绍。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　2. Area的路由注册也是在UseMvc方法中完成：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225502517-1226770373.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;注：携带Area的路由模板需要放在前面，否则在生成通过IUrlHelper或TagHelper生成链接时，由于Controller以及action会匹配到没有area的模板并使用该模板生成链接，导致area参数被忽略，而生成类似：/controller/action?area=area的结果(在生成Url时，ASP.NET Core会将多余的路由参数放置到查询字符串中)&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;View&lt;/h3&gt;
&lt;p&gt;　　View是基于Razor的HTML模板，Razor的详细语法参考文档：&lt;br/&gt;　　&lt;a href=&quot;https://docs.microsoft.com/en-us/aspnet/core/mvc/views/razor?view=aspnetcore-2.1&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/en-us/aspnet/core/mvc/views/razor?view=aspnetcore-2.1&lt;/a&gt;&lt;br/&gt;　　ASP.NET Core Mvc的View与ASP.NET Mvc中的使用方法基本一致，主要区别如下：&lt;br/&gt;　　1. 引入了TagHelper，使用TagHelper可以让View的代码更接近Html。更多TagHelper信息参考文档：&lt;a href=&quot;https://docs.microsoft.com/en-us/aspnet/core/mvc/views/tag-helpers/intro?view=aspnetcore-2.1&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/en-us/aspnet/core/mvc/views/tag-helpers/intro?view=aspnetcore-2.1&lt;/a&gt;&lt;br/&gt;　　2. Controller将参数传输到View的方法添加了ViewData特性，使用方法如下：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225535960-1780072849.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　View中访问被ViewData标记的方式：&lt;/p&gt;
&lt;p&gt;　　 &lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225559285-218387537.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　更多详情参考文档：&lt;a href=&quot;https://docs.microsoft.com/en-us/aspnet/core/mvc/views/overview?view=aspnetcore-2.1#passing-data-to-views&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/en-us/aspnet/core/mvc/views/overview?view=aspnetcore-2.1#passing-data-to-views&lt;/a&gt;&lt;br/&gt;　　3. 新增View组件：&lt;a href=&quot;https://docs.microsoft.com/en-us/aspnet/core/mvc/views/view-components?view=aspnetcore-2.1&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/en-us/aspnet/core/mvc/views/view-components?view=aspnetcore-2.1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;　　配置View的查找路径：&lt;br/&gt;　　ASP.NET Core可以在ConfigureServices方法中对RazorViewEngineOptions进行配置，如下图所示，在默认查找位置基础上添加了View以及AreaView的查找路径：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225652726-1211334779.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;模型绑定&lt;/h3&gt;
&lt;p&gt;　　模型绑定指的是ASP.NET Core Mvc将请求携带的数据绑定到Action参数的过程，ASP.NET Core Mvc的模型绑定数据源默认使用Form Values、Route Values以及Query Strings，所有值都以Name-Value的形式存在，模型绑定时主要通过参数名称、参数名称.属性名称、参数名称[索引]等方式与数据源的Name进行匹配。&lt;br/&gt;　　除了默认的数据源之外还可以从Http请求Header、Http请求Body甚至从依赖注入容器中获取数据，要从这些数据源中获取数据需要在相应参数上使用[FromHeader]、[FromBody]、[FromServices]特性。&lt;br/&gt;　　如果需要获取的数据在不同数据源中都存在时(Name存在于多个数据源中)，还可以通过特性指明从哪一个数据源中获取，如[FromForm]、[FromQuery]及[FromRoute]。&lt;br/&gt;　　需要注意的是[FromBody]默认只支持Json格式的内容，如果需要支持其它格式，如XML需要添加相应的格式化器，添加方法如下图所示：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225726969-1257150244.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　更多模型绑定及验证内容请参考文档：&lt;a href=&quot;https://docs.microsoft.com/en-us/aspnet/core/mvc/models/model-binding?view=aspnetcore-2.1&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/en-us/aspnet/core/mvc/models/model-binding?view=aspnetcore-2.1&lt;/a&gt;&lt;br/&gt;　　&lt;a href=&quot;https://docs.microsoft.com/en-us/aspnet/core/mvc/models/validation?view=aspnetcore-2.1&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/en-us/aspnet/core/mvc/models/validation?view=aspnetcore-2.1&lt;/a&gt;&lt;br/&gt;　　其中模型验证的使用方式与ASP.NET Mvc一致，仍然是通过相应的验证特性对模型或模型属性进行标记。&lt;/p&gt;
&lt;h3&gt;Action的返回值与Json序列化&lt;/h3&gt;
&lt;p&gt;　　说完Action方法参数的绑定，再来看一下Action方法的返回类型，在ASP.NET Mvc中Controller提供了返回页面内容的View方法以及返回Json内容的Json方法(当然还有文件、重定向、404等等其它内容返回方法，详见Controller与ControllerBase类型)。&lt;br/&gt;　　这里有一个需要注意的地方是当使用Json方法返回一个对象实例时，默认使用首字母小写的驼峰命名方式序列化实例的属性名称，如下图所示：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225832650-941689802.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　访问结果：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225849494-1067508188.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　要使用大写驼峰形式命名需要在配置Mvc服务时添加以下代码来修改Json默认的序列化配置：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225920535-709800226.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;注：同样的问题也存在于WebAPI的Ok方法以及Signalr的Json格式协议。&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;静态资源&lt;/h3&gt;
&lt;p&gt;　　由于ASP.NET Core已经不再使用IIS请求管道，所以对于静态资源的访问来说需要在请求管道中添加相应的处理中间件来完成：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130225956857-526910180.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　默认的无参UseStaticFiles方法将wwwroot目录作为静态资源存放目录，如果要添加其它静态内容目录可以再次使用UseStaticFiles方法，并通过StaticFileOptions对目录的访问路径以及实际路径进行配置：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230022533-890450358.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　&lt;span&gt;　注：由于ASP.NET Core可以在Linux下运行，所以对于Linux来说路径是大小写敏感的，另外由于Windows和Linux类系统的路径分隔符也不一致，所以为了保证路径的统一，可以使用Path.Combine方法，该方法会根据操作系统的不同对路径进行不同的处理。&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　　另外对于css及js资源文件的打包、压缩功能，最新版本(ASP.NET Core 2.1)的应用模板以及不会自动添加相关功能，需要在拓展工具中添加Bunlder&amp;amp; Minifier拓展：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230050626-1680509020.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　然后通过右键js等资源文件来创建bundleconfig.json文件：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230110152-478341636.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;WebAPI&lt;/h2&gt;
&lt;h3&gt;API控制器的创建&lt;/h3&gt;
&lt;p&gt;　　ASP.NET Core将Mvc和WebAPI进行了合并，它们的实现都直接或间接继承了ControllerBase类型，只不过Mvc的基类Controller在ControllerBase的基础上添加了一些用于处理View的功能。&lt;br/&gt;　　用ASP.NET Core开发WebAPI时，Controller类型直接继承ControllerBase。然后这个API的Controller就具有了基类的特性，返回一个结果仅需要使用Ok方法即可，如下图所示：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230140082-1836332137.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　然后在路由表中添加路由：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230155596-784947358.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　即可通过/api/default/index访问到这个API：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230325806-1886554062.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　但对于REST风格的API来说，它需要通过ApiController特性对Controller类型进行标记，并且通过Route特性来设置路由：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230341601-203232658.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　然后就可以通过HTTP谓词来访问API：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230359431-462522767.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　但要注意的是在ASP.NET Core中实现的REST风格的Controller，它不会再根据action方法的名称来匹配谓词，所以存在多个方法时会，那怕对方法进行了命名，但仍然会出现以下错误：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230417176-92407890.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　为了解决这个问题，需要通过添加谓词特性解决：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230515395-84252274.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;模型绑定&lt;/h3&gt;
&lt;p&gt;　　WebAPI中的模型绑定与MVC存在一些区别，首先当使用ApiController标记Controller类型时，如果模型绑定验证未通过，会直接返回400错误，不会执行Action方法(免去了使用!ModelState.IsValid进行判断)：&lt;/p&gt;
&lt;p&gt; 　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230547356-1085495426.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　执行结果：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230602020-372432047.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　其次使用ApiController标记的Controller在执行模型绑定时会使用默认的推断规则，该规则分别从Body、Form、Header、Query、Route、Services(它们分别对应FromBody、FromForm、FromHeader、FromQuery、FromRoute、FromServices特性)中推断获取数据并绑定，为什么说推断？&lt;/p&gt;
&lt;p&gt;　　因为有一些特殊的规则：&lt;br/&gt;　　1. FromBody用于复杂类型推断，如果不是复杂类型(如int、string等)以及特殊的内置类型(IFormCollection文档例子)，则不会从Body中获取数据，除非通过[FromBody]特性指明，例子如下：&lt;/p&gt;
&lt;p&gt; 　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230650810-401513277.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　请求结果：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230713321-1706006306.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　当使用[FormBody]指明参数数据源后可以正常访问：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230731458-933776454.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;注：当请求参数为简单类型时，请求体内容类型需要为application/json，内容不能为Json字符串，使用参数值作为内容即可(上图id没有提供的异常并不是因为Json格式问题，而是没有指明从body中获取数据导致的)。&lt;/span&gt;&lt;br/&gt;　　2. 只能存在一个参数从Body中获取数据，如果出现多个参数时，只能保证一个参数从Body中获取数据，其它参数需要指明获取数据的位置：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230756696-276260042.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　该API的调用方式如下：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230855801-665496637.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　3. FromForm默认只推断文件(IFormFile)及文件集合类型(IFormFileCollection)，其余类型默认均不会从Form中获取。&lt;br/&gt;　　4. 使用FromForm特性时会推断multipart/form-data请求内容类型。&lt;/p&gt;
&lt;p&gt;　　以上推断行为可以通过如下配置禁用：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230922334-1145138408.png&quot; alt=&quot;&quot;/&gt;　&lt;/p&gt;
&lt;p&gt;　　更多信息参考文档：&lt;a href=&quot;https://docs.microsoft.com/zh-cn/aspnet/core/web-api/?view=aspnetcore-2.1&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/zh-cn/aspnet/core/web-api/?view=aspnetcore-2.1&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;SignalR&lt;/h2&gt;
&lt;p&gt;　　SignalR是用于客户端服务器实时通信的工具库，从ASP.NET中就具有该功能，ASP.NET Core中的SignalR概念与用法与原来基本一致，但也存在一些区别：&lt;br/&gt;　　1. 支持更多的客户端，.Net客户端、Java客户端、Js客户端以及非官方的C++客户端、Swift客户端。&lt;br/&gt;　　2. 当链接SignalR并通过身份验证后，SignalR会保存当前用户链接SignalR的ID以及通过验证后的用户名，可以通过用户名向用户客户端推送消息。&lt;br/&gt;　　3. 在应用程序中可以通过IHubContext&amp;lt;HubType&amp;gt;方式，对SignalR上下文进行注入，并且可以直接通过该上下文推送数据给已经链接的客户端，IHubContext&amp;lt;HubType&amp;gt;实际上是GlobalHost.ConnectionManager.GetHubContext&amp;lt;HubType&amp;gt;()的替代方式。&lt;br/&gt;　　4. ASP.NET Core中通过app.UserSignalR以及route参数来映射一个Hub，每一个Hub拥有独立的上下文，因此如果要使用IHubContext&amp;lt;HubType&amp;gt;来向客户端推送信息，那么必须准确注明Hub的类型，如下图代码应该使用IHubContext&amp;lt;ChatHub&amp;gt;，不能使用除ChatHub以外的类型(基类也不行)。&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130230959346-1659184436.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　5. SignalR默认使用Json协议传输数据，默认情况下使用首字母小写的驼峰命名方式序列化对象，要更改该默认行为需要通过一下代码，替换默认的序列化行为：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/640251/201811/640251-20181130231017540-1152946267.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　6. ASP.NET Core的客户端代码(特指Js客户端)有变更，需要对应版本使用。&lt;br/&gt;　　关于更多SignalR内容请参考文档：&lt;a href=&quot;https://docs.microsoft.com/en-us/aspnet/core/signalr/introduction?view=aspnetcore-2.1&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/en-us/aspnet/core/signalr/introduction?view=aspnetcore-2.1&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;小结&lt;/h2&gt;
&lt;p&gt;　　本文主要介绍了ASP.NET Core中Mvc、WebAPI以及SignalR开发时与原来ASP.NET中的一些细小区别和新特性，整体来说ASP.NET Core与ASP.NET从使用方式上基本上是一致的，这也使得从ASP.NET迁移到ASP.NET Core变得更加容易，但可能因为这些细小的问题往往会向代码中埋入一些坑，所以特别编写了本文来解释这些问题。&lt;br/&gt;　　总的来说ASP.NET Core的文档相当齐全，本文中大部分内容实际都是文档中提到的，所以建议大家在使用ASP.NET Core开发时，首先第一步就是熟读文档，避免遗漏细节。希望本篇文章对大家有帮助(*^_^*)&lt;/p&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;p&gt;　　&lt;a href=&quot;https://docs.microsoft.com/en-us/aspnet/core/?view=aspnetcore-2.1&quot; target=&quot;_blank&quot;&gt;https://docs.microsoft.com/en-us/aspnet/core/?view=aspnetcore-2.1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文链接：&lt;a id=&quot;Editor_Edit_hlEntryLink&quot; title=&quot;view: ASP.Net Core开发(踩坑)指南&quot; href=&quot;https://www.cnblogs.com/selimsong/p/10047321.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/selimsong/p/10047321.html&lt;/a&gt; &lt;/p&gt;

</description>
<pubDate>Fri, 30 Nov 2018 15:27:00 +0000</pubDate>
<dc:creator>7m鱼</dc:creator>
<og:description>ASP.NET与ASP.NET Core很类似，但它们之间存在一些细微区别以及ASP.NET Core中新增特性的使用方法，在此之前也写过一篇简单的对比文章ASP.NET MVC应用迁移到ASP.NE</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/selimsong/p/10047321.html</dc:identifier>
</item>
<item>
<title>视频编码那些事儿 - 立冬以东</title>
<link>http://www.cnblogs.com/yongy1030/p/10047296.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yongy1030/p/10047296.html</guid>
<description>&lt;h3 align=&quot;center&quot;&gt;这是我大四的一个专业选修课的结课作业，写了点关于视频编码的相关知识点的汇总，由于本身也不是做这个方向的，水平不够，所有内容基本都来自于书籍、博客和课上知识。我没有去查看和实现源代码，也没有去看官方的标准手册，所以有些地方肯定说得有点问题。发这篇博客的原因是，希望能够给一些不知道视频编码为何物的人参考参考，大致的思路应该还是可以看看的。内容有什么不对的地方可以在底下评论，谢谢！&lt;/h3&gt;



&lt;p&gt;现在的时代是一个信息流的时代，人类接收信息的方式，已经更多的来自于手机、电脑、电视这些电子产品。你没事的时候看个电影，在直播平台给你喜欢的主播刷个小礼物，在B站上看看视频，都在使用着视频编码技术。不仅如此，现在的社会是一个数字的社会，你在你的手机、电脑、电视上看的东西，都是由一个个离散的数字值组合而成。因此，为了满足人民日益增长的对视频信息摄取的渴望，科学家们想出了一个又一个办法，来使得视频传输的效率越高、速度越快、显示更清晰等等，简而言之就是，以更小的带宽、更高的效率、更快的速度给人以更舒服的观看体验。&lt;/p&gt;

&lt;p&gt;不过对于一个不是这个专业的小白同学，就会有各种疑问了，这篇文章就是写给这些小白们，让他们对视频编码有一个直观清晰的认识。&lt;/p&gt;

&lt;p align=&quot;left&quot;&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;小白&lt;/strong&gt;：老师老师，我想问一下，什么是视频啊？视频和图像有啥关系吗？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我&lt;/strong&gt;：很多学生在刚接触视频这块知识的时候，都会有这样的疑问。其实我们在电影院看电影的时候，荧幕上放的东西并不是一个连续的画面，而是一幅幅快速闪过的图像，那我们为什么看到的是正常的连续视频，而不是卡来卡去的翻页PPT呢？这就不得不提一下什么是视觉暂留了！人眼在观察景物时，光信号传入大脑神经，需经过一段短暂的时间，光的作用结束后，视觉形象并不立即消失，这就是“视觉暂留”了，也就是说你看过的一个画面，并不会立刻消失，而是会在你的大脑中留下一点“余辉”。所以你看到的视频，都只是一幅一幅独立的快速闪过的图像组成。只要闪得足够快，你就以为那是连续的视频，不会有卡的效果啦！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白&lt;/strong&gt;：哇！这么神奇！那，那个闪得足够快具体是多快呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我&lt;/strong&gt;：你真是个喜欢提问的小白呢！人的视觉暂留大概能维持0.1s到0.4s的时间，以0.1s来算的话，也就是在视频播放中，一秒至少要放10个图像，才让人不会觉得卡。当然不同人的敏感程度也不同，为了一个更好的效果，现在电影院中的电影一般都是一秒放24帧图像，电视的话，咱国家是每秒25帧图像，美国加拿大那边是约每秒30帧。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白&lt;/strong&gt;：诶？咋我国和美国那边还不一样呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我&lt;/strong&gt;：哈哈，你真仔细，其实很简单，因为我们国家的用电体系是50Hz，美国那边是60Hz，视频每秒帧数正好是发电频率(也叫工频)的一半，你可以理解为是为了视频显示和用电的步调一致（一个正弦波周期对应一个波峰、一个波谷，也正好对应两帧的图像显示时间），这样的一致原则，更有利于信号的传输吧！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白&lt;/strong&gt;：哦…原来是这样。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;其实这就是最简单，也是最需要明白的一件事，“视频是由图像构成的”。所以说，对视频进行编码（为了使得一个视频占用的空间大小更小，却又不会很影响观看质量），最应该想到的一个方法就是先对每一幅静态的图像进行编码，每一帧图像都能够做到很好的压缩，视频自然就能很好的压缩了。&lt;/p&gt;
&lt;p&gt;由此，JPEG诞生啦！&lt;strong&gt;&lt;br clear=&quot;all&quot;/&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;老师老师，我明白了视频是由一帧帧快速闪过的图像构成的，视频编码首先就要考虑对图像编码。那么咋对图像进行编码呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;嘿嘿嘿，我来介绍一下什么是JPEG吧！小白，你自己用电脑查看图像的时候，细心的话是不是发现，图像的文件名后面都有个后缀，比如什么.jeg、.jpeg、.png、.bmp等等。前两个就是我们今天的主角。.jeg和.jpeg其实是一个东西，都是遵循jpeg标准的图像格式，只是因为DOS、Windows 95等早期系统采用的8.3命名规则只支持最长3字符的扩展名，为了兼容采用了.jpg。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;嗯..也就是说jpeg标准就是一种可以将图像进行压缩的算法标准，对吧？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;对对对。怎么对图像进行压缩呢？首先，我们有过一点信号的知识的同学都知道，我们可以从时域和频域两个角度去分析一个信号，而jpeg标准压缩其实是对图像的频域进行压缩的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;将信号从时域转换为频域用傅里叶变换，这我知道，为啥图像也能有频域？？？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;图像当然有时域和频域咯，你知道的那个傅里叶变换是将一个一维信号转换到频域的方法吧。图像其实你可以理解为一个二维信号，而且是一个二维的数字信号，是离散的。我们可以通过DCT变换来得到一个图像的频域信号。DCT变换其实就是二维信号的离散傅里叶变换的实部部分。比如一张8×8的图像信号，通过DCT变换之后，频域也是8×8的信号。同时在频域部分，左上角显示的是低频分量，右下角显示的高频分量。记住高低频的位置，接下来会涉及到。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;诶？很奇怪啊，为什么非要把图像转换到频域进行压缩呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;这个问题问得好！因为一幅图像中占比较多的部分往往是低频分量，也就是说，图像中的像素点的变化往往是缓慢的，相邻两个像素点往往是有很大相关的。辣么！如果我们将一幅图像变换到频域，往往是左上角低频部分的数值较大，而右下角的高频数值较小（因为图像高频分量少）。在实际中，左上角的值可以达到几百的数量级，而右下角的数值几乎接近于0 。&lt;/p&gt;
&lt;p&gt;所以当我们将图像变换到频域之后，我们再对频域信号进行量化。相比于直接对时域信号量化，这种方法的好处是，在量化之后，往往高频部分，即右下角部分的值全部为0了，仅仅保留了低频部分的量化值。以Lena的照片举个例子：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230439339-165288620.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;将Lena图像中取出一个8×8的小块进行DCT变换，得到的频域值如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230459199-698556310.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;此处注意，jpeg压缩的时候是一块一块进行压缩的，不是整个图一起压缩。&lt;/p&gt;


&lt;p&gt;我们可以很明显地发现，频域部分的左上角低频分量的值较大，，直流分量甚至达到235.6，而右下角高频分量的值接近于0 。&lt;/p&gt;
&lt;p&gt;接着我们对频域信号进行量化。我们直接将频域图像除以一个量化矩阵。量化矩阵中的值就是不同位置的点的量化阶梯，量化矩阵是：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230535723-1602855085.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;比方说，最左上角的直流分量是235.6，量化阶梯式16，则最终的量化值就是235.6/16 = 14.725（向上取整为15）。所以最终的量化结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230554880-1478948335.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;哇！太神奇了，没想到一幅这么复杂的图像，在频域进行量化之后，竟然变得这么简单。而且我看到，量化后的矩阵右下角部分都是0了，我们怎么利用这一个特性进行压缩呢？肯定有什么好方法吧！哈哈！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;小白真聪明！如果在一个码流中，总是有一大串相同的数字出现，我们完全可以只记一个数字的值和这个数字出现的次数,比如有15个连续0，我们就记(0,15)。也就是我们仅仅只用两个数字，就可以代替这么多的0了，这个压缩比可是相当相当的大啊！！！这种方法就叫做“游程编码”。&lt;/p&gt;
&lt;p&gt;而且由于图像的频域部分由低到高的方向是向右下角的，所以在编码的过程中，采用的z字形走位(zigzag编码)。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230610676-1783626134.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;所以编码的时候大致的顺序就是：15，0，-2，-1，-1，-1,0,0，-1,0,0,0……这样就可以使得高频分量集中在序列的后面，使得更多的0可以集中在一起。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;天哪！太厉害了吧！不过老师，我发现你刚刚有一点没说，你看你看，你之前那个量化矩阵，不同点的量化阶梯是不一样的。而且我发现整体趋势是低频分量量化阶梯较小，高频量化阶梯较大，这……你得给我解释解释。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230621416-706759884.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;你你你…你确定你是小白，而不是作者内心的想象出来的托？行叭，既然你发现了，那我就说一下吧。&lt;/p&gt;
&lt;p&gt;人的眼睛往往对低频分量更敏感，可以想象如果低频分量的量化阶梯过高，那图像中那种渐变的趋势就被抹去了，图像就像有了斑块的感觉。高频分量往往是描述突变的部分，比如边缘部分，只要超过一个量化阶梯后，便可以恢复出来。所以这样处理不仅对图像不会造成过大的失真，而且能够使更多的连续0出现，提高压缩比。&lt;/p&gt;
&lt;p&gt;不仅如此，如果是彩色图像的话，图像如果在亮色空间（YCbCr空间），由于人眼对亮度和颜色的敏感程度不同，所以量化的时候，亮度通道和色差通道使用的量化矩阵还有不同！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;诶？亮色空间是啥？你好像没说过这个概念。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;嗯，彩色图像可以用RGB（红绿蓝）三个通道描述，也可以用YUV或者YCbCr的亮度分量+两个色差分量描述（Y指亮度分量）。这几种描述方式都是可以互相转换的。大致这么理解就行了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;哦哦。我有点明白了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;其实呢，在jpeg编码标准中，我们在图像中的某一块量化之后的结果，DC分量和AC分量是分开编码的！还是上面的结果举例。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230656673-1310077326.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;DC（直流分量）就是最左上角的那个点，AC分量就是除了DC那个点剩下的所有点。为什么要分开编码呢？因为一幅图像中，相邻的编码块的DC分量，即整体的亮度信息或者色差平均值是很接近的。所以AC分量依旧按照上述的z字形(zigzag编码)游程编码，而DC分量是跨块的增量编码，比如一幅图像的连续小块的DC分量分别是15,13,14,12,15,16。则我们就编码15,-2,1,-2,3,1。通过这种增量编码，很好地利用了相邻块之间的DC分量缓变的冗余信息，来提高了编码效率！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;我似乎明白了jpeg的大致思想呢！将图像变换到频域，再量化，因为图像的频率分量大多集中在低频，所以会出现很多连续0，可以通过游程编码提高编码效率。同时还可以利用相邻块的直流分量的缓变特性，用增量编码来提高DC分量的编码效率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;emmmm，不错不错，看来你已经掌握本质了！接下来我们就开始介绍视频编码部分吧！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;嗯！上面是先修知识，老师好棒棒啊！&lt;/p&gt;

&lt;p align=&quot;left&quot;&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;之前老师说过，视频就是由一帧帧图像组合而成，所以我们对视频编码，就是要先对其中每一帧图像编码。那现在不就可以了吗？还能再提高编码效率吗？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;嘿嘿嘿！小白啊，当我们在考虑如何提高编码效率时候，就应该考虑我们的编码对象存在着哪些冗余信息！这点很重要！那我们想一个视频有哪些冗余呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;之前那个jpeg编码算是一种冗余吗？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;是的，之前我们通过对每一帧图像压缩编码，就是降低视频编码中的空间冗余。所谓空间冗余，就是像素之间存在一定的相关性，利用这种相关性，我们便可以用更少的码字来（近似）描述原来的信息。那有空间冗余，在我的提示下，小白你还能想出什么冗余呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;额。。。难道是时间冗余？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;哈哈，是的呢！那什么是时间冗余呢?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;是不是在时间维度上，前后帧的相关性产生的冗余呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;是的！小白，一看你就不是小白，一定是作者精神分裂的产物！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;是不是你心里不知道吗？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;好吧，言归正传。我们之前说视频是由一帧帧快速闪过的图像组成的，在这么快的闪动速度下，前一帧和后一帧图像很多地方都是相似的，甚至没有变化。这个冗余的量是非常非常可观的。如果我们仅仅把视频当作一帧帧独立互不相关的图像来进行压缩，那是远远不够的！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;嗯，有道理！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;其实视频编码技术，真正的核心技术点已经讲完了！就是如何解决视频帧与帧之间的冗余问题。其实除了空间冗余、时间冗余，还有视觉冗余、图像构造冗余、知识冗余等等。&lt;/p&gt;
&lt;p&gt;视觉冗余其实我们已经提到过了，比如人眼对亮度色差的敏感度差异，人眼对低频高频分量之间的敏感度差异，都算是视觉冗余。&lt;/p&gt;
&lt;p&gt;图像构造冗余的话，比方说一个具有很强的规则纹理性的图像，我们完全利用纹理中的相关性进行编码。知识冗余更有意思，假设我们的编解码系统具有了人的智慧，当发现图像有一个人脸，那么其实根据常识，我们知道人的有两只眼、一个鼻子、一张嘴，还能知道它们的大致相对位置，知道的信息越多，冗余就降低的越多，编码效率就越高！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;哇！视频编码听起来好好玩啊！接着说！！！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;现在在视频编码领域，有两大组织，一个是ITU-T(国际电信联盟远程通信标准化组),另一个是ISO/IEC(国际标准化组织/国际电工委员会)，好吧，翻译过来的名字有点长。这两个标准化组织在视频编码的历史中，互相促进，互相学习。前者制定的标准是H.26x系列，后者制定的标准是MPEG系列。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230727037-2113955845.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;br clear=&quot;all&quot;/&gt;
上面就是两个标准化组织制定的主要标准，中间的是两个组织合作的成果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;原来还有这么两个组织在干这些事啊！看图最先出来的是H.261标准。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;嗯，我们接下来就介绍H.261标准。其实当我们介绍完H.261标准之后，视频编码体系基本就已经介绍完了。因为之后的编码体系基本都是建立在H.261体系基础上，只是做一些算法等方面的改进。整个编码的宏观结构并没有改变。现在广泛用的是H.265编码，H.266还在制定之中。接下来我们讲什么是H.261编码。&lt;/p&gt;

&lt;p align=&quot;left&quot;&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;我已经知道了第一个视频编码标准是H.261。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;嗯，接下来我来介绍H.261的编码规范。&lt;/p&gt;
&lt;p&gt;H.261编码主要是为了解决帧与帧之间的时间冗余。由此它引入了一个前向预测的概念，即可以通过上一帧来预测当前帧的画面内容，并将当前帧的实际图像和预测图像的残差作为编码传输对象。&lt;/p&gt;
&lt;p&gt;我们先定义一个I帧和一个P帧。I帧代表此帧不参考任何帧，当系统要传输I帧的时候，直接对图像进行压缩编码，不参考其它帧图像。P帧代表此帧要参考前面的一帧，所以当系统传输的是P帧的时候，仅仅只需要传输一个残差，以及预测的相关参数即可。解码端通过上一帧图像和残差以及相关参数，就可以恢复这一帧的原始图像了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;老师，这里的相关参数是什么，不是只要一个残差和上一帧图像不就可以恢复出来了吗？两个相加不就可以了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;首先要明确一点，图像的编码都是基于宏块的，就像之前的静态的JPEG编码，也是将图像分成一个一个小块(宏块)，然后以宏块为基本单位进行编码的。&lt;/p&gt;
&lt;p&gt;如果我们在预测的过程中，仅仅是将上一帧和这一帧的每一个宏块的差值编码传输，确实不需要额外的参数，就可以完全恢复了。但是当在视频中，物体、人等对象往往都是在运动的，那么我们就可以去寻找当前帧的这一个欲编码的宏块与上一帧最相近的宏块的相对位置找到，然后再将这两个宏块的残差编码传输。寻找最近似匹配块的过程叫运动估计，将前后两个最近似的块作差的过程叫运动补偿。运动估计的过程如下图：&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230757592-1169313037.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;对当前帧的所有宏块进行运动估计则形成的一组运动矢量(场)，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230810333-198508744.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;/p&gt;
&lt;p&gt;所以在传输的过程中，不仅要传输残差信息，也要传输运动矢量，这样才能恢复原始图像。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;嗯，有点明白了，I帧直接传输原始图像信息，P帧要参考上一帧，进行运动估计和运动补偿，然后将预测的图像和当前的原始图像作残差，并和运动估计的矢量一起进行编码传输。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;对，大致结构就是这一过程，但是这里面仍然有一些细节问题。&lt;/p&gt;
&lt;p&gt;这样吧，我给你看一张H.261的整体框架图。&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230819582-348314639.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;上图就是H.261的结构图，我们来一步一步梳理这里面的知识。流程如下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;图像输入。&lt;/li&gt;
&lt;li&gt;帧内和帧间的选择器。这里的帧内就是要传输I帧的意思，帧间就是P帧的意思。而视频编码中，这一开关的控制权在编码者手中，标准中并没有做出严格规定。编码者可以通过“编码控制”模块，进行I、P帧的交换，可以控制I、P帧之间的比例大小。&lt;/li&gt;
&lt;li&gt;当传输的I帧的时候，图像先经过DCT编码，转换到频域，再经过量化，编码，即可传输。由此可见，当视频编码中，如果传输的是I帧，其实仅仅相当于做了一个图像编码(JPEG)。&lt;/li&gt;
&lt;li&gt;由于I帧之后是P帧，P帧的传输需要前面一帧（I帧或P帧）的参考，所以在第3步量化之后，又经过了反量化，反DCT变换，存储起来。当下一帧到来的时候，将这两帧图像进行进行运动估计和运动补偿。将运动估计的结构一起送入右边的编码传输模块。&lt;/li&gt;
&lt;li&gt;在运动补偿之后，已经输出了当前帧的预测图像了。按照我们之前的分析，由于两帧间隔很短，这个预测图像和真实图像其实相差不多，通过一次环路滤波之后，和真实图像作差，然后编码传输。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;大致就是这么一个框架，而这个框架将被一直延续了下来，之后的编码标准都是在这个的基础上进行小幅度修改和改进。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;这里有两个地方没搞明白。一个是环路滤波是做什么的，还有一个是在反DCT变换为什么会有一个相加器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;你观察的还是很仔细的，先解释环路滤波的问题。&lt;/p&gt;
&lt;p&gt;我们知道，在视频编码中，我们是以一个一个宏块为基本单位编码的，那我们这种预测方式（估计、补偿）的预测结果往往容易出现一块一块的斑块，就好像图像都是一块一块的，块块之间有明显的间隙（分块效应）。这个和原始图像肯定还是有一些差距的。而环路滤波可以对这个预测图像的边缘进行低通滤波，使得块与块之间的边界不那么明显。所以更接近原始图像，残差也就越小，编码的效率也会越高。&lt;/p&gt;
&lt;p&gt;至于第二问题，并不难理解。这是因为，我们并不只是I、P、I、P、I这样交换编码，我们可以在两个I帧之间，插入多个P帧，那在这种情况下，当上一帧是P帧，这一帧依旧是P帧时，从反DCT变换那里的输出结果就不是上一帧的完整图像了，而是残差！所以为了恢复完整图像，必须先和上一帧的预测图像进行一次加和。&lt;/p&gt;

&lt;p&gt;H．261标准是一个很宽泛的标准，给予了编码者很多自我调整的空间。它的思想也一直影响了后面的编码标准的制定。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;嗯，明白了！&lt;/p&gt;

&lt;p align=&quot;left&quot;&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;H.261已经讲完了，你还记得之前那个视频编码的年代图吗？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;记得记得，老师你看我这就给您复制过来！&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230829408-1629315255.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;谢谢谢谢！H.261之后，便是另一家标准组织的MPEG-1标准。由于都是基于H.261编码标准，所以，我们这里只介绍它的不同之处。&lt;/p&gt;
&lt;p&gt;相比于H.261，MPEG-1真的没有做多少改进，但是它在预测方法上，引出了前后预测的方法，这是一个最大的改进。下面我们主要介绍这格前后预测是怎么回事。&lt;/p&gt;
&lt;p&gt;我们知道H.261中有I帧、P帧，I帧是传输整个图像，P帧是参考的前一帧，只传输残差和相关参数。在MPEG-1中引入了B帧，这一帧不仅会参考前面的帧，也会参考后面帧，以此来共同预测当前帧。显然这样的预测方法可以使得预测结果更加接近原始图像。比如在前一帧中一个特征宏块在A处，在后一帧中那个特征宏块在B处，那么我们有理由去预测，在当前帧中，宏块很可能是在A、B的中点处。&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230853485-356844868.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这是编码过程中的的帧流，GOP是一组周期循环的帧组。如果我们将B帧全部去掉，那么其实和H.261是完全一样的。而我们在I、P帧间和P、P帧间插入的B帧，则是参考了前面I（P）帧以及后面的P（I）帧，注意B帧彼此不互相参考。那么这种算法结构就引发一个问题，视频采集的顺序肯定是IBBPBBPBBPBBI，而编码的时候，为了得出B帧要传输的残差，必须知道后面的P帧或I帧，以此来做参考。所以在这种要求下，视频采集端必须有一个缓冲，并且要将顺序重排，以适应编码顺序。&lt;/p&gt;

&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230905592-837059590.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;如上图，这便是加入了B帧之后的编码框图（其实这个图里面加入了一些MPEG-2的算法，我们现在不提，之后再提），和之前的H.261框图相比，整体结构没有多大改变，只是在视频输入端加入了帧重排模块。在反DCT变换之后，加入两个存储器，以实现双向预测。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;哦，原来MPEG-1相对于H.261最大的改进就是引入了双向预测帧。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;是的，不过当然它还做了一些其它的改进，比如它还将每一帧的中的各个编码宏块的直流分量单独编码传输了，这个可以用于在快进的时候，快速播放。类似的小改进还有一些，不过整体结构一直没变。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;看来H.261才是视频编码的基石啊！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;之后又出现了H.262/MPEG-2标准，这个标准其实只是MPEG-1的扩展版本，在全面继承MPEG-1的压缩所发基础上，增添了一些新的语法结构和算法。那么值得介绍说明的有：第一，MPEG-2不仅支持逐行扫描、也支持隔行扫描，以前的CRT显示器，为了防止扫描过程中，产生的闪烁现象，采用的是隔行扫描技术，同理在MPEG-2也添加了这一功能。第二，MPEG-2在运动估计的时候支持半像素的估计，也就是在估计的时候，可以先对估计的区域进行1:1插值(因为是半像素)，然后估计的运动矢量就相比于整像素估计更精细了。第三，MPEG-2可以支持各种清晰度可变的编码方式，比如可以控制信噪比的变化、空间分辨率的变化、时间分辨率的变化。&lt;/p&gt;

&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230913015-1817004999.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这个还是刚才的图，我们说过，这里有MPEG-2才出现的算法结构。就是右上角的自适应量化器。我们可以通过这里去调节量化矩阵的参数，可以选择更小的量化阶梯来达到更高的信噪比。同时为了改变空间分辨率，我们可以在原有的最高分辨率情况下，可以空间降采样得到较低分辨率的视频，为了改变时间分辨率，则可以抽帧。这样做都是为了在传输带宽受限的情况下，能够以较低分辨率来正常的播放视频。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;嗯，看来H.262/MPEG-2也只是MPEG-1基础上做了一些小改进，尤其是分辨率可调的技术，很符合我们现在看视频的习惯了！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;嗯是，之后MPEG-4又出来了，你去查MPEG-4的标准时，发现它是有很多部分组成，MPEG-4的第二部分是MPEG-4 Visual，我认为这是很大胆很前卫很有价值的改进，但是标准推出之后，由于实现难度过高，并没有落地。之后两家组织共同制定了H.264编码标准，这个标准也收录在MPEG-4的第十部分。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;MPEG-4 Visual这么厉害的吗？它是个啥东西？竟然都无法落地。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;哈哈，其实这个标准很好理解，还记得我们之前说编码的时候都是以一个个宏块为基本单位编码的吗？这种只是做了机械的固定的图像分割。而在MPEG-4 Visual中，它是以视频中的对象进项编码的。比如视频中有一个人在操场上打篮球，则会视频就有三个主要的对象，分别是“人”、“篮球”、“背景操场”。那么我们在做运动估计和补偿的时候就可以以对象为单位。小白！还记得我之前跟你说过视频中有哪些冗余吗？这种可以减小哪种冗余呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;哦！！！我明白了，知识冗余、图像构造冗余好像都可以减小了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;是啊！当我们一直能检测出人和篮球的位置，那我们基本就可以以非常小的残差编码传输了。然而，我说到了检测，真正的难度就在检测，人工智能还远远没有发展到可以在视频编码中实时进行检测识别物体对象，这也是为什么mpeg-4 visual不好落地原因。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;这个标准竟然是2000年之前提出的，那些做编码的科学家真的好厉害啊！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;嗯，科学研究永远要走在时代前面，才能为工业界指引前进的方向。&lt;/p&gt;
&lt;p&gt;之后两家标准组织开始制定H.264/mpeg-4(part10)。这是一个得到了非常广泛应用的编码标准。然而正如我之前所说的，我们的编码整体的框架一直没有变化。H.264编码继承了先前开发的视频编码标准的许多优点，并在各个主要功能模块都做了一些“精雕细琢”的改进，采用了H.264标准，视频的压缩比是MPEG-2压缩比的2到3倍，有效降低了在有线网络、卫星网络和电信网络上传送高画质视频的成本。&lt;/p&gt;
&lt;p&gt;虽然整体结构没有做大的改动，但是其中有几处也是很有必要值得说道说道的！&lt;/p&gt;
&lt;p&gt;首先，我们之前说MPEG-2的时候，它先引入了半像素估计，使得运动矢量的更加精细了，到了H.264已经可以支持1/4像素了，也就是原始像素与像素之间，插值更多，运动矢量也更精细了，估计的位置也更精确了。&lt;/p&gt;
&lt;p&gt;其次，预测编码的时候，块的大小不再固定为16*16了，现在可以可以支持8*8和4*4这种更精细的预测了。&lt;/p&gt;
&lt;p&gt;&lt;br clear=&quot;all&quot;/&gt;
当然还有一个最重要的改进，我们之前的预测仅仅局限在帧与帧之间的预测，这是时间冗余。但是在同一帧里，往往有很多空间冗余，即相邻宏块描述的图像也很接近。之前我们解决这种冗余是在JPEG编码的时候，将不同块的DC分量以增量编码形式编码传输。然而这还不够，我们为什么不引入帧内的预测模式呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230935822-18423832.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;如上图，中间的灰色就是一个4*4的预测块，而这种预测是根据其左边和上边像素进行预测的，而预测模式之多可以达到9种（8*8和16*16有4种预测方式），不同的预测方式对应不同的预测函数，H.264在帧内预测时候，并不是固定预测模式的，而是在搜索一个最佳（最近似）的预测模式，使得编码效率可以达到最高。&lt;/p&gt;
&lt;p&gt;不仅有如上的改进，值得一提的是H.264为了提高DCT运算速度，提出了整数DCT变换，相对于小数变化，速度真是提升了很多。而且在传输之前的熵编码阶段，H.264使用了上下文自适应的可变长度编码和算术编码，在熵编码这一块更接近香农极限，并且很好提高了熵编码的实时性（传统的哈夫曼编码不是实时的哦！）。正是有了这些改进，H.264在推出后得到了很长时间的非常广泛的应用。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;终于讲到了H.265编码标准了，H.265又称为HEVC，是H.264标准的继任者。2004年由两家标准组织开始制定。第一版的H.265视频压缩标准在2013年被正式推出。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;H.265应该也是建立之前的编码标准基础上的吧。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;是的，科学的前进并不是为了打破标准而打破标准，更靠谱的方式应该是在过往的优秀经验上，一点一点改进发展。&lt;/p&gt;
&lt;p&gt;我们知道，近些年的数字视频中，正朝着更高清（4k，8k）、更逼真（立体成像、VR）发展。在这种数据量越来越大的趋势推动下，H.264标准已经很难再支撑视频行业的高速发展了，如果继续采用以往的视频编码标准技术，就会出现以下一些局限性：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;更高清的视频导致像素点的增加，每帧图像的宏块个数急剧增加导致编码宏块的预测模式、运动矢量等参数占用的码字过多。&lt;/li&gt;
&lt;li&gt;同样由于视频的高清化，单个宏块描述的图像内容信息则很少，则在帧内预测的时候，相邻宏块之间的相似度增加，冗余度增加。&lt;/li&gt;
&lt;li&gt;以往的编码结构比较适合串行运算，制约了用并行计算的方式来提高编码速度的实现。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;正是有了这些局限性，H.265被推出了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;也就是说H.265的出现是为了解决视频越来越高清所带来的冗余度增加的问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;是的。H.265在很多细节上都做了改进，相比于H.264的编码标准，H.265的提高效果如下表：&lt;/p&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot; width=&quot;130&quot;&gt;

&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;111&quot;&gt;
&lt;p align=&quot;center&quot;&gt;480P&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;111&quot;&gt;
&lt;p align=&quot;center&quot;&gt;720P&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;111&quot;&gt;
&lt;p align=&quot;center&quot;&gt;1080P&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;111&quot;&gt;
&lt;p align=&quot;center&quot;&gt;4K&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td valign=&quot;top&quot; width=&quot;130&quot;&gt;
&lt;p&gt;平均码率降低&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;111&quot;&gt;
&lt;p align=&quot;center&quot;&gt;52%&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;111&quot;&gt;
&lt;p align=&quot;center&quot;&gt;56%&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;111&quot;&gt;
&lt;p align=&quot;center&quot;&gt;62%&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;111&quot;&gt;
&lt;p align=&quot;center&quot;&gt;64%&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;H.265标准也叫HEVC，全称为高效视频编码（High Efficiency Video Coding），就是为了高清视频降低码率而制定的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;是的。相比于H.264，H.265在高清视频压缩上做了一些比较好的改进。&lt;/p&gt;
&lt;p&gt;首先H.265的编码结构发生了很大的变化，它采用的是四叉树的划分。什么是四叉树划分呢？首先H.265的图像最大的划分块是64*64像素的，然后继续分层，如下图：&lt;/p&gt;

&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130230952194-251781467.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;



&lt;p&gt;对应于四叉树的话就是这样：&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130231012681-363381571.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;其中节点为0，代表这一子块没有继续分割，是叶子节点，节点是1，代表这一子块被继续分割了。我想说的是在H.264中，就有宏块继续分割子块的概念，目的都是为了在表达或者描述图像中更精细的部分时，能够采用更小的编码预测结构块，但是H.265这种以四叉树为基础的划分，更具有数据结构的整齐划一，在算法上便于回溯和查询，为更复杂的算法实现打下基础。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;嗯，这种树形结构的划分，很适合块的回溯和定位。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;是的，也正因为基于这种划分结构，H.265在H.264的整体框架下，几乎将每一部分的算法都做了改进，使得编码的效率更高。&lt;/p&gt;
&lt;p&gt;除此之外，在帧内预测时，H.265相比于H.264有着更多的预测模式，小白还记得H.264的帧内预测模式吗？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;记得啊，4*4的预测块有9种预测模式，在预测的时候，遍历所有的模式，选取最终和原始图像最接近的模式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;H.265为了提高预测精度，把预测模式的数量直接提高到了35种。&lt;/p&gt;

&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130231021053-1991626501.png&quot; alt=&quot;&quot;/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130231026422-1443941694.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;



&lt;p&gt;    左图：H.264的预测模式                  右图：H.265的预测模式&lt;/p&gt;

&lt;p&gt;这种精细的预测模式，虽然带来更精确的效果，但是由于要遍历所有模式，并对每种模式进行评估比较，所以必然会带来繁重的计算负担。然而近几年的硬件发展速度很快，并且H.265也做了非常多的适应并行计算的优化，使这一切都变成了可能。&lt;/p&gt;
&lt;p&gt;当然在帧内预测中，H.265还有一些改进，比如在预测之前，会对图像进行平滑滤波，减少噪声对预测的影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;说完帧内预测，接下来就是帧间预测的改进吧。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;对，之前说过，虽然H.265整体结构没有大幅度改进，但是在每个部分的细节上的处理可谓很精妙！&lt;/p&gt;
&lt;p&gt;在帧间预测的时候，我们的目的是要找到更合适MV（运动矢量），然后我们也会把MV作为参数进行编码传输到解码端，但是由于在高清视频中，传输MV的码字也很多，必须要对MV进行的传输进行优化。小白，我们都已学了这么编码优化的知识，你能想象如何对要传输的MV的信息进行压缩编码吗？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;哈哈，我明白你的意思了，对MV也进行预测，然后传输残差！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;可以的！你已经掌握了编码的精髓了！哈哈哈哈！然而我想说的是，这种方法在H.264标准中已经采用了，利用的就是空间(或时间)相邻块之间的运动矢量的相关性，来进行残差编码。在高清视频中，这种编码技术显得尤为重要。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;那H.265也是采用H.264这种结构吗？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;是的，但是H.265不仅保留这种编码技术，还采用一种基于索引编码传输的方式——merge模式。&lt;/p&gt;
&lt;p&gt;merge模式会为当前子块建立一个MV候选列表，遍历这些候选MV，选取最近似的作为最优MV。若编解码器依照相同的方式建立候选列表，则编码器只需要传输最优MV在候选列表中的索引即可。这种候选列表的MV可以在空域与当前子块上相邻，也可以在时域与当前子块上相邻。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;merge模式直接传输了最优的MV的对应块的索引，这种索引也是基于四叉树结构，索引的传输相比于残差的传输又提高了编码效率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;这是帧间预测，H.265的改进还有在熵编码上做了优化，以及采用了很多的并行技术，使得它的复杂算法得以落地实现！&lt;/p&gt;

&lt;p align=&quot;left&quot;&gt; &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;小白，讲到这里，你应该对整个视频编码的发展和实现思路有了一些自己的认识了吧。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;嗯，还行吧，我觉得视频编码的发展基本是基于第一代的编码标准（H.261），然后不断去改进，不断地适应时代的需求。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;在这种改进的过程中，融入了很多科学家和工程师的精妙的想法，这个过程是艰辛的，因为改进一处，其实就会牵动很多方面，但是这个过程相信也是有趣的，与时代共进步，服务于整个多媒体行业是一件很有成就感的事。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;那说完前面的编码标准，是不是该憧憬一下未来的标准呢？我们之后的发展方向是什么样的呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;下一代的编码标准H.266也是由两家标准组织共同制定的，H.266的探索是从2016年初开始提上日程，其目标是实现比现有标准提高50％以上的压缩率（目前已经达到40%以上），在开发日程上，第一个H.266标准版本将在2019年10月推出，最终标准将定于2020年底推出。新的标准将非常适合4K、8K、16K以及更高清的视频传输，以及在编解码中将会结合机器学习等AI算法，可以说是一种Future Video Codec。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;那H.266将会在哪些方面做出改进呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;由于H.266标准还处在探索阶段，标准的制定方案并不是确定的，也不一定能保留到最后阶段，只能通过几次会议来大致做一个了解。&lt;/p&gt;
&lt;p&gt;首先H.266的制定是针对4K及以上的高清视频，这导致目前编码器的最大块尺寸变为128*128（H.265是64*64）。其次在编码结构上，H.266中是四叉树、三叉树、二叉树混合划分的，比如一个大块可以先分成四块，然后子块可以再分成三块或两块，这就使得在编码过程中，更加可以精细地考虑图像的纹理特征，预测效果更好。几种划分方式如下：&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130231054407-1145199790.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;除此之外，H.266在环路滤波技术上，可能会采用自适应环路滤波。在帧内预测中，H.266的预测模式数量可能会达到70种以上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1196323/201811/1196323-20181130231106738-1107678044.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;/p&gt;

&lt;p align=&quot;left&quot;&gt;这么多种的帧内预测模式，遍历一遍会很耗计算力，H.266并不会全部遍历，而是会根据预测块的宽高比来选择使用哪些种角度预测模式作为候选预测模式（因为存在三叉树结构，宽高比肯定不会只有1:1）。&lt;/p&gt;
&lt;p&gt;在帧间预测的时候，H.266可能会考虑仿射运动的预测，我觉得这一点是非常好玩的。在H.265中，只有平动模型被用于运动补偿预测，然而在真实世界中，有各种各样的运动，比如放大、缩小，旋转等非规则运动。基于这种的预测方式，将会给运动估计的效果带来更精确的效果，编码效率也将会有所提高。&lt;/p&gt;
&lt;p&gt;总的来说，H.266将会在很多部分引入更优秀的算法，2018年4月10日美国圣地亚哥会议上，为新一代视频编码标准定名为Versatile Video Coding，主要目标是改进现有HEVC（H.265），提供更高的压缩性能，同时会针对新兴应用（360°全景视频和HDR）进行优化。2020年之后，5G通信开始商用化，人工智能不断发展，硬件的算力将会更高，新的视频编码标准将服务于人类更加Versatile（多功能的），多元化的的视频需求！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小白：&lt;/strong&gt;哇！生活在这个日新月异的时代真好！谢谢老师！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我：&lt;/strong&gt;不用谢。&lt;/p&gt;
</description>
<pubDate>Fri, 30 Nov 2018 15:12:00 +0000</pubDate>
<dc:creator>立冬以东</dc:creator>
<og:description>这是我大四的一个专业选修课的结课作业，写了点关于视频编码的相关知识点的汇总，由于本身也不是做这个方向的，水平不够，所有内容基本都来自于书籍、博客和课上知识。我没有去查看和实现源代码，也没有去看官方的标</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/yongy1030/p/10047296.html</dc:identifier>
</item>
<item>
<title>痞子衡嵌入式：恩智浦MCU安全加密启动一站式工具nxpSecBoot用户指南 - 痞子衡</title>
<link>http://www.cnblogs.com/henjay724/p/10047071.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/henjay724/p/10047071.html</guid>
<description>&lt;h3 id=&quot;软件概览&quot;&gt;1 软件概览&lt;/h3&gt;
&lt;h4 id=&quot;介绍&quot;&gt;1.1 介绍&lt;/h4&gt;
&lt;p&gt;　　nxpSecBoot是一个专为NXP MCU安全加密启动而设计的工具，其特性与NXP MCU里BootROM功能相对应，目前主要支持i.MXRT系列MCU芯片，与NXP官方提供的标准安全加密配套工具集（OpenSSL, CST, sdphost, blhost, elftosb, BD, MfgTool2）相比，nxpSecBoot是一个真正的一站式工具，一个工具包含NXP官方所有加密配套工具的功能，并且是全图形用户界面操作。借助于nxpSecBoot，你可以轻松上手NXP MCU安全加密启动。&lt;br/&gt;　　nxpSecBoot主要功能如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;支持i.MXRT全系列MCU，包含i.MXRT105x、i.MXRT102x、i.MXRT106x&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;支持UART和USB-HID两种串行下载方式&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;支持.elf和.srec格式的源image文件输入&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;支持FlexSPI NOR和SEMC NAND接口的外部启动设备&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;支持基于HAB实现的安全加密启动（单签名，签名和加密）&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;支持基于BEE实现的安全加密启动（唯一SNVS key，用户自定义key）&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;支持基于HAB和BEE联合实现的安全加密启动（HAB签名，BEE加密）&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;支持eFuse memory的回读和烧写操作&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;支持从外部启动设备回读已下载的bootable image数据，并对数据组成部分进行标注&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&quot;下载&quot;&gt;1.2 下载&lt;/h4&gt;
&lt;p&gt;　　nxpSecBoot完全基于Python语言开发，并且源代码全部开源，其具体开发环境为Python 2.7.14、wxPython 4.0.3、pySerial 3.4、bincopy 15.0.0、PyInstaller 3.3.1。&lt;/p&gt;
&lt;blockquote&gt;
&lt;/blockquote&gt;
&lt;p&gt;　　nxpSecBoot在发布时借助PyInstaller将所有的Python依赖全部打包进一个可执行文件（\nxp-sec-boot-ui\bin\nxpSecBoot.exe），因此如果不是对nxpSecBoot的二次开发，你不需要安装任何Python软件及相关库。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;Note: 源代码包里的nxpSecBoot.exe是在Windows 10 x64环境下打包的，也仅在该环境下测试过，如果因系统原因无法直接使用，你需要安装相应的Python开发环境，并在\nxp-sec-boot-ui\bin\目录下执行“pyinstaller .\nxpSecBoot.spec”命令重新生成nxpSecBoot.exe可执行文件。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;安装&quot;&gt;1.3 安装&lt;/h4&gt;
&lt;p&gt;　　nxpSecBoot是一个是纯绿色免安装的工具，下载了源代码包之后，直接双击\nxp-sec-boot-ui\bin\nxpSecBoot.exe即可使用。使用nxpSecBoot没有任何软件依赖，不需要额外安装任何软件。&lt;/p&gt;
&lt;h4 id=&quot;目录&quot;&gt;1.4 目录&lt;/h4&gt;
&lt;p&gt;　　nxpSecBoot软件目录组织如下：&lt;/p&gt;
&lt;pre class=&quot;text&quot;&gt;
&lt;code&gt;\nxp-sec-boot-ui
                \apps                        --放置示例的源image文件
                \bin                         --放置nxpSecBoot可执行文件及PyInstaller打包描述文件
                \doc                         --放置NXP官方安全启动相关的参考文档
                \gen                         --放置nxpSecBoot使用过程中生成的临时文件
                      \bd_file                  --根据配置动态生成的BD文件
                      \bee_crypto               --BEE加密过程中生成的文件
                      \bootable_image           --生成的bootable image文件
                      \hab_cert                 --HAB签名过程中生成的文件
                      \hab_crypto               --HAB加密过程中生成的文件
                \gui                         --放置开发nxpSecBoot UI构建工程文件
                \img                         --放置nxpSecBoot使用过程中需加载的图片
                \src                         --放置开发nxpSecBoot的所有Python源代码文件
                \tools                       --放置nxpSecBoot使用过程中需调用的外部程序
                      \blhost                   --与Flashloader通信的上位机命令行工具
                      \cst                      --HAB加密的配套命令行工具
                      \elftosb                  --生成bootable image的命令行工具
                      \image_enc                --BEE加密的配套命令行工具
                      \openssl                  --生成证书和秘钥的标准工具
                      \sdphost                  --与ROM通信的上位机命令行工具&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;界面&quot;&gt;1.5 界面&lt;/h4&gt;
&lt;p&gt;　　下图为nxpSecBoot工具的主界面，界面主要由六部分组成，各部分功能如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i2.bvimg.com/670279/c31a571884ab8182.png&quot;/&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;【Menu Bar】：功能菜单栏，提供软件通用设置。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;【Target Setup】：目标设备设置栏，提供MCU Device和Boot Device配置选项。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;【Port Setup】：串行接口设置栏，选择用于连接MCU Device的接口。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;【Device Status】：目标设备状态信息栏，当连接上目标设备之后，用于显示目标设备的状态。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;【Main Window】：安全加密启动主界面，提供对目标设备做安全加密启动的所有操作。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;【Log Window】：操作日志栏，记录软件操作日志。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&quot;软件使用&quot;&gt;2 软件使用&lt;/h3&gt;
&lt;h4 id=&quot;设置目标设备&quot;&gt;2.1 设置目标设备&lt;/h4&gt;
&lt;p&gt;　　在使用nxpSecBoot时首先需要配置目标设备，目标设备包括MCU Device和Boot Device。以NXP官方开发板EVK-MIMXRT1060为例，该开发板主芯片为i.MXRT1062DVL6A，所以【MCU Device】应设为i.MXRT106x。且以最常用的FlexSPI NOR启动为例，【Boot Device】设为FLEXSPI NOR，开发板上对应的外部存储芯片为IS25WP064AJBLE，其是一颗常用的四线QSPI NOR Flash，我们需要在软件里进一步配置该Boot Device，单击【Boot Device Configuration】按钮可弹出如下新的配置页面：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i2.bvimg.com/670279/b302ba13b565afe1.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　在弹出的名为FlexSPI NOR Device Configuration页面里可以看到很多描述Multi-IO SPI NOR Flash特性的选项，比如Device Type、Query Pads等，这些选项都需要被正确地设置，以与开发板上的外部存储芯片相匹配。&lt;br/&gt;　　除此以外，页面上还有一个名为【Use Typical Device Model】的选项，nxpSecBoot软件预先定义了一些常用的Multi-IO SPI NOR Flash型号模型，如果开发板上的外部存储芯片恰好在软件预定义的型号列表里，那么你可以直接在【Use Typical Device Model】选择对应型号，而不必在Nor Option里逐一配置。&lt;br/&gt;　　EVK-MIMXRT1060开发板上的IS25WP064AJBLE芯片属于ISSI - IS25LP064A大类，因此我们只需要在【Use Typical Device Model】选择ISSI - IS25LP064A并点击【Ok】即完成了目标设备的设置。&lt;/p&gt;
&lt;h4 id=&quot;连接目标设备&quot;&gt;2.2 连接目标设备&lt;/h4&gt;
&lt;p&gt;　　设置好目标设备之后，下一步便是连接目标设备，以USB-HID接口连接为例，给EVK-MIMXRT1060板子供电，并用USB Cable将PC与J9口连接起来，如果一切正常，应该可以在设备管理器找到vid,pid为0x1fc9,0x0135的HID-compliant vendor-defined device设备被枚举。如果没有发现该HID设备，请仔细检查板子SW7拨码开关是否将Boot Mode设为2'b01即Serial Downloader模式。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i1.bvimg.com/670279/64a8d3177d2895cb.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　确认HID设备存在之后，在【Port Setup】选中USB-HID，然后直接点击【Connect to ROM】按钮，此时软件便会自动完成目标设备连接全过程（使用sdphost连接ROM，获取一些MCU内部寄存器信息，使用sdphost加载Flashloader并跳转过去，使用blhost连接Flashloader，获取一些eFuse信息，使用blhost去配置boot device并获取boot device meomry信息），这个过程需要大概5s的时间，如果目标设备连接正常，你可以看到指示灯变蓝，并且【Connect to ROM】按钮标签变为【Reset Device】。如果目标设备连接失败，指示灯会变红，并且【Connect to ROM】按钮标签变为【Reconnect】。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i1.bvimg.com/670279/d2adabbf79ef9054.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　目标设备连接成功后可以在目标设备状态信息栏看到一些有用的设备状态信息，比如MCU芯片的UUID值、HAB状态、与启动相关的重要Fuse值，Boot Device的Page/Sector/Block大小等。&lt;/p&gt;
&lt;h4 id=&quot;安全加密启动&quot;&gt;2.3 安全加密启动&lt;/h4&gt;
&lt;p&gt;　　目标设备连接成功后便可以开始最核心的安全加密启动操作，在做安全加密启动之前先来介绍安全加密启动主界面分布：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i1.bvimg.com/670279/a2f576a87f53d802.png&quot;/&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;【Image Generation Sequence】：image生成窗口，用于对源image进行加密安全处理，生成可放在Boot Device中的bootable image&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;【Image Loading Sequence】：image下载窗口，用于将生成的bootable image下载进Boot Device中，并且在MCU中烧录相应的Fuse值（各种Key，HAB设置等）&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;【eFuse Operation Utility】：eFuse烧录窗口，用户可烧录自定义值进Fuse Region。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;【Boot Device Memory】：image回读与标注窗口，用于从Boot Device回读已下载的Bootable image数据，并对数据组成各部分进行标注&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;【Secure Boot Type】：安全模式选择，选择想要安全模式（不使能安全，HAB单签名，HAB签名加密，BEE加密）。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;【All-In-One Action】：一键操作，image生成窗口和image下载窗口里激活的操作自动按序执行&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h5 id=&quot;模式一不启用任何安全措施&quot;&gt;2.3.1 模式一：不启用任何安全措施&lt;/h5&gt;
&lt;p&gt;　　第一种模式是最简单的模式，即不启动任何安全措施，一般用于产品开发调试阶段。&lt;br/&gt;　　【Secure Boot Type】选择“Unsigned (XIP) Image Boot”，然后点击【Browse】按钮选择一个原始image文件（使用IDE生成的裸.elf/.srec文件即可，不需要包含任何i.MXRT启动所需的额外文件头），点击【All-In-One Action】按钮即可完成bootable image生成与下载所有操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i1.bvimg.com/670279/efd20119938ea3e7.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　上图中Step4和Step5并不是必需操作，仅是用于确认【All-In-One Action】按钮操作是否成功，尤其是Step5操作，可以对应image下载窗口里显示的Bootable image构成图做一遍检查。&lt;br/&gt;　　一切操作无误，板子上SW7拨码开关将Boot Mode设为2'b10即Internal Boot模式，其余保持全0，重新上电便可以看到unsigned image正常执行了。&lt;/p&gt;
&lt;h5 id=&quot;模式二启用hab签名认证&quot;&gt;2.3.2 模式二：启用HAB签名认证&lt;/h5&gt;
&lt;p&gt;　　第二种模式是初级的安全模式，即仅对image进行签名认证，一般用于对产品安全性要求较高的场合。签名认证主要是对image合法性进行校验，检测image是否被异常破坏或篡改，如果检测发现image不合法，那么MCU便不会启动执行该image。&lt;br/&gt;　　【Secure Boot Type】选择“HAB Signed (XIP) Image Boot”，然后输入serial（必须是8位数字）以及key_pass（任意长度字符）后点击【Advanced Cert Settings】按钮配置所有签名认证的参数（熟悉 &lt;a href=&quot;https://www.nxp.com/webapp/sps/download/license.jsp?colCode=IMX_CST_TOOL&amp;amp;appType=file2&amp;amp;location=null&amp;amp;DOWNLOAD_ID=null&amp;amp;lang_cd=en&quot;&gt;NXP官方HAB Code Signing Tool工具&lt;/a&gt; 使用的朋友应该对这些设置很熟悉），再点击【Browse】按钮选择一个原始image文件，最后点击【All-In-One Action】按钮即可完成bootable image生成与下载所有操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i1.bvimg.com/670279/9b7cf82111578180.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　上图中Step5主要确认两点：一、HAB状态是否是Closed的（Fuse 0x460[31:0]的bit1为1'b1）；二、SRKH是否被正确烧录（Fuse 0x580 - 0x5f0，一共256bit，即sha-256算法），SRKH是最终bootable image里CSF数据里的Public RSA Key的Hash值，用于校验Public RSA Key是否合法。&lt;br/&gt;　　一切操作无误，板子上SW7拨码开关将Boot Mode设为2'b10即Internal Boot模式，其余保持全0，重新上电便可以看到HAB signed image正常执行了。&lt;br/&gt;　　因为此时MCU芯片HAB状态已经是Closed，并且SRKH已经被烧录无法更改，所以未经签名认证的image无法正常运行，在软件目录\nxp-sec-boot\tools\cst\3.0.1\crts文件夹下存放着Private RSA Key文件，请妥善保存好，一旦遗失，那么新的image将无法被正确签名从而导致HAB认证失败无法被启动执行。&lt;/p&gt;
&lt;h5 id=&quot;模式三启用hab签名认证与hab加密&quot;&gt;2.3.3 模式三：启用HAB签名认证与HAB加密&lt;/h5&gt;
&lt;p&gt;　　第三种模式是中级的安全模式，即对image进行签名认证以及HAB级加密，一般用于对产品安全性要求很高的场合。签名认证主要是对image合法性进行校验，而加密则可以保护image在外部Boot Device中不被非法盗用，因为在外部Boot Device中存放的是image的密文数据，即使被非法获取也无法轻易破解，并且加密是和MCU芯片绑定的，因为HAB加密过程中使用了MCU内部SNVS模块里的唯一Master Secret Key。&lt;br/&gt;　　【Secure Boot Type】选择“HAB Signed Encrypted Image Boot”，然后配置所有签名认证的参数（如果本地已有证书，可以不用配置，软件会尝试复用），再点击【Browse】按钮选择一个原始image文件，最后点击【All-In-One Action】按钮即可完成bootable image生成与下载所有操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i1.bvimg.com/670279/8af3fa243981a5ff.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　上图中Step6操作之后可以看到下载进Boot Deivce里的image部分确实是密文，实际上HAB加密仅支持加密image区域，其他区域（比如FDCB、IVT、Boot Data等）均没有加密。&lt;br/&gt;　　一切操作无误，板子上SW7拨码开关将Boot Mode设为2'b10即Internal Boot模式，其余保持全0，重新上电便可以看到HAB signed encrypted image正常执行了。&lt;br/&gt;　　你可能会好奇，既然image是经过HAB加密的，那么密码在哪里？怎么设置的？其实image加密操作完全被HAB配套工具封装好了，HAB加密使用的AES-128算法，其对应的128bits的AES-128 Key不是由用户自定义的，而是HAB加密工具自动随机生成的，并且每一次加密操作生成的AES-128 Key都是不一样的，即使你没有更换输入的原始image。AES-128 Key保存在\nxp-sec-boot\gen\hab_crypto\hab_dek.bin文件里。&lt;br/&gt;　　从上图中image下载窗口里显示的Bootable image构成图里可以看出，相比HAB单签名的方式，HAB签名加密方式最终使用的Bootable image的最后多了一个DEK KeyBlob组成部分，这个DEK KeyBlob是通过MCU芯片内部SNVS模块里的Master Secret Key对hab_dek.bin里的key数据进行动态加密生成的，因为Master Secret Key是芯片唯一的，因此DEK KeyBlob也是芯片唯一的，这是保护image不被非法盗用的关键。&lt;br/&gt;　　关于HAB加密为何不支持XIP Image，其实简单分析一下启动原理便清楚，Image在Boot Device里存储的是密文，这部分密文必须要经过HAB解密成明文才可以被CPU执行，因此必须要指定不同的存储空间去存放Image明文，Non-XIP image天然指定了明文应存放在芯片内部SRAM或者外挂SDRAM中，而XIP Image是在Boot Device中直接执行的，一般明文地址与密文地址是相同的，因此HAB加密不支持XIP Image。&lt;/p&gt;
&lt;h5 id=&quot;模式四启用单引擎bee加密唯一snvs-key&quot;&gt;2.3.4 模式四：启用单引擎BEE加密（唯一SNVS Key）&lt;/h5&gt;
&lt;p&gt;　　第四种模式是高级的安全模式，即用唯一SNVS Key对image进行单引擎BEE级加密，一般用于对产品安全性要求极高的场合。BEE加密与HAB加密的主要区别是执行解密操作的主体不同，主要有如下三点区别：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;HAB加密是由BootROM里的HAB将加密后的image全部解密成明文另存后再执行（静态解密），而BEE加密是由MCU芯片内部的BEE模块对加密后的image原地边解密边执行（动态解密）。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;HAB加密仅支持Non-XIP Image（不限Boot Device），而BEE加密仅支持XIP在FlexSPI NOR中的Image。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;HAB加密区域不可指定（默认全部用户Image区域），而BEE加密的区域可由用户指定。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;　　【Secure Boot Type】选择“BEE (Signed) Encrypted XIP Image Boot”，点击【Browse】按钮选择一个原始image文件（必须是XIP在FlexSPI NOR中的image），【Key Storage Region】选择“Fixed SNVS Key”后点击【Advanced Key Settings】按钮配置所有BEE加密的参数，最后点击【All-In-One Action】按钮即可完成bootable image生成与下载所有操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i2.bvimg.com/670279/0394b7b9ace617eb.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　上图中Step5操作主要确认一点：BEE_KEY0_SEL是否设置的是From OTPMK[255:128]（Fuse 0x460[31:0]的bit13,12为2'b10）。Step6操作之后可以看到下载进Boot Deivce里的Bootable image从IVT开始全是密文，本示例仅启用一块加密区域，具体对哪些区域进行加密是在【Advanced Key Settings】里指定的，最大支持指定3块加密区域。&lt;br/&gt;　　一切操作无误，板子上SW7拨码开关将Boot Mode设为2'b10即Internal Boot模式，并且将BT_CFG[1]设为1'b1（使能Encrypted XIP），其余保持全0，重新上电便可以看到BEE encrypted image正常执行了。&lt;br/&gt;　　BEE加密相比HAB加密是要更安全的，因为HAB加密毕竟是静态解密，当HAB解密完成之后在SRAM/SDRAM中存储的是全部的image明文，如果此刻黑客去非法访问SRAM/SDRAM是有可能获取全部image明文的；而BEE加密是动态解密，CPU执行到什么地方才会去解密什么地方，任何时候都不存在完整的image明文，黑客永远无法获取全部的image明文。&lt;/p&gt;
&lt;h5 id=&quot;模式五启用双引擎bee加密用户自定义key&quot;&gt;2.3.5 模式五：启用双引擎BEE加密（用户自定义Key）&lt;/h5&gt;
&lt;p&gt;　　第五种模式也是高级的安全模式，即用用户自定义Key对image进行双引擎BEE级加密，跟第四种模式（单引擎）原理类似，一般用于对产品安全性要求极高的场合。单引擎BEE加密与双引擎BEE加密具体区别如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;唯一SNVS Key单引擎BEE加密默认使用SNVS Key，芯片出厂已预先烧录，无法更改；用户自定义Key双引擎BEE加密使用的Key是由用户自己设的，需要手动烧录在Fuse SW_GP2和GP4区域。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;唯一SNVS Key单引擎BEE加密只启用了BEE引擎0；用户自定义Key双引擎BEE加密可以同时启用BEE引擎0和引擎1。但需要注意的是无论启动几个BEE引擎，最大加密区域总数均是3个。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;http://i1.bvimg.com/670279/5fe69f5b112d3e34.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　【Secure Boot Type】选择“BEE (Signed) Encrypted XIP Image Boot”，点击【Browse】按钮选择一个原始image文件（必须是XIP在FlexSPI NOR中的image），【Key Storage Region】选择“Flexible User Keys”后点击【Advanced Key Settings】按钮配置所有BEE加密的参数，最后点击【All-In-One Action】按钮即可完成bootable image生成与下载所有操作。&lt;br/&gt;　　有必要对如下使用Flexible User Keys加密的BEE参数设置页面再做一下介绍，首先是选择要激活的BEE引擎，可以单独激活BEE引擎0，也可以单独激活BEE引擎1，当然更可以同时激活BEE引擎0和1，本示例同时激活BEE引擎0和1。指定了BEE引擎后需要进一步为该引擎配置加密所使用的Key的存储空间以及需要用户手动输入Key（128bits）。最后还需要设置加密保护的区域，本示例共使能加密2个区域，分别为0x60001000 - 0x60001fff（由BEE引擎0保护），0x60002000 - 0x60002fff（由BEE引擎1保护）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i1.bvimg.com/670279/d9c2a086f927d343.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　上图中Step5操作主要确认两点：一、BEE_KEY0_SEL是否设置正确（Fuse 0x460[31:0]的bit13,12）和BEE_KEY1_SEL是否设置正确（Fuse 0x460[31:0]的bit15,14）；二、用户Key是否被正确烧录（SW_GP2: Fuse 0x690 - 0x6c0，GP4: Fuse 0x8c0 - 0x8f0）。&lt;br/&gt;　　为了确认image是否按指定区域加密，你可以打开\nxp-sec-boot\gen\bootable_image\文件夹下面生成的未加密bootable image文件与image回读窗口里的内容进行比对。&lt;br/&gt;　　一切操作无误，板子上SW7拨码开关将Boot Mode设为2'b10即Internal Boot模式，并且将BT_CFG[1]设为1'b1（使能Encrypted XIP），其余保持全0，重新上电便可以看到BEE encrypted image正常执行了。&lt;br/&gt;　　双引擎BEE加密是将用户自定义的Key烧录进了Fuse SW_GP2/GP4区域里，但该区域的Fuse内容是可以回读的，如果黑客拿到Key，还是有可能破解存在外部Boot Device里的image密文，有没有对Fuse SW_GP2/GP4区域进行保护的方法？当然有，你可以对指定的Fuse区域进行加锁，可设置Fuse区域访问权限（读保护，写保护，覆盖保护），具体后面有单独章节详细介绍。&lt;br/&gt;　　双引擎BEE加密相比单引擎BEE加密，从破解角度来说难度加倍，毕竟可以启用两组不同的Key来共同保护image不被非法获取。&lt;/p&gt;
&lt;h5 id=&quot;模式六启用hab签名认证与bee加密&quot;&gt;2.3.6 模式六：启用HAB签名认证与BEE加密&lt;/h5&gt;
&lt;p&gt;　　第六种模式是顶级的安全模式，即对image进行HAB签名认证以及BEE级加密（单引擎/双引擎均可），一般用于对产品安全性要求最高的场合。模式四以及模式五均只有加密功能，并没有对image进行合法性检测，引入HAB签名认证可以解决image合法性问题。&lt;/p&gt;
&lt;p&gt;　　【Secure Boot Type】选择“BEE (Signed) Encrypted XIP Image Boot”，【Enable Certificate For BEE Encryption】选择“Yes”并点击【Advanced Cert Settings】按钮配置所有签名认证的参数，点击【Browse】按钮选择一个原始image文件（必须是XIP在FlexSPI NOR中的image），【Key Storage Region】选择“Fixed SNVS Key”或者“Flexible User Keys”均可并点击【Advanced Key Settings】按钮配置所有BEE加密的参数，最后点击【All-In-One Action】按钮即可完成bootable image生成与下载所有操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i1.bvimg.com/670279/f88a276040163bc0.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　一切操作无误，板子上SW7拨码开关将Boot Mode设为2'b10即Internal Boot模式，并且将BT_CFG[1]设为1'b1（使能Encrypted XIP），其余保持全0，重新上电便可以看到BEE encrypted image正常执行了。&lt;br/&gt;　　需要特别注意的是，因为引入了HAB签名认证，如果BEE加密Key选择的是Fixed SNVS Key，需要在HAB Closed的状态下执行上述操作，否则会启动失败，这是HAB与BEE联合使用的限制。&lt;/p&gt;
&lt;h3 id=&quot;软件进阶&quot;&gt;3 软件进阶&lt;/h3&gt;
&lt;p&gt;　　nxpSecBoot软件打开默认工作在Entry Mode下，可通过功能菜单栏Tools-&amp;gt;Option选择进入Master Mode，在Master模式下开放了一些高级功能，适用于对NXP MCU芯片以及Boot ROM非常熟悉的用户。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i1.bvimg.com/670279/271e2830fa0d9615.png&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;玩转fuse操作&quot;&gt;3.1 玩转Fuse操作&lt;/h4&gt;
&lt;p&gt;　　进入Master模式下，可以看到Fuse全部区域都开放了，你可以任意烧写指定的Fuse区域。Fuse操作是按bit一次性的（类似熔丝烧断），只能将0烧写成1，烧录成1之后便无法更改，所以Fuse的操作需要特别谨慎。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i1.bvimg.com/670279/bc5a182eb4bb37bd.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　在上一章节安全加密启动过程中，我们会烧录SRKH(0x580 - 0x5f0)、SW_GP2(0x690 - 0x6c0)、GP4(0x8c0 - 0x8f0)，这些区域一经烧录便不得更改，甚至我们希望这些区域不仅不能被更改，也要不能被回读。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://i1.bvimg.com/670279/65e512e03e8008bd.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　从上图可知Fuse 0x400即是各Fuse功能区域的Locker，我们可以通过烧录Fuse 0x400来锁住SRKH, SW_GP2, GP4区域。那么如何烧录呢？其实非常简单，直接在各Fuse框内填写想要烧录的值，点击【Burn】按钮即可。&lt;/p&gt;
</description>
<pubDate>Fri, 30 Nov 2018 15:03:00 +0000</pubDate>
<dc:creator>痞子衡</dc:creator>
<og:description>nxpSecBoot是一个专为NXP MCU安全加密启动而设计的工具，其特性与NXP MCU里BootROM功能相对应，目前主要支持i.MXRT系列MCU芯片，与NXP官方提供的标准安全加密配套工具集</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/henjay724/p/10047071.html</dc:identifier>
</item>
<item>
<title>防止系统锁屏-python、C++实现 - 朝十晚八</title>
<link>http://www.cnblogs.com/swarmbees/p/10046975.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/swarmbees/p/10046975.html</guid>
<description>&lt;h3 id=&quot;一背景&quot;&gt;一、背景&lt;/h3&gt;
&lt;p&gt;作为一个开发，我的电脑经常是一个礼拜不关机，甚至时间更久，不知道在其他人看来这是不是一个常规操作。在日常工作中，我们的电脑也是一直处于非锁屏状态，出于对个人工作成果的安全性保护，我们公司给每个人的电脑上下发了一个组策略(属于强制下发，抗议无效)，&lt;strong&gt;5min不对电脑进行操作，电脑就锁屏&lt;/strong&gt;，这可真是令人操蛋，出去上个厕所的功夫电脑就锁屏啦、和别人讨论问题的功夫电脑又锁屏了，作为一个开发，这真不能忍。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;最近一直在学习&lt;code&gt;python&lt;/code&gt;，刚好接触到了&lt;code&gt;python&lt;/code&gt;写&lt;code&gt;windows&lt;/code&gt;服务相关的一些东西，嘿嘿，5分钟不操作电脑锁屏是吧，那么我们在无任何操作下2分钟给他模拟一次键盘或者鼠标操作可好。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;二模拟鼠标键盘事件&quot;&gt;二、模拟鼠标、键盘事件&lt;/h3&gt;
&lt;p&gt;要写一个&lt;code&gt;windows&lt;/code&gt;服务也是比较简单的，只需要继承自win32serviceutil.ServiceFramework这个类，然后实现相关方法即可，主要的方法是SvcDoRun，服务启动后，该方法处于激活状态，该方法结束服务退出&lt;/p&gt;
&lt;blockquote readability=&quot;3.5187969924812&quot;&gt;
&lt;p&gt;具体的实现方式可参考&lt;a href=&quot;https://www.cnblogs.com/swarmbees/p/10035127.html&quot;&gt;Python-定时爬取指定城市天气(二)-邮件提醒&lt;/a&gt;文章中的第三小节，优化定时任务。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;python实现&quot;&gt;1、&lt;code&gt;python&lt;/code&gt;实现&lt;/h4&gt;
&lt;blockquote readability=&quot;3.8145695364238&quot;&gt;
&lt;p&gt;这里我只贴出关键代码，服务的整体框架不在细说，不会的同学请看这里&lt;a href=&quot;https://www.cnblogs.com/swarmbees/p/10035127.html&quot;&gt;Python-定时爬取指定城市天气(二)-邮件提醒&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;apython服务&quot;&gt;a、&lt;code&gt;python&lt;/code&gt;服务&lt;/h5&gt;
&lt;p&gt;首先判断鼠标2分钟内是否有操作，我们需要能获取到当前鼠标位置的函数，&lt;code&gt;pyautogui&lt;/code&gt;是一个&lt;code&gt;python&lt;/code&gt;的自动化库，满足我们的需求，该库提供了丰富的鼠标、键盘操作，使用该库，首先就得使用pip进行安装&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;pip install pyautogui&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;使用方式如下，x和y即是当前鼠标相对于屏幕左上角(0,0)的坐标&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;import pyautogui as pag
x, y = pag.position() #返回鼠标的坐标&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;模拟鼠标、键盘操作，无非是鼠标点击、移动、键盘按下等，这些&lt;code&gt;pyautogui&lt;/code&gt;都已经提供，看名字就知道什么意思，这里我们先进行了鼠标点击，默认是左键，然后移动了鼠标位置，并且在最后按下了键盘上的esc键&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;pag.click()
pag.moveTo(x + 10, y + 10, 0.1)
pag.moveTo(x, y, 0.1)
writeLog('模拟一次鼠标移动\n')#

pag.press('esc')
writeLog('模拟点击esc\n')#&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;完整的SvcDoRUn函数如下&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;def SvcDoRun(self):
    #what to do#
    prev_time = datetime.datetime.now()
    oldx = 0
    oldy = 0
    while self.run:
        x, y = pag.position() #返回鼠标的坐标
        now_time = datetime.datetime.now()

        if x == oldx and y == oldy:
            stay_seconds = (now_time -  prev_time).seconds
            if stay_seconds &amp;gt;= 60:
                prev_time = now_time
                pag.click()
                pag.moveTo(x + 10, y + 10, 0.1)
                pag.moveTo(x, y, 0.1)
                writeLog('模拟一次鼠标移动\n')#

                pag.press('esc')
                writeLog('模拟点击esc\n')#
        else:
            #更新旧坐标 最后一次移动鼠标时间
            oldx = x
            oldy = y
            prev_time = now_time
            #os.system('cls')#清楚屏幕

        stay_seconds = (now_time -  prev_time).seconds
        writeLog('鼠标{}秒未移动\n'.format(stay_seconds))#打印坐标

        posStr = &quot;Position:&quot; + str(x).rjust(4) + ',' + str(y).rjust(4)
        writeLog(posStr + '\n')#打印坐标

        time.sleep(2)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;服务函数写完了，接下来是打包服务的过程，并启动服务&lt;/p&gt;
&lt;pre class=&quot;pyhon&quot;&gt;
&lt;code&gt;1. 打包服务成一个exe，pyinstaller -F  aaa.py
2. 安装服务 python aaa.exe install
3. 启动服务 python aaa.exe start 
4. 停止服务 python aaa.exe stop
5. 移除服务 python aaa.exe remove&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行上述流程的1、2和3，服务就已经被成功启动，但不幸的是发现&lt;code&gt;pag.position()&lt;/code&gt;返回的坐标一直是0，各种测试都不对，开始怀疑是服务里可能找不到&lt;code&gt;pyautogui&lt;/code&gt;资源导致失败，后来在网上找了另一种或许鼠标位置的函数&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;def get_mouse_point():
   po = POINT()
   windll.user32.GetCursorPos(byref(po))
   return int(po.x), int(po.y)&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;经过测试，该函数单独运行时没有问题，放在服务里拿到的坐标还是(0, 0)，写服务的路子算是泡汤啦&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为了更好的查找服务的运行状态，我们这里把服务的运行时状态卸载了一个文件里，写日志代码如下&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;#写日志
def writeLog(msg):
    try:
        f = open('./prevent_lock_screen.log', 'a', encoding = 'utf-8')
        f.write(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S') + '：' + msg)
        f.close()
    except BaseException:
        pass&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;bpython函数&quot;&gt;b、&lt;code&gt;python&lt;/code&gt;函数&lt;/h5&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;code&gt;python&lt;/code&gt;服务的方式暂时算是中断了，但是我们还是不能放弃啊，经过尝试，&lt;strong&gt;把运行在服务里的代码拿出来放在正常&lt;code&gt;python&lt;/code&gt;文件里执行还是好使的&lt;/strong&gt;。不明所以啊，&lt;strong&gt;++哪位大神如果知道服务里的代码为什么运行失败，还请评论区支出，不胜感激。。。++&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;为了防止电脑自动锁屏，要一直运行一个&lt;code&gt;dos&lt;/code&gt;窗口看起来确实挺扯的，初学&lt;code&gt;python&lt;/code&gt;可能好多东西还是不懂，因此为了让这个需求更优雅一些，我拿起了&lt;code&gt;C++&lt;/code&gt;，我们还是先来写一个服务吧&lt;/p&gt;
&lt;h4 id=&quot;c实现&quot;&gt;2、&lt;code&gt;C++&lt;/code&gt;实现&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;为了实现这个需求，我也真是拼了&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;ac服务&quot;&gt;a、&lt;code&gt;C++&lt;/code&gt;服务&lt;/h5&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;不得不说，&lt;code&gt;C++&lt;/code&gt;写服务还是挺费劲的，在网上扒了一个服务的模子，我便开始写了，其实最主要的还是要实现服务中的死循环函数，代码逻辑和上述&lt;code&gt;python&lt;/code&gt;的思路一起，区别就是我们需要使用&lt;code&gt;C++&lt;/code&gt;的语法实现一遍而已。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&quot;cpp&quot;&gt;
&lt;code&gt;    POINT p;
    GetCursorPos(&amp;amp;p);//获取鼠标坐标
    int x = p.x, y = p.y;//返回鼠标的坐标
    time_t now_time = time(NULL);

    if (x == oldx &amp;amp;&amp;amp; y == oldy)
    {
        int stay_seconds = int(now_time - prev_time);
        if (stay_seconds &amp;gt;= 6)
        {
            prev_time = now_time;
            SetCursorPos(x + 10, y + 10);
            SetCursorPos(x, y);
            WriteToLog(&quot;模拟一次鼠标移动&quot;);

            mouse_event(MOUSEEVENTF_LEFTDOWN | MOUSEEVENTF_LEFTUP, x, y, 0, 0);
            WriteToLog(&quot;模拟鼠标单击&quot;);

            keybd_event('esc', 0, 0, 0);
            keybd_event('a', 0, 0, 0);
            WriteToLog(&quot;模拟点击esc&quot;);
        }
    }
    else
    {
        //更新旧坐标 最后一次移动鼠标时间
        oldx = x;
        oldy = y;
        prev_time = now_time;
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来的操作就是我们需要把写好的服务安装并启动&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;1. sc create test binPath= 可执行文件的路径
2. net start test
3. net stop test
4. net delete test&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;执行上述步骤1和2即可启动服务&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;经过测试，太不幸了，&lt;code&gt;GetCursorPos(&amp;amp;p)&lt;/code&gt;返回的坐标也为(0, 0)，这下真是郁闷了，服务这条路难道真的走不通了吗？看到的大神有解决思路的还请在评论区支出，不胜感激。。。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h5 id=&quot;bc可执行程序&quot;&gt;b、&lt;code&gt;C++&lt;/code&gt;可执行程序&lt;/h5&gt;
&lt;p&gt;照搬照抄上述&lt;code&gt;python&lt;/code&gt;服务转可执行程序的逻辑，我们把&lt;code&gt;C++&lt;/code&gt;服务里的代码拿出来，放到 &lt;code&gt;C++&lt;/code&gt;可执行程序中，我们也可以实现一个&lt;code&gt;C++&lt;/code&gt;可执行程序&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;进过测试，以上&lt;code&gt;python&lt;/code&gt;程序和&lt;code&gt;C++&lt;/code&gt;程序都还有一些问题，在一些特定的窗口上模拟鼠标、键盘操作不好使，比如&lt;code&gt;notepad ++&lt;/code&gt;、windows任务管理器等，系统在5分钟后还是锁屏，思前想后，觉着这个可能和程序权限有关系，&lt;strong&gt;随即把&lt;code&gt;C++&lt;/code&gt;工程的属性进行了调整，生成的exe需要带有管理员权限，在次进行测试，结果是完美的&lt;/strong&gt;，我们终于可以防止系统自动锁屏了，执行上述python的程序这里就不做权限升级研究了，有兴趣的同学自行研究&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;c++&lt;/code&gt;程序我们可以通过设置来吧程序设置成后台运行的，没有任何界面，这样显得更优雅一些，首先我们创建的是一个dos程序，设置设置两个地方即可&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;连接器-&amp;gt;系统：子系统设置成窗口 (/SUBSYSTEM:WINDOWS)&lt;/li&gt;
&lt;li&gt;连接器-&amp;gt;高级：入口点设置成mainCRTStartup&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;三优化&quot;&gt;三、优化&lt;/h3&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;最开始的模拟用户操作，我们使用的是点击鼠标左键、移动鼠标、和模拟点击esc按键，但是上述操作都会不懂程度的带来一些影响。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;如果用户正在看视频，没有进行键鼠操作，这个时候如果点击鼠标左键，可能会导致视频暂停，不是用户期望的操作&lt;/li&gt;
&lt;li&gt;如果用户打开了一个弹框，例如顶层窗口是一个esc快捷键可以关闭的程序，这个时候如果用户2分钟没有操作电脑，那么模拟的esc按键将会把用户的原始状态打乱&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;模拟操作优化过程&lt;/p&gt;
&lt;h4 id=&quot;wind&quot;&gt;1、win+d&lt;/h4&gt;
&lt;p&gt;切换到桌面，随即在开切换回来，这个操作相对来说比较靠谱，但是如果有一个窗口上有模态窗口存在，也会对打乱原始的窗口顺序&lt;/p&gt;
&lt;h4 id=&quot;win键&quot;&gt;2、win键&lt;/h4&gt;
&lt;p&gt;点击&lt;code&gt;windows&lt;/code&gt;键，随即在点击一次，恢复到点击之前的状态，这个操作相对第一种还是比较友好的&lt;/p&gt;
&lt;h4 id=&quot;切换大小写&quot;&gt;3、切换大小写&lt;/h4&gt;
&lt;p&gt;点击CapsLk按键，进行大小写切换，由于这个时候用户没有操作电脑，因此切换大小写不会对用户操作进行干扰，而且动静更小、更优雅&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;上述3中模拟操作行为基本思路都是一样的，只是模拟的方式所有不同，下边我们就以第三种方式讲解实现过程&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;点击CapsLk的操作分两部分，第一次主要是为了模拟用户点击，第二次是为了恢复第一次操作留下的痕迹，为了让程序更优雅的运行，我们这里需要启动子线程来恢复主线程留下的痕迹&lt;br/&gt;main函数代码如下&lt;/p&gt;
&lt;pre class=&quot;cpp&quot;&gt;
&lt;code&gt;hMutex = CreateMutex(NULL, FALSE, (LPCWSTR)&quot;PreventLockScreenApp&quot;);
WaitForSingleObject(hMutex, INFINITE);

HANDLE hThread = CreateThread(NULL, 0, RestoreWinState, NULL, 0, NULL);     //创建线程01
CloseHandle(hThread); //关闭句柄

remove(LOGFILE);
time_t prev_time = time(NULL);//
int oldx = 0;
int oldy = 0;
char positionText[100] = { 0 };
sprintf(positionText, &quot;防锁屏进程已启动，程序将在无鼠标移动情况下每隔%d秒模拟一次键盘操作&quot;, Job_TIME);
WriteToLog(positionText);
while (1)
{
    POINT p;
    GetCursorPos(&amp;amp;p);//获取鼠标坐标
    int x = p.x, y = p.y;//返回鼠标的坐标
    time_t now_time = time(NULL);

    if (x == oldx &amp;amp;&amp;amp; y == oldy)
    {
        int stay_seconds = int(now_time - prev_time);
        if (stay_seconds &amp;gt;= Job_TIME)
        {
            prev_time = now_time;

            keybd_event(VK_CAPITAL, (BYTE)0, 0, 0);
            keybd_event(VK_CAPITAL, (BYTE)0, KEYEVENTF_KEYUP, 0);
            WriteToLog(&quot;模拟点击CapsLk，切换大小写&quot;);

            //释放锁 让子线程去恢复win键状态
            ReleaseMutex(hMutex);
            Sleep(Restore_TIME / 2);
            WaitForSingleObject(hMutex, INFINITE);
        }
    }
    else
    {
        //更新旧坐标 最后一次移动鼠标时间
        oldx = x;
        oldy = y;
        prev_time = now_time;
    }

    int stay_seconds = int(now_time - prev_time);

    char mousemoved[100] = { 0 };
    sprintf(mousemoved, &quot;鼠标%d秒未移动&quot;, stay_seconds);
    WriteToLog(mousemoved);//打印坐标

    char positionText[100] = { 0 };
    sprintf(positionText, &quot;当前鼠标位置(%d,%d)&quot;, x, y);
    WriteToLog(positionText);//打印坐标

    Sleep(SLEEP_TIME);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;子线程代码如下&lt;/p&gt;
&lt;pre class=&quot;cpp&quot;&gt;
&lt;code&gt;void SimulationBehavior()
{
    keybd_event(VK_CAPITAL, (BYTE)0, 0, 0);
    keybd_event(VK_CAPITAL, (BYTE)0, KEYEVENTF_KEYUP, 0);
}

DWORD WINAPI RestoreWinState(LPVOID lvParamter)
{
    while (true)
    {
        WaitForSingleObject(hMutex, INFINITE);

        Sleep(Restore_TIME);
        SimulationBehavior();

        ReleaseMutex(hMutex);
    }

    return 0;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;主子线程使用一个全局的信号量来进行同步&lt;/p&gt;
&lt;h3 id=&quot;四demo下载&quot;&gt;四、demo下载&lt;/h3&gt;
&lt;p&gt;需要&lt;code&gt;C++&lt;/code&gt;和&lt;code&gt;python&lt;/code&gt;代码的同学到&lt;code&gt;csdn&lt;/code&gt;下载：&lt;a href=&quot;https://download.csdn.net/download/qq_30392343/10820441&quot;&gt;C++实现的防锁屏后台进程-内含python实现代码&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;博客园地址：&lt;a href=&quot;https://www.cnblogs.com/swarmbees/p/10046975.html&quot;&gt;防止系统锁屏-python、C++实现&lt;/a&gt;&lt;/strong&gt;&lt;br/&gt;&lt;strong&gt;简书地址：&lt;a href=&quot;https://www.jianshu.com/p/0e85e8943347&quot;&gt;防止系统锁屏-python、C++实现&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;strong&gt;转载声明：本站文章无特别说明，皆为原创，版权所有，转载请注明：&lt;a href=&quot;https://www.cnblogs.com/swarmbees/&quot;&gt;朝十晚八&lt;/a&gt; or &lt;a href=&quot;https://www.jianshu.com/u/7673f8cfb4e6&quot;&gt;Twowords&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;hr/&gt;</description>
<pubDate>Fri, 30 Nov 2018 14:57:00 +0000</pubDate>
<dc:creator>朝十晚八</dc:creator>
<og:description>一、背景 作为一个开发，我的电脑经常是一个礼拜不关机，甚至时间更久，不知道在其他人看来这是不是一个常规操作。在日常工作中，我们的电脑也是一直处于非锁屏状态，出于对个人工作成果的安全性保护，我们公司给每</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/swarmbees/p/10046975.html</dc:identifier>
</item>
<item>
<title>你真的了解 i++, ++i 和 i+++++i 以及 i+++i++ 吗？ - 帅地</title>
<link>http://www.cnblogs.com/kubidemanong/p/10047041.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/kubidemanong/p/10047041.html</guid>
<description>&lt;p&gt;我想大部分都知道 i++ 和 ++i的区别，i++ 就是先拿i来使用，之后再自增加1，而++i则是先自增加1，在拿i来使用，例如对于下面这两个语句，我敢保证大部分人都会做：&lt;/p&gt;

&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
int i = 1;
System.out.println(i++)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
int i = 1;
System.out.println(++1)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;答案分别为 1,2。对于这个答案我猜大多数人都能答出来。不过 i++ 和 ++i 这两个操作，在内部是如何实现的呢？&lt;/p&gt;

&lt;p&gt;我们先来看另外一个问题：&lt;/p&gt;

&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
public static void main(String[] args) {
   int i = 1;
   System.out.println(i+++i++);
   System.out.println(i);
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这个比刚才那个难了点，答案分别是3，3。假如你对这个答案的由来了如指掌，那么你大不可必往下看，假如你不大理解或者想从底层的汇编指令的来了解这个操作，那么你可以看看我的解释。&lt;/p&gt;

&lt;p&gt;首先我们先来看看 i++ 的题，主要是为了后面好解释点。&lt;/p&gt;

&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
int i = 1;
System.out.println(i++);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这两行代码的部分汇编指令如下，注意，我只列出了几个重点的汇编语句：&lt;/p&gt;

&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
ICONST_1 //把常量 1 加载到栈顶
ISTORE 1 //把栈顶的元素弹出，并赋值给局部变量表中位置为“1”的变量，此时指变量i。这两句就相当于 int i = 1;

//接下来执行第二行代码
ILOAD 1  //把局部变量表中位置为“1”的变量加载到栈顶，即把i的值加载到栈顶
IINC 1 1  //直接把局部变量表中位置为“1”的变量加1，即把 i 加1。注意，这条指令并没有修改操作数栈就把 i 加1了。
INVOKEVIRTUAL java/io/PrintStream.println (I)V  //把栈顶的元素打印出来，此时栈顶的元素是 1。所以打印的是 1
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;注：可以左右拉动&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;所以，此时打印的是1。&lt;/p&gt;

&lt;p&gt;有些人可能没弄过汇编会有点蒙蔽，没事，我花个时间画个图来模拟(注：省略很多细节)。&lt;/p&gt;

&lt;p&gt;刚开始时的局部变量表和操作数栈如图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFNSPe670IBhia4vIe0hxoiaMmYqIANLicic8n8pRnqBDSAgsKJuXrfOPS6Q/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.6310272536687631&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFNSPe670IBhia4vIe0hxoiaMmYqIANLicic8n8pRnqBDSAgsKJuXrfOPS6Q/640&quot; data-type=&quot;png&quot; data-w=&quot;477&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;1、执行  ICONST_1，常量 1 进栈&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFaMBnRVOHe6Zwhrs20CzD712e48GGAesQFRsVxCYtiasNep3bDCS85Hw/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.6012024048096193&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFaMBnRVOHe6Zwhrs20CzD712e48GGAesQFRsVxCYtiasNep3bDCS85Hw/640&quot; data-type=&quot;png&quot; data-w=&quot;499&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;2、执行 ISTORE 1，栈顶元素出栈存到位置“1”&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFUvSEWlzymia54Kicw06MIexkz77HHYc69oM8j82LKd2N8pFzXktv2Fpg/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.6115879828326181&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFUvSEWlzymia54Kicw06MIexkz77HHYc69oM8j82LKd2N8pFzXktv2Fpg/640&quot; data-type=&quot;png&quot; data-w=&quot;466&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;3、执行  ILOAD 1，把位置“1”的变量值存到栈顶&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFaBvzF5tm4UUdEhyDWA2IH8ibxJ3avwloYte3FcMx30kMBTSNTliaz86Q/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.5971370143149284&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFaBvzF5tm4UUdEhyDWA2IH8ibxJ3avwloYte3FcMx30kMBTSNTliaz86Q/640&quot; data-type=&quot;png&quot; data-w=&quot;489&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;4、执行 IINC 1 1 ，直接把局部变量表中位置为“1”的变量加 1&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFYGtQMZTKjE8MiaE2fJTubaUSzicoWPQlyDDicG6yRKLOV6bBBqSMKIFLQ/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.7371794871794872&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFYGtQMZTKjE8MiaE2fJTubaUSzicoWPQlyDDicG6yRKLOV6bBBqSMKIFLQ/640&quot; data-type=&quot;png&quot; data-w=&quot;468&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;5、执行 INVOKEVIRTUAL java/io/PrintStream.println (I)V  ，把栈顶的元素打印出来，此时栈顶的元素是 1.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFFcNNu5WX7KglvVzibShicibRGMQd8qp9GfhTv7ut8oa6Gll65jJPw4obA/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.6277533039647577&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFFcNNu5WX7KglvVzibShicibRGMQd8qp9GfhTv7ut8oa6Gll65jJPw4obA/640&quot; data-type=&quot;png&quot; data-w=&quot;454&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;所以虽然i已经等于2了，但此时栈顶的元素却是i之前的值 1 ，所以打印的是1。&lt;/p&gt;
&lt;p&gt;这下关于 i ++ 的懂了吧？&lt;/p&gt;

&lt;p&gt;那我们来看看 ++ i 与  i ++  的汇编指令有什么不同。&lt;/p&gt;

&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
int i = 1;
System.out.println(++i);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;对应的部分重点汇编指令如下：&lt;/p&gt;

&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
//和上面i++差不多，不过IINC 1 1 和ILOAD 1这两句的顺序调换了。
ICONST_1
ISTORE 1
IINC 1 1 //直接把局部变量表中位置为“1”的变量加1
ILOAD 1  //把位置“1”的变量压到栈顶，此时栈顶的元素是 2
INVOKEVIRTUAL java/io/PrintStream.println (I)V //所以打印的是2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;再画下图演示一下：&lt;/p&gt;

&lt;p&gt;1、执行了ICONST_1 和ISTORE 1这两句过后的局部变量和栈的情况如下&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFJNEdRSYQPdrDAdxnIeganYsThQDq96WUWYaNwBibvdznmb5SGzGLicEw/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.6651982378854625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFJNEdRSYQPdrDAdxnIeganYsThQDq96WUWYaNwBibvdznmb5SGzGLicEw/640&quot; data-type=&quot;png&quot; data-w=&quot;454&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;2、执行 IINC 1 1。注意，执行这条指令，操作数栈不会发生变化。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFEXrrj0liaBtTaUFDDZ80tZh1iafHVtZLJGyHr08SAOSDwSXzleqleMQA/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.6306122448979592&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFEXrrj0liaBtTaUFDDZ80tZh1iafHVtZLJGyHr08SAOSDwSXzleqleMQA/640&quot; data-type=&quot;png&quot; data-w=&quot;490&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;3、执行 ILOAD 1，把位置“1”的变量值压入栈顶&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFduhiafMl3riaNdc577fxIbe2Rdgiahz8Pw9Xiafyn5NsK7VWwGmeucY5qQ/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.6428571428571429&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFduhiafMl3riaNdc577fxIbe2Rdgiahz8Pw9Xiafyn5NsK7VWwGmeucY5qQ/640&quot; data-type=&quot;png&quot; data-w=&quot;476&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;4、执行 INVOKEVIRTUAL java/io/PrintStream.println (I)V  ，把栈顶的元素打印出来，此时栈顶的元素是 2&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFuXaGYNQCAod58nTNEIOCicsiaqGzCPqH2aUWgTnNjiczOGzv5ickmHNacg/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.6593406593406593&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFuXaGYNQCAod58nTNEIOCicsiaqGzCPqH2aUWgTnNjiczOGzv5ickmHNacg/640&quot; data-type=&quot;png&quot; data-w=&quot;455&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;所以，对于 i++ 和 ++i的区别彻底懂了吧。&lt;/p&gt;

&lt;p&gt;接下来我们来分析这个程序&lt;/p&gt;

&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
int i = 1;
System.out.println(i+++i++);
System.out.println(i);
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这里先说一下，按照运算符号的优先顺序，i+++i++等价于 (i++) + (i++)。&lt;/p&gt;

&lt;p&gt;对应的部分汇编指令如下：&lt;/p&gt;

&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
//第一行
ICONST_1
ISTORE 1
//第二行
ILOAD 1
IINC 1 1
ILOAD 1
IINC 1 1
IADD  //把栈顶的两个元素弹出相加之后在把结果放回栈顶
INVOKEVIRTUAL java/io/PrintStream.println (I)V
//第三行
ILOAD 1
INVOKEVIRTUAL java/io/PrintStream.println (I)V
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;如果上面的那两个 i++ 和 ++i你看懂了，那么上面那个汇编应该也差不多能看懂。我用图来逐条分析一下吧。&lt;/p&gt;

&lt;p&gt;1、执行了 ICONST_1 和ISTORE 1之后的状态如下&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFJNEdRSYQPdrDAdxnIeganYsThQDq96WUWYaNwBibvdznmb5SGzGLicEw/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.6651982378854625&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFJNEdRSYQPdrDAdxnIeganYsThQDq96WUWYaNwBibvdznmb5SGzGLicEw/640&quot; data-type=&quot;png&quot; data-w=&quot;454&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;2、执行 ILOAD 1&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTF9tcp389IrrAPYLibia8AlkydVHBsKHxxQzGkznIDKFpGccZcG7OibvGXQ/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.6545842217484008&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTF9tcp389IrrAPYLibia8AlkydVHBsKHxxQzGkznIDKFpGccZcG7OibvGXQ/640&quot; data-type=&quot;png&quot; data-w=&quot;469&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;3、执行 IINC 1 1&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFtONKLCBRK0qo1icjcWqiaTQoEosxWrbZTY1fgwB4kX4T6ZLTFajuzhWg/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.6471816283924844&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFtONKLCBRK0qo1icjcWqiaTQoEosxWrbZTY1fgwB4kX4T6ZLTFajuzhWg/640&quot; data-type=&quot;png&quot; data-w=&quot;479&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;4、执行  ILOAD 1&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTF9735icWzsJa6JVcWQUqzibTa7d1qKIaBlibVapBxMaj1g6cEa5ibNv4qoA/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.671201814058957&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTF9735icWzsJa6JVcWQUqzibTa7d1qKIaBlibVapBxMaj1g6cEa5ibNv4qoA/640&quot; data-type=&quot;png&quot; data-w=&quot;441&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;5、执行 IINC  1 1。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFW4lmFWwWCWSjiay7WdML6KkzjoKJnBbVEk8hic4dtPWhQUfrLgcojs6g/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.5853658536585366&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFW4lmFWwWCWSjiay7WdML6KkzjoKJnBbVEk8hic4dtPWhQUfrLgcojs6g/640&quot; data-type=&quot;png&quot; data-w=&quot;492&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;此时实际上 i 的值已经是 3 了，只是栈顶放的都是 i 的旧值。&lt;/p&gt;

&lt;p&gt;6、执行 IADD ，把栈顶两个元素出栈相加后再把结果入栈&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFIDMouJQ8AOT9jIbCu5Rk8Q9JpY3XFOgE22s5G3MxRv9ftqjtLhAibSw/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.698237885462555&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFIDMouJQ8AOT9jIbCu5Rk8Q9JpY3XFOgE22s5G3MxRv9ftqjtLhAibSw/640&quot; data-type=&quot;png&quot; data-w=&quot;454&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;7、执行INVOKEVIRTUAL java/io/PrintStream.println (I)V，此时栈顶元素为3，所以打印的是3&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFbe4Bp09icB7iahDCwIiarv97gfGibcqkgUr6IeNYR3Fc3wBSqV6DNBk9Xg/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.6153846153846154&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFbe4Bp09icB7iahDCwIiarv97gfGibcqkgUr6IeNYR3Fc3wBSqV6DNBk9Xg/640&quot; data-type=&quot;png&quot; data-w=&quot;481&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;8、执行  ILOAD 1，把局部变量表加载到栈顶&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFPMjZqRo95rqmfNB7gXhuDZr1AD3jricV4IqODosnic26BUjKPT6dA9YA/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.6583710407239819&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTFPMjZqRo95rqmfNB7gXhuDZr1AD3jricV4IqODosnic26BUjKPT6dA9YA/640&quot; data-type=&quot;png&quot; data-w=&quot;442&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;9、执行INVOKEVIRTUAL java/io/PrintStream.println (I)V，此时栈顶元素为3，所以打印的是3&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTF3N5icexSh4ZWW6RxibqGqny8wSb0f1knr8JNQlw7RxI924BJYHeFsdwA/640?tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&amp;amp;retryload=1&quot; alt=&quot;&quot; data-ratio=&quot;0.665929203539823&quot; data-s=&quot;300,640&quot; data-src=&quot;https://mmbiz.qpic.cn/mmbiz_png/gsQM61GSzIPYPkoctzrzJ7k1q8ZvfxTF3N5icexSh4ZWW6RxibqGqny8wSb0f1knr8JNQlw7RxI924BJYHeFsdwA/640&quot; data-type=&quot;png&quot; data-w=&quot;452&quot; data-fail=&quot;0&quot;/&gt;&lt;/p&gt;

&lt;p&gt;完毕&lt;/p&gt;

&lt;p&gt;现在知道了把，对于 i+++++i 的题也知道怎么做以及怎么回事了吧。&lt;/p&gt;

&lt;p&gt;这篇文章重点让你理解 i++ 与 ++ i的实现机制，对于上面的汇编指令以及进栈入栈的过程为了更好着说明要解决的问题，所以隐藏了很多细节，而且也删除了部分代码。如有错误的地方，还请见谅。&lt;/p&gt;

&lt;p&gt;如果你想了解更多的汇编指令，我这里看到一篇总结的还挺全的：https://blog.csdn.net/hudashi/article/details/7062675&lt;/p&gt;

&lt;p&gt;更多精彩文章可以关注我的公众号：&lt;strong&gt;苦逼的码农(ID:di201805)&lt;/strong&gt;，该公众号每周还会以&lt;strong&gt;专题的模式更新算法题&lt;/strong&gt;，期待你的关注&lt;/p&gt;
&lt;p&gt;推荐阅读：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzUxNzg0MDc1Mg==&amp;amp;mid=2247484791&amp;amp;idx=1&amp;amp;sn=555ecf7315a549de05555e5009678c8b&amp;amp;chksm=f9934f68cee4c67eeecd09a63f7212971fcb3e14eaa132c46b033085f562e5051e5a7300ef14&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;【算法实战】生成窗口最大值数组&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzUxNzg0MDc1Mg==&amp;amp;mid=2247484741&amp;amp;idx=1&amp;amp;sn=7c18cbb8ab38a57848640bd8397e451d&amp;amp;chksm=f9934f5acee4c64cfe9a8ef5da90cac3925a09290eeecbf194a126b0acab6e2af76deb5da42f&amp;amp;scene=21#wechat_redirect&quot; target=&quot;_blank&quot;&gt;谈谈NAT：什么？全球IP和私有IP是什么鬼？&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1122091/201811/1122091-20181130225238231-656884127.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

</description>
<pubDate>Fri, 30 Nov 2018 14:56:00 +0000</pubDate>
<dc:creator>帅地</dc:creator>
<og:description>我想大部分都知道 i++ 和 ++i的区别，i++ 就是先拿i来使用，之后再自增加1，而++i则是先自增加1，在拿i来使用，例如对于下面这两个语句，我敢保证大部分人都会做： 答案分别为 1,2。对于这</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/kubidemanong/p/10047041.html</dc:identifier>
</item>
<item>
<title>ffmpeg简易播放器的实现-完善版 - 叶余</title>
<link>http://www.cnblogs.com/leisure_chn/p/10047035.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/leisure_chn/p/10047035.html</guid>
<description>&lt;p&gt;实验平台：openSUSE Leap 42.3&lt;br/&gt;FFmpeg版本：4.1&lt;br/&gt;SDL版本：2.0.9&lt;/p&gt;
&lt;p&gt;基于FFmpeg和SDL实现的简易视频播放器，主要分为读取视频文件解码和调用SDL显示两大部分。详细流程可参考代码注释。&lt;br/&gt;本篇实验笔记主要参考如下两篇文章：&lt;br/&gt;[1]. &lt;a href=&quot;https://blog.csdn.net/leixiaohua1020/article/details/38868499&quot;&gt;最简单的基于FFMPEG+SDL的视频播放器ver2(采用SDL2.0)&lt;/a&gt;&lt;br/&gt;[2]. &lt;a href=&quot;https://blog.csdn.net/leixiaohua1020/article/details/38868499&quot;&gt;An ffmpeg and SDL Tutorial&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;播放器基本原理&quot;&gt;1. 播放器基本原理&lt;/h2&gt;
&lt;p&gt;下图及解释内容引用自“&lt;a href=&quot;https://blog.csdn.net/leixiaohua1020/article/details/18893769&quot;&gt;雷霄骅，视音频编解码技术零基础学习方法&lt;/a&gt;”，&lt;br/&gt;因原图太小，看不太清楚，故重新制作了一张图片。&lt;br/&gt;&lt;img src=&quot;https://leihl.github.io/img/ffmpeg_player/01_player_flow.jpg&quot; title=&quot;播放器基本原理示意图&quot; alt=&quot;播放器基本原理示意图&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;21&quot;&gt;
&lt;p&gt;&lt;strong&gt;解协议&lt;/strong&gt;&lt;br/&gt;将流媒体协议的数据，解析为标准的相应的封装格式数据。视音频在网络上传播的时候，常常采用各种流媒体协议，&lt;br/&gt;例如HTTP，RTMP，或是MMS等等。这些协议在传输视音频数据的同时，也会传输一些信令数据。这些信令数据包括&lt;br/&gt;对播放的控制（播放，暂停，停止），或者对网络状态的描述等。解协议的过程中会去除掉信令数据而只保留视音&lt;br/&gt;频数据。例如，采用RTMP协议传输的数据，经过解协议操作后，输出FLV格式的数据。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解封装&lt;/strong&gt;&lt;br/&gt;将输入的封装格式的数据，分离成为音频流压缩编码数据和视频流压缩编码数据。封装格式种类很多，例如MP4，&lt;br/&gt;MKV，RMVB，TS，FLV，AVI等等，它的作用就是将已经压缩编码的视频数据和音频数据按照一定的格式放到一起。&lt;br/&gt;例如，FLV格式的数据，经过解封装操作后，输出H.264编码的视频码流和AAC编码的音频码流。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解码&lt;/strong&gt;&lt;br/&gt;将视频/音频压缩编码数据，解码成为非压缩的视频/音频原始数据。音频的压缩编码标准包含AAC，MP3，AC-3等等，&lt;br/&gt;视频的压缩编码标准则包含H.264，MPEG2，VC-1等等。解码是整个系统中最重要也是最复杂的一个环节。通过解码，&lt;br/&gt;压缩编码的视频数据输出成为非压缩的颜色数据，例如YUV420P，RGB等等；压缩编码的音频数据输出成为非压缩的&lt;br/&gt;音频抽样数据，例如PCM数据。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;视音频同步&lt;/strong&gt;&lt;br/&gt;根据解封装模块处理过程中获取到的参数信息，同步解码出来的视频和音频数据，并将视频音频数据送至系统的显&lt;br/&gt;卡和声卡播放出来。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;源码清单&quot;&gt;2. 源码清单&lt;/h2&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;/*******************************************************************************
 * ffplayer.c
 *
 * history:
 *   2018-11-27 - [lei]     Create file: a simplest ffmpeg player
 *   2018-11-29 - [lei]     Refresh decoding thread with SDL event 
 *
 * details:
 *   A simple ffmpeg player.
 *
 * refrence:
 *   1. https://blog.csdn.net/leixiaohua1020/article/details/38868499
 *   2. http://dranger.com/ffmpeg/ffmpegtutorial_all.html#tutorial01.html
 *   3. http://dranger.com/ffmpeg/ffmpegtutorial_all.html#tutorial02.html
*******************************************************************************/

#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdbool.h&amp;gt;
#include &amp;lt;libavcodec/avcodec.h&amp;gt;
#include &amp;lt;libavformat/avformat.h&amp;gt;
#include &amp;lt;libswscale/swscale.h&amp;gt;
#include &amp;lt;SDL2/SDL.h&amp;gt;
#include &amp;lt;SDL2/SDL_video.h&amp;gt;
#include &amp;lt;SDL2/SDL_render.h&amp;gt;
#include &amp;lt;SDL2/SDL_rect.h&amp;gt;

#define SDL_USEREVENT_REFRESH  (SDL_USEREVENT + 1)

static bool s_playing_exit = false;
static bool s_playing_pause = false;

// 每40ms发送一个解码刷新事件，使解码器以25FPS的帧率工作
int sdl_thread_handle_refreshing(void *opaque)
{
    SDL_Event sdl_event;

    while (!s_playing_exit)
    {
        if (!s_playing_pause)
        {
            sdl_event.type = SDL_USEREVENT_REFRESH;
            SDL_PushEvent(&amp;amp;sdl_event);
        }
        SDL_Delay(40);
    }

    return 0;
}

int main(int argc, char *argv[])
{
    // Initalizing these to NULL prevents segfaults!
    AVFormatContext*    p_fmt_ctx = NULL;
    AVCodecContext*     p_codec_ctx = NULL;
    AVCodecParameters*  p_codec_par = NULL;
    AVCodec*            p_codec = NULL;
    AVFrame*            p_frm_raw = NULL;        // 帧，由包解码得到原始帧
    AVFrame*            p_frm_yuv = NULL;        // 帧，由原始帧色彩转换得到
    AVPacket*           p_packet = NULL;         // 包，从流中读出的一段数据
    struct SwsContext*  sws_ctx = NULL;
    int                 buf_size;
    uint8_t*            buffer = NULL;
    int                 i;
    int                 v_idx;
    int                 ret;
    int                 res;
    SDL_Window*         screen; 
    SDL_Renderer*       sdl_renderer;
    SDL_Texture*        sdl_texture;
    SDL_Rect            sdl_rect;
    SDL_Thread*         sdl_thread;
    SDL_Event           sdl_event;

    res = 0;
    
    if (argc &amp;lt; 2)
    {
        printf(&quot;Please provide a movie file\n&quot;);
        return -1;
    }

    // 初始化libavformat(所有格式)，注册所有复用器/解复用器
    // av_register_all();   // 已被申明为过时的，直接不再使用即可

    // A1. 打开视频文件：读取文件头，将文件格式信息存储在&quot;fmt context&quot;中
    ret = avformat_open_input(&amp;amp;p_fmt_ctx, argv[1], NULL, NULL);
    if (ret != 0)
    {
        printf(&quot;avformat_open_input() failed %d\n&quot;, ret);
        res = -1;
        goto exit0;
    }

    // A2. 搜索流信息：读取一段视频文件数据，尝试解码，将取到的流信息填入pFormatCtx-&amp;gt;streams
    //     p_fmt_ctx-&amp;gt;streams是一个指针数组，数组大小是pFormatCtx-&amp;gt;nb_streams
    ret = avformat_find_stream_info(p_fmt_ctx, NULL);
    if (ret &amp;lt; 0)
    {
        printf(&quot;avformat_find_stream_info() failed %d\n&quot;, ret);
        res = -1;
        goto exit1;
    }

    // 将文件相关信息打印在标准错误设备上
    av_dump_format(p_fmt_ctx, 0, argv[1], 0);

    // A3. 查找第一个视频流
    v_idx = -1;
    for (i=0; i&amp;lt;p_fmt_ctx-&amp;gt;nb_streams; i++)
    {
        if (p_fmt_ctx-&amp;gt;streams[i]-&amp;gt;codecpar-&amp;gt;codec_type == AVMEDIA_TYPE_VIDEO)
        {
            v_idx = i;
            printf(&quot;Find a video stream, index %d\n&quot;, v_idx);
            break;
        }
    }
    if (v_idx == -1)
    {
        printf(&quot;Cann't find a video stream\n&quot;);
        res = -1;
        goto exit1;
    }

    // A5. 为视频流构建解码器AVCodecContext

    // A5.1 获取解码器参数AVCodecParameters
    p_codec_par = p_fmt_ctx-&amp;gt;streams[v_idx]-&amp;gt;codecpar;
    
    // A5.2 获取解码器
    p_codec = avcodec_find_decoder(p_codec_par-&amp;gt;codec_id);
    if (p_codec == NULL)
    {
        printf(&quot;Cann't find codec!\n&quot;);
        res = -1;
        goto exit1;
    }
    
    // A5.3 构建解码器AVCodecContext
    // A5.3.1 p_codec_ctx初始化：分配结构体，使用p_codec初始化相应成员为默认值
    p_codec_ctx = avcodec_alloc_context3(p_codec);

    // A5.3.2 p_codec_ctx初始化：p_codec_par ==&amp;gt; p_codec_ctx，初始化相应成员
    ret = avcodec_parameters_to_context(p_codec_ctx, p_codec_par);
    if (ret &amp;lt; 0)
    {
        printf(&quot;avcodec_parameters_to_context() failed %d\n&quot;, ret);
        res = -1;
        goto exit2;
    }

    // A5.3.3 p_codec_ctx初始化：使用p_codec初始化p_codec_ctx，初始化完成
    ret = avcodec_open2(p_codec_ctx, p_codec, NULL);
    if (ret &amp;lt; 0)
    {
        printf(&quot;avcodec_open2() failed %d\n&quot;, ret);
        res = -1;
        goto exit2;
    }

    // A6. 分配AVFrame
    // A6.1 分配AVFrame结构，注意并不分配data buffer(即AVFrame.*data[])
    p_frm_raw = av_frame_alloc();
    if (p_frm_raw == NULL)
    {
        printf(&quot;av_frame_alloc() for p_frm_raw failed\n&quot;);
        res = -1;
        goto exit2;
    }
    p_frm_yuv = av_frame_alloc();
    if (p_frm_yuv == NULL)
    {
        printf(&quot;av_frame_alloc() for p_frm_raw failed\n&quot;);
        res = -1;
        goto exit3;
    }

    // A6.2 为AVFrame.*data[]手工分配缓冲区，用于存储sws_scale()中目的帧视频数据
    //     p_frm_raw的data_buffer由av_read_frame()分配，因此不需手工分配
    //     p_frm_yuv的data_buffer无处分配，因此在此处手工分配
    buf_size = av_image_get_buffer_size(AV_PIX_FMT_YUV420P, 
                                        p_codec_ctx-&amp;gt;width, 
                                        p_codec_ctx-&amp;gt;height, 
                                        1
                                       );
    // buffer将作为p_frm_yuv的视频数据缓冲区
    buffer = (uint8_t *)av_malloc(buf_size);
    if (buffer == NULL)
    {
        printf(&quot;av_malloc() for buffer failed\n&quot;);
        res = -1;
        goto exit4;
    }
    // 使用给定参数设定p_frm_yuv-&amp;gt;data和p_frm_yuv-&amp;gt;linesize
    ret = av_image_fill_arrays(p_frm_yuv-&amp;gt;data,     // dst data[]
                               p_frm_yuv-&amp;gt;linesize, // dst linesize[]
                               buffer,              // src buffer
                               AV_PIX_FMT_YUV420P,  // pixel format
                               p_codec_ctx-&amp;gt;width,  // width
                               p_codec_ctx-&amp;gt;height, // height
                               1                    // align
                              );
    if (ret &amp;lt; 0)
    {
        printf(&quot;av_image_fill_arrays() failed %d\n&quot;, ret);
        res = -1;
        goto exit5;
    }

    // A7. 初始化SWS context，用于后续图像转换
    sws_ctx = sws_getContext(p_codec_ctx-&amp;gt;width,    // src width
                             p_codec_ctx-&amp;gt;height,   // src height
                             p_codec_ctx-&amp;gt;pix_fmt,  // src format
                             p_codec_ctx-&amp;gt;width,    // dst width
                             p_codec_ctx-&amp;gt;height,   // dst height
                             AV_PIX_FMT_YUV420P,    // dst format
                             SWS_BICUBIC,           // flags
                             NULL,                  // src filter
                             NULL,                  // dst filter
                             NULL                   // param
                            );
    if (sws_ctx == NULL)
    {
        printf(&quot;sws_getContext() failed\n&quot;);
        res = -1;
        goto exit6;
    }

    // B1. 初始化SDL子系统：缺省(事件处理、文件IO、线程)、视频、音频、定时器
    if (SDL_Init(SDL_INIT_VIDEO | SDL_INIT_AUDIO | SDL_INIT_TIMER))
    {  
        printf(&quot;SDL_Init() failed: %s\n&quot;, SDL_GetError()); 
        res = -1;
        goto exit6;
    }
    
    // B2. 创建SDL窗口，SDL 2.0支持多窗口
    //     SDL_Window即运行程序后弹出的视频窗口，同SDL 1.x中的SDL_Surface
    screen = SDL_CreateWindow(&quot;Simplest ffmpeg player's Window&quot;, 
                              SDL_WINDOWPOS_UNDEFINED,// 不关心窗口X坐标
                              SDL_WINDOWPOS_UNDEFINED,// 不关心窗口Y坐标
                              p_codec_ctx-&amp;gt;width, 
                              p_codec_ctx-&amp;gt;height,
                              SDL_WINDOW_OPENGL
                             );

    if (screen == NULL)
    {  
        printf(&quot;SDL_CreateWindow() failed: %s\n&quot;, SDL_GetError());  
        res = -1;
        goto exit7;
    }

    // B3. 创建SDL_Renderer
    //     SDL_Renderer：渲染器
    sdl_renderer = SDL_CreateRenderer(screen, -1, 0);
    if (sdl_renderer == NULL)
    {  
        printf(&quot;SDL_CreateRenderer() failed: %s\n&quot;, SDL_GetError());  
        res = -1;
        goto exit7;
    }

    // B4. 创建SDL_Texture
    //     一个SDL_Texture对应一帧YUV数据，同SDL 1.x中的SDL_Overlay
    sdl_texture = SDL_CreateTexture(sdl_renderer, 
                                    SDL_PIXELFORMAT_IYUV, 
                                    SDL_TEXTUREACCESS_STREAMING,
                                    p_codec_ctx-&amp;gt;width,
                                    p_codec_ctx-&amp;gt;height);
    if (sdl_texture == NULL)
    {  
        printf(&quot;SDL_CreateTexture() failed: %s\n&quot;, SDL_GetError());  
        res = -1;
        goto exit7;
    }

    sdl_rect.x = 0;
    sdl_rect.y = 0;
    sdl_rect.w = p_codec_ctx-&amp;gt;width;
    sdl_rect.h = p_codec_ctx-&amp;gt;height;

    p_packet = (AVPacket *)av_malloc(sizeof(AVPacket));
    if (p_packet == NULL)
    {  
        printf(&quot;SDL_CreateThread() failed: %s\n&quot;, SDL_GetError());  
        res = -1;
        goto exit7;
    }

    // B5. 创建定时刷新事件线程，按照预设帧率产生刷新事件
    sdl_thread = SDL_CreateThread(sdl_thread_handle_refreshing, NULL, NULL);
    if (sdl_thread == NULL)
    {  
        printf(&quot;SDL_CreateThread() failed: %s\n&quot;, SDL_GetError());  
        res = -1;
        goto exit8;
    }

    while (1)
    {
        // B6. 等待刷新事件
        SDL_WaitEvent(&amp;amp;sdl_event);

        if (sdl_event.type == SDL_USEREVENT_REFRESH)
        {
            // A8. 从视频文件中读取一个packet
            //     packet可能是视频帧、音频帧或其他数据，解码器只会解码视频帧或音频帧，非音视频数据并不会被
            //     扔掉、从而能向解码器提供尽可能多的信息
            //     对于视频来说，一个packet只包含一个frame
            //     对于音频来说，若是帧长固定的格式则一个packet可包含整数个frame，
            //                   若是帧长可变的格式则一个packet只包含一个frame
            while (av_read_frame(p_fmt_ctx, p_packet) == 0)
            {
                if (p_packet-&amp;gt;stream_index == v_idx)  // 取到一帧视频帧，则退出
                {
                    break;
                }
            }
        
            // A9. 视频解码：packet ==&amp;gt; frame
            // A9.1 向解码器喂数据，一个packet可能是一个视频帧或多个音频帧，此处音频帧已被上一句滤掉
            ret = avcodec_send_packet(p_codec_ctx, p_packet);
            if (ret != 0)
            {
                printf(&quot;avcodec_send_packet() failed %d\n&quot;, ret);
                res = -1;
                goto exit8;
            }
            // A9.2 接收解码器输出的数据，此处只处理视频帧，每次接收一个packet，将之解码得到一个frame
            ret = avcodec_receive_frame(p_codec_ctx, p_frm_raw);
            if (ret != 0)
            {
                if (ret == AVERROR_EOF)
                {
                    printf(&quot;avcodec_receive_frame(): the decoder has been fully flushed\n&quot;);
                }
                else if (ret == AVERROR(EAGAIN))
                {
                    printf(&quot;avcodec_receive_frame(): output is not available in this state - &quot;
                           &quot;user must try to send new input\n&quot;);
                }
                else if (ret == AVERROR(EINVAL))
                {
                    printf(&quot;avcodec_receive_frame(): codec not opened, or it is an encoder\n&quot;);
                }
                else
                {
                    printf(&quot;avcodec_receive_frame(): legitimate decoding errors\n&quot;);
                }
                res = -1;
                goto exit8;
            }

            // A10. 图像转换：p_frm_raw-&amp;gt;data ==&amp;gt; p_frm_yuv-&amp;gt;data
            // 将源图像中一片连续的区域经过处理后更新到目标图像对应区域，处理的图像区域必须逐行连续
            // plane: 如YUV有Y、U、V三个plane，RGB有R、G、B三个plane
            // slice: 图像中一片连续的行，必须是连续的，顺序由顶部到底部或由底部到顶部
            // stride/pitch: 一行图像所占的空间字节数，Stride = BytesPerPixel * Width，4字节对齐
            // AVFrame.*data[]: 每个数组元素指向对应plane
            // AVFrame.linesize[]: 每个数组元素表示对应plane中一行图像所占的空间字节数
            sws_scale(sws_ctx,                                  // sws context
                      (const uint8_t *const *)p_frm_raw-&amp;gt;data,  // src slice
                      p_frm_raw-&amp;gt;linesize,                      // src stride
                      0,                                        // src slice y
                      p_codec_ctx-&amp;gt;height,                      // src slice height
                      p_frm_yuv-&amp;gt;data,                          // dst planes
                      p_frm_yuv-&amp;gt;linesize                       // dst strides
                     );
            
            // B7. 使用新的YUV像素数据更新SDL_Rect
            SDL_UpdateYUVTexture(sdl_texture,                   // sdl texture
                                 &amp;amp;sdl_rect,                     // sdl rect
                                 p_frm_yuv-&amp;gt;data[0],            // y plane
                                 p_frm_yuv-&amp;gt;linesize[0],        // y pitch
                                 p_frm_yuv-&amp;gt;data[1],            // u plane
                                 p_frm_yuv-&amp;gt;linesize[1],        // u pitch
                                 p_frm_yuv-&amp;gt;data[2],            // v plane
                                 p_frm_yuv-&amp;gt;linesize[2]         // v pitch
                                 );
            
            // B8. 使用特定颜色清空当前渲染目标
            SDL_RenderClear(sdl_renderer);
            // B9. 使用部分图像数据(texture)更新当前渲染目标
            SDL_RenderCopy(sdl_renderer,                        // sdl renderer
                           sdl_texture,                         // sdl texture
                           NULL,                                // src rect, if NULL copy texture
                           &amp;amp;sdl_rect                            // dst rect
                          );
            
            // B10. 执行渲染，更新屏幕显示
            SDL_RenderPresent(sdl_renderer);

            av_packet_unref(p_packet);
        }
        else if (sdl_event.type == SDL_KEYDOWN)
        {
            printf(&quot;SDL event KEYDOWN\n&quot;);
            if (sdl_event.key.keysym.sym == SDLK_SPACE)
            {
                // 用户按空格键，暂停/继续状态切换
                printf(&quot;player %s\n&quot;, s_playing_pause ? &quot;pause&quot; : &quot;continue&quot;);
                s_playing_pause = !s_playing_pause;
            }
        }
        else if (sdl_event.type == SDL_QUIT)
        {
            // 用户按下关闭窗口按钮
            printf(&quot;SDL event QUIT\n&quot;);
            s_playing_exit = true;
            break;
        }
        else
        {
            // printf(&quot;Ignore SDL event 0x%04X\n&quot;, sdl_event.type);
        }
    }

exit8:
    SDL_Quit();
exit7:
    av_packet_unref(p_packet);
exit6:
   sws_freeContext(sws_ctx); 
exit5:
    av_free(buffer);
exit4:
    av_frame_free(&amp;amp;p_frm_yuv);
exit3:
    av_frame_free(&amp;amp;p_frm_raw);
exit2:
    avcodec_close(p_codec_ctx);
exit1:
    avformat_close_input(&amp;amp;p_fmt_ctx);
exit0:
    return res;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;流程简述&quot;&gt;2.1 流程简述&lt;/h3&gt;
&lt;p&gt;流程比较简单，不画流程图了，简述如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;media file ---[decode]---&amp;gt; raw frame ---[scale]---&amp;gt; yuv frame ---[SDL]---&amp;gt; display  
media file --------------&amp;gt; p_frm_raw -------------&amp;gt; p_frm_yuv -----------&amp;gt; sdl_renderer  &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;加上相关关键函数后，流程如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;media_file ---[av_read_frame()]-----------&amp;gt;  
p_packet   ---[avcodec_send_packet()]-----&amp;gt;  
decoder    ---[avcodec_receive_frame()]---&amp;gt;  
p_frm_raw  ---[sws_scale]-----------------&amp;gt;  
p_frm_yuv  ---[SDL_UpdateYUVTexture()]----&amp;gt;  
display  &lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;相关概念&quot;&gt;2.2 相关概念&lt;/h3&gt;
&lt;p&gt;源码清单中涉及的一些概念简述如下：&lt;br/&gt;&lt;strong&gt;container:&lt;/strong&gt;&lt;br/&gt;对应数据结构AVFormatContext&lt;br/&gt;封装器，将流数据封装为指定格式的文件，文件格式如AVI、MP4等。&lt;br/&gt;FFmpeg可识别五种流类型：视频video(v)、音频audio(a)、attachment(t)、数据data(d)、字幕subtitle。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;codec:&lt;/strong&gt;&lt;br/&gt;对应数据结构AVCodec&lt;br/&gt;编解码器。编码器将未压缩的原始图像或音频数据编码为压缩数据。解码器与之相反。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;codec context&lt;/strong&gt;:&lt;br/&gt;对应数据结构AVCodecContext&lt;br/&gt;编解码器上下文。此为非常重要的一个数据结构，后文分析。各API大量使用AVCodecContext来引用编解码器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;codec par&lt;/strong&gt;:&lt;br/&gt;对应数据结构AVCodecParameters&lt;br/&gt;编解码器参数。新版本增加的字段。新版本建议使用AVStream-&amp;gt;codepar替代AVStream-&amp;gt;codec。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;packet&lt;/strong&gt;:&lt;br/&gt;对应数据结构AVPacket&lt;br/&gt;经过编码的数据。通过av_read_frame()从媒体文件中获取得到的一个packet可能包含多个(整数个)音频帧或单个&lt;br/&gt;视频帧，或者其他类型的流数据。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;frame&lt;/strong&gt;:&lt;br/&gt;对应数据结构AVFrame&lt;br/&gt;解码后的原始数据。解码器将packet解码后生成frame。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;plane&lt;/strong&gt;:&lt;br/&gt;如YUV有Y、U、V三个plane，RGB有R、G、B三个plane&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;slice&lt;/strong&gt;:&lt;br/&gt;图像中一片连续的行，必须是连续的，顺序由顶部到底部或由底部到顶部&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;stride/pitch&lt;/strong&gt;:&lt;br/&gt;一行图像所占的空间字节数，Stride = BytesPerPixel * Width，x字节对齐[待确认]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;sdl window&lt;/strong&gt;:&lt;br/&gt;对应数据结构SDL_Window&lt;br/&gt;播放视频时弹出的窗口。在SDL1.x版本中，只可以创建一个窗口。在SDL2.0版本中，可以创建多个窗口。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;sdl texture&lt;/strong&gt;:&lt;br/&gt;对应数据结构SDL_Texture&lt;br/&gt;一个SDL_Texture对应一帧解码后的图像数据。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;sdl renderer&lt;/strong&gt;:&lt;br/&gt;对应数据结构SDL_Renderer&lt;br/&gt;渲染器。将SDL_Texture渲染至SDL_Window。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;sdl rect&lt;/strong&gt;:&lt;br/&gt;对应数据结构SDL_Rect&lt;br/&gt;SDL_Rect用于确定SDL_Texture显示的位置。一个SDL_Window上可以显示多个SDL_Rect。这样可以实现同一窗口的分屏显示。&lt;/p&gt;
&lt;h3 id=&quot;帧率控制-定时刷新机制&quot;&gt;2.3 帧率控制-定时刷新机制&lt;/h3&gt;
&lt;p&gt;将上一版代码拆分为两个线程：定时刷新线程 + 解码主线程。&lt;br/&gt;定时刷新线程每40ms发送一个自定义SDL事件，通知解码主线程&lt;br/&gt;解码主线程收到SDL事件后，获取一个视频帧解码并显示&lt;/p&gt;
&lt;h2 id=&quot;编译&quot;&gt;3、编译&lt;/h2&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;gcc -o ffplayer ffplayer.c -lavutil -lavformat -lavcodec -lavutil -lswscale -lSDL2&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;测试&quot;&gt;4、测试&lt;/h2&gt;
&lt;pre class=&quot;shell&quot;&gt;
&lt;code&gt;./ffplayer 480x272.h265 &lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;参考资料&quot;&gt;5、参考资料&lt;/h2&gt;
&lt;p&gt;[1] 雷霄骅，&lt;a href=&quot;https://blog.csdn.net/leixiaohua1020/article/details/18893769&quot;&gt;视音频编解码技术零基础学习方法&lt;/a&gt;”&lt;br/&gt;[2] 雷霄骅，&lt;a href=&quot;https://blog.csdn.net/leixiaohua1020/article/details/41181155&quot;&gt;FFmpeg源代码简单分析：常见结构体的初始化和销毁(AVFormatContext，AVFrame等)&lt;/a&gt;&lt;br/&gt;[3] 雷霄骅，&lt;a href=&quot;https://blog.csdn.net/leixiaohua1020/article/details/38868499&quot;&gt;最简单的基于FFMPEG+SDL的视频播放器ver2(采用SDL2.0)&lt;/a&gt;&lt;br/&gt;[4] Martin Bohme, &lt;a href=&quot;http://dranger.com/ffmpeg/ffmpegtutorial_all.html#tutorial01.html&quot;&gt;An ffmpeg and SDL Tutorial, Tutorial 01: Making Screencaps&lt;/a&gt;&lt;br/&gt;[5] Martin Bohme, &lt;a href=&quot;http://dranger.com/ffmpeg/ffmpegtutorial_all.html#tutorial02.html&quot;&gt;An ffmpeg and SDL Tutorial, Tutorial 02: Outputting to the Screen&lt;/a&gt;&lt;br/&gt;[6] &lt;a href=&quot;https://www.cnblogs.com/welhzh/p/4939613.html&quot;&gt;YUV图像里的stride和plane的解释&lt;/a&gt;&lt;br/&gt;[7] &lt;a href=&quot;https://www.cnblogs.com/azraelly/archive/2013/01/01/2841269.html&quot;&gt;图文详解YUV420数据格式&lt;/a&gt;&lt;br/&gt;[8] &lt;a href=&quot;https://zh.wikipedia.org/wiki/YUV&quot;&gt;YUV&lt;/a&gt;，&lt;a href=&quot;https://zh.wikipedia.org/wiki/YUV&quot; class=&quot;uri&quot;&gt;https://zh.wikipedia.org/wiki/YUV&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;修改记录&quot;&gt;6、修改记录&lt;/h2&gt;
&lt;p&gt;2018-11-23 V1.0 初稿&lt;br/&gt;2018-11-29 V1.1 增加定时刷新线程，使解码帧率更加准确&lt;/p&gt;
</description>
<pubDate>Fri, 30 Nov 2018 14:55:00 +0000</pubDate>
<dc:creator>叶余</dc:creator>
<og:description>实验平台：openSUSE Leap 42.3 FFmpeg版本：4.1 SDL版本：2.0.9 基于FFmpeg和SDL实现的简易视频播放器，主要分为读取视频文件解码和调用SDL显示两大部分。详细流</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/leisure_chn/p/10047035.html</dc:identifier>
</item>
</channel>
</rss>