<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>【开源项目】将图片转换为字符画 - xiaoxi666</title>
<link>http://www.cnblogs.com/xiaoxi666/p/8452717.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xiaoxi666/p/8452717.html</guid>
<description>&lt;h2 id=&quot;原理&quot;&gt;原理&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;选定填充图片的ASCII字符，不同的字符对应于不同的灰度&lt;/li&gt;
&lt;li&gt;读取图片并计算各像素灰度值（同时考虑透明背景），用相应的的ASCII字符替换该像素&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;程序功能&quot;&gt;程序功能&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;支持3种文件选择方式：选定文件（支持图片预览），添加文件夹，拖入文件&lt;/li&gt;
&lt;li&gt;支持5种图片格式：.jpg， .jpeg， .gif， .png，.bmp&lt;/li&gt;
&lt;li&gt;支持5挡不同的缩放比例：10%，20%，25%，50%，以及不缩放，默认为不缩放&lt;/li&gt;
&lt;li&gt;转换结果以文件名“原文件名+.txt”保存至新建文件夹，新建文件夹的命名方式为“字符画转换结果+当前时间”，其中当前时间的格式为“年_月_日_时_分_秒”&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;建议：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;转换后的txt文件最好用notepad++等类似软件打开，这类软件不会将内容换行，同时支持缩放&lt;/li&gt;
&lt;li&gt;图片宽和高最好控制在1000px以内，太大的话，出来的图太过精细，不方便查看。这时可利用缩放功能。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;可视化界面&quot;&gt;可视化界面&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;为方便操作，特意包装成可视化界面，并加入“保持窗口最前”选项，方便文件拖入&lt;/li&gt;
&lt;li&gt;注意：如果所选文件格式不正确，“开始转换”按钮不可用&lt;/li&gt;
&lt;li&gt;程序已打包为exe文件64位版本，可以直接使用&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;源码exe文件-以及-软件截图效果图&quot;&gt;源码、exe文件 以及 软件截图、效果图&lt;/h2&gt;
&lt;p&gt;请移步Github仓库：&lt;a href=&quot;https://github.com/xiaoxi666/Img2AsciiVision&quot; class=&quot;uri&quot;&gt;https://github.com/xiaoxi666/Img2AsciiVision&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;source文件夹：源码及其资源文件&lt;/li&gt;
&lt;li&gt;ExecuteFileAndPackageTools文件夹：可执行文件Img2Ascii.exe及其打包文件&lt;/li&gt;
&lt;li&gt;Demos文件夹： 软件截图和效果图&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;软件截图和效果图&quot;&gt;软件截图和效果图&lt;/h2&gt;
&lt;p&gt;软件截图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/609124/201802/609124-20180218134834515-1146101988.png&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;原图：&lt;br/&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/609124/201802/609124-20180218134908577-542600774.jpg&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;转换为Ascii后的字符画：&lt;br/&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/609124/201802/609124-20180218134921827-1667081202.jpg&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
&lt;p&gt;局部放大图（可以看到Ascii码字符）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/609124/201802/609124-20180218135002905-1345819393.jpg&quot; alt=&quot;image&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 18 Feb 2018 05:35:00 +0000</pubDate>
<dc:creator>xiaoxi666</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/xiaoxi666/p/8452717.html</dc:identifier>
</item>
<item>
<title>获取View组件宽度以及ViewTreeObserver - ganchuanpu</title>
<link>http://www.cnblogs.com/ganchuanpu/p/8452698.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ganchuanpu/p/8452698.html</guid>
<description>&lt;h2&gt;View宽高测量方法：&lt;/h2&gt;
&lt;p&gt;测量方法有三种，如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1）&lt;/strong&gt;（直接在onCreate()执行）&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;int&lt;/span&gt; w = View.MeasureSpec.makeMeasureSpec(&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,View.MeasureSpec.UNSPECIFIED);  
&lt;/span&gt;&lt;span&gt;int&lt;/span&gt; h = View.MeasureSpec.makeMeasureSpec(&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,View.MeasureSpec.UNSPECIFIED);  
imageView.measure(w, h);  
&lt;/span&gt;&lt;span&gt;int&lt;/span&gt; height =&lt;span&gt;imageView.getMeasuredHeight();  
&lt;/span&gt;&lt;span&gt;int&lt;/span&gt; width =&lt;span&gt;imageView.getMeasuredWidth();  
textView.append(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;+height+&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;+width);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;2）&lt;/span&gt;&lt;/strong&gt;2和3都是在onCreate()调用完后回调拿到组件的宽高&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
ViewTreeObserver vto =&lt;span&gt; imageView.getViewTreeObserver();  
vto.addOnPreDrawListener(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; ViewTreeObserver.OnPreDrawListener() {  
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; boolean onPreDraw() {  
        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; height =&lt;span&gt; imageView.getMeasuredHeight();  
        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; width =&lt;span&gt; imageView.getMeasuredWidth();  
        textView.append(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;\n&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;+height+&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;+&lt;span&gt;width);  
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;  
    }  
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;3）&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
ViewTreeObserver vto2 =&lt;span&gt; imageView.getViewTreeObserver();    
vto2.addOnGlobalLayoutListener(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; OnGlobalLayoutListener() {  
    @Override    
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; onGlobalLayout() {  
        imageView.getViewTreeObserver().removeGlobalOnLayoutListener(&lt;/span&gt;&lt;span&gt;this&lt;/span&gt;&lt;span&gt;);    
        textView.append(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;\n\n&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;+imageView.getHeight()+&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;+&lt;span&gt;imageView.getWidth());  
    }    
});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注意：方法一比其他方法多一次onMeasure计算，方法二的回调函数会被多次调用。&lt;/p&gt;
&lt;p&gt;转自http://blog.csdn.net/johnny901114/article/details/7839512&lt;/p&gt;
&lt;h2&gt;ViewTreeObserver&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;一、结构&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; final &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ViewTreeObserver extends Object
    java.lang.Object
         android.view.ViewTreeObserver&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;二、概述&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;    这是一个注册监听视图树的观察者(observer)，在视图树种全局事件改变时得到通知。这个全局事件不仅还包括整个树的布局，从绘画过程开始，触摸模式的改变等。ViewTreeObserver不能够被应用程序实例化，因为它是由视图提供，参照getViewTreeObserver()以查看更多信息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三、内部类&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;  ViewTreeObserver.OnGlobalFocusChangeListener         
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;当在一个视图树中的焦点状态发生改变时，所要调用的回调函数的接口类&lt;/span&gt;
 
&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;  ViewTreeObserver.OnGlobalLayoutListener
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;当在一个视图树中全局布局发生改变或者视图树中的某个视图的可视状态发生改变时，所要调用的回调函数的接口类&lt;/span&gt;
 
&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;  ViewTreeObserver.OnPreDrawListener
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;当一个视图树将要绘制时，所要调用的回调函数的接口类&lt;/span&gt;
 
&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;  ViewTreeObserver.OnScrollChangedListener
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;当一个视图树中的一些组件发生滚动时，所要调用的回调函数的接口类&lt;/span&gt;
 
&lt;span&gt;interface&lt;/span&gt;&lt;span&gt;  ViewTreeObserver.OnTouchModeChangeListener
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;当一个视图树的触摸模式发生改变时，所要调用的回调函数的接口类&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;四、公共方法&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*注册一个回调函数，当在一个视图树中的焦点状态发生改变时调用这个回调函数。
 * 参数 listener    将要被添加的回调函数
 *异常 IllegalStateException       如果isAlive() 返回false
&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; addOnGlobalFocusChangeListener (ViewTreeObserver.OnGlobalFocusChangeListener listener)
     
 
&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*注册一个回调函数，当在一个视图树中全局布局发生改变或者视图树中的某个视图的可视状态发生改变时调用这个回调函数。
 *参数 listener    将要被添加的回调函数
 *异常 IllegalStateException       如果isAlive() 返回false
&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; addOnGlobalLayoutListener (ViewTreeObserver.OnGlobalLayoutListener listener)
　　
 
　　
&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*注册一个回调函数，当一个视图树将要绘制时调用这个回调函数。
 *参数 listener    将要被添加的回调函数
 *异常 IllegalStateException       如果isAlive() 返回false
&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
　&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; addOnPreDrawListener (ViewTreeObserver.OnPreDrawListener listener)
 
　   
&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*注册一个回调函数，当一个视图发生滚动时调用这个回调函数。
  *参数 listener    将要被添加的回调函数
　*异常 IllegalStateException       如果isAlive() 返回false
&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; addOnScrollChangedListener (ViewTreeObserver.OnScrollChangedListener listener)  
 
　
&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*注册一个回调函数，当一个触摸模式发生改变时调用这个回调函数。
  *参数 listener    将要被添加的回调函数
  *异常 IllegalStateException       如果isAlive() 返回false
&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; addOnTouchModeChangeListener (ViewTreeObserver.OnTouchModeChangeListener listener)
 
　　
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;当整个布局发生改变时通知相应的注册监听器。如果你强制对视图布局或者在一个没有附加到一个窗口的视图的层次结构或者在GONE状态下，它可以被手动的调用&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; final &lt;span&gt;void&lt;/span&gt;&lt;span&gt; dispatchOnGlobalLayout ()
    
&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*当一个视图树将要绘制时通知相应的注册监听器。如果这个监听器返回true，则这个绘制将被取消并重新计划。如果你强制对视图布局或者在一个没有附加到一个窗口的视图的层次结构或者在一个GONE状态下，它可以被手动的调用
 *返回值  当前绘制能够取消并重新计划则返回true，否则返回false。
&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt;&lt;span&gt; final boolean dispatchOnPreDraw ()
 
&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*指示当前的ViewTreeObserver是否可用(alive)。当observer不可用时，任何方法的调用（除了这个方法）都将抛出一个异常。如果一个应用程序保持和ViewTreeObserver一个历时较长的引用，它应该总是需要在调用别的方法之前去检测这个方法的返回值。
　*返回值 但这个对象可用则返回true，否则返回false   
&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt;&lt;span&gt; boolean isAlive ()
    
     
&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*移除之前已经注册的全局布局回调函数。
  *参数 victim 将要被移除的回调函数
  *异常 IllegalStateException       如果isAlive() 返回false   
&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; removeGlobalOnLayoutListener (ViewTreeObserver.OnGlobalLayoutListener victim)
　　
&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*移除之前已经注册的焦点改变回调函数。
　*参数 victim 将要被移除的回调函数
　*异常 IllegalStateException       如果isAlive() 返回false 
&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; removeOnGlobalFocusChangeListener (ViewTreeObserver.OnGlobalFocusChangeListener victim)
　　
&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*移除之前已经注册的预绘制回调函数。
　*参数 victim 将要被移除的回调函数
　 *异常 IllegalStateException       如果isAlive() 返回false  
&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; removeOnPreDrawListener (ViewTreeObserver.OnPreDrawListener victim)
　　
&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*移除之前已经注册的滚动改变回调函数。
　*参数 victim 将要被移除的回调函数
　*异常 IllegalStateException       如果isAlive() 返回false 
&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; removeOnScrollChangedListener (ViewTreeObserver.OnScrollChangedListener victim)
　
&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*移除之前已经注册的触摸模式改变回调函数
　*参数 victim 将要被移除的回调函数
　*异常 　IllegalStateException       如果isAlive() 返回false
&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; removeOnTouchModeChangeListener (ViewTreeObserver.OnTouchModeChangeListener victim)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;五、代码示例&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;br/&gt;&lt;/strong&gt;1、创建监听器&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;private&lt;/span&gt; final ViewTreeObserver.OnGlobalLayoutListener mGlobalLayoutListener = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ViewTreeObserver.OnGlobalLayoutListener() {
    @Override
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; onGlobalLayout() {
      &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; width = -&lt;span&gt;1&lt;/span&gt;&lt;span&gt;;
      &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; height = -&lt;span&gt;1&lt;/span&gt;&lt;span&gt;;
      
      &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
        width &lt;/span&gt;=&lt;span&gt; getActivity().getWindow().getDecorView().getWidth();
        height &lt;/span&gt;=&lt;span&gt; getActivity().getWindow().getDecorView().getHeight();
      } &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception e) {
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; called too early. so, just skip.&lt;/span&gt;
&lt;span&gt;      }
      
      &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (width != -&lt;span&gt;1&lt;/span&gt; &amp;amp;&amp;amp; mGlobalLayoutWidth != width) {&lt;span&gt;//&lt;/span&gt;&lt;span&gt;只有当尺寸真正有了数值，即已经确定了，更新UI才有意义&lt;/span&gt;
        mGlobalLayoutWidth =&lt;span&gt; width;
        updateUI();
      } &lt;/span&gt;&lt;span&gt;else&lt;/span&gt; &lt;span&gt;if&lt;/span&gt; (height != -&lt;span&gt;1&lt;/span&gt; &amp;amp;&amp;amp; mGlobalLayoutHeight !=&lt;span&gt; height) {
        mGlobalLayoutHeight &lt;/span&gt;=&lt;span&gt; height;                
    updateUI();
 } } };&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2、一般在onCreate或onCreateView中注册监听器&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
mViewTreeObserver =&lt;span&gt; getActivity().getWindow().getDecorView().getViewTreeObserver();
mViewTreeObserver.addOnGlobalLayoutListener(mGlobalLayoutListener);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

</description>
<pubDate>Sun, 18 Feb 2018 04:59:00 +0000</pubDate>
<dc:creator>ganchuanpu</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/ganchuanpu/p/8452698.html</dc:identifier>
</item>
<item>
<title>浅析Xilinx 三速以太网MAC IP核（仿真篇） - 没落骑士</title>
<link>http://www.cnblogs.com/moluoqishi/p/8448286.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/moluoqishi/p/8448286.html</guid>
<description>&lt;p&gt;　&lt;span&gt;　之前在使用Altera的三速以太网MAC IP的基础上，完成了UDP协议数据传输。此次为了将设计移植到xilinx FPGA上，需要用到xilinx的三速以太网MAC IP核，当然也可以自己用HDL编写，但必须对数据链路层协议有非常清晰的认识。以下是在使用xilinx 三速以太网MAC过程中的一些记录和总结。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　在使用IP核传输数据之前要对MAC层功能有个了解。MAC层功能用一个词概括就是“成帧解帧”，具体来讲&lt;span&gt;TX方向对用户侧发送来的MAC帧添加前导码和帧尾校验和，对长度过短帧会在帧尾填充0直至最小帧长，此外流控模块可以根据需要发送pause帧。RX方向过滤掉不符合规范的数据帧并移除填充域，只有目的MAC地址与自身相符且帧尾校验和正确的数据帧才为有效数据帧，去除前导码和校验域后即发送给用户侧。接收端也会根据可能收到的pause帧做出暂停发送处理。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;em&gt;&lt;span&gt;　　&lt;/span&gt;&lt;/em&gt;&lt;span&gt;认识以太网帧结构同样非常重要，目前常见的是Ethernet II和IEEE802.3两种格式，总体可以归纳为：目的MAC地址　　源MAC地址　　长度/类型　　有效负荷（可能有填充）　　帧校验，长度依次是6byte、6byte、2byte、46~1500byte、4byte。&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span&gt;区别在于Ethernet II帧长度/类型域解释为上层协议类型，而IEEE802.3同样位置是长度字段。区分两者的标准是：当该字段值小于等于1500（十六进制的0x05DC）时，为IEEE802.3格式；当字段值大于等于1536（或者十六进制的0x0600）时，帧使用的是Ethernet II格式。&lt;/span&gt;其中Ethernet II最为常见。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　IP核的配置很简单，根据自己的需求设置即可。重点关注第二页，这里选择使用GMII作为物理层接口，并选择三速模式，可以通过接口改动传输速率。&lt;img src=&quot;https://images2017.cnblogs.com/blog/1201289/201802/1201289-20180214144124281-1615650465.png&quot; alt=&quot;&quot; width=&quot;772&quot; height=&quot;526&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; 　　&lt;span&gt;IP核配置生成输出文件后，和其他较为复杂的IP核一样要熟读文档和分析example design的结构和功能。资料主要参考PG051.我们直接打开example design顶层文件对工程有个整体的认识：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    --------------------------------------------------
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | EXAMPLE DESIGN WRAPPER                         |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |                                                |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |                                                |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |   -------------------     -------------------  |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |   |                 |     |                 |  |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |   |    Clocking     |     |     Resets      |  |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |   |                 |     |                 |  |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |   -------------------     -------------------  |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |           -------------------------------------|
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |           |FIFO BLOCK WRAPPER                  |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |           |                                    |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |           |                                    |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |           |              ----------------------|
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |           |              | SUPPORT LEVEL       |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | --------  |              |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | |      |  |              |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | | AXI  |-&amp;gt;|-------------&amp;gt;|                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | | LITE |  |              |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | |  SM  |  |              |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | |      |&amp;lt;-|&amp;lt;-------------|                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | |      |  |              |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | --------  |              |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |           |              |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | --------  |  ----------  |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | |      |  |  |        |  |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | |      |-&amp;gt;|-&amp;gt;|        |-&amp;gt;|                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | | PAT  |  |  |        |  |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | | GEN  |  |  |        |  |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | |(ADDR |  |  |  AXI-S |  |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | | SWAP)|  |  |  FIFO  |  |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | |      |  |  |        |  |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | |      |  |  |        |  |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | |      |  |  |        |  |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | |      |&amp;lt;-|&amp;lt;-|        |&amp;lt;-|                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | |      |  |  |        |  |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    | --------  |  ----------  |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |           |              |                     |
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |           |              ----------------------|
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    |           -------------------------------------|
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    --------------------------------------------------

&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;------------------------------------------------------&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;span&gt;　　上边是官方提供的注释，非常清晰地给出了工程结构：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;example_clocks:　　　　　时钟模块，提供工程中用到的所有时钟信号；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;example_resets:　　　　　复位模块，产生所有子模块的复位信号；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;axi_lite_controller:　　　　控制模块，内部通过状态机对MAC和PHY芯片进行初始化和相应配置工作。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;basic_pat_gen_inst:         包测试模块，有两种模式：发送固定样式测试数据包和将收到数据包环回送出给PHY。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;trimac_fifo_block:　　       AXI-S接口异步FIFO和MAC IP核。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　MAC IP核包含的主要接口类型及作用是：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;GMII接口--PHY数据通道　　　　 &lt;/span&gt;&lt;span&gt;MDIO接口--PHY芯片配置管理　　　　 &lt;/span&gt;&lt;span&gt;AXI-Stream接口--用户数据通道　　　　 &lt;/span&gt;&lt;span&gt;AXI-Lite接口--用户控制管理&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　初步需要掌握的是用户数据接口，实际上AXI-Stream也无需过多关注，只要理解FIFO用户侧接口即可。以发送方向为例：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1201289/201802/1201289-20180214153720827-1234578887.png&quot; alt=&quot;&quot; width=&quot;652&quot; height=&quot;165&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　&lt;span&gt;　tx_axis_fifo_tdata 8位数据，tx_axis_fifo_tvalid 数据有效指示，tx_axis_fifo_tready MAC发送准备信号，tx_axis_fifo_tlast 数据包尾指示。接下来使用示例工程的testbench查看仿真波形，对用户接口时序有一个直观的认识。官方testbench demo_tb文件中会持续分别以10M 100M 1000M速率向example design RX方向GMII端口发送5个不同数据帧。先来看&lt;span&gt;&lt;strong&gt;千兆网&lt;/strong&gt;&lt;/span&gt;波形，在千兆模式下TX时钟为由FPGA提供的125MHz信号gtx_clk_bufg，RX时钟由PHY通过时钟恢复得到125MHz时钟信号。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1201289/201802/1201289-20180217153927718-347303136.png&quot; alt=&quot;&quot; width=&quot;1192&quot; height=&quot;373&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;数据的流向为：gmii_rx_xx --&amp;gt; rx_axis_mac_xx --&amp;gt; rx_axis_fifo_xx --&amp;gt; tx_axis_fifo_xx --&amp;gt; tx_axis_mac_xx --&amp;gt; gmii_tx_xx。此时example design中basic_pat_gen_inst模块设置为环回模式，会将MAC接收的数据环回到发送通道。由于第三个帧错误指示信号gmii_rx_er拉高，而第5个帧MAC地址不匹配，因此这两个数据帧被滤除掉。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1201289/201802/1201289-20180218113547343-1300218406.png&quot; alt=&quot;&quot; width=&quot;1249&quot; height=&quot;210&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　上图看出第三个数据帧带有错误指示信号，FIFO模块才会将其丢弃。第五个数据包MAC地址不符，在MAC核内部被丢弃。以第四个数据包为例观察时序：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1201289/201802/1201289-20180218114021515-2104445608.png&quot; alt=&quot;&quot; width=&quot;1259&quot; height=&quot;92&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; 　　&lt;span&gt;包尾指示和数据在MAC核收到FCS并检测完毕后才输出有效。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1201289/201802/1201289-20180217155603031-755993682.png&quot; alt=&quot;&quot; width=&quot;1257&quot; height=&quot;92&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;该帧目的MAC地址是48'hda_02_03_04_05_06 源MAC地址是48'h5a_02_03_04_05_06 长度/类型域是16'h00_03，因此是解释为帧长度为3字节，负荷是01 02 03。&lt;/span&gt;&lt;span&gt;环回后目的MAC地址和源MAC地址被basic_pat_gen_inst模块交换，TX方向用户数据包为：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1201289/201802/1201289-20180217155819374-599265245.png&quot; alt=&quot;&quot; width=&quot;1261&quot; height=&quot;101&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;我们看下MAC核TX方向实际的用户接口时序，FIFO模块屏蔽了用户侧与MAC核之间的握手应答机制，缓存至少一个数据帧即开始数据传输，从而简化了接口时序。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1201289/201802/1201289-20180218110125577-394202472.png&quot; alt=&quot;&quot; width=&quot;1260&quot; height=&quot;97&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;当数据发送到物理层接口，由于数据包小于最小长度，因此发送到gmii接口上再次被填充至最小帧长。此外添加上前导码和校验和。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1201289/201802/1201289-20180217161722171-1266151171.png&quot; alt=&quot;&quot; width=&quot;1256&quot; height=&quot;80&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;再&lt;/span&gt;&lt;span&gt;来看看&lt;span&gt;&lt;strong&gt;百兆网&lt;/strong&gt;&lt;/span&gt;，速率为100M时TX和RX方向时钟信号均由PHY芯片提供。第四数据帧TX方向用户接口波形：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1201289/201802/1201289-20180218110505358-2103899341.png&quot; alt=&quot;&quot; width=&quot;1247&quot; height=&quot;117&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;FIFO提供的用户侧接口时序上与千兆网没有差别，时钟频率是125MHz，位宽依然是8bit，那么又是如何实现百兆速率的呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1201289/201802/1201289-20180218110911905-137846735.png&quot; alt=&quot;&quot; width=&quot;1250&quot; height=&quot;101&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;MAC核用户接口时钟为25MHz，位宽为8bit，MAC核提供的tready信号每两周期拉高一周期，速率为25M*8/2 = 100M，因此100M速率是通过tready信号限流实现的。综上，对100M和1000M速率下全双工以太网概念和帧结构、MAC IP核配置以及核心用户接口时序功能均进行了阐述，本人也在学习中，希望对大家有帮助。&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 18 Feb 2018 03:51:00 +0000</pubDate>
<dc:creator>没落骑士</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/moluoqishi/p/8448286.html</dc:identifier>
</item>
<item>
<title>ASP.NET Core 2.0 : 四.  _Layout与_ViewStart - FlyLolo</title>
<link>http://www.cnblogs.com/FlyLolo/p/8452169.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/FlyLolo/p/8452169.html</guid>
<description>&lt;p&gt;本章我们新建一个项目,并通过这个项目熟悉一下_Layout与_ViewStart以及它们的加载顺序.&lt;/p&gt;

&lt;p&gt;首先, 文件-&amp;gt;新建一个解决方案&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/548134/201802/548134-20180217213100544-1212981877.png&quot; alt=&quot;&quot; width=&quot;204&quot; height=&quot;69&quot;/&gt;&lt;/p&gt;
&lt;p&gt;选择.Net Core 的APP下面的ASP.NET Core Web App(MVC)&lt;/p&gt;
&lt;p&gt;Next&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;http://images2017.cnblogs.com/blog/548134/201802/548134-20180218090605733-389996591.jpg&quot; alt=&quot;&quot; width=&quot;408&quot; height=&quot;297&quot;/&gt;&lt;/p&gt;
&lt;p&gt;设置解决方案的名称(和Xcode的界面风格有点像), 输入FL.WeightManager, 做一个每天记录体重的应用&lt;/p&gt;
&lt;p&gt;点击Create.&lt;/p&gt;
&lt;p&gt;项目新建完毕, 项目的文件结构上一章已经说过了.&lt;/p&gt;


&lt;p&gt;新建好的项目默认运行效果如下图&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://images2017.cnblogs.com/blog/548134/201802/548134-20180218092051640-1762210003.png&quot; alt=&quot;&quot; width=&quot;450&quot; height=&quot;239&quot;/&gt;&lt;/p&gt;
&lt;p&gt;页面主要分三部分, 上面的header, 下面的footer, 点击上面菜单总的Home、About和Contact切换一下页面看一下&lt;/p&gt;
&lt;p&gt;这两部分都是不变的, 只有中间部分在变.&lt;/p&gt;
&lt;p&gt;打开Shared文件夹下面的_layout.cshtml页面看一下, header和footer都是定义在这里的, &lt;/p&gt;
&lt;p&gt;而中间变的部分是 &lt;span&gt;@RenderBody().&lt;/span&gt;&lt;span&gt;也就是我们经常要改变的地方了.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;现在将主页改变一下, 打开Home文件夹下的Index文件,将里面的一大堆代码改成如下代码&lt;/span&gt;&lt;/p&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;@{
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt;     ViewData[&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Title&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;] = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;主页&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;}
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &amp;lt;table &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;table table-hover&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&amp;gt;
&lt;span&gt; 5&lt;/span&gt;     &amp;lt;thead&amp;gt;
&lt;span&gt; 6&lt;/span&gt;         &amp;lt;tr&amp;gt;
&lt;span&gt; 7&lt;/span&gt;             &amp;lt;th&amp;gt;序号&amp;lt;/th&amp;gt;
&lt;span&gt; 8&lt;/span&gt;             &amp;lt;th&amp;gt;日期&amp;lt;/th&amp;gt;
&lt;span&gt; 9&lt;/span&gt;             &amp;lt;th&amp;gt;体重&amp;lt;/th&amp;gt;
&lt;span&gt;10&lt;/span&gt;             &amp;lt;th&amp;gt;备注&amp;lt;/th&amp;gt;
&lt;span&gt;11&lt;/span&gt;         &amp;lt;/tr&amp;gt;
&lt;span&gt;12&lt;/span&gt;     &amp;lt;/thead&amp;gt;
&lt;span&gt;13&lt;/span&gt;     &amp;lt;tbody&amp;gt;
&lt;span&gt;14&lt;/span&gt;         &amp;lt;tr&amp;gt;
&lt;span&gt;15&lt;/span&gt;             &amp;lt;td&amp;gt;&lt;span&gt;1&lt;/span&gt;&amp;lt;/td&amp;gt;
&lt;span&gt;16&lt;/span&gt;             &amp;lt;td&amp;gt;&lt;span&gt;2018&lt;/span&gt;-&lt;span&gt;02&lt;/span&gt;-&lt;span&gt;15&lt;/span&gt;&amp;lt;/td&amp;gt;
&lt;span&gt;17&lt;/span&gt;             &amp;lt;td&amp;gt;&lt;span&gt;66.6&lt;/span&gt;&amp;lt;/td&amp;gt;
&lt;span&gt;18&lt;/span&gt;             &amp;lt;td&amp;gt;除夕,胖了&amp;lt;/td&amp;gt;
&lt;span&gt;19&lt;/span&gt;         &amp;lt;/tr&amp;gt;
&lt;span&gt;20&lt;/span&gt;         &amp;lt;tr&amp;gt;
&lt;span&gt;21&lt;/span&gt;             &amp;lt;td&amp;gt;&lt;span&gt;2&lt;/span&gt;&amp;lt;/td&amp;gt;
&lt;span&gt;22&lt;/span&gt;             &amp;lt;td&amp;gt;&lt;span&gt;2018&lt;/span&gt;-&lt;span&gt;02&lt;/span&gt;-&lt;span&gt;16&lt;/span&gt;&amp;lt;/td&amp;gt;
&lt;span&gt;23&lt;/span&gt;             &amp;lt;td&amp;gt;&lt;span&gt;68.8&lt;/span&gt;&amp;lt;/td&amp;gt;
&lt;span&gt;24&lt;/span&gt;             &amp;lt;td&amp;gt;春节,又重了&amp;lt;/td&amp;gt;
&lt;span&gt;25&lt;/span&gt;         &amp;lt;/tr&amp;gt;
&lt;span&gt;26&lt;/span&gt;     &amp;lt;/tbody&amp;gt;
&lt;span&gt;27&lt;/span&gt; &amp;lt;/table&amp;gt; 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;刷新一下页面&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/548134/201802/548134-20180217224433236-1995262637.png&quot; alt=&quot;&quot; width=&quot;476&quot; height=&quot;175&quot;/&gt;&lt;/p&gt;
&lt;p&gt;看起来效果还不错, 可能会注意到, 这个table有个class  &lt;span class=&quot;cnblogs_code&quot;&gt;&amp;lt;table &lt;span&gt;class&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;table table-hover&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt; ,&lt;/p&gt;
&lt;p&gt;这个class定义在哪里呢.&lt;/p&gt;
&lt;p&gt;再次打开_layout文件, 可以看到里面在Development环境下引用了bootstrap的css&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
    &amp;lt;environment include=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Development&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&amp;gt;
        &amp;lt;link rel=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;stylesheet&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; href=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;~/lib/bootstrap/dist/css/bootstrap.css&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; /&amp;gt;
        &amp;lt;link rel=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;stylesheet&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; href=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;~/css/site.css&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; /&amp;gt;
    &amp;lt;/environment&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;所以可以把一些&quot;通用&quot;的css和js的引用放在layout文件里, 避免重复写这些引用.&lt;/p&gt;
&lt;p&gt;顺便把header和footer中显示的项目名称改一下, 然后分别打开Index和About这些页面, Header和Footer都统一改变了.&lt;/p&gt;
&lt;p&gt;如下图的About页面.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/548134/201802/548134-20180217221525137-558510817.png&quot; alt=&quot;&quot; width=&quot;498&quot; height=&quot;228&quot;/&gt;&lt;/p&gt;

&lt;p&gt;但是我们在这个Index页中没有对这个模板做引用, 是通过什么方式引用的呢?&lt;/p&gt;

&lt;p&gt;回顾修改后的Index页面, 我们并没有写 &lt;span class=&quot;cnblogs_code&quot;&gt;Layout = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;_Layout&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;/span&gt; 这样的代码, 这是因为已经在_ViewStart中默认设置了&lt;/p&gt;
&lt;p&gt;_ViewStart中只有这一句&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
&lt;span&gt;@{
    Layout &lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;_Layout&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;如果我们在Index页面中添加一句 &lt;span class=&quot;cnblogs_code&quot;&gt;Layout=&lt;span&gt;null&lt;/span&gt;&lt;/span&gt; 如下,&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;@{
    Layout&lt;/span&gt;=&lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
    ViewData[&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Title&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;] = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;主页&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;再次刷新页面, 样子变成了这样&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/548134/201802/548134-20180217224206353-1532728059.png&quot; alt=&quot;&quot; width=&quot;242&quot; height=&quot;121&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Header和Footer以及Table的样式全都没有了, 是因为这些本来都写在_Layout中, 现在失去了对_Layout的引用, 这些也就消失了.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总结:&lt;/strong&gt; _ViewStart对模板页做了默认的设置, 除非显示的写明Layout=XXX, 否则会采用_ViewStart中的设置.&lt;/p&gt;
&lt;p&gt;       所以未做设置和设置 &lt;span class=&quot;cnblogs_code&quot;&gt;Layout = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;_Layout&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;/span&gt; 的效果是一样的.&lt;/p&gt;


&lt;p&gt; 加载顺序是: _ViewStart =&amp;gt;Index=&amp;gt;_Layout.&lt;/p&gt;
&lt;p&gt;1._ViewStart在所有View加载之前加载, 设置了默认的模板页.&lt;/p&gt;
&lt;p&gt;2.接着由Controller指定的页面查找Index.cshtml加载, 并读取该页面的Layout设置. &lt;/p&gt;
&lt;p&gt;3.根据Index页面的Layout设置的模板页查找对应的模板页加载.&lt;/p&gt;
&lt;p&gt;将_ViewStart中的 &lt;span class=&quot;cnblogs_code&quot;&gt;Layout = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;_Layout&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;/span&gt; 改为 &lt;span class=&quot;cnblogs_code&quot;&gt;Layout = &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;_Layout1&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;/span&gt; , 再次运行, 页面会出现如下找不到模板的错误.&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
An unhandled exception occurred &lt;span&gt;while&lt;/span&gt;&lt;span&gt; processing the request.

InvalidOperationException: The layout view &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;_Layout1&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt; could not be located. The following locations were searched:
&lt;/span&gt;/Views/Home/&lt;span&gt;_Layout1.cshtml
&lt;/span&gt;/Views/Shared/&lt;span&gt;_Layout1.cshtml
Microsoft.AspNetCore.Mvc.Razor.RazorView.GetLayoutPage(ViewContext context, &lt;/span&gt;&lt;span&gt;string&lt;/span&gt; executingFilePath, &lt;span&gt;string&lt;/span&gt; layoutPath)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;View的查找规则:&lt;/strong&gt; 先查找Controller对应的文件夹(这里是Home), 若未找到则到Shared文件夹查找, 若最终未找到则提示错误.&lt;/p&gt;
</description>
<pubDate>Sun, 18 Feb 2018 01:59:00 +0000</pubDate>
<dc:creator>FlyLolo</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/FlyLolo/p/8452169.html</dc:identifier>
</item>
<item>
<title>JDK8的新特性——Lambda表达式 - OKevin</title>
<link>http://www.cnblogs.com/yulinfeng/p/8452379.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yulinfeng/p/8452379.html</guid>
<description>&lt;p&gt;　　JDK8已经发布快4年的时间了，现在来谈它的新特性显得略微的有点“不合时宜”。尽管JDK8已不再“新”，但它的重要特性之一——Lambda表达式依然是不被大部分开发者所熟练运用，甚至不被开发者所熟知。&lt;/p&gt;
&lt;p&gt;　　国内的开发环境大家都知道，有各种的老项目，有各种各样的发布风险，让公司以及项目组对新的技术往往望而却步，有公司甚至时至今日还在使用JDK6来进行项目开发，这导致了在很多技术的选择上受到了很大限制，进而不能跟随时代的脚步使得项目甚至公司一步一步走向衰落。&lt;/p&gt;
&lt;p&gt;　　本文简单认识JDK8的重要新特性之一——Lambda表达式。 在JDK8之前，Java是不支持函数式编程的，所谓的函数编程，即可理解是将一个函数（也称为“行为”）作为一个参数进行传递。通常我们提及得更多的是面向对象编程，面向对象编程是对数据的抽象（各种各样的POJO类），而函数式编程则是对行为的抽象（将行为作为一个参数进行传递）。在JavaScript中这是很常见的一个语法特性，但在Java中将一个函数作为参数传递这却行不通，好在JDK8的出现打破了Java的这一限制。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;认识Lambda表达式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　&lt;/strong&gt;首先来引入一个示例，不知给是否有在IDEA编写代码的经历，如果在JDK8的环境下如下所示按照Java传统的语法规则编写一个线程。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;new&lt;/span&gt; Thread(&lt;span&gt;new&lt;/span&gt;&lt;span&gt; Runnable() {
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;    @Override
&lt;/span&gt;&lt;span&gt;3&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; run() {
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt;         System.out.println(&quot;Hello World!&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt; });
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　IDEA会给出提示可以使用Lambda表达式替换。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/630246/201802/630246-20180218000826703-1226076574.png&quot; alt=&quot;&quot; width=&quot;576&quot; height=&quot;188&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　使用Lambda表达式则只需要使用一句话就可代替上面使用匿名类的方式。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;new&lt;/span&gt; Thread(() -&amp;gt; System.out.println(&quot;Hello World!&quot;));
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; 　　在这个例子中，传统的语法规则，我们是将一个匿名内部类作为参数进行传递，我们实现了Runnable接口，并将其作为参数传递给Thread类，这实际上我们传递的是一段代码，也即我们将代码作为了数据进行传递，这就带来许多不必要的“样板代码”。&lt;/p&gt;
&lt;p&gt;　　Lambda表达式一共有三部分组成：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/630246/201802/630246-20180218001032906-1130608891.png&quot; alt=&quot;&quot; width=&quot;567&quot; height=&quot;157&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　后面的示例中我们会详解这个结构，包括有无参数，有无返回值的问题。 那么这个看起来奇奇怪怪的不太像Java的语法规则，其本身含义到底什么呢？这也是开始困扰我的问题，什么时候在什么场景下可以使用Lambda表达式。&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;能够接收Lambda表达式的参数类型，是一个只包含一个方法的接口。&lt;/strong&gt;只包含一个方法的接口称之为“&lt;strong&gt;函数接口&lt;/strong&gt;”。&lt;/p&gt;
&lt;p&gt;　　例如上面创建一个线程的示例，Runnable接口只包含一个方法，所以它被称为“函数接口”，所以它可以使用Lambad表达式来代替匿名内部类。根据这个规则，我们试着来写一个函数接口，并使用Lambda表达式作为参数传递。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;package&lt;/span&gt;&lt;span&gt; com.coderbuff.custom;
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; 
&lt;span&gt;3&lt;/span&gt; &lt;span&gt;/**&lt;/span&gt;
&lt;span&gt;4&lt;/span&gt; &lt;span&gt; * 函数接口：只有一个方法的接口。作为Lambda表达式的类型
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; &lt;span&gt; * Created by Kevin on 2018/2/17.
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt;  &lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;7&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; FunctionInterface {
&lt;/span&gt;&lt;span&gt;8&lt;/span&gt;     &lt;span&gt;void&lt;/span&gt;&lt;span&gt; test();
&lt;/span&gt;&lt;span&gt;9&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; 　　测试：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;package&lt;/span&gt;&lt;span&gt; com.coderbuff.custom;
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; 
&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.junit.Test;
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; 
&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;/**&lt;/span&gt;
&lt;span&gt; 6&lt;/span&gt; &lt;span&gt; * 函数接口测试
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt; * Created by Kevin on 2018/2/17.
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;  &lt;span&gt;*/&lt;/span&gt;
&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; FunctionInterfaceTest {
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; 
&lt;span&gt;11&lt;/span&gt; &lt;span&gt;    @Test
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; testLambda() {
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;         func(&lt;span&gt;new&lt;/span&gt;&lt;span&gt; FunctionInterface() {
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt; &lt;span&gt;            @Override
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt;             &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; test() {
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt;                 System.out.println(&quot;Hello World!&quot;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt; &lt;span&gt;        });
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;使用Lambda表达式代替上面的匿名内部类&lt;/span&gt;
&lt;span&gt;20&lt;/span&gt;         func(&lt;strong&gt;() -&amp;gt; System.out.println(&quot;Hello World&quot;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;)&lt;/strong&gt;);
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; 
&lt;span&gt;23&lt;/span&gt;     &lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; func(FunctionInterface functionInterface) {
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt; &lt;span&gt;        functionInterface.test();
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;26&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　可以看到，只要是一个接口中只包含一个方法，则可以使用Lambda表达式，这样的接口称之为“函数接口”。&lt;/p&gt;
&lt;p&gt;　　上面的函数接口比较简单&lt;strong&gt;不包含参数，也不包含返回值&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;　　我们再来修改FunctionInterface函数接口逐步加大Lambda表达式的难度——&lt;strong&gt;包含参数，不包含返回值&lt;/strong&gt;。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;package&lt;/span&gt;&lt;span&gt; com.coderbuff.custom;
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; 
&lt;span&gt;3&lt;/span&gt; &lt;span&gt;/**&lt;/span&gt;
&lt;span&gt;4&lt;/span&gt; &lt;span&gt; * 函数接口：只有一个方法的接口。作为Lambda表达式的类型
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; &lt;span&gt; * Created by Kevin on 2018/2/17.
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt;  &lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;7&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; FunctionInterface {
&lt;/span&gt;&lt;span&gt;8&lt;/span&gt;     &lt;span&gt;void&lt;/span&gt; test(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; param);
&lt;/span&gt;&lt;span&gt;9&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　测试：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;package&lt;/span&gt;&lt;span&gt; com.coderbuff.custom;
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; 
&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.junit.Test;
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; 
&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;/**&lt;/span&gt;
&lt;span&gt; 6&lt;/span&gt; &lt;span&gt; * 函数接口测试
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt; * Created by Kevin on 2018/2/17.
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;  &lt;span&gt;*/&lt;/span&gt;
&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; FunctionInterfaceTest {
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; 
&lt;span&gt;11&lt;/span&gt; &lt;span&gt;    @Test
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; testLambda() {
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;使用Lambda表达式代替匿名内部类&lt;/span&gt;
&lt;span&gt;14&lt;/span&gt;         func(&lt;strong&gt;(x) -&amp;gt; System.out.println(&quot;Hello World&quot; +&lt;/strong&gt;&lt;span&gt;&lt;strong&gt; x)&lt;/strong&gt;);
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; 
&lt;span&gt;17&lt;/span&gt;     &lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; func(FunctionInterface functionInterface) {
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;         &lt;span&gt;int&lt;/span&gt; x = 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;        functionInterface.test(x);
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　关注Lambda表达式“(x) -&amp;gt; Sysout.out.println(&quot;Hello World&quot; + x)”，左边传递的是参数，此处并没有指明参数类型，因为它可以通过上下文进行类型推导，但在有些情况下不能推导出参数类型（在编译时不能推导通常IDE会提示），此时则需要指明参数类型。&lt;strong&gt;我个人建议，任何情况下指明函数的参数类型&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;　　哪种情况不能推导出参数类型呢？就是函数接口是一个泛型的时候。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;package&lt;/span&gt;&lt;span&gt; com.coderbuff.custom;
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; 
&lt;span&gt;3&lt;/span&gt; &lt;span&gt;/**&lt;/span&gt;
&lt;span&gt;4&lt;/span&gt; &lt;span&gt; * 函数接口：只有一个方法的接口。作为Lambda表达式的类型
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; &lt;span&gt; * Created by Kevin on 2018/2/17.
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt;  &lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;7&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;interface&lt;/span&gt; FunctionInterface&amp;lt;T&amp;gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;8&lt;/span&gt;     &lt;span&gt;void&lt;/span&gt;&lt;span&gt; test(T param);
&lt;/span&gt;&lt;span&gt;9&lt;/span&gt; }　
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　测试：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;package&lt;/span&gt;&lt;span&gt; com.coderbuff.custom;
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; 
&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.junit.Test;
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; 
&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;/**&lt;/span&gt;
&lt;span&gt; 6&lt;/span&gt; &lt;span&gt; * 函数接口测试
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt; * Created by Kevin on 2018/2/17.
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;  &lt;span&gt;*/&lt;/span&gt;
&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; FunctionInterfaceTest {
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; 
&lt;span&gt;11&lt;/span&gt; &lt;span&gt;    @Test
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; testLambda() {
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;使用Lambda表达式代替匿名内部类&lt;/span&gt;
&lt;span&gt;14&lt;/span&gt;         func(&lt;strong&gt;(Integer x) -&amp;gt; System.out.println(&quot;Hello World&quot; +&lt;/strong&gt;&lt;span&gt;&lt;strong&gt; x)&lt;/strong&gt;);
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; 
&lt;span&gt;17&lt;/span&gt;     &lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; func(FunctionInterface&amp;lt;Integer&amp;gt;&lt;span&gt; functionInterface) {
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;         &lt;span&gt;int&lt;/span&gt; x = 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;        functionInterface.test(x);
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　上面的示例提到了Lambda表达式的两种情况：&lt;/p&gt;
&lt;p&gt;　　&lt;strong&gt;无参数，无返回值；&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　有参数，无返回值。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　接下来就是&lt;strong&gt;有参数，有返回值&lt;/strong&gt;这种较为复杂的情况。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;package&lt;/span&gt;&lt;span&gt; com.coderbuff.custom;
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; 
&lt;span&gt;3&lt;/span&gt; &lt;span&gt;/**&lt;/span&gt;
&lt;span&gt;4&lt;/span&gt; &lt;span&gt; * 函数接口：只有一个方法的接口。作为Lambda表达式的类型
&lt;/span&gt;&lt;span&gt;5&lt;/span&gt; &lt;span&gt; * Created by Kevin on 2018/2/17.
&lt;/span&gt;&lt;span&gt;6&lt;/span&gt;  &lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;7&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;interface&lt;/span&gt; FunctionInterface&amp;lt;T&amp;gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;8&lt;/span&gt;     &lt;span&gt;boolean&lt;/span&gt;&lt;span&gt; test(T param);
&lt;/span&gt;&lt;span&gt;9&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; 　　测试：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;package&lt;/span&gt;&lt;span&gt; com.coderbuff.custom;
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; 
&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.junit.Test;
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; 
&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;/**&lt;/span&gt;
&lt;span&gt; 6&lt;/span&gt; &lt;span&gt; * 函数接口测试
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt; * Created by Kevin on 2018/2/17.
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt;  &lt;span&gt;*/&lt;/span&gt;
&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; FunctionInterfaceTest {
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; 
&lt;span&gt;11&lt;/span&gt; &lt;span&gt;    @Test
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;     &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; testLambda() {
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;         &lt;span&gt;//&lt;/span&gt;&lt;span&gt;使用Lambda表达式代替匿名内部类&lt;/span&gt;
&lt;span&gt;14&lt;/span&gt;         func(&lt;strong&gt;(Integer x) -&amp;gt; &lt;span&gt;true&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; 
&lt;span&gt;17&lt;/span&gt;     &lt;span&gt;private&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; func(FunctionInterface&amp;lt;Integer&amp;gt;&lt;span&gt; functionInterface) {
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt;         &lt;span&gt;int&lt;/span&gt; x = 1&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; &lt;span&gt;        functionInterface.test(x);
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; }
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　此时的Lambda表达式“(Integer x) -&amp;gt; true”，右边是表达式的主体，直接返回true，如果有多行代码，则可以直接使用花括号表示，例如：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
func(&lt;strong&gt;(Integer x) -&amp;gt;&lt;span&gt; {
    System.out.println(&lt;/span&gt;&quot;Hello World&quot; +&lt;span&gt; x);
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;true&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;strong&gt;;
}&lt;/strong&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　Lambda表达式基本的语法规则：&lt;/p&gt;
&lt;p&gt;　　无参数，无返回值；&lt;/p&gt;
&lt;p&gt;　　有参数，无返回值；&lt;/p&gt;
&lt;p&gt;　　有参数，有返回值。&lt;/p&gt;
&lt;p&gt;　　这三种基本情况已经大致清楚了，特别是需要弄清，什么时候可以使用Lambda表达式代替匿名内部类，也就是Lambda表达式的应用场景是函数接口。Lambda表达式这一新特性在JDK8中的引入，更大的好处则是集合API的更新，新增的Stream类库，使得我们在遍历使用集合时不再像以往那样不断地使用for循环。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;JDK8使用集合的正确姿势&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　示例：计算来自“chengdu”的学生数量有多少。&lt;/p&gt;
&lt;p&gt;　　在JDK8前的代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;for&lt;/span&gt;&lt;span&gt; (Student student : studentList) {
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (student.getCity().equals(&quot;chengdu&quot;&lt;span&gt;)) {
        count&lt;/span&gt;++&lt;span&gt;;
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　JDK8使用集合的正确姿势：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
count = &lt;strong&gt;studentList.stream().filter((student -&amp;gt; student.getCity().equals(&quot;chengdu&quot;))).count()&lt;/strong&gt;;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　API的使用“难度”恰似提高了，实际只是不熟悉而已。传统迭代的方式需要阅读完整个循环才能明白代码逻辑，JDK8通过流的方式则可以望文生义且代码量大大减小。&lt;/p&gt;
&lt;p&gt;　　其中最为重要的是——Stream流。Stream的是通过函数式编程方式实现的在集合类上进行复杂操作的工具。若要详细讲解Stream的实现方式我相信再写一篇博客也不为过，所以此处不再考查Stream的内部实现。这里是想告诉大家，如果有幸使用JDK8的开发环境进行开发，尽量学习使用新的集合操作API。&lt;/p&gt;
&lt;p&gt;　　上面对于Lambda表达式以及函数式编程仅仅只是到了一个“认识”的地步，似乎只是感受到了缩小代码量，本文对于Lambda式的认识不深入更多的是对于后面更多的知识做一个铺垫或者作为一个扫盲贴，有关Lambda表达式的应用太多，并发编程、响应式编程等等。如果你有关于Lambda表达式或者函数式编程有更好的见解不妨留下评论。&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;这是一个能给程序员加buff的公众号 &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/630246/201710/630246-20171018224424427-1683168589.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 17 Feb 2018 16:20:00 +0000</pubDate>
<dc:creator>OKevin</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/yulinfeng/p/8452379.html</dc:identifier>
</item>
<item>
<title>R语言-选择样本数量 - 月上贺兰</title>
<link>http://www.cnblogs.com/luhuajun/p/8452377.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/luhuajun/p/8452377.html</guid>
<description>&lt;p&gt;功效分析:可以帮助在给定置信度的情况下,判断检测到给定效应值时所需的样本量,也可以在给定置信水平的情况下,计算某样本量内可以检测到的给定效应值的概率&lt;/p&gt;
&lt;p&gt;1.t检验&lt;/p&gt;
&lt;p&gt;　　案例:使用手机和司机反应时间的实验&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;library(pwr)
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; n表示样本大小&lt;/span&gt;
&lt;span&gt;3&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; d表示标准化均值之差&lt;/span&gt;
&lt;span&gt;4&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; sig.level表示显著性水平&lt;/span&gt;
&lt;span&gt;5&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; power为功效水平&lt;/span&gt;
&lt;span&gt;6&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; type指的是检验类型&lt;/span&gt;
&lt;span&gt;7&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; alternative指的是双侧检验还是单侧检验&lt;/span&gt;
&lt;span&gt;8&lt;/span&gt; pwr.t.test(d=.8,sig.level = .05,power = .9,type = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;two.sample&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,alternative = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;two.sided&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1173792/201802/1173792-20180217233314421-175958414.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　结论:每组需要34个样本(68)人才能保证有90%的把握检测到0.8效应值,并且最多5%会存在误差&lt;/p&gt;
&lt;p&gt;2.方差分析&lt;/p&gt;
&lt;p&gt;　　案例:对5组数据做方差分析,达到0.8的功效,效应值为0.25,选择0.5的显著水平.计算总体样本的大小&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#&lt;/span&gt;&lt;span&gt; k表示组的个数&lt;/span&gt;&lt;span&gt;
#&lt;/span&gt;&lt;span&gt; f表示效应值&lt;/span&gt;
pwr.anova.test(k=5,f=.25,sig.level = .05,power = .8)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1173792/201802/1173792-20180217234433500-1460140112.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　结论:需要39*5,195受试者参与实验才能得出以上结果&lt;/p&gt;
&lt;p&gt;3.相关性&lt;/p&gt;
&lt;p&gt;　　案例:抑郁症和孤独的关系,零假设和研究假设为&lt;/p&gt;
&lt;p&gt;　　　　 H0:p&amp;lt;=0.25和H1:p&amp;gt;0.25&lt;/p&gt;
&lt;p&gt;　　　　设定显著水平为0.05,耳光拒绝零假设,希望有90%的信息拒绝H0,需要多少测试者&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; r表示效应值&lt;/span&gt;
&lt;span&gt;2&lt;/span&gt; pwr.r.test(r=.25,sig.level = .05,power = .90,alternative = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;greater&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1173792/201802/1173792-20180217235054609-225760778.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　结论:需要134名受试者参与实验&lt;/p&gt;
&lt;p&gt;4.线性模型&lt;/p&gt;
&lt;p&gt;　　案例:老板的领导风格对员工满意度的影响,薪水和小费能解释30%员工满意度方差,领导风格能解释35%的方差,&lt;/p&gt;
&lt;p&gt;　　　　  要达到90%置信度下,显著水平为0.05,需要多少受试者才能达到方差贡献率&lt;/p&gt;
&lt;p&gt;　　f2 = (0.35-0.3)/(1-0.35)=0.0769&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; u表示分子自由度&lt;/span&gt;
&lt;span&gt;2&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; v表示分母自由度&lt;/span&gt;
&lt;span&gt;3&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; f2表示效应值&lt;/span&gt;
&lt;span&gt;4&lt;/span&gt; pwr.f2.test(u=3,f2=0.0769,sig.level = .05,power = .90)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1173792/201802/1173792-20180218000022765-2123891470.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　结论:v=总体样本-预测变量-1,所以N=v+7+1=187+7+1=193&lt;/p&gt;
&lt;p&gt;5.比例检验&lt;/p&gt;
&lt;p&gt;　　案例:某种药物有60%的治愈率,新药有65%的治愈率,现在有多少受试者才能体会到两种药物的差异&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; pwr.2p.test(h=ES.h(.65,.6),sig.level = .05,power = .9,alternative = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;greater&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1173792/201802/1173792-20180218000352531-1402053669.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　结论:本案例中使用单边检验,得出需要1605名受试者才能得出两种药品的区别&lt;/p&gt;
&lt;p&gt;6.卡方检验&lt;/p&gt;
&lt;p&gt;　　卡方检验用来评价两个变量之间的关系,零假设是变量之间独立,拒绝零假设是变量不独立&lt;/p&gt;
&lt;p&gt;　　案例:研究晋升和种族的关系:样本中70%是白人,10%黑人,20%西班牙裔,相比20%的黑人和50%的西班牙裔,60%的白人更容易获得晋升&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;45&quot;&gt;
&lt;pre&gt;
&lt;span&gt;1&lt;/span&gt; prob &amp;lt;- matrix(c(.42,.28,.03,.07,.10,.10),byrow = T,nrow = 3&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;2&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 计算双因素列连表中的备择假设的效应值&lt;/span&gt;
&lt;span&gt;3&lt;/span&gt; &lt;span&gt;ES.w2(prob)
&lt;/span&gt;&lt;span&gt;4&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; w是效应值,&lt;/span&gt;
&lt;span&gt;5&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; df是自由度&lt;/span&gt;
&lt;span&gt;6&lt;/span&gt; pwr.chisq.test(w=0.1853198,df=2,sig.level = .05,power = .90)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1173792/201802/1173792-20180218000950578-157303240.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　结论:该实验需要369名测试者才能证明晋升和种族存在关联&lt;/p&gt;
&lt;p&gt;7.在新的情况下选择合适的效应值&lt;/p&gt;
&lt;p&gt;　　7.1单因素&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;47&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; es &amp;lt;- seq(.1,.5,.01&lt;span&gt;)
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; nes &amp;lt;-&lt;span&gt; length(es)
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; samsize &amp;lt;-&lt;span&gt; NULL
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;(i &lt;span&gt;in&lt;/span&gt; 1&lt;span&gt;:nes){
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt;   result &amp;lt;- pwr.anova.test(k=5,f=es[i],sig.level = .05,power = .90&lt;span&gt;)
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt;   samsize[i] &amp;lt;-&lt;span&gt; ceiling(result$n)
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;}
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; plot(samsize,es,type=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;l&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,lwd=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;2&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,col=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;red&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;,
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;      ylab = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;Effect Size&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;,
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;      xlab = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;Sample Szie&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;,
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;      main = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;One way Anova with power=.90 and alpha=.05&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1173792/201802/1173792-20180218001136203-95920441.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　结论:赝本数量高于200时,在增加样本是效果不明显&lt;/p&gt;
&lt;p&gt;　　7.2 绘制功效分析图&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;68&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 1.生成一系列相关系数和功效值&lt;/span&gt;
&lt;span&gt; 2&lt;/span&gt; r &amp;lt;- seq(.1,.5,.01&lt;span&gt;)
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; nr &amp;lt;-&lt;span&gt; length(r)
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; 
&lt;span&gt; 5&lt;/span&gt; p &amp;lt;- seq(.4,.9,.1&lt;span&gt;)
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; np &amp;lt;-&lt;span&gt; length(p)
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; 
&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 2.获取样本大小&lt;/span&gt;
&lt;span&gt; 9&lt;/span&gt; samsize &amp;lt;- array(numeric(nr*np),dim =&lt;span&gt; c(nr,np))
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; 
&lt;span&gt;11&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;(i &lt;span&gt;in&lt;/span&gt; 1&lt;span&gt;:np){
&lt;/span&gt;&lt;span&gt;12&lt;/span&gt;   &lt;span&gt;for&lt;/span&gt;(j &lt;span&gt;in&lt;/span&gt; 1&lt;span&gt;:nr){
&lt;/span&gt;&lt;span&gt;13&lt;/span&gt;     result &amp;lt;- pwr.r.test(n=NULL,r=r[j],sig.level = .05,power = p[i],alternative = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;two.sided&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;14&lt;/span&gt;     samsize[j,i] &amp;lt;-&lt;span&gt; ceiling(result$n)
&lt;/span&gt;&lt;span&gt;15&lt;/span&gt; &lt;span&gt;  }
&lt;/span&gt;&lt;span&gt;16&lt;/span&gt; &lt;span&gt;}
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; 
&lt;span&gt;18&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 3.创建图形&lt;/span&gt;
&lt;span&gt;19&lt;/span&gt; xrange &amp;lt;-&lt;span&gt; range(r)
&lt;/span&gt;&lt;span&gt;20&lt;/span&gt; yrange &amp;lt;-&lt;span&gt; round(range(samsize))
&lt;/span&gt;&lt;span&gt;21&lt;/span&gt; colors &amp;lt;-&lt;span&gt; rainbow(length(p))
&lt;/span&gt;&lt;span&gt;22&lt;/span&gt; plot(xrange,yrange,type=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;n&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;,
&lt;/span&gt;&lt;span&gt;23&lt;/span&gt;      xlab = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;Corrlation Coefficient&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;,
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt;      ylab = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;Sample Size&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 4.添加功效曲线&lt;/span&gt;
&lt;span&gt;26&lt;/span&gt; &lt;span&gt;for&lt;/span&gt;(i &lt;span&gt;in&lt;/span&gt; 1&lt;span&gt;:np){
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt;   lines(r,samsize[,i],type=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;l&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,lwd=2,col=&lt;span&gt;colors[i])
&lt;/span&gt;&lt;span&gt;28&lt;/span&gt; &lt;span&gt;}
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 5.网格线&lt;/span&gt;
&lt;span&gt;30&lt;/span&gt; abline(v=0,h=seq(0,yrange[2],50),lty=2,col=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;grey89&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;31&lt;/span&gt; abline(h=0,v=seq(xrange[1],xrange[2],.02),lty=2,col=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;grey89&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;32&lt;/span&gt; &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 6.标题和注释&lt;/span&gt;
&lt;span&gt;33&lt;/span&gt; title(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;Sample Size Estimation for Corrlation\nSig=0.05&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;34&lt;/span&gt; legend(&lt;span&gt;'&lt;/span&gt;&lt;span&gt;topright&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,title = &lt;span&gt;'&lt;/span&gt;&lt;span&gt;Power&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;,as.character(p),fill=colors)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1173792/201802/1173792-20180218001549203-337765991.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; 　　结论:在40%的置信度下,要检测到0.2的相关性需要约75个样本,在90%的置信度下,要检测到相同的相关性需要大约260个样本&lt;/p&gt;

</description>
<pubDate>Sat, 17 Feb 2018 16:19:00 +0000</pubDate>
<dc:creator>月上贺兰</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/luhuajun/p/8452377.html</dc:identifier>
</item>
<item>
<title>剑指offer试题（PHP篇二） - zlnevsto</title>
<link>http://www.cnblogs.com/zlnevsto/p/8452370.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zlnevsto/p/8452370.html</guid>
<description>&lt;p&gt;&lt;strong&gt;6.旋转数组的最小数字&lt;/strong&gt;&lt;/p&gt;
&lt;h2 class=&quot;subject-item-title&quot;&gt;题目描述&lt;/h2&gt;
&lt;div class=&quot;subject-describe&quot; readability=&quot;29&quot;&gt;
&lt;p&gt;把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。 输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。 例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。 NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。&lt;/p&gt;
&lt;p&gt;时间限制：3秒   空间限制：32768K&lt;/p&gt;
&lt;div readability=&quot;35&quot;&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;38&quot;&gt;
&lt;pre class=&quot;brush:php;gutter:true;&quot;&gt;
&amp;lt;?php

function minNumberInRotateArray($rotateArray)
{
    // write code here
    /*
    if(count($rotateArray) == 0){
        return 0;
    }
    $min = min($rotateArray);
    foreach($rotateArray as $k=&amp;gt;$v){
        if($v == $min){
            $arrLeft[] = array_slice($rotateaArray,0,$k+1);
            $arrRight[] = array_slice($rotateArray,$k+1);
        }
    }
    弄了半天不是让输出翻转后的数组。。。。
    */
    if(count($rotateArray)){
        return min($rotateArray);
    }else{
        return 0;
    }
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;运行时间：985ms   占用内存：5156k&lt;/p&gt;
&lt;p&gt;感悟：&lt;/p&gt;
&lt;p&gt;　　这道题告诉我一定要审题审题审题=  =|，本来自己在一味的求解反转后的数组，结果不知什么时候一看，发现只是让求最小数，对于php而言太简单了。。。不过对于这道题，还是要提醒大家细心（汗）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;7.斐波那契数列&lt;/strong&gt;&lt;/p&gt;
&lt;h2 class=&quot;subject-item-title&quot;&gt;题目描述&lt;/h2&gt;
&lt;div class=&quot;subject-describe&quot; readability=&quot;20.5&quot;&gt;大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项。
&lt;p&gt;n&amp;lt;=39&lt;/p&gt;
&lt;p&gt;时间限制：1秒   空间限制：32768K&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:php;gutter:true;&quot;&gt;
&amp;lt;?php

function Fibonacci($n)
{
    // write code here
    if($n &amp;lt; 0 || $n &amp;gt; 39)
        return false;
    $ret = [];
    for($i = 0; $i &amp;lt;= $n; $i++){
        if($i == 0){
            $ret[$i] = 0;
            continue;
        }elseif($i == 1){
            $ret[$i] = 1;
            continue;
        }
        $ret[$i] = $ret[$i-1]+$ret[$i-2];
    }
    return $ret[$n];
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;运行时间：15ms   占用内存：2316k&lt;/p&gt;
&lt;p&gt;感悟：&lt;/p&gt;
&lt;p&gt;　　这道题，只要理解斐波那契数列，知道用递归来实现就完全ok，再说思路，首先，排除掉不成立的情况，其次，将0和1的特殊情况拿出来单独赋值，最后，就是一般情况的循环递归。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;8.跳台阶&lt;/strong&gt;&lt;/p&gt;
&lt;h2 class=&quot;subject-item-title&quot;&gt;题目描述&lt;/h2&gt;
&lt;div class=&quot;subject-describe&quot; readability=&quot;10&quot;&gt;
&lt;p&gt;一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法。&lt;/p&gt;
&lt;p&gt;时间限制：1秒   空间限制：32768K&lt;/p&gt;
&lt;div readability=&quot;7&quot;&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:php;gutter:true;&quot;&gt;
&amp;lt;?php

function jumpFloor($number)
{
    // write code here
    $arr = [];
    for($i=1;$i&amp;lt;=$number;$i++){
        if($i==1){
            $arr[1]=1;
            continue;
        }
        if($i==2){
            $arr[2]=2;
            continue;
        }
        $arr[$i]=$arr[$i-1]+$arr[$i-2];
    }
    return $arr[$number];
}
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;运行时间：9ms   占用内存：2316k&lt;/p&gt;
&lt;p&gt;感悟：&lt;/p&gt;
&lt;p&gt;　　唯一的感受。。竟然撞题了= =，不废话，这道题按照一般的思路有些难解，但换种想法，比较倾向于找规律的解法，f(1) = 1, f(2) = 2, f(3) = 3, f(4) = 5，  可以总结出f(n) = f(n-1) + f(n-2)的规律，但是为什么会出现这样的规律呢？假设现在6个台阶，我们可以从第5跳一步到6，这样的话有多少种方案跳到5就有多少种方案跳到6，另外我们也可以从4跳两步跳到6，跳到4有多少种方案的话，就有多少种方案跳到6，其他的不能从3跳到6什么的啦，所以最后就是f(6) = f(5) + f(4)；这样子也很好理解变态跳台阶的问题了，看到这里，你就会惊喜的发现！没错，就是斐波那契数列的问题，不过是少了0那种情况。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;9.变态跳台阶&lt;/strong&gt;&lt;/p&gt;
&lt;h2 class=&quot;subject-item-title&quot;&gt;题目描述&lt;/h2&gt;
&lt;div class=&quot;subject-describe&quot; readability=&quot;17.5&quot;&gt;
&lt;p&gt;一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。&lt;/p&gt;
&lt;p&gt;时间限制：1秒   空间限制：32768K&lt;/p&gt;
&lt;div readability=&quot;26&quot;&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:php;gutter:true;&quot;&gt;
&amp;lt;?php
 
function jumpFloorII($number)
{
    // write code here
    if($number == 1) return 1;
    return pow(2,($number - 1));
}　　
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;运行时间：24ms   占用内存：2936k&lt;/p&gt;
&lt;p&gt;感悟：&lt;/p&gt;
&lt;p&gt;　　因为n级台阶，第一步有n种跳法：跳1级、跳2级、到跳n级；&lt;/p&gt;
&lt;p&gt;　　跳1级，剩下n-1级，则剩下跳法是f(n-1)；&lt;/p&gt;
&lt;p&gt;　　跳2级，剩下n-2级，则剩下跳法是f(n-2)，&lt;/p&gt;
&lt;p&gt;所以f(n)=f(n-1)+f(n-2)+...+f(1)，因为f(n-1)=f(n-2)+f(n-3)+...+f(1)，所以f(n)=2*f(n-1)&lt;/p&gt;
&lt;p&gt;所以，f(n)=2的n-1次方。&lt;/p&gt;
&lt;p&gt;当然，还要知道php的pow(x,y)函数，返回 x 的 y 次方。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;10.矩形覆盖&lt;/strong&gt;&lt;/p&gt;
&lt;h2 class=&quot;subject-item-title&quot;&gt;题目描述&lt;/h2&gt;
&lt;div class=&quot;subject-describe&quot; readability=&quot;30.5&quot;&gt;
&lt;p&gt;我们可以用2*1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2*1的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？&lt;/p&gt;
&lt;p&gt;时间限制：1秒   空间限制：32768K&lt;/p&gt;
&lt;div readability=&quot;7&quot;&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:php;gutter:true;&quot;&gt;
&amp;lt;?php

function rectCover($number)
{
    // write code here
    if($number==0){
        return 0;
    }
     $arr = [];
    for($i=1;$i&amp;lt;=$number;$i++){
        if($i==1){
            $arr[1]=1;
            continue;
        }
        if($i==2){
            $arr[2]=2;
            continue;
        }
        $arr[$i]=$arr[$i-1]+$arr[$i-2];
    }
    return $arr[$number];
}
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div readability=&quot;7&quot;&gt;
&lt;p&gt;运行时间：29ms   占用内存：2928k&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;感悟：&lt;/p&gt;
&lt;p&gt;　　走过的弯路：开始只是简单地将 n 分成奇、偶讨论，并将 2*2 作为基本单元。测试后通不过，代码就不贴出来献丑了。&lt;/p&gt;
&lt;div readability=&quot;38&quot;&gt;思路分析：痛定思痛，还是不能够贪小便宜。用归纳法归纳如下，
&lt;p&gt;（1）当 n &amp;lt; 1时，显然不需要用2*1块覆盖，按照题目提示应该返回 0。&lt;/p&gt;
&lt;p&gt;（2）当 n = 1时，只存在一种情况。&lt;/p&gt;
&lt;div&gt;&lt;img src=&quot;https://uploadfiles.nowcoder.net/images/20160821/610669_1471715163771_7D5D4E0729A4FC3E473AD660E13B782E&quot; alt=&quot;&quot;/&gt; &lt;/div&gt;
&lt;p&gt;（3）当 n = 2时，存在两种情况。&lt;/p&gt;
&lt;div&gt;&lt;img src=&quot;https://uploadfiles.nowcoder.net/images/20160821/610669_1471715305312_F22B8EBDEC046FD7D7D93725B669BF33&quot; alt=&quot;&quot;/&gt; &lt;/div&gt;
&lt;p&gt;（4）当 n = 3时，明显感觉到如果没有章法，思维难度比之前提升挺多的。&lt;/p&gt;
&lt;div&gt;&lt;img src=&quot;https://uploadfiles.nowcoder.net/images/20160821/610669_1471715340361_4A8CA1EA1EFD2C46E73DB31C97F30D48&quot; alt=&quot;&quot;/&gt; &lt;/div&gt;
&lt;p&gt;... 尝试归纳，本质上 n 覆盖方法种类都是对 n - 1 时的扩展。&lt;/p&gt;
&lt;p&gt;可以明确，n 时必定有 n-1时原来方式与2*1的方块结合。也就是说, f(n) = f(n-1) + ?(暂时无法判断)。&lt;/p&gt;
&lt;p&gt;（4）如果我们现在归纳 n = 4，应该是什么形式？&lt;/p&gt;
&lt;p&gt;4.1）保持原来n = 3时内容，并扩展一个 2*1 方块，形式分别为 “| | | |”、“= | |”、“| = |”&lt;/p&gt;
&lt;p&gt;4.2）新增加的2*1 方块与临近的2*1方块组成 2*2结构，然后可以变形成 “=”。于是 n = 4在原来n = 3基础上增加了&quot;| | =&quot;、“= =”。&lt;/p&gt;
&lt;p&gt;再自己看看这多出来的两种形式，是不是只比n = 2多了“=”。其实这就是关键点所在...因为，只要2*1或1*2有相同的两个时，就会组成2*2形式，于是就又可以变形了。&lt;/p&gt;
&lt;p&gt;所以，自然而然可以得出规律： f(n) = f(n-1) + f(n-2)， (n &amp;gt; 2)。&lt;/p&gt;
&lt;p&gt;然后这个时候，你就会惊喜的发现，又回到斐波那契数列了。。。思路不再细说，有需要的朋友可以看7题和8题。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;span&gt; 注：以上均为个人理解，如有错误，请提出，必改正。&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

</description>
<pubDate>Sat, 17 Feb 2018 16:08:00 +0000</pubDate>
<dc:creator>zlnevsto</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/zlnevsto/p/8452370.html</dc:identifier>
</item>
<item>
<title>深入JavaScript类型判定 - liuyongjia</title>
<link>http://www.cnblogs.com/liuyongjia/p/8452242.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liuyongjia/p/8452242.html</guid>
<description>&lt;h2 id=&quot;基本区分方法&quot;&gt;基本区分方法&lt;/h2&gt;
&lt;p&gt;ECMAScript标准定义了7种数据类型&lt;br/&gt;6 种 基本类型:&lt;br/&gt;Boolean，两种取值：true和false&lt;br/&gt;Null，一种取值：null&lt;br/&gt;Undefined，一种取值：undefined&lt;br/&gt;Number，JS的数值为基于 IEEE 754 标准的双精度 64 位二进制格式的值（-(263 -1) 到 263 -1）。&lt;br/&gt;String，JavaScript的字符串类型用于表示文本数据。它是一组16位的无符号整数值的“元素”。它不可改变。&lt;br/&gt;Symbol，符号是唯一的并且是不可修改的, 并且也可以用来作为Object的key。&lt;br/&gt;一种复杂类型：&lt;br/&gt;Object，可以认为Object是一种键值对的集合。Array和Function就是Object的子类型。&lt;/p&gt;
&lt;h2 id=&quot;另一种区分方法值和址&quot;&gt;另一种区分方法：值和址&lt;/h2&gt;
&lt;p&gt;从C语言过来的朋友一定常听到传值和传址这样的说法，C语言里有指针的概念，指针本质上是一个内存地址，程序员可以通过指针来修改某些内容。&lt;br/&gt;在java和JavaScript这样的类C语言中虽然没有了指针这么强大却危险的东西，但是在函数中操作变量的方式却一脉而成。&lt;br/&gt;举个例子：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;sourceCode javascript&quot;&gt;
&lt;code class=&quot;sourceCode javascript&quot;&gt;&lt;span class=&quot;kw&quot;&gt;var&lt;/span&gt; 
    globalA &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;foo&lt;/span&gt; (a) &lt;span class=&quot;op&quot;&gt;{&lt;/span&gt;
    a &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;op&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;at&quot;&gt;foo&lt;/span&gt;(globalA)&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;va&quot;&gt;console&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;log&lt;/span&gt;(globalA)&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;co&quot;&gt;//1&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在函数中，如果入参是值类型，那么函数将会在执行时上下文建立一个副本，在函数中，实际修改的这个副本，不会影响真正的原始入参。&lt;br/&gt;如果入参是值类型，也就是我们常说的引用类型，那么将直接操作所引用的对象，也就是所说的，通过地址操作值。&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;sourceCode javascript&quot;&gt;
&lt;code class=&quot;sourceCode javascript&quot;&gt;&lt;span class=&quot;kw&quot;&gt;var&lt;/span&gt;
    obj &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;foo2&lt;/span&gt; (o) &lt;span class=&quot;op&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;va&quot;&gt;o&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;op&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;at&quot;&gt;ArrFoo&lt;/span&gt;(obj)&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;va&quot;&gt;console&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;log&lt;/span&gt;(obj)&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;co&quot;&gt;//{a:2}&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;此处需要注意的一点是，函数的形参o虽然是引用类型，但是它也是一个执行上下文中建立的副本，如果直接将它重新赋值，例如&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot;&gt;
&lt;pre class=&quot;sourceCode javascript&quot;&gt;
&lt;code class=&quot;sourceCode javascript&quot;&gt;o &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;};&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这种写法是不能影响到原始的入参的，执行完毕以后，原始的obj不会被修改。&lt;br/&gt;上面提到的是我们不论在C还是Java中也会涉及的一些传址传值的基本概念。&lt;br/&gt;但是在JavaScript中有一些特别的地方。&lt;/p&gt;
&lt;h3 id=&quot;每个函数都可能是构造函数&quot;&gt;每个函数都可能是构造函数&lt;/h3&gt;
&lt;p&gt;值和址一般是在入参里做体现，出参方面，按照正常理解即可。由于JavaScript的原型链特点，每个函数都可能是构造函数。在构造函数中，情况稍有不同。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;构造函数中带有return语句，如果return的是：&lt;br/&gt;值类型，那么构造函数会忽略掉这个值，返回构造的新对象；&lt;br/&gt;引用类型(数组、函数、对象)，那么构造函数就会直接返回该引用类型；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode javascript&quot;&gt;
&lt;code class=&quot;sourceCode javascript&quot;&gt;&lt;span class=&quot;co&quot;&gt;// 因为Super1返回的 123 是值类型，它被丢弃，直接返回构造对象&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;Super1&lt;/span&gt;(a)&lt;span class=&quot;op&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kw&quot;&gt;this&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;a&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;cf&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;123&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;          &lt;span class=&quot;co&quot;&gt;// 将return语句注释掉也没影响&lt;/span&gt;
&lt;span class=&quot;op&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;va&quot;&gt;Super1&lt;/span&gt;.&lt;span class=&quot;va&quot;&gt;prototype&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;sayHello&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt;()&lt;span class=&quot;op&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;va&quot;&gt;console&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;log&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&quot;Hello&quot;&lt;/span&gt;)
&lt;span class=&quot;op&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;va&quot;&gt;console&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;log&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;Super1&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;))&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;// Super2直接返回了对象，而前面构造函数的所有操作全被丢弃&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;// 包括它的构造函数、原型链全部都没有返回&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;Super2&lt;/span&gt;(a)&lt;span class=&quot;op&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kw&quot;&gt;this&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;a&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;cf&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;op&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;va&quot;&gt;Super2&lt;/span&gt;.&lt;span class=&quot;va&quot;&gt;prototype&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;sayHello&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt;()&lt;span class=&quot;op&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;va&quot;&gt;console&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;log&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&quot;Hello&quot;&lt;/span&gt;)
&lt;span class=&quot;op&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;va&quot;&gt;console&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;log&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;Super2&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;))&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;换言之，如果是return的是值类型，return则没什么作用；如果是引用类型，则对构造对象的任何操作不生效，直接返回原来的引用对象。&lt;/p&gt;

&lt;p&gt;其实js有一个自带的操作符专门用来进行类型判定———typeof，不过它只能判断几种基本类型。对于复杂类型，它有些无能无力，而且，对于一些基本类型，它还有一些陷阱。&lt;br/&gt;类型 | 结果&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;| -:&lt;br/&gt;Undefined | &quot;undefined&quot;&lt;br/&gt;Null | &quot;object&quot;&lt;br/&gt;Boolean | &quot;boolean&quot;&lt;br/&gt;Number | &quot;number&quot;&lt;br/&gt;String | &quot;string&quot;&lt;br/&gt;Symbol | &quot;symbol&quot;&lt;br/&gt;function | &quot;function&quot;&lt;br/&gt;任何其他对象(Array，Date等原生对象) | &quot;object&quot;&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;typeof有一些古怪的bug&quot;&gt;typeof有一些古怪的bug&lt;/h2&gt;
&lt;p&gt;即使是在typeof可以判定的地方，也会有一些bug。例如：&lt;br/&gt;最经典的&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;sourceCode javascript&quot;&gt;
&lt;code class=&quot;sourceCode javascript&quot;&gt;&lt;span class=&quot;kw&quot;&gt;typeof&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;===&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'object'&lt;/span&gt; &lt;span class=&quot;co&quot;&gt;// true&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;以及new操作符&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;sourceCode javascript&quot;&gt;
&lt;code class=&quot;sourceCode javascript&quot;&gt;&lt;span class=&quot;kw&quot;&gt;typeof&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;Number&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;) &lt;span class=&quot;op&quot;&gt;===&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'number'&lt;/span&gt; &lt;span class=&quot;co&quot;&gt;// true&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;typeof&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;Number&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;) &lt;span class=&quot;op&quot;&gt;===&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'object'&lt;/span&gt; &lt;span class=&quot;co&quot;&gt;// true&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;由于typeof的功能简陋，尤其是无法对object下的子类型做出详细的判定，所以我们常用另一个操作符进行判定。&lt;/p&gt;

&lt;p&gt;instanceof 用来测试一个对象在其原型链中是否存在一个构造函数的 prototype 属性。&lt;br/&gt;大概原理就是不停地去判断当前对象 _ _ proto _ _ 上的对象是否与实例的prototype相等。不相等的话，就令当前对象&lt;/p&gt;
&lt;p&gt;a. _ _ proto _ _ = a. _ _ proto _ _ . _ _ proto _ _ 继续判断。直到结果为null和true为止。&lt;br/&gt;举个栗子：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;9&quot;&gt;
&lt;pre class=&quot;sourceCode javascript&quot;&gt;
&lt;code class=&quot;sourceCode javascript&quot;&gt;&lt;span class=&quot;co&quot;&gt;// 构造函数&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;Foo&lt;/span&gt;()&lt;span class=&quot;op&quot;&gt;{}&lt;/span&gt;

&lt;span class=&quot;kw&quot;&gt;var&lt;/span&gt;
    foo1 &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;Foo&lt;/span&gt;()
&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;va&quot;&gt;foo1&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;constructor&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;===&lt;/span&gt; Foo&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;co&quot;&gt;//true&lt;/span&gt;
&lt;span class=&quot;va&quot;&gt;foo1&lt;/span&gt;.&lt;span class=&quot;va&quot;&gt;__proto__&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;constructor&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;===&lt;/span&gt; Foo&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;co&quot;&gt;// true;&lt;/span&gt;


&lt;span class=&quot;va&quot;&gt;foo1&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;__proto__&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;===&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;Foo&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;prototype&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;co&quot;&gt;// true;&lt;/span&gt;

&lt;span class=&quot;va&quot;&gt;foo1&lt;/span&gt;.&lt;span class=&quot;va&quot;&gt;__proto__&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;__proto__&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;===&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;Object&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;prototype&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;co&quot;&gt;// true&lt;/span&gt;

&lt;span class=&quot;va&quot;&gt;foo1&lt;/span&gt;.&lt;span class=&quot;va&quot;&gt;__proto__&lt;/span&gt;.&lt;span class=&quot;va&quot;&gt;__proto__&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;__proto__&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;===&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;co&quot;&gt;// true&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上面的代码展示了instanceof的判断原理，具体实现可以参考规范：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://tc39.github.io/ecma262/#sec-instanceofoperator&quot; class=&quot;uri&quot;&gt;https://tc39.github.io/ecma262/#sec-instanceofoperator&lt;/a&gt;&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://tc39.github.io/ecma262/#sec-ordinaryhasinstance&quot; class=&quot;uri&quot;&gt;https://tc39.github.io/ecma262/#sec-ordinaryhasinstance&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;根据instanceof，我们基本上可以判断Object下的所有对象类型了。但是instanceof也有一个问题。&lt;/p&gt;
&lt;h3 id=&quot;一切都在window下&quot;&gt;一切都在window下&lt;/h3&gt;
&lt;p&gt;在浏览器环境里，所有的构造函数，基本的对象，都挂在window下。Object也不例外。这导致了一个问题，在iframe这样的独立于当前窗口的环境里，instanceof可能会有bug产生。&lt;br/&gt;对于Array这样的常用对象，新版本提供了Array.isArray原生方法进行判定，但是对于Date等对象，就没有这么好了。所以我们还是需要一个更加健壮的类型判定方法。&lt;br/&gt;Prototype.js、underScore.js和jQuery的前辈们为我们找到了一个绝妙的方法——&lt;br/&gt;&lt;em&gt;Object.prototype.toString.call&lt;/em&gt;&lt;br/&gt;通过这个技巧，再结合typeof和instanceof，我们可以判断几乎全部的原生对象类型。&lt;br/&gt;下面是underscore的部分源码：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;21&quot;&gt;
&lt;pre class=&quot;sourceCode javascript&quot;&gt;
&lt;code class=&quot;sourceCode javascript&quot;&gt; &lt;span class=&quot;va&quot;&gt;_&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;each&lt;/span&gt;([&lt;span class=&quot;st&quot;&gt;'Arguments'&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'Function'&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'String'&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'Number'&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'Date'&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;,&lt;/span&gt; 
  &lt;span class=&quot;st&quot;&gt;'RegExp'&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'Error'&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'Symbol'&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'Map'&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'WeakMap'&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'Set'&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'WeakSet'&lt;/span&gt;]&lt;span class=&quot;op&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt;(name) &lt;span class=&quot;op&quot;&gt;{&lt;/span&gt;
    _[&lt;span class=&quot;st&quot;&gt;'is'&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;+&lt;/span&gt; name] &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;function&lt;/span&gt;(obj) &lt;span class=&quot;op&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;cf&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;toString&lt;/span&gt;.&lt;span class=&quot;at&quot;&gt;call&lt;/span&gt;(obj) &lt;span class=&quot;op&quot;&gt;===&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'[object '&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;+&lt;/span&gt; name &lt;span class=&quot;op&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;']'&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;op&quot;&gt;};&lt;/span&gt;
  &lt;span class=&quot;op&quot;&gt;}&lt;/span&gt;)&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;感谢阅读。&lt;/p&gt;

&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Operators/typeof&quot;&gt;typeof&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Operators/instanceof&quot;&gt;instanceof&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/jashkenas/underscore&quot;&gt;underscore.js&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
<pubDate>Sat, 17 Feb 2018 14:04:00 +0000</pubDate>
<dc:creator>liuyongjia</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/liuyongjia/p/8452242.html</dc:identifier>
</item>
<item>
<title>应用负载均衡之LVS(一)：基本概念和三种模式 - 骏马金龙</title>
<link>http://www.cnblogs.com/f-ck-need-u/p/8451982.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/f-ck-need-u/p/8451982.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;a&gt;&lt;span&gt;本文目录：&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;a href=&quot;http://www.cnblogs.com/f-ck-need-u/p/8451982.html#blog1&quot;&gt;&lt;span&gt;1. LVS简介&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;a href=&quot;http://www.cnblogs.com/f-ck-need-u/p/8451982.html#blog2&quot;&gt;&lt;span&gt;2. LVS-ipvs三种模式的工作原理&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　&lt;a href=&quot;http://www.cnblogs.com/f-ck-need-u/p/8451982.html#blog2.1&quot;&gt;&lt;span&gt;2.1 VS/NAT模式&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　&lt;a href=&quot;http://www.cnblogs.com/f-ck-need-u/p/8451982.html#blog2.2&quot;&gt;&lt;span&gt;2.2 VS/TUN模式&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　&lt;a href=&quot;http://www.cnblogs.com/f-ck-need-u/p/8451982.html#blog2.3&quot;&gt;&lt;span&gt;2.3 VS/DR模式&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;　&lt;a href=&quot;http://www.cnblogs.com/f-ck-need-u/p/8451982.html#blog2.4&quot;&gt;&lt;span&gt;2.4 lvs-ipvs的三种模式比较&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;a href=&quot;http://www.cnblogs.com/f-ck-need-u/p/8451982.html#blog3&quot;&gt;&lt;span&gt;3. VS/TUN和VS/DR模式中的ARP问题&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;a href=&quot;http://www.cnblogs.com/f-ck-need-u/p/8451982.html#blog4&quot;&gt;&lt;span&gt;4. LVS负载均衡的调度算法&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;网站架构中，负载均衡技术是实现网站架构&lt;span&gt;&lt;strong&gt;伸缩性&lt;/strong&gt;&lt;/span&gt;的主要手段之一。所谓&quot;伸缩性&quot;，是指可以不断向集群中添加新的服务器来提升性能、缓解不断增加的并发用户访问压力。通俗地讲，就是一头牛拉不动时，就用两头、三头、更多头牛来拉。&lt;/p&gt;
&lt;p&gt;负载均衡有好几种方式：http URL重定向、DNS的A记录负载均衡、反向代理负载均衡、IP负载均衡和链路层负载。本文所述为LVS，它的VS/NAT和VS/TUN模式是IP负载均衡的优秀代表，而它的VS/DR模式则是链路层负载均衡的优秀代表。&lt;/p&gt;

&lt;h2 id=&quot;1-lvs-&quot;&gt;1.LVS简介&lt;/h2&gt;
&lt;p&gt;LVS中文官方手册：&lt;span&gt;&lt;a href=&quot;http://www.linuxvirtualserver.org/zh/index.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;http://www.linuxvirtualserver.org/zh/index.html&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;。这个手册对于了解lvs的背景知识很有帮助。&lt;/p&gt;
&lt;p&gt;LVS英文官方手册：&lt;span&gt;&lt;a href=&quot;http://www.linuxvirtualserver.org/Documents.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;http://www.linuxvirtualserver.org/Documents.html&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;。这个手册比较全面，对于了解和学习lvs的原理、配置很有帮助。&lt;/p&gt;
&lt;p&gt;LVS是章文嵩开发的一个国产开源负载均衡软件。LVS最初是他在大学期间的玩具，随着后来使用的用户越来越多，LVS也越来越完善，最终集成到了Linux的内核中。有不少开源牛人都为LVS开发过辅助工具和辅助组件，最出名的就是Alexandre为LVS编写的Keepalived，它最初专门用于监控LVS，后来加入了通过VRRP实现高可用的功能。&lt;/p&gt;
&lt;p&gt;LVS的全称是Linux virtual server，即Linux虚拟服务器。之所以是虚拟服务器，是因为LVS自身是个负载均衡器(director)，不直接处理请求，而是将请求转发至位于它后端真正的服务器realserver上。&lt;/p&gt;
&lt;p&gt;LVS是四层(传输层tcp/udp)、七层(应用层)的负载均衡工具，只不过大众一般都使用它的四层负载均衡功能ipvs，而七层的内容分发负载工具ktcpvs(kernel tcp virtual server)不怎么完善，使用的人并不多。&lt;/p&gt;
&lt;p&gt;ipvs是集成在内核中的框架，可以通过用户空间的程序&lt;code&gt;ipvsadm&lt;/code&gt;工具来管理，该工具可以定义一些规则来管理内核中的ipvs。就像iptables和netfilter的关系一样。&lt;/p&gt;

&lt;h2 id=&quot;2-lvs-ipvs-&quot;&gt;2.LVS-ipvs三种模式的工作原理&lt;/h2&gt;
&lt;p&gt;首先要解释的是LVS相关的几种IP：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;VIP&lt;/code&gt;:virtual IP，LVS服务器上接收外网数据包的网卡IP地址。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DIP&lt;/code&gt;:director IP，LVS服务器上转发数据包到realserver的网卡IP地址。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RIP&lt;/code&gt;:realserver(常简称为RS)上接收Director转发数据包的IP，即提供服务的服务器IP。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CIP&lt;/code&gt;:客户端的IP。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/733013/201802/733013-20180211225301232-212054825.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;LVS的三种工作模式：通过网络地址转换(NAT)将一组服务器构成一个高性能的、高可用的虚拟服务器，是VS/NAT技术。在分析VS/NAT的缺点和网络服务的非对称性的基础上，提出了通过IP隧道实现虚拟服务器的方法VS/TUN（Virtual Server via IP Tunneling），和通过直接路由实现虚拟服务器的方法VS/DR（Virtual Server via Direct Routing），它们可以极大地提高系统的伸缩性。&lt;/p&gt;

&lt;h3 id=&quot;2-1-vs-nat-&quot;&gt;2.1 VS/NAT模式&lt;/h3&gt;
&lt;p&gt;客户端发送的请求到达Director后，Director根据负载均衡算法改写目标地址为后端某个RIP(web服务器池中主机之一)并转发给该后端主机，就像NAT一样。当后端主机处理完请求后，后端主机将响应数据交给Director，并由director改写源地址为VIP后传输给客户端。大多数商品化的IP负载均衡硬件都是使用此方法，如Cisco的LocalDirector、F5的Big/IP。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/733013/201802/733013-20180211234714295-412364937.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这种模式下：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;RIP和DIP一般处于同一私有网段中。但并非必须，只要它们能通信即可。&lt;/li&gt;
&lt;li&gt;各RealServer的网关指向DIP，这样能保证将响应数据交给Director。&lt;/li&gt;
&lt;li&gt;VS/NAT模式的最大缺点是Director负责所有进出数据：不仅处理客户端发起的请求，还负责将响应传输给客户端。而响应数据一般比请求数据大得多，调度器Director容易出现瓶颈。&lt;/li&gt;
&lt;li&gt;这种模式配置起来最简单。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;2-2-vs-tun-&quot;&gt;2.2 VS/TUN模式&lt;/h3&gt;
&lt;p&gt;采用NAT技术时，由于请求和响应报文都必须经过调度器地址重写，当客户请求越来越多时，调度器的处理能力将成为瓶颈。为了解决这个问题，调度器把请求报文通过IP隧道转发至真实服务器，而真实服务器将响应直接返回给客户，所以调度器只处理请求报文。由于一般网络服务响应报文比请求报文大许多，采用VS/TUN技术后，调度器得到极大的解放，集群系统的最大吞吐量可以提高10倍。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/733013/201802/733013-20180213102345546-471661305.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;VS/TUN模式的工作原理：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;(1)IP隧道技术又称为IP封装技术，它可以将带有源和目标IP地址的数据报文使用新的源和目标IP进行第二次封装，这样这个报文就可以发送到一个指定的目标主机上；&lt;/li&gt;
&lt;li&gt;(2)VS/TUN模式下，调度器和后端服务器组之间使用IP隧道技术。当客户端发送的请求(CIP--&amp;gt;VIP)被director接收后，director修改该报文，加上IP隧道两端的IP地址作为新的源和目标地址，并将请求转发给后端被选中的一个目标；&lt;/li&gt;
&lt;li&gt;(3)当后端服务器接收到报文后，首先解封报文得到原有的CIP--&amp;gt;VIP，该后端服务器发现自身的tun接口上配置了VIP，因此接受该数据包。&lt;/li&gt;
&lt;li&gt;(4)当请求处理完成后，结果将不会重新交给director，而是直接返回给客户端；在后端服务器返回给客户端数据包时，由于使用的是普通网卡接口，根据一般的路由条目，源IP地址将是该网卡接口上的地址，例如是RIP。因此，要让响应数据包的源IP为VIP，必须添加一条特殊的路由条目，明确指定该路由的源地址是VIP。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;采用VS/TUN模式时的基本属性和要求：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;RealServer的RIP和director的DIP不用处于同一物理网络中，且RIP必须可以和公网通信。也就是说集群节点可以跨互联网实现。&lt;/li&gt;
&lt;li&gt;realserver的tun接口上需要配置VIP地址，以便接收director转发过来的数据包，以及作为响应报文的源IP。&lt;/li&gt;
&lt;li&gt;director给realserver时需要借助隧道，隧道外层的IP头部的源IP是DIP，目标IP是RIP。而realsever响应给客户端的IP头部是根据隧道内层的IP头分析得到的，源IP是VIP，目标IP是CIP。这样客户端就无法区分这个VIP到底是director的还是服务器组中的。&lt;/li&gt;
&lt;li&gt;需要添加一条特殊的路由条目，使得后端服务器返回响应给客户端时的源IP为VIP。&lt;/li&gt;
&lt;li&gt;director只处理入站请求，响应请求由realserver完成。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;一般来说，VS/TUN模式会用来负载调度缓存服务器组，这些缓存服务器一般放置在不同网络环境，可以就近返回数据给客户端。在请求对象不能在Cache服务器本地命中的情况下，Cache服务器要向源服务器发请求，将结果取回，最后将结果返回给客户。&lt;/p&gt;

&lt;h3 id=&quot;2-3-vs-dr-&quot;&gt;2.3 VS/DR模式&lt;/h3&gt;
&lt;p&gt;VS/TUN模式下，调度器对数据包的处理是使用IP隧道技术进行二次封装。VS/DR模式和VS/TUN模式很类似，只不过调度器对数据包的处理是改写数据帧的目标MAC地址，通过链路层来负载均衡。&lt;/p&gt;
&lt;p&gt;VS/DR通过改写请求报文的目标MAC地址，将请求发送到真实服务器，而真实服务器将响应直接返回给客户。同VS/TUN技术一样，VS/DR技术可极大地提高集群系统的伸缩性。这种方法没有IP隧道的开销，对集群中的真实服务器也没有必须支持IP隧道协议的要求，但是要求调度器与真实服务器都有一块网卡连在同一物理网段上，以便使用MAC地址通信转发数据包。&lt;/p&gt;
&lt;p&gt;VS/DR模式的工作原理：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;(1)客户端发送的请求被director接收后，director根据负载均衡算法，改写数据帧的目标MAC地址为后端某RS的MAC地址，并将该数据包转发给该RS(实际上是往整个局域网发送，但只有该MAC地址的RS才不会丢弃)。&lt;/li&gt;
&lt;li&gt;(2)RS接收到数据包后，发现数据包的目标IP地址为VIP，而RS本身已经将VIP配置在了某个接口上，因此RS会接收下这个数据包并进行处理。&lt;/li&gt;
&lt;li&gt;(3)处理完毕后，RS直接将响应报文响应给客户端。在返回给客户端的时候，由于实用的是普通网卡接口，根据一般的路由条目，源IP地址将是该网卡接口上的地址，例如RIP。因此，要让响应数据包的源IP为VIP，需要添加一条特殊的路由条目，明确指定该路由的源地址为VIP。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;也就是说，客户端请求发送到LB上，源和目标IP为CIP:VIP，LB上有VIP和DIP，重新改写MAC地址后通过DIP发送给某个realserver，如RS1，此时源和目标IP还是CIP:VIP，但是目标MAC地址改写为RIP1所在网卡的MAC地址&quot;RS1_MAC&quot;，RS1发现自身有VIP地址，所以收下此数据报文(所以在RS上必须配置VIP)。返回时，RS1根据路由表直接返回给客户端，此时，源和目标IP是VIP:CIP。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/733013/201802/733013-20180213102610124-276805076.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;采用VS/DR模式时的基本属性和要求：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;RealServer的RIP和director的DIP必须处于同一网段中，以便使用MAC地址进行通信。&lt;/li&gt;
&lt;li&gt;realserver上必须配置VIP地址，以便接收director转发过来的数据包，以及作为响应报文的源IP。&lt;/li&gt;
&lt;li&gt;realsever响应给客户端的数据包的源和目标IP为VIP--&amp;gt;CIP。&lt;/li&gt;
&lt;li&gt;需要添加一条特殊的路由条目，使得后端服务器返回响应给客户端时的源IP为VIP。&lt;/li&gt;
&lt;li&gt;director只处理入站请求，响应请求由realserver完成。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;2-4-lvs-ipvs-&quot;&gt;2.4 lvs-ipvs的三种模式比较&lt;/h3&gt;
&lt;p&gt;三种模式的比较如图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/733013/201802/733013-20180213110217531-1638772778.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在性能上，VS/DR和VS/TUN远高于VS/NAT，因为调度器只处于从客户到服务器的半连接中，按照半连接的TCP有限状态机进行状态迁移，极大程度上减轻了调度器的压力。VS/DR性能又稍高于VS/TUN，因为少了隧道的开销。但是，VS/DR和VS/TUN的主要区别是VS/TUN可以跨网络实现后端服务器负载均衡(也可以局域网内)，而VS/DR只能和director在局域网内进行负载均衡。&lt;/p&gt;

&lt;h2 id=&quot;3-vs-tun-vs-dr-arp-&quot;&gt;3.VS/TUN和VS/DR模式中的ARP问题&lt;/h2&gt;
&lt;p&gt;在【【VS/TUN和VS/DR的arp问题】】中非常详细地分析了ARP、arp_ignore和arp_announce相关原理和设置方法。此处简单说明为何需要设置arp抑制以及设置arp抑制的方法。&lt;/p&gt;
&lt;p&gt;当一个目标IP地址为VIP的数据包进入Director前端的路由器时，路由器会向局域网内发送ARP广播，以找出VIP地址的MAC地址在哪台主机上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/733013/201802/733013-20180213170727562-1125645743.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Director和各RS都配置了VIP。当路由器发送ARP广播后，Director和RS都会收到这个广播包，且都认为这个广播包找的就是自己，于是都回应给路由器，这样路由器上的ARP缓存表中的条目&lt;code&gt;VIP&amp;lt;--&amp;gt;vip_MAC&lt;/code&gt;就不断被覆盖直到最后一个回应。这样一来，路由器将把客户端的数据包发送给最后一个回应的主机，这台主机的VIP可能是Director上的，也可能是某个RS上的。在一定时间内，路由器收到目标IP为VIP的数据包都会发送给该主机。但路由器会定时发送ARP广播包，这样一来ARP缓存表中的VIP对应的MAC地址可能会换成另一台主机。&lt;/p&gt;
&lt;p&gt;因此，必须要保证路由器只保存Director上VIP对应的MAC地址，即只允许Director才对路由器的ARP广播进行回应。也就是说，所有RS上的VIP必须隐藏起来。&lt;/p&gt;
&lt;p&gt;一般通过将Real Server上的VIP设置在lo接口的别名接口上(如lo:0)，并设置&lt;code&gt;arp_ignore=1&lt;/code&gt;和&lt;code&gt;arp_announce=2&lt;/code&gt;的方式来隐藏RS上的VIP。至于VIP为何要设置在lo接口上以及为何要这样设置这两个arp参数，请参看【【VS/TUN和VS/DR的arp问题】】，内容非常详细。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;hljs bash&quot;&gt;echo &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt; &amp;gt;&lt;span class=&quot;hljs-regexp&quot;&gt;/proc/sys&lt;/span&gt;&lt;span class=&quot;hljs-regexp&quot;&gt;/net/ipv&lt;/span&gt;4/conf/all/arp_ignore
echo &lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt; &amp;gt;&lt;span class=&quot;hljs-regexp&quot;&gt;/proc/sys&lt;/span&gt;&lt;span class=&quot;hljs-regexp&quot;&gt;/net/ipv&lt;/span&gt;4/conf/all/arp_announce
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;或者&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;hljs bash&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;sysctl&lt;/span&gt; -w net.ipv4.conf.&lt;span class=&quot;hljs-literal&quot;&gt;all&lt;/span&gt;.arp_ignore=1
&lt;span class=&quot;hljs-keyword&quot;&gt;sysctl&lt;/span&gt; -w net.ipv4.conf.&lt;span class=&quot;hljs-literal&quot;&gt;all&lt;/span&gt;.arp_announce=2
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;或者将arp参数设置到内核参数配置文件中以让其永久生效。&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;hljs bash&quot;&gt;echo &lt;span class=&quot;hljs-string&quot;&gt;&quot;net.ipv4.conf.all.arp_ignore=1&quot;&lt;/span&gt; &lt;span class=&quot;hljs-prompt&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;/etc/sysctl.conf
echo &lt;span class=&quot;hljs-string&quot;&gt;&quot;net.ipv4.conf.all.arp_announce=2&quot;&lt;/span&gt; &lt;span class=&quot;hljs-prompt&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;/etc/sysctl.conf
sysctl -p
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在网上几乎所有文章还设置了lo接口上的arp参数：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;hljs bash&quot;&gt;echo &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt; &amp;gt;&lt;span class=&quot;hljs-regexp&quot;&gt;/proc/sys&lt;/span&gt;&lt;span class=&quot;hljs-regexp&quot;&gt;/net/ipv&lt;/span&gt;4/conf/lo/arp_ignore
echo &lt;span class=&quot;hljs-number&quot;&gt;2&lt;/span&gt; &amp;gt;&lt;span class=&quot;hljs-regexp&quot;&gt;/proc/sys&lt;/span&gt;&lt;span class=&quot;hljs-regexp&quot;&gt;/net/ipv&lt;/span&gt;4/conf/lo/arp_announce
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;但这没有任何意义，因为从lo接口不受arp参数的影响。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;应该在配置VIP之前就设置arp参数，以防止配置VIP后、设置arp抑制之前被外界主机发现。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;h2 id=&quot;4-lvs-&quot;&gt;4.LVS负载均衡的调度算法&lt;/h2&gt;
&lt;p&gt;LVS的调度算法，详细内容见官方手册：&lt;span&gt;&lt;a href=&quot;http://www.linuxvirtualserver.org/zh/lvs4.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;http://www.linuxvirtualserver.org/zh/lvs4.html&lt;/span&gt;&lt;/a&gt;&lt;/span&gt; 。&lt;/p&gt;
&lt;p&gt;IPVS在内核中的负载均衡调度是&lt;span&gt;&lt;strong&gt;以连接为粒度&lt;/strong&gt;&lt;/span&gt;的。在HTTP协议（非持久）中，每次从WEB服务器上获取资源都需要建立一个TCP连接，同一用户的不同请求会被调度到不同的服务器上，所以这种细粒度的调度在一定程度上可以避免单个用户访问的突发性引起服务器间的负载不平衡。&lt;/p&gt;
&lt;p&gt;LVS分为两种调度方式：静态调度和动态反馈调度。&lt;/p&gt;
&lt;p&gt;静态调度方式是指不管RS的繁忙程度，根据调度算法计算后轮到谁就调度谁。例如两台realserver，一开始双方都在处理500个连接，下一个请求到来前，server1只断开了10个，而server2断开了490个，但是此时轮到了server1，就会调度server1而不管繁忙的程度。&lt;/p&gt;
&lt;p&gt;动态调度方式是指根据RS的繁忙程度反馈，计算出下一个连接应该调度谁(动态反馈负载均衡算法考虑服务器的实时负载和响应情况，不断调整服务器间处理请求的比例，来避免有些服务器超载时依然收到大量请求，从而提高整个系统的吞吐率)。&lt;/p&gt;
&lt;p&gt;在内核中的连接调度算法上，IPVS已实现了以下八种调度算法：默认的算法为wlc。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;静态调度：&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;轮叫调度（Round-Robin Scheduling,rr）&lt;/li&gt;
&lt;li&gt;加权轮叫调度（Weighted Round-Robin Scheduling,wrr），按照权重比例作为轮询标准&lt;/li&gt;
&lt;li&gt;目标地址散列调度（Destination Hashing Scheduling,dh），目标地址哈希，对于同一目标IP的请求总是发往同一服务器&lt;/li&gt;
&lt;li&gt;源地址散列调度（Source Hashing Scheduling,sh），源地址哈希，在一定时间内，只要是来自同一个客户端的请求，就发送至同一个realserver&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态反馈调度：&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;最小连接调度（Least-Connection Scheduling,lc），调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某服务器，其连接数加1；当连接中止或超时，其连接数减1。当各个服务器的处理能力不同时，该算法不理想。&lt;/li&gt;
&lt;li&gt;加权最小连接调度（Weighted Least-Connection Scheduling,wlc）&lt;/li&gt;
&lt;li&gt;基于本地的最少连接（Locality-Based Least Connections Scheduling,lblc），目前该算法主要用于cache集群系统。&lt;/li&gt;
&lt;li&gt;带复制的基于局部性最少连接（Locality-Based Least Connections with Replication Scheduling,lblcr），目前主要用于Cache集群系统。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;a href=&quot;http://www.cnblogs.com/f-ck-need-u/p/7048359.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;回到Linux系列文章大纲：http://www.cnblogs.com/f-ck-need-u/p/7048359.html&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;&lt;a href=&quot;http://www.cnblogs.com/f-ck-need-u/p/7576137.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;回到网站架构系列文章大纲：http://www.cnblogs.com/f-ck-need-u/p/7576137.html&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;&lt;a href=&quot;http://www.cnblogs.com/f-ck-need-u/p/7586194.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;回到数据库系列文章大纲：http://www.cnblogs.com/f-ck-need-u/p/7586194.html&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;&lt;a href=&quot;http://www.cnblogs.com/f-ck-need-u/p/8451982.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;转载请注明出处：http://www.cnblogs.com/f-ck-need-u/p/8451982.html&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;注：若您觉得这篇文章还不错请点击右下角推荐，您的支持能激发作者更大的写作热情，非常感谢！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sat, 17 Feb 2018 08:51:00 +0000</pubDate>
<dc:creator>骏马金龙</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/f-ck-need-u/p/8451982.html</dc:identifier>
</item>
<item>
<title>CNN网络架构演进：从LeNet到DenseNet - Madcola</title>
<link>http://www.cnblogs.com/skyfsm/p/8451834.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/skyfsm/p/8451834.html</guid>
<description>&lt;p&gt;卷积神经网络可谓是现在深度学习领域中大红大紫的网络框架，尤其在计算机视觉领域更是一枝独秀。CNN从90年代的LeNet开始，21世纪初沉寂了10年，直到12年AlexNet开始又再焕发第二春，从ZF Net到VGG，GoogLeNet再到ResNet和最近的DenseNet，网络越来越深，架构越来越复杂，解决反向传播时梯度消失的方法也越来越巧妙。新年有假期，就好好总结一波CNN的各种经典架构吧，领略一下CNN的发展历程中各路大神之间的智慧碰撞之美。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131558874-187072295.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上面那图是ILSVRC历年的Top-5错误率，我们会按照以上经典网络出现的时间顺序对他们进行介绍。&lt;/p&gt;
&lt;p&gt;本文将会谈到以下经典的卷积神经网络：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;LeNet&lt;/li&gt;
&lt;li&gt;AlexNet&lt;/li&gt;
&lt;li&gt;ZF&lt;/li&gt;
&lt;li&gt;VGG&lt;/li&gt;
&lt;li&gt;GoogLeNet&lt;/li&gt;
&lt;li&gt;ResNet&lt;/li&gt;
&lt;li&gt;DenseNet&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;开山之作lenet&quot;&gt;开山之作：LeNet&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131615671-367457714.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;闪光点：定义了CNN的基本组件，是CNN的鼻祖。&lt;/p&gt;
&lt;p&gt;LeNet是卷积神经网络的祖师爷LeCun在1998年提出，用于解决手写数字识别的视觉任务。自那时起，CNN的最基本的架构就定下来了：卷积层、池化层、全连接层。如今各大深度学习框架中所使用的LeNet都是简化改进过的LeNet-5（-5表示具有5个层），和原始的LeNet有些许不同，比如把激活函数改为了现在很常用的ReLu。&lt;/p&gt;
&lt;p&gt;LeNet-5跟现有的conv-&amp;gt;pool-&amp;gt;ReLU的套路不同，它使用的方式是conv1-&amp;gt;pool-&amp;gt;conv2-&amp;gt;pool2再接全连接层，但是不变的是，卷积层后紧接池化层的模式依旧不变。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131630609-291700181.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;以上图为例，对经典的LeNet-5做深入分析：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;首先输入图像是单通道的28*28大小的图像，用矩阵表示就是[1,28,28]&lt;/li&gt;
&lt;li&gt;第一个卷积层conv1所用的卷积核尺寸为5*5，滑动步长为1，卷积核数目为20，那么经过该层后图像尺寸变为24，28-5+1=24，输出矩阵为[20,24,24]。&lt;/li&gt;
&lt;li&gt;第一个池化层pool核尺寸为2*2，步长2，这是没有重叠的max pooling，池化操作后，图像尺寸减半，变为12×12，输出矩阵为[20,12,12]。&lt;/li&gt;
&lt;li&gt;第二个卷积层conv2的卷积核尺寸为5*5，步长1，卷积核数目为50，卷积后图像尺寸变为8,这是因为12-5+1=8，输出矩阵为[50,8,8].&lt;/li&gt;
&lt;li&gt;第二个池化层pool2核尺寸为2*2，步长2，这是没有重叠的max pooling，池化操作后，图像尺寸减半，变为4×4，输出矩阵为[50,4,4]。&lt;/li&gt;
&lt;li&gt;pool2后面接全连接层fc1，神经元数目为500，再接relu激活函数。&lt;/li&gt;
&lt;li&gt;再接fc2，神经元个数为10，得到10维的特征向量，用于10个数字的分类训练，送入softmaxt分类，得到分类结果的概率output。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;LeNet的Keras实现：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def LeNet():
    model = Sequential()
    model.add(Conv2D(32,(5,5),strides=(1,1),input_shape=(28,28,1),padding='valid',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Conv2D(64,(5,5),strides=(1,1),padding='valid',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Flatten())
    model.add(Dense(100,activation='relu'))
    model.add(Dense(10,activation='softmax'))
    return model&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;王者归来alexnet&quot;&gt;王者归来：AlexNet&lt;/h2&gt;
&lt;p&gt;AlexNet在2012年ImageNet竞赛中以超过第二名10.9个百分点的绝对优势一举夺冠，从此深度学习和卷积神经网络名声鹊起，深度学习的研究如雨后春笋般出现，AlexNet的出现可谓是卷积神经网络的王者归来。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131643890-1883639712.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;闪光点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;更深的网络&lt;/li&gt;
&lt;li&gt;数据增广&lt;/li&gt;
&lt;li&gt;ReLU&lt;/li&gt;
&lt;li&gt;dropout&lt;/li&gt;
&lt;li&gt;LRN&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;以上图AlexNet架构为例，这个网络前面5层是卷积层，后面三层是全连接层，最终softmax输出是1000类，取其前两层进行详细说明。&lt;/p&gt;
&lt;ol readability=&quot;0.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;AlexNet共包含5层卷积层和三层全连接层，层数比LeNet多了不少，但卷积神经网络总的流程并没有变化，只是在深度上加了不少。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;AlexNet针对的是1000类的分类问题，输入图片规定是256×256的三通道彩色图片，为了增强模型的泛化能力，避免过拟合，作者使用了随机裁剪的思路对原来256×256的图像进行随机裁剪，得到尺寸为3×224×224的图像，输入到网络训练。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131703406-1977094290.png&quot;/&gt;&lt;/p&gt;
&lt;ol readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;因为使用多GPU训练，所以可以看到第一层卷积层后有两个完全一样的分支，以加速训练。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;针对一个分支分析：第一层卷积层conv1的卷积核尺寸为11×11，滑动步长为4，卷积核数目为48。卷积后得到的输出矩阵为[48,55,55]。这里的55是个难以理解的数字，作者也没有对此说明，如果按照正常计算的话(224-11)/4+1 != 55的，所以这里是做了padding再做卷积的，即先padiing图像至227×227，再做卷积(227-11)/4+1 = 55。这些像素层经过relu1单元的处理，生成激活像素层，尺寸仍为2组48×55×55的像素层数据&lt;br/&gt;。然后经过归一化处理，归一化运算的尺度为5*5。第一卷积层运算结束后形成的像素层的规模为48×27×27。&lt;/li&gt;
&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;输入矩阵是[48,55,55].接着是池化层，做max pooling操作，池化运算的尺度为3*3，运算的步长为2，则池化后图像的尺寸为(55-3)/2+1=27。所以得到的输出矩阵是[48,27,27]。后面层不再重复叙述。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;AlexNet用到训练技巧：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;数据增广技巧来增加模型泛化能力。&lt;/li&gt;
&lt;li&gt;用ReLU代替Sigmoid来加快SGD的收敛速度&lt;/li&gt;
&lt;li&gt;Dropout:Dropout原理类似于浅层学习算法的中集成算法，该方法通过让全连接层的神经元（该模型在前两个全连接层引入Dropout）以一定的概率失去活性（比如0.5）失活的神经元不再参与前向和反向传播，相当于约有一半的神经元不再起作用。在测试的时候，让所有神经元的输出乘0.5。Dropout的引用，有效缓解了模型的过拟合。&lt;/li&gt;
&lt;li&gt;Local Responce Normalization：局部响应归一层的基本思路是，假如这是网络的一块，比如是 13×13×256， LRN 要做的就是选取一个位置，比如说这样一个位置，从这个位置穿过整个通道，能得到 256 个数字，并进行归一化。进行局部响应归一化的动机是，对于这张 13×13 的图像中的每个位置来说，我们可能并不需要太多的高激活神经元。但是后来，很多研究者发现 LRN 起不到太大作用，因为并不重要，而且我们现在并不用 LRN 来训练网络。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;AlexNet的Keras实现：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def AlexNet():

    model = Sequential()
    model.add(Conv2D(96,(11,11),strides=(4,4),input_shape=(227,227,3),padding='valid',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
    model.add(Conv2D(256,(5,5),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
    model.add(Flatten())
    model.add(Dense(4096,activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4096,activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1000,activation='softmax'))
    return model
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;稳步前行zf-net&quot;&gt;稳步前行：ZF-Net&lt;/h2&gt;
&lt;p&gt;ZFNet是2013ImageNet分类任务的冠军，其网络结构没什么改进，只是调了调参，性能较Alex提升了不少。ZF-Net只是将AlexNet第一层卷积核由11变成7，步长由4变为2，第3，4，5卷积层转变为384，384，256。这一年的ImageNet还是比较平静的一届，其冠军ZF-Net的名堂也没其他届的经典网络架构响亮。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131724437-1439325209.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;ZF-Net的Keras实现：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def ZF_Net():
    model = Sequential()  
    model.add(Conv2D(96,(7,7),strides=(2,2),input_shape=(224,224,3),padding='valid',activation='relu',kernel_initializer='uniform'))  
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))  
    model.add(Conv2D(256,(5,5),strides=(2,2),padding='same',activation='relu',kernel_initializer='uniform'))  
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))  
    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  
    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  
    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))  
    model.add(Flatten())  
    model.add(Dense(4096,activation='relu'))  
    model.add(Dropout(0.5))  
    model.add(Dense(4096,activation='relu'))  
    model.add(Dropout(0.5))  
    model.add(Dense(1000,activation='softmax'))  
    return model
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;越走越深vgg-nets&quot;&gt;越走越深：VGG-Nets&lt;/h2&gt;
&lt;p&gt;VGG-Nets是由牛津大学VGG（Visual Geometry Group）提出，是2014年ImageNet竞赛定位任务的第一名和分类任务的第二名的中的基础网络。VGG可以看成是加深版本的AlexNet. 都是conv layer + FC layer，在当时看来这是一个非常深的网络了，因为层数高达十多层，我们从其论文名字就知道了（《Very Deep Convolutional Networks for Large-Scale Visual Recognition》），当然以现在的目光看来VGG真的称不上是一个very deep的网络。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131736640-1269864740.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上面一个表格是描述的是VGG-Net的网络结构以及诞生过程。为了解决初始化（权重初始化）等问题，VGG采用的是一种Pre-training的方式，这种方式在经典的神经网络中经常见得到，就是先训练一部分小网络，然后再确保这部分网络稳定之后，再在这基础上逐渐加深。表1从左到右体现的就是这个过程，并且当网络处于D阶段的时候，效果是最优的，因此D阶段的网络也就是VGG-16了！E阶段得到的网络就是VGG-19了！VGG-16的16指的是conv+fc的总层数是16，是不包括max pool的层数！&lt;/p&gt;
&lt;p&gt;下面这个图就是VGG-16的网络结构。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131751843-269987601.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;由上图看出，VGG-16的结构非常整洁，深度较AlexNet深得多，里面包含多个conv-&amp;gt;conv-&amp;gt;max_pool这类的结构,VGG的卷积层都是same的卷积，即卷积过后的输出图像的尺寸与输入是一致的，它的下采样完全是由max pooling来实现。&lt;/p&gt;
&lt;p&gt;VGG网络后接3个全连接层，filter的个数（卷积后的输出通道数）从64开始，然后没接一个pooling后其成倍的增加，128、512，VGG的注意贡献是使用小尺寸的filter，及有规则的卷积-池化操作。&lt;/p&gt;
&lt;p&gt;闪光点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;卷积层使用更小的filter尺寸和间隔&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;与AlexNet相比，可以看出VGG-Nets的卷积核尺寸还是很小的，比如AlexNet第一层的卷积层用到的卷积核尺寸就是11*11，这是一个很大卷积核了。而反观VGG-Nets，用到的卷积核的尺寸无非都是1×1和3×3的小卷积核，可以替代大的filter尺寸。&lt;/p&gt;
&lt;p&gt;3×3卷积核的优点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;多个3×3的卷基层比一个大尺寸filter卷基层有更多的非线性，使得判决函数更加具有判决性&lt;/li&gt;
&lt;li&gt;多个3×3的卷积层比一个大尺寸的filter有更少的参数，假设卷基层的输入和输出的特征图大小相同为C，那么三个3×3的卷积层参数个数3×（3×3×C×C）=27CC；一个7×7的卷积层参数为49CC；所以可以把三个3×3的filter看成是一个7×7filter的分解（中间层有非线性的分解）&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;1*1卷积核的优点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;作用是在不影响输入输出维数的情况下，对输入进行线性形变，然后通过Relu进行非线性处理，增加网络的非线性表达能力。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;VGG-16的Keras实现：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def VGG_16():   
    model = Sequential()
    
    model.add(Conv2D(64,(3,3),strides=(1,1),input_shape=(224,224,3),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(64,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    
    model.add(Conv2D(128,(3,2),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(128,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    
    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    
    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    
    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(512,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(2,2)))
    
    model.add(Flatten())
    model.add(Dense(4096,activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4096,activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1000,activation='softmax'))
    
    return model
&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;大浪推手googlenet&quot;&gt;大浪推手：GoogLeNet&lt;/h2&gt;
&lt;p&gt;GoogLeNet在2014的ImageNet分类任务上击败了VGG-Nets夺得冠军，其实力肯定是非常深厚的，GoogLeNet跟AlexNet,VGG-Nets这种单纯依靠加深网络结构进而改进网络性能的思路不一样，它另辟幽径，在加深网络的同时（22层），也在网络结构上做了创新，引入Inception结构代替了单纯的卷积+激活的传统操作（这思路最早由Network in Network提出）。GoogLeNet进一步把对卷积神经网络的研究推上新的高度。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131814499-915840988.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;闪光点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;引入Inception结构&lt;/li&gt;
&lt;li&gt;中间层的辅助LOSS单元&lt;/li&gt;
&lt;li&gt;后面的全连接层全部替换为简单的全局平均pooling&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131828906-234829229.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上图结构就是Inception，结构里的卷积stride都是1，另外为了保持特征响应图大小一致，都用了零填充。最后每个卷积层后面都立刻接了个ReLU层。在输出前有个叫concatenate的层，直译的意思是“并置”，即把4组不同类型但大小相同的特征响应图一张张并排叠起来，形成新的特征响应图。Inception结构里主要做了两件事：1. 通过3×3的池化、以及1×1、3×3和5×5这三种不同尺度的卷积核，一共4种方式对输入的特征响应图做了特征提取。2. 为了降低计算量。同时让信息通过更少的连接传递以达到更加稀疏的特性，采用1×1卷积核来实现降维。&lt;/p&gt;
&lt;p&gt;这里想再详细谈谈1×1卷积核的作用，它究竟是怎么实现降维的。下面图1是3×3卷积核的卷积，图2是1×1卷积核的卷积过程。对于单通道输入，1×1的卷积确实不能起到降维作用，但对于多通道输入，就不不同了。考虑[50,200,200]的矩阵输入，我们可以使用20个1×1的卷积核进行卷积，得到输出[20,200,200]。有人问，我用20个3×3的卷积核不是也能得到[20,200,200]的矩阵输出吗，为什么就1×1的可以降维？我们计算一下卷积参数就知道了，对于1×1的参数总数：20×200×200×（1×1），对于3×3的参数总数：20×200×200×（3×3），可以看出，使用1×1的参数总数仅为3×3的总数的九分之一！这就是降维！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131851234-1368185941.gif&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131904781-1419692084.gif&quot;/&gt;&lt;/p&gt;
&lt;p&gt;GoogLeNet网络结构中有3个LOSS单元，这样的网络设计是为了帮助网络的收敛。在中间层加入辅助计算的LOSS单元，目的是计算损失时让低层的特征也有很好的区分能力，从而让网络更好地被训练。在论文中，这两个辅助LOSS单元的计算被乘以0.3，然后和最后的LOSS相加作为最终的损失函数来训练网络。&lt;/p&gt;
&lt;p&gt;GoogLeNet还有一个闪光点值得一提，那就是将后面的全连接层全部替换为简单的全局平均pooling，在最后参数会变的更少。而在AlexNet中最后3层的全连接层参数差不多占总参数的90%，使用大网络在宽度和深度允许GoogleNet移除全连接层，但并不会影响到结果的精度，在ImageNet中实现93.3%的精度，而且要比VGG还要快。&lt;/p&gt;
&lt;p&gt;GoogLeNet的Keras实现：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def Conv2d_BN(x, nb_filter,kernel_size, padding='same',strides=(1,1),name=None):
    if name is not None:
        bn_name = name + '_bn'
        conv_name = name + '_conv'
    else:
        bn_name = None
        conv_name = None

    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,activation='relu',name=conv_name)(x)
    x = BatchNormalization(axis=3,name=bn_name)(x)
    return x

def Inception(x,nb_filter):
    branch1x1 = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),name=None)

    branch3x3 = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),name=None)
    branch3x3 = Conv2d_BN(branch3x3,nb_filter,(3,3), padding='same',strides=(1,1),name=None)

    branch5x5 = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),name=None)
    branch5x5 = Conv2d_BN(branch5x5,nb_filter,(1,1), padding='same',strides=(1,1),name=None)

    branchpool = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same')(x)
    branchpool = Conv2d_BN(branchpool,nb_filter,(1,1),padding='same',strides=(1,1),name=None)

    x = concatenate([branch1x1,branch3x3,branch5x5,branchpool],axis=3)

    return x

def GoogLeNet():
    inpt = Input(shape=(224,224,3))
    #padding = 'same'，填充为(步长-1）/2,还可以用ZeroPadding2D((3,3))
    x = Conv2d_BN(inpt,64,(7,7),strides=(2,2),padding='same')
    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)
    x = Conv2d_BN(x,192,(3,3),strides=(1,1),padding='same')
    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)
    x = Inception(x,64)#256
    x = Inception(x,120)#480
    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)
    x = Inception(x,128)#512
    x = Inception(x,128)
    x = Inception(x,128)
    x = Inception(x,132)#528
    x = Inception(x,208)#832
    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)
    x = Inception(x,208)
    x = Inception(x,256)#1024
    x = AveragePooling2D(pool_size=(7,7),strides=(7,7),padding='same')(x)
    x = Dropout(0.4)(x)
    x = Dense(1000,activation='relu')(x)
    x = Dense(1000,activation='softmax')(x)
    model = Model(inpt,x,name='inception')
    return model&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;里程碑式创新resnet&quot;&gt;里程碑式创新：ResNet&lt;/h2&gt;
&lt;p&gt;2015年何恺明推出的ResNet在ISLVRC和COCO上横扫所有选手，获得冠军。ResNet在网络结构上做了大创新，而不再是简单的堆积层数，ResNet在卷积神经网络的新思路，绝对是深度学习发展历程上里程碑式的事件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131926202-233779647.jpg&quot;/&gt;&lt;/p&gt;
&lt;p&gt;闪光点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;层数非常深，已经超过百层&lt;/li&gt;
&lt;li&gt;引入残差单元来解决退化问题&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;从前面可以看到，随着网络深度增加，网络的准确度应该同步增加，当然要注意过拟合问题。但是网络深度增加的一个问题在于这些增加的层是参数更新的信号，因为梯度是从后向前传播的，增加网络深度后，比较靠前的层梯度会很小。这意味着这些层基本上学习停滞了，这就是梯度消失问题。深度网络的第二个问题在于训练，当网络更深时意味着参数空间更大，优化问题变得更难，因此简单地去增加网络深度反而出现更高的训练误差，深层网络虽然收敛了，但网络却开始退化了，即增加网络层数却导致更大的误差，比如下图，一个56层的网络的性能却不如20层的性能好，这不是因为过拟合（训练集训练误差依然很高），这就是烦人的退化问题。残差网络ResNet设计一种残差模块让我们可以训练更深的网络。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131941296-1327847371.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里详细分析一下残差单元来理解ResNet的精髓。&lt;/p&gt;
&lt;p&gt;从下图可以看出，数据经过了两条路线，一条是常规路线，另一条则是捷径（shortcut），直接实现单位映射的直接连接的路线，这有点类似与电路中的“短路”。通过实验，这种带有shortcut的结构确实可以很好地应对退化问题。我们把网络中的一个模块的输入和输出关系看作是y=H(x)，那么直接通过梯度方法求H(x)就会遇到上面提到的退化问题，如果使用了这种带shortcut的结构，那么可变参数部分的优化目标就不再是H(x),若用F(x)来代表需要优化的部分的话，则H(x)=F(x)+x，也就是F(x)=H(x)-x。因为在单位映射的假设中y=x就相当于观测值，所以F(x)就对应着残差，因而叫残差网络。为啥要这样做，因为作者认为学习残差F(X)比直接学习H(X)简单！设想下，现在根据我们只需要去学习输入和输出的差值就可以了，绝对量变为相对量（H（x）-x 就是输出相对于输入变化了多少），优化起来简单很多。&lt;/p&gt;
&lt;p&gt;考虑到x的维度与F(X)维度可能不匹配情况，需进行维度匹配。这里论文中采用两种方法解决这一问题(其实是三种，但通过实验发现第三种方法会使performance急剧下降，故不采用):&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;zero_padding:对恒等层进行0填充的方式将维度补充完整。这种方法不会增加额外的参数&lt;/li&gt;
&lt;li&gt;projection:在恒等层采用1x1的卷积核来增加维度。这种方法会增加额外的参数&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217131952952-92773471.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下图展示了两种形态的残差模块，左图是常规残差模块，有两个3×3卷积核卷积核组成，但是随着网络进一步加深，这种残差结构在实践中并不是十分有效。针对这问题，右图的“瓶颈残差模块”（bottleneck residual block）可以有更好的效果，它依次由1×1、3×3、1×1这三个卷积层堆积而成，这里的1×1的卷积能够起降维或升维的作用，从而令3×3的卷积可以在相对较低维度的输入上进行，以达到提高计算效率的目的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217132002999-1852938927.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;ResNet-50的Keras实现：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def Conv2d_BN(x, nb_filter,kernel_size, strides=(1,1), padding='same',name=None):
    if name is not None:
        bn_name = name + '_bn'
        conv_name = name + '_conv'
    else:
        bn_name = None
        conv_name = None

    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,activation='relu',name=conv_name)(x)
    x = BatchNormalization(axis=3,name=bn_name)(x)
    return x

def Conv_Block(inpt,nb_filter,kernel_size,strides=(1,1), with_conv_shortcut=False):
    x = Conv2d_BN(inpt,nb_filter=nb_filter[0],kernel_size=(1,1),strides=strides,padding='same')
    x = Conv2d_BN(x, nb_filter=nb_filter[1], kernel_size=(3,3), padding='same')
    x = Conv2d_BN(x, nb_filter=nb_filter[2], kernel_size=(1,1), padding='same')
    if with_conv_shortcut:
        shortcut = Conv2d_BN(inpt,nb_filter=nb_filter[2],strides=strides,kernel_size=kernel_size)
        x = add([x,shortcut])
        return x
    else:
        x = add([x,inpt])
        return x

def ResNet50():
    inpt = Input(shape=(224,224,3))
    x = ZeroPadding2D((3,3))(inpt)
    x = Conv2d_BN(x,nb_filter=64,kernel_size=(7,7),strides=(2,2),padding='valid')
    x = MaxPooling2D(pool_size=(3,3),strides=(2,2),padding='same')(x)
    
    x = Conv_Block(x,nb_filter=[64,64,256],kernel_size=(3,3),strides=(1,1),with_conv_shortcut=True)
    x = Conv_Block(x,nb_filter=[64,64,256],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[64,64,256],kernel_size=(3,3))
    
    x = Conv_Block(x,nb_filter=[128,128,512],kernel_size=(3,3),strides=(2,2),with_conv_shortcut=True)
    x = Conv_Block(x,nb_filter=[128,128,512],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[128,128,512],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[128,128,512],kernel_size=(3,3))
    
    x = Conv_Block(x,nb_filter=[256,256,1024],kernel_size=(3,3),strides=(2,2),with_conv_shortcut=True)
    x = Conv_Block(x,nb_filter=[256,256,1024],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[256,256,1024],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[256,256,1024],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[256,256,1024],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[256,256,1024],kernel_size=(3,3))
    
    x = Conv_Block(x,nb_filter=[512,512,2048],kernel_size=(3,3),strides=(2,2),with_conv_shortcut=True)
    x = Conv_Block(x,nb_filter=[512,512,2048],kernel_size=(3,3))
    x = Conv_Block(x,nb_filter=[512,512,2048],kernel_size=(3,3))
    x = AveragePooling2D(pool_size=(7,7))(x)
    x = Flatten()(x)
    x = Dense(1000,activation='softmax')(x)
    
    model = Model(inputs=inpt,outputs=x)
    return model&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;继往开来densenet&quot;&gt;继往开来：DenseNet&lt;/h2&gt;
&lt;p&gt;自Resnet提出以后，ResNet的变种网络层出不穷，都各有其特点，网络性能也有一定的提升。本文介绍的最后一个网络是CVPR 2017最佳论文DenseNet，论文中提出的DenseNet（Dense Convolutional Network）主要还是和ResNet及Inception网络做对比，思想上有借鉴，但却是全新的结构，网络结构并不复杂，却非常有效，在CIFAR指标上全面超越ResNet。可以说DenseNet吸收了ResNet最精华的部分，并在此上做了更加创新的工作，使得网络性能进一步提升。&lt;/p&gt;
&lt;p&gt;闪光点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;密集连接：缓解梯度消失问题，加强特征传播，鼓励特征复用，极大的减少了参数量&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;DenseNet 是一种具有密集连接的卷积神经网络。在该网络中，任何两层之间都有直接的连接，也就是说，网络每一层的输入都是前面所有层输出的并集，而该层所学习的特征图也会被直接传给其后面所有层作为输入。下图是 DenseNet 的一个dense block示意图，一个block里面的结构如下，与ResNet中的BottleNeck基本一致：BN-ReLU-Conv(1×1)-BN-ReLU-Conv(3×3) ，而一个DenseNet则由多个这种block组成。每个DenseBlock的之间层称为transition layers，由BN−&amp;gt;Conv(1×1)−&amp;gt;averagePooling(2×2)组成&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217132019609-1216378928.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;密集连接不会带来冗余吗？不会！密集连接这个词给人的第一感觉就是极大的增加了网络的参数量和计算量。但实际上 DenseNet 比其他网络效率更高，其关键就在于网络每层计算量的减少以及特征的重复利用。DenseNet则是让l层的输入直接影响到之后的所有层，它的输出为：xl=Hl([X0,X1,…,xl−1])，其中[x0,x1,...,xl−1]就是将之前的feature map以通道的维度进行合并。并且由于每一层都包含之前所有层的输出信息，因此其只需要很少的特征图就够了，这也是为什么DneseNet的参数量较其他模型大大减少的原因。这种dense connection相当于每一层都直接连接input和loss，因此就可以减轻梯度消失现象，这样更深网络不是问题&lt;/p&gt;
&lt;p&gt;需要明确一点，dense connectivity 仅仅是在一个dense block里的，不同dense block 之间是没有dense connectivity的，比如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1093303/201802/1093303-20180217132035937-2041404109.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;天底下没有免费的午餐，网络自然也不例外。在同层深度下获得更好的收敛率，自然是有额外代价的。其代价之一，就是其恐怖如斯的内存占用。&lt;/p&gt;
&lt;p&gt;DenseNet-121的Keras实现：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;def DenseNet121(nb_dense_block=4, growth_rate=32, nb_filter=64, reduction=0.0, dropout_rate=0.0, weight_decay=1e-4, classes=1000, weights_path=None):
    '''Instantiate the DenseNet 121 architecture,
        # Arguments
            nb_dense_block: number of dense blocks to add to end
            growth_rate: number of filters to add per dense block
            nb_filter: initial number of filters
            reduction: reduction factor of transition blocks.
            dropout_rate: dropout rate
            weight_decay: weight decay factor
            classes: optional number of classes to classify images
            weights_path: path to pre-trained weights
        # Returns
            A Keras model instance.
    '''
    eps = 1.1e-5

    # compute compression factor
    compression = 1.0 - reduction

    # Handle Dimension Ordering for different backends
    global concat_axis
    if K.image_dim_ordering() == 'tf':
      concat_axis = 3
      img_input = Input(shape=(224, 224, 3), name='data')
    else:
      concat_axis = 1
      img_input = Input(shape=(3, 224, 224), name='data')

    # From architecture for ImageNet (Table 1 in the paper)
    nb_filter = 64
    nb_layers = [6,12,24,16] # For DenseNet-121

    # Initial convolution
    x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(img_input)
    x = Convolution2D(nb_filter, 7, 7, subsample=(2, 2), name='conv1', bias=False)(x)
    x = BatchNormalization(epsilon=eps, axis=concat_axis, name='conv1_bn')(x)
    x = Scale(axis=concat_axis, name='conv1_scale')(x)
    x = Activation('relu', name='relu1')(x)
    x = ZeroPadding2D((1, 1), name='pool1_zeropadding')(x)
    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)

    # Add dense blocks
    for block_idx in range(nb_dense_block - 1):
        stage = block_idx+2
        x, nb_filter = dense_block(x, stage, nb_layers[block_idx], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)

        # Add transition_block
        x = transition_block(x, stage, nb_filter, compression=compression, dropout_rate=dropout_rate, weight_decay=weight_decay)
        nb_filter = int(nb_filter * compression)

    final_stage = stage + 1
    x, nb_filter = dense_block(x, final_stage, nb_layers[-1], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)

    x = BatchNormalization(epsilon=eps, axis=concat_axis, name='conv'+str(final_stage)+'_blk_bn')(x)
    x = Scale(axis=concat_axis, name='conv'+str(final_stage)+'_blk_scale')(x)
    x = Activation('relu', name='relu'+str(final_stage)+'_blk')(x)
    x = GlobalAveragePooling2D(name='pool'+str(final_stage))(x)

    x = Dense(classes, name='fc6')(x)
    x = Activation('softmax', name='prob')(x)

    model = Model(img_input, x, name='densenet')

    if weights_path is not None:
      model.load_weights(weights_path)

    return model


def conv_block(x, stage, branch, nb_filter, dropout_rate=None, weight_decay=1e-4):
    '''Apply BatchNorm, Relu, bottleneck 1x1 Conv2D, 3x3 Conv2D, and option dropout
        # Arguments
            x: input tensor 
            stage: index for dense block
            branch: layer index within each dense block
            nb_filter: number of filters
            dropout_rate: dropout rate
            weight_decay: weight decay factor
    '''
    eps = 1.1e-5
    conv_name_base = 'conv' + str(stage) + '_' + str(branch)
    relu_name_base = 'relu' + str(stage) + '_' + str(branch)

    # 1x1 Convolution (Bottleneck layer)
    inter_channel = nb_filter * 4  
    x = BatchNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base+'_x1_bn')(x)
    x = Scale(axis=concat_axis, name=conv_name_base+'_x1_scale')(x)
    x = Activation('relu', name=relu_name_base+'_x1')(x)
    x = Convolution2D(inter_channel, 1, 1, name=conv_name_base+'_x1', bias=False)(x)

    if dropout_rate:
        x = Dropout(dropout_rate)(x)

    # 3x3 Convolution
    x = BatchNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base+'_x2_bn')(x)
    x = Scale(axis=concat_axis, name=conv_name_base+'_x2_scale')(x)
    x = Activation('relu', name=relu_name_base+'_x2')(x)
    x = ZeroPadding2D((1, 1), name=conv_name_base+'_x2_zeropadding')(x)
    x = Convolution2D(nb_filter, 3, 3, name=conv_name_base+'_x2', bias=False)(x)

    if dropout_rate:
        x = Dropout(dropout_rate)(x)

    return x


def transition_block(x, stage, nb_filter, compression=1.0, dropout_rate=None, weight_decay=1E-4):
    ''' Apply BatchNorm, 1x1 Convolution, averagePooling, optional compression, dropout 
        # Arguments
            x: input tensor
            stage: index for dense block
            nb_filter: number of filters
            compression: calculated as 1 - reduction. Reduces the number of feature maps in the transition block.
            dropout_rate: dropout rate
            weight_decay: weight decay factor
    '''

    eps = 1.1e-5
    conv_name_base = 'conv' + str(stage) + '_blk'
    relu_name_base = 'relu' + str(stage) + '_blk'
    pool_name_base = 'pool' + str(stage) 

    x = BatchNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base+'_bn')(x)
    x = Scale(axis=concat_axis, name=conv_name_base+'_scale')(x)
    x = Activation('relu', name=relu_name_base)(x)
    x = Convolution2D(int(nb_filter * compression), 1, 1, name=conv_name_base, bias=False)(x)

    if dropout_rate:
        x = Dropout(dropout_rate)(x)

    x = AveragePooling2D((2, 2), strides=(2, 2), name=pool_name_base)(x)

    return x


def dense_block(x, stage, nb_layers, nb_filter, growth_rate, dropout_rate=None, weight_decay=1e-4, grow_nb_filters=True):
    ''' Build a dense_block where the output of each conv_block is fed to subsequent ones
        # Arguments
            x: input tensor
            stage: index for dense block
            nb_layers: the number of layers of conv_block to append to the model.
            nb_filter: number of filters
            growth_rate: growth rate
            dropout_rate: dropout rate
            weight_decay: weight decay factor
            grow_nb_filters: flag to decide to allow number of filters to grow
    '''

    eps = 1.1e-5
    concat_feat = x

    for i in range(nb_layers):
        branch = i+1
        x = conv_block(concat_feat, stage, branch, growth_rate, dropout_rate, weight_decay)
        concat_feat = merge([concat_feat, x], mode='concat', concat_axis=concat_axis, name='concat_'+str(stage)+'_'+str(branch))

        if grow_nb_filters:
            nb_filter += growth_rate

    return concat_feat, nb_filter
&lt;/code&gt;
&lt;/pre&gt;</description>
<pubDate>Sat, 17 Feb 2018 05:21:00 +0000</pubDate>
<dc:creator>Madcola</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/skyfsm/p/8451834.html</dc:identifier>
</item>
</channel>
</rss>