<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Eureka介绍 - 不要乱摸</title>
<link>http://www.cnblogs.com/cjsblog/p/9858154.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/cjsblog/p/9858154.html</guid>
<description>&lt;p&gt;&lt;span&gt;1.  Eureka是什么&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Eureka是一个基于REST的服务，主要用于AWS云中的定位服务，以实现中间层服务器的负载平衡和故障转移&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在 Spring Cloud &lt;strong&gt;微服务&lt;/strong&gt;架构中通常用作&lt;strong&gt;注册中心&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我们称这个服务为 Eureka Server，还有一个与之交互的客户端称之为 Eureka Client&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;2.  Eureka高级架构&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/874963/201810/874963-20181026182110965-1706291309.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如上图所示，其中&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Application Server 表示服务提供方&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Application Client  表示服务消费方&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Make Remote Call 表示远程调用&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;服务在Eureka上注册，然后每隔30秒发送心跳来更新它们的租约。如果客户端不能多次续订租约，那么它将在大约90秒内从服务器注册表中剔除。注册信息和更新被复制到集群中的所有eureka节点。来自任何区域的客户端都可以查找注册表信息（每30秒发生一次）来定位它们的服务（可能在任何区域）并进行远程调用。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;（PS：Eureka Client需要每30秒给Eureka Server发一次心跳，同时更新Server上最新的注册信息到本地，如果Server多次没有收到来自客户端的心跳，那么在90秒内会被Server上剔除）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;3.  Eureka 客户端与服务器之间的通信&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;服务发现有两种模式：一种是客户端发现模式，一种是服务端发现模式。Eureka采用的是客户端发现模式。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;3.1.  Register（注册）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Eureka客户端将关于运行实例的信息注册到Eureka服务器。注册发生在第一次心跳。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;3.2.  Renew（更新 / 续借）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Eureka客户端需要更新最新注册信息（续借），通过每30秒发送一次心跳。更新通知是为了告诉Eureka服务器实例仍然存活。如果服务器在90秒内没有看到更新，它会将实例从注册表中删除。建议不要更改更新间隔，因为服务器使用该信息来确定客户机与服务器之间的通信是否存在广泛传播的问题。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;3.3.  Fetch Registry（抓取注册信息）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Eureka客户端从服务器获取注册表信息并在本地缓存。之后，客户端使用这些信息来查找其他服务。通过在上一个获取周期和当前获取周期之间获取增量更新，这些信息会定期更新(每30秒更新一次)。获取的时候可能返回相同的实例。Eureka客户端自动处理重复信息。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;3.4.  Cancel（取消）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Eureka客户端在关机时向Eureka服务器发送一个取消请求。这将从服务器的实例注册表中删除实例，从而有效地将实例从流量中取出。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;4.  Eureka自我保护模式&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如果 Eureka 服务器检测到超过预期数量的注册客户端以一种不优雅的方式终止了连接，并且同时正在等待被驱逐，那么它们将进入自我保护模式。这样做是为了确保灾难性网络事件不会擦除eureka注册表数据，并将其向下传播到所有客户端。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;任何客户端，如果连续3次心跳更新失败，那么它将被视为非正常终止，病句将被剔除。当超过当前注册实例15%的客户端都处于这种状态，那么自我保护将被开启。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;当自我保护开启以后，eureka服务器将停止剔除所有实例，直到：&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;span&gt;它看到的心跳续借的数量回到了预期的阈值之上，或者&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;自我保护被禁用&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;span&gt;默认情况下，自我保护是启用的，并且，默认的阈值是要大于当前注册数量的15%&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;5.  Eureka  VS  Zookeeper&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; 5.1.  Eureka保证AP&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Eureka服务器节点之间是对等的，只要有一个节点在，就可以正常提供服务。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Eureka客户端的所有操作可能需要一段时间才能在Eureka服务器中反映出来，随后在其他Eureka客户端中反映出来。也就是说，客户端获取到的注册信息可能不是最新的，它并不保证强一致性&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;5.2.  Zookeeper保证CP&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Zookeeper集群中有一个Leader，多个Follower。Leader负责写，Follower负责读，ZK客户端连接到任何一个节点都是一样的，写操作完成以后要同步给所有Follower以后才会返回。如果Leader挂了，那么重新选出新的Leader，在此期间服务不可用。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;5.3.  为什么用Eureka&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;分布式系统大都可以归结为两个问题：数据一致性和防止单点故障。而作为注册中心的话，即使在一段时间内不一致，也不会有太大影响，所以在A和C之间选择A是比较适合该场景的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;6.  其它相关&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;《&lt;span&gt;&lt;a href=&quot;https://www.cnblogs.com/cjsblog/p/9837062.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;分布式事务&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;》&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;7.  参考&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;https://github.com/Netflix/eureka/wiki/Understanding-eureka-client-server-communication&quot; target=&quot;_blank&quot;&gt;https://github.com/Netflix/eureka/wiki/Understanding-eureka-client-server-communication&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;a href=&quot;https://blog.csdn.net/neosmith/article/details/53131023&quot; target=&quot;_blank&quot;&gt;https://blog.csdn.net/neosmith/article/details/53131023&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 29 Oct 2018 07:32:00 +0000</pubDate>
<dc:creator>不要乱摸</dc:creator>
<og:description>1. Eureka是什么 Eureka是一个基于REST的服务，主要用于AWS云中的定位服务，以实现中间层服务器的负载平衡和故障转移 在 Spring Cloud 微服务架构中通常用作注册中心 我们称</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/cjsblog/p/9858154.html</dc:identifier>
</item>
<item>
<title>【3y】从零单排学Redis【青铜】 - Java3y</title>
<link>http://www.cnblogs.com/Java3y/p/9870829.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Java3y/p/9870829.html</guid>
<description>&lt;blockquote&gt;
&lt;p&gt;只有光头才能变强&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d0b361503d?w=1200&amp;amp;h=401&amp;amp;f=png&amp;amp;s=50682&quot; alt=&quot;redis&quot;/&gt;&lt;/p&gt;
&lt;p&gt;最近在学Redis，我相信只要是接触过Java开发的都会听过Redis这么一个技术。面试也是非常高频的一个知识点，之前一直都是处于了解阶段。秋招过后这段时间是没有什么压力的，所以打算系统学学Redis，这也算是我从零学习Redis的笔记吧。&lt;/p&gt;
&lt;p&gt;本文&lt;strong&gt;力求讲清每个知识点&lt;/strong&gt;，希望大家看完能有所收获。&lt;/p&gt;

&lt;p&gt;首先，肯定是去官网看看官方是怎么介绍Redis的啦。&lt;a href=&quot;https://redis.io/topics/introduction&quot; class=&quot;uri&quot;&gt;https://redis.io/topics/introduction&lt;/a&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;如果像我一样，英语可能不太好的，可能看不太懂。没事，咱们Chrome浏览器可以切换成中文的，中文是我们的母语，肯定没啥压力了。Eumm...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;读完之后，发现中文也就那样了。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;一大堆没见过的技术：lua(Lua脚本)、replication(复制)、Redis Sentinel(哨兵)、Redis Cluster(Redis 集群)，当然我们也会有看得懂的技术：transactions(事务)、different levels of on-disk persistence(数据持久化)、LRU eviction(LRU淘汰机制)..&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;至少官方介绍Redis的第一句应该是可以很容易看懂：&quot;Redis is an open source (BSD licensed),&lt;strong&gt;in-memory data structure store&lt;/strong&gt;, used as a database,&lt;strong&gt;cache&lt;/strong&gt; and message broker.&quot;&lt;/p&gt;
&lt;p&gt;Redis是一个开源的，&lt;strong&gt;基于内存的数据结构存储&lt;/strong&gt;，可用作于数据库、&lt;strong&gt;缓存&lt;/strong&gt;、消息中间件。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;从官方的解释上，我们可以知道：Redis是基于内存，支持多种数据结构。&lt;/li&gt;
&lt;li&gt;从经验的角度上，我们可以知道：Redis常用作于缓存。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;就我个人认为：学习一种新技术，先把握该技术整体的知识(思想)，再扣细节，这样学习起来会比较轻松一些。所以我们先以“内存”、“数据结构”、“缓存”来对Redis入门。&lt;/p&gt;
&lt;h2 id=&quot;为什么要用redis&quot;&gt;1.1为什么要用Redis？&lt;/h2&gt;
&lt;p&gt;从上面可知：Redis是&lt;strong&gt;基于内存&lt;/strong&gt;，常用作于&lt;strong&gt;缓存&lt;/strong&gt;的一种技术，并且Redis存储的方式是以&lt;code&gt;key-value&lt;/code&gt;的形式。&lt;/p&gt;
&lt;p&gt;我们可以发现这不就是Java的Map容器所拥有的特性吗，那为什么还需要Redis呢？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Java实现的Map是&lt;strong&gt;本地缓存&lt;/strong&gt;，如果有多台实例(机器)的话，每个实例都需要&lt;strong&gt;各自&lt;/strong&gt;保存一份缓存，缓存&lt;strong&gt;不具有一致性&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Redis实现的是&lt;strong&gt;分布式缓存&lt;/strong&gt;，如果有多台实例(机器)的话，每个实例都&lt;strong&gt;共享&lt;/strong&gt;一份缓存，缓存&lt;strong&gt;具有一致性&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;Java实现的Map&lt;strong&gt;不是专业&lt;/strong&gt;做缓存的，JVM内存太大容易挂掉的。一般用做于容器来存储临时数据，缓存的数据随着JVM销毁而结束。Map所存储的数据结构，缓存过期机制等等是需要程序员自己手写的。&lt;/li&gt;
&lt;li&gt;Redis是&lt;strong&gt;专业&lt;/strong&gt;做缓存的，可以用几十个G内存来做缓存。Redis一般用作于缓存，可以将缓存数据保存在硬盘中，Redis重启了后可以将其恢复。原生提供丰富的数据结构、缓存过期机制等等简单好用的功能。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;参考资料：&lt;/p&gt;
&lt;h2 id=&quot;为什么要用缓存&quot;&gt;1.2为什么要用缓存？&lt;/h2&gt;
&lt;p&gt;如果我们的网站出现了性能问题(访问时间慢)，按经验来说，一般是由于&lt;strong&gt;数据库撑不住了&lt;/strong&gt;。因为一般数据库的读写都是要经过&lt;strong&gt;磁盘&lt;/strong&gt;的，而磁盘的速度可以说是相当慢的(相对内存来说)&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d0add27079?w=743&amp;amp;h=538&amp;amp;f=png&amp;amp;s=17518&quot; alt=&quot;数据库撑不住了&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如果学过Mybaits、Hibernate的同学就可以知道，它们有一级缓存、二级缓存这样的功能(终究来说还是本地缓存)。目的就是为了：&lt;strong&gt;不用每次读取的时候，都要查一次数据库&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;有了缓存之后，我们的访问就变成这样了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d0b6ef808a?w=1166&amp;amp;h=677&amp;amp;f=png&amp;amp;s=33453&quot; alt=&quot;有了缓存提高了并发和性能&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;二redis的数据结构&quot;&gt;二、Redis的数据结构&lt;/h2&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;本文不会讲述命令的使用方式，具体的如何使用可查询API。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Redis支持丰富的数据结构，&lt;strong&gt;常用&lt;/strong&gt;的有string、list、hash、set、sortset这几种。学习这些数据结构是使用Redis的基础！&lt;/p&gt;
&lt;p&gt;&quot;Redis is written in ANSI C&quot;--&amp;gt;Redis由C语言编写&lt;/p&gt;
&lt;p&gt;首先还是得声明一下，Redis的存储是以&lt;code&gt;key-value&lt;/code&gt;的形式的。Redis中的key一定是字符串，value可以是string、list、hash、set、sortset这几种常用的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d0b44ba6d1?w=793&amp;amp;h=509&amp;amp;f=png&amp;amp;s=18467&quot; alt=&quot;redis数据结构&quot;/&gt;&lt;/p&gt;
&lt;p&gt;但要值得注意的是：Redis并&lt;strong&gt;没有直接使用&lt;/strong&gt;这些数据结构来实现&lt;code&gt;key-value&lt;/code&gt;数据库，而是&lt;strong&gt;基于&lt;/strong&gt;这些数据结构创建了一个&lt;strong&gt;对象系统&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;简单来说：Redis使用对象来表示数据库中的键和值。每次我们在Redis数据库中新创建一个键值对时，&lt;strong&gt;至少会创建出两个对象&lt;/strong&gt;。一个是键对象，一个是值对象。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Redis中的每个对象都由一个redisObject结构来表示：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;
typedef struct redisObject{
    
    // 对象的类型
    unsigned type 4:;

    // 对象的编码格式
    unsigned encoding:4;

    // 指向底层实现数据结构的指针
    void * ptr;

    //.....


}robj;

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d0b081d5a2?w=1627&amp;amp;h=730&amp;amp;f=png&amp;amp;s=87493&quot; alt=&quot;数据结构对应的类型与编码&quot;/&gt;&lt;/p&gt;
&lt;p&gt;简单来说就是Redis对&lt;code&gt;key-value&lt;/code&gt;封装成对象，key是一个对象，value也是一个对象。每个对象都有type(类型)、encoding(编码)、ptr(指向底层数据结构的指针)来表示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d0b37f6989?w=833&amp;amp;h=349&amp;amp;f=png&amp;amp;s=13630&quot; alt=&quot;以值为1006的字符串对象为例&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面我就来说一下我们Redis常见的数据类型：string、list、hash、set、sortset。它们的底层数据结构究竟是怎么样的！&lt;/p&gt;
&lt;h2 id=&quot;sds简单动态字符串&quot;&gt;2.1SDS简单动态字符串&lt;/h2&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;简单动态字符串(Simple dynamic string,SDS)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Redis中的字符串跟C语言中的字符串，是&lt;strong&gt;有点差距的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;Redis使用sdshdr结构来表示一个SDS值：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;
struct sdshdr{

    // 字节数组，用于保存字符串
    char buf[];

    // 记录buf数组中已使用的字节数量，也是字符串的长度
    int len;

    // 记录buf数组未使用的字节数量
    int free;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;例子：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d112fb486f?w=763&amp;amp;h=222&amp;amp;f=png&amp;amp;s=7542&quot; alt=&quot;SDS例子&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;使用sds的好处&quot;&gt;2.1.1使用SDS的好处&lt;/h3&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;SDS与C的字符串表示比较&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol&gt;&lt;li&gt;sdshdr数据结构中用len属性记录了字符串的长度。那么&lt;strong&gt;获取字符串的长度时，时间复杂度只需要O(1)&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;SDS不会发生溢出的问题，如果修改SDS时，空间不足。先会扩展空间，再进行修改！(&lt;strong&gt;内部实现了动态扩展机制&lt;/strong&gt;)。&lt;/li&gt;
&lt;li&gt;SDS可以&lt;strong&gt;减少内存分配的次数&lt;/strong&gt;(空间预分配机制)。在扩展空间时，除了分配修改时所必要的空间，还会分配额外的空闲空间(free 属性)。&lt;/li&gt;
&lt;li&gt;SDS是&lt;strong&gt;二进制安全的&lt;/strong&gt;，所有SDS API都会以处理二进制的方式来处理SDS存放在buf数组里的数据。&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;链表&quot;&gt;2.2链表&lt;/h2&gt;
&lt;p&gt;对于链表而言，我们不会陌生的了。在大学期间肯定开过数据结构与算法课程，链表肯定是讲过的了。在Java中Linkedxxx容器底层数据结构也是链表+[xxx]的。我们来看看Redis中的链表是怎么实现的：&lt;/p&gt;
&lt;p&gt;使用listNode结构来表示每个节点：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;


typedef strcut listNode{

    //前置节点
    strcut listNode  *pre;

    //后置节点
    strcut listNode  *pre;

    //节点的值
    void  *value;

}listNode
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;使用listNode是可以组成链表了，Redis中&lt;strong&gt;使用list结构来持有链表&lt;/strong&gt;：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;
typedef struct list{

    //表头结点
    listNode  *head;

    //表尾节点
    listNode  *tail;

    //链表长度
    unsigned long len;

    //节点值复制函数
    void *(*dup) (viod *ptr);

    //节点值释放函数
    void  (*free) (viod *ptr);

    //节点值对比函数
    int (*match) (void *ptr,void *key);

}list
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;具体的结构如图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d11b171189?w=790&amp;amp;h=268&amp;amp;f=png&amp;amp;s=12074&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;redis链表的特性&quot;&gt;2.2.1Redis链表的特性&lt;/h2&gt;
&lt;p&gt;Redis的链表有以下特性：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;无环双向链表&lt;/li&gt;
&lt;li&gt;获取表头指针，表尾指针，链表节点长度的时间复杂度均为O(1)&lt;/li&gt;
&lt;li&gt;链表使用&lt;code&gt;void *&lt;/code&gt;指针来保存节点值，可以保存各种不同类型的值&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;哈希表&quot;&gt;2.3哈希表&lt;/h2&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;声明：《Redis设计与实现》里边有“字典”这么一个概念，我个人认为还是直接叫哈希表比较通俗易懂。从代码上看：“字典”也是在哈希表基础上再抽象了一层而已。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在Redis中，&lt;code&gt;key-value&lt;/code&gt;的数据结构底层就是哈希表来实现的。对于哈希表来说，我们也并不陌生。在Java中，哈希表实际上就是数组+链表的形式来构建的。下面我们来看看Redis的哈希表是怎么构建的吧。&lt;/p&gt;
&lt;p&gt;在Redis里边，哈希表使用dictht结构来定义：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;    typedef struct dictht{
        
        //哈希表数组
        dictEntry **table;  
    
        //哈希表大小
        unsigned long size;    
    
        //哈希表大小掩码，用于计算索引值
        //总是等于size-1
        unsigned long sizemark;     
    
        //哈希表已有节点数量
        unsigned long used;
         
    }dictht
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d11e4063b9?w=481&amp;amp;h=236&amp;amp;f=png&amp;amp;s=28184&quot; alt=&quot;哈希表的数据结构&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们下面继续写看看哈希表的节点是怎么实现的吧：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;
    typedef struct dictEntry {
        
        //键
        void *key;
    
        //值
        union {
            void *value;
            uint64_tu64;
            int64_ts64;
        }v;    
    
        //指向下个哈希节点，组成链表
        struct dictEntry *next;
    
    }dictEntry;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从结构上看，我们可以发现：Redis实现的哈希表和Java中实现的是&lt;strong&gt;类似&lt;/strong&gt;的。只不过Redis多了几个属性来记录常用的值：sizemark(掩码)、used(已有的节点数量)、size(大小)。&lt;/p&gt;
&lt;p&gt;同样地，Redis为了更好的操作，对哈希表往上再封装了一层(参考上面的Redis实现链表)，使用dict结构来表示：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;
typedef struct dict {

    //类型特定函数
    dictType *type;

    //私有数据
    void *privdata;
  
    //哈希表
    dictht ht[2];

    //rehash索引
    //当rehash不进行时，值为-1
    int rehashidx;  

}dict;


//-----------------------------------

typedef struct dictType{

    //计算哈希值的函数
    unsigned int (*hashFunction)(const void * key);

    //复制键的函数
    void *(*keyDup)(void *private, const void *key);
 
    //复制值得函数
    void *(*valDup)(void *private, const void *obj);  

    //对比键的函数
    int (*keyCompare)(void *privdata , const void *key1, const void *key2)

    //销毁键的函数
    void (*keyDestructor)(void *private, void *key);
 
    //销毁值的函数
    void (*valDestructor)(void *private, void *obj);  

}dictType
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;所以，最后我们可以发现，Redis所实现的哈希表最后的数据结构是这样子的：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d151ff3761?w=903&amp;amp;h=461&amp;amp;f=png&amp;amp;s=77731&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从代码实现和示例图上我们可以发现，&lt;strong&gt;Redis中有两个哈希表&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ht[0]：用于存放&lt;strong&gt;真实&lt;/strong&gt;的&lt;code&gt;key-vlaue&lt;/code&gt;数据&lt;/li&gt;
&lt;li&gt;ht[1]：用于&lt;strong&gt;扩容(rehash)&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Redis中哈希算法和哈希冲突跟Java实现的差不多，它俩&lt;strong&gt;差异&lt;/strong&gt;就是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Redis哈希冲突时：是将新节点添加在链表的&lt;strong&gt;表头&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;JDK1.8后，Java在哈希冲突时：是将新的节点添加到链表的&lt;strong&gt;表尾&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;rehash的过程&quot;&gt;2.3.1rehash的过程&lt;/h2&gt;
&lt;p&gt;下面来具体讲讲Redis是怎么rehash的，因为我们从上面可以明显地看到，&lt;strong&gt;Redis是专门使用一个哈希表来做rehash的&lt;/strong&gt;。这跟Java一次性直接rehash是有区别的。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;在对哈希表进行扩展或者收缩操作时，reash过程并不是一次性地完成的，而是&lt;strong&gt;渐进式&lt;/strong&gt;地完成的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Redis在rehash时采取渐进式的原因：&lt;strong&gt;数据量如果过大的话，一次性rehash会有庞大的计算量，这很可能导致服务器一段时间内停止服务&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;Redis具体是rehash时这么干的：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;(1:在字典中维持一个索引计数器变量rehashidx，并将设置为0，表示rehash开始。&lt;/li&gt;
&lt;li&gt;(2:在rehash期间每次对字典进行增加、查询、删除和更新操作时，&lt;strong&gt;除了执行指定命令外&lt;/strong&gt;；还会将ht[0]中rehashidx索引上的值&lt;strong&gt;rehash到ht[1]&lt;/strong&gt;，操作完成后rehashidx+1。&lt;/li&gt;
&lt;li&gt;(3:字典操作不断执行，最终在某个时间点，所有的键值对完成rehash，这时&lt;strong&gt;将rehashidx设置为-1，表示rehash完成&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;(4:在渐进式rehash过程中，字典会同时使用两个哈希表ht[0]和ht[1]，所有的更新、删除、查找操作也会在两个哈希表进行。例如要查找一个键的话，&lt;strong&gt;服务器会优先查找ht[0]，如果不存在，再查找ht[1]&lt;/strong&gt;，诸如此类。此外当执行&lt;strong&gt;新增操作&lt;/strong&gt;时，新的键值对&lt;strong&gt;一律保存到ht[1]&lt;/strong&gt;，不再对ht[0]进行任何操作，以保证ht[0]的键值对数量只减不增，直至变为空表。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;跳跃表shiplist&quot;&gt;2.4跳跃表(shiplist)&lt;/h2&gt;
&lt;p&gt;跳跃表(shiplist)是实现sortset(&lt;strong&gt;有序&lt;/strong&gt;集合)的底层数据结构之一！&lt;/p&gt;
&lt;p&gt;跳跃表可能对于大部分人来说不太常见，之前我在学习的时候发现了一篇不错的文章讲跳跃表的，建议大家先去看完下文再继续回来阅读：&lt;/p&gt;
&lt;p&gt;Redis的跳跃表实现由zskiplist和zskiplistNode两个结构组成。其中&lt;strong&gt;zskiplist保存跳跃表的信息&lt;/strong&gt;(表头，表尾节点，长度)，&lt;strong&gt;zskiplistNode则表示跳跃表的节点&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;按照惯例，我们来看看zskiplistNode跳跃表节点的结构是怎么样的：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;
typeof struct zskiplistNode {
        // 后退指针
        struct zskiplistNode *backward;
        // 分值
        double score;
        // 成员对象
        robj *obj;
        // 层
        struct zskiplistLevel {
                // 前进指针
                struct zskiplistNode *forward;
                // 跨度
                unsigned int span;
        } level[];
} zskiplistNode;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;zskiplistNode的对象示例图(带有不同层高的节点)：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d17a8801e8?w=676&amp;amp;h=334&amp;amp;f=png&amp;amp;s=7902&quot; alt=&quot;带有不同层高的节点&quot;/&gt;&lt;/p&gt;
&lt;p&gt;示例图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d17b3f1756?w=1016&amp;amp;h=505&amp;amp;f=png&amp;amp;s=23618&quot; alt=&quot;跳跃表节点的示例图&quot;/&gt;&lt;/p&gt;
&lt;p&gt;zskiplist的结构如下：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;typeof struct zskiplist {
        // 表头节点，表尾节点
        struct skiplistNode *header,*tail;
        // 表中节点数量
        unsigned long length;
        // 表中最大层数
        int level;
} zskiplist;

&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后我们整个跳跃表的示例图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d1c1ae1e62?w=1066&amp;amp;h=531&amp;amp;f=png&amp;amp;s=28176&quot; alt=&quot;跳跃表示例图&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;整数集合intset&quot;&gt;2.5整数集合(intset)&lt;/h2&gt;
&lt;p&gt;整数集合是set(集合)的底层数据结构之一。当一个set(集合)&lt;strong&gt;只包含整数值元素&lt;/strong&gt;，并且&lt;strong&gt;元素的数量不多&lt;/strong&gt;时，Redis就会采用整数集合(intset)作为set(集合)的底层实现。&lt;/p&gt;
&lt;p&gt;整数集合(intset)保证了元素是&lt;strong&gt;不会出现重复&lt;/strong&gt;的，并且是&lt;strong&gt;有序&lt;/strong&gt;的(从小到大排序)，intset的结构是这样子的：&lt;/p&gt;
&lt;pre class=&quot;c&quot;&gt;
&lt;code&gt;
typeof struct intset {
        // 编码方式
        unit32_t encoding;
        // 集合包含的元素数量
        unit32_t lenght;
        // 保存元素的数组
        int8_t contents[];
} intset;
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;intset示例图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d1ac2b7d4b?w=612&amp;amp;h=291&amp;amp;f=png&amp;amp;s=12321&quot; alt=&quot;intset示例图&quot;/&gt;&lt;/p&gt;
&lt;p&gt;说明：虽然intset结构将contents属性声明为int8_t类型的数组，但实际上contents数组并不保存任何int8_t类型的值，&lt;strong&gt;contents数组的真正类型取决于encoding属性的值&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;INTSET_ENC_INT16&lt;/li&gt;
&lt;li&gt;INTSET_ENC_INT32&lt;/li&gt;
&lt;li&gt;INTSET_ENC_INT64&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;从编码格式的名字我们就可以知道，16,32,64编码对应能存放的数字范围是不一样的。16明显最少，64明显最大。&lt;/p&gt;
&lt;p&gt;如果本来是INTSET_ENC_INT16的编码，想要存放大于INTSET_ENC_INT16编码能存放的整数值，此时就得编码&lt;strong&gt;升级&lt;/strong&gt;(从16升级成32或者64)。步骤如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1）根据新元素类型拓展整数集合底层数组的空间并为新元素分配空间。&lt;/li&gt;
&lt;li&gt;2）将底层数组现有的所以元素都转换成与新元素相同的类型，并将类型转换后的元素放到正确的位上，需要维持底层数组的有序性质不变。&lt;/li&gt;
&lt;li&gt;3）将新元素添加到底层数组。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;另外一提：&lt;strong&gt;只支持升级操作，并不支持降级操作&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;压缩列表ziplist&quot;&gt;2.6压缩列表(ziplist)&lt;/h2&gt;
&lt;p&gt;压缩列表(ziplist)是list和hash的底层实现之一。如果list的每个都是小整数值，或者是比较短的字符串，压缩列表(ziplist)作为list的底层实现。&lt;/p&gt;
&lt;p&gt;压缩列表(ziplist)是Redis为了节约内存而开发的，是由一系列的&lt;strong&gt;特殊编码的连续内存块&lt;/strong&gt;组成的&lt;strong&gt;顺序性&lt;/strong&gt;数据结构。&lt;/p&gt;
&lt;p&gt;压缩列表结构图例如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d1e4e4f50e?w=1225&amp;amp;h=291&amp;amp;f=png&amp;amp;s=14208&quot; alt=&quot;压缩列表的组成部分&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面我们看看节点的结构图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d237d200fd?w=694&amp;amp;h=238&amp;amp;f=png&amp;amp;s=10224&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;压缩列表从表尾节点&lt;strong&gt;倒序遍历&lt;/strong&gt;，首先指针通过zltail偏移量指向表尾节点，然后通过指向&lt;strong&gt;节点记录的前一个节点的长度依次向前遍历访问整个压缩列表&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;再次看回这张图，觉不觉得就很好理解了？&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d0b081d5a2?w=1627&amp;amp;h=730&amp;amp;f=png&amp;amp;s=87493&quot; alt=&quot;数据结构对应的类型与编码&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;字符串stirng对象&quot;&gt;3.1字符串(stirng)对象&lt;/h2&gt;
&lt;p&gt;在上面的图我们知道string类型有三种&lt;strong&gt;编码格式&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;int：整数值，这个整数值可以使用long类型来表示
&lt;ul&gt;&lt;li&gt;如果是浮点数，那就用embstr或者raw编码。具体用哪个就看这个数的长度了&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;embstr：字符串值，这个字符串值的长度小于39字节&lt;/li&gt;
&lt;li&gt;raw：字符串值，这个字符串值的长度大于39字节&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;embstr和raw的&lt;strong&gt;区别&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;raw分配内存和释放内存的次数是两次，embstr是一次&lt;/li&gt;
&lt;li&gt;embstr编码的数据保存在一块&lt;strong&gt;连续&lt;/strong&gt;的内存里面&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;编码之间的&lt;strong&gt;转换&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;int类型如果存的&lt;strong&gt;不再是一个整数值&lt;/strong&gt;，则会从int转成raw&lt;/li&gt;
&lt;li&gt;embstr是只读的，在修改的时候回从embstr转成raw&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;列表list对象&quot;&gt;3.2列表(list)对象&lt;/h2&gt;
&lt;p&gt;在上面的图我们知道list类型有两种&lt;strong&gt;编码格式&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ziplist：字符串元素的长度都小于64个字节&lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt;总数量少于512个&lt;/li&gt;
&lt;li&gt;linkedlist：字符串元素的长度大于64个字节&lt;code&gt;||&lt;/code&gt;总数量大于512个&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;ziplist编码的列表结构：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;    redis &amp;gt; RPUSH numbers 1 &quot;three&quot; 5
    (integer) 3 
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d258acad54?w=958&amp;amp;h=293&amp;amp;f=png&amp;amp;s=13654&quot; alt=&quot;ziplist的列表结构&quot;/&gt;&lt;/p&gt;
&lt;p&gt;linkedlist编码的列表结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d28cf0203f?w=1055&amp;amp;h=280&amp;amp;f=png&amp;amp;s=20539&quot; alt=&quot;linkedlist编码的列表结构&quot;/&gt;&lt;/p&gt;
&lt;p&gt;编码之间的&lt;strong&gt;转换：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;原本是ziplist编码的，如果保存的数据长度太大或者元素数量过多，会转换成linkedlist编码的。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;哈希hash对象&quot;&gt;3.3哈希(hash)对象&lt;/h2&gt;
&lt;p&gt;在上面的图我们知道hash类型有两种&lt;strong&gt;编码格式&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ziplist：key和value的字符串长度都小于64字节&lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt;键值对总数量小于512&lt;/li&gt;
&lt;li&gt;hashtable：key和value的字符串长度大于64字节&lt;code&gt;||&lt;/code&gt;键值对总数量大于512&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;ziplist编码的哈希结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d29c4d898b?w=457&amp;amp;h=306&amp;amp;f=png&amp;amp;s=8626&quot; alt=&quot;ziplist编码的哈希结构1&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d2a909aea8?w=1009&amp;amp;h=134&amp;amp;f=png&amp;amp;s=13546&quot; alt=&quot;ziplist编码的哈希结构2&quot;/&gt;&lt;/p&gt;
&lt;p&gt;hashtable编码的哈希结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d2e2248e9a?w=671&amp;amp;h=402&amp;amp;f=png&amp;amp;s=18814&quot; alt=&quot;hashtable编码的哈希结构&quot;/&gt;&lt;/p&gt;
&lt;p&gt;编码之间的&lt;strong&gt;转换：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;原本是ziplist编码的，如果保存的数据长度太大或者元素数量过多，会转换成hashtable编码的。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;集合set对象&quot;&gt;3.4集合(set)对象&lt;/h2&gt;
&lt;p&gt;在上面的图我们知道set类型有两种&lt;strong&gt;编码格式&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;intset：保存的元素全都是整数&lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt;总数量小于512&lt;/li&gt;
&lt;li&gt;hashtable：保存的元素不是整数&lt;code&gt;||&lt;/code&gt;总数量大于512&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;intset编码的集合结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d301b6e395?w=781&amp;amp;h=234&amp;amp;f=png&amp;amp;s=13061&quot; alt=&quot;intset编码的集合结构&quot;/&gt;&lt;/p&gt;
&lt;p&gt;hashtable编码的集合结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d2fb0be51c?w=588&amp;amp;h=251&amp;amp;f=png&amp;amp;s=14591&quot; alt=&quot;hashtable编码的集合结构&quot;/&gt;&lt;/p&gt;
&lt;p&gt;编码之间的&lt;strong&gt;转换：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;原本是intset编码的，如果保存的数据不是整数值或者元素数量大于512，会转换成hashtable编码的。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;有序集合sortset对象&quot;&gt;3.5有序集合(sortset)对象&lt;/h2&gt;
&lt;p&gt;在上面的图我们知道set类型有两种&lt;strong&gt;编码格式&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;ziplist：元素长度小于64&lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt;总数量小于128&lt;/li&gt;
&lt;li&gt;skiplist：元素长度大于64&lt;code&gt;||&lt;/code&gt;总数量大于128&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;ziplist编码的有序集合结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d303502e28?w=433&amp;amp;h=229&amp;amp;f=png&amp;amp;s=7427&quot; alt=&quot;ziplist编码的有序集合结构1&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d356b6995b?w=935&amp;amp;h=128&amp;amp;f=png&amp;amp;s=12056&quot; alt=&quot;ziplist编码的有序集合结构2&quot;/&gt;&lt;/p&gt;
&lt;p&gt;skiplist编码的有序集合结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://user-gold-cdn.xitu.io/2018/10/29/166be8d3441102ec?w=973&amp;amp;h=816&amp;amp;f=png&amp;amp;s=27002&quot; alt=&quot;skiplist编码的有序集合结构&quot;/&gt;&lt;/p&gt;
&lt;p&gt;有序集合(sortset)对象&lt;strong&gt;同时采用skiplist和哈希表来实现&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;skiplist能够达到插入的时间复杂度为O(logn)，根据成员查分值的时间复杂度为O(1)&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;编码之间的&lt;strong&gt;转换：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;原本是ziplist编码的，如果保存的数据长度大于64或者元素数量大于128，会转换成skiplist编码的。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;redis对象一些细节&quot;&gt;3.6Redis对象一些细节&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;(1：服务器在执行某些命令的时候，会&lt;strong&gt;先检查给定的键的类型&lt;/strong&gt;能否执行指定的命令。
&lt;ul&gt;&lt;li&gt;比如我们的数据结构是sortset，但你使用了list的命令。这是不对的，服务器会检查一下我们的数据结构是什么才会进一步执行命令&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;(2：Redis的对象系统带有&lt;strong&gt;引用计数&lt;/strong&gt;实现的&lt;strong&gt;内存回收机制&lt;/strong&gt;。
&lt;ul&gt;&lt;li&gt;对象不再被使用的时候，对象所占用的内存会释放掉&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;(3：Redis会共享值为0到9999的字符串对象&lt;/li&gt;
&lt;li&gt;(4：对象&lt;strong&gt;会记录自己的最后一次被访问时间&lt;/strong&gt;，这个时间可以用于计算对象的空转时间。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文主要讲了一下Redis常用的数据结构，以及这些数据结构的底层设计是怎么样的。整体来说不会太难，因为这些数据结构我们在学习的过程中多多少少都接触过了，《Redis设计与实现》这本书写得也足够通俗易懂。&lt;/p&gt;
&lt;p&gt;至于我们在使用的时候挑选哪些数据结构作为存储，可以简单看看：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;string--&amp;gt;简单的&lt;code&gt;key-value&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;list--&amp;gt;有序列表(底层是双向链表)--&amp;gt;可做简单队列&lt;/li&gt;
&lt;li&gt;set--&amp;gt;无序列表(去重)--&amp;gt;提供一系列的交集、并集、差集的命令&lt;/li&gt;
&lt;li&gt;hash--&amp;gt;哈希表--&amp;gt;存储结构化数据&lt;/li&gt;
&lt;li&gt;sortset--&amp;gt;有序集合映射(member-score)--&amp;gt;排行榜&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;如果大家有更好的理解方式或者文章有错误的地方还请大家不吝在评论区留言，大家互相学习交流~~~&lt;/p&gt;
&lt;p&gt;参考博客：&lt;/p&gt;
&lt;p&gt;参考资料：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;《Redis设计与实现》&lt;/li&gt;
&lt;li&gt;《Redis实战》&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;一个&lt;strong&gt;坚持原创的Java技术公众号：Java3y&lt;/strong&gt;，欢迎大家关注&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;原创技术文章导航：&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 29 Oct 2018 07:20:00 +0000</pubDate>
<dc:creator>Java3y</dc:creator>
<og:description>Redis学习</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/Java3y/p/9870829.html</dc:identifier>
</item>
<item>
<title>Spring基础系列-容器启动流程(1) - 唯一浩哥</title>
<link>http://www.cnblogs.com/V1haoge/p/9870339.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/V1haoge/p/9870339.html</guid>
<description>&lt;p&gt;原创作品，可以转载，但是请标注出处地址：&lt;a href=&quot;https://www.cnblogs.com/V1haoge/p/9870339.html&quot; class=&quot;uri&quot; title=&quot;文章出处&quot;&gt;https://www.cnblogs.com/V1haoge/p/9870339.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;概述&quot;&gt;概述&lt;/h2&gt;
&lt;pre&gt;
&lt;code&gt;我说的容器启动流程涉及两种情况，SSM开发模式和Springboot开发模式。&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;　　SSM开发模式中，需要配置web.xml文件用作启动配置文件，而Springboot开发模式中由main方法直接启动。&lt;/p&gt;
&lt;p&gt;　　下面是web项目中容器启动的流程，起点是web.xml中配置的ContextLoaderListener监听器。&lt;/p&gt;
&lt;h2 id=&quot;调用流程图右键可查看大图&quot;&gt;调用流程图（右键可查看大图）&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/592104/201810/592104-20181029140859646-541622002.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;流程解析&quot;&gt;流程解析&lt;/h2&gt;
&lt;p&gt;　　Tomcat服务器启动时会读取项目中&lt;code&gt;web.xml&lt;/code&gt;中的配置项来生成&lt;code&gt;ServletContext&lt;/code&gt;，在其中注册的&lt;code&gt;ContextLoaderListener&lt;/code&gt;是&lt;code&gt;ServletContextListener&lt;/code&gt;接口的实现类，它会时刻监听&lt;code&gt;ServletContext&lt;/code&gt;的动作，包括创建和销毁，&lt;code&gt;ServletContext&lt;/code&gt;创建的时候会触发其&lt;code&gt;contextInitialized()&lt;/code&gt;初始化方法的执行。而Spring容器的初始化操作就在这个方法之中被触发。&lt;/p&gt;
&lt;p&gt;　　源码1-来自：ContextLoaderListener&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;/**
 * Initialize the root web application context.
 */
@Override
public void contextInitialized(ServletContextEvent event) {
    initWebApplicationContext(event.getServletContext());
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;　　&lt;code&gt;ContextLoaderListener&lt;/code&gt;是启动和销毁Spring的&lt;code&gt;root WebApplicationContext&lt;/code&gt;（根web容器或者根web应用上下文）的引导器，其中实现了&lt;code&gt;ServletContextListener&lt;/code&gt;的&lt;code&gt;contextInitialized&lt;/code&gt;容器初始化方法与&lt;code&gt;contextDestoryed&lt;/code&gt;销毁方法，用于引导根web容器的创建和销毁。&lt;/p&gt;
&lt;p&gt;　　上面方法中&lt;code&gt;contextInitialized&lt;/code&gt;就是初始化根web容器的方法。其中调用了&lt;code&gt;initWebApplicationContext&lt;/code&gt;方法进行Spring web容器的具体创建。&lt;/p&gt;
&lt;p&gt;　　源码2-来自：ContextLoader&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public WebApplicationContext initWebApplicationContext(ServletContext servletContext) {
    //SpringIOC容器的重复性创建校验
    if (servletContext.getAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE) != null) {
        throw new IllegalStateException(
            &quot;Cannot initialize context because there is already a root application context present - &quot; +
            &quot;check whether you have multiple ContextLoader* definitions in your web.xml!&quot;);
    }

    Log logger = LogFactory.getLog(ContextLoader.class);
    servletContext.log(&quot;Initializing Spring root WebApplicationContext&quot;);
    if (logger.isInfoEnabled()) {
        logger.info(&quot;Root WebApplicationContext: initialization started&quot;);
    }
    //记录Spring容器创建开始时间
    long startTime = System.currentTimeMillis();

    try {
        // Store context in local instance variable, to guarantee that
        // it is available on ServletContext shutdown.
        if (this.context == null) {
            //创建Spring容器实例
            this.context = createWebApplicationContext(servletContext);
        }
        if (this.context instanceof ConfigurableWebApplicationContext) {
            ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context;
            if (!cwac.isActive()) {
                //容器只有被刷新至少一次之后才是处于active（激活）状态
                if (cwac.getParent() == null) {
                    //此处是一个空方法，返回null,也就是不设置父级容器
                    ApplicationContext parent = loadParentContext(servletContext);
                    cwac.setParent(parent);
                }
                //重点操作：配置并刷新容器
                configureAndRefreshWebApplicationContext(cwac, servletContext);
            }
        }
        //将创建完整的Spring容器作为一条属性添加到Servlet容器中
        servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context);

        ClassLoader ccl = Thread.currentThread().getContextClassLoader();
        if (ccl == ContextLoader.class.getClassLoader()) {
            //如果当前线程的类加载器是ContextLoader类的类加载器的话，也就是说如果是当前线程加载了ContextLoader类的话，则将Spring容器在ContextLoader实例中保留一份引用
            currentContext = this.context;
        }
        else if (ccl != null) {
            //添加一条ClassLoader到Springweb容器的映射
            currentContextPerThread.put(ccl, this.context);
        }

        if (logger.isDebugEnabled()) {
            logger.debug(&quot;Published root WebApplicationContext as ServletContext attribute with name [&quot; +
                         WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE + &quot;]&quot;);
        }
        if (logger.isInfoEnabled()) {
            long elapsedTime = System.currentTimeMillis() - startTime;
            logger.info(&quot;Root WebApplicationContext: initialization completed in &quot; + elapsedTime + &quot; ms&quot;);
        }

        return this.context;
    }
    catch (RuntimeException ex) {
        logger.error(&quot;Context initialization failed&quot;, ex);
        servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, ex);
        throw ex;
    }
    catch (Error err) {
        logger.error(&quot;Context initialization failed&quot;, err);
        servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, err);
        throw err;
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;　　这里十分清晰的显示出了&lt;code&gt;ServletContext&lt;/code&gt;和&lt;code&gt;Spring root ApplicationContext&lt;/code&gt;的关系：后者只是前者的一个属性，前者包含后者。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;知识点：&lt;/p&gt;
&lt;p&gt;​ &lt;code&gt;ServletContext&lt;/code&gt;表示的是一整个应用，其中囊括应用的所有内容，而&lt;code&gt;Spring&lt;/code&gt;只是应用所采用的一种框架。从&lt;code&gt;ServletContext&lt;/code&gt;的角度来看，Spring框架其实也算是应用的一部分，属于和我们编写的代码同级的存在，只是相对于我们编码人员来说，Spring是作为一种即存的编码架构而存在的，即我们将其看作我们编码的基础，或者看作应用的基础部件。虽然是基础部件，但也是属于应用的一部分。所以将其设置到&lt;code&gt;ServletContext&lt;/code&gt;中，而且是作为一个单一属性而存在，但是它的作用却是很大的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;　　源码中&lt;code&gt;WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE&lt;/code&gt;的值为：&lt;code&gt;WebApplicationContext.class.getName() + &quot;.ROOT&quot;&lt;/code&gt;，这个正是Spring容器在&lt;code&gt;ServletContext&lt;/code&gt;中的属性名。&lt;/p&gt;
&lt;p&gt;　　在这段源码中主要是概述Spring容器的创建和初始化，分别由两个方法实现：&lt;strong&gt;createWebApplicationContext&lt;/strong&gt;方法和&lt;strong&gt;configureAndRefreshWebApplicationContext&lt;/strong&gt;方法。&lt;/p&gt;
&lt;p&gt;　　首先，我们需要创建Spring容器，我们需要决定使用哪个容器实现。&lt;/p&gt;
&lt;p&gt;　　源码3-来自：ContextLoader&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;protected WebApplicationContext createWebApplicationContext(ServletContext sc) {
    //决定使用哪个容器实现
    Class&amp;lt;?&amp;gt; contextClass = determineContextClass(sc);
    if (!ConfigurableWebApplicationContext.class.isAssignableFrom(contextClass)) {
        throw new ApplicationContextException(&quot;Custom context class [&quot; + contextClass.getName() +
                                              &quot;] is not of type [&quot; + ConfigurableWebApplicationContext.class.getName() + &quot;]&quot;);
    }
    //反射方式创建容器实例
    return (ConfigurableWebApplicationContext) BeanUtils.instantiateClass(contextClass);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;//我们在web.xml中以 &amp;lt;context-param&amp;gt; 的形式设置contextclass参数来指定使用哪个容器实现类，
//若未指定则使用默认的XmlWebApplicationContext，其实这个默认的容器实现也是预先配置在一个
//叫ContextLoader.properties文件中的
protected Class&amp;lt;?&amp;gt; determineContextClass(ServletContext servletContext) {
    //获取Servlet容器中配置的系统参数contextClass的值，如果未设置则为null
    String contextClassName = servletContext.getInitParameter(CONTEXT_CLASS_PARAM);
    if (contextClassName != null) {
        try {
            return ClassUtils.forName(contextClassName, ClassUtils.getDefaultClassLoader());
        }
        catch (ClassNotFoundException ex) {
            throw new ApplicationContextException(
                &quot;Failed to load custom context class [&quot; + contextClassName + &quot;]&quot;, ex);
        }
    }
    else {
        //获取预先配置的容器实现类
        contextClassName = defaultStrategies.getProperty(WebApplicationContext.class.getName());
        try {
            return ClassUtils.forName(contextClassName, ContextLoader.class.getClassLoader());
        }
        catch (ClassNotFoundException ex) {
            throw new ApplicationContextException(
                &quot;Failed to load default context class [&quot; + contextClassName + &quot;]&quot;, ex);
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;　　&lt;code&gt;BeanUtils&lt;/code&gt;是Spring封装的反射实现，&lt;code&gt;instantiateClass&lt;/code&gt;方法用于实例化指定类。&lt;/p&gt;
&lt;p&gt;　　我们可以在&lt;code&gt;web.xml&lt;/code&gt;中以&lt;code&gt;&amp;lt;context-param&amp;gt;&lt;/code&gt;的形式设置&lt;code&gt;contextclass&lt;/code&gt;参数手动决定应用使用哪种Spring容器，但是一般情况下我们都遵循Spring的默认约定，使用&lt;code&gt;ContextLoader.properties&lt;/code&gt;中配置的&lt;code&gt;org.springframework.web.context.WebApplicationContext&lt;/code&gt;的值来作为默认的Spring容器来创建。&lt;/p&gt;
&lt;p&gt;　　源码4-来自：ContextLoader.properties&lt;/p&gt;
&lt;pre class=&quot;txt&quot;&gt;
&lt;code&gt;# Default WebApplicationContext implementation class for ContextLoader.
# Used as fallback when no explicit context implementation has been specified as context-param.
# Not meant to be customized by application developers.

org.springframework.web.context.WebApplicationContext=org.springframework.web.context.support.XmlWebApplicationContext&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;　　可见，一般基于Spring的web应用默认使用的都是&lt;code&gt;XmlWebApplicationContext&lt;/code&gt;作为容器实现类的。&lt;/p&gt;
&lt;p&gt;　　到此位置容器实例就创建好了，下一步就是配置和刷新了。&lt;/p&gt;
&lt;p&gt;　　源码5-来自：ContextLoader&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;protected void configureAndRefreshWebApplicationContext(ConfigurableWebApplicationContext wac, ServletContext sc) {
    if (ObjectUtils.identityToString(wac).equals(wac.getId())) {
        // The application context id is still set to its original default value
        // -&amp;gt; assign a more useful id based on available information 
        String idParam = sc.getInitParameter(CONTEXT_ID_PARAM);
        if (idParam != null) {
            wac.setId(idParam);
        }
        else {
            // Generate default id...
            wac.setId(ConfigurableWebApplicationContext.APPLICATION_CONTEXT_ID_PREFIX +
                      ObjectUtils.getDisplayString(sc.getContextPath()));
        }
    }
    //在当前Spring容器中保留对Servlet容器的引用
    wac.setServletContext(sc);
    //设置web.xml中配置的contextConfigLocation参数值到当前容器中
    String configLocationParam = sc.getInitParameter(CONFIG_LOCATION_PARAM);
    if (configLocationParam != null) {
        wac.setConfigLocation(configLocationParam);
    }

    // The wac environment's #initPropertySources will be called in any case when the context
    // is refreshed; do it eagerly here to ensure servlet property sources are in place for
    // use in any post-processing or initialization that occurs below prior to #refresh
    //在容器刷新之前，提前进行属性资源的初始化，以备使用，将ServletContext设置为servletContextInitParams
    ConfigurableEnvironment env = wac.getEnvironment();
    if (env instanceof ConfigurableWebEnvironment) {
        ((ConfigurableWebEnvironment) env).initPropertySources(sc, null);
    }
    //取得web.xml中配置的contextInitializerClasses和globalInitializerClasses对应的初始化器，并执行初始化操作，需自定义初始化器
    customizeContext(sc, wac);
    //刷新容器
    wac.refresh();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;　　首先将&lt;code&gt;ServletContext&lt;/code&gt;的引用置入Spring容器中，以便可以方便的访问&lt;code&gt;ServletContext&lt;/code&gt;；然后从&lt;code&gt;ServletContext&lt;/code&gt;中找到&lt;code&gt;contextConfigLocation&lt;/code&gt;参数的值，配置是在&lt;code&gt;web.xml&lt;/code&gt;中以&lt;code&gt;&amp;lt;context-param&amp;gt;&lt;/code&gt;形式配置的。&lt;/p&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;知识点：&lt;/p&gt;
&lt;p&gt;​ 在&lt;code&gt;Spring&lt;/code&gt;中凡是以&lt;code&gt;&amp;lt;context-param&amp;gt;&lt;/code&gt;配置的内容都会在&lt;code&gt;web.xml&lt;/code&gt;加载的时候优先存储到&lt;code&gt;ServletContext&lt;/code&gt;之中，我们可以将其看成&lt;code&gt;ServletContext&lt;/code&gt;的配置参数，将参数配置到&lt;code&gt;ServletContext&lt;/code&gt;中后，我们就能方便的获取使用了，就如此处我们就能直接从&lt;code&gt;ServletContext&lt;/code&gt;中获取&lt;code&gt;contextConfigLocation&lt;/code&gt;的值，用于初始化Spring容器。&lt;/p&gt;
&lt;p&gt;　　在Java的web开发中，尤其是使用Spring辅助开发的情况下，基本就是一个容器对应一套配置，这套配置就是用于初始化容器的。&lt;code&gt;ServletContext&lt;/code&gt;对应于&lt;code&gt;&amp;lt;context-param&amp;gt;&lt;/code&gt;配置，Spring容器对应&lt;code&gt;applicationContext.xml&lt;/code&gt;配置，这个配置属于默认的配置，如果自定义名称就需要将其配置到&lt;code&gt;&amp;lt;context-param&amp;gt;&lt;/code&gt;中备用了，还有&lt;code&gt;DispatchServlet&lt;/code&gt;的Spring容器对应&lt;code&gt;spring-mvc.xml&lt;/code&gt;配置文件。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;　　Spring容器的&lt;code&gt;Environment&lt;/code&gt;表示的是容器运行的基础环境配置，其中保存的是&lt;code&gt;Profile&lt;/code&gt;和&lt;code&gt;Properties&lt;/code&gt;，其&lt;code&gt;initPropertySources&lt;/code&gt;方法是在&lt;code&gt;ConfigurableWebEnvironment&lt;/code&gt;接口中定义的，是专门用于web应用中来执行真实属性资源与占位符资源（&lt;code&gt;StubPropertySource&lt;/code&gt;）的替换操作的。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;知识点：&lt;/p&gt;
&lt;p&gt;　　&lt;code&gt;StubPropertySource&lt;/code&gt;就是一个占位用的实例，在应用上下文创建时，当实际属性资源无法及时初始化时，临时使用这个实例进行占位，等到容器刷新的时候执行替换操作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;​ 源码6-来自：StandardServletEnvironment&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;@Override
public void initPropertySources(@Nullable ServletContext servletContext, @Nullable ServletConfig servletConfig) {
    WebApplicationContextUtils.initServletPropertySources(getPropertySources(), servletContext, servletConfig);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;​ 源码7-来自：WebApplicationContextUtils&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public static void initServletPropertySources(MutablePropertySources sources,
                                              @Nullable ServletContext servletContext, @Nullable ServletConfig servletConfig) {

    Assert.notNull(sources, &quot;'propertySources' must not be null&quot;);
    String name = StandardServletEnvironment.SERVLET_CONTEXT_PROPERTY_SOURCE_NAME;
    if (servletContext != null &amp;amp;&amp;amp; sources.contains(name) &amp;amp;&amp;amp; sources.get(name) instanceof StubPropertySource) {
        sources.replace(name, new ServletContextPropertySource(name, servletContext));
    }
    name = StandardServletEnvironment.SERVLET_CONFIG_PROPERTY_SOURCE_NAME;
    if (servletConfig != null &amp;amp;&amp;amp; sources.contains(name) &amp;amp;&amp;amp; sources.get(name) instanceof StubPropertySource) {
        sources.replace(name, new ServletConfigPropertySource(name, servletConfig));
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;​ 从上面的源码中可以看出，这里只进行了有关Servlet的占位资源的替换操作：&lt;code&gt;ServletContext&lt;/code&gt;和&lt;code&gt;ServletConfig&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;　　上面源码中&lt;code&gt;customizeContext&lt;/code&gt;方法的目的是在刷新容器之前对容器进行自定义的初始化操作，需要我们实现&lt;code&gt;ApplicationContextInitializer&amp;lt;C extends ConfigurableApplicationContext&amp;gt;&lt;/code&gt;接口，然后将其配置到&lt;code&gt;web.xml&lt;/code&gt;中即可生效。&lt;/p&gt;
&lt;p&gt;　　源码8-来自：ContextLoader&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;protected void customizeContext(ServletContext sc, ConfigurableWebApplicationContext wac) {
    //获取初始化器类集合
    List&amp;lt;Class&amp;lt;ApplicationContextInitializer&amp;lt;ConfigurableApplicationContext&amp;gt;&amp;gt;&amp;gt; initializerClasses =
        determineContextInitializerClasses(sc);

    for (Class&amp;lt;ApplicationContextInitializer&amp;lt;ConfigurableApplicationContext&amp;gt;&amp;gt; initializerClass : initializerClasses) {
        Class&amp;lt;?&amp;gt; initializerContextClass =
            GenericTypeResolver.resolveTypeArgument(initializerClass, ApplicationContextInitializer.class);
        if (initializerContextClass != null &amp;amp;&amp;amp; !initializerContextClass.isInstance(wac)) {
            throw new ApplicationContextException(String.format(
                &quot;Could not apply context initializer [%s] since its generic parameter [%s] &quot; +
                &quot;is not assignable from the type of application context used by this &quot; +
                &quot;context loader: [%s]&quot;, initializerClass.getName(), initializerContextClass.getName(),
                wac.getClass().getName()));
        }
        //实例化初始化器并添加到集合中
        this.contextInitializers.add(BeanUtils.instantiateClass(initializerClass));
    }
    //排序并执行，编号越小越早执行
    AnnotationAwareOrderComparator.sort(this.contextInitializers);
    for (ApplicationContextInitializer&amp;lt;ConfigurableApplicationContext&amp;gt; initializer : this.contextInitializers) {
        initializer.initialize(wac);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;protected List&amp;lt;Class&amp;lt;ApplicationContextInitializer&amp;lt;ConfigurableApplicationContext&amp;gt;&amp;gt;&amp;gt;
            determineContextInitializerClasses(ServletContext servletContext) {
    List&amp;lt;Class&amp;lt;ApplicationContextInitializer&amp;lt;ConfigurableApplicationContext&amp;gt;&amp;gt;&amp;gt; classes =
        new ArrayList&amp;lt;Class&amp;lt;ApplicationContextInitializer&amp;lt;ConfigurableApplicationContext&amp;gt;&amp;gt;&amp;gt;();
    //通过&amp;lt;context-param&amp;gt;属性配置globalInitializerClasses获取全局初始化类名
    String globalClassNames = servletContext.getInitParameter(GLOBAL_INITIALIZER_CLASSES_PARAM);
    if (globalClassNames != null) {
        for (String className : StringUtils.tokenizeToStringArray(globalClassNames, INIT_PARAM_DELIMITERS)) {
            classes.add(loadInitializerClass(className));
        }
    }
    //通过&amp;lt;context-param&amp;gt;属性配置contextInitializerClasses获取容器初始化类名
    String localClassNames = servletContext.getInitParameter(CONTEXT_INITIALIZER_CLASSES_PARAM);
    if (localClassNames != null) {
        for (String className : StringUtils.tokenizeToStringArray(localClassNames, INIT_PARAM_DELIMITERS)) {
            classes.add(loadInitializerClass(className));
        }
    }
    return classes;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;​ &lt;code&gt;customizeContext&lt;/code&gt;的主要作用就是执行应用上下文初始化器（&lt;code&gt;ApplicationContextInitializer&lt;/code&gt;），这些初始化器的作用就是在容器刷新之前进行一轮预初始化操作。我们可以通过手动实现&lt;code&gt;ApplicationContextInitializer&lt;/code&gt;的方式自定义预初始化逻辑，然后通过&lt;code&gt;&amp;lt;context-param&amp;gt;&lt;/code&gt;配置到&lt;code&gt;web.xml&lt;/code&gt;中，这些配置就会在此处被加载处理并执行。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;知识点：&lt;/p&gt;
&lt;p&gt;​ &lt;code&gt;ApplicationContextInitializer&lt;/code&gt;是Spring中定义的扩展点之一，可以通过手动实现该接口的方式来自定义预初始化逻辑，在刷新操作之前来执行。&lt;/p&gt;
&lt;p&gt;​ 一般用于注册属性资源，或者激活profiles等操作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;　　到达refresh操作我们先暂停。refresh操作是容器初始化的操作。是通用操作，而到达该点的方式确实有多种，每种就是一种Spring的开发方式。&lt;/p&gt;
&lt;p&gt;　　除了此处的web开发方式，还有Springboot开发方式，貌似就两种。。。下面说说Springboot启动的流程，最后统一说refresh流程。&lt;/p&gt;
</description>
<pubDate>Mon, 29 Oct 2018 06:07:00 +0000</pubDate>
<dc:creator>唯一浩哥</dc:creator>
<og:description>原创作品，可以转载，但是请标注出处地址：</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/V1haoge/p/9870339.html</dc:identifier>
</item>
<item>
<title>网络协议 1 - 概述 - 北国丶风光</title>
<link>http://www.cnblogs.com/BeiGuo-FengGuang/p/9848805.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/BeiGuo-FengGuang/p/9848805.html</guid>
<description>&lt;p&gt;互联网世界中，网络协议的重要性不言而喻。很多人都知道，网络协议中的五层模型或者七层模型，这些在操作系统中，那都是“必考题”。上学的时候，无论是死记硬背，还是各种小抄，总得把下面这个图记下来。踏入工作，走进 web 开发“不归路”，发现还是不能落下它。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/861679/201810/861679-20181029134506598-1350627036.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;协议三要素&quot;&gt;协议三要素&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;&lt;em&gt;语法&lt;/em&gt;&lt;/strong&gt;，就是一段内容要符合一定的规则和格式。例如，括号要成对，结束要使用分号等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;语义&lt;/em&gt;&lt;/strong&gt;，就是这段内容要代表某种意义。例如，数字相减是有意义的，而数字减去文本一般来说就没有意义。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;em&gt;顺序&lt;/em&gt;&lt;/strong&gt;，就是规定先干什么，后干什么。就像我们常做的，先加某个数值，再减去某个数值等。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;HTTP 协议：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;HTTP/1.1 200 OK
Date: Thu, 25 Oct 2018 01:56:12 GMT
Content-Type: 
Content-Language:

&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;base href=&quot;http://blog.muzixizao.com/&quot; /&amp;gt;
&amp;lt;meta charset=&quot;utf-8&quot;/&amp;gt; &amp;lt;title&amp;gt;木子与西早的博客屋 &amp;lt;/title&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们来看看上面的 HTTP 协议是否符合协议的三要素。&lt;/p&gt;
&lt;p&gt;首先，符合语法，也就是说，只有按照上面那个格式来，浏览器才能解析。例如，上面是状态，然后是首部，最后是内容。&lt;/p&gt;
&lt;p&gt;其次，符合语义，就是要按照约定的意思来。例如，状态 200，表示网页成功返回。如果不成功，就是常见的 404。&lt;/p&gt;
&lt;p&gt;最后，符合顺序，点击浏览器，就是发送一个 HTTP 请求，然后才有上面那串返回的东西。&lt;/p&gt;
&lt;p&gt;浏览器显然按照协议商定好的做了，才能将网页呈现在你面前。&lt;/p&gt;
&lt;h2 id=&quot;常用的网络协议&quot;&gt;常用的网络协议&lt;/h2&gt;
&lt;p&gt;我们面试的时候经常会被问到这样一个问题：&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;在浏览器输入一个地址，然后点击回车，此时到页面加载出来，这个过程发生了什么？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们就用打开博客的过程，看看互联网世界运行过程中，都使用了哪些网络协议。&lt;/p&gt;
&lt;p&gt;当在浏览器里输入 “&lt;a href=&quot;http://blog.muzixizao.com&quot; class=&quot;uri&quot;&gt;http://blog.muzixizao.com&lt;/a&gt;”，这是一个 URL，而浏览器知道它的名字是 blog.muzixizao.com，但是不知道具体的地点，所以浏览器不知道如何访问。&lt;/p&gt;
&lt;p&gt;于是，它&lt;em&gt;打开地址簿去查找&lt;/em&gt;。在这个过程中，我们一般使用&lt;strong&gt;&lt;em&gt;地址簿协议-DNS&lt;/em&gt;&lt;/strong&gt;，还可以使用另一种更加精准的地址簿查找协议-&lt;strong&gt;&lt;em&gt;HTTPDNS&lt;/em&gt;&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;无论使用哪一种方法查找，最终都可以得到这个地址：47.106.81.116。这个是 IP 地址，可以把它当做是互联网世界的“门牌号”。&lt;/p&gt;
&lt;p&gt;知道了目标地址，浏览器就开始打包它的请求。对于普通的 HTTP 请求，一般会使用 HTTP 协议，但是如果对于购物的请求，往往会进行加密传输，因而会使用 HTTPS 协议。无论是什么协议，里面都会写明“我要看哪篇博文”。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/861679/201810/861679-20181029121815054-331558801.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;DNS、HTTP、HTTPS 所在的层我们成为&lt;strong&gt;&lt;em&gt;应用层&lt;/em&gt;&lt;/strong&gt;。经过应用层封装后，浏览器会将应用层的包交给下一层去完成，通过 socket 编程来实现。下一层是&lt;strong&gt;&lt;em&gt;传输层&lt;/em&gt;&lt;/strong&gt;。传输层有两种协议，一种是无连接的协议 UDP，一种是面向连接的协议 TCP。而所谓的面向连接就是，TCP 会保证这个包能够到达目的地，如果不能到达，就会重新发送，直至到达。&lt;/p&gt;
&lt;p&gt;TCP 协议里面会有两个端口。一个是浏览器监听的端口，一个是博客服务器监听的端口。操作系统往往通过端口来判断，它得到的包应该给哪个 进程。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/861679/201810/861679-20181029122625469-102645898.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;传输层封装完毕后，浏览器会将包交给操作系统的&lt;strong&gt;&lt;em&gt;网络层&lt;/em&gt;&lt;/strong&gt;。网络层的协议是 &lt;strong&gt;&lt;em&gt;IP 协议&lt;/em&gt;&lt;/strong&gt;。在 IP 协议里面会有源 IP 地址和目标 IP 地址，也就是浏览器所在机器的 IP 地址和博客网站所在服务器的 IP 地址。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/861679/201810/861679-20181029123146853-793062332.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;操作系统既然知道了目标 IP 地址，下一步就是根据这个 IP 找到目标机器。它首先会判断，这个目标 IP 是本地人还是外地人。从 IP 很明显就能看出来，博客服务器不在本地。&lt;/p&gt;
&lt;p&gt;操作系统知道了，要到目标机器，就要要离开本地去远方。那如何去远方呢？这个时候就可以拿出国旅游作类比。我们要去国外，就要经过海关。同样的，操作系统要去远方，也要经过&lt;strong&gt;&lt;em&gt;网关&lt;/em&gt;&lt;/strong&gt;。而操作系统启动的时候，就会被 DHCP 协议配置 IP 地址，以及默认的网关 IP 地址：192.168.1.1。&lt;/p&gt;
&lt;p&gt;操作系统如何将 IP 地址发给网关呢？在本地通信基本靠吼，于是操作系统大吼一声，谁是 192.168.1.1 ？网关会回答它，我就是，我的本地地址在村东头。这个本地地址就是 MAC 地址，而大吼的那一声就是 &lt;strong&gt;&lt;em&gt;ARP 协议&lt;/em&gt;&lt;/strong&gt;。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/861679/201810/861679-20181029130853658-1030309840.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;操作系统拿到了 MAC 地址，就将 IP 包交给了下一层：MAC 层。网卡再将这个包含 MAC 地址的包发出去。由于这个包里面有网关的 MAC 地址，因而它能够到达网关。&lt;/p&gt;
&lt;p&gt;网关收到包之后，会根据自己的知识，判断下一步应该怎么走。网关往往是一个路由器，到某个 IP 地址应该怎么走，这个叫做&lt;strong&gt;&lt;em&gt;路由表&lt;/em&gt;&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;路由器有点像玄奘西行路过的一个个国家的城关。每个城关连接着两个国家，每个国家相当于一个局域网，在每个国家内部，都可以使用本地的地址 MAC 进行通信。&lt;/p&gt;
&lt;p&gt;一旦跨越城关，就需要拿出 IP 头来，里面写着贫僧来自东土大唐（源 IP 地址），想去西天（目标 IP 地址）拜佛求经。路过此地，借宿一晚，明日启行。请问接下来该怎么走？&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/861679/201810/861679-20181029132107119-451277843.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;城关往往是知道这些“知识”的，因为城关和临近的城关也会经常沟通。到哪里应该怎么走，这种沟通的协议称为&lt;strong&gt;&lt;em&gt;路由协议&lt;/em&gt;&lt;/strong&gt;，常用的有 OSPF 和 BGP。&lt;/p&gt;
&lt;p&gt;城关与城关之间是一个国家，当网络包知道了下一步去哪个城关，还是要使用国家内部的 MAC 地址，通过下一个城关的 MAC 地址，找到下一个城关，然后再问下一步的路怎么走，一直到走出最后一个城关。&lt;/p&gt;
&lt;p&gt;最后一个城关知道这个网络包要去的地方，于是，就对着这个国家吼一声（ARP协议），谁是目标 IP ？目标服务器就会回复一个 MAC 地址。网络包过关后，通过这个 MAC 地址就能找到目标服务器。&lt;/p&gt;
&lt;p&gt;目标服务器发现 MAC 地址对上了，取下 MAC 头来，然后发送给操作系统的网络层。网络层发现 IP 也对上了，就取下 IP 头。 IP 头里会写上一层封装的是 TCP 协议，然后将其交给传输层，即 TCP 层。&lt;/p&gt;
&lt;p&gt;在这一层里，对于收到的每个包，都会有一个回复的包说明收到了。这个回复的包不是这次请求的结果，而仅仅是 TCP 层的一个收到回复。这个回复会沿着刚才来的方向走回去，报个平安。&lt;/p&gt;
&lt;p&gt;如果过一段时间，发送端的 TCP 层没有收到平安回复，就会重新发送这个包，重复上面的过程，直到收到平安到达的回复为止。这个重试不是浏览器重新进行请求，对于浏览器而言，只发送一次请求，而 TCP 层在没有收到平安回复时，不断闷头重试。除非 TCP 层出了问题，比如连接断了，才需要浏览器的应用层重新发送请求。&lt;/p&gt;
&lt;p&gt;当网络包平安到达 TCP 层后，TCP 头中有目标端口号，通过这个端口号，可以找到博客网站的进程正在监听这个端口号，假设是 Nginx，于是就将这个包发给 Nginx，进行相关业务处理。处理完成后，将相关数据打包，然后回复给浏览器，显示出博文页。&lt;/p&gt;
&lt;p&gt;下图就是整个HTTP 请求中可能用到的协议。后续会通过从底层到上层的顺序来一一分享。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/861679/201810/861679-20181029120449017-1428867284.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;喜欢就给个大拇指吧！&lt;/p&gt;
</description>
<pubDate>Mon, 29 Oct 2018 05:57:00 +0000</pubDate>
<dc:creator>北国丶风光</dc:creator>
<og:description>互联网世界中，网络协议的重要性不言而喻。很多人都知道，网络协议中的五层模型或者七层模型，这些在操作系统中，那都是“必考题”。上学的时候，无论是死记硬背，还是各种小抄，总得把下面这个图记下来。踏入工作，</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/BeiGuo-FengGuang/p/9848805.html</dc:identifier>
</item>
<item>
<title>软件测试，如何月薪过万？ - Vincent83</title>
<link>http://www.cnblogs.com/yingyingja/p/9857865.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yingyingja/p/9857865.html</guid>
<description>&lt;p&gt;月薪过万这个话题，在现在这个百花齐放的职场里是个很流行的命题。&lt;/p&gt;
&lt;p&gt;月薪过万对于行业大佬来说，可能是个不屑一顾的追求，但对于职场新人而言通常是个很实际的人生目标。&lt;/p&gt;

&lt;p&gt;我怎么样能达到月薪过万呢，其实严格来说，要找到一份满足你薪资期望的工作有三个要素：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;个人提升&lt;/li&gt;
&lt;li&gt;求职技巧&lt;/li&gt;
&lt;li&gt;你所在的地域&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;做为一个闷骚IT技术宅，我最能回答的主要是第一点：怎么进行个人提升，毕竟功夫到家才是硬道理。&lt;/p&gt;

&lt;p&gt;软件测试从业人员可能都有这样一种感受，就是干这一行你要会的东西太多了，说的通俗一点就是知识库庞杂。&lt;/p&gt;
&lt;p&gt;在这个信息爆炸的时代，我们可以学习的东西太多了，看起来很多东西都能实现个人价值的提升。比如去学一本驾照，比如去学游泳，学健康养生。。。&lt;/p&gt;
&lt;p&gt;测试工程师学什么？&lt;/p&gt;

&lt;p&gt;我个人会把测试工程师的学习提升路线分为四条主线：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;测试技术&lt;/li&gt;
&lt;li&gt;行业知识&lt;/li&gt;
&lt;li&gt;职场能力&lt;/li&gt;
&lt;li&gt;管理技能&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;在不同的路线上去深化，会引领你走上不同的职业发展道路。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第一：&lt;/strong&gt;先说&lt;strong&gt;测试技术&lt;/strong&gt;，大致罗列一下，测试工程师需要学习的东西：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;　测试理论
&lt;ul&gt;&lt;li&gt;测试基础&lt;/li&gt;
&lt;li&gt;测试方法论&lt;/li&gt;
&lt;li&gt;测试思维&lt;/li&gt;
&lt;li&gt;基于经验测试&lt;/li&gt;
&lt;li&gt;静态测试&lt;/li&gt;
&lt;li&gt;单元测试&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;　工具技术&lt;/li&gt;
&lt;li&gt;
&lt;ul&gt;&lt;li&gt;操作系统知识&lt;/li&gt;
&lt;li&gt;服务器相关技术&lt;/li&gt;
&lt;li&gt;数据库技术&lt;/li&gt;
&lt;li&gt;基础测试工具&lt;/li&gt;
&lt;li&gt;性能测试工具&lt;/li&gt;
&lt;li&gt;接口测试工具&lt;/li&gt;
&lt;li&gt;安全性测试工具&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;　编程技术
&lt;ul&gt;&lt;li&gt;脚本编程技术&lt;/li&gt;
&lt;li&gt;白盒技术&lt;/li&gt;
&lt;li&gt;自动化编程技术&lt;/li&gt;
&lt;li&gt;测试开发技术&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;首先是&lt;strong&gt;测试的理论&lt;/strong&gt;，有的人可能做了几年测试，积累了一些经验，就对这方面样的知识有些瞧不起了。其实我个人认为，理论始终是指导实践的最坚实基础。&lt;/p&gt;
&lt;p&gt;做测试我们可以在工具、技能上面不断的雕琢，但其实测试的基础同样也是需要我们不断钻研的东西。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;要学会从宏观的高度去看待测试工作：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;测试的最终目的是交付高质量的产品；&lt;/p&gt;
&lt;p&gt;产品的质量需求又是由项目性质决定；&lt;/p&gt;
&lt;p&gt;测试工作不能脱离团队而存在；&lt;/p&gt;
&lt;p&gt;测试如何服务于产品质量把控和风险缓解；&lt;/p&gt;
&lt;p&gt;客户想要的究竟是怎样的产品特性和功能；&lt;/p&gt;
&lt;p&gt;一个缺陷的背后，揭示的是怎么样的过程问题；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;要学会从微观的角度去切入测试工作：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于复杂的测试目标，有哪些方法论可以帮助我实现测试；&lt;/p&gt;
&lt;p&gt;对于模糊的质量定义，我怎么挖掘其真实需求；&lt;/p&gt;
&lt;p&gt;发现了问题，我怎么去对他进行分类和定位；&lt;/p&gt;
&lt;p&gt;测试的数据怎么设计才能达到足够的覆盖；&lt;/p&gt;
&lt;p&gt;测试用例怎么编排描述才能达到最好的效果；&lt;/p&gt;
&lt;p&gt;如何进行反馈才能让发现的问题得到最有效的解决；&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;测试基础和理论就像一个侠客的内功，无论你的剑耍得有多六，最终决胜负还是要靠内力。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;再说&lt;strong&gt;测试工具，&lt;/strong&gt;做为IT从业人士，工具的使用可能是个人能力的最直接体现，是一种很外露的本事。&lt;/p&gt;
&lt;p&gt;软件测试这个行业所涉及的领域非常广泛，从行业的角度来说，现在几乎所有行业都要上IT系统，连冰箱都要联网了。涉及行业的广泛，决定了我们在工作中可能用到的工具也种类繁多。&lt;/p&gt;
&lt;p&gt;同时，软件产品质量的维度也非常的多，功能性、安全性、互操作性、负载、压力、易用性、兼容性、可维护性、可移植性等等等等。每一种质量的维度可能都有最适合去应用的一些工具。&lt;/p&gt;
&lt;p&gt;还有一些操作系统级别和基础应用级别的工具，比如数据库，比如linux，比如JDK，中间件，我们也要去掌握。他们是我们开展测试工作必不可少的（你迟早会用到）工具。&lt;/p&gt;
&lt;p&gt;在一定程度上，学会了一种工具，就意味着你测试工作的领域就被拓宽了一点，很自然的这会是你升职加薪的有效砝码。&lt;/p&gt;
&lt;p&gt;不过在工具的学习上，还是有一些策略可以去应用的。不要被所谓工具的‘高大上’和‘酷炫感’这样的特性吸引，盲目去学习那些看起来很厉害，实际应用价值和范围却不大的工具。&lt;/p&gt;
&lt;p&gt;不管是从升职加薪的角度而言，还是自我提升的角度而言，我们应该优先去学习市场应用面广的，最有用有实际价值的工具。人的精力和时间都是有限的，从最有用的学起，切忌好高骛远。先把基础的常用的工具学好，慢慢再去学习高阶工具是一个最优策略。&lt;/p&gt;
&lt;p&gt;而且工具这个东西，其实是触类旁通的，等你学好了一部分工具，另外看起来高阶的那些说不定对你来说就已经很容易了，无非是去体验他的实际应用场景而已。&lt;/p&gt;

&lt;p&gt;最后呢，学习工具不要只停留在应用级别，即不要只会用，要知其然知其所以然。工具的操作流程，不如他实现的原理对你来说更有价值。&lt;/p&gt;

&lt;p&gt;接下来是&lt;strong&gt;编程技术&lt;/strong&gt;，其实很多理论里把测试编程技术也归为工具的使用，不过我们把他单拿出来说。&lt;/p&gt;
&lt;p&gt;也许有一些测试工程师其实是因为不爱写代码才做了测试这行，但是要在测试技术领域深化下去，编程技能又是不可或缺的。&lt;/p&gt;
&lt;p&gt;是不是很纠结。&lt;/p&gt;
&lt;p&gt;测试工程师的编程能力到底有什么用处呢？总结一下主要在以下方面：自动化测试、脚本编程，白盒/单元测试以及测试开发。&lt;/p&gt;
&lt;p&gt;自动化测试是现在比较火的一个领域，不必多说。学些自动化测试编程，我们的目标应该不单单是应用，更应该深化到框架的编写。&lt;/p&gt;
&lt;p&gt;脚本编程是脚本语言的应用，比如shell脚本和windows批处理这类工作控制语言，许多IT项目会很依赖这类脚本去做工作自动化控制，比如CI环境部署。&lt;/p&gt;
&lt;p&gt;掌握编程知识同样也会帮助我们去完成白盒/单元测试这样的任务。如果我们在编程能力和测试能力双向深入发展，测试开发是一个很好（薪水也很高）的发展方向。&lt;/p&gt;
&lt;p&gt;一个前提要说到的就是，测试工程师的编程技术门槛是比较低的。我们在学习代码编写以应用到测试工作时，一开始其实不需要多深入。&lt;/p&gt;
&lt;p&gt;比如做为一个测试工程师去学习自动化编程，入门级级别来说，我们只用学习现有自动化工具和类库的使用，其实学习难度并没有想象的那么高。&lt;/p&gt;
&lt;p&gt;随着学习的深入，当你有了更高的追求，再进一步去在编程领域内深造是个不错的选择。比如上文提到的去写框架，去改进框架，去引领一个机构的自动化测试。&lt;/p&gt;

&lt;p&gt;学好了这些技术，不管是综合发展还是专项深造，我们的职业发展路线会向技术型深入。比如成为自动化测试工程师，性能测试工程师，白盒测试工程师又或者是安全测试专家等。这些职位比起测试基础岗而言，薪资水平是有着显著上升的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第二：是行业知识&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;IT归根结底属于第三产业，第三产业是什么？通俗一点来讲就是服务业。IT产业是为其他基础行业服务的，最终我们要完成的事情是让传统的事务处理IT化，自动化，网络化。&lt;/p&gt;
&lt;p&gt;这就牵扯到一个问题，不论我们做怎么样的项目、系统或软件，他的最终应用会是在另一个与计算机体系无关的领域，比如金融，比如零售，比如医疗，等等。&lt;/p&gt;
&lt;p&gt;做为IT从业人员，除了本行的计算机应用技术以外，这些行业的知识就成为了我们需要学习掌握的第二学科。&lt;/p&gt;
&lt;p&gt;将行业理解的透彻，是另一条IT人员必点的技能树，对于软件测试而言尤其如此。因为做为项目的测试和质量把控，我们只有非常了解软件应用的领域，才能更好的帮助我们对项目质量进行把关；而软件测试倾向的用户立场，也要求我们必须能够以专业的角度去衡量我们的产品在专有领域的适用程度。&lt;/p&gt;
&lt;p&gt;比如在金融领域，真的要做好这一行的测试，财务领域知识、基金会计技能有的时候可能比你的测试技术更为重要。毕竟如果不精通这一领域的东西，你可能连系统到底要怎么实现用户/市场需求都把握不准，更不要提很好的把控产品的质量了。其他领域也各自都有不同程度的对行业知识的要求。&lt;/p&gt;

&lt;p&gt;当然，有的时候测试工程师可能会有这样的经历，自己就像个雇佣兵，在数个项目之间来来回回，根本没有固定在某一个行业领域当中。客户要什么系统，我们就去测什么系统，在数个不同领域之中辗转徘徊、浅尝辄止，根本没有时间让我在某个领域中间去沉淀。&lt;/p&gt;
&lt;p&gt;这是一种现实情况，在这种情况下，你对于某个行业的积累仍然可以帮助到你，但是你却很难成为该领域的专家。&lt;/p&gt;
&lt;p&gt;不过如果你有机会在某个领域的测试工作中稳定下来的话，我会更推荐你去在这样的领域内深入，将测试技术和行业知识双向发展。&lt;/p&gt;
&lt;p&gt;当测试工程师有了足够深入的某行业领域专业知识和技能以后，那么我们的发展方向就可以是‘&lt;strong&gt;领域测试专家&lt;/strong&gt;’和‘&lt;strong&gt;领域测试咨询&lt;/strong&gt;’。这样的人才在该行业内，一定是非常受欢迎的，高薪当然不成问题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第三：是职场能力&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;职场能力可以说是一种个人素质和综合能力。&lt;/p&gt;
&lt;p&gt;不论我们有多好的测试技术和行业知识，都需要有强大的职场能力去辅助，我们才能将自己的专业能力更好的发挥出来，否则别说当大牛拿高薪，可能工作能不能保得住都难说。&lt;/p&gt;
&lt;p&gt;职场能力有哪些呢，我归纳了一下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;沟通能力&lt;/li&gt;
&lt;li&gt;自律能力&lt;/li&gt;
&lt;li&gt;学习能力&lt;/li&gt;
&lt;li&gt;思考能力&lt;/li&gt;
&lt;li&gt;抗压能力&lt;/li&gt;
&lt;li&gt;规划能力&lt;/li&gt;
&lt;li&gt;时间观念&lt;/li&gt;
&lt;li&gt;团队精神&lt;/li&gt;
&lt;li&gt;善于思考&lt;/li&gt;
&lt;li&gt;承担责任&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;沟通能力：自不用说，测试工程师可能在一个IT团队里是沟通任务最重的，也是最需要沟通能力的。我们的测试工作强依赖着其他工作团队的产出，所以我们不但要沟通，还要会沟通；其次，我们测试工程又承担着项目质量反馈和过程改进的作用，这又要求我们要把测试结果和结论进行很好的沟通。测试人员不能不讲究沟通，沟通技能的差别是关系到我们团队地位和个人评价的非常重要的因素。&lt;/p&gt;
&lt;p&gt;自律能力、时间观念和用于担当放到一起说，都是一个人责任感的体现。我们不鼓吹放弃自己应有的生活和娱乐，一心一意扑在工作上，做测试岗位上的劳模。但是在你分内的工作时间内，我们要尽心尽责的去做好本职工作，做自己该做的事情，该担当的责任要用于担当，舍得奉献。用自己的目标鞭策自己，不管你是为了养家糊口还是自我实现。进一步说，要主动去发现工作中的乐趣，干一行爱一行，切忌眼高手低。&lt;/p&gt;
&lt;p&gt;学习和思考能力：要求我们有好的学习和思考意识，也要掌握好的方法论。IT行业不断发展，新兴领域不断涌入对我们的行业产生冲击，都要求我们必须肯学而且能学，在学习和工作中勤于独立思考，善于发现问题，总结问题，提出解决方案。创新能力则是学习和思考能力的一个进阶体现。&lt;/p&gt;
&lt;p&gt;规划能力：测试基础工作说起来是由一些很繁杂的事项组成的。即使你的职位在测试路线上越走越远，你仍然摆脱不了一定程度上的杂事。所以这就要求我们有系统的规划能力，测试新人在刚入行的时候可能会觉得，细心细致对于测试这样一个‘找问题’的工种而言可能是最重要的素质，其实系统的规划能力才是我们做事的必备技能。即使是天生不够细心细致的人，通过有效的系统规划，也可以避免我们因为粗枝大叶而犯下错误，并且可以帮助我们对繁杂的工作事项和对象进行抽丝剥茧，把握主线，帮我们更为轻松高效无纰漏的完成工作。&lt;/p&gt;
&lt;p&gt;抗压能力：做IT做测试，免不了会有工作上的压力，不管是工作时长上的，还是工作成果上的。要学会抗压，遇到挫折时不能轻易气馁，完成成果时戒骄戒躁。也要学会判断压力是否合理，加班的压力合理吗？领导的质疑合理吗？要学会科学的判断，科学的应对。其实相较而言，测试岗位的压力其实算是中等水平，不要被工作压垮，否则又何谈升职加薪。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第四：是管理能力&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于测试工程师来说，随着经验的积累和在这个行业的深入，转做管理岗可能是我们每个人都会去思考的一个方向。&lt;/p&gt;
&lt;p&gt;当领导当然有很多好处，比如地位的上升，比如薪资的上涨--特别是在薪资的上限上，做管理和纯做技术还是有着明显差别的。&lt;/p&gt;
&lt;p&gt;要做测试管理，除了有相应的机遇之外，当然我们个人在管理能力上也要做好准备。&lt;/p&gt;
&lt;p&gt;我将测试管理能力划分为三个维度，分别是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;测试组织能力&lt;/li&gt;
&lt;li&gt;测试技术能力&lt;/li&gt;
&lt;li&gt;团队管理能力&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;测试组织能力让我们学会怎么去组织，策划，实施，监控和汇报一个测试项目。让我们能把测试这个工程给完成好，也要让他很好的完成风险管控、质量反馈和过程改进的作用。&lt;/p&gt;
&lt;p&gt;测试技术能力让我们做为测试的管理人员了解技术在测试活动中的应用场景和机会，让我们有能力去把控一个测试工程对于技术的引入和使用。也需要我们有相应的技术能力，去指导具体技术在工程里的使用，说起来其实还是需要我们在第一点：测试技术上面下功夫。&lt;/p&gt;
&lt;p&gt;团队管理能力是与人打交道的能力，对上沟通，对下管理，团队建设，团队提升，管理团队内部各种各样的人才，让他们能为你所用。这也是一门专门的学问。&lt;/p&gt;

&lt;p&gt;学习好了管理能力，再遇到适合的机遇，我们就可以去向测试lead，测试经理，测试主管方向发展。&lt;/p&gt;
&lt;p&gt;当然其实一旦你做到管理岗，后续的可能性就要增大很多，高管的机会大门就将向你敞开。取决于个人的把握，其实最后成为CTO，部门经理，VP都是有可能的，当然他就不属于测试岗位的直接进阶了。&lt;/p&gt;

&lt;p&gt;以上我们说到的四个方向，大部分都不是独立存在的，在实际应用的场景中更多的是交织在一起，形成一个测试人员的能力体系。他们之中可以有侧重，这些能力上的侧重指引就我们的职业方向。&lt;/p&gt;
&lt;p&gt;比如说在测试技术方面加重投入，我们的方向可能是测试技术专家和技术专项领域；&lt;/p&gt;
&lt;p&gt;测试技术和管理能力双修，那么可能的方向可以是测试架构师，测试lead；&lt;/p&gt;
&lt;p&gt;测试技术和行业知识双修，那么又可以成为领域测试专家。&lt;/p&gt;
</description>
<pubDate>Mon, 29 Oct 2018 05:32:00 +0000</pubDate>
<dc:creator>Vincent83</dc:creator>
<og:description>月薪过万这个话题，在现在这个百花齐放的职场里是个很流行的命题。 月薪过万对于行业大佬来说，可能是个不屑一顾的追求，但对于职场新人而言通常是个很实际的人生目标。 我怎么样能达到月薪过万呢，其实严格来说，</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/yingyingja/p/9857865.html</dc:identifier>
</item>
<item>
<title>网易考拉规则引擎平台架构设计与实践 - 网易云</title>
<link>http://www.cnblogs.com/163yun/p/9870171.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/163yun/p/9870171.html</guid>
<description>&lt;p&gt;此文已由作者肖凡授权网易云社区发布。&lt;/p&gt;
&lt;p&gt;欢迎访问&lt;a href=&quot;https://sq.163yun.com/blog?tag=M_tg_487_65&quot;&gt;网易云社区&lt;/a&gt;，了解更多网易技术产品运营经验。&lt;/p&gt;

&lt;p&gt;考拉安全部技术这块目前主要负责两块业务：一个是内审，主要是通过敏感日志管理平台搜集考拉所有后台系统的操作日志，数据导入到es后，结合storm进行实时计算，主要有行为查询、数据监控、事件追溯、风险大盘等功能；一个是业务风控，主要是下单、支付、优惠券、红包、签到等行为的风险控制，对抗的风险行为包括黄牛刷单、恶意占用库存、机器领券、撸羊毛等。这两块业务其实有一个共通点，就是有大量需要进行规则决策的场景，比如内审中需要进行实时监控，当同一个人在一天时间内的导出操作超过多少次后进行告警，当登录时不是常用地登录并且设备指纹不是该账号使用过的设备指纹时告警。而在业务风控中需要使用到规则决策的场景更多，由于涉及规则的保密性，这里就不展开了。总之，基于这个出发点，安全部决定开发出一个通用的规则引擎平台，来满足以上场景。&lt;/p&gt;


&lt;p&gt;在给出整体架构前，想跟大家聊聊关于架构的一些想法。目前架构上的分层设计思想已经深入人心，大家都知道要分成controller,server,dao等，是因为我们刚接触到编码的时候，mvc的模型已经大行其道，早期的jsp里面包含大量业务代码逻辑的方式已经基本绝迹。但是这并不是一种面向对象的思考方式，而往往我们是以一种面向过程的思维去编程。举个简单例子，我们要实现一个网银账户之间转账的需求，往往会是下面这种实现方式：&lt;/p&gt;

&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;设计一个账户交易服务接口AccountingService，设计一个服务方法transfer()，并提供一个具体实现类AccountingServiceImpl，所有账户交易业务的业务逻辑都置于该服务类中。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;提供一个AccountInfo和一个Account，前者是一个用于与展示层交换账户数据的账户数据传输对象，后者是一个账户实体（相当于一个EntityBean），这两个对象都是普通的JavaBean，具有相关属性和简单的get/set方法。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;然后在transfer方法中，首先获取A账户的余额，判断是否大于转账的金额，如果大于则扣减A账户的余额，并增加对应的金额到B账户。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这种设计在需求简单的情况下看上去没啥问题，但是当需求变得复杂后，会导致代码变得越来越难以维护，整个架构也会变的腐烂。比如现在需要增加账户的信用等级，不同等级的账户每笔转账的最大金额不同，那么我们就需要在service里面加上这个逻辑。后来又需要记录转账明细，我们又需要在service里面增加相应的代码逻辑。最后service代码会由于需求的不断变化变得越来越长，最终变成别人眼中的“祖传代码”。导致这个问题的根源，我认为就是我们使用的是一种面向过程的编程思想。那么如何去解决这种问题呢？主要还是思维方式上需要改变，我们需要一种真正的面向对象的思维方式。比如一个“人”，除了有id、姓名、性别这些属性外，还应该有“走路”、“吃饭”等这些行为，这些行为是天然属于“人”这个实体的，而我们定义的bean都是一种“失血模型”，只有get/set等简单方法，所有的行为逻辑全部上升到了service层，这就导致了service层过于臃肿，并且很难复用已有的逻辑，最后形成了各个service之间错综复杂的关联关系，在做服务拆分的时候，很难划清业务边界，导致服务化进程陷入泥潭。&lt;/p&gt;

&lt;p&gt;对应上面的问题，我们可以在Account这个实体中加入本应该就属于这个实体的行为，比如借记、贷记、转账等。每一笔转账都对应着一笔交易明细，我们根据交易明细可以计算出账户的余额，这个是一个潜在的业务规则，这种业务规则都需要交由实体本身来维护。另外新增账户信用实体，提供账户单笔转账的最大金额计算逻辑。这样我们就把原本全部在service里面的逻辑划入到不同的负责相关职责的“领域对象”当中了，service的逻辑变得非常清楚明了，想实现A给B转账，直接获取A实体，然后调用A实体中的转账方法即可。service将不再关注转账的细节，只负责将相关的实体组织起来，完成复杂的业务逻辑处理。&lt;/p&gt;

&lt;p&gt;上面的这种架构设计方式，其实就是一种典型的“领域驱动设计(DDD)”思想，在这里就不展开说明了（主要是自己理解的还不够深入，怕误导大家了）。DDD也是目前非常热门的一种架构设计思想了，它不能减少你的代码量，但是能使你的代码具有很高的内聚性，当你的项目变得越来越复杂时，能保持架构的稳定而不至于过快的腐烂掉，不了解的同学可以查看相关资料。要说明的是，没有一种架构设计是万能的、是能解决所有问题的，我们需要做的是吸收好的架构设计思维方式，真正架构落地时还是需要根据实际情况选择合适的架构。&lt;/p&gt;


&lt;p&gt;上面说了些架构设计方面的想法，现在我们回到规则引擎平台本身。我们抽象出了四个分层，从上到下分别为：服务层、引擎层、计算层和存储层，整个逻辑层架构见下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://nos.netease.com/knowledge/47b9f3ab-ba03-40ce-8c41-07404c35a687&quot; alt=&quot;Alt pic&quot;/&gt;&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;3.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;服务层：服务层主要是对外提供服务的入口层，提供的服务包括数据分析、风险检测、业务决策等，所有的服务全部都是通过数据接入模块接入数据，具体后面讲&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;引擎层：引擎层是整个平台的核心，主要包括了执行规则的规则引擎、还原事件现场和聚合查询分析的查询引擎以及模型预测的模型引擎&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;计算层：计算层主要包括了指标计算模块和模型训练模块。指标会在规则引擎中配置规则时使用到，而模型训练则是为模型预测做准备&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;存储层：存储层包括了指标计算结果的存储、事件信息详情的存储以及模型样本、模型文件的存储&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在各个分层的逻辑架构划定后，我们就可以开始分析整个平台的业务功能模块。主要包括了事件接入模块、指标计算模块、规则引擎模块、运营中心模块，整个业务架构如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://nos.netease.com/knowledge/75027f27-187e-454b-b630-24160d1f18c8&quot; alt=&quot;Alt pic&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;1.事件接入中心&lt;/h2&gt;

&lt;p&gt;事件接入中心主要包括事件接入模块和数据管理模块。数据接入模块是整个规则引擎的数据流入口，所有的业务方都是通过这个模块接入到平台中来。提供了实时(dubbo)、准实时（kafka）和离线（hive）三种数据接入方式。数据管理模块主要是进行事件的元数据管理、标准化接入数据、补全必要的字段，如下图： &lt;img src=&quot;http://nos.netease.com/knowledge/39b8454c-9962-4795-af70-b3f04053c119&quot; alt=&quot;Alt pic&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;2.指标计算模块&lt;/h2&gt;

&lt;p&gt;指标计算模块主要是进行指标计算。一个指标由主维度、从维度、时间窗口等组成，其中主维度至少有一个，从维度最多有一个。如下图： &lt;img src=&quot;http://nos.netease.com/knowledge/b63d11b5-6d52-4ba6-b2be-6a7526cfe677?imageView&amp;amp;thumbnail=600x0&quot; alt=&quot;Alt pic&quot;/&gt;&lt;/p&gt;

&lt;p&gt;举个例子，若有这样一个指标：“最近10分钟，同一个账号在同一个商家的下单金额”，那么主维度就是下单账号+商家id，从维度就是订单金额。可以看到，这里的主维度相当于sql里面的group by，从维度相当于count，数值累加相当于sum。从关于指标计算，有几点说明下：&lt;/p&gt;

&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;key的构成。我们的指标存储是用的redis，那么这里会涉及到一个key该如何构建的问题。我们目前的做法是：key=指标id+版本号+主维度值+时间间隔序号。&lt;/span&gt;&lt;/p&gt;
&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;指标id就是指标的唯一标示；&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;版本号是指标对象的版本，每次更新完指标都会更新对应的版本号，这样可以让就的指标一次全部失效；&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;主维度值是指当前事件对象中，主维度字段对应的值，比如一个下单事件，主维度是用户账号，那么这里就是对应的类似XXX@163.com，如果有多个主维度则需要全部组装上去；&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;如果主维度的值出现中文，这样直接拼接在key里面会有问题，可以采用转义或者md5的方式进行。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;时间间隔序号是指当前时间减去指标最后更新时间，得到的差值再除以采样周期，得到一个序号。这么做主要是为了实现指标的滑动窗口计算，下面会讲&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;span&gt;滑动窗口计算。比如我们的指标是最近10分钟的同一用户的下单量，那么我们就需要实现一种类似的滑动窗口算法，以便任何时候都能拿到“最近10分钟”的数据。这里我们采用的是一种简单的算法：创建指标时，指定好采样次数。比如要获取“最近10分钟”的数据，采样次数设置成30次，这样我们会把每隔20秒的数据会放入一个key里面。每次一个下单事件过来时，计算出时间间隔序号（见第1点），然后组装好key之后看该key是否存在，存在则进行累计，否则往redis中添加该key。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;span&gt;如何批量获取key。每次获取指标值时，我们都是先计算出需要的key集合（比如我要获取“单个账号最近10分钟的下单量”，我可能需要获取30个key，因为每个key的跨度是20s），然后获取到对应的value集合，再进行累加。而实际上我们只是需要累加后的值，这里可以通过redis+lua脚本进行优化，脚本里面直接根据key集合获取value后进行累加然后返回给客户端，这样就较少了每次响应的数据量。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;如何保证指标的计算结果不丢失？目前的指标是存储在redis里面的，后来会切到solo-ldb，ldb提供了持久化的存储引擎，可以保证数据不丢失。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;3.规则引擎模块&lt;/h2&gt;
&lt;p&gt;计划开始做规则引擎时进行过调研，发现很多类似的平台都会使用drools。而我们从一开始就放弃了drools而全部使用groovy脚本实现，主要是有以下几点考虑：&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;1&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;drools相对来说有点重，而且它的规则语言不管对于开发还是运营来说都有学习成本&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;drools使用起来没有groovy脚本灵活。groovy可以和spring完美结合，并且可以自定义各种组件实现插件化开发。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;当规则集变得复杂起来时，使用drools管理起来有点力不从心。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当然还有另外一种方式是将drools和groovy结合起来，综合双方的优点，也是一种不错的选择，大家可以尝试一下。&lt;/p&gt;

&lt;p&gt;规则引擎模块是整个平台的核心，我们将整个模块分成了以下几个部分： &lt;img src=&quot;http://nos.netease.com/knowledge/0f8bcd7d-0105-440b-b474-94f5683ccde0&quot; alt=&quot;Alt pic&quot;/&gt;&lt;/p&gt;

&lt;p&gt;规则引擎在设计中也碰到了一些问题，这里给大家分享下一些心得：&lt;/p&gt;

&lt;ul class=&quot; list-paddingleft-2&quot; readability=&quot;5.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;使用插件的方式加载各种组件到上下文中，极大的方便了功能开发的灵活性。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;span&gt;使用预加载的方式加载已有的规则，并将加载后的对象缓存起来，每次规则变更时重新load整条规则，极大的提升了引擎的执行效率&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;span&gt;计数器引入AtomicLongFieldUpdater工具类，来减少计数器的内存消耗&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;span&gt;灵活的上下文使用方式，方便定制规则执行的流程（规则执行顺序、同步异步执行、跳过某些规则、规则集短路等），灵活定义返回结果（可以返回整个上下文，可以返回每条规则的结果，也可以返回最后一条规则的结果），这些都可以通过设置上下文来实现。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;groovy的方法查找策略，默认是从metaClass里面查找，再从上下文里找，为了提升性能，我们重写了metaClass，修改了这个查询逻辑：先从上下文里找，再从metaClass里面找。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;规则配置如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://nos.netease.com/knowledge/25408470-69a8-434a-835c-fcf4f439c064?imageView&amp;amp;thumbnail=700x0&quot; alt=&quot;Alt pic&quot;/&gt;&lt;/p&gt;


&lt;p&gt;后面规则引擎平台主要会围绕下面几点来做：&lt;/p&gt;

&lt;ol class=&quot; list-paddingleft-2&quot; readability=&quot;7.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;指标存储计划从redis切换到hbase。目前的指标计算方式会导致缓存key的暴涨，获取一个指标值可能需要N个key来做累加，而换成hbase之后，一个指标就只需要一条记录来维护，使用hbase的列族来实现滑动窗口的计算。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;span&gt;规则的灰度上线。当一条新规则创建后，如果不进行灰度的测试，直接上线是可能会带来灾难的。后面再规则上线流程中新增灰度上线环节，整个引擎会根据配置的灰度比例，复制一定的流量到灰度规则中，并对灰度规则的效果进行展示，达到预期效果并稳定后才能审批上线。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;事件接入的自动化。dubbo这块可以采用泛化调用，http接口需要统一调用标准，消息需要统一格式。有了统一的标准就可以实现事件自动接入而不需要修改代码上线，这样也可以保证整个引擎的稳定性。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;模型生命周期管理。目前模型这块都是通过在猛犸平台上提交jar包的方式，离线跑一个model出来，没有一个统一的平台去管控整个模型的生命周期。现在杭研已经有类似的平台了，后续需要考虑如何介入。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;span&gt;数据展示优化。现在整个平台的数字化做的比较弱，没法形成数据驱动业务。而风控的运营往往是需要大量的数据去驱动规则的优化的，比如规则阈值的调试、规则命中率、风险大盘等都需要大量数据的支撑。&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;网易云&lt;a href=&quot;https://www.163yun.com/free?tag=M_tg_487_65&quot;&gt;免费体验馆&lt;/a&gt;，0成本体验20+款云产品！ &lt;/p&gt;
&lt;p&gt;更多网易技术、产品、运营经验分享请&lt;a href=&quot;https://sq.163yun.com/blog?tag=M_tg_487_65&quot;&gt;点击&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;相关文章：&lt;br/&gt;【推荐】 &lt;a href=&quot;https://www.cnblogs.com/zyfd/p/9814626.html&quot;&gt;TiDB和MongoDB分片集群架构比较&lt;/a&gt;&lt;br/&gt;【推荐】 &lt;a href=&quot;https://www.jianshu.com/p/50114c6a21b4&quot;&gt;浅谈代码结构的设计&lt;/a&gt;&lt;br/&gt;【推荐】 &lt;a href=&quot;https://www.cnblogs.com/zyfd/p/9512270.html&quot;&gt;6本互联网技术畅销书免费送（数据分析、深度学习、编程语言）！&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 29 Oct 2018 05:31:00 +0000</pubDate>
<dc:creator>网易云</dc:creator>
<og:description>此文已由作者肖凡授权网易云社区发布。 欢迎访问网易云社区，了解更多网易技术产品运营经验。 背景 考拉安全部技术这块目前主要负责两块业务：一个是内审，主要是通过敏感日志管理平台搜集考拉所有后台系统的操作</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/163yun/p/9870171.html</dc:identifier>
</item>
<item>
<title>【RDB】MariaDB 之事务、复制、集群 - Never、C</title>
<link>http://www.cnblogs.com/neverc/p/9870088.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/neverc/p/9870088.html</guid>
<description>&lt;h2 id=&quot;目录&quot;&gt;目录&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;简介&lt;/li&gt;
&lt;li&gt;安装启动&lt;/li&gt;
&lt;li&gt;权限&lt;/li&gt;
&lt;li&gt;事务
&lt;ul&gt;&lt;li&gt;脏读、不可重复读、幻读&lt;/li&gt;
&lt;li&gt;MVCC&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;复制
&lt;ul&gt;&lt;li&gt;异步复制&lt;/li&gt;
&lt;li&gt;半同步复制&lt;/li&gt;
&lt;li&gt;GTID复制&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;集群(Galera)&lt;/li&gt;
&lt;li&gt;配置&lt;/li&gt;
&lt;li&gt;监控(Zabbix)&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;简介&quot;&gt;简介&lt;/h2&gt;
&lt;p&gt;环境：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;CentOS 7.4.1708&lt;/li&gt;
&lt;li&gt;MariaDB 10.3.9&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;简介：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;MySQL 由 MySQLAB 公司开发。&lt;/li&gt;
&lt;li&gt;MariaDB 是 MySQL的一个分支，它是 MySQL 之父 Monty Widenius 开发&lt;/li&gt;
&lt;li&gt;目前很多知名的 Linux 发行版已经使用 MariaDB 替代了 MySQL。如：RHEL 7，CentOS 7。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;MariaDB的优点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;插件式存储引擎&lt;/li&gt;
&lt;li&gt;单进程多线程&lt;/li&gt;
&lt;li&gt;MySQL 有走向封闭的趋势&lt;/li&gt;
&lt;li&gt;MariaDB 高度兼容 MySQL&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;安装启动&quot;&gt;安装启动&lt;/h2&gt;
&lt;h3 id=&quot;安装&quot;&gt;安装&lt;/h3&gt;
&lt;p&gt;查看是否安装MariaDB rpm包：&lt;br/&gt;&lt;code&gt;rpm -qa | grep MariaDB&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;在 CentOS 7.4 默认源中的 MariaDB 仍为5.x版本，当需要 10.x 版本时，可通过添加第三方源实现：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://downloads.MariaDB.org/MariaDB/repositories&quot;&gt;MariaDB 官方源&lt;/a&gt;：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;echo -e &quot;[MariaDB]\nname = MariaDB\nbaseurl = http://yum.MariaDB.org/10.3/centos7-amd64\ngpgkey=https://yum.MariaDB.org/RPM-GPG-KEY-MariaDB\ngpgcheck=1&quot; &amp;gt; /etc/yum.repos.d/MariaDB-10.3.repo&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;官方源比较慢的情况，可以使用清华镜像源(根据需要执行yum clean all)：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;echo -e &quot;[MariaDB]\nname = MariaDB\nbaseurl = https://mirrors.tuna.tsinghua.edu.cn/mariadb//mariadb-10.3.9/yum/centos/7.4/x86_64/\ngpgkey=https://yum.MariaDB.org/RPM-GPG-KEY-MariaDB\ngpgcheck=1&quot; &amp;gt; /etc/yum.repos.d/MariaDB-10.3.repo&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;安装MariaDB客户端(包含MariaDB-common、MariaDB-client下载9MB 安装50M)：&lt;br/&gt;&lt;code&gt;yum install -y MariaDB.x86_64&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;安装MariaDB服务端(包含MariaDB-common、MariaDB-client、MariaDB-server)：&lt;br/&gt;&lt;code&gt;yum install -y MariaDB-server.x86_64&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;查看 MariaDB 安装的文件：&lt;br/&gt;&lt;code&gt;rpm -ql MariaDB-server&lt;/code&gt; 或 &lt;code&gt;rpm -ql MariaDB-client&lt;/code&gt;&lt;/p&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;3&quot;&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;&lt;code&gt;/etc/my.cnf&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;默认配置文件&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;/var/lib/mysql/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;文件夹下是 MariaDB 数据库目录、错误日志和 socket 文件&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;&lt;code&gt;mysql&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;mysql cli 客户端&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;mysqldump&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;备份工具，基于 mysql协议 向 mysqld 发起查询，将结果转化为insert语句导出。&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;&lt;code&gt;mysqladmin&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;基于 mysql协议 管理 mysqld。&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;&lt;code&gt;mysqlimport&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;mysql 导入工具&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;注意：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;MariaDB 在 10.X 版本以前包名为 mariadb，之后为 MariaDB。但服务名仍为 mariadb：service mariadb start;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;启动&quot;&gt;启动&lt;/h3&gt;
&lt;p&gt;启动MariaDB服务：&lt;br/&gt;&lt;code&gt;service mariadb start&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;初始化(为root设置密码，删除测试数据库、匿名用户)：&lt;br/&gt;&lt;code&gt;/usr/bin/mysql_secure_installation&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;登录mysql查看版本：&lt;br/&gt;&lt;code&gt;mysqladmin version -p123123&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;一键卸载MariaDB且清除MariaDB数据(便于调试)：&lt;br/&gt;&lt;code&gt;yum -y remove `rpm -qa | grep MariaDB` &amp;amp;&amp;amp; rm -rf /var/lib/mysql&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&quot;权限&quot;&gt;权限&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;授权表：db、host、user、table_priv、column_priv、procs_priv&lt;/li&gt;
&lt;li&gt;用户账号：'username'@'host' host:主机名、IP、通配符(%,_)&lt;/li&gt;
&lt;li&gt;创建用户：create user 'username'@'host' [identity by 'passwd']&lt;/li&gt;
&lt;li&gt;查看用户权限：show grants for 'username'@'host';&lt;/li&gt;
&lt;li&gt;重命名用户：RENAME USER oldname TO newname;&lt;/li&gt;
&lt;li&gt;删除用户：DROP USER 'username'@'host';&lt;/li&gt;
&lt;li&gt;修改密码：SET PASSWORD&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;允许root远程访问：&lt;br/&gt;&lt;code&gt;GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123123' WITH GRANT OPTION;&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;WITH GRANT OPTION 表示该用户可以将自己的权限授权给别人&lt;/li&gt;
&lt;li&gt;如果只授予部分权限，其中 all privileges 改为 select,insert,update,delete,create,drop,index,alter,grant,references,reload,shutdown,process,file 其中一部分。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;精确到列的权限：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;GRANT SELECT(Id,Name) ON testdb.Users TO testuser@'%' IDENTIFIED BY '123123'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;重载授权表:&lt;br/&gt;&lt;code&gt;FLUSH PRIVILEGES;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;忘记root密码：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;systemctl stop mariadb.service&lt;/li&gt;
&lt;li&gt;mysqld_safe --skip-grant-tables&lt;/li&gt;
&lt;li&gt;mysql -u root
&lt;ol&gt;&lt;li&gt;update mysql.user set password=PASSWORD('newpassword') where User='root’;&lt;/li&gt;
&lt;li&gt;flush privileges;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;systemctl restart mariadb.service&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;事务&quot;&gt;事务&lt;/h2&gt;
&lt;p&gt;MySQL按照标准SQL定义了4种隔离级别，较低的隔离级别，能带来更高的并发和更低的系统开销。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;未提交读(READ-UNCOMMITTED)
&lt;ul&gt;&lt;li&gt;可以读到未提交的修改记录&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;读已提交(READ-COMMITTED)
&lt;ul&gt;&lt;li&gt;只要提交的修改记录(包括其他的事务)都可以读到&lt;/li&gt;
&lt;li&gt;基于MVCC并发控制&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;可重复读(REPEATABLE-READ)
&lt;ul&gt;&lt;li&gt;在事务开始第一次读取后，其他事务可修改读到的数据，但读到的数据不会被修改(幻读情况下会新增和减少)&lt;/li&gt;
&lt;li&gt;基于MVCC并发控制&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;串行读(SERIALIZABLE)
&lt;ul&gt;&lt;li&gt;事务开始后发生对数据的操作(即使发生读操作)，其他事务都不能修改数据&lt;/li&gt;
&lt;li&gt;基于锁控制：实际上串行读在RR级别上隐式加gap间隙共享锁：&lt;code&gt;select ... for update&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;备注：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;code&gt;set tx_isolation='READ-UNCOMMITTED';&lt;/code&gt; 调整当前 session 隔离级别&lt;/li&gt;
&lt;li&gt;&lt;code&gt;select @@tx_isolation&lt;/code&gt; 查看当前 session 隔离级别&lt;/li&gt;
&lt;li&gt;&lt;code&gt;show processlist;&lt;/code&gt; 查看 mysql 连接状态&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;在4种隔离级别中又分别存在不同的读问题：&lt;/p&gt;
&lt;ol readability=&quot;9.5&quot;&gt;&lt;li readability=&quot;2&quot;&gt;脏读(dirty reads)
&lt;ul&gt;&lt;li&gt;在 READ-UNCOMMITTED 级别会出现读到未提交的数据&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;T1：select * from users where id = 1;
T2：insert into `users`(`id`, `name`) values (1, 'foo'); -- 事务未提交
T1：select * from users where id = 1; -- 会读到&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;不可重复读(non-repeatable reads)
&lt;ul&gt;&lt;li&gt;在 READ-COMMITTED 级别会出现先后读取不一致的情况(关注点：读-读)&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;T1：select * from users where id = 2;
T2：insert into `users`(`id`, `name`) values (2, 'foo');
T2：commit;
T1：select * from users where id = 2; -- 会读到&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;6&quot;&gt;幻读(phantom reads)
&lt;ul&gt;&lt;li&gt;在 REPEATABLE-READ 级别会出现插入事先不存在的记录时，发现(insert会隐式的select)这些数据又存在(关注点：读-写)&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;T1：select * from users where id = 3; -- 判断是否有 Id = 3 的数据,没有则插入
T2：insert into `users`(`id`, `name`) values (3, 'bar'); -- 执行成功
T1：insert into `users`(`id`, `name`) values (3, 'bar'); -- 执行失败，由于 T1 发生幻读，不能支持该业务执行&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;锁读(lock reads)
&lt;ul&gt;&lt;li&gt;在 SERIALIZABLE 级别会出现读的数据无法修改情况&lt;/li&gt;
&lt;/ul&gt;&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;T1：select * from users where id = 3;
T2：update `users` set `name` = 'baz' where `id` = 3; -- 执行失败，由于 Id = 3 的数据被锁&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;在同1次连接上，上次事务未提交，执行 &lt;code&gt;start transaction;&lt;/code&gt;。会自动提交该连接上次的修改。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;mvcc机制&quot;&gt;MVCC机制：&lt;/h3&gt;
&lt;p&gt;在 MVCC 之前，RC 和 RR 隔离级别是怎么工作？&lt;/p&gt;
&lt;p&gt;在 MVCC 之前，是单纯依赖锁的机制实现隔离级别。&lt;br/&gt;当T1修改1条数据时加上排他锁，T2事务的读操作会被阻塞。当T1提交或回滚，锁被释放时，才能读取到提交的数据。但一般应用都是读多写少，导致系统处于大量的等待中，非常低效。&lt;/p&gt;
&lt;p&gt;有了 MVCC 机制后，效果是怎么样？&lt;/p&gt;
&lt;p&gt;有了 MVCC 后，当数据被修改时，会生成1个副本出来供其他事务读取。不会出现阻塞情况，读的性能会大幅提升。只有 SERIALIZABLE 级别的读操作才有可能被阻塞。(MVCC应用在RC和RR隔离级别上)&lt;/p&gt;
&lt;p&gt;MVCC 具体如何实现的？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在 MySQL 中 MVCC 是在 InnoDB 存储引擎上实现的。&lt;/li&gt;
&lt;li&gt;InnoDB 为每行数据增加3个字段：隐藏的ID、当前事务ID、回滚指针。&lt;/li&gt;
&lt;li&gt;MVCC 依赖 undo log 和 readview 来确定数据的可见性。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;undo log：记录了原始数据的多个副本，用来回滚和提供其他事务读取&lt;br/&gt;readview：记录了活动事务Id，用来确定可见哪个副本&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;在每个事务开启执行第1条语句的时候，会创建1个readview。&lt;/li&gt;
&lt;li&gt;将行数据的当前事务TRID 与 readview中的事务RVID 比较
&lt;ol&gt;&lt;li&gt;TRID &amp;lt; 所有的 RVID：可见(之前的事务创建)&lt;/li&gt;
&lt;li&gt;TRID &amp;gt; 所有的 RVID：不可见(新事务创建)&lt;/li&gt;
&lt;li&gt;TRID 在 RVID 中存在：不可见(活动的事务创建)&lt;/li&gt;
&lt;li&gt;TRID 在 RVID 中不存在：可见(内存中commit或自己创建)&lt;/li&gt;
&lt;li&gt;当数据不可见时，会从数据的回滚指针获取数据重新判断一遍&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;RC 和 RR的区别：
&lt;ol&gt;&lt;li&gt;RR 在事务开始只创建1次 readview&lt;/li&gt;
&lt;li&gt;RC 在事务每次执行语句都会创建 readview&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;事务提交过程及日志变化：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;用 排他锁 锁定该行&lt;/li&gt;
&lt;li&gt;记录 redo buffer&lt;/li&gt;
&lt;li&gt;copy 数据到 undo buffer&lt;/li&gt;
&lt;li&gt;内存中修改数据 填写隐藏字段 事务Id 和 回滚指针&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;commit：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;redo log 文件持久化(innodb_flush_log_at_trx_commit)&lt;/li&gt;
&lt;li&gt;bin log 文件持久化(sync_binlog)(这一步完成能确保故障恢复)&lt;/li&gt;
&lt;li&gt;innodb引擎 commit(数据持久化，undo log)&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;注意：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;redo log 文件并不一定在commit时才做持久化
&lt;ol&gt;&lt;li&gt;Master Thread 每秒执行一次&lt;/li&gt;
&lt;li&gt;每个事务提交时&lt;/li&gt;
&lt;li&gt;当重做日志缓存可用空间 少于一半时&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;redo log 是连续的一段存储空间，而修改的数据很可能是随机的区域&lt;/li&gt;
&lt;li&gt;undo log 并非在事务提交完立即释放
&lt;ol&gt;&lt;li&gt;提交后放入待清理区域，由purge线程判断是否仍有其他事务在使用，来决定是否删除。&lt;/li&gt;
&lt;li&gt;默认undo log 存储在 idb 表空间中，在 MariaDB 10.0(MySQL 5.7)后通过innodb_undo_directory 、innodb_undo_logs 、innodb_undo_tablespaces 可配置独立文件&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;主从复制&quot;&gt;主从复制&lt;/h2&gt;
&lt;p&gt;主从复制能提供水平扩展 数据备份 数据分析 高可用性等，故开启主从复制越来越必要。&lt;/p&gt;
&lt;h3 id=&quot;复制&quot;&gt;复制&lt;/h3&gt;
&lt;p&gt;MariaDB 主从复制工作3步：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;主库的数据更改记录到 binlog 中&lt;/li&gt;
&lt;li&gt;从库将主库的日志 复制到 relaylog 中
&lt;ol&gt;&lt;li&gt;从库使用 IO 线程请求主库&lt;/li&gt;
&lt;li&gt;主库使用 dump 线程读取 binlog 传给&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;备库 SQL 线程读取 relaylog 事件，重放到数据库。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;配置复制：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;在主库和从库创建复制账号
&lt;ol&gt;&lt;li&gt;GRANT REPLICATION SLAVE, REPLICATION CLIENT ON &lt;em&gt;.&lt;/em&gt; TO repl@'10.0.0.%' IDENTIFIED BY 'p4ssword';&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;配置主库和从库
&lt;ol readability=&quot;-0.5&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;配置主服务器：&lt;/p&gt;
&lt;pre class=&quot;ini&quot;&gt;
&lt;code&gt;[mysqld]
log_bin   = mysql-bin
server_id = 1 # 唯一，可以用IP地址的末几位&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;从服务器：&lt;/p&gt;
&lt;pre class=&quot;ini&quot;&gt;
&lt;code&gt;[mysqld]
log_bin   = mysql-bin
server_id = 2
log_slave_updates = 1 # 重放同时写到binlog
relay_log = /var/lib/mysql/mysql-relay-bin&lt;/code&gt;
&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;从库启动复制
&lt;ol&gt;&lt;li&gt;MariaDB &amp;gt; CHANGE MASTER TO MASTER_HOST='server1', -&amp;gt; MASTER_USER='repl', -&amp;gt; MASTER_PASSWORD='p4ssword', -&amp;gt; MASTER_LOG_FILE='mysql-bin.000001', -&amp;gt; MASTER_LOG_POS=0;&lt;/li&gt;
&lt;li&gt;MariaDB &amp;gt; START SLAVE;&lt;/li&gt;
&lt;li&gt;MariaDB &amp;gt; SHOW SLAVE STATUS\G&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;注意：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;要填写的复制的POSITION，可以通过 &lt;code&gt;SHOW MASTER STATUS\G&lt;/code&gt; 查看&lt;/li&gt;
&lt;li&gt;启用复制功能不会给服务器太多的开销。(主要是开启 binlog 和 sync_binlog=1 fsync的开销)&lt;/li&gt;
&lt;li&gt;如果复制配置有问题，可以重置配置信息：&lt;code&gt;stop slave; reset slave;&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;半同步复制&quot;&gt;半同步复制：&lt;/h3&gt;
&lt;p&gt;默认复制是单向异步的，也支持半同步复制功能(MariaDB 10.3 后内置不需要单独安装插件)。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;主库：&lt;br/&gt;&lt;code&gt;set global rpl_semi_sync_master_enabled = 1;&lt;/code&gt;&lt;br/&gt;&lt;code&gt;set global rpl_semi_sync_master_wait_point = AFTER_SYNC;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;从库：&lt;br/&gt;&lt;code&gt;set global rpl_semi_sync_slave_enabled = 1;&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;semi配置：&lt;/p&gt;
&lt;p&gt;配置项|推荐配置值|说明&lt;br/&gt;rpl_semi_sync_master_enabled|ON|开启主库半同步复制&lt;br/&gt;rpl_semi_sync_master_timeout|10000|最多等待从库响应10s&lt;br/&gt;rpl_semi_sync_master_wait_no_slave|ON|当没有从节点时(从节点突然断开)是否继续等待&lt;br/&gt;rpl_semi_sync_master_wait_point|AFTER_SYNC|控制Wait Slave ACK的时机&lt;br/&gt;rpl_semi_sync_slave_enabled|ON|开启从库半同步复制&lt;/p&gt;
&lt;p&gt;原理：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;半同步复制是在事务提交时，等待至少1个从库接收并写到relay log才返回给客户端(Wait Slave ACK)。&lt;/li&gt;
&lt;li&gt;半同步复制提高数据安全性，但也造成一定的延迟(最少是1次tcp/ip返还的时间)。&lt;/li&gt;
&lt;li&gt;半同步复制默认AFTER_COMMIT是在bin log持久化及存储引擎提交后再等待从库接收写到relay log，通过rpl_semi_sync_master_wait_point配置为AFTER_SYNC，可以将从库复制操作改到主库存储引擎提交之前。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;相当于有异步复制、半同步复制还有个全同步复制，代表为 mysql-cluster性能太差，需要等待所有slave都同步才commit成功(性能太差)&lt;/p&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;半同步复制数据一致性并不能100%保证，在非常极端情况下，AFTER_SYNC会出现从库数据多的情况，AFTER_COMMIT会出现从库数据丢失的情况。&lt;/li&gt;
&lt;li&gt;AFTER_SYNC 可以让存储引擎commit支持group commit。所以性能安全性都比AFTER_COMMIT好&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;gtid&quot;&gt;GTID&lt;/h3&gt;
&lt;p&gt;从MariaDB 10.0.2开始，GTID会自动启用，在 binlog 中的每个事件组(事务)都会先记录1个GTID。&lt;/p&gt;
&lt;p&gt;全局事务ID（简称GTID）由三个用短划线“ - ”分隔的数字组成。例如：&lt;code&gt;0-1-10&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;第一个数字0是域ID，它特定于全局事务ID（以下更多内容）。它是一个32位无符号整数。&lt;/li&gt;
&lt;li&gt;第二个数字是服务器ID，与旧式复制中使用的相同。它是一个32位无符号整数。&lt;/li&gt;
&lt;li&gt;第三个数字是序列号。这是一个64位无符号整数，对于登录到binlog中的每个新事件组，它会单调递增。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;为什么要使用GTID：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;以前复制需要确定 binlog 文件名+偏移量。使用GTID则会自动确定。&lt;/li&gt;
&lt;li&gt;以前通过 relaylog 文件记录复制进度，且和数据同步是独立进行。使用GTID，将会在数据更新的事务中一起更新状态(存在mysql.gtid_slave_pos)&lt;/li&gt;
&lt;li&gt;更适合MHA时failover。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;如何配置：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CHANGE MASTER TO master_use_gtid = { slave_pos | current_pos | no }&lt;/code&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;current_pos：当前服务器最后1条binlog命令的gtid记录&lt;/li&gt;
&lt;li&gt;slave_pos：当前(从)服务器最后1次执行重放数据的gtid记录&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;完整：&lt;code&gt;CHANGE MASTER TO master_host = &quot;127.0.0.1&quot;, master_user = &quot;root&quot;, master_use_gtid = current_pos;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;select @@gtid_slave_pos 可查看slave最后1个gtid。&lt;br/&gt;select @@gtid_current_pos 可查看当前服务器执行的最后1个gtid。&lt;/p&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;MariaDB和MySQL具有不同的GTID实现，并且它们彼此不兼容。&lt;/li&gt;
&lt;li&gt;完成复制的必要条件主库开启 binlog 日志，相当于开启主库的GTID。从库及时不开启 binlog, slave_pos 也会更新，但自执行的SQL不会影响current_pos。&lt;/li&gt;
&lt;li&gt;SET GLOBAL gtid_slave_pos = &quot;&quot;; 会重置GTID进度。&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;galera集群&quot;&gt;Galera集群&lt;/h2&gt;
&lt;p&gt;在MariaDB 5.5和MariaDB 10.0中，MariaDB Galera Server是一个独立的软件包，而不是标准的MariaDB Server软件包。从MariaDB 10.1开始，MariaDB Server和MariaDB Galera Server软件包已经合并，并且在安装MariaDB时会自动安装Galera软件包及其依赖项。Galera部件在配置之前保持休眠状态，如插件或存储引擎。&lt;/p&gt;
&lt;p&gt;相比于复制、半同步复制，Galera集群相当于是同步复制。其实现原理完全与 binlog 没有任何关系。&lt;/p&gt;
&lt;p&gt;配置步骤：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;配置&lt;br/&gt;&lt;code&gt;ini [galera] # Mandatory settings wsrep_on=ON # rpm -ql galera.x86_64 -&amp;gt; /usr/lib64/galera/libgalera_smm.so wsrep_provider=/usr/lib64/galera/libgalera_smm.so # DNS名称也有效，IP是性能的首选 wsrep_cluster_address=&quot;gcomm://172.17.145.110, 172.18.0.2&quot; binlog_format=row default_storage_engine=InnoDB innodb_autoinc_lock_mode=2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;引导新集群&lt;br/&gt;$ galera_new_cluster(Systemd推荐)&lt;/li&gt;
&lt;li&gt;在多台服务器上开启mysql服务&lt;br/&gt;$ service mariadb start&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;注意：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Galera Cluster方式会出现自增ID不连续的情况，可使用GUID由程序生成&lt;/li&gt;
&lt;/ol&gt;&lt;h2 id=&quot;配置&quot;&gt;配置&lt;/h2&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;4&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;4&quot;&gt;&lt;td&gt;&lt;code&gt;mysqld --verbose --help | less&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;查看默认配置及配置说明&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;4&quot;&gt;&lt;td&gt;&lt;code&gt;cat /etc/my.cnf | grep -v '^#' | grep -v '^$'&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;查看去除注释后的配置文件&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;&lt;code&gt;show [global] variables;&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;查看配置&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot;&gt;&lt;td&gt;&lt;code&gt;set [global] name=value;&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;修改配置&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead/&gt;&lt;tbody readability=&quot;7&quot;&gt;&lt;tr class=&quot;odd&quot; readability=&quot;3&quot;&gt;&lt;td&gt;autocommit&lt;/td&gt;
&lt;td&gt;on&lt;/td&gt;
&lt;td&gt;off&lt;/td&gt;
&lt;td&gt;是否开启自动提交，默认开启，所有修改操作都会自动开启1个事务，并提交。(影响性能)&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;3&quot;&gt;&lt;td&gt;skip-name-resolve&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td&gt;跳过IP反解为域名过程，默认关闭，所有连接都会反解IP为域名。(影响性能以及授权)&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;4&quot;&gt;&lt;td&gt;innodb_flush_log_at_trx_commit&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;在事务提交时确保redolog持久化&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;even&quot; readability=&quot;2&quot;&gt;&lt;td&gt;innodb-file-per-table&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td&gt;独立表空间，每1个表都以独立文件存储&lt;/td&gt;
&lt;/tr&gt;&lt;tr class=&quot;odd&quot; readability=&quot;2&quot;&gt;&lt;td&gt;sync_binlog&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;在事务提交时确保binlog持久化&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;(配置项会不断更新比较重要的)&lt;/p&gt;
&lt;h2 id=&quot;监控&quot;&gt;监控&lt;/h2&gt;
&lt;p&gt;监控可使用 Zabbix 对MariaDB 做监控。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/677578/201810/677578-20181029124838453-172480552.png&quot; alt=&quot;Zabbix&quot;/&gt;&lt;/p&gt;
&lt;p&gt;(实现原理是通过查询 MariaDB 的状态变量实现)&lt;/p&gt;
&lt;p&gt;本文地址：https://www.cnblogs.com/neverc/p/9870088.html&lt;/p&gt;
</description>
<pubDate>Mon, 29 Oct 2018 05:04:00 +0000</pubDate>
<dc:creator>Never、C</dc:creator>
<og:description>目录 简介 安装启动 权限 事务 脏读、不可重复读、幻读 MVCC 复制 异步复制 半同步复制 GTID复制 集群(Galera) 配置 监控(Zabbix) 简介 环境： CentOS 7.4.17</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/neverc/p/9870088.html</dc:identifier>
</item>
<item>
<title>Apache Ignite 学习笔记(一): Ignite介绍、部署安装和REST/SQL客户端使用 - Dinoroar</title>
<link>http://www.cnblogs.com/peppapigdaddy/p/9717324.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/peppapigdaddy/p/9717324.html</guid>
<description>&lt;h2 id=&quot;apache-ignite-介绍&quot;&gt;Apache Ignite 介绍&lt;/h2&gt;
&lt;hr/&gt;&lt;p&gt;Ignite是什么呢？先引用一段官网关于Ignite的描述：&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;Ignite is memory-centric distributed &lt;strong&gt;database&lt;/strong&gt;, &lt;strong&gt;caching&lt;/strong&gt;, and &lt;strong&gt;processing&lt;/strong&gt; platform for transactional, analytical, and streaming workloads delivering in-memory speeds at petabyte scale&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;直接翻译就是，Ignite是以内存为中心的分布式的数据库，缓存和处理平台。它可以在数据量达到PB级别，依然为事务性处理，数据分析和流式任务提供了内存级的操作速度。 再从官网借用一张架构图，从下面这张图也可以看出来Ignite提供了哪些能力：&lt;br/&gt;&lt;img src=&quot;https://files.readme.io/0bad3a9-ignite_architecture.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;图中红色部分属于Ignite提供的组件，我们依次从下往上看：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;持久化层：Ignite同时支持原生持久化和用第三方存储做持久化，比如RMDBMS，HDFS等。虽然Ignite有以内存为中心的存储，但是毕竟内存中数据在节点出现故障的时候都有丢失的可能性。 因此持久化层为Ignite提供了故障恢复的能力。另外有了持久化能力，可以让冷热数据更合理使用内存。比如在内存足够情况下，数据可以全部加载到内存中。 而当内存紧张时，可以只加载热数据至内存中，冷数据就留在硬盘上。&lt;/li&gt;
&lt;li&gt;Ignite内存存储层：这一层可以算是Ignite的核心层了。数据可以通过不同分区，复制模式分布在Ignite集群所有节点，部分节点或者本地节点。通过数据分区和复制，比如1主多备的方式，可以提高数据的可用性，即便主数据节点故障后，集群中的备数据节点可以切换为主节点继续提供读写服务。 同时备节点也可以作为只读节点使用，提高数据读操作的吞吐量。Ignite还利用Java堆外内存存储数据和索引，减少了JVM的垃圾回收次数和时间，提供了更高效的操作。&lt;/li&gt;
&lt;li&gt;API接口层： 丰富多样的接口支撑Ignite向上提供了诸如分布式数据库，数据网格和计算网格的能力。Key/Value+transaction，可以把Ignite当做和Redis,Memcached一样的缓存使用。 而对SQL ANSI-99的兼容，有可以把Ignite当做一个分布式数据库来用。 除了数据能力，Ignite还允许你通过Compute Grid的接口提交计算任务，充分利用集群的计算资源。Ignite还支持把计算任务部署在和计算数据所在的相同节点上，减少网络传输和数据的序列化开销，提高计算效率。 流处理，机器学习网格，服务网格，消息队列等，Ignite也同时提供支持。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;以上只是简单罗列了目前我所了解的Ignite的特性，如果还想了解更多关于Ignite基本概念和资料，可以参阅&lt;a href=&quot;https://apacheignite.readme.io/docs&quot;&gt;官方文档&lt;/a&gt;, 英文不好的同学可以看看李玉珏翻译的&lt;a href=&quot;https://liyuj.gitee.io/doc/java/#_1-1-ignite%E6%98%AF%E4%BB%80%E4%B9%88&quot;&gt;中文官方文档&lt;/a&gt;。 光从文档量上看，Ignite的特性相当繁杂，而且有些例子还是需要实际跑跑代码才能弄清楚如何使用，后面我会根据自己的学习进度，更新Ignite的学习笔记，把自己对Ignite的理解和小伙伴分享。&lt;/p&gt;
&lt;h2 id=&quot;ignite-集群安装部署和启动&quot;&gt;Ignite 集群安装部署和启动&lt;/h2&gt;
&lt;hr/&gt;&lt;p&gt;Ignite有多种安装方式，比如源码安装，docker，RPM包等，个人认为二进制包的安装方式最简单，开箱即用。下面我们看看如何通过二级制包来安装部署Ignite。&lt;br/&gt;1.首先我们需要从官网下载二进制压缩包。在我写这篇博客时候，最新版本为&lt;a href=&quot;http://apache.mirror.colo-serv.net//ignite/2.6.0/apache-ignite-fabric-2.6.0-bin.zip&quot;&gt;2.6.0&lt;/a&gt;。&lt;br/&gt;2.下载后我们需要解压缩二进制包，然后设置好环境变量IGNITE_HOME，指向刚刚解压好的目录。&lt;br/&gt;3.然后我们可以通过IGNITE_HOME/bin/ignite.sh脚本启动我们的第一个Ignite节点：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$cd IGNITE_HOME  
$bin/ignite.sh&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;4.节点启动过程，会在终端上打印日志信息，当看到下面类似日志时就代表节点启动成功了：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[23:41:41] Ignite node started OK (id=e935ab3a)   
[23:41:41] Topology snapshot [ver=1, servers=1, clients=0, CPUs=2, offheap=1.6GB, heap=1.0GB]&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们先来简单看看最后那一行日志都提供了哪些信息：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;“&lt;em&gt;ver=1&lt;/em&gt;”代表Ignite集群topology版本是1。关于什么是topology，我会在介绍Ignite原生持久化能力的时候讨论到。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;“&lt;em&gt;servers=1&lt;/em&gt;”代表现在集群里面就一个server节点，“&lt;em&gt;clients=0&lt;/em&gt;”代表集群里没有client节点。 client/server节点在作为数据节点和计算节点时时有区别的，我会在后面介绍。现在可以简单的理解为server节点总是存放数据，client节点不存放数据，数据的访问总是通过server节点。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;“&lt;em&gt;CPUs=2&lt;/em&gt;”代表当前节点的CPU数量。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;“&lt;em&gt;offheap=1.6GB&lt;/em&gt;”代表当前节点可以使用的Java堆外内存是1.6GB。堆外内存是个很重要的概念，我会在介绍Ignite内存架构的时候再详细解释Ignite是如何使用堆外内存。现在只要记住Ignite用堆外用来存储数据和索引来减少GC。默认配置下Ignite能使用的堆外内存为节点内存大小的20%。我启动Ignite的虚拟机只有8G内存，因此堆外内存为8GB*20%=1.6GB。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;“&lt;em&gt;heap=1.0GB&lt;/em&gt;”这个就是Ignite能使用的Java堆内存了。这个值的大小也是可以调整的，如果你没有配置JAVA_OPTS,在ignite.sh脚本中启动JVM时用的最小/最大堆都是1GB。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;就是这么简单，开箱即用。 到目前为止我们已经成功在一个节点上启动了一个Ignite实例。我们还可以在同一个节点上或者多个节点上用相同的办法启动多个Ignite实例。在新的Ignite实例启动后，新老节点会互相发现自动的形成一个集群。比如我在相同的虚拟机上在启动一个实例，在第一个和第二个实例的日志中有这么一行：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;[00:24:27] Topology snapshot [ver=2, servers=2, clients=0, CPUs=2, offheap=3.1GB, heap=2.0GB]&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;细心的小伙伴应该会发现&lt;em&gt;ver, servers, offheap, heap&lt;/em&gt;值都改变了，这说明Ignite集群加入了新的节点，所以topology的版本号变了，集群内&lt;em&gt;server&lt;/em&gt;数量也变成2。&lt;/p&gt;
&lt;h2 id=&quot;ignite-rest和sql客户端&quot;&gt;Ignite REST和SQL客户端&lt;/h2&gt;
&lt;hr/&gt;&lt;p&gt;server节点启动后，我们就可以用客户端连接上进行操作了。 目前Ignite支持的客户端有REST, SQL, Java/.NET客户端。 其中Java/.NET客户端都需要自己写代码连接到服务器上，所以这里我们先介绍使用REST和SQL客户端，下一篇文章再分享如何写一个简单的Java程序连接Ignite server节点。&lt;/p&gt;
&lt;h3 id=&quot;rest-客户端使用&quot;&gt;REST 客户端使用&lt;/h3&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;注意： 为了启用REST连接，必须保证&lt;em&gt;ignite-rest-http&lt;/em&gt;模块在启动JVM的classpath中。 如果你下载了二进制包，可以在$IGNITE_HOME/libs/optional中找到&lt;em&gt;ignite-rest-http&lt;/em&gt;模块，只要将它拷贝到$IGNITE_HOME/libs目录中就可以了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ignite启动后，默认会自动监听8080端口，我们就可以通过以下&lt;em&gt;curl&lt;/em&gt;命令查看server节点版本(&lt;em&gt;192.168.0.110&lt;/em&gt;是我的Ignite server节点启动的ip地址)：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$curl 'http://192.168.0.110:8080/ignite?cmd=version'
{&quot;successStatus&quot;:0,&quot;sessionToken&quot;:null,&quot;error&quot;:null,&quot;response&quot;:&quot;2.6.0&quot;}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;目前我们的Ignite集群里没有任何的cache，让我们试着用REST命令创建一个新的cache:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$curl 'http://192.168.0.110:8080/ignite?cmd=getorcreate&amp;amp;cacheName=myfirstcache'
{&quot;successStatus&quot;:0,&quot;sessionToken&quot;:null,&quot;error&quot;:null,&quot;response&quot;:null}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;然后我们就可以往这个cache里添加数据了：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$curl 'http://192.168.0.110:8080/ignite?cmd=put&amp;amp;key=Toronto&amp;amp;val=Ontario&amp;amp;cacheName=myfirstcache'
{&quot;successStatus&quot;:0,&quot;affinityNodeId&quot;:&quot;370c1554-03f4-4fa2-9c45-880e40288467&quot;,&quot;sessionToken&quot;:null,&quot;error&quot;:null,&quot;response&quot;:true}
$curl 'http://192.168.0.110:8080/ignite?cmd=put&amp;amp;key=Edmonton&amp;amp;val=Alberta&amp;amp;cacheName=myfirstcache'
{&quot;successStatus&quot;:0,&quot;affinityNodeId&quot;:&quot;370c1554-03f4-4fa2-9c45-880e40288467&quot;,&quot;sessionToken&quot;:null,&quot;error&quot;:null,&quot;response&quot;:true}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们往cache里写了两条关于加拿大城市和所在省份的数据，第一条key是Toronto市，value值是Ontario省。 第二条key是Edmonton市，value值是Alberta省。 然后再让我们试着读取cache里的数据：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$curl 'http://192.168.0.110:8080/ignite?cmd=get&amp;amp;key=Toronto&amp;amp;cacheName=myfirstcache'
{&quot;successStatus&quot;:0,&quot;affinityNodeId&quot;:&quot;370c1554-03f4-4fa2-9c45-880e40288467&quot;,&quot;sessionToken&quot;:null,&quot;error&quot;:null,&quot;response&quot;:&quot;Ontario&quot;}
$curl 'http://192.168.0.110:8080/ignite?cmd=get&amp;amp;key=Edmonton&amp;amp;cacheName=myfirstcache'
{&quot;successStatus&quot;:0,&quot;affinityNodeId&quot;:&quot;370c1554-03f4-4fa2-9c45-880e40288467&quot;,&quot;sessionToken&quot;:null,&quot;error&quot;:null,&quot;response&quot;:&quot;Alberta&quot;}
$curl 'http://192.168.0.110:8080/ignite?cmd=get&amp;amp;key=Ottawa&amp;amp;cacheName=myfirstcache'
{&quot;successStatus&quot;:0,&quot;affinityNodeId&quot;:&quot;370c1554-03f4-4fa2-9c45-880e40288467&quot;,&quot;sessionToken&quot;:null,&quot;error&quot;:null,&quot;response&quot;:null}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;当我们查询Toronto和Edmonton时，返回的省份名称和我们之前写入的一样。 当我们查询Ottawa时，因为我们的cache没有这组数据，所以返回值是&lt;em&gt;null&lt;/em&gt;。&lt;br/&gt;或许有小伙伴已经注意到默认情况下REST API会把key/value当做String来处理，包括存储在集群里的格式也是String。 当然在用put/get命令的时候也你可以用keyType/valueType将key/value其他Ignite支持的类型，比如整型，布尔型，浮点型，日期等类型，但这些类型也仅限于Java内置类型。 如果你想通过REST API来存储一个复杂对象，可能就需要你自己先把对象序列化为一个string，然后读取的时候再反序列化回一个对象。 所以个人觉得REST API还不能发挥出Ignite全部的实力，只能支持一些简单的缓存使用场景，对复杂的操作可能还是SQL或者用代码更方便。&lt;/p&gt;
&lt;p&gt;更多的REST API和具体的使用参数可以查看&lt;a href=&quot;https://apacheignite.readme.io/docs/rest-api#section-api-reference&quot;&gt;官方的REST API文档&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&quot;sql-客户端使用&quot;&gt;SQL 客户端使用&lt;/h3&gt;
&lt;hr/&gt;&lt;p&gt;还记得在官方介绍Ignite的描述中，把Ignite描述为一个以内存为中心的分布式数据，同时Ignite兼容SQL ANSI-99标准，所以可以像使用一个数据库一样使用Ignite，这个特性倒是目前其他内存缓存所不具备的。&lt;/p&gt;
&lt;p&gt;我们可以使用DBeaver工具像连接其他数据库一样连接Ignite。按照&lt;a href=&quot;https://apacheignite-sql.readme.io/docs/sql-tooling&quot;&gt;官方文档&lt;/a&gt;配置完JDBC驱动用到的类，URL连接模板，端口号以及需要使用到的Ignite的jar包，就可以连接到Ignite上了。这个时候Ignite集群里还没有任何数据，所以在DBeaver里是看不到任何表的：&lt;br/&gt;&lt;img src=&quot;https://github.com/codyke/blogs/raw/master/ignite%20study/ignite_study_1/clean_cluster.PNG&quot;/&gt;&lt;br/&gt;现在让我们用SQL语句创建两张表，在执行完SQL语句后，在左边的&lt;em&gt;Tables&lt;/em&gt;选项下就可以看见刚刚创建的两张表了，点开任意一张表，我们就可以在Dbeaver里看到表的schema定义了。:&lt;br/&gt;&lt;img src=&quot;https://github.com/codyke/blogs/raw/master/ignite%20study/ignite_study_1/create_tables.PNG&quot;/&gt;&lt;br/&gt;然后我们在对这两张表用省的名字和市的名字分别建立索引:&lt;br/&gt;&lt;img src=&quot;https://github.com/codyke/blogs/raw/master/ignite%20study/ignite_study_1/create_index.PNG&quot;/&gt;&lt;br/&gt;同样，在执行完SQL语句后，我们就在&lt;em&gt;indexes&lt;/em&gt;选项下看到新建的表索引了。接着，我们可以往表格里插入一些数据，并做简单的查询:&lt;br/&gt;&lt;img src=&quot;https://github.com/codyke/blogs/raw/master/ignite%20study/ignite_study_1/insert_query.PNG&quot;/&gt;&lt;br/&gt;对就是这么简单，和使用其他的数据库没什么区别。而且如果你的Ignite集群包含多个节点，Ignite已经根据你建表时的配置(注意我们在建表的时候&lt;em&gt;with&lt;/em&gt;之后有诸如&lt;em&gt;template=replicated&lt;/em&gt;, &lt;em&gt;backup=1&lt;/em&gt;，&lt;em&gt;affinityKey=province_id&lt;/em&gt;关键字，这些配置会在后面进行介绍)，自动帮你把表数据复制到不同的节点上去了，你不用关心你的数据是如何分布的，一切就交给Ignite做管理吧，即便是有些节点发生故障，也不用担心数据会丢失。&lt;/p&gt;
&lt;p&gt;除了Dbeaver外，Ignite也自带了一个SQL命令行工具，叫做SQLLine，也可以用来连接Ignite执行SQL语句。在$IGNITE_HOME/bin下可以找到这个工具，使用下面的命令启动SQLLine并连接到Ignite集群中：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$cd $IGNITE_HOME/bin
$./sqlline.sh --verbose=true -u jdbc:ignite:thin://192.168.0.110/&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;连接成功后，我们可以查看Ignite中所有的表(&lt;em&gt;!tables&lt;/em&gt;)，表结构(&lt;em&gt;!columns&lt;/em&gt;)，还可以用SQL语句修改/查询数据(&lt;em&gt;!sql SQL Statement&lt;/em&gt;)：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;0: jdbc:ignite:thin://192.168.0.110/&amp;gt; !tables
+--------------------------------+--------------------------------+--------------------------------+--------------------------------+--+
|           TABLE_CAT            |          TABLE_SCHEM           |           TABLE_NAME           |           TABLE_TYPE           |  |
+--------------------------------+--------------------------------+--------------------------------+--------------------------------+--+
|                                | PUBLIC                         | CITY                           | TABLE                          |  |
|                                | PUBLIC                         | PROVINCE                       | TABLE                          |  |
+--------------------------------+--------------------------------+--------------------------------+--------------------------------+--+
0: jdbc:ignite:thin://192.168.0.110/&amp;gt; !columns
+--------------------------------+--------------------------------+--------------------------------+--------------------------------+--+
|           TABLE_CAT            |          TABLE_SCHEM           |           TABLE_NAME           |          COLUMN_NAME           |  |
+--------------------------------+--------------------------------+--------------------------------+--------------------------------+--+
|                                | PUBLIC                         | CITY                           | ID                             |  |
|                                | PUBLIC                         | CITY                           | NAME                           |  |
|                                | PUBLIC                         | CITY                           | PROVINCE_ID                    |  |
|                                | PUBLIC                         | PROVINCE                       | ID                             |  |
|                                | PUBLIC                         | PROVINCE                       | NAME                           |  |
+--------------------------------+--------------------------------+--------------------------------+--------------------------------+--+
0: jdbc:ignite:thin://192.168.0.110/&amp;gt; !sql SELECT p.name, c.name FROM PROVINCE p, CITY c WHERE p.id=c.province_id;
+--------------------------------+--------------------------------+
|              NAME              |              NAME              |
+--------------------------------+--------------------------------+
| Alberta                        | Edmonton                       |
| Alberta                        | Calgary                        |
| Ontario                        | Toronto                        |
| Quebec                         | Montreal                       |
+--------------------------------+--------------------------------+
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;更多SQLLine使用的方法和命令，可以看&lt;a href=&quot;https://apacheignite-sql.readme.io/docs/sqlline&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;ignite-visor-命令行工具&quot;&gt;Ignite Visor 命令行工具&lt;/h2&gt;
&lt;hr/&gt;&lt;p&gt;在启动了Ignite集群后，Ignite也提供了一个简单的命令行工具，&lt;a href=&quot;https://apacheignite-tools.readme.io/docs/command-line-interface&quot;&gt;Visor Command Line Interface&lt;/a&gt;，通过这个工具可以查询集群的状态，检测缓存的使用情况，控制节点等。同样，在$IGNITE_HOME/bin下可以找到Visor命令行工具并启动：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$cd $IGNITE_HOME/bin
$ ./ignitevisorcmd.sh
...
ADMIN CONSOLE
2018 Copyright(C) Apache Software Foundation

+-------------------------------------+
| Status               | Disconnected |
| Ignite instance name | &amp;lt;n/a&amp;gt;        |
| Config path          | &amp;lt;n/a&amp;gt;        |
| Uptime               | &amp;lt;n/a&amp;gt;        |
+-------------------------------------+

Type 'help' for more information.
Type 'open' to join the grid.
Type 'quit' to quit form Visor console.

visor&amp;gt; open&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;启动成功后, 再通过&lt;em&gt;open&lt;/em&gt;命令连接到当前使用的Ignite集群上，我们就可以查询集群的topology信息：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;visor&amp;gt; top 
Hosts: 1
+=========================================================================================================================+
|   Int./Ext. IPs    |   Node ID8(@)    | Node Type |              OS               | CPUs |       MACs        | CPU Load |
+=========================================================================================================================+
| 0:0:0:0:0:0:0:1%lo | 1: 134F0292(@n0) | Server    | Linux amd64 3.13.0-32-generic | 2    | 08:00:27:8F:07:76 | 10.17 %  |
| 127.0.0.1          | 2: B677DAF2(@n1) | Server    |                               |      |                   |          |
| 192.168.0.110      |                  |           |                               |      |                   |          |
+-------------------------------------------------------------------------------------------------------------------------+

Summary:
+--------------------------------------+
| Active         | true                |
| Total hosts    | 1                   |
| Total nodes    | 2                   |
| Total CPUs     | 2                   |
| Avg. CPU load  | 10.17 %             |
| Avg. free heap | 81.00 %             |
| Avg. Up time   | 00:28:14            |
| Snapshot time  | 2018-10-11 00:52:24 |
+--------------------------------------+&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;从上面的输出可以看到，目前我的集群里有1台主机，2个Ignite server节点，这两个节点都跑在同一台机器上的。我们还可以查看下目前集群里的缓存数据：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;visor&amp;gt; cache
Time of the snapshot: 2018-10-11 01:04:59
+============================================================================================================================+
|         Name(@)          |    Mode     | Nodes | Entries (Heap / Off-heap) |   Hits    |  Misses   |   Reads   |  Writes   |
+============================================================================================================================+
| myfirstcache(@c0)        | PARTITIONED | 2     | min: 1 (0 / 1)            | min: 0    | min: 0    | min: 0    | min: 0    |
|                          |             |       | avg: 1.00 (0.00 / 1.00)   | avg: 0.00 | avg: 0.00 | avg: 0.00 | avg: 0.00 |
|                          |             |       | max: 1 (0 / 1)            | max: 0    | max: 0    | max: 0    | max: 0    |
+--------------------------+-------------+-------+---------------------------+-----------+-----------+-----------+-----------+
| SQL_PUBLIC_CITY(@c1)     | PARTITIONED | 2     | min: 2 (0 / 2)            | min: 0    | min: 0    | min: 0    | min: 0    |
|                          |             |       | avg: 2.00 (0.00 / 2.00)   | avg: 0.00 | avg: 0.00 | avg: 0.00 | avg: 0.00 |
|                          |             |       | max: 2 (0 / 2)            | max: 0    | max: 0    | max: 0    | max: 0    |
+--------------------------+-------------+-------+---------------------------+-----------+-----------+-----------+-----------+
| SQL_PUBLIC_PROVINCE(@c2) | REPLICATED  | 2     | min: 1 (0 / 1)            | min: 0    | min: 0    | min: 0    | min: 0    |
|                          |             |       | avg: 1.50 (0.00 / 1.50)   | avg: 0.00 | avg: 0.00 | avg: 0.00 | avg: 0.00 |
|                          |             |       | max: 2 (0 / 2)            | max: 0    | max: 0    | max: 0    | max: 0    |
+----------------------------------------------------------------------------------------------------------------------------+&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到目前我们集群里面有3个缓存，一个是我们通过REST API建立的&lt;em&gt;myfirstcache&lt;/em&gt;缓存，剩下两个是我们在DBeaver里面创建的两张数据库表。同时我们还可以看到每个缓存的统计信息，比如缓存是REPLICATED还是PARTITIONED模式，缓存中有多少条目，读写次数，命中率等。&lt;/p&gt;
&lt;p&gt;Visor的命令行工具就简单介绍到这， 更多命令的使用说明通过&quot;help CMD&quot; 或者 “？ CMD”命令输出命令的帮助文档供查阅。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;hr/&gt;&lt;ul&gt;&lt;li&gt;简单的介绍了Apache Ignite的特性，Ignite可以当做缓存使用，也可以当做分布式数据库使用，还可以用来做计算节点和服务网格等。详细的特性介绍会在随后的文章详细展开。&lt;/li&gt;
&lt;li&gt;Ignite的二进制包安装十分简单，一个命令就可以用默认的配置启动一个Ignite实例，属于开箱即用。&lt;/li&gt;
&lt;li&gt;Ignite支持REST, SQL, Java/.NET客户端连接。使用REST, SQL客户端(Dbeaver和SQLLine)，可以不用写一行代码快速体验Ignite的缓存和分布式数据库能力。&lt;/li&gt;
&lt;li&gt;Ignite自带的Visor Command Line Interface提供了基本的集群查询/管理能力。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;下一篇，让我们看看如何写Java代码来连接Ignite集群，并解锁更多Ignite的特性。&lt;/p&gt;
</description>
<pubDate>Mon, 29 Oct 2018 04:45:00 +0000</pubDate>
<dc:creator>Dinoroar</dc:creator>
<og:description>Ignite 101: 简单介绍Ignite的特性，如何部署安装，以及使用REST/SQL客户端连接Ignite简单的使用。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/peppapigdaddy/p/9717324.html</dc:identifier>
</item>
<item>
<title>【译】写好JavaScript条件语句的5个技巧 - LINJIAJUN</title>
<link>http://www.cnblogs.com/GeniusLyzh/p/9870015.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/GeniusLyzh/p/9870015.html</guid>
<description>&lt;p&gt;译文&lt;br/&gt;当我们写JavaScript代码时，经常会用到到条件判断处理，这里有5个技巧能使你写出更好、更简洁的条件语句。&lt;/p&gt;
&lt;h2 id=&quot;使用array.includes处理多种条件&quot;&gt;1、使用Array.includes处理多种条件&lt;/h2&gt;
&lt;p&gt;让我们来看一下的例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;// conditionfunction test(fruit) {
if (fruit == 'apple' || fruit == 'strawberry') {
console.log('red');
}}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;一眼看去，以上的例子貌似没有什么问题。但是，如果我们加入更多的红色水果，比如车厘子（cherry）和蔓越橘（cranberries）？那就要使用||写更多的条件判断了。&lt;br/&gt;为了解决以上问题，我们可以使用Array.includes来重写以上的条件判断。看以下例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function test(fruit) {
// extract conditions to array
const redFruits = ['apple', 'strawberry', 'cherry', 'cranberries'];
if (redFruits.includes(fruit)) {
console.log('red');
}}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;将这些“红色水果”（条件）提取到数组里面，这样写就会看起来很简洁了。&lt;/p&gt;
&lt;h2 id=&quot;减少嵌套尽早return&quot;&gt;2、减少嵌套，尽早return&lt;/h2&gt;
&lt;p&gt;下面我们增加两个条件判断来扩展下上一个例子：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;如果没有水果则抛出异常&lt;/li&gt;
&lt;li&gt;如果数量超出10则输出水果数量&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;function test(fruit, quantity) {
  const redFruits = ['apple', 'strawberry', 'cherry', 'cranberries'];
  // condition 1: fruit must has value
  if (fruit) {
    // condition 2: must be red
    if (redFruits.includes(fruit)) {
      console.log('red');
      // condition 3: must be big quantity
      if (quantity &amp;gt; 10) {
        console.log('big quantity');
      }
    }
  } else {
    throw new Error('No fruit!');
  }
}
// test results
test(null); // error: No fruits
test('apple'); // print: red
test('apple', 20); // print: red, big quantity&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;看着以上的代码，发现以下的问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一个过滤无效条件的if/else语句&lt;/li&gt;
&lt;li&gt;嵌套三级 if条件语句&lt;br/&gt;我个人遵循的一般规则：在处理无效条件时尽早return&lt;/li&gt;
&lt;/ul&gt;&lt;pre&gt;
&lt;code&gt;/_ return early when invalid conditions found _/
function test(fruit, quantity) {
  const redFruits = ['apple', 'strawberry', 'cherry', 'cranberries'];
  // condition 1: throw error early
  if (!fruit) throw new Error('No fruit!');
  // condition 2: must be red
  if (redFruits.includes(fruit)) {
    console.log('red');
    // condition 3: must be big quantity
    if (quantity &amp;gt; 10) {
      console.log('big quantity');
    }
  }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过这种写法，可以减少一层嵌套。当if语句很长的时候，这种写法就比较好。（试想一下，你需要滚动到很底部才能看到else语言，这样不酷）。&lt;br/&gt;我们也可以用相反的条件判断和尽早返回来减少if语句嵌套，看以下第二个条件是如何处理的。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;/_ return early when invalid conditions found _/

function test(fruit, quantity) {
  const redFruits = ['apple', 'strawberry', 'cherry', 'cranberries'];
  if (!fruit) throw new Error('No fruit!'); // condition 1: throw error early
  if (!redFruits.includes(fruit)) return; // condition 2: stop when fruit is not red
  console.log('red');
  // condition 3: must be big quantity
  if (quantity &amp;gt; 10) {
    console.log('big quantity');
  }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;通过在第二个条件里取反的条件来判断，现在的代码释放了一个嵌套。当我们要写很长的逻辑以及想停止更一步的过程时，这种方法很凑效。&lt;br/&gt;但是，这样写并不是硬性的，要看具体的场景。有时候，你要问下自己，这样的写法（没有嵌套）是否比之前那种（在条件2嵌套）更好或者更具可读性。&lt;/p&gt;
&lt;p&gt;对我来说，我只会远离之前的那种写法（在条件2嵌套），注意有以下两个原因：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;对比嵌套if语句，这种写法更短，更简洁&lt;/li&gt;
&lt;li&gt;取反的条件判断可能招致更多的思考过程（增加认知负荷）&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;因此，始终旨在减少嵌套和及时及早返回（return），但是不要过度去这样做。如果感兴趣可以查看以下的一篇相关文章和在StackOverflow的关于这主题的更多讨论：&lt;/p&gt;
&lt;h2 id=&quot;使用函数默认参数和解构&quot;&gt;3、使用函数默认参数和解构&lt;/h2&gt;
&lt;p&gt;我猜以下的代码你看起来应该很熟悉了，我们仍然需要在执行JavaScript时检查空值（undefined或null）。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function test(fruit, quantity) {
  if (!fruit) return;
  const q = quantity || 1; // if quantity not provided, default to one
  console.log(`We have ${q} ${fruit}!`);
}
//test results
test('banana'); // We have 1 banana!
test('apple', 2); // We have 2 apple!&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;事实上，我们可以消除变量p来分配函数默认参数。看以下例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function test(fruit, quantity = 1) { // if quantity not provided, default to one
  if (!fruit) return;
  console.log(`We have ${quantity} ${fruit}!`);
}
//test results
test('banana'); // We have 1 banana!
test('apple', 2); // We have 2 apple!&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;是不是看起来很简单，很直观？请记住，每个参数都有自己的默认函数参数。例如，我们也可以为fruit分配默认值（即以上代码的第一个参数）:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function test(fruit = 'unknown', quantity = 1)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;另外一个问题来了：如果fruit参数是Object类型怎么办？我们可以指定默认值吗？&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function test(fruit) { 
  // printing fruit name if value provided
  if (fruit &amp;amp;&amp;amp; fruit.name)  {
    console.log (fruit.name);
  } else {
    console.log('unknown');
  }
}
//test results
test(undefined); // unknown
test({ }); // unknown
test({ name: 'apple', color: 'red' }); // apple&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;看看上面的例子，我们想要打印出fruit的名称如果值存在的话，否则打印出“unknow”。我们可以通过检查默认函数参数和对象解构来避免fruit&amp;amp;&amp;amp;fruit.name这个条件。看看以下例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;// destructing - get name property only
// assign default empty object {}
function test({name} = {}) {
  console.log (name || 'unknown');
}
//test results
test(undefined); // unknown
test({ }); // unknown
test({ name: 'apple', color: 'red' }); // apple&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;由于我们只需要fruit对象的name属性，可以使用{name}来解构对象，然后我们可以在代码中使用name作为变量代替fruit.name。&lt;br/&gt;我们还将分配空对象{}作为默认参数。如果不这样做的话，在执行test(undefined)这行代码时就会报错：无法解析’undefined’或’null’的属性name，因为undefined没有name这个属性。&lt;br/&gt;如果你不介意使用第三方库，有几个方法可以减少空值检查。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;使用&lt;a href=&quot;https://lodash.com/docs/4.17.10#get&quot;&gt;Lodash get&lt;/a&gt;方法&lt;/li&gt;
&lt;li&gt;使用Facebook 开源的&lt;a href=&quot;https://github.com/facebookincubator/idx&quot;&gt;idx&lt;/a&gt;库（和Bablejs）&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;以下是使用Lodash的例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;// Include lodash library, you will get _
function test(fruit) {
  console.log(__.get(fruit, 'name', 'unknown'); // get property name, if not available, assign default value 'unknown'
}
//test results
test(undefined); // unknown
test({ }); // unknown
test({ name: 'apple', color: 'red' }); // apple&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;你可以在&lt;a href=&quot;http://jsbin.com/bopovajiye/edit?js,console&quot;&gt;这里&lt;/a&gt;执行这个demo。另外，如果你热衷于使用函数式编程(FP)，你可能会选择用&lt;a href=&quot;https://github.com/lodash/lodash/wiki/FP-Guide&quot;&gt;Lodash fp&lt;/a&gt;，Lodash的函数式版本（方法改为get或getOr）。&lt;/p&gt;
&lt;h2 id=&quot;支持map或对象字面量而不是switch声明&quot;&gt;4、支持Map或对象字面量而不是switch声明&lt;/h2&gt;
&lt;p&gt;我们来看看以下例子：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function test(color) {
  // use switch case to find fruits in color
  switch (color) {
    case 'red':
      return ['apple', 'strawberry'];
    case 'yellow':
      return ['banana', 'pineapple'];
    case 'purple':
      return ['grape', 'plum'];
    default:
      return [];
  }
}
//test results
test(null); // []
test('yellow'); // ['banana', 'pineapple']&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上的代码看起来貌似没什么错误，但是我发现代码十分杂乱。其实可以用字面量对象更清晰的语法来实现相同的结果。例如：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;// use object literal to find fruits in color
  const fruitColor = {
    red: ['apple', 'strawberry'],
    yellow: ['banana', 'pineapple'],
    purple: ['grape', 'plum']
  };
function test(color) {
  return fruitColor[color] || [];
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;或者，你也可以用Map来实现同样的结果，例如：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;// use Map to find fruits in color
  const fruitColor = new Map()
    .set('red', ['apple', 'strawberry'])
    .set('yellow', ['banana', 'pineapple'])
    .set('purple', ['grape', 'plum']);
function test(color) {
  return fruitColor.get(color) || [];
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map&quot;&gt;Map&lt;/a&gt;是自ES6开始才可用的对象类型，可以用来存储键值对。&lt;/p&gt;
&lt;h2 id=&quot;对所有或部分规则使用array.every和array.some&quot;&gt;5、对所有或部分规则使用Array.every和Array.some&lt;/h2&gt;
&lt;p&gt;最后一个技巧是关于利用新的（其实不是很新了）JavaScript数组方法来减少代码函数。看看下面的代码，我们想所有的水果是否都是红色的。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;const fruits = [
    { name: 'apple', color: 'red' },
    { name: 'banana', color: 'yellow' },
    { name: 'grape', color: 'purple' }
  ];
function test() {
  let isAllRed = true;
  // condition: all fruits must be red
  for (let f of fruits) {
    if (!isAllRed) break;
    isAllRed = (f.color == 'red');
  }
  console.log(isAllRed); // false
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的代码真的好冗长！我们可以用Array.every来减少代码行数。来看看：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;const fruits = [
    { name: 'apple', color: 'red' },
    { name: 'banana', color: 'yellow' },
    { name: 'grape', color: 'purple' }
  ];
function test() {
  // condition: short way, all fruits must be red
  const isAllRed = fruits.every(f =&amp;gt; f.color == 'red');
  console.log(isAllRed); // false
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;现在是不是简洁很多了？同样类似的方法，如果你想测试是否所有的水果都是红色，可以用Array.some一行代码即可实现。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;const fruits = [
    { name: 'apple', color: 'red' },
    { name: 'banana', color: 'yellow' },
    { name: 'grape', color: 'purple' }
];
function test() {
  // condition: if any fruit is red
  const isAnyRed = fruits.some(f =&amp;gt; f.color == 'red');
  console.log(isAnyRed); // true
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;让我们一起生成更多可读代码。 我希望你能在本文中学到一些新东西。&lt;br/&gt;就这样。 写代码快乐！&lt;br/&gt;(完)&lt;/p&gt;
&lt;h2 id=&quot;后记&quot;&gt;后记&lt;/h2&gt;
&lt;p&gt;以上译文仅用于学习交流，水平有限，难免有错误之处，敬请指正。&lt;/p&gt;
&lt;h2 id=&quot;更多阅读&quot;&gt;更多阅读&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map&quot;&gt;解构赋值&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map&quot;&gt;Map&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://juejin.im/post/5bd66b7d6fb9a05ce1729ae5?utm_source=gold_browser_extension&quot;&gt;倔金&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;原文链接&quot;&gt;原文链接&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://scotch.io/bar-talk/5-tips-to-write-better-conditionals-in-javascript#toc-4-favor-map-object-literal-than-switch-statement%5D&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 29 Oct 2018 04:39:00 +0000</pubDate>
<dc:creator>LINJIAJUN</dc:creator>
<og:description>译文 当我们写JavaScript代码时，经常会用到到条件判断处理，这里有5个技巧能使你写出更好、更简洁的条件语句。 1、使用Array.includes处理多种条件 让我们来看一下的例子： 一眼看去</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/GeniusLyzh/p/9870015.html</dc:identifier>
</item>
<item>
<title>密码学基础上篇 - he1m4n6a</title>
<link>http://www.cnblogs.com/he1m4n6a/p/9869458.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/he1m4n6a/p/9869458.html</guid>
<description>&lt;p&gt;本文首发自&lt;a href=&quot;https://www.chongdongshequ.com/article/1540780662067.html&quot; target=&quot;_blank&quot;&gt;虫洞社区&lt;/a&gt;，转载请注明出处。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;密码学概念&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;密码学是对信息进行编码实现隐蔽信息的一门科学，采用密码技术可以隐藏和保护需要保密的信息，使未经授权者不能提取信息。需要隐藏的消息称为“明文”；明文被变换成的另一种隐蔽的形式就是“密文”。这种变换称为“加密”；加密的逆过程，即从密文恢复出对应的明文的过程称为“解密”。对明文进行加密时采用的一组规则（函数）称为“加密算法”。对密文解密时使用的算法称为“解密算法”。一般地，加密算法和解密算法都是在一组密钥控制之下进行的，加密时使用的密钥称之为“加密密钥”，解密时使用的密钥称之为“解密密钥”。&lt;/p&gt;

&lt;p&gt;什么是密码系统呢？密码系统是一个概念，可以用以下的等式简单概括：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;密码系统 = 密码算法 + 明文空间 + 密文空间 + 密钥集合&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;把密码系统拆开来看，就容易理解，一个完整的密码系统，必定包含算法、秘钥、明文、密文四个部分。&lt;/p&gt;
&lt;h3 id=&quot;h3--&quot;&gt;密码系统应该满足的要求：&lt;/h3&gt;
&lt;ol&gt;&lt;li&gt;系统的保密性不依赖与算法的保密性，而依赖于密钥&lt;/li&gt;
&lt;li&gt;破译加解密算法在计算上是不可行的（破译密文的代价超过被加密信息的价值；破译密文所花的时间操作信息有用期）&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;h3--&quot;&gt;密码体制分类：&lt;/h3&gt;
&lt;p&gt;密码体制中根据加密秘秘钥是否相同，分为对称加密算法和非对称加密算法。顾名思义，非对称加密算法需要两个不同密钥：公开密钥（publickey）和私有密钥（privatekey）。公开密钥与私有密钥是一对，如果用公开密钥对数据进行加密，只有用对应的私有密钥才能解密；如果用私有密钥对数据进行加密，那么只有用对应的公开密钥才能解密。反之使用同一秘钥的算法称为对称算法。&lt;/p&gt;
&lt;p&gt;对称算法：加解密使用同一秘钥。&lt;br/&gt;&lt;img src=&quot;https://cdn.ktvsky.com/a57adc4f6f52088702520f20989b8b60.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;非对称算法：加解密使用不同的秘钥。&lt;br/&gt;&lt;img src=&quot;https://cdn.ktvsky.com/cac61f2acde2d32924ba71849f80913b.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;对称与非对称加密方式对比：&lt;br/&gt;&lt;img src=&quot;https://cdn.ktvsky.com/97c4637fe311a9897fe3dca2e6e1edb1.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;h4-u5E38u89C1u5BF9u79F0u7B97u6CD5&quot;&gt;常见对称算法&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.ktvsky.com/6aa15a2047f6ac7067d6fcee17149162.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;由于对称算法加解密秘钥是相同的，所以对称算法的安全性依赖秘钥的长度，通常情况下秘钥越长，安全性越高。所以56bit的DES的安全性极低，极容易被暴力破解。而3DES是为了兼容DES的折中方案，目前比较安全的算法是AES。&lt;/p&gt;
&lt;h4 id=&quot;h4-u5E38u89C1u975Eu5BF9u79F0u7B97u6CD5&quot;&gt;常见非对称算法&lt;/h4&gt;
&lt;p&gt;说到非对称算法，一般都会先想到大名鼎鼎的RSA算法。RSA的安全基于大数分解的难度。其公钥和私钥是一对大素数（100到200位十进制数或更大）的函数。从一个公钥和密文恢复出明文的难度，等价于分解两个大素数之积（这是公认的数学难题）。RSA的公钥、私钥的组成，以及加密、解密的公式如下：&lt;br/&gt;&lt;img src=&quot;https://cdn.ktvsky.com/3dbf64e55a3b1ed9b87ca65d07c7498c.jpg&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;当然非对称算法还有椭圆曲线算法ECC，其主要安全性在于利用了椭圆曲线离散对数问题的困难性，证明过程还是挺繁琐，这边不细讲，有兴趣同学可以自己搜集资料了解下。&lt;/p&gt;

&lt;h3 id=&quot;h3-hash-&quot;&gt;Hash函数定义&lt;/h3&gt;
&lt;p&gt;Hash算法又叫做杂凑算法、单项散列函数。散列函数就是把可变长度输入串（叫预映射）转化成固定长度的输出串（叫散列值）的一种函数。&lt;/p&gt;
&lt;p&gt;Hash函数的要求：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;任意消息大小都适用&lt;/li&gt;
&lt;li&gt;输出固定的长度&lt;/li&gt;
&lt;li&gt;计算相对简单：在有限时间和有限资源内能计算出 hash 值&lt;/li&gt;
&lt;li&gt;抗第一原相性（单向性）：给出一个输出z，找到满足h(x)=z的输入x是不可能的&lt;/li&gt;
&lt;li&gt;抗第二原相性：给定x1和h(x1)，找到满足h(x1)=h(x2)的x2在计算上是不可能的&lt;/li&gt;
&lt;li&gt;抗冲突性满足h(x1)=h(x2)的一对，在计算上是不可行的&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;Hash函数算法特点：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;正向快速：给定明文和 hash 算法，在有限时间和有限资源内能计算出 hash 值。&lt;/li&gt;
&lt;li&gt;逆向困难：给定（若干） hash 值，在有限时间内很难（基本不可能）逆推出明文。&lt;/li&gt;
&lt;li&gt;输入敏感：原始输入信息修改一点信息，产生的 hash 值看起来应该都有很大不同。&lt;/li&gt;
&lt;li&gt;冲突避免：很难找到两段内容不同的明文，使得它们的 hash 值一致（发生冲突）。即对于任意两个不同的数据块，其hash值相同的可能性极小；对于一个给定的数据块，找到和它hash值相同的数据块极为困难。&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;h3-u751Fu65E5u653Bu51FB&quot;&gt;生日攻击&lt;/h3&gt;
&lt;p&gt;生日问题：假设每个人的生日都是等概率的，每年365天，在k个中至少两个人的生日概率大于1/2，问k最小是多少？&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;P(至少两人生日相同)=1- P(k人生日都不同)&lt;br/&gt;P(365, k) = 1- (1-1/365)(1-2/365)…(1-k/365)&lt;br/&gt;p(365,23) = 0.5073&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;所以只要23个人，两个人相同生日的概率就大于50%了。根据生日悖论可以得到这样一个结论：对于hash值长度为2n的hash函数，生日攻击的复杂度是2n/2，注意这边攻击的是hash函数的抗第二原性。&lt;/p&gt;
&lt;p&gt;王小云教授破解hash函数又是怎么回事。根据hash函数的特定我们知道，hash是不可能被破解的，这边说的破解说的是一个概念叫理论破解，指的是提出一个算法，使得可以用低于理论值得枚举次数找到碰撞。王小云的主要工作是给出了MD5，SHA-0的碰撞，以及SHA-1的理论破解，例如她证明了160位SHA-1，只需要大约2^69次计算就能找出来，而理论值是2^80次。所以王小云的贡献就是找到了比生日攻击复杂度低得多算法来快速找到一对强碰撞，弱碰撞依旧是不行的。&lt;/p&gt;
&lt;h3 id=&quot;h3-hash-&quot;&gt;Hash函数的应用&lt;/h3&gt;
&lt;p&gt;hash函数常用在密码加密中，这样即使密码泄露也无法反向得到明文密码。但是可以事先得到一些字符的hash值，然后对比这个hash值得到明文密码，这就是常见的彩虹表破解。所以为了提高安全性，一些网站还会对密码加salt后再进行hash计算，这边所谓的salt就是几位随机字符串。接下来重点说下hash函数在区块链中的应用。哈希算法在区块链系统中的应用很广泛：比特币使用哈希算法通过公钥计算出钱包地址、区块头以及交易事务的哈希值，梅克尔树结构本身就是一颗哈希树，就连挖矿算法都是使用的哈希值难度匹配；以太坊中的挖矿计算也使用哈希算法，其中的梅克尔-帕特里夏树同样也是一颗哈希树。下面就举两例说明下hash在区块链中的重要性。&lt;/p&gt;
&lt;p&gt;一：梅克尔树&lt;br/&gt;在区块主体中，所有交易信息先进行两个一组的哈希计算，这种结构叫做梅克尔树（Merkle Tree），而且是一棵倒挂的树。例如一个区块里只有4笔交易，则默克尔树生成过程。&lt;br/&gt;&lt;img src=&quot;https://cdn.ktvsky.com/bd277d3109eb5825cc30ee2decdf2bd4.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;二：Hash挖矿&lt;br/&gt;那hash在区块链中最为人知的应用是hash挖矿，那这到底是怎么一回事呢？例如比特币中的挖矿，简单来说，即要找出类似 00010000000000000000000000000000 的目标hash。后面挖矿越来越困难，就是因为要找到hash值越来越小。所以，可以简单理解为挖矿就是找出某随机数的hash使得比目标hash还要小。&lt;/p&gt;
</description>
<pubDate>Mon, 29 Oct 2018 03:04:00 +0000</pubDate>
<dc:creator>he1m4n6a</dc:creator>
<og:description>本文首发自虫洞社区，转载请注明出处。 密码学概念 密码学是对信息进行编码实现隐蔽信息的一门科学，采用密码技术可以隐藏和保护需要保密的信息，使未经授权者不能提取信息。需要隐藏的消息称为“明文”；明文被变</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/he1m4n6a/p/9869458.html</dc:identifier>
</item>
</channel>
</rss>