<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>【10.15总结】绕过CSRF的Referer保护 - zoe宇</title>
<link>http://www.cnblogs.com/zz0eyu/p/9789072.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zz0eyu/p/9789072.html</guid>
<description>&lt;p&gt;今天下午可能要出远门，所以现在就把总结写好了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Write-up地址：&lt;/strong&gt;&lt;a href=&quot;https://medium.com/bugbountywriteup/critical-bypass-csrf-protection-on-ibm-313ffb68dd0c&quot;&gt;[Critical] Bypass CSRF protection on IBM&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这个CSRF漏洞存在于IBM的修改邮箱页面，修改邮箱的地址是&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
https://www.ibm.com/ibmweb/myibm/account/sendmail?locale=us-en&amp;amp;email=NEW_EMAIL 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;所以理论上讲，只要修改上面链接中的NEW_EMAIL为自己的邮箱，被攻击者在登录了自己的IBM账户后点击该链接，就能达到修改被攻击者邮箱的目的。&lt;/p&gt;
&lt;p&gt;但是作者&lt;a href=&quot;https://medium.com/@flex0geek?source=post_header_lockup&quot;&gt;Mohamed Sayed&lt;/a&gt;在尝试时，发现IBM会&lt;span&gt;检测请求发出的Referer头部&lt;/span&gt;，正常修改邮箱的请求Referer头部为&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
https://www.ibm.com/ibmweb/myibm/profile/profile-edit.jsp
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;作者经过几个小时的尝试，发现使用下面的Referer头部可以成功绕过IBM的验证&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
http://my_website/www.ibm.com/ibmweb/myibm/profile/profile-edit.jsp.php 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在测试漏洞时，作者&lt;span&gt;使用了Moakt的临时邮箱服务生成了一个临时邮箱地址&lt;/span&gt;作为NEW_EMAIL，在自己的网站上创建文件profile-edi.jsp.php&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;script &lt;/span&gt;&lt;span&gt;type&lt;/span&gt;&lt;span&gt;=&quot;text/javascript&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;
    document.location.href&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;https://www.ibm.com/ibmweb/myibm/account/sendmail?locale=us-en&amp;amp;email=NEW_EMAIL&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;script&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这样，只要欺骗被攻击者访问该网页，就可以在自己生成的临时邮箱里收到确认修改邮箱的邮件，成功修改被攻击者IBM账号的邮箱了。&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;其实这个漏洞原理很简单，我之前在看对CSRF介绍的文章时也有看到过验证Referer的防御手段，只是真实案例是第一次接触，所以仍然很有新鲜感。从该案例也可以看出，CSRF可以使用验证Referer头部的方式进行防御，但是&lt;span&gt;网站对Referer的验证方法仍然可能存在漏洞，需要进行不断的尝试&lt;/span&gt;。&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;今天还看了另外一篇文章&lt;a href=&quot;https://medium.com/bugbountywriteup/devoops-an-xml-external-entity-xxe-hackthebox-walkthrough-fb5ba03aaaa2&quot;&gt;DevOops — An XML External Entity (XXE) HackTheBox Walkthrough&lt;/a&gt;，一开始没明白文章中提到的DevOops是什么东西，只是觉得可以通过这篇文章了解一下渗透测试的简单流程，后来谷歌了一下，才发现Hack the box是一个在线的渗透测试平台，感觉还蛮不错的，注册需要通过一个小测试，并不难，虽然网上已经有教程了，但我还是遵守规则不说出通过测试的方法，只是一个小tip——看网页的源码。&lt;/p&gt;
</description>
<pubDate>Sun, 14 Oct 2018 23:16:00 +0000</pubDate>
<dc:creator>zoe宇</dc:creator>
<og:description>今天下午可能要出远门，所以现在就把总结写好了。 Write-up地址：[Critical] Bypass CSRF protection on IBM 这个CSRF漏洞存在于IBM的修改邮箱页面，修改</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/zz0eyu/p/9789072.html</dc:identifier>
</item>
<item>
<title>ASP.NET Core框架揭秘[持续更新中…] - Artech</title>
<link>http://www.cnblogs.com/artech/p/inside-asp-net-core.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/artech/p/inside-asp-net-core.html</guid>
<description>&lt;p&gt;之前一段时间都在个人公众号账号“大内老A”发布关于ASP.NET Core的系列文章，很多人留言希望能够同步到这里，所以在这里 对这些文章做一个汇总，以便于PC端阅读。如果说微软官方文档主要关于ASP.NET Core的编程模式的话，我这个系列则主要关注整个ASP.NET Core的&lt;span&gt;设计思想&lt;/span&gt;和&lt;span&gt;实现原理&lt;/span&gt;。我希望这个系列为致力于深入学习ASP.NET Core的人提供一个&lt;span&gt;全面&lt;/span&gt;、&lt;span&gt;系统&lt;/span&gt;而&lt;span&gt;深入&lt;/span&gt;的知识库。为了确保本系列的纯粹性，这个系列旨在关注ASP.NET Core以中间件管道核心的框架，不会涉及建立在它之上的编程模型（比如ASP.NET Core MVC）。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.  多平台开发体验&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    &lt;a href=&quot;https://www.cnblogs.com/artech/p/asp-net-core-hello-world-01.html&quot;&gt;多平台开发体验[1]: Windows&lt;/a&gt; &lt;br/&gt;    &lt;a href=&quot;https://www.cnblogs.com/artech/p/asp-net-core-hello-world-02.html&quot;&gt;多平台开发体验[2]: Mac OS X&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;https://www.cnblogs.com/artech/p/asp-net-core-hello-world-03.html&quot;&gt;多平台开发体验[3]: Linux&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;https://www.cnblogs.com/artech/p/asp-net-core-hello-world-04.html&quot;&gt;多平台开发体验[4]: Docker&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;2. 跨平台的奥秘&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484208&amp;amp;idx=1&amp;amp;sn=be494a40da629a13c14ee51d36857c31&amp;amp;chksm=97746221a003eb37a6e1c4f837cbd165721d2785aef7e2024bcedc88a1279c67daaf68abfa54#rd&quot;&gt;跨平台的奥秘[1]: 历史的枷锁[上篇]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484214&amp;amp;idx=1&amp;amp;sn=f66dda6e90d44dbd4ff6f288b413b64b&amp;amp;chksm=97746227a003eb31bf60e192d440a280c7e3d5cb25b08995274615d5fb36437397299cd20469#rd&quot;&gt;跨平台的奥秘[2]: 历史的枷锁[下篇]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484215&amp;amp;idx=1&amp;amp;sn=bbb0853a2dbf358a1de1582e48bbde57&amp;amp;chksm=97746226a003eb3076f8f7fe908a186d9e76bdf0847330e7dbc6daaec3f89bc0764d6e392289#rd&quot;&gt;跨平台的奥秘[3]: 复用之殇[上篇]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484216&amp;amp;idx=1&amp;amp;sn=23d408b8c60fa6324a1758db13495a08&amp;amp;chksm=97746229a003eb3f1a9c042dea1ff94fa48c82e9845a8c69b7add22d36dbde95317a2d99f760#rd&quot;&gt;跨平台的奥秘[4]: 复用之殇[中篇]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484217&amp;amp;idx=1&amp;amp;sn=c4c4fb9f5e56174e9ffba3a8d2f69e69&amp;amp;chksm=97746228a003eb3ec5e872640b244c842045033d7e54839751c9c55c33527bf60fc40529cee4#rd&quot;&gt;跨平台的奥秘[5]: 复用之殇[下篇]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484227&amp;amp;idx=1&amp;amp;sn=25e760695d35db4bc5c23832513e8c63&amp;amp;chksm=97746252a003eb440e7b049459d1cc5a081257b1a86c49e999d78c37e7ff96cb82c10c8f98d8#rd&quot;&gt;跨平台的奥秘[6]: 全新的布局[上篇]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484236&amp;amp;idx=1&amp;amp;sn=d2a3c0a598e855afe475e6acd15a527e&amp;amp;chksm=9774625da003eb4bfcdec73f83cf67a28f0d9f26136ff10fa4b1fd3f8986716f75b2542521f1#rd&quot;&gt;跨平台的奥秘[7]: 全新的布局[下篇]&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;3. 依赖注入&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484122&amp;amp;idx=1&amp;amp;sn=35b48f7d4dfa4fd71aa3d8cd5a41f75a&amp;amp;chksm=977463cba003eaddddf77762281bc69ed788a557cec0b48a24130f06414e9b0ce972592e48fa#rd&quot;&gt;依赖注入[1]: 控制反转&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484126&amp;amp;idx=1&amp;amp;sn=d25d50f3afae0bb7fa0b13ade205aaf0&amp;amp;chksm=977463cfa003ead9444f1c6b663da3cfc036388aba44def567b505b59f8cb493eabe7c1a25e1#rd&quot;&gt;依赖注入[2]: 基于IoC的设计模式&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484139&amp;amp;idx=1&amp;amp;sn=800aefd616775399f31788666d681478&amp;amp;chksm=977463faa003eaec679907cd53f924d9b13009b9349b91ed9aaa01652229ce188b26cf386901#rd&quot;&gt;依赖注入[3]: 依赖注入模式&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484139&amp;amp;idx=1&amp;amp;sn=800aefd616775399f31788666d681478&amp;amp;chksm=977463faa003eaec679907cd53f924d9b13009b9349b91ed9aaa01652229ce188b26cf386901#rd&quot;&gt;依赖注入[4]: 创建一个简易版的DI框架[上篇]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484142&amp;amp;idx=1&amp;amp;sn=264ad4d40e01d5067f502e14e08177dd&amp;amp;chksm=977463ffa003eae9ff79e5de18d5b0114fb36488d74855099b0c80b7763640209e67f3968c58#rd&quot;&gt;依赖注入[5]: 创建一个简易版的DI框架[下篇]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484148&amp;amp;idx=1&amp;amp;sn=c61e00e4edf6c66ee51804ce2ac23d3f&amp;amp;chksm=977463e5a003eaf3e745a9b40d3ca1387f5886ff4f81b19f8a433148a07aa273a108e180b240#rd&quot;&gt;依赖注入[6]: .NET Core DI框架[编程体验]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484160&amp;amp;idx=1&amp;amp;sn=0303a6964350795932468031ac2c86ca&amp;amp;chksm=97746211a003eb071efa58f6c2b838bea5369b69150c705781a5db7a491676dede140f713626#rd&quot;&gt;依赖注入[7]: .NET Core DI框架[服务注册]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484170&amp;amp;idx=1&amp;amp;sn=dae95816f12fc0203d7fb746196e0adc&amp;amp;chksm=9774621ba003eb0dd5c20f81d020e1c6cd77b28ef164fd1d4c0a8abb9f45bad469fdef402b98#rd&quot;&gt;依赖注入[8]: .NET Core DI框架[服务消费]&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;4. 文件系统&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484244&amp;amp;idx=1&amp;amp;sn=6dbe5d696826fef8f3a083c2c96cefb6&amp;amp;chksm=97746245a003eb53386a73ffc614ef9fc28b6c367fa4903ca0debf2b814cc1926ebf3ea4d90e#rd&quot;&gt;文件系统[1]: 一个抽象的“文件系统”&lt;/a&gt; &lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484250&amp;amp;idx=1&amp;amp;sn=e60c86371a23ede1b58d164073b2fee4&amp;amp;chksm=9774624ba003eb5d52b71fdf722d3fd2dc496a90a6fae0ac8a1c4474c76207a770dcc7984252#rd&quot;&gt;文件系统[2]: 物理文件系统&lt;/a&gt; &lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484255&amp;amp;idx=1&amp;amp;sn=287151c9c33bfe648949038348ec7a1b&amp;amp;chksm=9774624ea003eb5812a3e552b6ce2a5c2af31d725aa3f10532941ceede59999a877d7c3ddcb8#rd&quot;&gt;文件系统[3]: 内嵌文件系统&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;5. 配置&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484262&amp;amp;idx=1&amp;amp;sn=9353bd185a046801ae17f3569fe638d7&amp;amp;chksm=97746277a003eb615f7b2e9163009d748c842fb1760840723d72e4a6287a71bac803449fc7ab#rd&quot;&gt;配置[1]: 读取配置信息[上篇]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484269&amp;amp;idx=1&amp;amp;sn=3a856c2efbd07df0d7b78fe4a2cd9775&amp;amp;chksm=9774627ca003eb6acf56959f908dbaa6266f2435d279892be22f90b17810e7a6fd4e007d69c4#rd&quot;&gt;配置[2]: 读取配置信息[下篇]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;https://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484277&amp;amp;idx=1&amp;amp;sn=5a630553b6512ceb43457763c7ececa8&amp;amp;chksm=97746264a003eb727ec8c5715dece437050380f5090bde096804ded35c223e0264f625355b5a&amp;amp;token=1970862794&amp;amp;lang=zh_CN#rd&quot;&gt;配置[3]: 配置模型详解&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484281&amp;amp;idx=1&amp;amp;sn=02fad25e1d414b2acf7a503fcdf80e79&amp;amp;chksm=97746268a003eb7e3aa677050e4d0a7ed87ec016cadaace2d134ff0a330c36cfcc2e74098fca#rd&quot;&gt;配置[4]: 配置绑定 [上篇]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484286&amp;amp;idx=1&amp;amp;sn=8bb80293799099b18c06db337690ea73&amp;amp;chksm=9774626fa003eb79e23344b4d6401c0aee6330ec96a60c05f24bce1d3249f1b03ffc94582c42#rd&quot;&gt;配置[5]: 配置绑定 [下篇]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484290&amp;amp;idx=1&amp;amp;sn=f744c7da1ea4d617c9a454b8df34ff37&amp;amp;chksm=97746293a003eb8598a8379cba71cc303881493a054934b3b3532a434c83dee0d937c1a07a1f#rd&quot;&gt;配置[6]: 配置源的同步&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484295&amp;amp;idx=1&amp;amp;sn=8b57dfbf74a9b9623af203436c6b405d&amp;amp;chksm=97746296a003eb8052cd9913afeb60c86758aaba25d8b619411b990d84c64fe5bf33e180d131#rd&quot;&gt;配置[7]: 多样性的配置源 [上篇]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484298&amp;amp;idx=1&amp;amp;sn=8903351b67e310182ddb92a17b679890&amp;amp;chksm=9774629ba003eb8d353bc2a773fc22351afcab5b401031244b26023a60266a3e3b76bc489d5b#rd&quot;&gt;配置[8]: 多样性的配置源 [下篇]&lt;/a&gt;&lt;br/&gt;    &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484301&amp;amp;idx=1&amp;amp;sn=964a7006e32617d8c17e93d6bfa44735&amp;amp;chksm=9774629ca003eb8aba84320d1b04750f998ec86a9e915fe8f4e1e822d1099e980b3938e098a3#rd&quot;&gt;配置[9]: 自定义配置源&lt;/a&gt;  &lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;6. Options模式&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484311&amp;amp;idx=1&amp;amp;sn=7e23893d2384206aa4c933ee78bc62f9&amp;amp;chksm=97746286a003eb90006e9bda546146449f56499c2c3f9d6fc594054ff245b6be6cfea74f7ec7#rd&quot;&gt;Options模式[1]: 以注入的方式使用配置选项[上篇]&lt;/a&gt;&lt;br/&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484312&amp;amp;idx=1&amp;amp;sn=27b43fccf9629c458d5c1b041897e705&amp;amp;chksm=97746289a003eb9f20a1454f79a62b14e1ceb8bee4d150834e54073c5c98a3c6d4ff8bbadff0#rd&quot;&gt;Options模式[2]: 以注入的方式使用配置选项[下篇]&lt;/a&gt;&lt;br/&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484320&amp;amp;idx=1&amp;amp;sn=f7b141503cfe2e68cf46a9fd5d55991b&amp;amp;chksm=977462b1a003eba7879c1727a18893ef95aee48a5b4bd169cdbc05a0de0bf82bc9aae7d8919c#rd&quot;&gt;Options模式[3]: Options模型详解[上篇]&lt;/a&gt;&lt;br/&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484321&amp;amp;idx=1&amp;amp;sn=700bb926cdcd5fc3bfb985e82da0d561&amp;amp;chksm=977462b0a003eba6033f0d431c869ef7528ade38343f0d001cb0bc8c6fd1bd726dac63af0f8c#rd&quot;&gt;Options模式[4]: Options模型详解[下篇]&lt;/a&gt;&lt;br/&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484326&amp;amp;idx=1&amp;amp;sn=cd24daee887b46ac199a860fb83763e7&amp;amp;chksm=977462b7a003eba1919e86169b015fdffd893ab5d82341f1c4bd9811e402d1f3aae674d5c362#rd&quot;&gt;Options模式[5]: 依赖注入&lt;/a&gt;&lt;br/&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484330&amp;amp;idx=1&amp;amp;sn=88e2868bdeb5db1714b00ccf96d42048&amp;amp;chksm=977462bba003ebadeaf11aaf0ef2a58399acb21ab9543e45bf678559ac8a7df612ac13bf9e2b#rd&quot;&gt;Options模式[6]: 扩展与定制&lt;/a&gt;&lt;br/&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484334&amp;amp;idx=1&amp;amp;sn=cda02dbfe40f6772902a219e2669f0cc&amp;amp;chksm=977462bfa003eba98dc88de7cad6272b8b3410e0369c9269dc602a8f7ddd8f2c0fb5e3f65407#rd&quot;&gt;Options模式[7]: 与配置系统的整合&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;7. 诊断日志&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484343&amp;amp;idx=1&amp;amp;sn=85708a4894834835977340c1afc525bd&amp;amp;chksm=977462a6a003ebb0019baf13bc9e71cd66583c56d76a77603b07ac4443c077b9ea03d3ffbcc9#rd&quot;&gt;诊断日志[1]: 各种诊断日志编程体验[上篇]&lt;/a&gt;&lt;br/&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484352&amp;amp;idx=1&amp;amp;sn=19b5595ffddfeccb24b10abf4fd4728f&amp;amp;chksm=977462d1a003ebc7b04b44f816fbb18fbce121412cef26c3f52db020fccee6b5c9b6206ce473#rd&quot;&gt;诊断日志[2]: 各种诊断日志编程体验[下篇]&lt;/a&gt;&lt;br/&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484358&amp;amp;idx=1&amp;amp;sn=e066b3f54c2aabf632d9b2b8f1ecbd31&amp;amp;chksm=977462d7a003ebc11748a5ed65e7b47ba3f60ea63767c82a4bc689dcc9fce298c8a162752e54#rd&quot;&gt;诊断日志[3]: 针对Debugger的调试日志&lt;/a&gt;&lt;br/&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484364&amp;amp;idx=1&amp;amp;sn=ef147306fa20c6d4c591c9df53b073bf&amp;amp;chksm=977462dda003ebcb2c50d4ad6dcc8ab950b68e023baefa87735704b907de09347a0fd064d54c#rd&quot;&gt;诊断日志[4]: 针对TraceSource的跟踪日志[上篇]&lt;/a&gt;&lt;br/&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484372&amp;amp;idx=1&amp;amp;sn=be1f4a5f60ea2c9aede9c7da03065a8e&amp;amp;chksm=977462c5a003ebd34e410458580a660c7a8d395831fb38c10e33641972f24c7471371551f83c#rd&quot;&gt;诊断日志[5]: 针对TraceSource的跟踪日志[下篇]&lt;/a&gt;&lt;br/&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484376&amp;amp;idx=1&amp;amp;sn=0b3bb10cc38bd572f43ec2615edc001d&amp;amp;chksm=977462c9a003ebdf30e82e5e1f859e6613a983883aea1dac1b256d62f2ae3ba1beb8b86271ef#rd&quot;&gt;诊断日志[6]: 针对EventSource的事件日志[上篇]&lt;/a&gt;&lt;br/&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484382&amp;amp;idx=1&amp;amp;sn=0d5b38245a0015bfd9a551f49dadecde&amp;amp;chksm=977462cfa003ebd9d6b42fe2fbef4312a48325c70bb9d74961d2635aaff853bd63f80e5e2e82#rd&quot;&gt;诊断日志[7]: 针对EventSource的事件日志[中篇]&lt;/a&gt;&lt;br/&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484389&amp;amp;idx=1&amp;amp;sn=0801529f810b156ce9fcf41aef16845f&amp;amp;chksm=977462f4a003ebe20b317b84a523dd7d6aaaf99ec81d10be14cbae3b5db7235099ceb3dd5584#rd&quot;&gt;诊断日志[8]: 针对EventSource的事件日志[下篇]&lt;/a&gt;&lt;br/&gt;   &lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwOTM1MjgzMA==&amp;amp;mid=2247484395&amp;amp;idx=1&amp;amp;sn=0da1bfa6a35ac3377ca503e6e436a381&amp;amp;chksm=977462faa003ebec8bee08f5cc43d76e7162bde9d7bfc0704b1236273bcfb8d5f8cb206bf2dd#rd&quot;&gt;诊断日志[9]: 针对EventSource的事件日志[补充]&lt;/a&gt;&lt;br/&gt;   诊断日志[10]: 针对DiagnosticSource的诊断日志[上篇]&lt;br/&gt;   诊断日志[11]: 针对DiagnosticSource的诊断日志[中篇]&lt;br/&gt;   诊断日志[12]: 针对DiagnosticSource的诊断日志[下篇]&lt;/p&gt;



</description>
<pubDate>Sun, 14 Oct 2018 22:52:00 +0000</pubDate>
<dc:creator>Artech</dc:creator>
<og:description>之前一段时间都在个人公众号账号“大内老A”发布关于ASP.NET Core的系列文章，很多人留言希望能够同步到这里，所以在这里 对这些文章做一个汇总，以便于PC端阅读。如果说微软官方文档主要关于ASP</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/artech/p/inside-asp-net-core.html</dc:identifier>
</item>
<item>
<title>Linux 桌面玩家指南：08. 使用 GCC 和 GNU Binutils 编写能在 x86 实模式运行的 16 位代码 - 京山游侠</title>
<link>http://www.cnblogs.com/youxia/p/LinuxDesktop008.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/youxia/p/LinuxDesktop008.html</guid>
<description>&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;strong&gt;特别说明：&lt;/strong&gt;要在我的随笔后写评论的小伙伴们请注意了，我的博客开启了 MathJax 数学公式支持，MathJax 使用&lt;code&gt;$&lt;/code&gt;标记数学公式的开始和结束。如果某条评论中出现了两个&lt;code&gt;$&lt;/code&gt;，MathJax 会将两个&lt;code&gt;$&lt;/code&gt;之间的内容按照数学公式进行排版，从而导致评论区格式混乱。如果大家的评论中用到了&lt;code&gt;$&lt;/code&gt;，但是又不是为了使用数学公式，就请使用&lt;code&gt;\$&lt;/code&gt;转义一下，谢谢。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;想从头阅读该系列吗？下面是传送门：&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;这是一个非常复古的话题，希望能够吸引到你们。x86 实模式、16 位的代码、汇编语言，这些古老的东西还有谁会关注呢？只能是浪漫的程序员。网上传说，程序员有三大浪漫：操作系统、编译原理和计算机图形学。在如此浪漫情怀的支持下，我也曾尝试写一个自己的操作系统。后来呢？当然是从入门到放弃啦。不过在 x86 实模式下编写 16 位的引导扇区，仍然给我留下了深刻的记忆。而且，在自己写操作系统的过程中，我一直强烈希望能早一点脱离汇编语言，早一点进入 C 语言的世界。因此，有了这篇随笔。不可否认，这次的标题有点长。之所以把标题写得这么详细，主要是为了搜索引擎能够准确地把确实需要了解 GCC 生成 16 位实模式代码方法的朋友带到我的博客。&lt;/p&gt;
&lt;p&gt;要运行 x86 实模式的程序，目前我知道的只有两种方式，一种是使用 DOS 系统，另一种是把它写成引导扇区的代码，在系统启动时直接运行。很显然，许多讲自己实现操作系统的书籍都会讲到 x86 实模式，也只有自己实现操作系统引导的朋友需要用到 x86 实模式，所以我这篇随笔的阅读用户数肯定很少，虽然我自认为它填补了网上关于该话题相关资料缺乏的空白。因此，凡是逛到我这篇文章的朋友，请点一下推荐，谢谢。&lt;/p&gt;
&lt;p&gt;为什么说我这篇博客填补了相关话题的空白呢？那是因为不管是那些写书的，还是网上写文章的，一旦需要编写 16 位的实模式代码，都喜欢拿 NASM 说事儿，一点也不顾 GNU AS 的感受。当然，这是有历史原因的，因为 Linux 自从其诞生起就是 32 位，就是多用户多任务操作系统，所以 GCC 和 Gnu AS 一移植到 Linux 上就是用来编写 32 位保护模式的代码的。而且，ELF 可执行文件格式也只有 ELF32 和 ELF64，没听说过有 ELF16 的。即使是 Linux 自己，刚诞生的时候（1991年），也只有使用 as86 汇编器来编写自己的 16 位启动代码，直到 1995 年以后，GNU AS 才逐步加入编写 16 位代码的能力。&lt;/p&gt;
&lt;p&gt;按照惯例，我当然是要给大家安利参考资料的啦。首先，是 &lt;a href=&quot;https://www.gnu.org/software/gnu-c-manual/gnu-c-manual.pdf&quot;&gt;GNU C 语言手册&lt;/a&gt;，C 语言是 Linux 操作系统的母语，也是我接触计算机后学习的第一门语言，所以是有非常深厚的感情的。而且，C 语言非常简洁。还记得我前面给大家推荐的 Bash 手册吗？我说它只有 171 页，算是非常简短的了。我这里给大家推荐的 &lt;a href=&quot;https://www.gnu.org/software/gnu-c-manual/gnu-c-manual.pdf&quot;&gt;GNU C 语言手册&lt;/a&gt;，加上封面、目录和索引，总共也才 91 页。有 PDF 版本，下载到手机上慢慢看吧。其次，是 AT&amp;amp;T 汇编语言的资料，以及 Binutils 的资料，这个只能上 &lt;a href=&quot;https://www.gnu.org/software/binutils/&quot;&gt;Gnu Binutils 官网&lt;/a&gt; 上看它的官方文档了，而且没有 PDF 版，没有那种从头读到尾的畅快感。最后，我送大家一本 &lt;a href=&quot;https://files.cnblogs.com/files/youxia/professionalassemblylanguage.pdf&quot;&gt;Professional Assembly Language&lt;/a&gt; 和一本 &lt;a href=&quot;https://files.cnblogs.com/files/youxia/ProgrammingGroundUp-1-0-booksize.pdf&quot;&gt;Programming from the ground up&lt;/a&gt;，希望大家学得愉快。&lt;/p&gt;
&lt;h2 id=&quot;gcc-和-gnu-binutils-的-16-位代码之旅&quot;&gt;GCC 和 GNU Binutils 的 16 位代码之旅&lt;/h2&gt;
&lt;p&gt;我决定使用 DOS 作为我的测试环境，所以最后生成的可执行文件都把它制作成 DOS 系统中可运行的 Plain Binary 格式。第一步安装一个 Qemu 虚拟机来运行 FreeDOS，安装虚拟机在 Ubuntu 中只需要一个 &lt;code&gt;sudo aptitude install qemu&lt;/code&gt; 命令就可以完成，所以我就不截图了。但是 FreeDOS 的软盘镜像文件需要到 Qemu 的官网上面去下载，下载地址如下图：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241249183784711.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;使用 &lt;code&gt;qemu-system-i386 -fda freedos.img&lt;/code&gt; 可以运行 Qemu 虚拟机和 FreeDOS 系统，如下图：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241254186742622.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;因为汇编语言更接近底层，而 C 语言更高级，所以先从汇编语言开始，逐步过渡到 C 语言。先写一个简单的、能在 DOS 中显示一个“Hello，world!”的汇编语言程序，考虑到我之后会使用该程序调用 C 语言的 &lt;code&gt;main&lt;/code&gt; 函数，并且该程序负责让程序运行结束后顺利返回 DOS 系统，所以我把这个程序命名为 &lt;code&gt;test_code16_startup.s&lt;/code&gt;。其代码如下：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241253258317309.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面对以上代码进行简单解释：&lt;/p&gt;
&lt;p&gt;1、GNU AS 汇编器使用的汇编语言采用的是 AT&amp;amp;T 语法，该语法和 Intel 语法不同。我更喜欢 AT&amp;amp;T 的语法，原因有两个，一是 AT&amp;amp;T 语法是 Linux 世界中通用的标准，二是 AT&amp;amp;T 语法在某些概念方面确实理解起来更简单（比如内存寻址模式）。有汇编语言基础的人，AT&amp;amp;T 语法学起来也很快，主要有以下几条：①汇编指令后面跟有操作数长度的后缀，比如 &lt;code&gt;mov&lt;/code&gt; 指令，如果操作数是 8 位，则用 &lt;code&gt;movb&lt;/code&gt;，如果操作数是 16 位，则用 &lt;code&gt;movw&lt;/code&gt;，如果操作数是 32 位，则用 &lt;code&gt;movl&lt;/code&gt;，如果操作数是 64 位，则用 &lt;code&gt;movq&lt;/code&gt;，其余指令依此类推；②操作数的顺序是源操作数在前，目标操作数在后，比如 &lt;code&gt;movw %cs, %ax&lt;/code&gt; 表示把 cs 寄存器中的数据移动到 ax 寄存器中，这个顺序和 Intel 汇编语法正好相反；③所有的寄存器使用 % 前缀，如 &lt;code&gt;%ax&lt;/code&gt;, &lt;code&gt;%di&lt;/code&gt;, &lt;code&gt;%esp&lt;/code&gt; 等；④对于立即数，需要使用 \$ 前缀，比如 &lt;code&gt;$4&lt;/code&gt;, &lt;code&gt;$0x0c&lt;/code&gt;，而且如果一个数字是以 0 开头，则是 8 进制，以其它数字开头，是 10 进制，以 0x 开头则是 16 进制，标号当立即数使用时，需要 \$ 前缀，比如上面的 &lt;code&gt;pushw $message&lt;/code&gt;，而标号当函数名使用时，不需要 \$ 前缀，比如上面的 &lt;code&gt;callw display_str&lt;/code&gt;；⑤内存寻址方式，众所周知，x86 寻址方式众多，什么直接寻址、间接寻址、基址寻址、基址变址寻址等等让人眼花缭乱，而 AT&amp;amp;T 语法对内存寻址方式做了一个很好的统一，其格式为 &lt;code&gt;section:displacement(base, index, scale)&lt;/code&gt;，其中 section 是段地址，displacement 是位移，base 是基址寄存器，index 是索引，scale 是缩放因子，其计算方式为&lt;code&gt;线性地址=section + displacement + base + index*scale&lt;/code&gt;，最重要的是，可以省略以上格式中的一个或多个部分，比如 &lt;code&gt;movw 4, %ax&lt;/code&gt; 就是把内存地址 4 中的值移动到 ax 寄存器中，&lt;code&gt;movw 4(%esp), %ax&lt;/code&gt; 就是把 esp+4 指向的地址中的值移动到 ax 寄存器中，依此类推。我上面的介绍是不是全网络最简明的 AT&amp;amp;T 汇编语法教程？&lt;/p&gt;
&lt;p&gt;2、在以上代码中我全部使用的都是 16 位的指令，如 &lt;code&gt;movw&lt;/code&gt;、&lt;code&gt;pushw&lt;/code&gt;、&lt;code&gt;callw&lt;/code&gt; 等，并且直接在代码中定义了字符串&lt;code&gt;&quot;Hello, world!&quot;&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;3、在以上代码中使用了函数 &lt;code&gt;display_str&lt;/code&gt;，在调用 &lt;code&gt;display_str&lt;/code&gt; 之前，我使用 &lt;code&gt;pushw $15&lt;/code&gt; 和 &lt;code&gt;pushw $message&lt;/code&gt; 将参数从右向左依次压栈，然后使用 &lt;code&gt;callw&lt;/code&gt; 指令调用函数，这和 C 语言的函数调用约定是一样的。调用 &lt;code&gt;callw&lt;/code&gt; 指令会自动将 &lt;code&gt;%ip&lt;/code&gt; 寄存器压栈，而在函数开始时，我又用 &lt;code&gt;pushw %bp&lt;/code&gt; 将 &lt;code&gt;%bp&lt;/code&gt; 寄存器压栈，所以 &lt;code&gt;%esp&lt;/code&gt; 又向下移动了 4 个字节，所以在函数中使用 &lt;code&gt;0x4(%esp)&lt;/code&gt; 和 &lt;code&gt;0x6(%esp)&lt;/code&gt; 可以访问到这两个参数。在 32 位代码中，由于调用函数时压栈的是 &lt;code&gt;%eip&lt;/code&gt; 和 &lt;code&gt;%ebp&lt;/code&gt;，所以需要使用 &lt;code&gt;0x8(%esp)&lt;/code&gt; 和 &lt;code&gt;0xc(%esp)&lt;/code&gt; 来依次访问压栈的参数。关于汇编语言函数调用的细节，可以参考 &lt;a href=&quot;(https://files.cnblogs.com/files/youxia/ProgrammingGroundUp-1-0-booksize.pdf)&quot;&gt;《Programming from the ground up》&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;4、以上代码使用 BIOS 中断 &lt;code&gt;int 0x10&lt;/code&gt; 来输出字符串，使用 DOS 中断 &lt;code&gt;int 0x21&lt;/code&gt; 来返回 DOS 系统。&lt;/p&gt;
&lt;p&gt;5、最重要的是，需要使用 &lt;code&gt;.code16&lt;/code&gt; 指令让汇编器将程序汇编成 16 位的代码。&lt;/p&gt;
&lt;p&gt;代码完成后，使用下面一串命令就可以把它进行汇编、链接，然后转换成 DOS 下的纯二进制格式（Plain Binary），最后复制到 FreeDOS.img 中，使用 Qemu 虚拟机执行 FreeDOS，然后运行该 16 位实模式程序。这一串命令及其运行效果如下图：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241342463781040.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这些命令中比较重要的选项我都特意标出来了。由于我用的是 64 位的环境，所以调用 &lt;code&gt;as&lt;/code&gt; 命令的时候需要指定 &lt;code&gt;--32&lt;/code&gt; 选项，调用 &lt;code&gt;ld&lt;/code&gt; 命令的时候需要指定 &lt;code&gt;-m elf_i386&lt;/code&gt; 选项。指定以上选项后，生成的是 32 位的 ELF 目标文件，否则默认会生成 64 位的 ELF 目标文件，如果目标文件是 64 位，以后和 C 语言生成的目标文件连接时会出问题。使用 32 位环境的朋友们不用特意指定这两个选项。由于 DOS 系统总是把 Plain Binary 文件载入到 0x100 地址处执行，所以调用 &lt;code&gt;ld&lt;/code&gt; 命令时，需要指定 &lt;code&gt;-Ttext 0x100&lt;/code&gt; 选项。&lt;code&gt;ld&lt;/code&gt; 命令执行完成后，生成的是 ELF 格式的可执行文件 &lt;code&gt;test.elf&lt;/code&gt;，最后需要调用 &lt;code&gt;objcopy&lt;/code&gt; 生成纯二进制文件，&lt;code&gt;-j .text&lt;/code&gt; 选项的意思是只需要代码段，因为我把&lt;code&gt;&quot;Hello, world!&quot;&lt;/code&gt;也是定义在代码段中的，&lt;code&gt;-O binary&lt;/code&gt; 选项指定输出格式为纯二进制文件，输出文件为 &lt;code&gt;test.com&lt;/code&gt;。最后，将 &lt;code&gt;freedos.img&lt;/code&gt; 镜像文件 &lt;code&gt;mount&lt;/code&gt; 到 Ubuntu 中，将 &lt;code&gt;test.com&lt;/code&gt; 拷贝到其中，然后 &lt;code&gt;umount&lt;/code&gt;，然后运行虚拟机，在 DOS 中运行 &lt;code&gt;test&lt;/code&gt;，就可以看到效果了。&lt;/p&gt;
&lt;p&gt;除了 &lt;code&gt;as&lt;/code&gt; 和 &lt;code&gt;ld&lt;/code&gt;，GNU Binutils 中的其它程序也是写程序和分析程序时的好帮手。可以使用 &lt;code&gt;readelf -S&lt;/code&gt; 查看 &lt;code&gt;test.elf&lt;/code&gt; 文件中的所有段，也可以使用 &lt;code&gt;objdump -s&lt;/code&gt; 命令将 &lt;code&gt;test.elf&lt;/code&gt; 中的数据以 16 进制形式输入，如下图：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241359046744683.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当然，也可以使用 &lt;code&gt;objdump -d&lt;/code&gt; 或者 &lt;code&gt;objdump -D&lt;/code&gt; 将程序进行反汇编，查看是否真正生成了 16 位代码，如下图：（反汇编时一定要指定 &lt;code&gt;-m i8086&lt;/code&gt; 选项）&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241400500181333.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;也可以对纯二进制格式的文件进行反汇编，必须指定 &lt;code&gt;-b binary&lt;/code&gt; 选项，如下图，对 &lt;code&gt;test.com&lt;/code&gt; 进行反汇编：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241402537997382.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;反汇编时，一定要指定 &lt;code&gt;-m i8086&lt;/code&gt; 选项，否则 &lt;code&gt;objdump&lt;/code&gt; 不知道反汇编的是 16 位代码。（前面提到过 Linux 从诞生起就是 32 位，所以 ELF 只有 32 位和 64 位两种，没有 16 位的ELF格式。）如下图，如果使用 &lt;code&gt;-m i386&lt;/code&gt; 选项进行反汇编，反汇编结果将不知所云：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241405535038114.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面进入 C 语言的世界。为了搞清楚 C 语言生成的 16 位代码的汇编指令有哪些特别之处，先写一个简单的 C 语言程序进行调研，如下图：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241426053312502.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;该程序有以下特点：&lt;/p&gt;
&lt;p&gt;1、程序的开头使用了 &lt;code&gt;__asm__(&quot;.code16\n&quot;)&lt;/code&gt; 嵌入汇编指令，以指示 &lt;code&gt;as&lt;/code&gt; 生成 16 位代码；&lt;/p&gt;
&lt;p&gt;2、&lt;code&gt;display_str&lt;/code&gt; 函数的签名和之前汇编语言中的相同，可以使用它来观察 C 语言生成的代码如何传递参数。&lt;/p&gt;
&lt;p&gt;使用下面的命令对程序进行编译和反汇编，如下图：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241429264241838.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从上图可以看出，C 语言生成的代码虽然是 16 位，但是它有如下特点：①从生成的 &lt;code&gt;display_str&lt;/code&gt; 函数中可以看出，函数一开始是 &lt;code&gt;push %ebp&lt;/code&gt;，而不是 &lt;code&gt;push %bp&lt;/code&gt;；②在 &lt;code&gt;display_str&lt;/code&gt; 函数中获取参数的位置分别为 &lt;code&gt;0x8(%ebp)&lt;/code&gt; 和 &lt;code&gt;0xc(%ebp)&lt;/code&gt;，而不是我在汇编语言中写的 &lt;code&gt;0x4(%ebp)&lt;/code&gt; 和 &lt;code&gt;0x6(%ebp)&lt;/code&gt;；③从生成的 &lt;code&gt;main&lt;/code&gt; 函数可以看出，调用 &lt;code&gt;diaplay_str&lt;/code&gt; 之前，没有使用 &lt;code&gt;push&lt;/code&gt; 命令把参数压栈，而是直接通过 &lt;code&gt;sub $0x18, %esp&lt;/code&gt; 调整 &lt;code&gt;%esp&lt;/code&gt; 的位置，然后使用 &lt;code&gt;mov&lt;/code&gt; 指令将参数放到指定位置，和使用 &lt;code&gt;push&lt;/code&gt; 指令的效果相同；④虽然我在 &lt;code&gt;display_str&lt;/code&gt; 函数的定义中故意将长度参数定义为 &lt;code&gt;short&lt;/code&gt;，但是从生成的代码中可以看到依然是每隔 4 个字节放一个参数。&lt;/p&gt;
&lt;p&gt;另外需要说明的是，调用 &lt;code&gt;gcc&lt;/code&gt; 时除了指定 &lt;code&gt;-c&lt;/code&gt; 选项指示它只编译不连接外，还要指定 &lt;code&gt;-m32&lt;/code&gt; 选项，这样才会生成 32 位的汇编代码，而只有在 32 位的汇编代码中使用 &lt;code&gt;.code16&lt;/code&gt; 指令，才能编译成 16 位的机器码。如果没有指定 &lt;code&gt;-m32&lt;/code&gt; 选项，则生成的是 64 位汇编代码，然后汇编时会出错。使用 -m32 选项后，生成的目标文件是 ELF32 格式。ELF32 格式的目标文件只能和 ELF32 格式的目标文件连接，这也是为什么前面的 &lt;code&gt;as&lt;/code&gt; 和 &lt;code&gt;ld&lt;/code&gt; 需要指定 &lt;code&gt;--32&lt;/code&gt; 和 &lt;code&gt;-m elf_i386&lt;/code&gt; 选项的原因。&lt;/p&gt;
&lt;p&gt;通过以上分析，似乎可以得出以下结论：只需要将汇编代码中的 &lt;code&gt;pushw %bp&lt;/code&gt; 更改为 &lt;code&gt;pushl %ebp&lt;/code&gt;，然后将获取参数的位置调整为 &lt;code&gt;0x8(%ebp)&lt;/code&gt; 和 &lt;code&gt;0xc(%ebp)&lt;/code&gt;，就可以从 C 语言里面成功调用到汇编语言中的函数了。而事实上，还有一点点小差距。从上面的反汇编代码中可以看到，函数调用时使用的是 16 位的 &lt;code&gt;call&lt;/code&gt; 指令，该指令压栈的是 &lt;code&gt;%ip&lt;/code&gt;，而不是 &lt;code&gt;%eip&lt;/code&gt;，而 C 语言生成的函数框架中获取的参数位置是按照将 &lt;code&gt;%eip&lt;/code&gt; 压栈计算出来的，它们之间差了两个字节。&lt;/p&gt;
&lt;p&gt;为了证明我以上判断的准确性，我将上面的C语言程序和汇编程序修改后，编译连接成一个完整的程序，看看它究竟能否正确运行。&lt;/p&gt;
&lt;p&gt;C 语言程序修改很简单，就是去掉了 display_str 函数的实现，只保留声明。如下图：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241448101121330.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;汇编语言的更改包含以下几个地方：将 &lt;code&gt;display_str&lt;/code&gt; 函数导出，将 &lt;code&gt;pushw %bp&lt;/code&gt; 改为 &lt;code&gt;pushl %ebp&lt;/code&gt;，同时修改获取参数的位置。如下图：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241449122848290.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;编译、连接、运行程序的指令如下：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241451148463868.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看到&lt;code&gt;&quot;Hello world from C language.&quot;&lt;/code&gt;没有正确显示出来。上面的命令都是前面用过的，不需要多解释，唯一不同的是使用 C 语言写的程序多了一个 &lt;code&gt;.rodata&lt;/code&gt; 段，所以在 &lt;code&gt;objcopy&lt;/code&gt; 的时候需要把这个段也包含进来。&lt;/p&gt;
&lt;p&gt;由于 Ｃ 语言生成的函数框架都是从 &lt;code&gt;0x8(%ebp)&lt;/code&gt; 开始取参数，它认为 &lt;code&gt;0x0(%ebp)&lt;/code&gt; 是 old ebp，&lt;code&gt;0x4(%ebp)&lt;/code&gt;是 &lt;code&gt;%eip&lt;/code&gt;，而事实上使用 16 位的 &lt;code&gt;call&lt;/code&gt; 指令调用函数后，&lt;code&gt;0x4(%ebp)&lt;/code&gt; 中是 &lt;code&gt;%ip&lt;/code&gt; 而不是 &lt;code&gt;%eip&lt;/code&gt;，所以要从 &lt;code&gt;0x6(%ebp)&lt;/code&gt; 开始取参数。我们不可能修改 C 语言生成的函数框架，只能看看能否将 16 位的 &lt;code&gt;call&lt;/code&gt; 改成 32 位的 &lt;code&gt;call&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;办法当然是有的，那就是不使用 &lt;code&gt;.code16&lt;/code&gt;，而使用 &lt;code&gt;.code16gcc&lt;/code&gt;。&lt;code&gt;.code16gcc&lt;/code&gt; 和 &lt;code&gt;.code16&lt;/code&gt; 不同的地方就在于它生成的汇编代码在使用到 &lt;code&gt;call&lt;/code&gt;、&lt;code&gt;ret&lt;/code&gt;、&lt;code&gt;jump&lt;/code&gt; 等指令时，都生成 32 位的机器码，相当于 &lt;code&gt;calll&lt;/code&gt;，&lt;code&gt;retl&lt;/code&gt;，&lt;code&gt;jumpl&lt;/code&gt;。这也是 &lt;code&gt;.code16gcc&lt;/code&gt; 叫 &lt;code&gt;.code16gcc&lt;/code&gt; 的原因，因为它就是配合 GCC 生成的函数框架使用的。&lt;/p&gt;
&lt;p&gt;下面再来修改代码，C 语言代码修改很简单，只需要将 &lt;code&gt;.code16&lt;/code&gt; 改成 &lt;code&gt;.code16gcc&lt;/code&gt; 即可，如下图：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241502074872253.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通过反汇编，可以看到它使用了 32 位的 calll 和 retl，如下图：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241503143786287.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;汇编程序的修改主要是将 .code16 改为 .code16gcc，然后手动将 callw 改成 calll，将 retw 改成 retl，如下图：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241504336127661.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;最后，编译连接，拷贝到 freedos.img，运行虚拟机，查看运行效果，如下图：&lt;br/&gt;&lt;img src=&quot;https://images0.cnblogs.com/blog/16576/201408/241505305968704.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;大功告成。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;编写运行于 x86 实模式下的 16 位代码是一个很复古的话题，编写能在 DOS 下运行的 Plain Binary 可执行文件是一个更复古的话题。以往，凡是需要使用 x86 的 16 位实模式的时候，作者都喜欢用 NASM 来编程。比如《30天自制操作系统》、《Orange's 一个操作系统的实现》、《x86汇编语言——从实模式到保护模式》等书籍都以 NASM 汇编器和 Intel 汇编语法作为示例。而且他们都是在进入 32 位保护模式后，才让汇编语言和 C 语言共同工作。&lt;/p&gt;
&lt;p&gt;我用 Linux 操作系统，所以我就是想不管是写 32 位代码，还是 16 位代码，都能使用 GCC 和 GNU AS。我还想即使是在 16 位模式下，也能尽量少用汇编语言，多用 C 语言。经过努力，有了上面的文章。使用 GCC 和 GNU Binutils 编写运行于 x86 实模式的 16 位代码的过程如下：&lt;/p&gt;
&lt;p&gt;1、如果只用汇编语言编写 16 位程序，请使用 &lt;code&gt;.code16&lt;/code&gt; 指令，并保证只使用 16 位的指令和寄存器；如果要和 C 语言一起工作，请使用 &lt;code&gt;.code16gcc&lt;/code&gt; 指令，并且在函数框架中使用 &lt;code&gt;pushl&lt;/code&gt;，&lt;code&gt;calll&lt;/code&gt;，&lt;code&gt;retl&lt;/code&gt;，&lt;code&gt;leavel&lt;/code&gt;，&lt;code&gt;jmpl&lt;/code&gt;，使用 &lt;code&gt;0x8(%ebp)&lt;/code&gt; 开始访问函数的参数；很显然，使用 C 语言和汇编语言混编的程序可以在实模式下运行，但是不能在 286 之前的真实 CPU 上运行，因为 286 之前的 CPU 还没有 &lt;code&gt;pushl&lt;/code&gt;、&lt;code&gt;calll&lt;/code&gt;、&lt;code&gt;retl&lt;/code&gt;、&lt;code&gt;leavel&lt;/code&gt;、&lt;code&gt;jmpl&lt;/code&gt; 等指令。&lt;/p&gt;
&lt;p&gt;2、使用 &lt;code&gt;as&lt;/code&gt; 时，请指定 &lt;code&gt;--32&lt;/code&gt; 选项，使用 &lt;code&gt;gcc&lt;/code&gt; 时，请指定 &lt;code&gt;-m32&lt;/code&gt; 选项，使用 &lt;code&gt;ld&lt;/code&gt; 时，请指定 &lt;code&gt;-m elf_i386&lt;/code&gt; 选项。如果是反汇编 16 位代码，在使用 &lt;code&gt;objdump&lt;/code&gt; 时，请使用 &lt;code&gt;-m i8086&lt;/code&gt; 选项。&lt;/p&gt;
&lt;p&gt;3、在 DOS 中运行的 .com 文件会被加载到 0x100 处执行，所以使用 &lt;code&gt;ld&lt;/code&gt; 连接时需指定 &lt;code&gt;-Ttext 0x100&lt;/code&gt; 选项；引导扇区的代码会被加载到 0x7c00 处执行，所以使用 &lt;code&gt;ld&lt;/code&gt; 连接时需指定 &lt;code&gt;-Ttext 0x7c00&lt;/code&gt; 选项。&lt;/p&gt;
&lt;p&gt;4、使用 &lt;code&gt;gcc&lt;/code&gt;、&lt;code&gt;as&lt;/code&gt;、&lt;code&gt;ld&lt;/code&gt; 生成的程序默认都是 ELF 格式，而在 DOS 下运行的 .com 程序是 Plain Binary 的，在引导扇区运行的代码也是 Plain Binary 的，所以需要使用 &lt;code&gt;objcopy&lt;/code&gt; 将 ELF 文件中的代码段和数据段拷贝到一个 Plain Binary 文件中，使用 &lt;code&gt;-O binary&lt;/code&gt; 选项； Plain Binary 文件也可以反汇编，在使用 &lt;code&gt;objdump&lt;/code&gt; 时需指定 &lt;code&gt;-b binary&lt;/code&gt; 选项。&lt;/p&gt;
&lt;h2 id=&quot;求打赏&quot;&gt;求打赏&lt;/h2&gt;
&lt;p&gt;我对这次写的这个系列要求是非常高的：首先内容要有意义、够充实，信息量要足够丰富；其次是每一个知识点要讲透彻，不能模棱两可含糊不清；最后是包含丰富的截图，让那些不想装 Linux 系统的朋友们也可以领略到 Linux 桌面的风采。如果我的努力得到大家的认可，可以扫下面的二维码打赏一下：&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/16576/201808/16576-20180831154735325-1276475036.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;版权申明&quot;&gt;版权申明&lt;/h2&gt;
&lt;p&gt;该随笔由京山游侠在2018年10月14日发布于博客园，引用请注明出处，转载或出版请联系博主。QQ邮箱：1841079@qq.com&lt;/p&gt;
</description>
<pubDate>Sun, 14 Oct 2018 22:25:00 +0000</pubDate>
<dc:creator>京山游侠</dc:creator>
<og:description>特别说明： 要在我的随笔后写评论的小伙伴们请注意了，我的博客开启了 MathJax 数学公式支持，MathJax 使用 标记数学公式的开始和结束。如果某条评论中出现了两个 ，MathJax 会将两个</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/youxia/p/LinuxDesktop008.html</dc:identifier>
</item>
<item>
<title>用 C# 编写 C# 编译器，先有鸡还是先有蛋？ - Liam Wang</title>
<link>http://www.cnblogs.com/willick/p/csharp-roslyn-chicken-egg-problem.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/willick/p/csharp-roslyn-chicken-egg-problem.html</guid>
<description>&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/191097/201810/191097-20181014235946250-639748090.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;div readability=&quot;47.104091888011&quot;&gt;
&lt;p&gt;&lt;span&gt;前段时间翻译了一篇文章&lt;/span&gt; &lt;a href=&quot;https://mp.weixin.qq.com/s/dYRMMWF5Jqfdul8piqFpAA&quot;&gt;微软是如何重写 C# 编译器并使它开源的&lt;/a&gt;&lt;span&gt;，文章讲了微软用 C# 重写 C# 编译器的坎坷路，引发了一些童鞋的思考：用 C# 编写 C# 编译器（Roslyn），那么 C# 编译器本身是由谁来编译的？C# 语言编写了 C# 编译器，而 C# 语言又是由 C# 编译器编译的，这不就是先有鸡还是先有蛋的问题吗？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;虽然（博客园）文章下方评论中提出这类问题的人不多（注：除了公众号，我的技术文章一般也会隔天在博客园发布），但我相信有这类疑问的人肯定不少。这个问题提得很好，会产生这个疑问说明你是个善于思考的人，有思辨能力；如果你又恰好看到了我这篇文章，得到了你要的答案，那么这就是我写文章的意义。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;看到童鞋们的评论，我并没有立即回复，因为这个问题确实不好回答。但作为 .NET 忠实的布道老者（请允许我装逼一回），我还是觉得有必要给大家解释一下。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先，编译器 Roslyn 确实是自己编译自己，它的每个版本都是由该版本的上一个版本来编译的。那么 Roslyn 最初的第一个版本是由什么来编译的呢？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这里就要提到了个计算机科学中的一个概念：&lt;span&gt;Bootstrapping&lt;/span&gt; Compiler，中文叫&lt;span&gt;自举&lt;/span&gt;编译器。它的目的是实现自己编译自己。编译器为了达到自己编译自己的目的，它第一个版本必须由其它编程语言来实现，而它的第一个版本通常是非常简单和基础的版本。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;很多编程语言发展成熟后都会用该语言本身来编写自己的编译器，比如 C# 和 Go 语言。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;C# 编译器 Roslyn 的第一个版本是由其它语言来编译的。具体是什么语言我不确定，我觉得应该是用 C++ 写的（因为老的 C# 编译器用的是 C++），我还没查到，如果你知道，麻烦留言告诉我。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如果 Roslyn 的第一个版本是由 C++ 来编写的，那么 C++ 编译器的第一个版本又是由什么来编写的呢？如果不是 C 语言那很可能就是直接用机器语言来编写的了，机器语言是操作系统可以直接运行的指令，自然不需要编译器来翻译。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;所以，但凡自举编译器是由高级语言来编写的，它的第一个版本一定是由其它语言来编写的，追溯它最初的祖先，一定是用机器语言来编写的。&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;2018-10-14 续&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;关于 C# 编译器 Roslyn 的第一个版本是用什么编译的，我在 Medium 留言问了 C# 语言负责人 Mads Torgersen：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://i.imgur.com/1ygnZWH.jpg&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;他的回答是：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://i.imgur.com/8CpXQIK.jpg&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;至此，文中的怀疑得到了确认。也就是说 Roslyn 最初的第一版是用老的 C# 编译器编译的（老的编译器是用 C++ 编写的），之后都是用 Roslyn 自己编译的。&lt;/span&gt;&lt;/p&gt;

&lt;/div&gt;
</description>
<pubDate>Sun, 14 Oct 2018 16:18:00 +0000</pubDate>
<dc:creator>Liam Wang</dc:creator>
<og:description>前段时间翻译了一篇文章 微软是如何重写 C# 编译器并使它开源的，文章讲了微软用 C# 重写 C# 编译器的坎坷路，引发了一些童鞋的思考：用 C# 编写 C# 编译器（Roslyn），那么 C# 编译</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/willick/p/csharp-roslyn-chicken-egg-problem.html</dc:identifier>
</item>
<item>
<title>浅析JDK中ServiceLoader的源码 - throwable</title>
<link>http://www.cnblogs.com/throwable/p/9788819.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/throwable/p/9788819.html</guid>
<description>&lt;p&gt;紧接着上一篇《通过源码浅析JDK中的资源加载》，ServiceLoader是SPI(Service Provider Interface)中的服务类加载的核心类，也就是，这篇文章先介绍ServiceLoader的使用方式，再分析它的源码。&lt;/p&gt;

&lt;p&gt;这里先列举一个经典的例子，MySQL的Java驱动就是通过ServiceLoader加载的，先引入&lt;code&gt;mysql-connector-java&lt;/code&gt;的依赖：&lt;/p&gt;
&lt;pre class=&quot;xml&quot;&gt;
&lt;code&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;mysql&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;mysql-connector-java&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;5.1.47&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查看这个依赖的源码包下的META-INF目录，可见：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://pazkqls86.bkt.clouddn.com/r-s-l-1.png&quot; alt=&quot;r-s-l-1&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们接着查看java.lang.DriverManager，静态代码块里面有：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;static {
    loadInitialDrivers();
    println(&quot;JDBC DriverManager initialized&quot;);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中，可以查看&lt;code&gt;loadInitialDrivers()&lt;/code&gt;有如下的代码片段：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://pazkqls86.bkt.clouddn.com/r-s-l-2.png&quot; alt=&quot;r-s-l-2&quot;/&gt;&lt;/p&gt;
&lt;p&gt;java.lang.DriverManager是启动类加载器加载的基础类，但是它可以加载&lt;code&gt;rt.jar&lt;/code&gt;包之外的类，上篇文章提到，这里打破了双亲委派模型，原因是：ServiceLoader中使用了线程上下文类加载器去加载类。这里JDBC加载的过程就是典型的SPI的使用，总结规律如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、需要定义一个接口。&lt;/li&gt;
&lt;li&gt;2、接口提供商需要实现第1步中的接口。&lt;/li&gt;
&lt;li&gt;3、接口提供商在META-INF/services目录下建立一个文本文件，文件名是第1步中定义的接口的全限定类名，文本内容是接口的实现类的全限定类名，每个不同的实现占独立的一行。&lt;/li&gt;
&lt;li&gt;4、使用ServiceLoader加载接口类，获取接口的实现的实例迭代器。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;举个简单的实例，先定义一个接口和两个实现：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public interface Say {

  void say();
}

public class SayBye implements Say {

    @Override
    public void say() {
        System.out.println(&quot;Bye!&quot;);
    }
}

public class SayHello implements Say {

    @Override
    public void say() {
        System.out.println(&quot;Hello!&quot;);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接着在项目的META-INF/services中添加文件如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://pazkqls86.bkt.clouddn.com/r-s-l-3.png&quot; alt=&quot;r-s-l-3&quot;/&gt;&lt;/p&gt;
&lt;p&gt;最后通过main函数验证：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://pazkqls86.bkt.clouddn.com/r-s-l-4.png&quot; alt=&quot;r-s-l-4&quot;/&gt;&lt;/p&gt;
&lt;p&gt;基于SPI或者说ServiceLoader加载接口实现这种方式也可以广泛使用在相对基础的组件中，因为这是一个成熟的规范。&lt;/p&gt;

&lt;p&gt;上面通过一个经典例子和一个实例介绍了ServiceLoader的使用方式，接着我们深入分析ServiceLoader的源码。我们先看ServiceLoader的类签名和属性定义：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public final class ServiceLoader&amp;lt;S&amp;gt; implements Iterable&amp;lt;S&amp;gt;{
    //需要加载的资源的路径的目录，固定是ClassPath下的META-INF/services/
    private static final String PREFIX = &quot;META-INF/services/&quot;;
    // ServiceLoader需要正在需要加载的类或者接口
    // The class or interface representing the service being loaded
    private final Class&amp;lt;S&amp;gt; service;
    // ServiceLoader进行类加载的时候使用的类加载器引用
    // The class loader used to locate, load, and instantiate providers
    private final ClassLoader loader;
    // 权限控制上下文
    // The access control context taken when the ServiceLoader is created
    private final AccessControlContext acc;
    //基于实例的顺序缓存类的实现实例，其中Key为实现类的全限定类名
    // Cached providers, in instantiation order
    private LinkedHashMap&amp;lt;String,S&amp;gt; providers = new LinkedHashMap&amp;lt;&amp;gt;();
    // 当前的&quot;懒查找&quot;迭代器，这个是ServiceLoader的核心
    // The current lazy-lookup iterator
    private LazyIterator lookupIterator;

    //暂时忽略其他代码...
}    &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;ServiceLoader实现了Iterable接口，这一点提示了等下我们在分析它源码的时候，需要重点分析&lt;code&gt;iterator()&lt;/code&gt;方法的实现。ServiceLoader依赖于类加载器实例进行类加载，它的核心属性LazyIterator是就是用来实现&lt;code&gt;iterator()&lt;/code&gt;方法的，下文再重点分析。接着，我们分析ServiceLoader的构造函数：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public void reload() {
    //清空缓存
    providers.clear();
    //构造LazyIterator实例
    lookupIterator = new LazyIterator(service, loader);
}

private ServiceLoader(Class&amp;lt;S&amp;gt; svc, ClassLoader cl) {
    service = Objects.requireNonNull(svc, &quot;Service interface cannot be null&quot;);
    loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl;
    acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null;
    reload();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;ServiceLoader只有一个私有的构造函数，也就是它不能通过构造函数实例化，但是要实例化ServiceLoader必须依赖于它的静态方法调用私有构造去完成实例化操作，而实例化过程主要做了几步：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1、判断传入的接口或者类的Class实例不能为null，否则会抛出异常。&lt;/li&gt;
&lt;li&gt;2、如果传入的ClassLoader实例为null，则使用应用类加载器(Application ClassLoader)。&lt;/li&gt;
&lt;li&gt;3、实例化访问控制上下文。&lt;/li&gt;
&lt;li&gt;4、调用实例方法&lt;code&gt;reload()&lt;/code&gt;，清空目标加载类的实现类实例的缓存并且构造LazyIterator实例。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;注意一点是实例方法&lt;code&gt;reload()&lt;/code&gt;的修饰符是public，也就是可以主动调用去清空目标加载类的实现类实例的缓存和重新构造LazyIterator实例。接着看ServiceLoader提供的静态方法：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public static &amp;lt;S&amp;gt; ServiceLoader&amp;lt;S&amp;gt; load(Class&amp;lt;S&amp;gt; service, ClassLoader loader){
    return new ServiceLoader&amp;lt;&amp;gt;(service, loader);
}

public static &amp;lt;S&amp;gt; ServiceLoader&amp;lt;S&amp;gt; load(Class&amp;lt;S&amp;gt; service) {
    ClassLoader cl = Thread.currentThread().getContextClassLoader();
    return ServiceLoader.load(service, cl);
}

public static &amp;lt;S&amp;gt; ServiceLoader&amp;lt;S&amp;gt; loadInstalled(Class&amp;lt;S&amp;gt; service) {
    ClassLoader cl = ClassLoader.getSystemClassLoader();
    ClassLoader prev = null;
    while (cl != null) {
        prev = cl;
        cl = cl.getParent();
    }
    return ServiceLoader.load(service, prev);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面的三个公共静态方法都是用于构造ServiceLoader实例，其中&lt;code&gt;load(Class&amp;lt;S&amp;gt; service, ClassLoader loader)&lt;/code&gt;就是典型的静态工厂方法，直接调用ServiceLoader的私有构造器进行实例化，除了需要指定加载类的目标类型，还需要传入类加载器的实例。&lt;code&gt;load(Class&amp;lt;S&amp;gt; service)&lt;/code&gt;实际上也是委托到&lt;code&gt;load(Class&amp;lt;S&amp;gt; service, ClassLoader loader)&lt;/code&gt;，不过它使用的类加载器指定为线程上下文类加载器，一般情况下，线程上下文类加载器获取到的就是应用类加载器(系统类加载器)。&lt;code&gt;loadInstalled(Class&amp;lt;S&amp;gt; service)&lt;/code&gt;方法又看出了&quot;双亲委派模型&quot;的影子，它指定类加载器为最顶层的启动类加载器，最后也是委托到&lt;code&gt;load(Class&amp;lt;S&amp;gt; service, ClassLoader loader)&lt;/code&gt;。接着我们需要重点分析&lt;code&gt;ServiceLoader#iterator()&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;public Iterator&amp;lt;S&amp;gt; iterator() {

    //Iterator的匿名实现
    return new Iterator&amp;lt;S&amp;gt;() {
        
    //目标类实现类实例缓存的Map的Entry的迭代器实例
    Iterator&amp;lt;Map.Entry&amp;lt;String,S&amp;gt;&amp;gt; knownProviders = providers.entrySet().iterator();
        
        //先从缓存中判断是否有下一个实例，否则通过懒加载迭代器LazyIterator去判断是否存在下一个实例
        public boolean hasNext() {
            if (knownProviders.hasNext())
                return true;
            return lookupIterator.hasNext();
        }

        //如果缓存中判断是否有下一个实例，如果有则从缓存中的值直接返回
        //否则通过懒加载迭代器LazyIterator获取下一个实例
        public S next() {
            if (knownProviders.hasNext())
                return knownProviders.next().getValue();
            return lookupIterator.next();
        }

        //不支持移除操作，直接抛异常
        public void remove() {
            throw new UnsupportedOperationException();
        }
    };
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;iterator()&lt;/code&gt;内部仅仅是Iterator接口的匿名实现，&lt;code&gt;hasNext()&lt;/code&gt;和&lt;code&gt;next()&lt;/code&gt;方法都是优先判断缓存中是否已经存在实现类的实例，如果存在则直接从缓存中返回，否则调用懒加载迭代器LazyIterator的实例去获取，而LazyIterator本身也是一个Iterator接口的实现，它是ServiceLoader的一个私有内部类，源码如下：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;private class LazyIteratorimplements Iterator&amp;lt;S&amp;gt;{

        Class&amp;lt;S&amp;gt; service;
        ClassLoader loader;
        //加载的资源的URL集合
        Enumeration&amp;lt;URL&amp;gt; configs = null;
        //所有需要加载的实现类的全限定类名的集合
        Iterator&amp;lt;String&amp;gt; pending = null;
        //下一个需要加载的实现类的全限定类名
        String nextName = null;

        private LazyIterator(Class&amp;lt;S&amp;gt; service, ClassLoader loader) {
            this.service = service;
            this.loader = loader;
        }

        private boolean hasNextService() {
            //如果下一个需要加载的实现类的全限定类名不为null，则说明资源中存在内容
            if (nextName != null) {
                return true;
            }
            //如果加载的资源的URL集合为null则尝试进行加载
            if (configs == null) {
                try {
                    //资源的名称，META-INF/services + '需要加载的类的全限定类名'
                    //这样得到的刚好是需要加载的文件的资源名称
                    String fullName = PREFIX + service.getName();
                    //这里其实ClassLoader实例应该不会为null
                    if (loader == null)
                        configs = ClassLoader.getSystemResources(fullName);
                    else
                        //从ClassPath加载资源
                        configs = loader.getResources(fullName);
                } catch (IOException x) {
                    fail(service, &quot;Error locating configuration files&quot;, x);
                }
            }
            //从资源中解析出需要加载的所有实现类的全限定类名
            while ((pending == null) || !pending.hasNext()) {
                if (!configs.hasMoreElements()) {
                    return false;
                }
                pending = parse(service, configs.nextElement());
            }
            //获取下一个需要加载的实现类的全限定类名
            nextName = pending.next();
            return true;
        }

        private S nextService() {
            if (!hasNextService())
                throw new NoSuchElementException();
            String cn = nextName;
            nextName = null;
            Class&amp;lt;?&amp;gt; c = null;
            try {
                //反射构造Class&amp;lt;S&amp;gt;实例
                c = Class.forName(cn, false, loader);
            } catch (ClassNotFoundException x) {
                fail(service,
                     &quot;Provider &quot; + cn + &quot; not found&quot;);
            }
            //这里会做一次类型判断，也就是实现类必须是当前加载的类或者接口的派生类，否则抛出异常终止
            if (!service.isAssignableFrom(c)) {
                fail(service,
                     &quot;Provider &quot; + cn  + &quot; not a subtype&quot;);
            }
            try {
                //通过Class#newInstance()进行实例化，并且强制转化为对应的类型的实例
                S p = service.cast(c.newInstance());
                //添加缓存，Key为实现类的全限定类名，Value为实现类的实例
                providers.put(cn, p);
                return p;
            } catch (Throwable x) {
                fail(service,
                     &quot;Provider &quot; + cn + &quot; could not be instantiated&quot;,
                     x);
            }
            throw new Error();          // This cannot happen
        }

        public boolean hasNext() {
            if (acc == null) {
                return hasNextService();
            } else {
                PrivilegedAction&amp;lt;Boolean&amp;gt; action = new PrivilegedAction&amp;lt;Boolean&amp;gt;() {
                    public Boolean run() { return hasNextService(); }
                };
                return AccessController.doPrivileged(action, acc);
            }
        }

        public S next() {
            if (acc == null) {
                return nextService();
            } else {
                PrivilegedAction&amp;lt;S&amp;gt; action = new PrivilegedAction&amp;lt;S&amp;gt;() {
                    public S run() { return nextService(); }
                };
                return AccessController.doPrivileged(action, acc);
            }
        }

        public void remove() {
            throw new UnsupportedOperationException();
        }

    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;LazyIterator&lt;/code&gt;也是Iterator接口的实现，它的Lazy特性表明它总是在ServiceLoader的Iterator接口匿名实现&lt;code&gt;iterator()&lt;/code&gt;执行&lt;code&gt;hasNext()&lt;/code&gt;判断是否有下一个实现或者&lt;code&gt;next()&lt;/code&gt;获取下一个实现类的实例的时候才会&quot;懒判断&quot;或者&quot;懒加载&quot;下一个实现类的实例。最后是加载资源文件后对资源文件的解析过程的源码：&lt;/p&gt;
&lt;pre class=&quot;java&quot;&gt;
&lt;code&gt;private Iterator&amp;lt;String&amp;gt; parse(Class&amp;lt;?&amp;gt; service, URL u) throws ServiceConfigurationError{
        InputStream in = null;
        BufferedReader r = null;
        //存放文件中所有的实现类的全类名，每一行是一个元素
        ArrayList&amp;lt;String&amp;gt; names = new ArrayList&amp;lt;&amp;gt;();
        try {
            in = u.openStream();
            r = new BufferedReader(new InputStreamReader(in, &quot;utf-8&quot;));
            int lc = 1;
            while ((lc = parseLine(service, u, r, lc, names)) &amp;gt;= 0);
        } catch (IOException x) {
            fail(service, &quot;Error reading configuration file&quot;, x);
        } finally {
            try {
                if (r != null) r.close();
                if (in != null) in.close();
            } catch (IOException y) {
                fail(service, &quot;Error closing configuration file&quot;, y);
            }
        }
        //返回的是ArrayList的迭代器实例
        return names.iterator();
}

//解析资源文件中每一行的内容
private int parseLine(Class&amp;lt;?&amp;gt; service, URL u, BufferedReader r, int lc,
                      List&amp;lt;String&amp;gt; names)throws IOException, ServiceConfigurationError{
        // 下一行没有内容，返回-1，便于上层可以跳出循环                 
        String ln = r.readLine();
        if (ln == null) {
            return -1;
        }
        //如果存在'#'字符，截取第一个'#'字符串之前的内容，'#'字符之后的属于注释内容
        int ci = ln.indexOf('#');
        if (ci &amp;gt;= 0) ln = ln.substring(0, ci);
        ln = ln.trim();
        int n = ln.length();
        if (n != 0) {
            //不能存在空格字符' '和特殊字符'\t'
            if ((ln.indexOf(' ') &amp;gt;= 0) || (ln.indexOf('\t') &amp;gt;= 0))
                fail(service, u, lc, &quot;Illegal configuration-file syntax&quot;);
            int cp = ln.codePointAt(0);
            //判断第一个char是否一个合法的Java起始标识符
            if (!Character.isJavaIdentifierStart(cp))
                fail(service, u, lc, &quot;Illegal provider-class name: &quot; + ln);
            //判断所有其他字符串是否属于合法的Java标识符
            for (int i = Character.charCount(cp); i &amp;lt; n; i += Character.charCount(cp)) {
                cp = ln.codePointAt(i);
                if (!Character.isJavaIdentifierPart(cp) &amp;amp;&amp;amp; (cp != '.'))
                    fail(service, u, lc, &quot;Illegal provider-class name: &quot; + ln);
            }
            //如果缓存中不存在加载出来的全类名或者已经加载的列表中不存在加载出来的全类名则添加进去加载的全类名列表中
            if (!providers.containsKey(ln) &amp;amp;&amp;amp; !names.contains(ln))
                names.add(ln);
        }
        return lc + 1;
    }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;整个资源文件的解析过程并不复杂，主要包括文件内容的字符合法性判断和缓存避免重复加载的判断。&lt;/p&gt;

&lt;p&gt;SPI被广泛使用在第三方插件式类库的加载，最常见的如JDBC、JNDI、JCE(Java加密模块扩展)等类库。理解ServiceLoader的工作原理有助于编写扩展性良好的可插拔的类库。&lt;/p&gt;
&lt;p&gt;(本文完 c-1-d e-20181014)&lt;/p&gt;
</description>
<pubDate>Sun, 14 Oct 2018 15:42:00 +0000</pubDate>
<dc:creator>throwable</dc:creator>
<og:description>前提 紧接着上一篇《通过源码浅析JDK中的资源加载》，ServiceLoader是SPI(Service Provider Interface)中的服务类加载的核心类，也就是，这篇文章先介绍Servi</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/throwable/p/9788819.html</dc:identifier>
</item>
<item>
<title>傻瓜式的go modules的讲解和代码 - lgp20151222</title>
<link>http://www.cnblogs.com/ydymz/p/9788804.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ydymz/p/9788804.html</guid>
<description>&lt;p&gt;国内关于gomod的文章，哪怕是使用了百度 -csdn，依然全是理论，虽然golang的使用者大多是大神但是也有像我这样的的弱鸡是不是？&lt;/p&gt;
&lt;p&gt;所以，我就写个傻瓜式教程了。&lt;/p&gt;
&lt;p&gt;github地址：&lt;a href=&quot;https://github.com/247292980/go_moudules_demo&quot; target=&quot;_blank&quot;&gt;https://github.com/247292980/go_moudules_demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;代码很少很简单。。。。&lt;/p&gt;


&lt;p&gt;1.新建文件夹 go_moudiules_demo&lt;/p&gt;
&lt;p&gt;2.go mod之，生成gomod.go文件&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
go mod init go_moudiules_demo&lt;br/&gt;语法&lt;br/&gt;go mod init [module]
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1095725/201810/1095725-20181014224841101-505005851.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;3.创建main.go，默认包名是gomod，需要改成main&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1095725/201810/1095725-20181014222428547-304067604.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;4.创建正真的存放代码的文件夹 demo和文件gomod.go，注意不能与main放在同一文件夹下，因为会造成包名冲突&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1095725/201810/1095725-20181014224959803-421992495.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; 5.根据规则引入代码，这里有个坑，因为goland做的不太好，实际上golang的所有工具都做的不太好，导致代码报红，但是实际上go build/run还是能跑通的&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1095725/201810/1095725-20181014225405079-306593380.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当然goland也可以配置，就是不知道怎么去红名。。。　　&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1095725/201810/1095725-20181014225246288-1930892805.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;gomod最容易让人进了误区就是，把自己之前的代码都gomod一次，那么后面使用的时候直接根据gomod的package找之前的代码，简直美滋滋。&lt;/p&gt;
&lt;p&gt;毕竟是go moudules但是，实际上只是go moudule，他只管一个项目里的多个包。&lt;/p&gt;
&lt;p&gt;为什么造成这个误区呢？因为国内说的都是包管理，我还真以为是针对包的操作，然后第一次尝试失败后，翻了下官网&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;brush:java;gutter:true;&quot;&gt;
A module is a collection of related Go packages. &lt;br/&gt;Modules are the unit of source code interchange and versioning.&lt;br/&gt;The go command has direct support for working with modules, including recording and resolving dependencies on other modules.&lt;br/&gt;Modules replace the old GOPATH-based approach to specifying which source files are used in a given build.
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt; a collection of related Go packages.&lt;/strong&gt; &lt;code class=&quot;hljs&quot;&gt;相关Go包的集合，这玩意的理解真的是难，什么相关，相关的是什么？这时候根据官网的usage代码反向理解下&lt;/code&gt;go mod init [module]&lt;/p&gt;
&lt;p&gt;&lt;code class=&quot;hljs&quot;&gt;，显然是 &lt;code class=&quot;hljs&quot;&gt;module的相关Go包的集合，而module是一个单数啊。。。&lt;code class=&quot;hljs&quot;&gt;&lt;code class=&quot;hljs&quot;&gt;module&lt;/code&gt;&lt;/code&gt;和go mudules。。。我该如何理解啊。。。模板我倒是知道。。。总感觉这个怪不到谷歌头上，而且这玩意大家试个两下，就能找到正确理解也不算什么事。而且我要是把自己的代码都丢到github上同样不会报错，只是我是想着不丢到github上面的使用所以进了歪路。而且看后面的语法解析 &lt;span&gt;go mod download 看起来就像是能实现我说的效果的，就是国内没什么材料，我只好一个一个翻英文，，，&lt;/span&gt;&lt;/code&gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;而第二句&lt;strong&gt;Modules are the unit of source code interchange and versioning. &lt;strong&gt;Modules&lt;/strong&gt;&lt;/strong&gt; 是源码的版本控制和交换的单位，也就说明go mod之间是独立的，，，不能互调，除非在gopath里面。感觉大神看到这句两下都不用试了。。。&lt;/p&gt;

&lt;p&gt;主要是一个人的博客 http://blog.51cto.com/qiangmzsx/2164520?source=dra&lt;/p&gt;
&lt;p&gt;我把其中的关键抽出来，去掉他的代码，有兴趣的可以去原文看看&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;    go mod init:初始化modules
    go mod download:下载modules到本地cache
    go mod edit:编辑go.mod文件，选项有&lt;/span&gt;-json、-require和-&lt;span&gt;exclude，可以使用帮助go help mod edit
    go mod graph:以文本模式打印模块需求图
    go mod tidy:删除错误或者不使用的modules
    go mod vendor:生成vendor目录
    go mod verify:验证依赖是否正确
    go mod why：查找依赖

    go test    执行一下，自动导包

    go list &lt;/span&gt;-&lt;span&gt;m  主模块的打印路径
    go list &lt;/span&gt;-m -f=&lt;span&gt;{{.Dir}}  print主模块的根目录
    go list &lt;/span&gt;-m all  查看当前的依赖和版本信息
&lt;/pre&gt;&lt;/div&gt;

</description>
<pubDate>Sun, 14 Oct 2018 15:36:00 +0000</pubDate>
<dc:creator>lgp20151222</dc:creator>
<og:description>一 国内关于gomod的文章，哪怕是使用了百度 -csdn，依然全是理论，虽然golang的使用者大多是大神但是也有像我这样的的弱鸡是不是？ 所以，我就写个傻瓜式教程了。 github地址：https</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/ydymz/p/9788804.html</dc:identifier>
</item>
<item>
<title>Scheme来实现八皇后问题(1) - 窗户</title>
<link>http://www.cnblogs.com/Colin-Cai/p/9768105.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Colin-Cai/p/9768105.html</guid>
<description>&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:sql;gutter:true;&quot;&gt;
　　版权申明：本文为博主窗户(Colin Cai)原创，欢迎转帖。如要转贴，必须注明原文网址

　　http://www.cnblogs.com/Colin-Cai/p/9768105.html 

　　作者：窗户

　　QQ/微信：6679072

　　E-mail：6679072@qq.com 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　看到有人写八皇后，那我就也写写这个吧。&lt;/p&gt;

&lt;p&gt;　　&lt;strong&gt;&lt;span&gt;八皇后问题&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;　　这个问题大家应该都不陌生，很多计算机教程都以八皇后为例题。&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1151747/201810/1151747-20181011155033401-1675650246.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;　　上面是一个国际象棋棋盘，总共8X8个格子。&lt;/p&gt;
&lt;p&gt;　　皇后是国际象棋里杀力最强的子，它可以吃掉同一条横线、竖线上其他棋子，也可以吃掉所在的两条斜线上的其他棋子（当然在角上只有一条斜线）。&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1151747/201810/1151747-20181011155624161-1529676479.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　能否在棋盘上放更多的皇后，让彼此之间不能互相吃到？基于很显然一行或者一列最多只有一个皇后，那么这个8X8的棋盘是否可以放8个皇后？&lt;/p&gt;

&lt;p&gt;　　&lt;strong&gt;&lt;span&gt;解的表示&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;　　8个皇后的表示可以用坐标，那么就是8个坐标的集合，其中行、列都是范围1~8的数字。&lt;/p&gt;
&lt;p&gt;　　考虑到每一行都只有一个，我们完全可以用让8个皇后按照行坐标进行从小到大排序，那么必然8个皇后的行坐标分别是1、2、3、4、5、6、7、8，于是这都是无用的信息。又因为只有8列，而且任意两个皇后都不能同列，从而每一列也有且只有一个，从而刚才排序之后的8个皇后的纵坐标序列是1、2、3、4、5、6、7、8的一个排列。于是每一种可行的解对应着1、2、3、4、5、6、7、8的一个排列。&lt;/p&gt;
&lt;p&gt;　　考虑更一般的情况，n皇后问题：nXn的棋盘上放n个皇后，要求彼此之间不互相吃。那么它的&lt;strong&gt;&lt;span&gt;每一个解对应着1~n的一个排列&lt;/span&gt;&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;　　&lt;span&gt;&lt;strong&gt;解法框架&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;　　一种做法就是先找到1~n的所有排列，然后筛选符合条件的结果。&lt;/p&gt;
&lt;p&gt; 　　那么利用filter算子最终代码很容易给出:&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;(define (queen n)
 (filter
  valid&lt;/span&gt;?&lt;span&gt;
  (P n)
 )
)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;　　这里的(P n)是所有的1~n排列的集合，这里排列当然用list来表示，集合也用list来表示。&lt;/p&gt;
&lt;p&gt;　　集合的每个元素是没有序的关系，所以逻辑上表示集合的list我们应该忽略其各个元素的序的差别。&lt;/p&gt;
&lt;p&gt;　　比如(P 2)表示的是'((1 2) (2 1))，或者是'((2 1) (1 2))，无论哪种实现，都是可行的。&lt;/p&gt;

&lt;p&gt;　　valid?是个谓词函数(返回bool值的函数)，它的作用是对于某个具体排列，判断其表示的n个皇后有没有互相吃的情况：&lt;/p&gt;
&lt;p&gt;　　如果有两个皇后互相吃，那么这个排列不可以作为最后的解，应当返回假，Scheme里也就是#f；&lt;/p&gt;
&lt;p&gt;　　如果不存在两个皇后互相吃，那么这个排列可以作为最后的皆，从而应当返回真，Scheme里也就是#t。&lt;/p&gt;

&lt;p&gt;　　filter算子就是使用valid?这样的谓词函数来过滤后面的集合，&lt;/p&gt;
&lt;p&gt;　　比如(filter even? '(1 2 3 4 5 6 7 8 9 10))就是抓取其中为偶数的元素组成的集合，那么当然返回'(2 4 6 8 10)。&lt;/p&gt;
&lt;p&gt;　　filter这么常用的算子似乎并未出现在r5rs中，很奇怪，我在这里就给出一个实现如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
(define (filter boolf &lt;span&gt;set&lt;/span&gt;&lt;span&gt;)
 (cond
  ((&lt;/span&gt;&lt;span&gt;null&lt;/span&gt;? &lt;span&gt;set&lt;/span&gt;) &lt;span&gt;'&lt;/span&gt;&lt;span&gt;())&lt;/span&gt;
  ((boolf (car &lt;span&gt;set&lt;/span&gt;)) (cons (car &lt;span&gt;set&lt;/span&gt;) (filter boolf (cdr &lt;span&gt;set&lt;/span&gt;&lt;span&gt;))))
  (&lt;/span&gt;&lt;span&gt;else&lt;/span&gt; (filter boolf (cdr &lt;span&gt;set&lt;/span&gt;&lt;span&gt;)))
 )
)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;　　接下去就是P函数和valid?函数的实现。&lt;/p&gt;

&lt;p&gt;　　&lt;span&gt;&lt;strong&gt;全排列&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;　　第一个问题就是要解决1~n的所有排列，可能会有人考虑将所有的排列用字典排序依次输出。&lt;/p&gt;
&lt;p&gt;　　不过这一般是迭代的思想，而对于一种Lisp，我们第一反应一般是&lt;span&gt;&lt;strong&gt;递归&lt;/strong&gt;&lt;/span&gt;。&lt;/p&gt;

&lt;p&gt;　　假设我们已经有1~n-1的全排列了，那么我们怎么得到1~n的全排列呢？&lt;/p&gt;
&lt;p&gt;　　我们可以取1~n-1的一个排列，不妨用字母标注&lt;/p&gt;
&lt;p&gt;　　a&lt;sub&gt;1&lt;/sub&gt; a&lt;sub&gt;2&lt;/sub&gt; ... a&lt;sub&gt;n-1&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt;　　我们希望找个位置插入n，得到新的1~n的排列。&lt;/p&gt;
&lt;p&gt;　　这个插入点一共有n个，分别为：&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;a&lt;sub&gt;1&lt;/sub&gt;之前&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　a&lt;sub&gt;1&lt;/sub&gt;和a&lt;sub&gt;2&lt;/sub&gt;之间&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　a&lt;sub&gt;2&lt;/sub&gt;和a&lt;sub&gt;3&lt;/sub&gt;之间&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　...&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　a&lt;sub&gt;n-2&lt;/sub&gt;和a&lt;sub&gt;n-1&lt;/sub&gt;之间&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　&lt;/span&gt;&lt;span&gt;a&lt;sub&gt;n-1&lt;/sub&gt;之后&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　从而可以得到n个1~n的排列。&lt;/p&gt;
&lt;p&gt;　　而对1~n-1的所有排列都这么做，则构成了1~n的所有排列，且不存在重复。&lt;/p&gt;

&lt;p&gt;　　比如1~2的所有排列组成的集合为&lt;/p&gt;
&lt;p&gt;　　((1 2) (2 1))&lt;/p&gt;
&lt;p&gt;　　现在我们要用它生成1~3的全排列&lt;/p&gt;
&lt;p&gt;　　对于(1 2)，有3个插入点，插入3，得到三个排列&lt;/p&gt;
&lt;p&gt;　　(3 1 2) (1 3 2) (1 2 3)&lt;/p&gt;
&lt;p&gt;　　对于(2 1)，有3个插入点，插入3，得到三个排列&lt;/p&gt;
&lt;p&gt;　　(3 2 1) (2 3 1) (2 1 3)&lt;/p&gt;
&lt;p&gt;　　以上6个排列组成的集合就是我们所需要的结果。&lt;/p&gt;

&lt;p&gt;　　首先，当然要建立一个往列表某个位置插值的函数list-insert,带三个参数，将列表lst的位置pos插入v。而对于位置的解释是，列表头之前的位置称为0，然后依次增加。比如(1 2 3)的位置1插入4，得到列表(1 4 2 3)。这个很容易用递归设计出来，如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
(define (list-&lt;span&gt;insert lst pos v)
 (&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (zero?&lt;span&gt; pos) (cons v lst)
  (cons (car lst) (list&lt;/span&gt;-insert (cdr lst) (- pos &lt;span&gt;1&lt;/span&gt;&lt;span&gt;) v))
 )
)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　上述(list-insert '(1 2 3) 1 4)，运算返回'(1 4 2 3)&lt;/p&gt;

&lt;p&gt;　　按照上面的递归思想，我们使用map算子先写一点测试测试，我们希望从1~2的全排列推到1~3的全排列&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　(map&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　 (lambda (x) (map (lambda (m) (list-insert x m 3)) '(0 1 2))) ;对于每个排列，给出0、1、2三个位置插入3&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　 '((1 2)(2 1))&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　结果为&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;'(((3 1 2) (1 3 2) (1 2 3)) ((3 2 1) (2 3 1) (2 1 3)))&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;　　这很像我们所要的，但似乎又不是，因为我们需要应该是'((3 1 2) (1 3 2) (1 2 3) (3 2 1) (2 3 1) (2 1 3))&lt;/p&gt;
&lt;p&gt;　　实际上，(apply append '(((3 1 2) (1 3 2) (1 2 3)) ((3 2 1) (2 3 1) (2 1 3))))就是我们需要的结果了。&lt;/p&gt;
&lt;p&gt;　　而apply是把最后一个参数(这个参数一定要是i列表)展开。&lt;/p&gt;
&lt;p&gt;　　于是上述就成了(append '((3 1 2) (1 3 2) (1 2 3)) '((3 2 1) (2 3 1) (2 1 3)) )，当然就是我们需要的结果了。&lt;/p&gt;

&lt;p&gt;　　而只有1个元1的全排列集合就是'((1))，这是递归的边界，&lt;/p&gt;
&lt;p&gt;　　结合上述，全排列的函数定义应该如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;(define (P n)
 (&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (= n &lt;span&gt;1&lt;/span&gt;) &lt;span&gt;'&lt;/span&gt;&lt;span&gt;((1))&lt;/span&gt;
&lt;span&gt;  (apply append 
   (map 
    (lambda (x) (map (lambda (m) (list&lt;/span&gt;-insert x m n)) (range &lt;span&gt;0&lt;/span&gt;&lt;span&gt; n)))
    (P (&lt;/span&gt;- n &lt;span&gt;1&lt;/span&gt;&lt;span&gt;))
   )
  )
 )
)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;　　&lt;strong&gt;&lt;span&gt;判断合法&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;　　目前只剩下valid?函数的实现了。实际上，在我们开始采用用1~n排序来作为最后的解的时候，已经把棋盘中同行同列的情况给排除了。于是，valid?函数实际上是要判断是否有两个棋子在同一个斜线上。&lt;/p&gt;
&lt;p&gt;　　比如'(1 3 6 4 2 5 8 7)表示如图的八个皇后，皇后的位置被打了红圈&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1151747/201810/1151747-20181014224713830-1552455456.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　其中存在着皇后互吃，&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://img2018.cnblogs.com/blog/1151747/201810/1151747-20181014224904802-1860372898.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　在数据上看，'(1 3 6 4 2 5 8 7)，其中&lt;/p&gt;
&lt;p&gt;　　1和4相差3，距离也为3(1在列表的第0个位置，4在列表的第3个位置，所以距离为3)；&lt;/p&gt;
&lt;p&gt;　　3和8相差5，距离也为5；&lt;/p&gt;
&lt;p&gt;　　8和7相差1，距离也为1。&lt;/p&gt;
&lt;p&gt;　　对应着上面三对互吃的皇后。&lt;/p&gt;

&lt;p&gt;　　我们这里可以用迭代来完成，这有点类似于过程式语言的循环了。&lt;/p&gt;
&lt;p&gt;　　从左到右先距离为1的，看看有没有值也相差1的，如果有，那么valid?返回假，也就是#f&lt;/p&gt;
&lt;p&gt;　　然后从左到右再扫距离为2的....&lt;/p&gt;
&lt;p&gt;　　...&lt;/p&gt;
&lt;p&gt;　　最后当距离到n的时候，直接返回真，也就是#f(因为最左边和最右边距离达到，也就是n-1，此时代表所有可能都已扫过)&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
(define (_valid? x left-&lt;span&gt;pos distance)
 (cond
  ;当距离以及达到列表长度了，扫完了，返回真
  ((&lt;/span&gt;=&lt;span&gt; distance (length x)) #t)
  ;如果发现差值等于距离，这一对皇后互吃，返回假
  ((&lt;/span&gt;= distance (abs (- (list-&lt;span&gt;ref&lt;/span&gt; x left-pos) (list-&lt;span&gt;ref&lt;/span&gt; x (+ left-&lt;span&gt;pos distance))))) #f)
  ;如果这个距离还没扫完，那么往后推一个扫
  ((&lt;/span&gt;&amp;lt; (+ left-pos distance) (- (length x) &lt;span&gt;1&lt;/span&gt;)) (_valid? x (+ left-pos &lt;span&gt;1&lt;/span&gt;&lt;span&gt;) distance))
  ;否则，这个距离的已经扫完，距离加1，从最左边开始扫
  (&lt;/span&gt;&lt;span&gt;else&lt;/span&gt; (_valid? x &lt;span&gt;0&lt;/span&gt; (+ distance &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)))
 )
)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;　　用它实现valid?，初始的时候，从left-pos为0，distance为1的一对皇后开始扫起&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
(define (valid?&lt;span&gt; x)
 (_valid&lt;/span&gt;? x &lt;span&gt;0&lt;/span&gt; &lt;span&gt;1&lt;/span&gt;&lt;span&gt;)
)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;　　&lt;span&gt;&lt;strong&gt;运行&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;　　我们就拿8个皇后来测试一下，计算&lt;span&gt;(queen 8)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　得到　　&lt;/p&gt;
&lt;p&gt;&lt;span&gt;((4 7 3 8 2 5 1 6) (3 6 4 2 8 5 7 1) (3 5 2 8 6 4 7 1) (6 3 7 2 4 8 1 5) (3 6 8 2 4 1 7 5) (3 7 2 8 6 4 1 5) (3 5 2 8 1 7 4 6) (6 3 7 2 8 5 1 4) (3 6 2 7 5 1 8 4) (3 6 2 5 8 1 7 4) (7 3 8 2 5 1 6 4) (3 7 2 8 5 1 4 6) (3 6 2 7 1 4 8 5) (4 2 7 3 6 8 5 1) (4 2 7 3 6 8 1 5) (5 2 4 6 8 3 1 7) (5 2 4 7 3 8 6 1) (2 4 6 8 3 1 7 5) (5 7 2 6 3 1 8 4) (5 7 2 6 3 1 4 8) (8 2 5 3 1 7 4 6) (2 7 3 6 8 5 1 4) (7 2 6 3 1 4 8 5) (2 6 8 3 1 4 7 5) (4 7 5 2 6 1 3 8) (6 4 2 8 5 7 1 3) (4 2 5 8 6 1 3 7) (4 2 7 5 1 8 6 3) (7 4 2 5 8 1 3 6) (4 2 8 5 7 1 3 6) (4 6 8 2 7 1 3 5) (7 4 2 8 6 1 3 5) (4 2 8 6 1 3 5 7) (5 7 2 4 8 1 3 6) (2 5 7 4 1 8 6 3) (6 8 2 4 1 7 5 3) (7 2 4 1 8 5 3 6) (8 2 4 1 7 5 3 6) (5 2 6 1 7 4 8 3) (5 2 8 1 4 7 3 6) (2 7 5 8 1 4 6 3) (6 2 7 1 4 8 5 3) (2 6 1 7 4 8 3 5) (2 5 7 1 3 8 6 4) (6 2 7 1 3 5 8 4) (2 8 6 1 3 5 7 4) (4 7 5 3 1 6 8 2) (4 8 5 3 1 7 2 6) (4 6 8 3 1 7 5 2) (5 3 8 4 7 1 6 2) (3 5 8 4 1 7 2 6) (3 6 4 1 8 5 7 2) (6 3 7 4 1 8 2 5) (3 8 4 7 1 6 2 5) (6 3 5 7 1 4 2 8) (6 3 5 8 1 4 2 7) (3 5 7 1 4 2 8 6) (3 6 8 1 4 7 5 2) (6 3 1 8 4 2 7 5) (7 5 3 1 6 8 2 4) (5 3 1 6 8 2 4 7) (5 3 1 7 2 8 6 4) (6 3 1 7 5 8 2 4) (6 3 1 8 5 2 4 7) (3 6 8 1 5 7 2 4) (7 3 1 6 8 5 2 4) (3 1 7 5 8 2 4 6) (8 3 1 6 2 5 7 4) (5 7 4 1 3 8 6 2) (5 8 4 1 3 6 2 7) (4 1 5 8 6 3 7 2) (6 4 7 1 3 5 2 8) (8 4 1 3 6 2 7 5) (4 8 1 3 6 2 7 5) (5 7 1 3 8 6 4 2) (1 6 8 3 7 4 2 5) (7 1 3 8 6 4 2 5) (5 1 8 6 3 7 2 4) (1 5 8 6 3 7 2 4) (5 8 4 1 7 2 6 3) (6 4 1 5 8 2 7 3) (4 6 1 5 2 8 3 7) (4 7 1 8 5 2 6 3) (4 8 1 5 7 2 6 3) (4 1 5 8 2 7 3 6) (6 4 7 1 8 2 5 3) (5 1 4 6 8 2 7 3) (5 7 1 4 2 8 6 3) (5 1 8 4 2 7 3 6) (1 7 4 6 8 2 5 3) (1 7 5 8 2 4 6 3) (6 1 5 2 8 3 7 4))&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　一共92个解。&lt;/p&gt;
</description>
<pubDate>Sun, 14 Oct 2018 15:08:00 +0000</pubDate>
<dc:creator>窗户</dc:creator>
<og:description>看到有人写八皇后，那我就也写写这个吧。 八皇后问题 这个问题大家应该都不陌生，很多计算机教程都以八皇后为例题。 上面是一个国际象棋棋盘，总共8X8个格子。 皇后是国际象棋里杀力最强的子，它可以吃掉同一</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/Colin-Cai/p/9768105.html</dc:identifier>
</item>
<item>
<title>【自编码】变分自编码大杂烩 - 文字妖精</title>
<link>http://www.cnblogs.com/wzyj/p/9766655.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wzyj/p/9766655.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.&lt;span&gt;变分自编码&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;         变分是数学上的概念，大致含义是寻求一个中间的函数，通过改变中间函数来查看目标函数的改变。变分推断是变分自编码的核心，那么变分推断是要解决的是什么问题??&lt;/p&gt;
&lt;p&gt;问题描述如下，假如我们有一批样本X，这个时候，我们想生成一批和它类似的样本，且分布相同，这个时候我们该怎么办呢?&lt;/p&gt;
&lt;p&gt;1.如果我们知道样本的分布的情况下，这个事情就好办了，先生成一批均匀分布的样本，通过分布的具体形式与均匀分布之间的关系，生成一批新的样本。&lt;/p&gt;
&lt;p&gt;2.如果我们不知道样本分布的情况下，仍然可以通过一些方法得到类似的样本，例如MCMC过程，Gibbs-Sample等&lt;/p&gt;
&lt;p&gt;更加详细的推断和过程，可以在&lt;a href=&quot;http://vdisk.weibo.com/s/q0sGh/1360334108?utm_source=weibolife&quot; target=&quot;_blank&quot;&gt;LDA数学八卦&lt;/a&gt;来寻找答案。&lt;/p&gt;
&lt;p&gt;        神经网络拥有拟合出任意函数的特点，那么使用它来拟合我们的数据分布可以不?答案是肯定的，AutoEncoder的就是为了尽可能拟合原始数据而服务的，但是一般的AutoEncoder在工程中大部分只是被用来作为降维的手段，并没有产生新样本的功能，那就是VAE(变分自编码)的能解决的问题了。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.1 &lt;span&gt;变分推断&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;限于本人数学造诣只是二把刀，下面的论断大部分来自网上相关博客，引用已经写在下面，有疑问，大家勿喷。下面的公式来自于 &lt;/span&gt;&lt;a href=&quot;https://www.dropbox.com/s/v6ua3d9yt44vgb3/cover_and_thesis.pdf?dl=0&amp;amp;utm_campaign=Revue+newsletter&amp;amp;utm_medium=Newsletter&amp;amp;utm_source=NLP+News&quot; target=&quot;_blank&quot;&gt;VARIATIONAL INFERENCE  &amp;amp; DEEP LEARNING: &lt;em id=&quot;__mceDel&quot;&gt;&lt;em id=&quot;__mceDel&quot;&gt;&lt;em id=&quot;__mceDel&quot;&gt;A NEW SYNTHESIS&lt;/em&gt;&lt;/em&gt;&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/377271/201810/377271-20181014180546391-1489863292.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/377271/201810/377271-20181014180711867-1995520443.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;公式的推倒主要使用了贝叶斯公式和詹森不等式，有兴趣的同学可以尝试一下。下面我们只分析这个结果，以及用途。&lt;/p&gt;
&lt;p&gt;变分推断给出了一个下界，我们可以通过最大化$L_{\theta,\phi }(x)$ 来同时获得$\phi ,\theta $的最优解，从而获得需要逼近的数据分布。比较有趣的是$D_{KL}(q_{\phi }(z|x)||p_{\theta }(z|x))$决定了两个“距离”:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt; KL散度决定了先验假设的分布和真实分布的相似性。&lt;/li&gt;
&lt;li&gt;$L_{\theta,\phi }(x)$ 和最大相似似然函数$log p_{\theta }(x)$之间的间隔。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;所以最大化KL散度既能使得$q_{\phi }(z|x)$趋近于真实的分布$p_{\theta }(z|x)$,又使得$L_{\theta,\phi }(x)$和$log p_{\theta }(x)$的“间隔”变得更小。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.2 &lt;span&gt;VAE的学习过程&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/377271/201810/377271-20181014211128557-1019145838.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如上面幅图显示的如此，VAE包含两部分：Encoder和Decoder，前者又被成为推理模型，后者又被成为生成模型。正常来说$q_{D}(x)$的分布是比较复杂的，而映射之后的z空间在比较简单(通常假设为我们常见的分布，像高斯分布)，生成模型学习一个联合分布$p_{\theta }(x,z)=p_{\theta }(z)p_{\theta }(x|z)$，该联合分布分解为两部分，首先是z空间的先验分布$p_{\theta }(z)$和随机解码器$p_{\theta }(x|z)$。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/377271/201810/377271-20181014210925625-92440224.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上面这张图给出了模型训练的伪代码，值得注意的是下面两点:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在实际工程当中，我们经常假设z服从高斯分布，从理论上讲可以是任何分布，也可以是均匀分布，但是均匀分布在训练过程中计算KL散度可能得到无穷大值。&lt;/li&gt;
&lt;li&gt;中间采样的过程是怎么加入到神经网络的BP算法中的?这个地方是作者采用了 &lt;strong&gt;reparemerization&lt;/strong&gt; 的方法，在实际训练中$z=g(\varepsilon ,\phi ,x)$满足该分布，其中$\varepsilon$是独立于$\phi$和x的，经常把$\varepsilon$ 看作原始分布的一种噪音，这样随机独立的噪音可以与模型训练无关，我们只关注于$\phi$和x，抽样的过程则是不同$\varepsilon$ 的由z分布生成的样本。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;&lt;span&gt;1.3 &lt;span&gt;比较常见的VAE模型&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;隐含变量z服从高斯分布，对应的目标函数变成&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/377271/201810/377271-20181014214848833-1926403688.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;中间的抽样过程如下图所示:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/377271/201810/377271-20181014215019542-441298142.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;训练模型时值得注意&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;生成模型$p_{\theta }(x|z)$也经常假设一种分布，如果是二值的数据的话，我们经常假设为伯努利分布；如果是真实的数据的话，经常假设为高斯分布。&lt;/li&gt;
&lt;li&gt;生成模型的输出，都是独立的，也就是说神经网络的最后一层的每个输出不能使用softmax这种彼此互斥的输出的函数。&lt;/li&gt;
&lt;li&gt;输入模型的数据建议归一化一下，因为网上有些代码中会使用mse作为对$p_{\theta }(x)$的等价，其实拟合的输出是高斯分布的情况(&lt;span&gt;具体证明参见Pattern Recognition and Machine Learning 第5.2章节&lt;/span&gt;)，对于非归一化的数据，mse倾向于优化变化范围大的列。归一化之后，可以使用binary_cross-entropy (这里使用的是多输出的情况)。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;1.4 &lt;span&gt;网上的例子&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py&quot; target=&quot;_blank&quot;&gt;https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/vae.py&quot; target=&quot;_blank&quot;&gt;https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/vae.py&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;第一个着重于实践，是使用keras来写的，后者是使用tensorflow写的，比较符合数学上的公式推导，我们来一起分析一下代码的重点部分&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;62&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; make_encoder(activation, latent_size, base_depth):
  &lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span&gt;Creates the encoder function.
  Args:
    activation: Activation function in hidden layers.
    latent_size: The dimensionality of the encoding.
    base_depth: The lowest depth for a layer.
  Returns:
    encoder: A `callable` mapping a `Tensor` of images to a
      `tfd.Distribution` instance over encodings.
  &lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span&gt;
  conv &lt;/span&gt;=&lt;span&gt; functools.partial(
      tf.keras.layers.Conv2D, padding&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;SAME&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, activation=&lt;span&gt;activation)

  encoder_net &lt;/span&gt;=&lt;span&gt; tf.keras.Sequential([
      conv(base_depth, &lt;/span&gt;5, 1&lt;span&gt;),
      conv(base_depth, &lt;/span&gt;5, 2&lt;span&gt;),
      conv(&lt;/span&gt;2 * base_depth, 5, 1&lt;span&gt;),
      conv(&lt;/span&gt;2 * base_depth, 5, 2&lt;span&gt;),
      conv(&lt;/span&gt;4 * latent_size, 7, padding=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;VALID&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
      tf.keras.layers.Flatten(),
      &lt;span&gt;tf.keras.layers.Dense(&lt;/span&gt;&lt;/span&gt;&lt;span&gt;2 * latent_size, activation=&lt;/span&gt;&lt;span&gt;&lt;span&gt;None),&lt;/span&gt;
  ])

  &lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; encoder(images):
    images &lt;/span&gt;= 2 * tf.cast(images, dtype=tf.float32) - 1&lt;span&gt;
    net &lt;/span&gt;=&lt;span&gt; encoder_net(images)
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; tfd.&lt;span&gt;MultivariateNormalDiag&lt;/span&gt;(
        loc&lt;/span&gt;=&lt;span&gt;net[..., :latent_size],
        scale_diag&lt;/span&gt;=tf.nn.softplus(net[..., latent_size:] +&lt;span&gt;
                                  _softplus_inverse(&lt;/span&gt;1.0&lt;span&gt;)),
        name&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;code&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)

  &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; encoder
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;首先是encoder，encoder部分的最后一层的大小是2*lant_size，其中在构建高斯分布的时候，0~ lant_size个输出作为了Mean，后lant_size个输出作为了方差。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;69&quot;&gt;
&lt;pre&gt;
&lt;span&gt;def&lt;/span&gt;&lt;span&gt; make_decoder(activation, latent_size, output_shape, base_depth):
  &lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span&gt;Creates the decoder function.
  Args:
    activation: Activation function in hidden layers.
    latent_size: Dimensionality of the encoding.
    output_shape: The output image shape.
    base_depth: Smallest depth for a layer.
  Returns:
    decoder: A `callable` mapping a `Tensor` of encodings to a
      `tfd.Distribution` instance over images.
  &lt;/span&gt;&lt;span&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span&gt;
  deconv &lt;/span&gt;=&lt;span&gt; functools.partial(
      tf.keras.layers.Conv2DTranspose, padding&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;SAME&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, activation=&lt;span&gt;activation)
  conv &lt;/span&gt;=&lt;span&gt; functools.partial(
      tf.keras.layers.Conv2D, padding&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;SAME&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, activation=&lt;span&gt;activation)

  decoder_net &lt;/span&gt;=&lt;span&gt; tf.keras.Sequential([
      deconv(&lt;/span&gt;2 * base_depth, 7, padding=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;VALID&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
      deconv(&lt;/span&gt;2 * base_depth, 5&lt;span&gt;),
      deconv(&lt;/span&gt;2 * base_depth, 5, 2&lt;span&gt;),
      deconv(base_depth, &lt;/span&gt;5&lt;span&gt;),
      deconv(base_depth, &lt;/span&gt;5, 2&lt;span&gt;),
      deconv(base_depth, &lt;/span&gt;5&lt;span&gt;),
      conv(output_shape[&lt;/span&gt;-1], 5, activation=&lt;span&gt;None),
  ])

  &lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; decoder(codes):
    original_shape &lt;/span&gt;=&lt;span&gt; tf.shape(codes)
    &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; Collapse the sample and batch dimension and convert to rank-4 tensor for&lt;/span&gt;
    &lt;span&gt;#&lt;/span&gt;&lt;span&gt; use with a convolutional decoder network.&lt;/span&gt;
    codes = tf.reshape(codes, (-1, 1, 1&lt;span&gt;, latent_size))
    logits &lt;/span&gt;=&lt;span&gt; decoder_net(codes)
    logits &lt;/span&gt;=&lt;span&gt; tf.reshape(
        logits, shape&lt;/span&gt;=tf.concat([original_shape[:-1], output_shape], axis=&lt;span&gt;0))
    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; tfd.&lt;span&gt;Independent&lt;/span&gt;(tfd.&lt;span&gt;Bernoulli&lt;/span&gt;(logits=&lt;span&gt;logits),
                           reinterpreted_batch_ndims&lt;/span&gt;=&lt;span&gt;len(output_shape),
                           name&lt;/span&gt;=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;image&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)

  &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; decoder
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在decoder中我们看到，输出都是彼此独立的，且是伯努利分布。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
approx_posterior =&lt;span&gt; encoder(features)//数据进行encoder处理，得到高斯分布的参数
approx_posterior_sample &lt;/span&gt;= approx_posterior.sample(params[&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;n_samples&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;])//从得到的高斯函数中抽样，并没有使用重参数的方法
decoder_likelihood &lt;/span&gt;=&lt;span&gt; decoder(approx_posterior_sample)//将抽样的样本输入给decoder，得到伯努利分布的输出
distortion &lt;/span&gt;= -&lt;span&gt;decoder_likelihood.log_prob(features)//得到-logp(x)

latent_prior &lt;/span&gt;= make_mixture_prior(params[&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;latent_size&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;],
                                    params[&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;mixture_components&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;])//得到一个标准的多维高斯分布，主要是为了计算KL的时候使用

&lt;/span&gt;&lt;span&gt;if&lt;/span&gt; params[&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;analytic_kl&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;]:
    rate &lt;/span&gt;=&lt;span&gt; tfd.kl_divergence(approx_posterior, latent_prior)
  &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;:
    rate &lt;/span&gt;=&lt;span&gt; (approx_posterior.log_prob(approx_posterior_sample)
            &lt;/span&gt;-&lt;span&gt; latent_prior.log_prob(approx_posterior_sample))//该方法是指另外一种衡量生成分布和高斯分布之间距离的形式
  avg_rate &lt;/span&gt;=&lt;span&gt; tf.reduce_mean(rate)
  tf.summary.scalar(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;rate&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, avg_rate)

  elbo_local &lt;/span&gt;= -(rate +&lt;span&gt; distortion)

  elbo &lt;/span&gt;=&lt;span&gt; tf.reduce_mean(elbo_local)
  loss &lt;/span&gt;= -elbo
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;上述则是loss函数的组成了，其中features就是原始输入。&lt;/p&gt;

&lt;p&gt;注：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;输入的数据是binarized_mnist，所以输出用的伯努利分布，伯努利之前的输出层并没有任何激活函数。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;2.VAE条件自编码&lt;/p&gt;
&lt;p&gt;3.使用VAE做异常检测&lt;/p&gt;
&lt;p&gt;4.使用VAE做聚类&lt;/p&gt;

&lt;p&gt;待续&lt;/p&gt;
</description>
<pubDate>Sun, 14 Oct 2018 14:40:00 +0000</pubDate>
<dc:creator>文字妖精</dc:creator>
<og:description>1.变分自编码 变分是数学上的概念，大致含义是寻求一个中间的函数，通过改变中间函数来查看目标函数的改变。变分推断是变分自编码的核心，那么变分推断是要解决的是什么问题?? 问题描述如下，假如我们有一批样</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/wzyj/p/9766655.html</dc:identifier>
</item>
<item>
<title>机器学习排序算法：RankNet to LambdaRank to LambdaMART - RL-Learning</title>
<link>http://www.cnblogs.com/genyuan/p/9788294.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/genyuan/p/9788294.html</guid>
<description>&lt;p&gt;&lt;span class=&quot;html-tag&quot;&gt;使用机器学习排序算法LambdaMART有一段时间了，但一直没有真正弄清楚算法中的所有细节。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;html-tag&quot;&gt;学习过程中细读了两篇不错的博文，推荐给大家：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/pinard/p/6140514.html&quot; target=&quot;_blank&quot;&gt;&lt;span class=&quot;html-tag&quot;&gt;梯度提升树(GBDT)原理小结&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/starzhou/article/details/52413366&quot; target=&quot;_blank&quot;&gt;&lt;span class=&quot;html-tag&quot;&gt;徐博From RankNet to LambdaRank to LambdaMART: An Overview&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;但经过一番搜寻之后发现，目前网上并没有一篇透彻讲解该算法的文章，所以希望这篇文章能够达到此目的。&lt;/p&gt;
&lt;p&gt;本文主要参考微软研究院2010年发表的文章&lt;a href=&quot;https://www.microsoft.com/en-us/research/publication/from-ranknet-to-lambdarank-to-lambdamart-an-overview/&quot; target=&quot;_blank&quot;&gt;From RankNet to LambdaRank to LambdaMART: An Overview&lt;/a&gt;$^1$，并结合自己的理解，试图将RankNet、LambdaRank和LambdaMART这三种算法的所有算法细节讲解透彻。&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;1. 概述&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;RankNet、LambdaRank和LambdaMART是三个关系非常紧密的机器学习排序算法。简而言之，RankNet是最基础，基于神经网络的排序算法；而LambdaRank在RankNet的基础上修改了梯度的计算方式，也即加入了lambda梯度；LambdaMART结合了lambda梯度和MART（另称为GBDT，梯度提升树）。这三种算法在工业界中应用广泛，在BAT等国内大厂和微软谷歌等世界互联网巨头内部都有大量应用，还曾经赢得“Yahoo！Learning To Rank Challenge(Track 1)&quot;的冠军。本人认为如果评选当今工业界中三种最重要的机器学习算法，以LambdaMART为首的集成学习算法肯定占有一席之地，另外两个分别是支持向量机和深度学习。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;2. RankNet&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.1 算法基础定义&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;RankNet解决如下搜索排序问题：给定query集合，每个query都对应着一个文档集合，如何对每个query返回排序后的文档集合。可以想象这样的场景：某位高考生在得知自己的成绩后，准备报考志愿。听说最近西湖大学办得不错，所以就想到网上搜搜关于西湖大学的资料。他打开一个搜索引擎，输入“西湖大学”四个字，然后点击“搜索”，页面从上到下显示了10条搜索结果，他认为排在上面的肯定比下面的相关，所以就开始从上往下一个个地浏览。所以RankNet的目标就是对所有query，都能将其返回的文档按照相关性进行排序。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;RankNet网络将输入query的特征向量$x\in \mathbb{R}^n$映射为一个实数$f(x) \in \mathbb{R}$。RankNet采用pairwise的方法进行模型训练。具体地，给定特定query下的两个文档$U_i$和$U_j$，其特征向量分别为$x_i$和$x_j$，经过RankNet进行前向计算得到对应的分数为$s_i=f(x_i)$和$s_j=f(x_j)$。用$U_i \rhd U_j$表示$U_i$比$U_j$排序更靠前（如对某个query来说，$U_i$被标记为“good”，$U_j$被标记为“bad”）。继而可以用下面的公式来表示$U_i$应该比$U_j$排序更靠前的概率：$$P_{ij} \equiv P(U_i \rhd U_j) \equiv \frac{1}{1+e^{-\sigma(s_i-s_j)}}$$这个概率实际上就是深度学习中经常使用的sigmoid函数，参数$\sigma$决定sigmoid函数的形状。对于特定的query，定义$S_{ij} \in \{0,\pm1\}$为文档$i$和文档$j$被标记的标签之间的关联，即&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;$$ S_{ij}=\left\{&lt;br/&gt;\begin{aligned}&lt;br/&gt;1&amp;amp;&amp;amp;     文档i比文档j更相关\\&lt;br/&gt;0&amp;amp;&amp;amp;    文档i和文档j相关性一致\\&lt;br/&gt;-1&amp;amp;&amp;amp;   文档j比文档i更相关&lt;br/&gt;\end{aligned}&lt;br/&gt;\right.&lt;br/&gt;$$&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;html-tag&quot;&gt;定义$\overline{P}_{ij}=\frac{1}{2}(1+S_{ij})$表示$U_i$应该比$U_j$排序更靠前的已知概率，则可以用交叉熵定义优化目标的损失函数：$$C=-\overline{P}_{ij}log{P_{ij}}-(1-\overline{P}_{ij})log(1-P_{ij})$$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;html-tag&quot;&gt;如果不太熟悉什么是交叉熵，可以参考宗成庆老师的《统计自然语言处理》2.2节“信息论基本概念”，里面将熵、联合熵、互信息、相对熵、交叉熵和困惑度等概念都讲得相当清楚。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;结合以上多个公式，可以改写损失函数$C$为：$$C=\frac{1}{2}(1-S_{ij})\sigma(s_i-s_j)+log(1+e^{-\sigma(s_i-s_j)})$$&lt;/p&gt;
&lt;p&gt;对于$S_{ij}=1$，$$C=log\left(1+e^{-\sigma(s_i-s_j)}\right)$$&lt;/p&gt;
&lt;p&gt;然而对于$S_{ij}=-1$，$$C=log\left(1+e^{-\sigma(s_j-s_i)}\right)$$&lt;/p&gt;
&lt;p&gt;可以看出损失函数$C$具有对称性，也即交换$i$和$j$的位置，损失函数的值不变。&lt;/p&gt;
&lt;p&gt;分析损失函数$C$的趋势发现，如果对文档$U_i$和$U_j$的打分可以正确地拟合标记的标签，则$C$趋向于0，否则$C$趋向于线性函数。具体地，假如$S_{ij}=1$，也即$U_i$应该比$U_j$排序高，如果$s_i&amp;gt;s_j$，则拟合的分数可以正确排序文档$i$和文档$j$，$$\lim \limits_{s_i-s_j\rightarrow\infty}C=\lim \limits_{s_i-s_j\rightarrow\infty}log\left(1+e^{-\sigma(s_i-s_j)}\right)=log1=0$$&lt;/p&gt;
&lt;p&gt;如果$s_i&amp;lt;s_j$，则拟合的分数不能正确排序文档$i$和文档$j$，$$\lim \limits_{s_i-s_j\rightarrow\infty}C=\lim \limits_{s_i-s_j\rightarrow\infty}log\left(1+e^{-\sigma(s_i-s_j)}\right)=log\left(e^{-\sigma(s_i-s_j)}\right)=-\sigma(s_i-s_j)$$&lt;/p&gt;
&lt;p&gt;利用神经网络对模型进行训练，目前最有效的方法就是反向传播算法。反向传播算法中最核心部分就是损失函数对模型参数的求导，然后可以使用下面的公式对模型参数进行迭代更新：&lt;/p&gt;
&lt;p&gt;$$w_k\rightarrow{w_k}-\eta\frac{\partial{C}}{\partial{w_k}}={w_k}-\eta\left(\frac{\partial{C}}{\partial{s_i}}\frac{\partial{s_i}}{\partial{w_k}}+\frac{\partial{C}}{\partial{s_j}}\frac{\partial{s_j}}{\partial{w_k}}\right)$$&lt;/p&gt;
&lt;p&gt;损失函数$C$对$s_i$和$s_j$的偏导数为：$$\frac{\partial{C}}{\partial{s_i}}=\sigma\left(\frac{1}{2}(1-S_{ij})-\frac{1}{1+e^{\sigma(s_i-s_j)}}\right)=-\frac{\partial{C}}{\partial{s_j}}$$&lt;/p&gt;
&lt;p&gt;$s_i$和$s_j$对$w_k$的偏导数可根据神经网络求偏导数的方式求得。求得了损失函数$C$对神经网络模型参数$w_k$的偏导数之后，就可以使用梯度下降算法对其更新。这里的学习率$\eta$也是一个正数，因为$\eta$需要满足下面的不等式：$$\delta C=\sum_{k}\frac{\partial{C}}{\partial{w_k}}\delta w_k=\sum_{k}\frac{\partial{C}}{\partial{w_k}}\left(-\eta\frac{\partial{C}}{\partial{w_k}}\right)=-\eta\sum_{k}\left(\frac{\partial{C}}{\partial{w_k}}\right)^2&amp;lt;0$$&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;2.2 RankNet分解形式：加速RankNet训练过程&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;2.1节中定义的RankNet，对于每一个文档对$(U_i$,$U_j)$都将计算损失函数对神经网络的参数$w_k$的偏导数，然后更新模型参数$w_k$。这样做的缺点在于，对模型参数更新慢，耗时长。所以本节讲解如何通过分解组合的方式加快这一训练过程。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;对于给定的文档对$U_i$和$U_j$，损失函数$C$对参数$w_k$的偏导数为：$$\frac{\partial{C}}{\partial{w_k}}=\frac{\partial{C}}{\partial{s_i}}\frac{\partial{s_i}}{\partial{w_k}}+\frac{\partial{C}}{\partial{s_j}}\frac{\partial{s_j}}{\partial{w_k}}=\sigma\left(\frac{1}{2}(1-S_{ij})-\frac{1}{1+e^{\sigma(s_i-s_j)}}\right)\left(\frac{\partial{s_i}}{\partial{w_k}}-\frac{\partial{s_j}}{\partial{w_k}}\right)=\lambda_{ij}\left(\frac{\partial{s_i}}{\partial{w_k}}-\frac{\partial{s_j}}{\partial{w_k}}\right)$$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;其中：$$\lambda_{ij}=\frac{\partial{C(s_i-s_j)}}{\partial{s_i}}=\sigma\left(\frac{1}{2}(1-S_{ij})-\frac{1}{1+e^{\sigma(s_i-s_j)}}\right)$$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;定义$I$为索引对$\{i,j\}$的集合，在不损失信息量的情况下，可以将集合$I$中的索引对都转换成满足$U_i \rhd U_j$的形式。另外集合$I$中的索引对还应该满足最多只出现一次的条件。在此基础上，累加权重参数$w_k$的更新量：$$\delta w_k=-\eta\sum_{(i,j) \in I}\left(\lambda_{ij}\frac{\partial{s_i}}{\partial{w_k}}-\lambda_{ij}\frac{\partial{s_j}}{\partial{w_k}}\right)=-\eta\sum_{i}\lambda_i\frac{\partial{s_j}}{\partial{w_k}}$$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;其中：$$\lambda_i=\sum_{j:\{i,j\} \in I}\lambda_{ij}-\sum_{j:\{j,i\} \in I}\lambda_{ij}$$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;通俗地说，$\lambda_i$就是集合$I$中所有$\{i,j\}$的$\lambda_{ij}$的和$-$集合$I$中所有$\{j,i\}$的$\lambda_{ij}$的和。如果还是不太明白，那看下面这个例子就明白了。集合$I=\{\{1,2\},\{2,3\},\{1,3\}\}$，则&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;$$\delta w_k=-\eta\sum_{\{i,j\}\in I}\left(\lambda_{ij}\frac{\partial{s_i}}{\partial{w_k}}-\lambda_{ij}\frac{\partial{s_j}}{\partial{w_k}}\right)=-\eta\left(\lambda_{12}\frac{\partial{s_1}}{\partial{w_k}}-\lambda_{12}\frac{\partial{s_2}}{\partial{w_k}}+\lambda_{13}\frac{\partial{s_1}}{\partial{w_k}}-\lambda_{13}\frac{\partial{s_3}}{\partial{w_k}}+\lambda_{23}\frac{\partial{s_2}}{\partial{w_k}}-\lambda_{23}\frac{\partial{s_3}}{\partial{w_k}}\right)=-\eta\left((\lambda_{12}+\lambda_{13})\frac{\partial{s_1}}{\partial{w_k}}+(\lambda_{23}-\lambda_{12})\frac{\partial{s_2}}{\partial{w_k}}+(-\lambda_{23}-\lambda_{13})\frac{\partial{s_3}}{\partial{w_k}}\right)$$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;于是可以得到$\lambda_1=\lambda_{12}+\lambda_{13}$，$\lambda_2=\lambda_{23}-\lambda_{12}$，$\lambda_3=-\lambda_{23}-\lambda_{13}$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;$\lambda_i$可以看成是作用在排序文档上的力，其正负代表了方向，长度代表了力的大小。最初的实现是对每个文档对，都计算一遍梯度并且更新神经网络的参数值，而这里则是将同一个query下的所有文档对进行叠加，然后更新一次网络的权重参数。这种分解组合形式实际上就是一种小批量学习方法，不仅可以加快迭代速度，还可以为后面使用非连续的梯度模型打下基础。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;2.3 模型训练过程示例&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;假设某个搜索系统中，文档用2维的特征向量表示。给定一个query下的三个文档向量分别为$x_1=(5,4.5)^T$，$x_2=(4,3.7)^T$和$x_3=(2,1.8)^T$，标记情况为$U_1 \rhd U_2 \rhd U_3$。为了简化训练过程，这里采用单层的神经网络模型，即输入层大小2，输出层大小为1，输出值为$f(x)=w_0+w_1x^{(1)}+w_2x^{(2)}$。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;初始化$\mathbf{w}=[0, -1, 1]$，控制sigmoid函数形状的$\sigma=0.1$，神经网络学习率$\eta=0.1$。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;根据以上初始值可以计算出$s_1=-0.5$，$s_2=-0.3$和$s_3=-0.2$，可见此时三个文档输出的分数并不满足标记$U_1 \rhd U_2 \rhd U_3$。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;计算$\lambda_1=\lambda_{12}+\lambda_{13}=-0.1012$，$\lambda_2=\lambda_{23}-\lambda_{12}=0.0002$，$\lambda_3=-\lambda_{23}-\lambda_{13}=-0.1010$。&lt;/p&gt;
&lt;p&gt;$\delta w_0=-\eta\left(\lambda_1\frac{\partial{s_1}}{\partial{w_0}}+\lambda_2\frac{\partial{s_2}}{\partial{w_0}}+\lambda_3\frac{\partial{s_3}}{\partial{w_0}}\right)=0$&lt;/p&gt;
&lt;p&gt;$\delta w_1=-\eta\left(\lambda_1\frac{\partial{s_1}}{\partial{w_1}}+\lambda_2\frac{\partial{s_2}}{\partial{w_1}}+\lambda_3\frac{\partial{s_3}}{\partial{w_1}}\right)=3.032$&lt;/p&gt;
&lt;p&gt;$\delta w_2=-\eta\left(\lambda_1\frac{\partial{s_1}}{\partial{w_2}}+\lambda_2\frac{\partial{s_2}}{\partial{w_2}}+\lambda_3\frac{\partial{s_3}}{\partial{w_2}}\right)=2.7286$&lt;/p&gt;
&lt;p&gt;更新网络权重:&lt;/p&gt;
&lt;p&gt;$w_0=w0+\delta w_0=0+0=0$&lt;/p&gt;
&lt;p&gt;$w_1=w1+\delta w_1=-1+3.032=2.032$&lt;/p&gt;
&lt;p&gt;$w_2=w2+\delta w_2=1+2.7286=3.7286$&lt;/p&gt;
&lt;p&gt;使用更新后的权重重新计算三个文档的分数，分别为$s_1=26.9387$，$s_2=21.92382$，$s_3=10.77548$。可见，经过一轮训练，单层神经网络的输出分数已经可以很好地拟合标记的标签。&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;3. 信息检索评分&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;信息检索研究者经常使用的排序质量评分指标有以下四种：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MRR&lt;/strong&gt;(Mean Reciprocal Rank)，平均倒数排名&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MAP&lt;/strong&gt;(Mean Average Precision)，平均正确率均值&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NDCG&lt;/strong&gt;(Normalized Discounted Cumulative Gain)，归一化折损累积增益&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ERR&lt;/strong&gt;(Expected Reciprocal Rank)，预期倒数排名&lt;/p&gt;
&lt;p&gt;&lt;span&gt;其中，MRR和MAP只能对二级的相关性（排序等级：相关和不相关）进行评分，而NDCG和ERR则可以对多级的相关性（排序等级&amp;gt;2）进行评分。NDCG和ERR的另一个优点是更关注排名靠前的文档，在计算分数时会给予排名靠前的文档更高的权重。但是这两种评分方式的缺点是函数不连续，不能进行求导，所以也就不能简单地将这两种评分方式加入到模型的损失函数中去。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.1 MRR&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;对于一个查询$i$来说，$rank_i$表示第一个相关结果的排序位置，所以：$$MRR(Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\frac{1}{rank_i}$$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;$|Q|$表示查询的数量，$MRR$表示搜索系统在查询集$Q$下的平均倒数排名值。$MRR$只能度量检索结果只有一个并且相关性等级只有相关和不相关两种的情况。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;举个简单例子：&lt;/span&gt;&lt;/p&gt;
&lt;table border=&quot;2&quot;&gt;&lt;tbody readability=&quot;3&quot;&gt;&lt;tr&gt;&lt;td&gt;查询语句&lt;/td&gt;
&lt;td&gt;查询结果&lt;/td&gt;
&lt;td&gt;正确结果&lt;/td&gt;
&lt;td&gt;排序位置&lt;/td&gt;
&lt;td&gt;排序倒数&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;机器学习&lt;/td&gt;
&lt;td&gt;快速排序，深度学习，并行计算&lt;/td&gt;
&lt;td&gt;深度学习&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;1/2&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;苹果手机&lt;/td&gt;
&lt;td&gt;小米手机，华为手机，iphone 7&lt;/td&gt;
&lt;td&gt;iphone 7&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;1/3&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;2&quot;&gt;&lt;td&gt;小米移动电源&lt;/td&gt;
&lt;td&gt;小米移动电源，华为充电器，苹果充电插头&lt;/td&gt;
&lt;td&gt;小米移动电源&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1/1&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt;所以$MRR(Q)=\frac{1/2+1/3+1}{3}=\frac{11}{18}$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt; 3.2 MAP&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;假定信息需求$q_j \in Q$对应的所有相关文档集合为${d_{1},...,d_{mj}}$，$R_{jk}$是返回结果中直到遇到$d_k$后其所在位置前（含$d_k$）的所有文档的集合，则定义$MAP(Q)^2$如下：&lt;/p&gt;
&lt;p&gt;$$MAP(Q)=\frac{1}{|Q|}\sum_{j=1}^{|Q|}\frac{1}{m_j}\sum_{k=1}^{m_j}Precision(R_{jk})$$&lt;/p&gt;
&lt;p&gt;实际上有两种计算$MAP$的方法或者说有两种$MAP(Q)$的定义方法。第一种方法是在每篇相关文档所在位置上求正确率然后平均（参考上面的公式）。另一种是在每个召回率水平上计算此时的插值正确率，然后求11点平均正确率，最后在不同查询之间计算平均。前者也称为非插值$MAP(Q)$。一般提$MAP(Q)$都指前者，所有这里也只讨论前者。&lt;/p&gt;
&lt;p&gt;如果对定义的公式不太理解，可以结合下面的例子进行理解。&lt;/p&gt;
&lt;table border=&quot;2&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot;&gt;查询1：机器学习&lt;/td&gt;
&lt;td colspan=&quot;2&quot;&gt;查询2：苹果手机&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;排序位置&lt;/td&gt;
&lt;td&gt;是否相关&lt;/td&gt;
&lt;td&gt;排序位置&lt;/td&gt;
&lt;td&gt;是否相关&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;针对上面检索的结果，可计算出&lt;/p&gt;
&lt;p&gt;$AP(1)=\left(1*1+1*1+2/3*0+2/4*0+3/5*1+3/6*0+3/7*0\right)/3=\frac{13}{15}$&lt;/p&gt;
&lt;p&gt;$AP(2)=\left(0*0+1/2*1+2/3*1+2/4*0+2/5*0+3/6*1+4/7*1\right)/4=\frac{47}{84}$&lt;/p&gt;
&lt;p&gt;$MAP(Q)=\frac{AP(1)+AP(2)}{2}=\frac{13/15+47/84}{2}=\frac{599}{420}$&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.3 NDCG&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;NDCG是基于前$k$个检索结果进行计算的。设$R(j,m)$是评价人员给出的文档$d$对查询$j$的相关性得分，那么有：&lt;/p&gt;
&lt;p&gt;$$NDCG(Q,k)=\frac{1}{|Q|}\sum_{j=1}^{|Q|}Z_{j,k}\sum_{m=1}^{k}\frac{2^{R(j,m)}-1}{log(1+m)}$$&lt;/p&gt;
&lt;p&gt;其中$$DCG_k=\sum_{m=1}^{k}\frac{2^{R(j,m)}-1}{log(1+m)}$$&lt;/p&gt;
&lt;p&gt;$Z_{j,k}$为第$j$个查询的DCG归一化因子，用于保证对于查询$j$最完美系统的$DCG_k$得分是1。$Z_{j,k}$也可以用$\frac{1}{IDCG_k}$表示。$m$是返回文档的位置。如果某查询返回的文档数$k'&amp;lt;k$，那么上述公式只需要计算到$k'$为止。&lt;/p&gt;
&lt;p&gt;修改上面简单的例子进行辅助理解：&lt;/p&gt;
&lt;table border=&quot;2&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot;&gt;查询1：机器学习&lt;/td&gt;
&lt;td colspan=&quot;2&quot;&gt;查询2：苹果手机&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;排序位置&lt;/td&gt;
&lt;td&gt;相关程度&lt;/td&gt;
&lt;td&gt;排序位置&lt;/td&gt;
&lt;td&gt;相关程度&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;对于查询1：机器学习:&lt;/p&gt;
&lt;p&gt;$$DCG_7=\sum_{m=1}^{7}\frac{2^{R(j,m)}-1}{log(1+m)}=21.421516$$&lt;/p&gt;
&lt;p&gt;查询1返回结果的最佳相关程度排序为：3,3,2,2,2,1,0，所以，$IDCG_7=22.686817$，$NDCG_7=\frac{DCG_7}{IDCG_7}=0.944227$&lt;/p&gt;
&lt;p&gt;对于查询2：苹果手机:&lt;/p&gt;
&lt;p&gt;$$DCG_7=\sum_{m=1}^{7}\frac{2^{R(j,m)}-1}{log(1+m)}=18.482089$$&lt;/p&gt;
&lt;p&gt;查询2返回结果的最佳相关程度排序为：3,3,2,2,2,1,1，所以，$IDCG_7=23.167716$，$NDCG_7=\frac{DCG_7}{IDCG_7}=0.797752$&lt;/p&gt;
&lt;p&gt;最后可得：$NDCG(Q,7)=(0.944227+0.797752)/2=0.870990$&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;3.4 ERR&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;$ERR^3$旨在改善NDCG计算当前结果时未考虑排在前面结果的影响的缺点，提出了一种基于级联模型的评价指标。首先定义：&lt;/p&gt;
&lt;p&gt;$$R(g)=\frac{2^g-1}{2^{g_{max}}}, g \in \{0,1,...,g_{max}\}$$&lt;/p&gt;
&lt;p&gt;$g$代表文档的得分级别，$g_{max}$代表最大的分数级别。&lt;/p&gt;
&lt;p&gt;于是定义：&lt;/p&gt;
&lt;p&gt;$$ERR=\sum_{r=1}^{n}\frac{1}{r}\prod_{i=1}^{r-1}(1-R_i)R_r$$&lt;/p&gt;
&lt;p&gt;展开公式如下：&lt;/p&gt;
&lt;p&gt;$$ERR=R_1+\frac{1}{2}(1-R_1)R_2+\frac{1}{3}(1-R_1)(1-R_2)R_3+...+\frac{1}{n}(1-R_1)(1-R_2)...(1-R_{n-1})R_n$$ &lt;/p&gt;
&lt;p&gt;举例来说($g_{max}=3$):&lt;/p&gt;
&lt;table border=&quot;2&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot;&gt;查询：机器学习&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;排序位置&lt;/td&gt;
&lt;td&gt;相关程度&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;&lt;span&gt;$R_1=0.875,R2=0.375,R_3=0.875,R_4=0.125$&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;$ERR=0.875+\frac{1}{2}*0.125*0.375+\frac{1}{3}*0.125*0.625*0.875+\frac{1}{4}*0.125*0.625*0.125*0.125=0.913391$&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;4. LambdaRank&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;4.1 为什么需要LambdaRank&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;先看一张论文原文中的图，如下所示。这是一组用二元等级相关性进行排序的链接地址，其中浅灰色代表链接与query不相关，深蓝色代表链接与query相关。 对于左边来说，总的pairwise误差为13，而右边总的pairwise误差为11。但是大多数情况下我们更期望能得到左边的结果。这说明最基本的pairwise误差计算方式并不能很好地模拟用户对搜索引擎的期望。右边黑色箭头代表RankNet计算出的梯度大小，红色箭头是期望的梯度大小。NDCG和ERR在计算误差时，排名越靠前权重越大，可以很好地解决RankNet计算误差时的缺点。但是NDCG和ERR均是不可导的函数，如何加入到RankNet的梯度计算中去？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img title=&quot;图1&quot; src=&quot;https://img2018.cnblogs.com/blog/436630/201810/436630-20181008202412844-1605451333.png&quot; alt=&quot;图1&quot;/&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;4.2  LambdaRank定义&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;RankNet中的$\lambda_{ij}$可以看成是$U_i$和$U_j$中间的作用力，如果$U_i \rhd U_j$，则$U_j$会给予$U_i$向上的大小为$|\lambda_{ij}$的推动力，而对应地$U_i$会给予$U_j$向下的大小为$|\lambda_{ij}$的推动力。如何将NDCG等类似更关注排名靠前的搜索结果的评价指标加入到排序结果之间的推动力中去呢？实验表明，直接用$|\Delta_{NDCG}|$乘以原来的$\lambda_{ij}$就可以得到很好的效果，也即：&lt;/p&gt;
&lt;p&gt;$$\lambda_{ij}=\frac{\partial{C(s_i-s_j)}}{\partial{s_i}}=\frac{-\sigma}{1+e^{\sigma(s_i-s_j)}}|\Delta_{NDCG}|$$&lt;/p&gt;
&lt;p&gt;其中$|\Delta_{NDCG}|$是交换排序结果$U_i$和$U_j$得到的NDCG差值。NDCG倾向于将排名高并且相关性高的文档更快地向上推动，而排名地而且相关性较低的文档较慢地向上推动。&lt;/p&gt;
&lt;p&gt;另外还可以将$|\Delta_{NDCG}|$替换成其他的评价指标。&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;5. LambdaMART&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;5.1 MART&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;LambdaMART是MART和LambdaRank的结合，所以要学习LambdaMART首先得了解什么是MART。MART是Multiple Additive Regession Tree的简称，很多时候又称为GBDT（Gradient Boosting Decision Tree）。MART是一种集成学习算法，不同于经典的集成学习算法Adaboost利用前一轮学习器的误差来更新下一轮学习的样本权重，MART每次都拟合上一轮分类器产生的残差。举个例子便于理解，比如一个人的年龄是50岁，第一棵树拟合的结果是35岁，第一轮的残差为15岁；然后第二棵数拟合的结果是10岁，两棵树相加总的拟合结果是45岁，第二轮的残差为5岁；第三棵数拟合的结果为2岁，三棵树相加拟合的结果是47岁，第三轮的残差是3岁......只要如此不断地进行下去，拟合结果就可以达到50岁，拟合残差的过程就是训练数据的过程。&lt;/p&gt;
&lt;p&gt;对于一个给定的数据集$\{x_i,y_i\}, i=1,2,...,m$，其中特征向量$x_i \in \mathbb{R}^n$，标签$y_i \in \mathbb{R}$，可以用$x_{ij}, j=1,2,...,d来代表x_i的第j个特征值$。对于一个典型的回归决策树问题，需要遍历所有特征$j$的全部阈值$t$，找到最优的$j$和$t$使下面的等式最小化：&lt;/p&gt;
&lt;p&gt;$$S_j=\sum_{i \in L}(y_i-\mu_L)^2+\sum_{i \in R}(y_i-\mu_R)^2$$&lt;/p&gt;
&lt;p&gt;其中$x_{ij} \leq t$的所有样本落入左子树$L$中，其中$x_{ij} &amp;gt; t$的所有样本落入右子树$R$中，$\mu_L(\mu_R)$表示左子树（右子树）所有样例标签值的均值。如果这就是一棵最简单的拥有一个根节点、两个叶子节点的二叉回归树，那么只需要根据最优阈值切分为左右子树，并且分别计算左右子树的值$\gamma_l,l=1,2$即可。如果将划分子树的过程继续进行$L-1$次即可得到一棵包含$L$个叶子节点的回归树。&lt;/p&gt;
&lt;p&gt;上面公式使用最小二乘法计算拟合误差，所以通过上面方法得到的模型又称为最小二乘回归树。其实不管误差的计算方式如何，我们都可以拟合出相应的回归树，唯一的区别是梯度的计算不同而已。&lt;/p&gt;
&lt;p&gt;MART使用线性组合的方式将拟合的树结合起来，作为最后的输出：&lt;/p&gt;
&lt;p&gt;$$F_n(x)=\sum_{i=1}^{N}\alpha_if_i(x)$$&lt;/p&gt;
&lt;p&gt;$f_i(x)$是单棵回归树函数，$\alpha_i$是第$i$棵回归树的权重。&lt;/p&gt;
&lt;p&gt;在这里我们需要弄清楚为什么拟合残差就能不断减少拟合误差。假设拟合误差$C$是拟合函数$F_n$的函数$C(F_n)$。那么：&lt;/p&gt;
&lt;p&gt;$$\delta C \approx \frac{\partial{C(F_n)}}{\partial{F_n}}\delta F_n$$&lt;/p&gt;
&lt;p&gt;如果取$\delta F_n=-\eta \frac{\partial{C}}{\partial{F_n}}$，就可以得到$\delta C&amp;lt;0$。其中$\eta$是学习率，为正实数。所以只要函数$F_n$拟合误差函数的负梯度就可以不断降低拟合误差的值。&lt;/p&gt;
&lt;p&gt;设标签向量$y=[y_1,y_2,...,y_m]^T$，如果用最小二乘的方式表示拟合误差，则：$$C=\frac{1}{2}(F_n-y)^2$$&lt;/p&gt;
&lt;p&gt;那么$\delta F_n=-\eta \frac{\partial{C}}{\partial{F_n}}=-\eta (F_n-y)$。这其实就是上面提到的残差，所以拟合残差可以不断减少拟合误差。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;5.2 逻辑回归+MART进行二分类&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;了解了MART之后，下面举一个MART实际应用的例子：使用MART和逻辑回归进行二分类。用于分类的样本$x_i \in \mathbb{R}^n$，标签$y_i \in \{\pm1\}$，拟合函数$F(x)$。为了简化表示，我们表示条件概率如下：&lt;/p&gt;
&lt;p&gt;$$P_+ \equiv P(y=1|x)$$&lt;/p&gt;
&lt;p&gt;$$P_- \equiv P(y=-1|x)$$&lt;/p&gt;
&lt;p&gt;用交叉熵表示损失函数：$$L(y,F)=-ylog(P_+)-(1-y)log(P_-)$$&lt;/p&gt;
&lt;p&gt;逻辑回归使用对数机率（属于正例概率/属于负例概率）进行建模，&lt;/p&gt;
&lt;p&gt;$$F_n(x)=\frac{1}{2}log(\frac{P_+}{P_-})$$&lt;/p&gt;
&lt;p&gt;$$P_+=\frac{1}{1+e^{-2\sigma F_n(x)}}$$&lt;/p&gt;
&lt;p&gt;$$P_-=1-P_+=\frac{1}{1+e^{2\sigma F_n(x)}}$$&lt;/p&gt;
&lt;p&gt;将$P_+$和$P_-$带入$L(y,F)$中，得到：&lt;/p&gt;
&lt;p&gt;$$L(y,F_n)=log(1+e^{-2y\sigma F_n})$$&lt;/p&gt;
&lt;p&gt;$R_{jm}$表示落入第$m$棵树的第$j$个叶子节点中的样例集合，可以通过下式对该叶子节点的值进行优化：&lt;/p&gt;
&lt;p&gt;$$\gamma_{jm}=arg\min_{\gamma}\sum_{x_i \in R_{jm}}\log\left(1+e^{-2\sigma y_i\left(F_{m-1}\,\,\left({x_i}\right)+\gamma\right)\,}\right)$$&lt;/p&gt;
&lt;p&gt;上式可以使用Newton-Raphson方法按照下面的公式进行迭代求解：&lt;/p&gt;
&lt;p&gt;$$\gamma_{n+1}=\gamma_{n}-\frac{g'(\gamma_n)}{g''(\gamma_n)}$$&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;5.3 LambdaMART基本定义&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;LambdaMART基于MART，优化$\lambda$梯度。根据上面的定义，对于任意$U_i$和$U_j$，有：&lt;/p&gt;
&lt;p&gt;$$\lambda_{ij}=\frac{\partial{C(s_i-s_j)}}{\partial{s_i}}=\frac{-\sigma |\Delta_{Z_{ij}}|}{1+e^{\sigma(s_i-s_j)}}$$&lt;/p&gt;
&lt;p&gt;$|\Delta_{Z_{ij}}|$表示交换$U_i$和$U_j$的位置产生的评价指标差值，$Z$可以是$NDCG$或者$ERR$等。对于特定$U_i$，累加其他所有排序项的影响，得到：&lt;/p&gt;
&lt;p&gt;$$\lambda_i=\sum_{j:\{i,j\} \in I}\lambda_{ij}-\sum_{j:\{j,i\} \in I}\lambda_{ij}$$&lt;/p&gt;
&lt;p&gt; 为了简化表示：&lt;/p&gt;
&lt;p&gt;$$\sum_{\{i,j\}\rightleftharpoons I}=\sum_{j:\{i,j\} \in I}\lambda_{ij}-\sum_{j:\{j,i\} \in I}\lambda_{ij}$$&lt;/p&gt;
&lt;p&gt;于是我们可以更新损失函数：&lt;/p&gt;
&lt;p&gt;$$\frac{\partial{C}}{\partial{s_i}} = \sum_{j:\{i,j\} \in I} \frac{-\sigma |\Delta_{Z_{ij}}|}{1+e^{\sigma(s_i-s_j)}} = \sum_{j:\{i,j\} \in I} -\sigma |\Delta_{Z_{ij}}| \rho_{ij}$$&lt;/p&gt;
&lt;p&gt;其中，我们定义：&lt;/p&gt;
&lt;p&gt;$$\rho_{ij}=\frac{1}{1+e^{\sigma(s_i-s_j)}}=\frac{-\lambda_{ij}}{\sigma |\Delta_{Z_{ij}}|}$$&lt;/p&gt;
&lt;p&gt;然后可以得到：&lt;/p&gt;
&lt;p&gt;$$\frac{\partial{^2C}}{\partial{s_i^2}}=\sum_{\{i,j\}\rightleftharpoons I}\sigma^2|\Delta_{Z_{ij}}|\rho{ij}(1-\rho_{ij})$$&lt;/p&gt;
&lt;p&gt;所以我们可以用下面的公式计算第$k$棵树的第$k$个叶子节点上的值：&lt;/p&gt;
&lt;p&gt;$$\gamma_{km}=\frac{\sum_{x_i \in R_{km}}\frac{\partial{C}}{\partial{s_i}}}{\sum_{x_i \in R_{km}}\frac{\partial{^2C}}{\partial{s_i^2}}}=\frac{-\sum_{x_i \in R_{km}}\sum_{\{i,j\}\rightleftharpoons I}|\Delta_{Z_{ij}}|\rho_{ij}}{\sum_{x_i \in R_{km}}\sum_{\{i,j\}\rightleftharpoons I}|\Delta_{Z_{ij}}|\rho_{ij}(1-\rho_{ij})}$$&lt;/p&gt;
&lt;p&gt;所以总结&lt;strong&gt;LambdaMART&lt;/strong&gt;算法如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/436630/201810/436630-20181014200717864-340780855.png&quot; alt=&quot;&quot; width=&quot;845&quot; height=&quot;335&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;6. 参考文献&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;1. Christopher J.C. Burges. From RankNet to LambdaRank to LambdaMART: An Overview. Microsoft Research Technical Report MSR-TR-010-82.&lt;/p&gt;
&lt;p&gt;2. Chrisopher D.Manning, Prabhakar Raghavan, Hinrich Schutze著, 王斌译. Introduction to Information Retrieval, 8.4 有序检索结果的评价方法, 2017年10月北京第11次印刷.&lt;/p&gt;
&lt;p&gt;3. Olivier Chapelle, Ya Zhang, Pierre Grinspan. Expected Recipocal Rank for Graded Relevance. CIKM 2009.&lt;/p&gt;
</description>
<pubDate>Sun, 14 Oct 2018 14:01:00 +0000</pubDate>
<dc:creator>RL-Learning</dc:creator>
<og:description>RankNet、LambdaRank和LambdaMART是三个关系非常紧密的机器学习排序算法。简而言之，RankNet是最基础，基于神经网络的排序算法；而LambdaRank在RankNet的基础上</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/genyuan/p/9788294.html</dc:identifier>
</item>
<item>
<title>Effective Java 第三版——48. 谨慎使用流并行 - 林本托</title>
<link>http://www.cnblogs.com/IcanFixIt/p/9788231.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/IcanFixIt/p/9788231.html</guid>
<description>&lt;blockquote readability=&quot;8.2216981132075&quot;&gt;
&lt;p&gt;Tips&lt;br/&gt;《Effective Java, Third Edition》一书英文版已经出版，这本书的第二版想必很多人都读过，号称Java四大名著之一，不过第二版2009年出版，到现在已经将近8年的时间，但随着Java 6，7，8，甚至9的发布，Java语言发生了深刻的变化。&lt;br/&gt;在这里第一时间翻译成中文版。供大家学习分享之用。&lt;br/&gt;书中的源代码地址：&lt;a href=&quot;https://github.com/jbloch/effective-java-3e-source-code&quot; class=&quot;uri&quot;&gt;https://github.com/jbloch/effective-java-3e-source-code&lt;/a&gt;&lt;br/&gt;注意，书中的有些代码里方法是基于Java 9 API中的，所以JDK 最好下载 JDK 9以上的版本。但是Java 9 只是一个过渡版本，所以建议安装JDK 10。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/4366140-8966e457a14bc8b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;Effective Java, Third Edition&quot;/&gt;&lt;/p&gt;

&lt;p&gt;在主流语言中，Java一直处于提供简化并发编程任务的工具的最前沿。 当Java于1996年发布时，它内置了对线程的支持，包括同步和wait / notify机制。 Java 5引入了&lt;code&gt;java.util.concurrent&lt;/code&gt;类库，带有并发集合和执行器框架。 Java 7引入了fork-join包，这是一个用于并行分解的高性能框架。 Java 8引入了流，可以通过对&lt;code&gt;parallel&lt;/code&gt;方法的单个调用来并行化。 用Java编写并发程序变得越来越容易，但编写正确快速的并发程序还像以前一样困难。 安全和活跃度违规（liveness violation）是并发编程中的事实，并行流管道也不例外。&lt;/p&gt;
&lt;p&gt;考虑条目 45中的程序：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;// Stream-based program to generate the first 20 Mersenne primes

public static void main(String[] args) {

    primes().map(p -&amp;gt; TWO.pow(p.intValueExact()).subtract(ONE))

        .filter(mersenne -&amp;gt; mersenne.isProbablePrime(50))

        .limit(20)

        .forEach(System.out::println);

}

static Stream&amp;lt;BigInteger&amp;gt; primes() {

    return Stream.iterate(TWO, BigInteger::nextProbablePrime);

}
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在我的机器上，这个程序立即开始打印素数，运行到完成需要12.5秒。假设我天真地尝试通过向流管道中添加一个到&lt;code&gt;parallel()&lt;/code&gt;的调用来加快速度。你认为它的表现会怎样?它会快几个百分点吗?慢几个百分点?遗憾的是，它不会打印任何东西，但是CPU使用率会飙升到90%，并且会无限期地停留在那里(liveness failure:活性失败)。这个程序可能最终会终止，但我不愿意去等待；半小时后我强行阻止了它。&lt;/p&gt;
&lt;p&gt;这里发生了什么？简而言之，流类库不知道如何并行化此管道并且启发式失败（heuristics fail.）。即使在最好的情况下，&lt;strong&gt;如果源来自&lt;code&gt;Stream.iterate&lt;/code&gt;方法，或者使用中间操作&lt;code&gt;limit&lt;/code&gt;方法，并行化管道也不太可能提高其性能&lt;/strong&gt;。这个管道必须应对这两个问题。更糟糕的是，默认的并行策略处理不可预测性的&lt;code&gt;limit&lt;/code&gt;方法，假设在处理一些额外的元素和丢弃任何不必要的结果时没有害处。在这种情况下，找到每个梅森素数的时间大约是找到上一个素数的两倍。因此，计算单个额外元素的成本大致等于计算所有先前元素组合的成本，并且这种无害的管道使自动并行化算法瘫痪。这个故事的寓意很简单：不要无差别地并行化流管道（stream pipelines）。性能后果可能是灾难性的。&lt;/p&gt;
&lt;p&gt;通常，&lt;strong&gt;并行性带来的性能收益在ArrayList、HashMap、HashSet和ConcurrentHashMap实例、数组、int类型范围和long类型的范围的流上最好&lt;/strong&gt;。这些数据结构的共同之处在于，它们都可以精确而廉价地分割成任意大小的子程序，这使得在并行线程之间划分工作变得很容易。用于执行此任务的流泪库使用的抽象是&lt;code&gt;spliterator&lt;/code&gt;，它由&lt;code&gt;spliterator&lt;/code&gt;方法在Stream和Iterable上返回。&lt;/p&gt;
&lt;p&gt;所有这些数据结构的共同点的另一个重要因素是它们在顺序处理时提供了从良好到极好的引用位置（ locality of reference）：顺序元素引用在存储器中存储在一块。 这些引用所引用的对象在存储器中可能彼此不接近，这降低了引用局部性。 对于并行化批量操作而言，引用位置非常重要：没有它，线程大部分时间都处于空闲状态，等待数据从内存传输到处理器的缓存中。 具有最佳引用位置的数据结构是基本类型的数组，因为数据本身连续存储在存储器中。&lt;/p&gt;
&lt;p&gt;流管道终端操作的性质也会影响并行执行的有效性。 如果与管道的整体工作相比，在终端操作中完成了大量的工作，并且这种操作本质上是连续的，那么并行化管道的有效性将是有限的。 并行性的最佳终操作是缩减（reductions），即使用流的&lt;code&gt;reduce&lt;/code&gt;方法组合管道中出现的所有元素，或者预先打包的reduce(如min、max、count和sum)。短路操作&lt;code&gt;anyMatch&lt;/code&gt;、&lt;code&gt;allMatch&lt;/code&gt;和&lt;code&gt;noneMatch&lt;/code&gt;也可以支持并行性。由Stream的&lt;code&gt;collect&lt;/code&gt;方法执行的操作，称为可变缩减（mutable reductions），不适合并行性，因为组合集合的开销非常大。&lt;/p&gt;
&lt;p&gt;如果编写自己的Stream，Iterable或Collection实现，并且希望获得良好的并行性能，则必须重写&lt;code&gt;spliterator方&lt;/code&gt;法并广泛测试生成的流的并行性能。 编写高质量的spliterator很困难，超出了本书的范围。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;并行化一个流不仅会导致糟糕的性能，包括活性失败（liveness failures）;它会导致不正确的结果和不可预知的行为(安全故障)&lt;/strong&gt;。使用映射器（mappers），过滤器（filters）和其他程序员提供的不符合其规范的功能对象的管道并行化可能会导致安全故障。 Stream规范对这些功能对象提出了严格的要求。 例如，传递给Stream的&lt;code&gt;reduce&lt;/code&gt;方法操作的累加器（accumulator）和组合器（combiner）函数必须是关联的，非干扰的和无状态的。 如果违反了这些要求（其中一些在第46项中讨论过），但按顺序运行你的管道，则可能会产生正确的结果; 如果将它并行化，它可能会失败，也许是灾难性的。&lt;/p&gt;
&lt;p&gt;沿着这些思路，值得注意的是，即使并行的梅森素数程序已经运行完成，它也不会以正确的(升序的)顺序打印素数。为了保持顺序版本显示的顺序，必须将&lt;code&gt;forEach&lt;/code&gt;终端操作替换为&lt;code&gt;forEachOrdered&lt;/code&gt;操作，它保证以遇出现顺序（encounter order）遍历并行流。&lt;/p&gt;
&lt;p&gt;即使假设正在使用一个高效的可拆分的源流、一个可并行化的或廉价的终端操作以及非干扰的函数对象，也无法从并行化中获得良好的加速效果，除非管道做了足够的实际工作来抵消与并行性相关的成本。作为一个非常粗略的估计，流中的元素数量乘以每个元素执行的代码行数应该至少是100,000 [Lea14]。&lt;/p&gt;
&lt;p&gt;重要的是要记住并行化流是严格的性能优化。 与任何优化一样，必须在更改之前和之后测试性能，以确保它值得做（第67项）。 理想情况下，应该在实际的系统设置中执行测试。 通常，程序中的所有并行流管道都在公共fork-join池中运行。 单个行为不当的管道可能会损害系统中不相关部分的其他行为。&lt;/p&gt;
&lt;p&gt;如果在并行化流管道时，这种可能性对你不利，那是因为它们确实存在。一个认识的人，他维护一个数百万行代码库，大量使用流，他发现只有少数几个地方并行流是有效的。这并不意味着应该避免并行化流。&lt;strong&gt;在适当的情况下，只需向流管道添加一个&lt;code&gt;parallel&lt;/code&gt;方法调用，就可以实现处理器内核数量的近似线性加速&lt;/strong&gt;。某些领域，如机器学习和数据处理，特别适合这些加速。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;作为并行性有效的流管道的简单示例，请考虑此函数来计算π(n)，素数小于或等于n：
// Prime-counting stream pipeline - benefits from parallelization
static long pi(long n) {
    return LongStream.rangeClosed(2, n)
        .mapToObj(BigInteger::valueOf)
        .filter(i -&amp;gt; i.isProbablePrime(50))
        .count();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在我的机器上，使用此功能计算π（10&lt;sup&gt;8&lt;/sup&gt;）需要31秒。 只需添加&lt;code&gt;parallel()&lt;/code&gt;方法调用即可将时间缩短为9.2秒：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;// Prime-counting stream pipeline - parallel version
static long pi(long n) {
    return LongStream.rangeClosed(2, n)
        .parallel()
        .mapToObj(BigInteger::valueOf)
        .filter(i -&amp;gt; i.isProbablePrime(50))
        .count();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;换句话说，在我的四核计算机上，并行计算速度提高了3.7倍。值得注意的是，这不是你在实践中如何计算π(n)为n的值。还有更有效的算法，特别是Lehmer’s formula。&lt;/p&gt;
&lt;p&gt;如果要并行化随机数流，请从&lt;code&gt;SplittableRandom&lt;/code&gt;实例开始，而不是&lt;code&gt;ThreadLocalRandom&lt;/code&gt;（或基本上过时的&lt;code&gt;Random&lt;/code&gt;）。 &lt;code&gt;SplittableRandom&lt;/code&gt;专为此用途而设计，具有线性加速的潜力。&lt;code&gt;ThreadLocalRandom&lt;/code&gt;设计用于单个线程，并将自身适应作为并行流源，但不会像&lt;code&gt;SplittableRandom&lt;/code&gt;一样快。Random实例在每个操作上进行同步，因此会导致过度的并行杀死争用（ parallelism-killing contention）。&lt;/p&gt;
&lt;p&gt;总之，甚至不要尝试并行化流管道，除非你有充分的理由相信它将保持计算的正确性并提高其速度。不恰当地并行化流的代价可能是程序失败或性能灾难。如果您认为并行性是合理的，那么请确保您的代码在并行运行时保持正确，并在实际情况下进行仔细的性能度量。如果您的代码是正确的，并且这些实验证实了您对性能提高的怀疑，那么并且只有这样才能在生产代码中并行化流。&lt;/p&gt;
</description>
<pubDate>Sun, 14 Oct 2018 13:51:00 +0000</pubDate>
<dc:creator>林本托</dc:creator>
<og:description>Tips 《Effective Java, Third Edition》一书英文版已经出版，这本书的第二版想必很多人都读过，号称Java四大名著之一，不过第二版2009年出版，到现在已经将近8年的时间</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/IcanFixIt/p/9788231.html</dc:identifier>
</item>
</channel>
</rss>