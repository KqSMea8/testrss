<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>跟浩哥学自动化测试Selenium -- Selenium简介 (1) - JackTester</title>
<link>http://www.cnblogs.com/jacktest/p/9074939.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/jacktest/p/9074939.html</guid>
<description>&lt;p&gt;&lt;span&gt;    Selenium 是一款开源的web自动化测试工具，用来模拟对浏览器的操作(主要是对页面元素的操作)，简单来讲，其实就是一个jar包。&lt;/span&gt;&lt;span&gt;Selenium早期的版本比如1.0市场占有率很小，主要原因都是因为1.0采用的是js注入的方式，带来得问题比如跨域的问题，安全性的问题。2.0版本已经解决这个问题，主要采用浏览器的原生组件来操作浏览器，所以针对不同的浏览器需要相应的 native component 把WebDriver 的API 转化成浏览器的 native invoke。3.0 版本的主要变化是支持w3c。至于各个版本之间到底有什么不同，如果有兴趣可以参考Selenium官方网站。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;    版本选择：不管你是初学者还是之前了解过，还是建议直接使用Selenium3.0以上版本，必定新的版本稳定性，性能，兼容性更好一些&lt;/span&gt;&lt;span&gt;(除了Firefox需要显示设置 geckodriver.exe之外几乎和以前没什么不同，当然2.0也是需要驱动的只不过Selenium内部帮你设置了)&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;span&gt;下载地址: &lt;a href=&quot;https://www.seleniumhq.org/download/&quot; target=&quot;_blank&quot;&gt;https://www.seleniumhq.org/download/&lt;/a&gt; 选择 Selenium Standalone Server下的 Download version 链接即可，目前 最新版本 3.12.0 (下载记得用代理)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;驱动：同页面下有相应的浏览器驱动，例如火狐的 GeckoDriver，google的 Chrome Driver ，注意IE 驱动分为32位和64位版本&lt;/span&gt;&lt;span&gt; &lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;span&gt;    &lt;/span&gt;&lt;span&gt;版本升级：如果浏览器提示你升级，建议等一等，因为有可能相应的Selenium驱动版本还未更新，老的驱动在新版本的浏览器执行时可能会有兼容问题，这种问题几乎无法解决，所以升级要慎重(不说了，全是泪)，建议等2-3周再更新并下载新的驱动。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;    对于无法使用代理的同学，提供另一个种方式，也是比较推荐的方式，如果你是java的项目，可以搭建maven项目(如何搭建不在详细讲述，可自行百度，非常简单，python 程序请参考自动化教程之Selenium python版本)。简单分为如下三个步骤：&lt;/span&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;span&gt;打开maven 仓库地址：&lt;a href=&quot;https://mvnrepository.com/&quot; target=&quot;_blank&quot;&gt;https://mvnrepository.com/&lt;/a&gt;，在搜索栏中输入Selenium，点击&quot;search&quot;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;点击第一个黑体链接 Selenium Java，点击最新版本3.12.0&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;拷贝页面中间 dependency部分到你的项目的pom依赖中(maven会自行下载jar到你的maven仓库中)，下载成功后你的pom中dependency依赖会变成黑色(表示下载成功，否则为红色)，且在项目的External Libraries中会显示有关Selenium的jar，由于网速不同，下载有时会稍慢，可耐心等待，如下图：&lt;/span&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;&lt;span&gt;    &lt;img src=&quot;https://images2018.cnblogs.com/blog/1372635/201805/1372635-20180523224035776-651209432.png&quot; alt=&quot;&quot;/&gt;下载成功&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;    &lt;img src=&quot;https://images2018.cnblogs.com/blog/1372635/201805/1372635-20180523224322986-21000869.png&quot; alt=&quot;&quot; width=&quot;454&quot; height=&quot;221&quot;/&gt;External Libraries显示的jar&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; 　　&lt;span&gt;Selenium 驱动无法通过Maven来下载，必须使用代理，所以需要驱动的同学可以联系我，到时候发给大家。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;   当Selenium的jar和驱动都下载并配置完成后，我们就可以使用 Selenium 的api 进行第一个脚本了。什么，不知道怎么配置，没关系，详见 Selenium 教程第二篇《我的第一个Demo》。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;   转载请注明作者与出处，谢谢！&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 01 Jul 2018 15:38:00 +0000</pubDate>
<dc:creator>JackTester</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/jacktest/p/9074939.html</dc:identifier>
</item>
<item>
<title>数据准备:变量筛选-理论篇 - hbsygfz</title>
<link>http://www.cnblogs.com/hbsygfz/p/9251695.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/hbsygfz/p/9251695.html</guid>
<description>&lt;blockquote readability=&quot;7.4285714285714&quot;&gt;
&lt;p&gt;&lt;span&gt;在上一篇文章&lt;a href=&quot;http://www.cnblogs.com/hbsygfz/p/9026998.html&quot;&gt;《数据准备&amp;lt;3&amp;gt;：数据预处理》&lt;/a&gt;中，我们提到降维主要包括两种方式：基于特征选择的降维和基于维度转换的降维，其中基于特征选择的降维通俗的讲就是特征筛选或者变量筛选，是指从多个特征（变量）中筛选出显著的特征（变量），在分类预测问题中，就是筛选出对目标变量有预测能力的特征（变量）。本篇主要介绍特征（变量）筛选的基本思路与方法，为简洁，下文均使用“变量筛选”指代。&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;变量筛选主要有&lt;strong&gt;三种方法&lt;/strong&gt;：&lt;strong&gt;基于经验的方法（比如专家法）、基于统计的方法（比如信息增益、区分度）和基于机器学习的方法（比如决策树算法）&lt;/strong&gt;。下面将分别具体介绍：&lt;/p&gt;
&lt;h2 id=&quot;基于经验的方法&quot;&gt;1.基于经验的方法&lt;/h2&gt;
&lt;p&gt;根据业务专家或者数据专家的以往经验、实际数据情况、业务理解程度等进行综合考虑。业务专家依靠的是业务背景，从众多维度变量中选择对结果影响较大的变量；而数据专家依靠的则是数据工作经验，基于数据的基本特征以及对后期数据处理和建模的影响来选择或者排除，比如删除缺失值较多的变量。&lt;/p&gt;
&lt;h2 id=&quot;基于统计的方法&quot;&gt;2.基于统计的方法&lt;/h2&gt;
&lt;p&gt;构建统计指标，对变量的预测能力进行度量，选择其中预测能力较大的变量。&lt;br/&gt;首先，从&lt;strong&gt;香农的信息熵&lt;/strong&gt;说起。&lt;br/&gt;香农（Claude Elwood Shannon，1916年4月30日—2001年2月24日）是美国数学家、信息论的创始人，他在1948年发表的《通信的数学理论》论文中提出了信息熵的概念，认为信息是用来减少随机不确定的东西，使用信息熵对信息进行定量度量。&lt;br/&gt;定义任意一个随机事件&lt;span class=&quot;math inline&quot;&gt;\(X\)&lt;/span&gt;，其发生的可能情况有&lt;span class=&quot;math inline&quot;&gt;\(x_1,x_2……,x_n\)&lt;/span&gt;，对应的概率分别为&lt;span class=&quot;math inline&quot;&gt;\(p_1,p_2,……,p_n\)&lt;/span&gt;，它的信息熵&lt;span class=&quot;math inline&quot;&gt;\(H(X)\)&lt;/span&gt;定义为：&lt;br/&gt;&lt;span class=&quot;math display&quot;&gt;\[ H(X)=-\sum_{i=1}^n{p_i*log(p_i)} \]&lt;/span&gt;信息熵反映了消除这个随机事件不确定性所需要的信息量的大小，换言之，信息熵度量了一个随机事件不确定程度的大小。&lt;br/&gt;信息熵越大，代表一个随机事件不确定程度越高，消除这个随机事件不确定性所需要的信息就越多。&lt;br/&gt;&lt;strong&gt;例1：&lt;/strong&gt;现在要基于历史样本集预测一个新用户是否会换机，提供了三个样本集：&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/554583/201807/554583-20180701231312944-152896541.png&quot;/&gt;&lt;br/&gt;对于一个用户来说，是否会换机是一个随机事件，其取值有两种情况：换、不换。&lt;br/&gt;在三个样本集下，该随机事件的概率分布分别为：&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/554583/201807/554583-20180701231332544-506143500.png&quot;/&gt;&lt;br/&gt;对应的，在三个样本集下，这个随机事件的信息熵分别为：&lt;br/&gt;样本集1：H=1&lt;br/&gt;样本集2：H=0.88&lt;br/&gt;样本集3：H=0.47&lt;br/&gt;可以看到，随机事件的概率分布越均匀，它的不确定程度就越大，信息熵就越大。&lt;br/&gt;下面我们回到变量筛选的话题中。&lt;br/&gt;&lt;strong&gt;变量筛选是筛选出对目标变量的预测有帮助的变量，那么又如何定义一个变量对目标变量的预测有帮助？&lt;/strong&gt;&lt;br/&gt;可以认为，如果引入一个变量后，这个变量能够一定程度上消除目标变量这个随机事件的不确定性，那么就说这个变量对目标变量的预测有帮助，换言之，这个变量具有对目标变量的预测能力。如果消除不确定性的程度越大，那么这个变量就越重要、预测能力就越强。&lt;br/&gt;明白这一点后，事情就变得简单起来。我们可以通过评估引入某个变量前后，目标变量这个随机事件的不确定性的变化大小，来度量一个变量对目标变量的预测能力强弱。&lt;/p&gt;
&lt;h3 id=&quot;信息增益&quot;&gt;2.1 信息增益&lt;/h3&gt;
&lt;p&gt;信息增益的概念非常简单，就是引入一个变量前后，一个随机事件的信息熵的变化值，通俗的说，就是不确定性消除的大小。&lt;br/&gt;&lt;span class=&quot;math display&quot;&gt;\[ Gain(A) = H(X) - H(X,A) \]&lt;/span&gt;其中，&lt;span class=&quot;math inline&quot;&gt;\(H(X)\)&lt;/span&gt;为引入变量A之前随机事件X的信息熵，&lt;span class=&quot;math inline&quot;&gt;\(H(X,A)\)&lt;/span&gt;为引入变量A之后随机事件X的信息熵。&lt;br/&gt;显然，信息增益越大，代表引入变量A之后，消除随机事件X不确定性的程度越大，说明变量A对目标变量X的预测能力就越强。&lt;br/&gt;另外，我们称&lt;span class=&quot;math inline&quot;&gt;\(H(X,A)\)&lt;/span&gt;为条件熵，即随机变量X在条件A下的信息熵。其计算方法为：&lt;br/&gt;&lt;span class=&quot;math display&quot;&gt;\[ H(X,A)=-\sum_{j=1}^m{pa_j}\sum_{i=1}^n{(p_i|pa_j)*log(p_i|pa_j)} \]&lt;/span&gt;其中，&lt;span class=&quot;math inline&quot;&gt;\(p_i|pa_j\)&lt;/span&gt;为条件A取值为j的情况下随机变量X的取值概率，&lt;span class=&quot;math inline&quot;&gt;\(pa_j\)&lt;/span&gt;为随机变量A取值为j的概率。&lt;br/&gt;&lt;strong&gt;例2：&lt;/strong&gt;使用经典的AllElectronics数据集，用于预测一个顾客是否会购买电脑。&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/554583/201807/554583-20180701231359329-2090350071.png&quot;/&gt;&lt;br/&gt;从样本总体上看：&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/554583/201807/554583-20180701231411566-700055109.png&quot;/&gt;&lt;br/&gt;如果引入age变量，如下：&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/554583/201807/554583-20180701231420497-896654581.png&quot;/&gt;&lt;br/&gt;如果引入income变量，如下：&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/554583/201807/554583-20180701231431940-101822698.png&quot;/&gt;&lt;br/&gt;可以得到：&lt;br/&gt;H(X)=0.9403&lt;br/&gt;H(X,'age')=0.6935，Gain(X,'age')=0.2468&lt;br/&gt;H(X,'income')=0.9111，Gain(X,'income')=0.0292&lt;br/&gt;由于Gain(X,'age')&amp;gt;Gain(X,'income')，所以变量age比变量income对目标变量buy_computer的预测能力要强。&lt;/p&gt;
&lt;h3 id=&quot;基尼指数&quot;&gt;2.2 基尼指数&lt;/h3&gt;
&lt;p&gt;基尼指数（Gini Index），是另一个用来度量随机事件不确定程度的指标，其定义&lt;strong&gt;Gini(X)&lt;/strong&gt;为：&lt;br/&gt;&lt;span class=&quot;math display&quot;&gt;\[ Gini(X)=\sum_{i=1}^n{p_i*(1-p_i)=1-\sum_{i=1}^n{p_i^2}} \]&lt;/span&gt;针对例1，分别计算基尼指数：&lt;br/&gt;情况1：Gini=0.50&lt;br/&gt;情况2：Gini=0.42&lt;br/&gt;情况3：Gini=0.18&lt;br/&gt;可以看出，基尼指数越大，随机事件的不确定程度就越大。&lt;br/&gt;类似于信息增益的定义，定义指标“基尼指数降低值”：&lt;br/&gt;&lt;span class=&quot;math display&quot;&gt;\[ \Delta{Gini}(A) = Gini(X) - Gini(X,A) \]&lt;/span&gt;其中，&lt;span class=&quot;math inline&quot;&gt;\(Gini(X)\)&lt;/span&gt;为引入变量A之前随机事件X的基尼指数，&lt;span class=&quot;math inline&quot;&gt;\(Gini(X,A)\)&lt;/span&gt;为引入变量A之后随机事件X的基尼指数。&lt;br/&gt;同样，基尼指数降低值越大，代表引入变量A之后，消除随机事件X不确定程度越大，说明变量A对目标变量X的预测能力就越强。&lt;br/&gt;针对例2，计算基尼指数及其降低值：&lt;br/&gt;Gini(X)=0.4592&lt;br/&gt;Gini(X,'age')=0.3429，&lt;span class=&quot;math inline&quot;&gt;\(\Delta\)&lt;/span&gt;Gini('age')=0.1163&lt;br/&gt;Gini(X,'income')=0.4405，&lt;span class=&quot;math inline&quot;&gt;\(\Delta\)&lt;/span&gt;Gini('income')=0.0187&lt;br/&gt;&lt;span class=&quot;math inline&quot;&gt;\(\Delta\)&lt;/span&gt;Gini('age')&amp;gt;&lt;span class=&quot;math inline&quot;&gt;\(\Delta\)&lt;/span&gt;Gini('income')，因此变量“age”比变量“income”对目标变量的预测能力要强。&lt;/p&gt;
&lt;h3 id=&quot;区分度&quot;&gt;2.3 区分度&lt;/h3&gt;
&lt;p&gt;在二分类问题中，可以使用区分度这个指标，它是从另一个角度来评估随机事件不确定程度的指标。&lt;br/&gt;上文中，信息增益和基尼指数降低值，都是从引入变量A后随机事件X不确定性的消除程度来评估变量A对X的预测能力的。由于引入变量A前，随机事件X的不确定程度是确定的，消除程度越大，说明引入变量A后随机事件X的不确定程度越小，所以也可以直接通过度量引入变量A后随机事件X的不确定程度来评估变量A对X的预测能力。区分度正是这样的指标。&lt;br/&gt;在上文中，我们还知道，随机事件的概率分布越均匀，它的不确定程度越大。&lt;br/&gt;因此，基于这两点，定义“区分度”如下：&lt;br/&gt;&lt;span class=&quot;math display&quot;&gt;\[ 区分度=max_{j=1}^m(pa_j/p) \]&lt;/span&gt;其中，&lt;span class=&quot;math inline&quot;&gt;\(p\)&lt;/span&gt;为引入变量A以前随机变量X取值为响应值的概率，&lt;span class=&quot;math inline&quot;&gt;\(pa_j\)&lt;/span&gt;为引入变量A之后，在变量A取值为j时，随机变量X取值为响应值的概率。&lt;br/&gt;区分度反映了引入变量A后随机事件X发生概率的均匀程度，取值越大，代表越不均匀，不确定程度就越小，变量A的预测能力就越强。&lt;br/&gt;针对例2，它属于一个二分类问题，buy_computer='yes'为响应值。&lt;br/&gt;区分度('age')=1.56&lt;br/&gt;区分度('income')=1.17&lt;br/&gt;区分度('age')&amp;gt;区分度('income')，因此变量“age”比变量“income”对目标变量的预测能力要强。&lt;br/&gt;&lt;strong&gt;一般的，将区分度=1.5作为筛选阈值，选择区分度大于1.5的变量。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;信息值iv&quot;&gt;2.4 信息值（IV）&lt;/h3&gt;
&lt;p&gt;在二分类问题中，也可以使用信息值（Information Value，IV）度量变量A对随机事件X的预测能力。&lt;br/&gt;定义如下：&lt;br/&gt;&lt;span class=&quot;math display&quot;&gt;\[ woe_j=ln(\frac{{cov_Y}_j}{{cov_N}_j})=ln(\frac{\frac{Y_j}{Y}}{\frac{N_j}{N}}) \]&lt;/span&gt;&lt;span class=&quot;math display&quot;&gt;\[ IV=\sum_{j=1}^m{({cov_Y}_j-{cov_N}_j)*woe_j}=\sum_{j=1}^m{({\frac{Y_j}{Y}}-{\frac{N_j}{N}})*woe_j} \]&lt;/span&gt;其中，woe（Weight of Evidence，证据权重），它是根据变量A的取值将随机事件样本集进行分组，分成m组，每组分别计算woe取值。&lt;br/&gt;woe等于每一组内响应样本的覆盖率（&lt;span class=&quot;math inline&quot;&gt;\({cov_Y}_j\)&lt;/span&gt;）与非响应样本的覆盖率（&lt;span class=&quot;math inline&quot;&gt;\({cov_N}_j\)&lt;/span&gt;）的比值的取对数，从这个定义上可以理解成，woe考察的是每个分组内，响应样本相对非响应样本的分布差异，如果二者没有差异，说明与总体分布完全相同，此时woe取值为0。当响应样本分布多于非响应样本，woe&amp;gt;0；反之，woe&amp;lt;0。&lt;br/&gt;由于woe的取值有正有负，同时，衡量变量A的预测能力是一个样本全集概念，而不是某一个样本子集，因此，将每一组内响应样本的覆盖率与非响应样本的覆盖率的差值作为权重，对woe进行加权求和得到的值，定义为IV，既可以得到一个整体指标，也可以将指标值调和成正值。&lt;br/&gt;针对例2，buy_computer='yes'为响应值，buy_computer='no'为非响应值。&lt;br/&gt;IV('age')=2.0358&lt;br/&gt;IV('income')=0.1773&lt;br/&gt;IV('age')&amp;gt;IV('income')，因此变量“age”比变量“income”对目标变量的预测能力要强。&lt;br/&gt;&lt;strong&gt;一般的：&lt;/strong&gt;&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/554583/201807/554583-20180701231448833-1151426232.png&quot;/&gt;&lt;br/&gt;&lt;strong&gt;将0.10作为筛选阈值，选择IV大于等于0.10的变量。&lt;/strong&gt;&lt;br/&gt;需要说明的：关于&lt;strong&gt;分组中的响应值或者非响应值为0&lt;/strong&gt;时的处理方式：&lt;br/&gt;1）重新分组，尽量不出现这种情况；&lt;br/&gt;2）手工调整这个值，将其调整为1。&lt;/p&gt;
&lt;h2 id=&quot;基于机器学习的方法&quot;&gt;3.基于机器学习的方法&lt;/h2&gt;
&lt;p&gt;基于机器学习的方法进行变量筛选，是指构建一个或者多个机器学习模型，来判断每个变量的重要程度，得到最重要的变量。与基于统计的方法相比，基于机器学习的方法同时考虑了所有变量，而不是对单个变量进行独立度量。&lt;/p&gt;
&lt;h3 id=&quot;单一算法&quot;&gt;3.1 单一算法&lt;/h3&gt;
&lt;p&gt;基于单一算法的方法，是指构建一个有监督的机器学习模型，这个模型不需要用于最终的模型构建，模型自动为每个变量提供某种重要性度量，进而通过这个度量进行重要性排序，比如使用决策树、随机森林等，算法内部包含有变量重要性度量指标。&lt;/p&gt;
&lt;h3 id=&quot;迭代&quot;&gt;3.2 迭代&lt;/h3&gt;
&lt;p&gt;基于迭代的方法，其实就是基于多个模型甚至是一系列模型来进行判断。它主要有两种思路：前向筛选和后向筛选，即开始时没有变量，然后逐个添加变量，直到满足某个终止条件；或者从所有变量开始，然后逐个删除变量，直到满足某个终止条件。相比基于单一算法的方法，基于迭代的变量筛选的结果更好。&lt;br/&gt;&lt;strong&gt;由于涉及到具体的实现环境，这一部分将在下一篇《数据准备&amp;lt;5&amp;gt;:变量筛选-实战篇》介绍，基于sklearn环境下的实现。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;参考与感谢&quot;&gt;4. 参考与感谢&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href=&quot;https://book.douban.com/subject/2038599/&quot;&gt;数据挖掘概念与技术&lt;/a&gt;&lt;br/&gt;[2] &lt;a href=&quot;https://book.douban.com/subject/30147778/&quot;&gt;Python机器学习基础教程&lt;/a&gt;&lt;br/&gt;[3] &lt;a href=&quot;https://book.douban.com/subject/27608466/&quot;&gt;Python数据分析与数据化运营&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 01 Jul 2018 15:31:00 +0000</pubDate>
<dc:creator>hbsygfz</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/hbsygfz/p/9251695.html</dc:identifier>
</item>
<item>
<title>数学分析的主线，高等数学的一切：连续函数与“有理”分析 - 黑山雁</title>
<link>http://www.cnblogs.com/xjtu-blacksmith/p/9250454.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xjtu-blacksmith/p/9250454.html</guid>
<description>&lt;p&gt;这里要讨论的，是关于&lt;strong&gt;数学分析&lt;/strong&gt;（以及工科生的&lt;strong&gt;高等数学&lt;/strong&gt;）这门课程本身的某些中心思想和知识内容的组织方式。我并不是数学教师，甚至不是数学系学生，但是我作为一个“业余”读者，还是从这门课程中发现了一些自己以前没有注意过的东西。在此分享出来，供大家参考和批评。&lt;/p&gt;
&lt;h2 id=&quot;连续函数的意义&quot;&gt;1 连续函数的意义&lt;/h2&gt;
&lt;p&gt;首先，让我们从一个高等数学中再熟悉不过的概念——&lt;strong&gt;连续性&lt;/strong&gt;说起。所谓函数的连续性定义如下：&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;设实函数&lt;span class=&quot;math inline&quot;&gt;\(f(x)\)&lt;/span&gt;在点&lt;span class=&quot;math inline&quot;&gt;\(x_0\)&lt;/span&gt;及其附近有定义。若给定一任意小的&lt;span class=&quot;math inline&quot;&gt;\(\varepsilon&amp;gt;0\)&lt;/span&gt;，总能找到对应的&lt;span class=&quot;math inline&quot;&gt;\(\delta&amp;gt;0\)&lt;/span&gt;使得&lt;span class=&quot;math inline&quot;&gt;\(|f(x)-f(x_0)|&amp;lt;\varepsilon\)&lt;/span&gt;对所有的&lt;span class=&quot;math inline&quot;&gt;\(|x-x_0|&amp;lt;\delta\)&lt;/span&gt;都成立，则称&lt;span class=&quot;math inline&quot;&gt;\(f(x)\)&lt;/span&gt;在&lt;span class=&quot;math inline&quot;&gt;\(x_0\)&lt;/span&gt;处&lt;strong&gt;连续&lt;/strong&gt;。若一个函数在其定义域内都连续，则常称该函数为&lt;strong&gt;连续函数&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我在这里没有直接使用极限的记法，仍然用&lt;span class=&quot;math inline&quot;&gt;\(\varepsilon-\delta\)&lt;/span&gt;方法表述了一遍。“连续”两个字究竟是在说什么呢？如果我们直观地把定义翻译成自然语言，就是说：如果函数在其定义域内某一点（且称其为&lt;em&gt;中心点&lt;/em&gt;）附近，总是可以划出一片足够小的区域，使得该区域内的函数值都与函数在中心点处的值充分接近，那么就称这个函数在该点处连续。归根结底，我们不如说：函数在某点连续，就是说函数在此足够&lt;em&gt;平坦&lt;/em&gt;，足够&lt;em&gt;光滑&lt;/em&gt;。这是我们能够从各种连续函数的图像所得到的一种印象。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images.cnblogs.com/cnblogs_com/xjtu-blacksmith/1245580/o_%E8%BF%9E%E7%BB%AD.jpg&quot; alt=&quot;函数的连续性-平滑与平坦&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我们可以说，连续性是一种&lt;em&gt;较好&lt;/em&gt;的性质，因为很多函数并不能满足连续性的要求。一些函数在若干个离散的点上不连续，这里引出了关于间断点的讨论；另一些函数则干脆是处处不连续，比如在教材中常常讨论的诸如Dirichlet函数与Riemann函数之类。尽管如此，这里却要给出对微积分课程给出一个关键的断语，那就是：&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;连续函数是数学分析课程（理科）的主线，更是高等数学课程（工科）所讨论的几乎全部内容。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在已经指出许多常见常用但并不连续的函数之后，为何我们仍然会得到这样一个结论呢？我们不妨再回头看看连续函数究竟有怎样的特性。&lt;/p&gt;
&lt;h3 id=&quot;连续函数类是实函数类的杰出代表&quot;&gt;1.1 连续函数类是实函数类的“杰出代表”&lt;/h3&gt;
&lt;p&gt;关于连续函数，有一个很不起眼的命题——这个命题常常作为一些数学分析乃至实变函数教材课后一道简单的习题列出，而工科生则可能没有接触过这个命题。其内容大致是这样的：&lt;/p&gt;
&lt;blockquote readability=&quot;14&quot;&gt;
&lt;p&gt;&lt;strong&gt;命题&lt;/strong&gt;：设有两函数&lt;span class=&quot;math inline&quot;&gt;\(f_1(x),f_2(x)\)&lt;/span&gt;均在一个开区间&lt;span class=&quot;math inline&quot;&gt;\((a,b)\)&lt;/span&gt;上连续，其中&lt;span class=&quot;math inline&quot;&gt;\(a&amp;lt;b\)&lt;/span&gt;为两个任意的实数。若&lt;span class=&quot;math inline&quot;&gt;\(f_1(x)\)&lt;/span&gt;与&lt;span class=&quot;math inline&quot;&gt;\(f_2(x)\)&lt;/span&gt;在&lt;span class=&quot;math inline&quot;&gt;\((a,b)\)&lt;/span&gt;内所有的有理点处取值相同，即&lt;br/&gt;&lt;span class=&quot;math display&quot;&gt;\[f_1(x)=f_2(x)\ (\forall x\in\mathbb{Q}),\]&lt;/span&gt;&lt;br/&gt;则函数&lt;span class=&quot;math inline&quot;&gt;\(f_1(x),f_2(x)\)&lt;/span&gt;必然在&lt;span class=&quot;math inline&quot;&gt;\((a,b)\)&lt;/span&gt;上所有点处都取值相同，即它们在区间上是同一个函数。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这个命题换句话说，就是：对于一个连续函数而言，只需要其在某区间&lt;span class=&quot;math inline&quot;&gt;\((a,b)\)&lt;/span&gt;上所有有理点上的值，就可以完全确定这个连续函数在&lt;span class=&quot;math inline&quot;&gt;\((a,b)\)&lt;/span&gt;内的情况，尽管我们甚至还不知道这个函数在那比有理点“多得多”（这个所谓的“多”当然不是严格描述）的无理点上究竟为何值——事实上大多数情况下我们也无法算出。&lt;/p&gt;
&lt;p&gt;对于数学系的学生而言，这一命题看起来是十分普通的，至多不过为一道普通的练习题罢了；但是，如果我们现在是处在一个数学理论之“局外人”的视角来看待这个命题，我们不能不说这样一个结果是极其值得思考的。为了便于读者理解这个命题的深层内涵，这里我们还是有必要把这个命题证明一下，尽管所用的工具仍然是对于一般人而言显得枯燥无味的&lt;span class=&quot;math inline&quot;&gt;\(\varepsilon-\delta\)&lt;/span&gt;理论（也就是利用前面那条连续性的定义来证明）。&lt;/p&gt;
&lt;p&gt;证明是枯燥的——我在叙说的过程中显得比较罗嗦，无非是为了避免给一般的读者造成太大障碍。在证明过程中，别的许多细节或技巧都可以忽略（例如取&lt;span class=&quot;math inline&quot;&gt;\(\dfrac{\varepsilon}{3}\)&lt;/span&gt;的“别有用心”），唯有一点特别重要：&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;在任何一个无理点的任意小邻域内总是有有理点存在。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这正是证明的核心。从比较直观的角度出发，这个命题的证明过程其实可以非常容易的为我们理解：由于在任何一个无理点的附近都有有理点（说得更仔细一些，是无穷多个），再加上函数的连续性要求，这使得连续函数在无理点处的取值绝不是&lt;strong&gt;自由&lt;/strong&gt;的——它必须与其周围这样无数多个有理点处的函数取值相&lt;em&gt;协调&lt;/em&gt;，结果便是函数在无理点处的取值事实上已经被这些有理点&lt;em&gt;锁死&lt;/em&gt;了（所谓的&lt;em&gt;qin-ding&lt;/em&gt;）。这便是隐藏在令人头痛的&lt;span class=&quot;math inline&quot;&gt;\(\dfrac{\varepsilon}{3}\)&lt;/span&gt;之下的基本逻辑——函数的连续性与其在这看似很稀疏的有理点处之取值，便足以确定函数在整个实数域上的分布。&lt;/p&gt;
&lt;p&gt;相反地，对于非连续的函数，当然不可能有这样的好事情。有间断点的函数当然可以在间断点处取任何值——间断点附近的那些连续点不能像在连续函数中那样，约束住函数在该间断点的取值。对于更一般一些的函数类，例如Riemann可积函数，所谓约束更是天方夜谭了——凡是熟悉Riemann可积性理论的学生一定知道，一个Riemann可积函数在一段区间上的积分，不因其在该区间上任意有限个（甚至可数无穷个）点处函数值的改变而发生变化。对于这些更加一般的函数，我们可以说：只要有&lt;strong&gt;一个点&lt;/strong&gt;处的函数值不知道，函数就确定不下来。对于只含离散间断点的函数而言，我们可以说这个点是任意一个间断点（因为在间断点之外函数还是连续的）；而对于由Riemann积分值确定的一个可积函数，这个点可以是其定义域上的任何一个点了——也就是说，必须确定了所有的点才能真正的定下来这个函数。可以说以这种方式定义出来的函数是相当的&lt;em&gt;桀骜不驯&lt;/em&gt;的。&lt;/p&gt;
&lt;p&gt;到这里，我们可以初步得到一个结论了：连续函数类，正是整个实函数类之&lt;strong&gt;杰出代表&lt;/strong&gt;。连续函数是一切实函数中最简单、最方便处理的一类函数，也最与我们对所谓“函数”的表观认识接近。从感性的角度来看，如果我们已经知道了某一个函数在足够多个点（例如所有的有理点）的取值，这个函数不就应该定下来了吗？然而，只有连续函数才具有这样的性质。我们同样可以将前面那个命题按另外一种方式来理解：在所有有理点处取给定函数值的连续函数是&lt;strong&gt;唯一&lt;/strong&gt;的——完美的东西，理应是唯一的。&lt;/p&gt;
&lt;h3 id=&quot;连续函数与实际科学问题的关系&quot;&gt;1.2 连续函数与实际科学问题的关系&lt;/h3&gt;
&lt;p&gt;前几天与同学闲聊，说到高等数学的知识内容，他不禁感慨：“数学家们研究那么多千奇百怪的东西，在现实中又&lt;strong&gt;不存在&lt;/strong&gt;，有什么意义呢？”这种看法，大致可以说是我们大多数大学生对于大学数学的普遍认识了。&lt;/p&gt;
&lt;p&gt;这里首先要讨论的倒不是这种&lt;em&gt;成见&lt;/em&gt;，而是连续函数与实际科学问题的联系。众所周知，一旦我们打算在实际科学问题中应用诸如微积分之类的数学工具，我们便已经默认了我们所用的函数应当是“连续”的——这个“连续”不同于前面所讨论的那种数学上的连续性，而是说这一个函数理应在观测域内的任何一个点处都有定义都有值。至于数学上的那种连续性，对于大多数自然科学问题也往往是需要的，不过我们必须认识到这种连续性并非必要的事物——至少到目前为止我们可以这样认为。&lt;/p&gt;
&lt;p&gt;例如，现在我们要利用微分方程来研究某一动物种群的增长。设有一个时间变量&lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt;（我们可以认为它是从研究开始的时间点计起的），又记这样一个动物种群中的个体数在&lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt;时刻为&lt;span class=&quot;math inline&quot;&gt;\(N(t)\)&lt;/span&gt;。此外，我们还假设，这一种群有一个固定的出生率&lt;span class=&quot;math inline&quot;&gt;\(b\)&lt;/span&gt;。由于出生率表示的是“在单位时间内出生的个体数占当前个体总数的比率”，我们在这里把所谓的“单位时间”压缩为一个时间微元&lt;span class=&quot;math inline&quot;&gt;\(\mathrm{d}t\)&lt;/span&gt;以表示瞬态过程，那么就有&lt;span class=&quot;math inline&quot;&gt;\(b=\dfrac{\mathrm{d}N}{N\cdot\mathrm{d}t}\)&lt;/span&gt;，也即&lt;br/&gt;&lt;span class=&quot;math display&quot;&gt;\[\dfrac{\mathrm{d}N}{\mathrm{d}t}=bN\]&lt;/span&gt;&lt;br/&gt;该方程表示动物种群的增长率正比于种群的数量——个体越多，生的越快。这是很好理解的。通过非常简单的分离变量法来解这个微分方程，并假设在&lt;span class=&quot;math inline&quot;&gt;\(t=0\)&lt;/span&gt;时种群数量为&lt;span class=&quot;math inline&quot;&gt;\(N_0,\)&lt;/span&gt;我们很快能得到这个微分方程在该初值条件下的解为&lt;span class=&quot;math inline&quot;&gt;\(N(t)=N_0\mathrm{e}^{bt}\)&lt;/span&gt;。这个式子表明种群数量随时间的变化呈现为急剧增长的指数函数——也就是高中生物课所谓的“J”型增长。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://timgsa.baidu.com/timg?image&amp;amp;quality=80&amp;amp;size=b9999_10000&amp;amp;sec=1530466652483&amp;amp;di=3df0e1ab2c4dbfb86fe0c0a6298c7301&amp;amp;imgtype=0&amp;amp;src=http%3A%2F%2Fres.tongyi.com%2Fresources%2Farticle%2Fstudent%2Fothers%2Fxf090318%2Fxf%2Fgz%2Fsw%2F7.files%2Fimage007.gif&quot; alt=&quot;动物种群的J型增长曲线&quot;/&gt;&lt;/p&gt;
&lt;p&gt;无论是微分方程的解法还是生物学的理论，皆非此处所关心的重点问题。我们所关注的问题是：真实世界中，种群数量的增长真的是由这样的连续函数所确定的吗？事实上并非如此，因为一方面种群个体的数量总是整数，不可能遍历一个区间；另一方面，种群个体的数量也并非无时无刻不在增加，也就是说那个增长率&lt;span class=&quot;math inline&quot;&gt;\(b\)&lt;/span&gt;不可能表现为一个瞬态的变化系数。这些问题的根源归结于：种群个体数量增长这样一个过程，本来就是一个离散的过程；因此，出生率&lt;span class=&quot;math inline&quot;&gt;\(b\)&lt;/span&gt;也最多只能是关于一段足够长的时间所计算出来的比率，不可能用于描述连续的变化过程。在现实情况下，我们对于种群个数的记录总是离散的，例如我们选择每一年记录一次种群的数量——这时&lt;span class=&quot;math inline&quot;&gt;\(t\)&lt;/span&gt;只能取整数年，相应的变化模型则应表述为&lt;br/&gt;&lt;span class=&quot;math display&quot;&gt;\[\dfrac{\Delta N}{\Delta t}=Nb_y\]&lt;/span&gt;&lt;br/&gt;这里&lt;span class=&quot;math inline&quot;&gt;\(\Delta t\)&lt;/span&gt;恒为一年，而&lt;span class=&quot;math inline&quot;&gt;\(b_y\)&lt;/span&gt;则表示年出生率——我们仍然假设其是恒定的。微分模型被转化为离散模型（也就是差分模型），种群的数量最终也并不会表现为指数函数了——它只会是一系列看起来呈指数增长的离散数据点而已。（如果结合&lt;span class=&quot;math inline&quot;&gt;\(N(t)\)&lt;/span&gt;的意义要求该函数在每一个时刻都应有值，那么函数图像就会是一个所谓分段函数的形态。）&lt;/p&gt;
&lt;p&gt;从这个例子我们可以得到什么？尽管在大多数自然科学问题中我们总是不自觉的使用那些在区间上任何实数点处都有值的函数（也就是一般人所理解的“连续函数”）来作为实际问题的数学模型，但我们所面对的现实世界却往往是离散的、不便于处理的。这一方面源于某些自然规律或实际问题本身就是以离散的变化而呈现出来（例如种群个体的出生与死亡，银行存款的利息生成，乃至量子论的相关结果），另一方面也出自于观测这一行为本身的有限性——我们不可能观测到无限个数据点，人眼有最小的视觉分辨频率，电子设备也有采样的时间间隔。这一系列原因导致我们所最终接触到的世界总是以离散的形态呈现于我们的面前，尽管我们倾向于认为这些离散形态因其极小的时间间隔而可被毫无顾忌的用连续模型加以概括。连续的函数在许多时候都比离散的数据更易于理解和应用——前提是这种连续的规律足够简单并已经为人类认识研究的足够透彻，例如初等函数或一部分特殊函数。&lt;/p&gt;
&lt;p&gt;在数学理论的领域以内，我们可以说有许许多多不同的函数，且在上一节我们也认识到只有连续函数能够通过相对“稀疏”的点加以确定，其余函数则可任意的改变它们在那些奇异点处的取值而不受约束。但是，在实际科学问题中，我们却会发现：我们最终所拥有的只有&lt;strong&gt;连续函数&lt;/strong&gt;——包括一部分只有少数间断点的“几乎”连续函数。为何如此？因为我们总是在观测、记录数据时作出这样一个假设：&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;观测和记录所得的数据，已经足以确定该函数的变化规律而没有过分的偏差。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这不是与连续函数的性质十分类同吗？区别仅在于，我们的观测和记录总是有限的，因此即使是确定连续函数所要求的“所有有理点处函数值”我们也不可能全部获得。但总体而言，通过缩小观测间隔，我们可以保证观测结果的足够“充分”，接下来通过插值的方法所得的近似曲线之相对误差可以降到自然科学所容忍的范围以内。这“缩小观测间隔”的目的，也无非就是为了保证一件事情：&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;在任意给定的时间点周围足够近的时间范围内，总是存在已经观测到的数据点。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这样，再利用连续函数的特性，我们便可以放心的认为：利用观测数据加上插值等连续化方法所得到的函数曲线，基本上能够反映被观测量、被研究问题的真实情况。换句话说，在自然科学的领域内，我们利用连续函数在连续点附近&lt;strong&gt;相对平滑&lt;/strong&gt;这一特性，来弥补观测有限这一问题，以降低其所造成的误差，保证科学规律最大的真实性。这就是连续函数在一般自然科学问题（特别是各种连续现象）中的重要意义与价值。&lt;/p&gt;
&lt;p&gt;而对于前面所言的那些离散模型问题（如生物种群数量），用连续函数来表征的意义在于将问题简单化，毕竟在较为简单的情形下微分方程比差分方程易于解决。再者，我们又何尝不能说生物种群在某一刻的数量是个小数呢？怀胎十月，我们不妨认为每过一个月这世界上就多了0.1个人，直到孩子诞生，人数达到1为止。所以，关于离散模型，我们也可以说是观测或记录上的间断所导致的，而连续函数的引入正是为了填补上那些没有数据点处的规律。&lt;/p&gt;
&lt;p&gt;当然，我们也得说，这里有很多例外。当我们的观测已经被约束局限于某些固定的特殊点，或待研究的现象表现为某种瞬时突变，连续函数的这种局域特性反而会显得多余，甚至会引发错误的结论。这时我们所应用的数学模型，又会有所改易。这些内容，在具体的学科领域之内，会有更加详细的讨论。&lt;/p&gt;
&lt;h3 id=&quot;概念延伸稠密集确定连续函数&quot;&gt;1.3 概念延伸：稠密集确定连续函数&lt;/h3&gt;
&lt;p&gt;前面我们一直在喋喋不休地重复“所有有理点确定连续函数”，这“所有的有理点”难道真的有什么特殊之处？其实，选取这一系列点为代表，有理数本身的诸多性质（比如可以表示为&lt;span class=&quot;math inline&quot;&gt;\(p/q\)&lt;/span&gt;）倒并没有发挥什么作用，唯一的要点在于：&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;任何一个实数的任意小邻域内都有有理数。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;正是这一条性质使得我们最终得以确认连续函数只需要有理点就可以完全确定。事实上，不限于有理数集，只要任何一个数集满足这样的性质，我们都可以证明函数在这个数集上的取值就能唯一的确定一个连续函数。因此，我们给出这样一个定义：&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;定义：设数集&lt;span class=&quot;math inline&quot;&gt;\(A\subset B\)&lt;/span&gt;，若任给&lt;span class=&quot;math inline&quot;&gt;\(x\in B\)&lt;/span&gt;及任意小的&lt;span class=&quot;math inline&quot;&gt;\(\delta&amp;gt;0,\)&lt;/span&gt;总是存在&lt;span class=&quot;math inline&quot;&gt;\(x'\in A\)&lt;/span&gt;满足&lt;span class=&quot;math inline&quot;&gt;\(|x'-x|&amp;lt;\delta,\)&lt;/span&gt;则我们称&lt;span class=&quot;math inline&quot;&gt;\(A\)&lt;/span&gt;是&lt;span class=&quot;math inline&quot;&gt;\(B\)&lt;/span&gt;的一个&lt;strong&gt;稠密子集&lt;/strong&gt;，或称&lt;span class=&quot;math inline&quot;&gt;\(A\)&lt;/span&gt;在&lt;span class=&quot;math inline&quot;&gt;\(B\)&lt;/span&gt;中&lt;strong&gt;稠密&lt;/strong&gt;。如果这里取&lt;span class=&quot;math inline&quot;&gt;\(B=\mathbb{R}\)&lt;/span&gt;，我们也常直称&lt;span class=&quot;math inline&quot;&gt;\(A\)&lt;/span&gt;是一个&lt;strong&gt;稠密集&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;于是，我们起初所讨论的那一个命题可以进一步拓展为：&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;连续函数在整个实轴上的取值，可以唯一地由其在一个稠密集上的取值所决定。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;稠密集决定一个连续函数。这正是连续函数的神奇之处：部分决定整体。当然我们也得承认，这不是一种魔术，而是因为连续这两个字已经给连续函数施加了非常强的约束，这种约束使得整个实数集显得“多余”了。&lt;/p&gt;
&lt;p&gt;关于稠密集，我们还可以有更多的思考。例如，有理数集显然是一个稠密集，那么在有理数集中移出有限多个有理数之后，所得到的数集还是稠密的吗？显然还是。（证明或理解，交由读者自己完成。）那么我们忍不住要问，实数集最小的稠密集是什么呢？也就是说，是否存在一个稠密集&lt;span class=&quot;math inline&quot;&gt;\(S\)&lt;/span&gt;是其他所有稠密集的子集呢？若是有这样的一个数集，我们就可以只靠某一函数在&lt;span class=&quot;math inline&quot;&gt;\(S\)&lt;/span&gt;上的取值来“最经济”地决定一个连续函数了。关于这个问题，我所能给出的结论是：空想是徒劳的，因为没有这样的“最小稠密集”——既然我们已经确认任意稠密集去掉有限个点仍然稠密，那么如果真有这样一个最小稠密集&lt;span class=&quot;math inline&quot;&gt;\(S\)&lt;/span&gt;，给它去掉若干个点又如何呢？这必然与其最小性矛盾。这些内容，读者若感到有很强的兴趣，欢迎自学点集拓扑理论的相关内容；点集拓扑算是数学理论的柱石之一，然而相关知识对于自然科学的意义却比较寥寥，因此在这里就不再多费口舌了。（这里有Matrix 67上的几个比较简单而有趣的稠密集问题：&lt;a href=&quot;http://www.matrix67.com/blog/archives/1480&quot;&gt;再谈稠密性：令人吃惊的稠密集及其交集&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&quot;何谓有理分析数学分析的知识结构&quot;&gt;2 何谓“有理”分析：数学分析的知识结构&lt;/h2&gt;
&lt;p&gt;以上我们讨论了连续函数的特殊价值。现在我们仍然从大家都有了解过的《高等数学》课本之中，再举出几个例子来——而它们并不是连续函数。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Dirichlet函数：&lt;span class=&quot;math inline&quot;&gt;\(D(x)=\begin{cases}1,x\in\mathbb{Q}\\0,x\notin\mathbb{Q}\end{cases}.\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Riemann函数：&lt;span class=&quot;math inline&quot;&gt;\(R(x)=\begin{cases}1/q,x=p/q\in\mathbb{Q},(p,q)=1\\0,x\notin\mathbb{Q}\end{cases}.\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;符号函数：&lt;span class=&quot;math inline&quot;&gt;\(\mathrm{sgn}(x)=\begin{cases}1,x&amp;gt;0\\0,x=0\\-1,x&amp;lt;0\end{cases}.\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;一个分段函数&lt;span class=&quot;math inline&quot;&gt;\(f(x)=\begin{cases}\sin\dfrac{1}{x},x\neq0\\0,x=0\end{cases}.\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;前面两个函数可以说是高等数学乃至数学分析课程中各种“不存在”、“不是”问题的常客，唯一的例外可能是在可积性理论中要求你证明“Riemann函数是可积的”这样一个出人意料的结论；符号函数存在一个跳跃间断点（第一类），而最后一个分段函数以&lt;span class=&quot;math inline&quot;&gt;\(0\)&lt;/span&gt;为其振荡间断点（第二类），总之它们的性质都相对于一般的连续函数要奇异许多，也不便于处理。&lt;/p&gt;
&lt;p&gt;但是最重要的一点却在这里：这些函数，无一例外，几乎都是以反例的形象出现在课程当中，而未“再当大任”。在间断点的对应章节以外何尝再见到过所谓的振荡间断点？Dirichlet函数、Riemann函数和符号函数可曾有过什么实际的应用？皆没有。这些在后续课程中发挥重要作用的函数，在微积分的基础课程中则只是表现为差劲的反例，从这里我们便可以看到一个非常强的偏向：&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;所谓的“高等数学”归根结底就是“连续函数论”。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;学过工科的复变函数课程的读者可能会马上联想到另外一个说法：&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;所谓的“复变函数”归根结底就是“解析函数论”。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这两者有非常高的相似性。高等数学课程的要求似乎是要求学生掌握利用微积分工具对“各类”函数进行研究，然而事实上我们在这门课程中从头到尾研究的都是连续或至多有几个寥落的间断点的函数而已！这是否是一种局限呢？这是出自于课程的安排不足，还是来自于古典微积分工具本身的缺陷，或是源于我们的实际需要确实仅止步于此呢？以下我们就来讨论这一系列的问题。&lt;/p&gt;
&lt;h3 id=&quot;数学分析高等数学的知识框架&quot;&gt;2.1 数学分析/高等数学的知识框架&lt;/h3&gt;
&lt;p&gt;这里我们应当首先列出数学分析或高等数学课程的具体知识框架，以便于我们来具体分析。为了简便起见，我仅按照一个非常粗略的结构来概述它们。读者若已经非常熟悉这些内容，请跳过。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;逻辑基础：实数理论（&lt;em&gt;高等数学无&lt;/em&gt;）&lt;/li&gt;
&lt;li&gt;基本工具：极限理论【 数列和数列极限 | 函数极限 | 函数的连续性，初等函数的连续性 | 函数的阶，等价无穷小 | 函数的一致连续性（&lt;em&gt;高等数学可能无&lt;/em&gt;） 】&lt;/li&gt;
&lt;li&gt;一元微分学【 导数和微分 | 微分中值定理，不等式 | Taylor公式 | 函数性质与函数作图 】&lt;/li&gt;
&lt;li&gt;一元积分学【 不定积分（原函数） | 定积分的定义（Riemann积分） | 可积性理论（&lt;em&gt;高等数学无&lt;/em&gt;） | Newton-Leibniz公式（微积分学基本定理） | 广义积分，敛散性判别 | 微元法，积分应用（&lt;em&gt;数学分析讨论稍少&lt;/em&gt;） 】&lt;/li&gt;
&lt;li&gt;多元微分学 【 理论基础：&lt;span class=&quot;math inline&quot;&gt;\(\mathbb{R}^n\)&lt;/span&gt;空间，其上的拓扑（&lt;em&gt;高等数学几乎不讨论&lt;/em&gt;） | 多元函数及其极限 | 偏导数与全微分，梯度 | 隐/反函数存在定理，求导公式（&lt;em&gt;高等数学可能无&lt;/em&gt;） | 多元函数Taylor公式（&lt;em&gt;高等数学可能无&lt;/em&gt;） | 有/无约束极值问题 】&lt;/li&gt;
&lt;li&gt;高维空间上的积分学 【 重积分（二重、三重积分） | 含参积分，敛散性判别（&lt;em&gt;高等数学无&lt;/em&gt;） | 线面积分 | Green公式，Gauss公式，Stokes公式 | 场论初步 】&lt;/li&gt;
&lt;li&gt;常微分方程初步（&lt;em&gt;数学分析常无，单独开一门专业课&lt;/em&gt;） 【 简易常微分方程（分离变量，齐次，常数变易法，可降阶） | 高阶线性微分方程（组） | 恰当方程与积分因子 | 各类换元法 】&lt;/li&gt;
&lt;li&gt;无穷级数理论 【 数项级数的敛散性判别（正项级数，一般项级数） | 函数项级数的收敛域 | 函数项级数的一致收敛性，极限换序理论（&lt;em&gt;高等数学可能无，或讨论不深&lt;/em&gt;） | 幂级数，收敛半径，函数的幂级数展开 | Fourier级数初步（&lt;em&gt;部分教材或课程可能无&lt;/em&gt;） 】&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;越过这长长的一段提纲，我们需要注意到一点：这看似庞杂的内容，其实可以归结为两个&lt;strong&gt;中心&lt;/strong&gt;——以古典微积分及相应工具（导数、积分、常微分方程、无穷级数）为&lt;strong&gt;理论安排的中心&lt;/strong&gt;，以连续函数为&lt;strong&gt;研究对象的中心&lt;/strong&gt;。前者是显性的，而后者却是隐性的；我们能见到许多名为《解析函数论》的书，却还没有见到过所谓《连续函数论》的书，因为并不是连续函数——而是古典微积分理论赋予了高等数学或者数学分析课程以最大的意义。（在复变函数理论中则有所不同，解析函数本身具有的优良性质在很大程度上引领了早期复变函数理论的研究。）&lt;/p&gt;
&lt;p&gt;尽管如此，我们却仍然需要意识到连续函数在这两门课程之中的重要性。对于数学系学生而言，其重要性倒是可以稍微搁置一边，毕竟连续函数只是他们将来要研究的各类函数和数学对象之中普普通通、轻松易懂的一类罢了；但对于将要走上工程或研究岗位、与实际问题打交道的学生们来说，连续函数（从这里开始我总是用这个词指代连续函数或只有少量简短点的函数之总称）却将是他们最经常甚至是唯一有可能接触到的数学对象——要和它们打一辈子的交道。这件事情从古典微积分诞生的数百年来，似乎都还没有发生过太大的变化——这反映了连续函数与实际问题之间非常特殊的一种联系。这是严谨、“完美”的理论在现实世界中一个最令人感到亲切的投影。&lt;/p&gt;
&lt;h3 id=&quot;从稠密集到连续集从数学分析到实变函数论&quot;&gt;2.2 从稠密集到连续集，从《数学分析》到《实变函数论》&lt;/h3&gt;
&lt;p&gt;不知道读者是否对实数系理论有所了解？如果读者还完全没有接触过这一内容，不妨抽空读一读本博客中的两篇诙谐有趣的概述&lt;a href=&quot;https://www.cnblogs.com/xjtu-blacksmith/p/7616948.html&quot;&gt;实数系与实数定理（上）&lt;/a&gt;与&lt;a href=&quot;http://www.cnblogs.com/xjtu-blacksmith/p/7625717.html&quot;&gt;实数系与实数定理（下）&lt;/a&gt;。下面的内容都由实数理论的相关内容说起。&lt;/p&gt;
&lt;p&gt;我们知道，数学分析或高等数学所研究的对象，是“&lt;em&gt;实数系上的函数&lt;/em&gt;”；然而前面种种分析叙述已经表明，唯有连续函数是这两门课程的主线，对于工科生而言连续函数甚至是他们唯一熟悉的东西。一方面，我们已经讲清，在实际的工程、科学技术问题中，的确只有连续函数是最为适合的研究对象和理论依据；另一方面，我们也应当认识到，在数学分析或高等数学课程中所使用的古典微积分工具，本身就是出自于当时的数学家们对连续函数的研究、归纳与把握。&lt;/p&gt;
&lt;p&gt;就以古典的Riemann积分为例。齐民友先生的《重温微积分》一书中有一节标题为“&lt;em&gt;这样评价Riemann公正吗？&lt;/em&gt;”讨论的是Riemann积分的缺陷与不足究竟应当怎样看待。在现代数学家们看来，Riemann积分是非常粗糙的，法国的著名数学家Dieudonne在他的《现代分析基础》一书之中甚至完全没有涉及Riemann积分，原因是：&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;如果不是它的带有权威的名字，它老早就该没落下去了……现今这一“理论”的重要性在测度与积分的一般理论中，最多不过是一普通的有趣的练习……长久以后必将失去它的历史重要性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在此我们倒不必探讨Dieudonne先生的这个预言是否得到应验，反正到现在为止国内大部分数学系学生分析课本上的积分理论也还没有直接换成一般的测度积分理论。前沿数学家们持这样观点的原因在于，由Riemann最终概括总结的这套古典微积分理论，是出自于几百年前（Newton与Leibniz的时代）就基本成形的对连续函数和实际物理问题的研究。它虽然易于理解但缺乏一般性，完全可以充作现代分析理论下一个非常不起眼的特例来看待。这里我们是不是该惊呼数学家和其他自然科学工作者之间的巨大差异呢？&lt;/p&gt;
&lt;p&gt;数学史上有许多非常为人熟知的故事：所谓“函数”定义的&lt;a href=&quot;http://www.math168.com/sxsh/888.htm&quot;&gt;变迁&lt;/a&gt;（John Bernoulli, Euler, Cauchy, Fourier, Dirichlet, 一直到近现代的数学家们）；分析学家关于收敛性（主要是级数收敛性）漫长的&lt;a href=&quot;https://wenku.baidu.com/view/8cbeadd376eeaeaad1f33046.html?sxts=1530453114865&quot;&gt;探索过程&lt;/a&gt;；分析学的算术化（实数理论的建立）……从这一系列的故事中我们可以发现关键的一个线索：数学家从直观认识走向严谨理论经历了漫长的历史阶段，而这所谓的“直观认识”则正是今天的连续函数。没有人会在Newton或者Euler所在的时代提出所谓“处处不连续函数”或者“无穷多个间断点”——在他们看来，函数本来就应当是连续的，是一条曲线，是“随手画出来的”。从历史发展的角度来说，如果不是出现了某些危机（例如看似连续Fourier级数收敛于存在间断点的函数），我们完全可以把古典微积分的应用范围乃至数学研究的范围局限于连续函数类之中——就像最终是三次方程而不是二次方程推动了虚数和复数理论的发展。然而，一旦走出这和谐美好、符合直观的“温室”，数学家们似乎就再也没法走回来了，哪怕有许多的指责与质疑，因为在连续函数之外我们确实看到了许多更加丰富的内容，就像进入看似玄虚的复数域却给数学理论与科学技术领域带来了极大的方便。&lt;/p&gt;
&lt;p&gt;关于数学分析，我们要说的最重要的一点是什么呢？也许不仅仅是连续函数的问题了，而应当归结到实数系的性质上去：&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;古典微积分所研究的一切内容，几乎都仅限于实数系的数域性质、有序性质和阿基米德性质（即无界性质），而很少真正利用实数系独有的连续性。换句话说，我们完全可以仅在有理数集上建立一套微积分体系——只要我们稍稍修改相关定义即可。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;那么我们为什么还要将研究的范围扩张至实域呢？原因无非是：实数域是我们所认为真实存在的“数”之总和（可以参见&lt;a href=&quot;http://www.cnblogs.com/xjtu-blacksmith/p/7625717.html&quot;&gt;实数系与实数定理（下）&lt;/a&gt;的最后一节内容），因而有必要将其统一囊括起来，哪怕有理数之外的无理数在实际研究问题之中并不真正比有理数特殊多少，更何况我们应当指出我们所观测到和记录到的一切数据&lt;em&gt;本质上都是有理数&lt;/em&gt;。这是对于面向实际问题的学生们特别重要的一点，他们不必拘束于繁杂严谨的数学框架之下，而应当将更多的精力放在对于实际问题的研究与把握之上。理论的严谨与成体系与应用上的简洁方便总是存在着一点矛盾，这是有待于我们去解决的问题。&lt;/p&gt;
&lt;p&gt;由于有理数集不完备，我们当然可以找到无数个收敛于无理数的有理数列，这确实是理论上的空缺，需要由更加深刻完备的理论加以补充；但是，对于应用者而言，他完全可以不必理会这样的数列，如果他限定数列收敛于一个有理数或某个无理数的有理近似（如小数点后若干位）而已，那么这一类数列对他而言便没有任何研究的价值，诸如此类。我在这里想说的是，我们既要看到理论是如何一层一层完备严谨起来的，也要认识到在自己将来所要面临的领域与问题之中哪些东西是多余的、是不必考虑的。&lt;/p&gt;
&lt;p&gt;那么，在哪里我们真正的要让实数集的连续性派上用场呢？那就是数学系的实变函数课程了。本来在这里还可以接下去讨论许多有趣的内容，但写到这里我突觉如此将有破坏文章主旨之嫌，因此这些内容不妨留到以后有空时再专辟一章来叙述。读者切不要秉持流行的偏见，把实变函数论所研究的内容一并视为现实世界中不存在的反例、怪物；我想在这里引用齐民友老先生在《重温微积分》第四章中的一段评述：&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;反例的重要性在于它揭露了无法回避的矛盾。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;无论数学家与自然科学工作者各自怎样看待这些课程、知识、内容，他们一定都会赞同一个结论：我们的知识与科学，总是需要不断的前进与提高，而这是每一个人的责任。&lt;/p&gt;
</description>
<pubDate>Sun, 01 Jul 2018 14:55:00 +0000</pubDate>
<dc:creator>黑山雁</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/xjtu-blacksmith/p/9250454.html</dc:identifier>
</item>
<item>
<title>痞子衡嵌入式：通用NOR接口标准(CFI-JESD68)及SLC Parallel NOR简介 - 痞子衡</title>
<link>http://www.cnblogs.com/henjay724/p/9251620.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/henjay724/p/9251620.html</guid>
<description>&lt;hr/&gt;&lt;p&gt;　　大家好，我是痞子衡，是正经搞技术的痞子。今天痞子衡给大家介绍的是&lt;strong&gt;CFI标准及SLC Parallel NOR&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;　　NOR Flash是嵌入式世界里最常见的存储器，常常内嵌在微控制器里(Parallel型)或外置作为内存扩展(Serial型)，作为代码存储器。对于嵌入式开发而言，NOR主要分为两大类：Serial NOR、Parallel NOR，最早出现的NOR是Parallel NOR，后来为了简化引脚数，逐渐发展出了Serial NOR，目前的格局是Serial NOR主要占据低容量NOR市场（128Mb以下），而Parallel NOR主要占据高容量NOR市场（128Mb以上），虽然这两类NOR的差异比较大（软件驱动开发角度而言），但是它们有一个共性，那就是均兼容CFI接口标准，这给软件驱动开发带来了便利。&lt;/p&gt;
&lt;h3 id=&quot;一cfi-jesd68标准由来&quot;&gt;一、CFI-JESD68标准由来&lt;/h3&gt;
&lt;p&gt;　　关于NOR Flash发展史，我们知道早在1988年Intel便发表了NOR Flash结构，从此改变了由EPROM/EEPROM一统天下的局面。早期的NOR产品主要是Parallel NOR，作为半导体行业领导大厂，为了使NOR产品发展标准化，Intel于1996年制定了CFI 1.0标准（1.0版本属于draft版本，正式版本是1997年发布的1.1），CFI标准的存在是为了让Host能够从NOR Flash device中直接获取制造商ID、设备ID、Flash大小以及各种物理特性，从而使得NOR Flash产品在前后兼容性上表现更好，软件驱动设计也更加标准化。&lt;br/&gt;　　鉴于CFI已慢慢发展成为NOR Flash事实上的接口标准，JEDEC组织于1999年9月正式将CFI标准命名为JESD68，下表是CFI-JESD68标准制定的时间关系：&lt;/p&gt;
&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;时间&lt;/th&gt;
&lt;th&gt;NOR标准&lt;/th&gt;
&lt;th&gt;制定者&lt;/th&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1996.07&lt;/td&gt;
&lt;td&gt;CFI 1.0&lt;/td&gt;
&lt;td&gt;Intel&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1997.05&lt;/td&gt;
&lt;td&gt;CFI 1.1&lt;/td&gt;
&lt;td&gt;Intel&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;1999.09&lt;/td&gt;
&lt;td&gt;JESD68&lt;/td&gt;
&lt;td&gt;JEDEC&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;2001.12&lt;/td&gt;
&lt;td&gt;CFI 2.0&lt;/td&gt;
&lt;td&gt;AMD&lt;/td&gt;
&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;2003.09&lt;/td&gt;
&lt;td&gt;JESD68.01&lt;/td&gt;
&lt;td&gt;JEDEC&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;Note: CFI-JESD68标准原则上是为Parallel NOR制定的，但是部分Serial NOR也支持这一标准。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;二slc-parallel-nor原理&quot;&gt;二、SLC Parallel NOR原理&lt;/h3&gt;
&lt;h4 id=&quot;parallel-nor分类&quot;&gt;2.1 Parallel NOR分类&lt;/h4&gt;
&lt;p&gt;　　从软件驱动开发角度而言，Parallel NOR可以从以下几个方面进一步细分：&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;单元层数(bit/cell)：SLC（1bit/cell） / MLC（2bit/cell）&lt;br/&gt;地址模式： ADP / ADM / AADM&lt;br/&gt;数据线宽度：x8 / x16&lt;br/&gt;信号线模式：Asynchronous / Synchronous&lt;br/&gt;数据采集模式：SDR / DDR&lt;br/&gt;接口标准：CFI&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;　　本文的主要研究对象是兼容CFI 2.0 (JESD68.01)标准的Asynchronous SDR SLC Parallel NOR Flash。&lt;/p&gt;
&lt;h4 id=&quot;parallel-nor内存模型&quot;&gt;2.2 Parallel NOR内存模型&lt;/h4&gt;
&lt;p&gt;　　NOR内存单元从大到小一般分为如下5层：Device、Block、Sector、Page、Byte，其中Byte、Page和Sector是必有的，因为&lt;span&gt;Byte是读取的最小单元（即可以任意地址随机访问），Page是编程的最小单元，Sector是擦除的最小单元&lt;/span&gt;，而Block则不是必有的（如没有，可认为Block=1）。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;Note: 关于Block有一点需要特别说明，即NOR的RWW（Read While Write）特性，我们知道NOR是可以存储代码直接原地执行XIP的，如果在某个Block里执行代码（即CPU从NOR中读取指令数据）的同时去擦除或编程这块Block会发生什么情况呢？有些NOR是支持这种RWW操作的，但也有的NOR不支持RWW（此时会产生hardfault/lockup），Block的存在是为了规避RWW问题，RWW问题的作用范围是Block，如果某Block中执行代码擦除/编程的是另一块Block，则完全不用担忧RWW问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;parallel-nor信号与封装&quot;&gt;2.3 Parallel NOR信号与封装&lt;/h4&gt;
&lt;p&gt;　　CFI手册里并没有明确规定Parallel NOR信号线与封装，但业界有默认的标准，从信号线角度来说NOR和SRAM基本是一样的，如下是典型的Parallel NOR内部结构图，除了内存单元外，还有三大组成，分别是控制单元、地址译码单元和输出缓冲单元，信号线主要挂在这三大组成上，关于各信号线具体作用，请查阅相关文档。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_block_diagram.PNG&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　NOR芯片根据Flash size大小不同封装也不尽相同，以经典的128Mb容量的ADP NOR芯片为例，其封装一般有三种TSOP-56, TFBGA-56, LFBGA-64，下图是TSOP-56封装信号分布：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_tsop56.PNG&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;parallel-nor接口命令&quot;&gt;2.4 Parallel NOR接口命令&lt;/h4&gt;
&lt;p&gt;　　CFI手册里也没有明确规定Parallel NOR接口命令，同样地业界还是有默认的标准，如下是从Micron MT28EW系列手册里截取的部分基本命令，包括Reset、Read、Read CFI、Program(Word program)、Buffer Program、Block(Sector) Erase，涵盖读写擦最基本的三种操作，这些基本命令在主流厂商的NOR产品里都被支持。此外，NOR还支持更多高级命令（Blank Check、security/protect相关，lower power相关等），那些命令因Device而异，不是本文讨论重点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_cmd_set.PNG&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_cmd_set2.PNG&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_cmd_set3.PNG&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_cmd_set4.PNG&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_cmd_set5.PNG&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_cmd_set6.PNG&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_cmd_set7.PNG&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_cmd_set8.PNG&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_cmd_set9.PNG&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　除了读写擦这三个最基本命令外，还有一个Data Polling机制也非常常用，这个机制用于获取命令（主要是Program/Erase）执行状态与结果，当Program/Erase命令发给NOR device之后，NOR device是通过DQ[7:0]引脚来返回命令执行状态的，各bit意义如下图所示，简单来说DQ3（Erase timer bit）表明操作的开始，DQ5（Error bit）表明操作过程中是否发生硬件错误，DQ6（Toggle bit）表明操作是否结束。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_data_polling_register_bit.PNG&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_data_polling_register_bit2.PNG&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　下图为Toggle bit检测的流程图，这个检测流程是最常用的，主要用于确认Program/Erase操作是否成功地执行了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_toggle_bit_flowchart.PNG&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　此外，还有一个必有命令不得不提，这个命令是Read CFI，用于获取芯片内部存储的出厂信息（包括内存结构、特性、其他行为参数等），这个query table最多由五部分组成，其结构已由CFI规定如下表，痞子衡已经圈出了一些重要信息，在设计NOR软件驱动时，可以通过获取这个query table来做到代码通用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_query_table.PNG&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_query_table2.PNG&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_query_table3_1.PNG&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_query_table4.PNG&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;parallel-nor数据速率&quot;&gt;2.5 Parallel NOR数据速率&lt;/h4&gt;
&lt;p&gt;　　数据存取速率是个重要的技术指标，对于这个指标，CFI手册里并没有定义，所以需要根据NOR Flash手册里的AC characteristics表来确定。以异步模式Read命令为例讲解（以Micron生产的型号为MT28EW128ABA为例），下面是Read的两种模式Random Read和Page Read完整时序简图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_random_read_ac_timing_x16.PNG&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_page_read_ac_timing_x16.PNG&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　从上述时序图，我们可以知道Page Read平均数据率肯定是比Random Read要高的，那么这两种数据率分别能达到多少呢？可继续参看如下时序参数表，t&lt;sub&gt;RC&lt;/sub&gt;最小为70ns，那么Random Read数据率最大为2Bytes/70ns = 228.571Mbps，而t&lt;sub&gt;PAGE&lt;/sub&gt;最大为20ns，那么Page Read的数据率最小为2Bytes / 20ns = 800Mbps。（注：均以x16 Device为例）&lt;br/&gt;&lt;img src=&quot;http://odox9r8vg.bkt.clouddn.com/image/cnblogs/cfi_read_ac_characteristics.PNG&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　如果想快捷地了解NOR Flash的性能，最简单的就是打开NOR Flash手册，看首页的feature介绍，如下是MT28EW128ABA的简要feature：&lt;/p&gt;
&lt;pre class=&quot;text&quot;&gt;
&lt;code&gt;• Single-level cell (SLC) process technology
• Density: 128Mb
• Supply voltage
  – VCC = 2.7–3.6V (program, erase, read)
  – VCCQ = 1.65 - VCC (I/O buffers)
• Asynchronous random/page read
  – Page size: 16 words or 32 bytes
  – Page access: 20ns
  – Random access: 70ns (VCC = VCCQ = 2.7-3.6V)
  – Random access: 75ns (VCCQ = 1.65-VCC)
• Buffer program (512-word program buffer)
  – 2.0 MB/s (TYP) when using full buffer program
  – 2.5 MB/s (TYP) when using accelerated buffer program (VHH)
• Word/Byte program: 25us per word (TYP)
• Block erase (128KB): 0.2s (TYP)
• Memory organization
  – Uniform blocks: 128KB or 64KW each
  – x8/x16 data bus
• CFI (Common Flash Interface) support&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;三slc-parallel-nor产品&quot;&gt;三、SLC Parallel NOR产品&lt;/h3&gt;
&lt;p&gt;　　最后痞子衡收集了可以售卖SLC Parallel NOR芯片的厂商及产品系列：&lt;/p&gt;
&lt;table&gt;&lt;tbody readability=&quot;5.5830039525692&quot;&gt;&lt;tr&gt;&lt;th&gt;厂商&lt;/th&gt;
&lt;th&gt;芯片系列&lt;/th&gt;
&lt;th&gt;官方网址&lt;/th&gt;
&lt;/tr&gt;&lt;tr readability=&quot;0.63768115942029&quot;&gt;&lt;td&gt;Micron&lt;/td&gt;
&lt;td&gt;MT28EW, MT28FW&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://www.micron.com&quot;&gt;https://www.micron.com&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.micron.com/products/nor-flash/parallel-nor-flash/parallel-nor-flash-part-catalog#/&quot;&gt;parallel-nor-part-catalog&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;6.16&quot;&gt;&lt;td&gt;Macronix&lt;/td&gt;
&lt;td&gt;MX68GL&lt;br/&gt;MX29LA, MX29GL, MX29GA, MX29LV&lt;br/&gt;MX29VS, MX29NS, MX29SL, MX29F&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;http://www.macronix.com&quot;&gt;http://www.macronix.com&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://www.macronix.com/en-us/products/NOR-Flash/Parallel-NOR-Flash/Pages/default.aspx#!tabs=1-8V32Mb&quot;&gt;parallel-nor-part-catalog&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;0.4375&quot;&gt;&lt;td&gt;Winbond&lt;/td&gt;
&lt;td&gt;W29GL&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;http://www.winbond.com.tw&quot;&gt;http://www.winbond.com.tw&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://www.winbond.com.tw/hq/product/code-storage-flash-memory/parallel-nor-flash/?__locale=zh&amp;amp;selected=256Mbit#categoryArea&quot;&gt;parallel-nor-part-catalog&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;3&quot;&gt;&lt;td&gt;Spansion&lt;/td&gt;
&lt;td&gt;S29GL, S29AL, S29AS, S29PL&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;http://www.cypress.com/&quot;&gt;http://www.cypress.com/&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://www.cypress.com/products/parallel-nor-flash-memory&quot;&gt;parallel-nor-part-catalog&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;0.48979591836735&quot;&gt;&lt;td&gt;ISSI&lt;/td&gt;
&lt;td&gt;IS29GL&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;http://www.cnblogs.com/henjay724/p/www.issi.com&quot;&gt;www.issi.com&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://www.issi.com/US/product-flash.shtml#jump8&quot;&gt;parallel-nor-part-catalog&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;tr readability=&quot;0.7012987012987&quot;&gt;&lt;td&gt;Microchip&lt;/td&gt;
&lt;td&gt;SST38VF, SST39VF&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://www.microchip.com&quot;&gt;https://www.microchip.com&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;http://www.microchip.com/ParamChartSearch/chart.aspx?branchID=7130107&quot;&gt;parallel-nor-part-catalog&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;　　至此，CFI标准及SLC Parallel NOR痞子衡便介绍完毕了，掌声在哪里~~~&lt;/p&gt;
</description>
<pubDate>Sun, 01 Jul 2018 14:29:00 +0000</pubDate>
<dc:creator>痞子衡</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/henjay724/p/9251620.html</dc:identifier>
</item>
<item>
<title>三方依赖库扫描系统 - he1m4n6a</title>
<link>http://www.cnblogs.com/he1m4n6a/p/9230888.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/he1m4n6a/p/9230888.html</guid>
<description>&lt;h2&gt;简介&lt;/h2&gt;
&lt;p&gt;Dependency-Check 是一款分析软件构成的工具，他会检测项目中依赖项的公开披露漏洞。Dependency-Check 常用于扫描&lt;strong&gt;&lt;span&gt;java&lt;/span&gt;&lt;/strong&gt;和&lt;span&gt;&lt;strong&gt;.NET&lt;/strong&gt;&lt;/span&gt;程序，实验性的分析器有python、ruby、php以及nodejs，这些作为实验性研究是因为他们的高误报率。如果你公司主要使用c，java，这个系统作为作为上线前的扫描不乏是个好选择。&lt;/p&gt;

&lt;h2&gt;工作原理&lt;/h2&gt;
&lt;ol&gt;&lt;li&gt;Dependency-Check工作的方式是通过分析器对文件进行扫描搜集信息，搜集到的信息被叫做迹象。&lt;/li&gt;
&lt;li&gt;这边共搜集3种迹象，分时是vendor（供应商），product（产品）和version（版本）。例如，jarAnalyzer将从jar文件包中的Mainfest、pom.xml和包名进行信息搜集，然后把各种搜集到的源放到一个或者多个迹象表里。&lt;/li&gt;
&lt;li&gt;通过搜集到的迹象和CPE条目（NVD、CVE数据索引）进行匹配，分析器匹配到了就会给个标志发送到报告。&lt;/li&gt;
&lt;li&gt;Dependency-Check 目前&lt;span&gt;&lt;strong&gt;不使用hash&lt;/strong&gt;&lt;/span&gt;识别文件，因为第三方依赖从源码中的hash值构建通常不会匹配官方发布版本的hash。后续版本中可能会增加一些hash来匹配一些常用的第三方库，例如Spring, Struts等。&lt;/li&gt;
&lt;/ol&gt;&lt;h2&gt;常用命令&lt;/h2&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;./dependency-check.sh -n --project &quot;test&quot; --scan &quot;WEB-INF/lib/&quot; -o output.html&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;-n 不更新漏洞库，默认4小时自动拉取&lt;/li&gt;
&lt;li&gt;--project 项目名字&lt;/li&gt;
&lt;li&gt;--scan 扫描的路径或文件（可以扫目录，也可以直接扫压缩文件，zip，war，tgz等）&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;.&lt;br/&gt;/dependency-check.sh -n --project &quot;test&quot; --scan &quot;strusts2.war&quot; --log logfile&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;扫描压缩文件&lt;/li&gt;
&lt;li&gt;--log 日志记录&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;.&lt;/p&gt;
&lt;p&gt;./dependency-check.sh --updateonly&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;--updateonly 只更新数据库&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2&gt;报告解读&lt;/h2&gt;
&lt;p&gt;不完整的报告截图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1205448/201806/1205448-20180626191226751-1772312910.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Dependency - 被扫描的第三依赖库名字&lt;/li&gt;
&lt;li&gt;CPE - 所有被识别出来的CPE.&lt;/li&gt;
&lt;li&gt;GAV - Maven 组, Artifact, 版本 (GAV).&lt;/li&gt;
&lt;li&gt;Highest Severity - 所有关联的cve的最高漏洞等级&lt;/li&gt;
&lt;li&gt;CVE Count - 关联的cve个数&lt;/li&gt;
&lt;li&gt;CPE Confidence - dependency-check正确识别cpe的程度&lt;/li&gt;
&lt;li&gt;Evidence Count - 识别CPE的数据个数&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;使用场景&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;理解了上面depency-check的原理后，应业务的需求，需要把这个开源工具二进制版本封装成web界面，可供自己和业务方调用。笔者也实现了这个功能，github地址。在业务实际使用场景：&lt;/p&gt;
&lt;p&gt;1、如果项目迭代很快，项目很多。可以考虑配合代码管理系统，每次新发布前，自动打包文件进行扫描（报告没有修复参考，一般是推荐官方最新版包）&lt;/p&gt;
&lt;p&gt;2、如果项目不多，或者监控重点项目。可让业务提单，安全人员进行扫描后提供结果和修复建议给到业务方&lt;/p&gt;

&lt;p&gt;笔者对项目封装后的项目地址：&lt;a href=&quot;https://github.com/he1m4n6a/dcweb&quot; target=&quot;_blank&quot;&gt;https://github.com/he1m4n6a/dcweb&lt;/a&gt;，可以很方便的提交三方依赖库的压缩包进行扫描即可。&lt;/p&gt;

</description>
<pubDate>Sun, 01 Jul 2018 14:19:00 +0000</pubDate>
<dc:creator>he1m4n6a</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/he1m4n6a/p/9230888.html</dc:identifier>
</item>
<item>
<title>tensorflow机器学习模型的跨平台上线 - 刘建平Pinard</title>
<link>http://www.cnblogs.com/pinard/p/9251296.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/pinard/p/9251296.html</guid>
<description>&lt;p&gt;　　　　在&lt;a id=&quot;cb_post_title_url&quot; class=&quot;postTitle2&quot; href=&quot;https://www.cnblogs.com/pinard/p/9220199.html&quot;&gt;用PMML实现机器学习模型的跨平台上线&lt;/a&gt;中，我们讨论了使用PMML文件来实现跨平台模型上线的方法，这个方法当然也适用于tensorflow生成的模型，但是由于tensorflow模型往往较大，使用无法优化的PMML文件大多数时候很笨拙，因此本文我们专门讨论下tensorflow机器学习模型的跨平台上线的方法。&lt;/p&gt;

&lt;p&gt;　　　　tensorflow模型的跨平台上线的备选方案一般有三种：即PMML方式，tensorflow serving方式，以及跨语言API方式。&lt;/p&gt;
&lt;p&gt;　　　　PMML方式的主要思路在上一篇以及讲过。这里唯一的区别是转化生成PMML文件需要用一个Java库&lt;a title=&quot;jpmml-tensorflow&quot; href=&quot;https://github.com/jpmml/jpmml-tensorflow&quot; target=&quot;_blank&quot;&gt;jpmml-tensorflow&lt;/a&gt;来完成，生成PMML文件后，跨语言加载模型和其他PMML模型文件基本类似。&lt;/p&gt;
&lt;p&gt;　　　　tensorflow serving是tensorflow 官方推荐的模型上线预测方式，它需要一个专门的tensorflow服务器，用来提供预测的API服务。如果你的模型和对应的应用是比较大规模的，那么使用tensorflow serving是比较好的使用方式。但是它也有一个缺点，就是比较笨重，如果你要使用tensorflow serving，那么需要自己搭建serving集群并维护这个集群。所以为了一个小的应用去做这个工作，有时候会觉得麻烦。&lt;/p&gt;
&lt;p&gt;　　　　跨语言API方式是本文要讨论的方式，它会用tensorflow自己的Python API生成模型文件，然后用tensorflow的客户端库比如Java或C++库来做模型的在线预测。下面我们会给一个生成生成模型文件并用tensorflow Java API来做在线预测的例子。&lt;/p&gt;

&lt;p&gt;　　　　我们这里给一个简单的逻辑回归并生成逻辑回归tensorflow模型文件的例子。&lt;/p&gt;
&lt;p&gt;　　　　首先，我们生成了一个6特征，3分类输出的4000个样本数据。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; numpy as np
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; matplotlib.pyplot as plt
&lt;/span&gt;%&lt;span&gt;matplotlib inline
&lt;/span&gt;&lt;span&gt;from&lt;/span&gt; sklearn.datasets.samples_generator &lt;span&gt;import&lt;/span&gt;&lt;span&gt; make_classification
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; tensorflow as tf
X1, y1 &lt;/span&gt;= make_classification(n_samples=4000, n_features=6, n_redundant=&lt;span&gt;0,
                             n_clusters_per_class&lt;/span&gt;=1, n_classes=3)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　　　接着我们构建tensorflow的数据流图，这里要注意里面的两个名字，第一个是输入x的名字input,第二个是输出prediction_labels的名字output，这里的这两个名字可以自己取，但是后面会用到，所以要保持一致。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;46&quot;&gt;
&lt;pre&gt;
learning_rate = 0.01&lt;span&gt;
training_epochs &lt;/span&gt;= 600&lt;span&gt;
batch_size &lt;/span&gt;= 100&lt;span&gt;

x &lt;/span&gt;= tf.placeholder(tf.float32, [None, 6],name=&lt;span&gt;'&lt;/span&gt;&lt;span&gt;input&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;) &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 6 features&lt;/span&gt;
y = tf.placeholder(tf.float32, [None, 3]) &lt;span&gt;#&lt;/span&gt;&lt;span&gt; 3 classes&lt;/span&gt;
&lt;span&gt;
W &lt;/span&gt;= tf.Variable(tf.zeros([6, 3&lt;span&gt;]))
b &lt;/span&gt;= tf.Variable(tf.zeros([3&lt;span&gt;]))

&lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt; softmax回归&lt;/span&gt;
pred = tf.nn.softmax(tf.matmul(x, W) + b, name=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;softmax&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;) 
cost &lt;/span&gt;= tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1&lt;span&gt;))
optimizer &lt;/span&gt;=&lt;span&gt; tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)

prediction_labels &lt;/span&gt;= tf.argmax(pred, axis=1, name=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;output&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)

init &lt;/span&gt;= tf.global_variables_initializer()
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　　　接着就是训练模型了，代码比较简单，毕竟只是一个演示：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;49&quot;&gt;
&lt;pre&gt;
sess =&lt;span&gt; tf.Session()
sess.run(init)
y2 &lt;/span&gt;= tf.one_hot(y1, 3&lt;span&gt;)
y2 &lt;/span&gt;=&lt;span&gt; sess.run(y2)

&lt;/span&gt;&lt;span&gt;for&lt;/span&gt; epoch &lt;span&gt;in&lt;/span&gt;&lt;span&gt; range(training_epochs):

    _, c &lt;/span&gt;= sess.run([optimizer, cost], feed_dict=&lt;span&gt;{x: X1, y: y2})
    &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (epoch+1) % 10 ==&lt;span&gt; 0:
        &lt;/span&gt;&lt;span&gt;print&lt;/span&gt; (&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Epoch:&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;%04d&lt;/span&gt;&lt;span&gt;'&lt;/span&gt; % (epoch+1), &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;cost=&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;{:.9f}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;.format(c))
    
&lt;/span&gt;&lt;span&gt;print&lt;/span&gt; (&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;优化完毕!&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
correct_prediction &lt;/span&gt;= tf.equal(tf.argmax(pred, 1), tf.argmax(y2, 1&lt;span&gt;))
accuracy &lt;/span&gt;=&lt;span&gt; tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
acc &lt;/span&gt;= sess.run(accuracy, feed_dict=&lt;span&gt;{x: X1, y: y2})
&lt;/span&gt;&lt;span&gt;print&lt;/span&gt; (acc)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　　　打印输出我这里就不写了，大家可以自己去试一试。接着就是关键的一步，存模型文件了，注意要用convert_variables_to_constants这个API来保存模型，否则模型参数不会随着模型图一起存下来。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
graph = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, [&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;output&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;])
tf.train.write_graph(graph, &lt;/span&gt;&lt;span&gt;'&lt;/span&gt;&lt;span&gt;.&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, &lt;span&gt;'&lt;/span&gt;&lt;span&gt;rf.pb&lt;/span&gt;&lt;span&gt;'&lt;/span&gt;, as_text=False)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　　　至此，我们的模型文件rf.pb已经被保存下来了，下面就是要跨平台上线了。　&lt;/p&gt;

&lt;p&gt;　　　　这里我们以Java平台的模型上线为例，C++的API上线我没有用过，这里就不写了。我们需要引入tensorflow的java库到我们工程的maven或者gradle文件。这里给出maven的依赖如下，版本可以根据实际情况选择一个较新的版本。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
        &amp;lt;dependency&amp;gt;
            &amp;lt;groupId&amp;gt;org.tensorflow&amp;lt;/groupId&amp;gt;
            &amp;lt;artifactId&amp;gt;tensorflow&amp;lt;/artifactId&amp;gt;
            &amp;lt;version&amp;gt;1.7.0&amp;lt;/version&amp;gt;
        &amp;lt;/dependency&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　　　接着就是代码了，这个代码会比JPMML的要简单，我给出了4个测试样本的预测例子如下，一定要注意的是里面的input和output要和训练模型的时候对应的节点名字一致。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt; org.tensorflow.*&lt;span&gt;;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.tensorflow.Graph;

&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; java.io.IOException;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; java.nio.file.Files;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; java.nio.file.Paths;


&lt;/span&gt;&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
 * Created by 刘建平pinard on 2018/7/1.
 &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; TFjavaDemo {
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; main(String args[]){
        &lt;/span&gt;&lt;span&gt;byte&lt;/span&gt;[] graphDef = loadTensorflowModel(&quot;D:/rf.pb&quot;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;float&lt;/span&gt; inputs[][] = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;float&lt;/span&gt;[4][6&lt;span&gt;];
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;(&lt;span&gt;int&lt;/span&gt; i = 0; i&amp;lt; 4; i++&lt;span&gt;){
            &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;(&lt;span&gt;int&lt;/span&gt; j =0; j&amp;lt; 6;j++&lt;span&gt;){
                &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;(i&amp;lt;2&lt;span&gt;) {
                    inputs[i][j] &lt;/span&gt;= 2 * i - 5 * j - 6&lt;span&gt;;
                }
                &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;{
                    inputs[i][j] &lt;/span&gt;= 2 * i + 5 * j - 6&lt;span&gt;;
                }
            }
        }
        Tensor&lt;/span&gt;&amp;lt;Float&amp;gt; input =&lt;span&gt; covertArrayToTensor(inputs);
        Graph g &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Graph();
        g.importGraphDef(graphDef);
        Session s &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Session(g);
        Tensor result &lt;/span&gt;= s.runner().feed(&quot;input&quot;, input).fetch(&quot;output&quot;).run().get(0&lt;span&gt;);

        &lt;/span&gt;&lt;span&gt;long&lt;/span&gt;[] rshape =&lt;span&gt; result.shape();
        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; rs = (&lt;span&gt;int&lt;/span&gt;) rshape[0&lt;span&gt;];
        &lt;/span&gt;&lt;span&gt;long&lt;/span&gt; realResult[] = &lt;span&gt;new&lt;/span&gt; &lt;span&gt;long&lt;/span&gt;&lt;span&gt;[rs];
        result.copyTo(realResult);

        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt;(&lt;span&gt;long&lt;/span&gt;&lt;span&gt; a: realResult ) {
            System.out.println(a);
        }
    }
    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; &lt;span&gt;byte&lt;/span&gt;&lt;span&gt;[] loadTensorflowModel(String path){
        &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Files.readAllBytes(Paths.get(path));
        } &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (IOException e) {
            e.printStackTrace();
        }
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
    }

    &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;private&lt;/span&gt; Tensor&amp;lt;Float&amp;gt; covertArrayToTensor(&lt;span&gt;float&lt;/span&gt;&lt;span&gt; inputs[][]){
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Tensors.create(inputs);
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　　　我的预测输出是1,1,0,0，供大家参考。&lt;/p&gt;

&lt;p&gt;　　　　对于tensorflow来说，模型上线一般选择tensorflow serving或者client API库来上线，前者适合于较大的模型和应用场景，后者则适合中小型的模型和应用场景。因此算法工程师使用在产品之前需要做好选择和评估。&lt;/p&gt;

&lt;p&gt;（欢迎转载，转载请注明出处。欢迎沟通交流： liujianping-ok@163.com） &lt;/p&gt;
</description>
<pubDate>Sun, 01 Jul 2018 13:42:00 +0000</pubDate>
<dc:creator>刘建平Pinard</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/pinard/p/9251296.html</dc:identifier>
</item>
<item>
<title>了解java内存模型，看这里就够了 - 朱小杰</title>
<link>http://www.cnblogs.com/zhuxiaojie/p/9251447.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zhuxiaojie/p/9251447.html</guid>
<description>&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;转载请注明作者与出处&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;程序计数器&quot;&gt;程序计数器&lt;/h2&gt;
&lt;h3 id=&quot;线程私有&quot;&gt;线程私有&lt;/h3&gt;
&lt;p&gt;因为物理cpu并不多，所以jvm是对java里面的线程进行不停的切换执行，因为切换的执行速度太快，所以我们看到是并发执行。所以jvm在切换线程执行后，如果要切换回原来的线程，它需要记住这个线程的执行位置，下一条指令是什么。所以每一个线程都有一个独立的程序计数器，它是线程私有的。&lt;/p&gt;
&lt;h3 id=&quot;数据内容&quot;&gt;数据内容&lt;/h3&gt;
&lt;p&gt;程序计数器保存了每个对象的引用数量，但是也不仅仅是对象的引用，它保存了一个线程中一系列需要执行的字节码指令的内存地址，包括循环，异常等&lt;/p&gt;
&lt;h3 id=&quot;native方法&quot;&gt;native方法&lt;/h3&gt;
&lt;p&gt;如果当前正在执行的是native方法，那么它在程序计数器里面的值是空（&lt;code&gt;undefined&lt;/code&gt;）。&lt;/p&gt;
&lt;h2 id=&quot;java栈&quot;&gt;java栈&lt;/h2&gt;
&lt;h3 id=&quot;线程私有-1&quot;&gt;线程私有&lt;/h3&gt;
&lt;p&gt;java栈保存的是执行每一个方法的内容，所以每执行一个方法，都会创建一个栈帧(StackFrame)，保存局部变量，操作数栈，动态链接，方法的进出信息等，直到一个方法调用完成，就意味着一个栈帧从进去到出来的过程，所以它也是线程私有的。&lt;/p&gt;
&lt;h3 id=&quot;数据内容-1&quot;&gt;数据内容&lt;/h3&gt;
&lt;p&gt;java栈帧中，保存了当前局部的基本数据类型(boolean,byte,char,short,int,float,long,double)，以及&lt;strong&gt;对象引用&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;对象引用，这里指的是定义的那些对象，但是值得注意的是，这里保存的是引用，而不是具体的内容，当我们new一个对象时，jvm会把创建的引用放在栈里面，但是对象本身，是存在堆里面的，而引用只是保存了对象在堆里面的内存地址，这是因为栈内存很小，但是栈读取数据快，所以存储了引用，而我们开辟出来的对象，或者申请的内存是放在堆里面的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;局部变量所需要的内存，在一开始就是确定的，jvm会按照变量类型计算。因为当进入一个栈帧时，所需要的内存是确定的，直到出栈，这里面的内存不会发生任何变化。&lt;/p&gt;
&lt;h3 id=&quot;栈异常&quot;&gt;栈异常&lt;/h3&gt;
&lt;p&gt;jvm中对于栈规则了两种异常。&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;当java类中的方法进入次数太多时，会导致栈的层次越来越深，如果请求的栈深度，超出了jvm虚拟机所允许的深度，就会抛出&lt;code&gt;StackOverflowError&lt;/code&gt;异常。（当前绝大部分虚拟机都是可以动态调整栈深度的，所以一般不会出现这个问题，但是也不排除，因为jvm规范中也允许固定长度的栈深度）&lt;/li&gt;
&lt;li&gt;另一方面，如果扩展栈深度时，无法申请到足够的内存，就会抛出&lt;code&gt;OutOfMemoryError&lt;/code&gt;异常。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;所以当我们遍历文件夹的时候，最好不要用递归，因为可能出现栈溢出的异常。&lt;/p&gt;
&lt;h2 id=&quot;本地方法栈&quot;&gt;本地方法栈&lt;/h2&gt;
&lt;p&gt;本地方法栈所起的作用和java栈的作用几乎一致，只不过本地方法栈中，保存的是native方法的栈信息，但是虚拟机规范中，对于native方法的实现语言，实现类型，数据结构并没有明确规定，各种虚拟机可以自由实现它，比如Sun HotSpot虚拟机就把java栈和本地方法栈合二为一了。&lt;/p&gt;
&lt;p&gt;本地方法栈也有着&lt;code&gt;StackOverflowError&lt;/code&gt;和&lt;code&gt;OutOfMemoryError&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&quot;java堆&quot;&gt;java堆&lt;/h2&gt;
&lt;p&gt;堆是所有线程共享的，它是jvm管理内存的最大的一块区域，也是java程序员所能操控的内存区域。&lt;/p&gt;
&lt;h3 id=&quot;数据内容-2&quot;&gt;数据内容&lt;/h3&gt;
&lt;p&gt;java程序员所能操控的内存，虽然对于程序员来说没有感知，但实际上全部是在堆里面操作，比如我们new出来的对象，以及数组，其实都是存放在堆内存里面的。&lt;/p&gt;
&lt;h3 id=&quot;垃圾回收&quot;&gt;垃圾回收&lt;/h3&gt;
&lt;p&gt;java堆是gc回收内存的主要区域，因为现在的内存回收算法基本都是采用分代算法，所以还可以分为新生代和老生代，这样的分配是为了更快的找出需要回收的内存，提高gc效率。甚至还可以更往细分Eden,From Survivor,To Survivor等。&lt;/p&gt;
&lt;h3 id=&quot;空间大小&quot;&gt;空间大小&lt;/h3&gt;
&lt;p&gt;java堆里面的内存可以是物理上不连续的内存，只要是逻辑上连续就可以，一般主流虚拟机，都是可以在启动的时候，根据启动参数指定内存大小(-Xms -Xmx)，如果在使用内存时，jvm无法再申请新的堆内存，就会抛出&lt;code&gt;OutOfMemoryError&lt;/code&gt;异常。&lt;/p&gt;
&lt;h2 id=&quot;方法区&quot;&gt;方法区&lt;/h2&gt;
&lt;p&gt;方法区是所有线程共享的区域，方法区也叫永久代，因为它永远不会被gc回收。&lt;/p&gt;
&lt;h3 id=&quot;数据内容-3&quot;&gt;数据内容&lt;/h3&gt;
&lt;p&gt;用于存储虚拟机加载的类信息，常量，静态变量等数据，这些数据是在类加载器加载时候完成的，所以虽然说new出来的对象是存在堆里面的，但是如果这个对象是常量，那么在类加载器加载这个类的时候，就会把这些静态变量存储到方法区里面去。&lt;/p&gt;
&lt;h3 id=&quot;异常信息&quot;&gt;异常信息&lt;/h3&gt;
&lt;p&gt;同样的，方法区的内存无法满足内存的根本需求时，抛出&lt;code&gt;OutOfMemoryError&lt;/code&gt;异常&lt;/p&gt;
&lt;h2 id=&quot;堆外内存直接内存&quot;&gt;堆外内存（直接内存）&lt;/h2&gt;
&lt;p&gt;堆外内存是一块独立的内存，值得注意的是，它是由java程序员完全操纵的一个内存，意味着，程序员需要显式的申请内存，以及手动释放内存，因为它不由gc管理。&lt;/p&gt;
&lt;p&gt;它的优点是因为直接操作内存，在某些应用场景中，可以避免内存的复制，以及回收再创建，可以提升内存的利用率。&lt;/p&gt;
&lt;p&gt;它的缺点就是需要手动释放内存，而不是交给gc来处理，所以使用不当，很容易抛出&lt;code&gt;OutOfMemoryError&lt;/code&gt;异常。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;堆外内存不受到堆内存的限制，也就是不受到-Xmx的限制，但是还是受到物理内存的限制，如果超出物理内存，就就会抛出&lt;code&gt;OutOfMemoryError&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Sun, 01 Jul 2018 13:30:00 +0000</pubDate>
<dc:creator>朱小杰</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/zhuxiaojie/p/9251447.html</dc:identifier>
</item>
<item>
<title>记录一次线程池的在项目中的实际应用，讲解一下线程池的配置和参数理解。 - 致未来的自己</title>
<link>http://www.cnblogs.com/liran123/p/9251249.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/liran123/p/9251249.html</guid>
<description>&lt;h3&gt;&lt;span&gt;前言：最近项目中与融360项目中接口对接，有反馈接口（也就是我们接收到请求，需要立即响应，并且还要有一个接口推送给他们其他计算结果），推送过程耗时、或者说两个接口不能是同时返回，有先后顺序。&lt;/span&gt;&lt;/h3&gt;
&lt;h3&gt;这时我想到了把自己Controller立即返回接受成功，中间添加一个新的线程去做其他耗时的操作(线程池配置和参数测试讲解请阅读第5步)。&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;1、Controller代码如下：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;45&quot;&gt;
&lt;pre&gt;
@Autowired&lt;br/&gt;private CallThreadDemo worker;
&lt;/pre&gt;
&lt;pre&gt;
@RequestMapping(&quot;/bandBankConfirm2&quot;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; bandBankConfirm2(String jsonString) {
        System.out.println(&lt;/span&gt;&quot;controller开始--------------&quot;&lt;span&gt;);&lt;br/&gt;　　　　//这里是需要调用第三方的接口传入参数
        String method &lt;/span&gt;= &quot;is.api.v3.order.bindcardfeedback&quot;&lt;span&gt;;
        Map&lt;/span&gt;&amp;lt;String, Object&amp;gt; map = &lt;span&gt;new&lt;/span&gt; HashMap&amp;lt;&amp;gt;&lt;span&gt;();
        map.put(&lt;/span&gt;&quot;order_no&quot;, &quot;254986512848973&quot;&lt;span&gt;);
        map.put(&lt;/span&gt;&quot;bind_status&quot;, 1&lt;span&gt;);
        map.put(&lt;/span&gt;&quot;reason&quot;, &quot;&quot;&lt;span&gt;);
　　　　//这里开始调用线程池的方法
        worker.callRong360(method, map);
        System.out.println(&lt;/span&gt;&quot;controller  end --------------&quot;&lt;span&gt;);&lt;br/&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;span&gt;　　　　//renderJson这个方法是jfinal的，可以理解为@ReponseBody 需要return的操作了&lt;br/&gt;&lt;/span&gt;&lt;span&gt;　　　　renderJson(&lt;/span&gt;&quot;接口调用完毕&quot;&lt;span&gt;);&lt;/span&gt;&lt;span&gt;　　　&lt;/span&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;span&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;span&gt;&lt;span&gt;2、调用线程池的方法 &lt;/span&gt;&lt;em&gt;&lt;span&gt;CallThreadDemo 类代码：&lt;/span&gt;&lt;br/&gt;&lt;/em&gt;&lt;/span&gt;
&lt;/pre&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre readability=&quot;4.5&quot;&gt;
&lt;span&gt;@Component
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; CallThreadDemo {
&lt;br/&gt;　　　//这里是Spring.xml中配置的bean名称
    @Autowired
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; ThreadPoolTaskExecutor executor;
    @Autowired
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; ServiceTest serviceTest;

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; callRong360(&lt;span&gt;final&lt;/span&gt; String method, &lt;span&gt;final&lt;/span&gt; Map&amp;lt;String, Object&amp;gt;&lt;span&gt; map) {
        &lt;/span&gt;&lt;span&gt;//这个类是我封装的抽象类，里面有一个公共方法，具体代码下面有&lt;/span&gt;
        ServiceParent callRong360Method = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ServiceParent() {
            @Override
            &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; run() {
                &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
                    Thread.sleep(&lt;/span&gt;20000&lt;span&gt;);
                } &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (InterruptedException e) {
                    e.printStackTrace();
                }
                System.out.println(&lt;/span&gt;&quot;线程开始-------------&quot;&lt;span&gt;);&lt;br/&gt;　　　　　　　　　　//这里调用第三方公用接口
                JSONObject result &lt;/span&gt;=&lt;span readability=&quot;3&quot;&gt; callBandBankMethod(method, map);&lt;p&gt;　　　　　　　　　　//这里调用service方法，实现自己的业务逻辑
                serviceTest.insertUser(&lt;/p&gt;&lt;/span&gt;&quot;111&quot;, &quot;222222&quot;&lt;span&gt;);&lt;br/&gt;System.out.println(result);
                System.out.println(&lt;/span&gt;&quot;线程结束-------------&quot;&lt;span&gt;);

            }
        };&lt;br/&gt;　　　　　//这里线程池方法调用一个线程继承类或者实现Runable接口的类
        executor.execute(callRong360Method);

        System.out.println(&lt;/span&gt;&quot;当前活动线程数：&quot;+&lt;span&gt; executor.getActiveCount());
        System.out.println(&lt;/span&gt;&quot;核心线程数：&quot;+&lt;span&gt; executor.getCorePoolSize());
        System.out.println(&lt;/span&gt;&quot;总线程数：&quot;+&lt;span&gt; executor.getPoolSize());
        System.out.println(&lt;/span&gt;&quot;最大线程池数量&quot;+&lt;span&gt;executor.getMaxPoolSize());
        System.out.println(&lt;/span&gt;&quot;线程处理队列长度&quot;+&lt;span&gt;executor.getThreadPoolExecutor().getQueue().size());
    }
    &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;3、封装的抽象类代码如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;class&lt;/span&gt; ServiceParent &lt;span&gt;implements&lt;/span&gt;&lt;span&gt; Runnable {

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; JSONObject callBandBankMethod(String method, Map&amp;lt;String, Object&amp;gt;&lt;span&gt; map) {&lt;br/&gt;//这个方法是调用三方的接口，公用部分
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;  &lt;span&gt;//&lt;/span&gt;&lt;span&gt;输入 参数如下 ：
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;        Map&amp;lt;String, Object&amp;gt; map = new HashMap&amp;lt;&amp;gt;();
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;        map.put(&quot;order_no&quot;, &quot;254986512848973&quot;);
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;        map.put(&quot;bind_status&quot;, 1);
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;        map.put(&quot;reason&quot;, &quot;&quot;);
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;        net.sf.json.JSONObject ret = callRong360Method.callBandBankMethod(&quot;is.api.v3.order.bindcardfeedback&quot;, map);
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;
&lt;span&gt;//&lt;/span&gt;    &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 异常情况输出参数 为 null：&lt;/span&gt;
        OpenapiClient openapiClient = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; OpenapiClient();
        openapiClient.setMethod(method);
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; (Map.Entry&amp;lt;String, Object&amp;gt;&lt;span&gt; entry : map.entrySet()) {
            openapiClient.setField(entry.getKey(), String.valueOf(entry.getValue()));
        }
        net.sf.json.JSONObject ret &lt;/span&gt;= &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
        &lt;/span&gt;&lt;span&gt;try&lt;/span&gt;&lt;span&gt; {
            ret &lt;/span&gt;=&lt;span&gt; openapiClient.execute();
        } &lt;/span&gt;&lt;span&gt;catch&lt;/span&gt;&lt;span&gt; (Exception e) {
            e.printStackTrace();
            System.out.println(&lt;/span&gt;&quot;调用反馈接口异常----&amp;gt;&quot; +&lt;span&gt; e.getMessage());
        }
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; ret;
    }
　　//这里定义为抽象方法，创建匿名内部类或者继承类必须实现
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;abstract&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; run();
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;4、ServiceTest接口方法如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;@Service
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ServiceTest {

    @Autowired
    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt;&lt;span&gt; BankMapper bankMapper;

    @Transactional(rollbackFor &lt;/span&gt;= {Exception.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;})
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; insertUser(String s, String s1) {
        bankMapper.insertUser(s, s1);

         &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;这里创建异常，测试事务。已测试，事务生效&lt;/span&gt;
        &lt;span&gt;int&lt;/span&gt; i = 1 / 0&lt;span&gt;;
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;以上四步，成功在调用Controller方法立即返回结果，也实现了另外的一个线程去调用三方接口返回信息，并且实现了自己的业务逻辑。&lt;/p&gt;
&lt;p&gt;5、接着我们继续说明一下线程池对应配置和参数说明，这里我们通过测试来说明参数的作用（corePoolSize 核心线程数量,maxPoolSize 最大线程数,queueCapacity 处理队列）&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
　　threadpool.corePoolSize=5&lt;br/&gt;　　threadpool.keepAliveSeconds=200&lt;br/&gt;　　threadpool.maxPoolSize=10&lt;br/&gt;　　threadpool.queueCapacity=2
&lt;/pre&gt;
&lt;pre&gt;
　　&amp;lt;!-- 线程池 --&amp;gt;
    &amp;lt;bean id=&quot;taskExecutor&quot; &lt;span&gt;class&lt;/span&gt;=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&amp;gt;
        &amp;lt;property name=&quot;corePoolSize&quot; value=&quot;${threadpool.corePoolSize}&quot; /&amp;gt;
        &amp;lt;property name=&quot;keepAliveSeconds&quot; value=&quot;${threadpool.keepAliveSeconds}&quot; /&amp;gt;
        &amp;lt;property name=&quot;maxPoolSize&quot; value=&quot;${threadpool.maxPoolSize}&quot; /&amp;gt;
        &amp;lt;property name=&quot;queueCapacity&quot; value=&quot;${threadpool.queueCapacity}&quot; /&amp;gt;
    &amp;lt;/bean&amp;gt;
        &amp;lt;!--请在bean xsd中配置task--&amp;gt;
    &amp;lt;task:annotation-driven executor=&quot;taskExecutor&quot; /&amp;gt;
    
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;下面贴出测试输出的日志信息：controller开始--------------&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre readability=&quot;11.5&quot;&gt;
&lt;em readability=&quot;17&quot;&gt;&lt;span&gt;当前活动线程数：&lt;/span&gt;1&lt;span&gt;
核心线程数：&lt;/span&gt;5&lt;span&gt;
总线程数：&lt;/span&gt;1&lt;span&gt;
最大线程池数量10
线程处理队列长度0
controller  end &lt;/span&gt;--------------&lt;p&gt;&lt;span&gt;controller开始&lt;/span&gt;--------------&lt;span&gt;
当前活动线程数：&lt;/span&gt;2&lt;span&gt;
核心线程数：&lt;/span&gt;5&lt;span&gt;
总线程数：&lt;/span&gt;2&lt;span&gt;
最大线程池数量10
线程处理队列长度0
controller  end &lt;/span&gt;--------------&lt;/p&gt;&lt;p&gt;&lt;span&gt;controller开始&lt;/span&gt;--------------&lt;span&gt;
当前活动线程数：&lt;/span&gt;3&lt;span&gt;
核心线程数：&lt;/span&gt;5&lt;span&gt;
总线程数：&lt;/span&gt;3&lt;span&gt;
最大线程池数量10
线程处理队列长度0
controller  end &lt;/span&gt;--------------&lt;/p&gt;&lt;p&gt;&lt;span&gt;controller开始&lt;/span&gt;--------------&lt;span&gt;
当前活动线程数：&lt;/span&gt;4&lt;span&gt;
核心线程数：&lt;/span&gt;5&lt;span&gt;
总线程数：&lt;/span&gt;4&lt;span&gt;
最大线程池数量10
线程处理队列长度0
controller  end &lt;/span&gt;--------------&lt;/p&gt;&lt;p&gt;&lt;span&gt;controller开始&lt;/span&gt;--------------&lt;span&gt;
当前活动线程数：&lt;/span&gt;5&lt;span&gt;
核心线程数：&lt;/span&gt;5&lt;span&gt;
总线程数：&lt;/span&gt;5&lt;span&gt;
最大线程池数量10
线程处理队列长度0
controller  end &lt;/span&gt;--------------&lt;/p&gt;&lt;p&gt;&lt;span&gt;controller开始&lt;/span&gt;--------------&lt;span&gt;
当前活动线程数：&lt;/span&gt;5---------------》因为放入了队列中，此处活动线程数还是5&lt;span&gt;
核心线程数：&lt;/span&gt;5&lt;span&gt;
总线程数：&lt;/span&gt;5&lt;span&gt;
最大线程池数量10
线程处理队列长度1  -------------》这里达到了最大的核心线程数量 &lt;/span&gt;corePoolSize=5，开始放入处理队列中&lt;/p&gt;&lt;/em&gt;queueCapacity=2&lt;br/&gt;&lt;em id=&quot;__mceDel&quot;&gt;&lt;span&gt;controller end &lt;/span&gt;--------------&lt;/em&gt;
&lt;/pre&gt;
&lt;pre readability=&quot;16.5&quot;&gt;
&lt;em id=&quot;__mceDel&quot; readability=&quot;27&quot;&gt;&lt;span&gt;controller开始&lt;/span&gt;--------------&lt;span&gt;
当前活动线程数：&lt;/span&gt;5&lt;span&gt;
核心线程数：&lt;/span&gt;5&lt;span&gt;
总线程数：&lt;/span&gt;5&lt;span&gt;
最大线程池数量10
线程处理队列长度2　---------------》继续放入队列中，达到了最大队列数量2
controller  end &lt;/span&gt;--------------&lt;p&gt;&lt;span&gt;controller开始&lt;/span&gt;--------------&lt;span&gt;
当前活动线程数：&lt;/span&gt;6-----------------》这里因为达到了最大队列数量，所以继续创建线程去执行，一直到最后到最大线程数量&lt;span&gt;
核心线程数：&lt;/span&gt;5&lt;span&gt;
总线程数：&lt;/span&gt;6&lt;span&gt;
最大线程池数量10
线程处理队列长度2
controller  end &lt;/span&gt;--------------&lt;/p&gt;&lt;p&gt;&lt;span&gt;controller开始&lt;/span&gt;--------------&lt;span&gt;
当前活动线程数：&lt;/span&gt;7&lt;span&gt;
核心线程数：&lt;/span&gt;5&lt;span&gt;
总线程数：&lt;/span&gt;7&lt;span&gt;
最大线程池数量10
线程处理队列长度2
controller  end &lt;/span&gt;--------------&lt;/p&gt;&lt;p&gt;&lt;span&gt;controller开始&lt;/span&gt;--------------&lt;span&gt;
当前活动线程数：&lt;/span&gt;8&lt;span&gt;
核心线程数：&lt;/span&gt;5&lt;span&gt;
总线程数：&lt;/span&gt;8&lt;span&gt;
最大线程池数量10
线程处理队列长度2
controller  end &lt;/span&gt;--------------&lt;/p&gt;&lt;p&gt;&lt;span&gt;controller开始&lt;/span&gt;--------------&lt;span&gt;
当前活动线程数：&lt;/span&gt;9&lt;span&gt;
核心线程数：&lt;/span&gt;5&lt;span&gt;
总线程数：&lt;/span&gt;9&lt;span&gt;
最大线程池数量10
线程处理队列长度2
controller  end &lt;/span&gt;--------------&lt;/p&gt;&lt;p&gt;&lt;span&gt;controller开始&lt;/span&gt;--------------&lt;span&gt;
当前活动线程数：&lt;/span&gt;10　--------------》这里活动线程数量达到了最大线程池数量&lt;span&gt;
核心线程数：&lt;/span&gt;5&lt;span&gt;
总线程数：&lt;/span&gt;10&lt;span&gt;
最大线程池数量10
线程处理队列长度2
controller  end &lt;/span&gt;--------------&lt;/p&gt;&lt;p&gt;&lt;span&gt;controller开始&lt;/span&gt;--------------

2018-07-01 20:23:19　-----------------》这里继续调用，因为最大线程池数量和队列中都已经到了最大值，抛出了异常&lt;span&gt;
 [] [] [WARN]&lt;/span&gt;-[Thread: qtp1276504061-60]-&lt;span&gt;[org.springframework.web.servlet.handler.AbstractHandlerExceptionResolver.logException()]: Handler execution resulted in exception
org.springframework.core.task.TaskRejectedException: Executor [java.util.concurrent.ThreadPoolExecutor@17d95b77[Running, pool size &lt;/span&gt;= 10, active threads = 10, queued tasks = 2, completed tasks = 0]] did not accept task: com.fastx.cooperate.rong360.rong.service.CallThreadDemo$1&lt;span&gt;@5fa6bf1
    at org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor.execute(ThreadPoolTaskExecutor.java:&lt;/span&gt;245&lt;span&gt;)
    at com.fastx.cooperate.rong360.rong.service.CallThreadDemo.callRong360(CallThreadDemo.java:&lt;/span&gt;43)&lt;/p&gt;&lt;/em&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这样，通过输出的日志，我们可以很容易的理解了各个参数的作用。&lt;/p&gt;
&lt;pre&gt;
&lt;span&gt;&lt;em id=&quot;__mceDel&quot;&gt; &lt;/em&gt;&lt;/span&gt;
&lt;/pre&gt;</description>
<pubDate>Sun, 01 Jul 2018 12:57:00 +0000</pubDate>
<dc:creator>致未来的自己</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/liran123/p/9251249.html</dc:identifier>
</item>
<item>
<title>Angularjs的$apply及其优化使用 - 北辰狼月</title>
<link>http://www.cnblogs.com/yky-iris/p/9251230.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yky-iris/p/9251230.html</guid>
<description>&lt;p&gt;今天，我们要聊得是Angularjs中的小明星$apply。当我们数据更新了，但是view层却没反应时，总能听到有人说，用apply吧，然后，懵懂无知的我们，在赋值代码后面加了$scope.$apply(),然后就惊喜的发现。噢，真的更新了。&lt;br/&gt;然而，有些时候，编译器会无情的给你返回&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Error: $digest already in progress&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;那么，导致这些现象的原因时什么的呢？$apply究竟干了啥？听我慢慢到来。&lt;/p&gt;
&lt;h3 id=&quot;一.apply的作用&quot;&gt;一.$apply的作用&lt;/h3&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;$apply()函数可以从Angular框架的外部让表达式在Angular上下文内部执行。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上面是AngularJs权威教程中的一句话。什么意思呢？&lt;br/&gt;首先，你要清楚，在原生js或者第三方框架下，修改model，是有可能不会触发视图更新的，比如setTimeout、jquery插件。为什么？因为他们脱离了Angularjs的上下文，Angularjs并不能监听到数据的改变。看例子。&lt;/p&gt;
&lt;h4 id=&quot;settimeout&quot;&gt;1.setTimeout&lt;/h4&gt;
&lt;p&gt;html:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;p&amp;gt;{{name}}&amp;lt;/p&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;js:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$scope.name=&quot;张三&quot;;
setTimeout(function(){
$scope.name = '李四';
//$scope.$apply()
},500)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;首先，name等于张三，500ms后，我把他赋值为李四，但是，页面上并没有改变，依然是张三。&lt;br/&gt;而，我们把$scope.$apply()放开，就正常了，张三成功变为李四。&lt;/p&gt;
&lt;h4 id=&quot;第三方插件&quot;&gt;2.第三方插件&lt;/h4&gt;
&lt;p&gt;html:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;p&amp;gt;Date: &amp;lt;input type=&quot;text&quot; id=&quot;datepicker&quot;&amp;gt;&amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt;
&amp;lt;header&amp;gt;所选日期&amp;lt;/header&amp;gt;
{{selectedDate}}
&amp;lt;/p&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;js:&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$scope.selectedDate = '';
$( function() {
    $( &quot;#datepicker&quot; ).datepicker({
    onClose: function( selectedDate ) {
        $scope.selectedDate = selectedDate;
        // $scope.$apply();
    }
    });
} );&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这是jquery的datepicker插件，当我们选定日期后，下面的日期应该随之显现，而现在却没有。这种情况就必须依靠$apply(),才能更新视图。&lt;/p&gt;
&lt;p&gt;以上两种情况，都因为不处于Angularjs上下文中，导致监听不到数据的变化。而$apply究竟干了什么，才导致数据更新正常了呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;其实$apply相当于一个触发器，它的作用就是触发digest循环，从而更新视图。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在digest是Angularjs的核心，是它实现了神奇的数据绑定。凡是触发事件，必会触发digest循环，比如，我们数值的ng事件，click啊，change,实际上都是触发了digest循环。&lt;/p&gt;
&lt;p&gt;所以，我们所做的事，其实就是手动触发了digest循环。关于digest循环，属于题外话，这里不做过多介绍，想深入了解的同学，可以看看书籍，或者百度。&lt;/p&gt;
&lt;h4 id=&quot;二.更好地运用digest循环&quot;&gt;二.更好地运用digest循环&lt;/h4&gt;
&lt;p&gt;在Angularjs中，除了$apply可以触发digest循环外，还有其他的方法，也可以触发此循环。而且$apply往往时最坏的选择。下面推荐一些更好的选择。&lt;/p&gt;
&lt;h4 id=&quot;digest&quot;&gt;1.$digest&lt;/h4&gt;
&lt;p&gt;$scope.$digest()的速度要比$apply要快，因为它只更新当前作用域和子作用域的值，对于父作用域时不管的。而$apply还要评估父作用域，这就大大消耗了性能。&lt;/p&gt;
&lt;h4 id=&quot;timeout&quot;&gt;2.$timeout&lt;/h4&gt;
&lt;p&gt;用$timeout去代替你的setTimeout,$timeout作为Angularjs的自带服务，当然时更契合Angularjs环境啦。它会隐性触发digest循环，而且它会延迟执行，会在上一个digest循环完成后的下一刻，触发digest循环，这样就不会出现上文所说的&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$digest already in progress&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我们把setTime的代码放到$timeout中&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$timeout(function(){
$scope.name = '李四';
},500)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这就能正常工作了，看，没有讨厌的apply了！&lt;/p&gt;
&lt;h4 id=&quot;evalasync&quot;&gt;3.$evalAsync&lt;/h4&gt;
&lt;p&gt;最推荐的应该时这个方法了。如果当前正好有一个digest循环在执行，那么它就会把导致digest循环的操作，放到当前digest循环中去执行。而$timeout是要等到当前digest循环执行完，再执行一次digest循环才可以。所以evalAsync执行更快，性能更好。我们可以像$timeout那样去调用它，即&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$scope.$evalAsync(
                    function( $scope ) {
                        console.log( &quot;$evalAsync&quot; );
                    }
                );
    &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上，就是今天要说的全部内容。Angularjs中还藏着许多奥秘，和更好的使用方法，希望大家可以深入地研究，分享出更好的文章。&lt;br/&gt;下面是可执行的代码，大家可以探究探究&lt;br/&gt;&lt;a href=&quot;https://codepen.io/hanwolfxue/pen/yEZbYQ&quot; class=&quot;uri&quot;&gt;https://codepen.io/hanwolfxue/pen/yEZbYQ&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 01 Jul 2018 12:48:00 +0000</pubDate>
<dc:creator>北辰狼月</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/yky-iris/p/9251230.html</dc:identifier>
</item>
<item>
<title>解决TensorFlow的ImportError: DLL load failed: 动态链接库(DLL)初始化例程失败 - wwcom123</title>
<link>http://www.cnblogs.com/wwcom123/p/9251081.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wwcom123/p/9251081.html</guid>
<description>&lt;h2&gt;&lt;strong&gt;【背景】&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　在scikit-learn基础上系统结合数学和编程的角度学习了机器学习后(我的github:&lt;a href=&quot;https://github.com/wwcom614/machine-learning&quot; target=&quot;_blank&quot;&gt;https://github.com/wwcom614/machine-learning&lt;/a&gt;)，意犹未尽，打算再借势学习下深度学习TensorFlow。无奈安装之后遇到了这个问题，耽误了几个小时才得以解决。&lt;/p&gt;
&lt;p&gt;我发现这是个很多人开始TensorFlow之旅普遍遇到的问题，而且是很多人尝试了网上很多方法都未解决的问题。排坑过程很烦，主要是各种尝试很耗时间，最终自己找到了原因，解决了问题，共享给各位同学，少走弯路，抓紧上路，呵呵。&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;【遇到问题】&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;我是在Windows环境下，使用Anaconda3的python3.6.5环境，安装TensorFlow最简单的CPU版本(自己的搓平板电脑不支持GPU)：&lt;/p&gt;
&lt;p&gt;管理员身份运行Anaconda Prompt，然后执行：pip install tensorflow&lt;/p&gt;
&lt;p&gt;安装过程非常顺利，Python中  import tensorflow  也OK&lt;/p&gt;
&lt;p&gt;但是运行tensorflow程序时，报：&lt;/p&gt;
&lt;p&gt;File &quot;路径\Python\Python36\lib\importlib\__init__.py&quot;, line 126, in import_module&lt;br/&gt;return _bootstrap._gcd_import(name[level:], package, level)&lt;br/&gt;File &quot;&amp;lt;frozen importlib._bootstrap&amp;gt;&quot;, line 978, in _gcd_import&lt;br/&gt;File &quot;&amp;lt;frozen importlib._bootstrap&amp;gt;&quot;, line 961, in _find_and_load&lt;br/&gt;File &quot;&amp;lt;frozen importlib._bootstrap&amp;gt;&quot;, line 950, in _find_and_load_unlocked&lt;br/&gt;File &quot;&amp;lt;frozen importlib._bootstrap&amp;gt;&quot;, line 648, in _load_unlocked&lt;br/&gt;File &quot;&amp;lt;frozen importlib._bootstrap&amp;gt;&quot;, line 560, in module_from_spec&lt;br/&gt;File &quot;&amp;lt;frozen importlib._bootstrap_external&amp;gt;&quot;, line 922, in create_module&lt;br/&gt;File &quot;&amp;lt;frozen importlib._bootstrap&amp;gt;&quot;, line 205, in _call_with_frames_removed&lt;br/&gt;ImportError: DLL load failed: 动态链接库(DLL)初始化例程失败。&lt;/p&gt;

&lt;h2&gt;&lt;strong&gt;【解决过程】&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;　　网上搜索有人说，这是使用Python3.6导致的，TensorFlow目前只支持Python3.5。但我在TensorFlow官网发现其已经支持Python3.6。但我考虑也许最新版本支持不完善？反正咱用的是Anaconda，换个Python版本so easy(有兴趣可以查看我的另外一篇使用Anaconda的博客&lt;a href=&quot;https://www.cnblogs.com/wwcom123/p/9152909.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/wwcom123/p/9152909.html&lt;/a&gt;)。轻松切换为Python3.5环境，发现问题依旧，那么不是这个问题。&lt;/p&gt;
&lt;p&gt;　　于是我换回Python3.6.5版本继续尝试。&lt;/p&gt;
&lt;p&gt;　　网上还有人说，这是未安装微软的Microsoft Visual C++ 2015 Redistributable Update 3导致，于是到&lt;a href=&quot;https://www.microsoft.com/zh-cn/download/confirmation.aspx?id=53587&quot; target=&quot;_blank&quot;&gt;https://www.microsoft.com/zh-cn/download/confirmation.aspx?id=53587&lt;/a&gt;下载安装，发现机器上本来就有，而且问题依旧，那么也不是这个问题。&lt;/p&gt;
&lt;p&gt;　　最终想到，也许是最新版本有兼容性问题，安装老版本的TensorFlow尝试一下，于是管理员身份运行Anaconda Prompt，先卸载之前安装的最新版版本的TensorFlow：pip uninstall tensorflow   , 然后执行：pip install tensorflow==1.3。结果问题解决。&lt;/p&gt;

&lt;h2&gt;【结论】&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;　&lt;/strong&gt;　目前可以基于Python3.6.5版本进行TensorFlow开发。根本原因是自己的电脑不新，CPU尽管是Intel的，但不新也许太老不主流了，TensorFlow的新版本已不打算继续支持这种CPU了。所以我尝试1.3版本的TensorFlow是OK的，但最新的1.8版本就报错了(1.4版本会有个warning)。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;uploading_image_95450&quot; src=&quot;https://common.cnblogs.com/images/loading.gif&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 01 Jul 2018 11:51:00 +0000</pubDate>
<dc:creator>wwcom123</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/wwcom123/p/9251081.html</dc:identifier>
</item>
</channel>
</rss>