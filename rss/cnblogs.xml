<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>史上最全的数据库面试题，不看绝对后悔 - 追寻自我</title>
<link>http://www.cnblogs.com/wenxiaofei/p/9853682.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wenxiaofei/p/9853682.html</guid>
<description>&lt;h2 id=&quot;一基本概念&quot;&gt;一、基本概念&lt;/h2&gt;
&lt;h4 id=&quot;主键外键超键候选键&quot;&gt;&lt;strong&gt;1.主键、外键、超键、候选键&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;超键&lt;/strong&gt;：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;候选键&lt;/strong&gt;：是最小超键，即没有冗余元素的超键。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;主键&lt;/strong&gt;：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;外键&lt;/strong&gt;：在一个表中存在的另一个表的主键称此表的外键。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;为什么用自增列作为主键&quot;&gt;&lt;strong&gt;2.为什么用自增列作为主键&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;25&quot;&gt;
&lt;p&gt;如果我们定义了主键(PRIMARY KEY)，那么InnoDB会选择主键作为聚集索引、&lt;/p&gt;
&lt;p&gt;如果没有显式定义主键，则InnoDB会选择第一个不包含有NULL值的唯一索引作为主键索引、&lt;/p&gt;
&lt;p&gt;如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐含的聚集索引(ROWID随着行记录的写入而主键递增，这个ROWID不像ORACLE的ROWID那样可引用，是隐含的)。&lt;/p&gt;
&lt;p&gt;数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）&lt;/p&gt;
&lt;p&gt;如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页&lt;/p&gt;
&lt;p&gt;如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置，此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;触发器的作用&quot;&gt;&lt;strong&gt;3.触发器的作用？&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;触发器是一种特殊的存储过程，主要是通过事件来触发而被执行的。它可以强化约束，来维护数据的完整性和一致性，可以跟踪数据库内的操作从而不允许未经许可的更新和变化。可以联级运算。如，某表上的触发器上包含对另一个表的数据操作，而该操作又会导致该表触发器被触发。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;什么是存储过程用什么来调用&quot;&gt;&lt;strong&gt;4.什么是存储过程？用什么来调用？&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;存储过程是一个预编译的SQL语句，优点是允许模块化的设计，就是说只需创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次SQL，使用存储过程比单纯SQL语句执行要快。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;调用：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1）可以用一个命令对象来调用存储过程。&lt;/p&gt;
&lt;p&gt;2）可以供外部程序调用，比如：java程序。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;存储过程的优缺点&quot;&gt;&lt;strong&gt;5.存储过程的优缺点？&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;12&quot;&gt;
&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1）存储过程是预编译过的，执行效率高。&lt;/p&gt;
&lt;p&gt;2）存储过程的代码直接存放于数据库中，通过存储过程名直接调用，减少网络通讯。&lt;/p&gt;
&lt;p&gt;3）安全性高，执行存储过程需要有一定权限的用户。&lt;/p&gt;
&lt;p&gt;4）存储过程可以重复使用，可减少数据库开发人员的工作量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缺点：&lt;/strong&gt;移植性差&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;存储过程与函数的区别&quot;&gt;&lt;strong&gt;6.存储过程与函数的区别&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/ymE9HPJ.png&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;什么叫视图游标是什么&quot;&gt;&lt;strong&gt;7.什么叫视图？游标是什么？&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;&lt;strong&gt;视图：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;是一种虚拟的表，具有和物理表相同的功能。可以对视图进行增，改，查，操作，试图通常是有一个表或者多个表的行或列的子集。对视图的修改会影响基本表。它使得我们获取数据更容易，相比多表查询。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;游标：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;是对查询出来的结果集作为一个单元来有效的处理。游标可以定在该单元中的特定行，从结果集的当前行检索一行或多行。可以对结果集当前行做修改。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;视图的优缺点&quot;&gt;&lt;strong&gt;8.视图的优缺点&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;14&quot;&gt;
&lt;p&gt;&lt;strong&gt;优点：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1对数据库的访问，因为视图可以有选择性的选取数据库里的一部分。&lt;/p&gt;
&lt;p&gt;2)用户通过简单的查询可以从复杂查询中得到结果。&lt;/p&gt;
&lt;p&gt;3)维护数据的独立性，试图可从多个表检索数据。&lt;/p&gt;
&lt;p&gt;4)对于相同的数据可产生不同的视图。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缺点：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;性能：查询视图时，必须把视图的查询转化成对基本表的查询，如果这个视图是由一个复杂的多表查询所定义，那么，那么就无法更改数据&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;droptruncate-delete区别&quot;&gt;&lt;strong&gt;9.drop、truncate、 delete区别&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;54&quot;&gt;
&lt;p&gt;&lt;strong&gt;最基本：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;drop直接删掉表。&lt;/li&gt;
&lt;li&gt;truncate删除表中数据，再插入时自增长id又从1开始。&lt;/li&gt;
&lt;li&gt;delete删除表中数据，可以加where字句。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;（1） DELETE语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行进行回滚操作。TRUNCATE TABLE 则一次性地从表中删除所有的数据并不把单独的删除操作记录记入日志保存，删除行是不能恢复的。并且在删除的过程中不会激活与表有关的删除触发器。执行速度快。&lt;/p&gt;
&lt;p&gt;（2） 表和索引所占空间。当表被TRUNCATE 后，这个表和索引所占用的空间会恢复到初始大小，而DELETE操作不会减少表或索引所占用的空间。drop语句将表所占用的空间全释放掉。&lt;/p&gt;
&lt;p&gt;（3） 一般而言，drop &amp;gt; truncate &amp;gt; delete&lt;/p&gt;
&lt;p&gt;（4） 应用范围。TRUNCATE 只能对TABLE；DELETE可以是table和view&lt;/p&gt;
&lt;p&gt;（5） TRUNCATE 和DELETE只删除数据，而DROP则删除整个表（结构和数据）。&lt;/p&gt;
&lt;p&gt;（6） truncate与不带where的delete ：只删除数据，而不删除表的结构（定义）drop语句将删除表的结构被依赖的约束（constrain),触发器（trigger)索引（index);依赖于该表的存储过程/函数将被保留，但其状态会变为：invalid。&lt;/p&gt;
&lt;p&gt;（7） delete语句为DML（data maintain Language),这个操作会被放到 rollback segment中,事务提交后才生效。如果有相应的 tigger,执行的时候将被触发。&lt;/p&gt;
&lt;p&gt;（8） truncate、drop是DLL（data define language),操作立即生效，原数据不放到 rollback segment中，不能回滚。&lt;/p&gt;
&lt;p&gt;（9） 在没有备份情况下，谨慎使用 drop 与 truncate。要删除部分数据行采用delete且注意结合where来约束影响范围。回滚段要足够大。要删除表用drop;若想保留表而将表中数据删除，如果于事务无关，用truncate即可实现。如果和事务有关，或老师想触发trigger,还是用delete。&lt;/p&gt;
&lt;p&gt;（10） Truncate table 表名 速度快,而且效率高,因为:?truncate table 在功能上与不带 WHERE 子句的 DELETE 语句相同：二者均删除表中的全部行。但 TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少。DELETE 语句每次删除一行，并在事务日志中为所删除的每行记录一项。TRUNCATE TABLE 通过释放存储表数据所用的数据页来删除数据，并且只在事务日志中记录页的释放。&lt;/p&gt;
&lt;p&gt;（11） TRUNCATE TABLE 删除表中的所有行，但表结构及其列、约束、索引等保持不变。新行标识所用的计数值重置为该列的种子。如果想保留标识计数值，请改用 DELETE。如果要删除表定义及其数据，请使用 DROP TABLE 语句。&lt;/p&gt;
&lt;p&gt;（12） 对于由 FOREIGN KEY 约束引用的表，不能使用 TRUNCATE TABLE，而应使用不带 WHERE 子句的 DELETE 语句。由于 TRUNCATE TABLE 不记录在日志中，所以它不能激活触发器。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;什么是临时表临时表什么时候删除&quot;&gt;&lt;strong&gt;10.什么是临时表，临时表什么时候删除?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;15&quot;&gt;
&lt;p&gt;&lt;strong&gt;临时表可以手动删除：&lt;/strong&gt;&lt;br/&gt;DROP TEMPORARY TABLE IF EXISTS temp_tb;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;临时表只在当前连接可见，当关闭连接时，MySQL会自动删除表并释放所有空间。因此在不同的连接中可以创建同名的临时表，并且操作属于本连接的临时表。&lt;br/&gt;创建临时表的语法与创建表语法类似，不同之处是增加关键字TEMPORARY，&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如：&lt;/p&gt;
&lt;p&gt;CREATE TEMPORARY TABLE tmp_table (&lt;/p&gt;
&lt;p&gt;NAME VARCHAR (10) NOT NULL,&lt;/p&gt;
&lt;p&gt;time date NOT NULL&lt;br/&gt;);&lt;/p&gt;
&lt;p&gt;select * from tmp_table;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;非关系型数据库和关系型数据库区别优势比较&quot;&gt;&lt;strong&gt;11.非关系型数据库和关系型数据库区别，优势比较?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;非关系型数据库的优势：&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;性能：&lt;/strong&gt;NOSQL是基于键值对的，可以想象成表中的主键和值的对应关系，而且不需要经过SQL层的解析，所以性能非常高。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可扩展性：&lt;/strong&gt;同样也是因为基于键值对，数据之间没有耦合性，所以非常容易水平扩展。&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;关系型数据库的优势：&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;复杂查询：&lt;/strong&gt;可以用SQL语句方便的在一个表以及多个表之间做非常复杂的数据查询。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;事务支持：&lt;/strong&gt;使得对于安全性能很高的数据访问要求得以实现。&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;其他：&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt;对于这两类数据库，对方的优势就是自己的弱势，反之亦然。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt;NOSQL数据库慢慢开始具备SQL数据库的一些复杂查询功能，比如MongoDB。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.&lt;/strong&gt;对于事务的支持也可以用一些系统级的原子操作来实现例如乐观锁之类的方法来曲线救国，比如Redis set nx。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;数据库范式根据某个场景设计数据表&quot;&gt;&lt;strong&gt;12.数据库范式，根据某个场景设计数据表?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;第一范式:&lt;/strong&gt;(确保每列保持原子性)所有字段值都是不可分解的原子值。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;第一范式是最基本的范式。如果数据库表中的所有字段值都是不可分解的原子值，就说明该数据库表满足了第一范式。&lt;br/&gt;第一范式的合理遵循需要根据系统的实际需求来定。比如某些数据库系统中需要用到“地址”这个属性，本来直接将“地址”属性设计成一个数据库表的字段就行。但是如果系统经常会访问“地址”属性中的“城市”部分，那么就非要将“地址”这个属性重新拆分为省份、城市、详细地址等多个部分进行存储，这样在对地址中某一部分操作的时候将非常方便。这样设计才算满足了数据库的第一范式，如下表所示。&lt;br/&gt;上表所示的用户信息遵循了第一范式的要求，这样在对用户使用城市进行分类的时候就非常方便，也提高了数据库的性能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;strong&gt;第二范式:&lt;/strong&gt;(确保表中的每列都和主键相关)在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;第二范式在第一范式的基础之上更进一层。第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。&lt;br/&gt;比如要设计一个订单信息表，因为订单中可能会有多种商品，所以要将订单编号和商品编号作为数据库表的联合主键。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;第三范式:&lt;/strong&gt;(确保每列都和主键列直接相关,而不是间接相关) 数据表中的每一列数据都和主键直接相关，而不能间接相关。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;第三范式需要确保数据表中的每一列数据都和主键直接相关，而不能间接相关。&lt;br/&gt;比如在设计一个订单数据表的时候，可以将客户编号作为一个外键和订单表建立相应的关系。而不可以在订单表中添加关于客户其它信息（比如姓名、所属公司等）的字段。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;BCNF:&lt;/strong&gt;符合3NF，并且，主属性不依赖于主属性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;若关系模式属于第二范式，且每个属性都不传递依赖于键码，则R属于BC范式。&lt;br/&gt; 通常BC范式的条件有多种等价的表述：每个非平凡依赖的左边必须包含键码；每个决定因素必须包含键码。&lt;br/&gt; BC范式既检查非主属性，又检查主属性。当只检查非主属性时，就成了第三范式。满足BC范式的关系都必然满足第三范式。&lt;br/&gt;还可以这么说：若一个关系达到了第三范式，并且它只有一个候选码，或者它的每个候选码都是单属性，则该关系自然达到BC范式。&lt;br/&gt; 一般，一个数据库设计符合3NF或BCNF就可以了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第四范式:&lt;/strong&gt;要求把同一表内的多对多关系删除。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;第五范式:&lt;/strong&gt;从最终结构重新建立原始结构。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;什么是-内连接外连接交叉连接笛卡尔积等&quot;&gt;&lt;strong&gt;13.什么是 内连接、外连接、交叉连接、笛卡尔积等?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;&lt;strong&gt;内连接:&lt;/strong&gt; 只连接匹配的行&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;左外连接:&lt;/strong&gt; 包含左边表的全部行（不管右边的表中是否存在与它们匹配的行），以及右边表中全部匹配的行&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;右外连接:&lt;/strong&gt; 包含右边表的全部行（不管左边的表中是否存在与它们匹配的行），以及左边表中全部匹配的行&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;例如1：&lt;br/&gt;SELECT a.&lt;em&gt;,b.&lt;/em&gt; FROM luntan LEFT JOIN usertable as b ON a.username=b.username&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;例如2：&lt;br/&gt;SELECT a.&lt;em&gt;,b.&lt;/em&gt; FROM city as a FULL OUTER JOIN user as b ON a.username=b.username&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;&lt;strong&gt;全外连接:&lt;/strong&gt; 包含左、右两个表的全部行，不管另外一边的表中是否存在与它们匹配的行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;交叉连接:&lt;/strong&gt; 生成笛卡尔积－它不使用任何匹配或者选取条件，而是直接将一个数据源中的每个行与另一个数据源的每个行都一一匹配&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;例如：&lt;br/&gt;SELECT type,pub_name FROM titles CROSS JOIN publishers ORDER BY type&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;9.4949494949495&quot;&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;很多公司都只是考察是否知道其概念，但是也有很多公司需要不仅仅知道概念，还需要动手写sql,一般都是简单的连接查询，具体关于连接查询的sql练习，参见以下链接：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.nowcoder.com/ta/sql&quot;&gt;牛客网数据库SQL实战&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://leetcode-cn.com/problemset/database/&quot;&gt;leetcode中文网站数据库练习&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;varchar和char的使用场景&quot;&gt;&lt;strong&gt;14.varchar和char的使用场景?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;21&quot;&gt;
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt;char的长度是不可变的，而varchar的长度是可变的。&lt;/p&gt;
&lt;p&gt;定义一个char[10]和varchar[10]。&lt;br/&gt;如果存进去的是‘csdn’,那么char所占的长度依然为10，除了字符‘csdn’外，后面跟六个空格，varchar就立马把长度变为4了，取数据的时候，char类型的要用trim()去掉多余的空格，而varchar是不需要的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt;char的存取数度还是要比varchar要快得多，因为其长度固定，方便程序的存储与查找。&lt;br/&gt;char也为此付出的是空间的代价，因为其长度固定，所以难免会有多余的空格占位符占据空间，可谓是以空间换取时间效率。&lt;br/&gt;varchar是以空间效率为首位。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.&lt;/strong&gt;char的存储方式是：对英文字符（ASCII）占用1个字节，对一个汉字占用两个字节。&lt;br/&gt;varchar的存储方式是：对每个英文字符占用2个字节，汉字也占用2个字节。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.&lt;/strong&gt;两者的存储数据都非unicode的字符数据。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;sql语言分类&quot;&gt;&lt;strong&gt;15.SQL语言分类&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;SQL语言共分为四大类：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;数据查询语言DQL&lt;/li&gt;
&lt;li&gt;数据操纵语言DML&lt;/li&gt;
&lt;li&gt;数据定义语言DDL&lt;/li&gt;
&lt;li&gt;数据控制语言DCL。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote readability=&quot;39&quot;&gt;
&lt;p&gt;&lt;strong&gt;1. 数据查询语言DQL&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据查询语言DQL基本结构是由SELECT子句，FROM子句，WHERE子句组成的查询块：&lt;/p&gt;
&lt;p&gt;SELECT &amp;lt;字段名表&amp;gt;&lt;br/&gt;FROM &amp;lt;表或视图名&amp;gt;&lt;br/&gt;WHERE &amp;lt;查询条件&amp;gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2 .数据操纵语言DML&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据操纵语言DML主要有三种形式：&lt;/p&gt;
&lt;p&gt;1) 插入：INSERT&lt;/p&gt;
&lt;p&gt;2) 更新：UPDATE&lt;/p&gt;
&lt;p&gt;3) 删除：DELETE&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. 数据定义语言DDL&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据定义语言DDL用来创建数据库中的各种对象-----表、视图、索引、同义词、聚簇等如：&lt;br/&gt;CREATE TABLE/VIEW/INDEX/SYN/CLUSTER&lt;/p&gt;
&lt;p&gt;表 视图 索引 同义词 簇&lt;/p&gt;
&lt;p&gt;DDL操作是隐性提交的！不能rollback&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. 数据控制语言DCL&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据控制语言DCL用来授予或回收访问数据库的某种特权，并控制数据库操纵事务发生的时间及效果，对数据库实行监视等。如：&lt;/p&gt;
&lt;p&gt;1) GRANT：授权。&lt;/p&gt;
&lt;p&gt;2) ROLLBACK [WORK] TO [SAVEPOINT]：回退到某一点。回滚---ROLLBACK；回滚命令使数据库状态回到上次最后提交的状态。其格式为：&lt;br/&gt;SQL&amp;gt;ROLLBACK;&lt;/p&gt;
&lt;p&gt;3) COMMIT [WORK]：提交。&lt;/p&gt;
&lt;p&gt;在数据库的插入、删除和修改操作时，只有当事务在提交到数据&lt;br/&gt;库时才算完成。在事务提交前，只有操作数据库的这个人才能有权看&lt;br/&gt;到所做的事情，别人只有在最后提交完成后才可以看到。&lt;br/&gt;提交数据有三种类型：显式提交、隐式提交及自动提交。下面分&lt;br/&gt;别说明这三种类型。&lt;/p&gt;
&lt;p&gt;(1) 显式提交&lt;br/&gt;用COMMIT命令直接完成的提交为显式提交。其格式为：&lt;br/&gt;SQL&amp;gt;COMMIT；&lt;/p&gt;
&lt;p&gt;(2) 隐式提交&lt;br/&gt;用SQL命令间接完成的提交为隐式提交。这些命令是：&lt;br/&gt;ALTER，AUDIT，COMMENT，CONNECT，CREATE，DISCONNECT，DROP，&lt;br/&gt;EXIT，GRANT，NOAUDIT，QUIT，REVOKE，RENAME。&lt;/p&gt;
&lt;p&gt;(3) 自动提交&lt;br/&gt;若把AUTOCOMMIT设置为ON，则在插入、修改、删除语句执行后，&lt;br/&gt;系统将自动进行提交，这就是自动提交。其格式为：&lt;br/&gt;SQL&amp;gt;SET AUTOCOMMIT ON；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;1.2295081967213&quot;&gt;
&lt;p&gt;参考文章：&lt;br/&gt;&lt;a href=&quot;https://www.cnblogs.com/study-s/p/5287529.html&quot; class=&quot;uri&quot;&gt;https://www.cnblogs.com/study-s/p/5287529.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;like-和-的区别&quot;&gt;&lt;strong&gt;16.like %和-的区别&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;23&quot;&gt;
&lt;p&gt;&lt;strong&gt;通配符的分类:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;%百分号通配符:&lt;/strong&gt;表示任何字符出现任意次数(可以是0次).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;_下划线通配符:&lt;/strong&gt;表示只能匹配单个字符,不能多也不能少,就是一个字符.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;like操作符:&lt;/strong&gt; LIKE作用是指示mysql后面的搜索模式是利用通配符而不是直接相等匹配进行比较.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意:&lt;/strong&gt; 如果在使用like操作符时,后面的没有使用通用匹配符效果是和=一致的,SELECT * FROM products WHERE products.prod_name like '1000';&lt;br/&gt;只能匹配的结果为1000,而不能匹配像JetPack 1000这样的结果.&lt;/p&gt;
&lt;ul readability=&quot;3.5&quot;&gt;&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;%通配符使用: 匹配以&quot;yves&quot;开头的记录:(包括记录&quot;yves&quot;) SELECT * FROM products WHERE products.prod_name like 'yves%';&lt;br/&gt;匹配包含&quot;yves&quot;的记录(包括记录&quot;yves&quot;) SELECT * FROM products WHERE products.prod_name like '%yves%';&lt;br/&gt;匹配以&quot;yves&quot;结尾的记录(包括记录&quot;yves&quot;,不包括记录&quot;yves &quot;,也就是yves后面有空格的记录,这里需要注意) SELECT * FROM products WHERE products.prod_name like '%yves';&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;_通配符使用: SELECT * FROM products WHERE products.prod_name like '_yves'; 匹配结果为: 像&quot;yyves&quot;这样记录.&lt;br/&gt;SELECT * FROM products WHERE products.prod_name like 'yves__'; 匹配结果为: 像&quot;yvesHe&quot;这样的记录.(一个下划线只能匹配一个字符,不能多也不能少)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;注意事项:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;注意大小写,在使用模糊匹配时,也就是匹配文本时,mysql是可能区分大小的,也可能是不区分大小写的,这个结果是取决于用户对MySQL的配置方式.如果是区分大小写,那么像YvesHe这样记录是不能被&quot;yves__&quot;这样的匹配条件匹配的.&lt;/li&gt;
&lt;li&gt;注意尾部空格,&quot;%yves&quot;是不能匹配&quot;heyves &quot;这样的记录的.&lt;/li&gt;
&lt;li&gt;注意NULL,%通配符可以匹配任意字符,但是不能匹配NULL,也就是说SELECT * FROM products WHERE products.prod_name like '%;是匹配不到products.prod_name为NULL的的记录.&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;技巧与建议:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;正如所见， MySQL的通配符很有用。但这种功能是有代价的：通配符搜索的处理一般要比前面讨论的其他搜索所花时间更长。这里给出一些使用通配符要记住的技巧。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;不要过度使用通配符。如果其他操作符能达到相同的目的，应该 使用其他操作符。&lt;/li&gt;
&lt;li&gt;在确实需要使用通配符时，除非绝对有必要，否则不要把它们用 在搜索模式的开始处。把通配符置于搜索模式的开始处，搜索起 来是最慢的。&lt;/li&gt;
&lt;li&gt;仔细注意通配符的位置。如果放错地方，可能不会返回想要的数.&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;参考博文：&lt;a href=&quot;https://blog.csdn.net/u011479200/article/details/78513632&quot; class=&quot;uri&quot;&gt;https://blog.csdn.net/u011479200/article/details/78513632&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;countcount1countcolumn的区别&quot;&gt;&lt;strong&gt;17.count(*)、count(1)、count(column)的区别&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;count(*)对行的数目进行计算,包含NULL&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;count(column)对特定的列的值具有的行数进行计算,不包含NULL值。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;ul&gt;&lt;li&gt;count()还有一种使用方式,count(1)这个用法和count(*)的结果是一样的。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;性能问题:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.任何情况下SELECT COUNT(*) FROM tablename是最优选择;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;2.尽量减少SELECT COUNT(*) FROM tablename WHERE COL = ‘value’ 这种查询;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;3.杜绝SELECT COUNT(COL) FROM tablename WHERE COL2 = ‘value’ 的出现。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;如果表没有主键,那么count(1)比count(*)快。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;如果有主键,那么count(主键,联合主键)比count(*)快。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;如果表只有一个字段,count(*)最快。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;count(1)跟count(主键)一样,只扫描主键。count(*)跟count(非主键)一样,扫描整个表。明显前者更快一些。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;最左前缀原则&quot;&gt;&lt;strong&gt;18.最左前缀原则&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;26&quot;&gt;
&lt;p&gt;&lt;strong&gt;多列索引：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ALTER TABLE people ADD INDEX lname_fname_age (lame,fname,age);&lt;/p&gt;
&lt;p&gt;为了提高搜索效率，我们需要考虑运用多列索引,由于索引文件以B－Tree格式保存，所以我们不用扫描任何记录，即可得到最终结果。&lt;/p&gt;
&lt;p&gt;注：在mysql中执行查询时，只能使用一个索引，如果我们在lname,fname,age上分别建索引,执行查询时，只能使用一个索引，mysql会选择一个最严格(获得结果集记录数最少)的索引。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最左前缀原则：&lt;/strong&gt;顾名思义，就是最左优先，上例中我们创建了lname_fname_age多列索引,相当于创建了(lname)单列索引，(lname,fname)组合索引以及(lname,fname,age)组合索引。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;二索引&quot;&gt;二、索引&lt;/h2&gt;
&lt;h4 id=&quot;什么是索引&quot;&gt;&lt;strong&gt;1.什么是索引？&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;&lt;strong&gt;何为索引：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据库索引，是数据库管理系统中一个排序的数据结构，索引的实现通常使用B树及其变种B+树。&lt;/p&gt;
&lt;p&gt;在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;索引的作用它的优点缺点是什么&quot;&gt;&lt;strong&gt;2.索引的作用？它的优点缺点是什么？&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;索引作用：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;协助快速查询、更新数据库表中数据。&lt;/p&gt;
&lt;p&gt;为表设置索引要付出代价的：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一是增加了数据库的存储空间&lt;/li&gt;
&lt;li&gt;二是在插入和修改数据时要花费较多的时间(因为索引也要随之变动)。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&quot;索引的优缺点&quot;&gt;&lt;strong&gt;3.索引的优缺点？&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;28&quot;&gt;
&lt;p&gt;&lt;strong&gt;创建索引可以大大提高系统的性能（优点）：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。&lt;/p&gt;
&lt;p&gt;2.可以大大加快数据的检索速度，这也是创建索引的最主要的原因。&lt;/p&gt;
&lt;p&gt;3.可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。&lt;/p&gt;
&lt;p&gt;4.在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。&lt;/p&gt;
&lt;p&gt;5.通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;增加索引也有许多不利的方面(缺点)：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。&lt;/p&gt;
&lt;p&gt;2.索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。&lt;/p&gt;
&lt;p&gt;3.当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;哪些列适合建立索引哪些不适合建索引&quot;&gt;&lt;strong&gt;4.哪些列适合建立索引、哪些不适合建索引？&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;48&quot;&gt;
&lt;p&gt;索引是建立在数据库表中的某些列的上面。在创建索引的时候，应该考虑在哪些列上可以创建索引，在哪些列上不能创建索引。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一般来说，应该在这些列上创建索引：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;（1）在经常需要搜索的列上，可以加快搜索的速度；&lt;/p&gt;
&lt;p&gt;（2）在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构；&lt;/p&gt;
&lt;p&gt;（3）在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度；&lt;/p&gt;
&lt;p&gt;（4）在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的；&lt;/p&gt;
&lt;p&gt;（5）在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间；&lt;/p&gt;
&lt;p&gt;（6）在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对于有些列不应该创建索引：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;（1）对于那些在查询中很少使用或者参考的列不应该创建索引。&lt;/p&gt;
&lt;p&gt;这是因为，既然这些列很少使用到，因此有索引或者无索引，并不能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。&lt;/p&gt;
&lt;p&gt;（2）对于那些只有很少数据值的列也不应该增加索引。&lt;/p&gt;
&lt;p&gt;这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。&lt;/p&gt;
&lt;p&gt;（3）对于那些定义为text, image和bit数据类型的列不应该增加索引。&lt;/p&gt;
&lt;p&gt;这是因为，这些列的数据量要么相当大，要么取值很少。&lt;/p&gt;
&lt;p&gt;(4)当修改性能远远大于检索性能时，不应该创建索引。&lt;/p&gt;
&lt;p&gt;这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;什么样的字段适合建索引&quot;&gt;&lt;strong&gt;5.什么样的字段适合建索引&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;唯一、不为空、经常被查询的字段&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;mysql-btree索引和hash索引的区别&quot;&gt;&lt;strong&gt;6.MySQL B+Tree索引和Hash索引的区别?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;Hash索引和B+树索引的特点：&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;Hash索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;B+树索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;为什么不都用Hash索引而使用B+树索引？&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ol&gt;&lt;li&gt;Hash索引仅仅能满足&quot;=&quot;,&quot;IN&quot;和&quot;&amp;lt;=&amp;gt;&quot;查询，不能使用范围查询,因为经过相应的Hash算法处理之后的Hash值的大小关系，并不能保证和Hash运算前完全一样；&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ol&gt;&lt;li&gt;Hash索引无法被用来避免数据的排序操作，因为Hash值的大小关系并不一定和Hash运算前的键值完全一样；&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ol&gt;&lt;li&gt;Hash索引不能利用部分索引键查询，对于组合索引，Hash索引在计算Hash值的时候是组合索引键合并后再一起计算Hash值，而不是单独计算Hash值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash索引也无法被利用；&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ol&gt;&lt;li&gt;Hash索引在任何时候都不能避免表扫描，由于不同索引键存在相同Hash值，所以即使取满足某个Hash键值的数据的记录条数，也无法从Hash索引中直接完成查询，还是要回表查询数据；&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ol&gt;&lt;li&gt;Hash索引遇到大量Hash值相等的情况后性能并不一定就会比B+树索引高。&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;补充：&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;1.MySQL中，只有HEAP/MEMORY引擎才显示支持Hash索引。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;2.常用的InnoDB引擎中默认使用的是B+树索引，它会实时监控表上索引的使用情况，如果认为建立哈希索引可以提高查询效率，则自动在内存中的“自适应哈希索引缓冲区”建立哈希索引（在InnoDB中默认开启自适应哈希索引），通过观察搜索模式，MySQL会利用index key的前缀建立哈希索引，如果一个表几乎大部分都在缓冲池中，那么建立一个哈希索引能够加快等值查询。&lt;br/&gt;B+树索引和哈希索引的明显区别是：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;3.如果是等值查询，那么哈希索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值；当然了，这个前提是，键值都是唯一的。如果键值不是唯一的，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;4.如果是范围查询检索，这时候哈希索引就毫无用武之地了，因为原先是有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索；&lt;br/&gt;同理，哈希索引没办法利用索引完成排序，以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询）；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;5.哈希索引也不支持多列联合索引的最左匹配规则；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;6.B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;7.在大多数场景下，都会有范围查询、排序、分组等查询特征，用B+树索引就可以了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;b树和b树的区别&quot;&gt;&lt;strong&gt;7.B树和B+树的区别&lt;/strong&gt;&lt;/h4&gt;
&lt;ol&gt;&lt;li&gt;B树，每个节点都存储key和data，所有节点组成这棵树，并且叶子节点指针为nul，叶子结点不包含任何关键字信息。&lt;br/&gt;&lt;img src=&quot;https://i.imgur.com/RbzI0R8.jpg&quot;/&gt;&lt;/li&gt;
&lt;li&gt;B+树，所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接，所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。 (而B 树的非终节点也包含需要查找的有效信息)&lt;br/&gt;&lt;img src=&quot;https://i.imgur.com/9VbnDME.jpg&quot;/&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h4 id=&quot;为什么说b比b树更适合实际应用中操作系统的文件索引和数据库索引&quot;&gt;&lt;strong&gt;8.为什么说B+比B树更适合实际应用中操作系统的文件索引和数据库索引？&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;16&quot;&gt;
&lt;p&gt;&lt;strong&gt;1.B+的磁盘读写代价更低&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;B+的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.B+tree的查询效率更加稳定&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;聚集索引和非聚集索引区别&quot;&gt;&lt;strong&gt;9.聚集索引和非聚集索引区别?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;11&quot;&gt;
&lt;p&gt;&lt;strong&gt;聚合索引(clustered index):&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;聚集索引&lt;strong&gt;表记录的排列顺序和索引的排列顺序一致，所以查询效率快，&lt;/strong&gt;只要找到第一个索引值记录，其余就连续性的记录在物理也一样连续存放。聚集索引对应的缺点就是修改慢，因为为了保证表中记录的物理和索引顺序一致，在记录插入的时候，会对数据页重新排序。&lt;br/&gt;聚集索引类似于新华字典中用拼音去查找汉字，拼音检索表于书记顺序都是按照a~z排列的，就像相同的逻辑顺序于物理顺序一样，当你需要查找a,ai两个读音的字，或是想一次寻找多个傻(sha)的同音字时，也许向后翻几页，或紧接着下一行就得到结果了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;&lt;strong&gt;非聚合索引(nonclustered index):&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;非聚集索引&lt;strong&gt;指定了表中记录的逻辑顺序，但是记录的物理和索引不一定一致，&lt;/strong&gt;两种索引都采用B+树结构，非聚集索引的叶子层并不和实际数据页相重叠，而采用叶子层包含一个指向表中的记录在数据页中的指针方式。非聚集索引层次多，不会造成数据重排。&lt;br/&gt;非聚集索引类似在新华字典上通过偏旁部首来查询汉字，检索表也许是按照横、竖、撇来排列的，但是由于正文中是a~z的拼音顺序，所以就类似于逻辑地址于物理地址的不对应。同时适用的情况就在于分组，大数目的不同值，频繁更新的列中，这些情况即不适合聚集索引。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;根本区别：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;聚集索引和非聚集索引的根本区别是表记录的排列顺序和与索引的排列顺序是否一致。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;三事务&quot;&gt;三、事务&lt;/h2&gt;
&lt;h4 id=&quot;什么是事务&quot;&gt;&lt;strong&gt;1.什么是事务？&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;事务是对数据库中一系列操作进行统一的回滚或者提交的操作，主要用来保证数据的完整性和一致性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;事务四大特性acid原子性一致性隔离性持久性&quot;&gt;&lt;strong&gt;2.事务四大特性（ACID）原子性、一致性、隔离性、持久性?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;原子性（Atomicity）:&lt;/strong&gt;&lt;br/&gt;原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;strong&gt;一致性（Consistency）:&lt;/strong&gt;&lt;br/&gt;事务开始前和结束后，数据库的完整性约束没有被破坏。比如A向B转账，不可能A扣了钱，B却没收到。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;strong&gt;隔离性（Isolation）:&lt;/strong&gt;&lt;br/&gt;隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。同一时间，只允许一个事务请求同一数据，不同的事务之间彼此没有任何干扰。比如A正在从一张银行卡中取钱，在A取钱的过程结束前，B不能向这张卡转账。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;持久性（Durability）:&lt;/strong&gt;&lt;br/&gt;持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;事务的并发事务隔离级别每个级别会引发什么问题mysql默认是哪个级别&quot;&gt;&lt;strong&gt;3.事务的并发?事务隔离级别，每个级别会引发什么问题，MySQL默认是哪个级别?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;17&quot;&gt;
&lt;p&gt;从理论上来说, 事务应该彼此完全隔离, 以避免并发事务所导致的问题，然而, 那样会对性能产生极大的影响, 因为事务必须按顺序运行， 在实际开发中, 为了提升性能, 事务会以较低的隔离级别运行， 事务的隔离级别可以通过隔离事务属性指定。&lt;br/&gt;&lt;strong&gt;事务的并发问题&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、脏读：&lt;/strong&gt;事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;2、不可重复读：&lt;/strong&gt;事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果因此本事务先后两次读到的数据结果会不一致。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;strong&gt;3、幻读：&lt;/strong&gt;幻读解决了不重复读，保证了同一个事务里，查询的结果都是事务开始时的状态（一致性）。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;例如：事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作 这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。 而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有跟没有修改一样，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。&lt;br/&gt;&lt;strong&gt;小结：不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表。 　　&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;事务的隔离级别&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.imgur.com/xAeWTSp.png&quot;/&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;strong&gt;读未提交：&lt;/strong&gt;另一个事务修改了数据，但尚未提交，而本事务中的SELECT会读到这些未被提交的数据脏读&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;不可重复读：&lt;/strong&gt;事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果因此本事务先后两次读到的数据结果会不一致。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;strong&gt;可重复读：&lt;/strong&gt;在同一个事务里，SELECT的结果是事务开始时时间点的状态，因此，同样的SELECT操作读到的结果会是一致的。但是，会有幻读现象&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;strong&gt;串行化：&lt;/strong&gt;最高的隔离级别，在这个隔离级别下，不会产生任何异常。并发的事务，就像事务是在一个个按照顺序执行一样&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;特别注意：&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;MySQL默认的事务隔离级别为repeatable-read&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;MySQL 支持 4 中事务隔离级别.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;事务的隔离级别要得到底层数据库引擎的支持, 而不是应用程序或者框架的支持.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;Oracle 支持的 2 种事务隔离级别：READ_COMMITED , SERIALIZABLE&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;SQL规范所规定的标准，不同的数据库具体的实现可能会有些差异&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;strong&gt;MySQL中默认事务隔离级别是“可重复读”时并不会锁住读取到的行&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;事务隔离级别：&lt;/strong&gt;未提交读时，写数据只会锁住相应的行。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;事务隔离级别为：&lt;/strong&gt;可重复读时，写数据会锁住整张表。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;事务隔离级别为：&lt;/strong&gt;串行化时，读写数据都会锁住整张表。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大，鱼和熊掌不可兼得啊。对于多数应用程序，可以优先考虑把数据库系统的隔离级别设为Read Committed，它能够避免脏读取，而且具有较好的并发性能。尽管它会导致不可重复读、幻读这些并发问题，在可能出现这类问题的个别场合，可以由应用程序采用悲观锁或乐观锁来控制。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;事务传播行为&quot;&gt;&lt;strong&gt;4.事务传播行为&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;23&quot;&gt;
&lt;p&gt;&lt;strong&gt;1.PROPAGATION_REQUIRED：&lt;/strong&gt;如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.PROPAGATION_SUPPORTS：&lt;/strong&gt;支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.PROPAGATION_MANDATORY：&lt;/strong&gt;支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.PROPAGATION_REQUIRES_NEW：&lt;/strong&gt;创建新事务，无论当前存不存在事务，都创建新事务。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.PROPAGATION_NOT_SUPPORTED：&lt;/strong&gt;以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6.PROPAGATION_NEVER：&lt;/strong&gt;以非事务方式执行，如果当前存在事务，则抛出异常。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7.PROPAGATION_NESTED：&lt;/strong&gt;如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED类似的操作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;嵌套事务&quot;&gt;&lt;strong&gt;5.嵌套事务&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;strong&gt;什么是嵌套事务？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;嵌套是子事务套在父事务中执行，子事务是父事务的一部分，在进入子事务之前，父事务建立一个回滚点，叫save point，然后执行子事务，这个子事务的执行也算是父事务的一部分，然后子事务执行结束，父事务继续执行。重点就在于那个save point。看几个问题就明了了：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;如果子事务回滚，会发生什么？&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;父事务会回滚到进入子事务前建立的save point，然后尝试其他的事务或者其他的业务逻辑，父事务之前的操作不会受到影响，更不会自动回滚。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;如果父事务回滚，会发生什么？&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;父事务回滚，子事务也会跟着回滚！为什么呢，因为父事务结束之前，子事务是不会提交的，我们说子事务是父事务的一部分，正是这个道理。那么：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;事务的提交，是什么情况？&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;是父事务先提交，然后子事务提交，还是子事务先提交，父事务再提交？答案是第二种情况，还是那句话，子事务是父事务的一部分，由父事务统一提交。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;参考文章：&lt;a href=&quot;https://blog.csdn.net/liangxw1/article/details/51197560&quot; class=&quot;uri&quot;&gt;https://blog.csdn.net/liangxw1/article/details/51197560&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;四存储引擎&quot;&gt;四、存储引擎&lt;/h2&gt;
&lt;h4 id=&quot;mysql常见的三种存储引擎innodbmyisammemory的区别&quot;&gt;&lt;strong&gt;1.MySQL常见的三种存储引擎（InnoDB、MyISAM、MEMORY）的区别?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;两种存储引擎的大致区别表现在：&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;1.&lt;strong&gt;InnoDB支持事务，MyISAM不支持，&lt;/strong&gt; &lt;strong&gt;这一点是非常之重要。&lt;/strong&gt;事务是一种高级的处理方式，如在一些列增删改中只要哪个出错还可以回滚还原，而MyISAM就不可以了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;2.MyISAM适合查询以及插入为主的应用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;3.InnoDB适合频繁修改以及涉及到安全性较高的应用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;4.InnoDB支持外键，MyISAM不支持。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;5.从MySQL5.5.5以后，InnoDB是默认引擎。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;6.InnoDB不支持FULLTEXT类型的索引。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;7.InnoDB中不保存表的行数，如select count(&lt;em&gt;) from table时，InnoDB需要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当count(&lt;/em&gt;)语句包含where条件时MyISAM也需要扫描整个表。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;8.对于自增长的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中可以和其他字段一起建立联合索引。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;9.DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的 删除，效率非常慢。MyISAM则会重建表。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;10.InnoDB支持行锁（某些情况下还是锁整表，如 update table set a=1 where user like '%lee%'。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;mysql存储引擎myisam与innodb如何选择&quot;&gt;&lt;strong&gt;2.MySQL存储引擎MyISAM与InnoDB如何选择&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;MySQL有多种存储引擎，每种存储引擎有各自的优缺点，可以择优选择使用：MyISAM、InnoDB、MERGE、MEMORY(HEAP)、BDB(BerkeleyDB)、EXAMPLE、FEDERATED、ARCHIVE、CSV、BLACKHOLE。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;虽然MySQL里的存储引擎不只是MyISAM与InnoDB这两个，但常用的就是两个。&lt;br/&gt;关于MySQL数据库提供的两种存储引擎，MyISAM与InnoDB选择使用：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;1.INNODB会支持一些关系数据库的高级功能，如事务功能和行级锁，MyISAM不支持。&lt;/li&gt;
&lt;li&gt;2.MyISAM的性能更优，占用的存储空间少，所以，选择何种存储引擎，视具体应用而定。&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;32&quot;&gt;
&lt;p&gt;如果你的应用程序一定要使用事务，毫无疑问你要选择INNODB引擎。但要注意，INNODB的行级锁是有条件的。在where条件没有使用主键时，照样会锁全表。比如DELETE FROM mytable这样的删除语句。&lt;/p&gt;
&lt;p&gt;如果你的应用程序对查询性能要求较高，就要使用MyISAM了。MyISAM索引和数据是分开的，而且其索引是压缩的，可以更好地利用内存。所以它的查询性能明显优于INNODB。压缩后的索引也能节约一些磁盘空间。MyISAM拥有全文索引的功能，这可以极大地优化LIKE查询的效率。&lt;/p&gt;
&lt;p&gt;有人说MyISAM只能用于小型应用，其实这只是一种偏见。如果数据量比较大，这是需要通过升级架构来解决，比如分表分库，而不是单纯地依赖存储引擎。&lt;/p&gt;
&lt;p&gt;现在一般都是选用innodb了，主要是MyISAM的全表锁，读写串行问题，并发效率锁表，效率低，MyISAM对于读写密集型应用一般是不会去选用的。&lt;br/&gt;MEMORY存储引擎&lt;/p&gt;
&lt;p&gt;MEMORY是MySQL中一类特殊的存储引擎。它使用存储在内存中的内容来创建表，而且数据全部放在内存中。这些特性与前面的两个很不同。&lt;br/&gt;每个基于MEMORY存储引擎的表实际对应一个磁盘文件。该文件的文件名与表名相同，类型为frm类型。该文件中只存储表的结构。而其数据文件，都是存储在内存中，这样有利于数据的快速处理，提高整个表的效率。值得注意的是，服务器需要有足够的内存来维持MEMORY存储引擎的表的使用。如果不需要了，可以释放内存，甚至删除不需要的表。&lt;/p&gt;
&lt;p&gt;MEMORY默认使用哈希索引。速度比使用B型树索引快。当然如果你想用B型树索引，可以在创建索引时指定。&lt;/p&gt;
&lt;p&gt;注意，MEMORY用到的很少，因为它是把数据存到内存中，如果内存出现异常就会影响数据。如果重启或者关机，所有数据都会消失。因此，基于MEMORY的表的生命周期很短，一般是一次性的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;mysql的myisam与innodb两种存储引擎在事务锁级别各自的适用场景&quot;&gt;&lt;strong&gt;3.MySQL的MyISAM与InnoDB两种存储引擎在，事务、锁级别，各自的适用场景?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;事务处理上方面&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul readability=&quot;5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;MyISAM：强调的是性能，每次查询具有原子性,其执行数度比InnoDB类型更快，但是不提供事务支持。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;InnoDB：提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;锁级别&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;MyISAM：只支持表级锁，用户在操作MyISAM表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;InnoDB：支持事务和行级锁，是innodb的最大特色。行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;关于存储引擎MyISAM和InnoDB的其他参考资料如下：&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;0.069306930693069&quot;&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/lc0817/article/details/52757194&quot;&gt;MySQL存储引擎中的MyISAM和InnoDB区别详解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/kevingrace/p/5685355.html&quot;&gt;MySQL存储引擎之MyISAM和Innodb总结性梳理&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;五优化&quot;&gt;五、优化&lt;/h2&gt;
&lt;h4 id=&quot;查询语句不同元素wherejionlimitgroup-byhaving等等执行先后顺序&quot;&gt;&lt;strong&gt;1.查询语句不同元素（where、jion、limit、group by、having等等）执行先后顺序?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;where:&lt;/strong&gt;过滤表中数据的条件&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;group by:&lt;/strong&gt;如何将上面过滤出的数据分组&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;having:&lt;/strong&gt;对上面已经分组的数据进行过滤的条件&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;select:&lt;/strong&gt;查看结果集中的哪个列，或列的计算结果&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;order by :&lt;/strong&gt;按照什么样的顺序来查看返回的数据&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;1.5671641791045&quot;&gt;
&lt;p&gt;其他参考资源：&lt;br/&gt;&lt;a href=&quot;http://www.cnblogs.com/huminxxl/p/3149097.html&quot; class=&quot;uri&quot;&gt;http://www.cnblogs.com/huminxxl/p/3149097.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;使用explain优化sql和索引&quot;&gt;&lt;strong&gt;2.使用explain优化sql和索引?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;46&quot;&gt;
&lt;p&gt;&lt;strong&gt;对于复杂、效率低的sql语句，我们通常是使用explain sql 来分析sql语句，这个语句可以打印出，语句的执行。这样方便我们分析，进行优化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;table：&lt;/strong&gt;显示这一行的数据是关于哪张表的&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;type：&lt;/strong&gt;这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为const、eq_reg、ref、range、index和ALL&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;all:&lt;/strong&gt;full table scan ;MySQL将遍历全表以找到匹配的行；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;index:&lt;/strong&gt; index scan; index 和 all的区别在于index类型只遍历索引；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;range：&lt;/strong&gt;索引范围扫描，对索引的扫描开始于某一点，返回匹配值的行，常见与between ，&amp;lt; ,&amp;gt;等查询；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ref：&lt;/strong&gt;非唯一性索引扫描，返回匹配某个单独值的所有行，常见于使用非唯一索引即唯一索引的非唯一前缀进行查找；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;eq_ref：&lt;/strong&gt;唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配，常用于主键或者唯一索引扫描；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;const，system：&lt;/strong&gt;当MySQL对某查询某部分进行优化，并转为一个常量时，使用这些访问类型。如果将主键置于where列表中，MySQL就能将该查询转化为一个常量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;possible_keys：&lt;/strong&gt;显示可能应用在这张表中的索引。如果为空，没有可能的索引。可以为相关的域从WHERE语句中选择一个合适的语句&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;key：&lt;/strong&gt; 实际使用的索引。如果为NULL，则没有使用索引。很少的情况下，MySQL会选择优化不足的索引。这种情况下，可以在SELECT语句中使用USE INDEX（indexname）来强制使用一个索引或者用IGNORE INDEX（indexname）来强制MySQL忽略索引&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;key_len：&lt;/strong&gt;使用的索引的长度。在不损失精确性的情况下，长度越短越好&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ref：&lt;/strong&gt;显示索引的哪一列被使用了，如果可能的话，是一个常数&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;rows：&lt;/strong&gt;MySQL认为必须检查的用来返回请求数据的行数&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Extra：&lt;/strong&gt;关于MySQL如何解析查询的额外信息。将在表4.3中讨论，但这里可以看到的坏的例子是Using temporary和Using filesort，意思MySQL根本不能使用索引，结果是检索会很慢。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;mysql慢查询怎么解决&quot;&gt;&lt;strong&gt;3.MySQL慢查询怎么解决?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;slow_query_log 慢查询开启状态。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;slow_query_log_file 慢查询日志存放的位置（这个目录需要MySQL的运行帐号的可写权限，一般设置为MySQL的数据存放目录）。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;long_query_time 查询超过多少秒才记录。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&quot;六数据库锁&quot;&gt;六、数据库锁&lt;/h2&gt;
&lt;h4 id=&quot;mysql都有什么锁死锁判定原理和具体场景死锁怎么解决&quot;&gt;&lt;strong&gt;1.mysql都有什么锁，死锁判定原理和具体场景，死锁怎么解决?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;MySQL有三种锁的级别：&lt;/strong&gt;页级、表级、行级。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;表级锁：&lt;/strong&gt;开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;行级锁：&lt;/strong&gt;开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;页面锁：&lt;/strong&gt;开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般&lt;br/&gt;&lt;strong&gt;什么情况下会造成死锁?&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote readability=&quot;28&quot;&gt;
&lt;p&gt;&lt;strong&gt;什么是死锁？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;死锁&lt;/strong&gt; 是指两个或两个以上的进程在执行过程中。因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁,这些永远在互相等竺的进程称为死锁进程。&lt;/p&gt;
&lt;p&gt;表级锁不会产生死锁.所以解决死锁主要还是针对于最常用的InnoDB。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;死锁的关键在于：&lt;/strong&gt;两个(或以上)的Session加锁的顺序不一致。&lt;/p&gt;
&lt;p&gt;那么对应的解决死锁问题的关键就是：让不同的session加锁有次序。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;死锁的解决办法?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.查出的线程杀死 kill&lt;br/&gt;SELECT trx_MySQL_thread_id FROM information_schema.INNODB_TRX;&lt;/p&gt;
&lt;p&gt;2.设置锁的超时时间&lt;br/&gt;Innodb 行锁的等待时间，单位秒。可在会话级别设置，RDS 实例该参数的默认值为 50（秒）。&lt;/p&gt;
&lt;p&gt;生产环境不推荐使用过大的 innodb_lock_wait_timeout参数值&lt;br/&gt;该参数支持在会话级别修改，方便应用在会话级别单独设置某些特殊操作的行锁等待超时时间，如下：&lt;br/&gt;set innodb_lock_wait_timeout=1000; —设置当前会话 Innodb 行锁等待超时时间，单位秒。&lt;/p&gt;
&lt;p&gt;3.指定获取锁的顺序&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;有哪些锁乐观锁悲观锁select-时怎么加排它锁&quot;&gt;&lt;strong&gt;2.有哪些锁（乐观锁悲观锁），select 时怎么加排它锁?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;悲观锁（Pessimistic Lock）:&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;&lt;strong&gt;悲观锁特点:&lt;/strong&gt;先获取锁，再进行业务操作。&lt;/p&gt;
&lt;p&gt;即“悲观”的认为获取锁是非常有可能失败的，因此要先确保获取锁成功再进行业务操作。通常所说的&lt;strong&gt;“一锁二查三更新”即指的是使用悲观锁。&lt;/strong&gt;通常来讲在数据库上的悲观锁需要数据库本身提供支持，即通过常用的select … for update操作来实现悲观锁。当数据库执行select for update时会获取被select中的数据行的行锁，因此其他并发执行的select for update如果试图选中同一行则会发生排斥（需要等待行锁被释放），因此达到锁的效果。select for update获取的行锁会在当前事务结束时自动释放，因此必须在事务中使用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;补充：&lt;/strong&gt;&lt;br/&gt;不同的数据库对select for update的实现和支持都是有所区别的，&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;oracle支持select for update no wait，表示如果拿不到锁立刻报错，而不是等待，MySQL就没有no wait这个选项。&lt;/li&gt;
&lt;li&gt;MySQL还有个问题是select for update语句执行中所有扫描过的行都会被锁上，这一点很容易造成问题。因此如果在MySQL中用悲观锁务必要确定走了索引，而不是全表扫描。&lt;/li&gt;
&lt;/ul&gt;&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;乐观锁（Optimistic Lock）:&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;17&quot;&gt;
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt;乐观锁，也叫乐观并发控制，它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，那么当前正在提交的事务会进行回滚。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.乐观锁的特点先进行业务操作，不到万不得已不去拿锁。&lt;/strong&gt;即“乐观”的认为拿锁多半是会成功的，因此在进行完业务操作需要实际更新数据的最后一步再去拿一下锁就好。&lt;br/&gt;乐观锁在数据库上的实现完全是逻辑的，不需要数据库提供特殊的支持。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.&lt;/strong&gt;一般的做法是&lt;strong&gt;在需要锁的数据上增加一个版本号，或者时间戳&lt;/strong&gt;，&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;实现方式举例如下：&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;strong&gt;乐观锁（给表加一个版本号字段）&lt;/strong&gt; 这个并不是乐观锁的定义，给表加版本号，是&lt;strong&gt;数据库实现乐观锁的一种方式&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ol&gt;&lt;li&gt;SELECT data AS old_data, version AS old_version FROM …;&lt;/li&gt;
&lt;li&gt;根据获取的数据进行业务操作，得到new_data和new_version&lt;/li&gt;
&lt;li&gt;UPDATE SET data = new_data, version = new_version WHERE version = old_version&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;if (updated row &amp;gt; 0) {&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;// 乐观锁获取成功，操作完成&lt;/p&gt;
&lt;p&gt;} else {&lt;/p&gt;
&lt;p&gt;// 乐观锁获取失败，回滚并重试&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;ul&gt;&lt;li&gt;乐观锁在不发生取锁失败的情况下开销比悲观锁小，但是一旦发生失败回滚开销则比较大，因此适合用在取锁失败概率比较小的场景，可以提升系统并发性能&lt;/li&gt;
&lt;li&gt;乐观锁还适用于一些比较特殊的场景，例如在业务操作过程中无法和数据库保持连接等悲观锁无法适用的地方。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;总结：&lt;/strong&gt;&lt;br/&gt;悲观锁和乐观锁是数据库用来保证数据并发安全防止更新丢失的两种方法，例子在select ... for update前加个事务就可以防止更新丢失。悲观锁和乐观锁大部分场景下差异不大，一些独特场景下有一些差别，一般我们可以从如下几个方面来判断。&lt;/p&gt;
&lt;ul readability=&quot;1&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;响应速度：&lt;/strong&gt; 如果需要非常高的响应速度，建议采用乐观锁方案，成功就执行，不成功就失败，不需要等待其他并发去释放锁。'&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;冲突频率：&lt;/strong&gt; 如果冲突频率非常高，建议采用悲观锁，保证成功率，如果冲突频率大，乐观锁会需要多次重试才能成功，代价比较大。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;strong&gt;重试代价：&lt;/strong&gt; 如果重试代价大，建议采用悲观锁。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h2 id=&quot;七其他&quot;&gt;七、其他&lt;/h2&gt;
&lt;h4 id=&quot;数据库的主从复制&quot;&gt;&lt;strong&gt;1.数据库的主从复制&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;主从复制的几种方式:&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;同步复制:&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;所谓的同步复制，意思是master的变化，必须等待slave-1,slave-2,...,slave-n完成后才能返回。 这样，显然不可取，也不是MySQL复制的默认设置。比如，在WEB前端页面上，用户增加了条记录，需要等待很长时间。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;异步复制:&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;如同AJAX请求一样。master只需要完成自己的数据库操作即可。至于slaves是否收到二进制日志，是否完成操作，不用关心,MySQL的默认设置。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;半同步复制:&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;master只保证slaves中的一个操作成功，就返回，其他slave不管。 这个功能，是由google为MySQL引入的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;数据库主从复制分析的-7-个问题&quot;&gt;&lt;strong&gt;2.数据库主从复制分析的 7 个问题?&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;问题1：&lt;/strong&gt;master的写操作，slaves被动的进行一样的操作，保持数据一致性，那么slave是否可以主动的进行写操作？&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;假设slave可以主动的进行写操作，slave又无法通知master，这样就导致了master和slave数据不一致了。因此slave不应该进行写操作，至少是slave上涉及到复制的数据库不可以写。实际上，这里已经揭示了读写分离的概念。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;问题2：&lt;/strong&gt;主从复制中，可以有N个slave,可是这些slave又不能进行写操作，要他们干嘛？&lt;/p&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;&lt;strong&gt;实现数据备份:&lt;/strong&gt;&lt;br/&gt;类似于高可用的功能，一旦master挂了，可以让slave顶上去，同时slave提升为master。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;异地容灾:&lt;/strong&gt;比如master在北京，地震挂了，那么在上海的slave还可以继续。&lt;br/&gt;主要用于实现scale out,分担负载,可以将读的任务分散到slaves上。&lt;br/&gt;【很可能的情况是，一个系统的读操作远远多于写操作，因此写操作发向master，读操作发向slaves进行操作】&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;问题3：&lt;/strong&gt;主从复制中有master,slave1,slave2,...等等这么多MySQL数据库，那比如一个JAVA WEB应用到底应该连接哪个数据库?&lt;/p&gt;
&lt;blockquote readability=&quot;16&quot;&gt;
&lt;p&gt;我们在应用程序中可以这样，insert/delete/update这些更新数据库的操作，用connection(for master)进行操作，&lt;/p&gt;
&lt;p&gt;select用connection(for slaves)进行操作。那我们的应用程序还要完成怎么从slaves选择一个来执行select，例如使用简单的轮循算法。&lt;/p&gt;
&lt;p&gt;这样的话，相当于应用程序完成了SQL语句的路由，而且与MySQL的主从复制架构非常关联，一旦master挂了，某些slave挂了，那么应用程序就要修改了。能不能让应用程序与MySQL的主从复制架构没有什么太多关系呢？&lt;br/&gt;找一个组件，application program只需要与它打交道，用它来完成MySQL的代理，实现SQL语句的路由。&lt;br/&gt;MySQL proxy并不负责，怎么从众多的slaves挑一个？可以交给另一个组件(比如haproxy)来完成。&lt;/p&gt;
&lt;p&gt;这就是所谓的MySQL READ WRITE SPLITE，MySQL的读写分离。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;问题4：&lt;/strong&gt;如果MySQL proxy , direct , master他们中的某些挂了怎么办？&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;总统一般都会弄个副总统，以防不测。同样的，可以给这些关键的节点来个备份。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;问题5：&lt;/strong&gt;当master的二进制日志每产生一个事件，都需要发往slave，如果我们有N个slave,那是发N次，还是只发一次？如果只发一次，发给了slave-1，那slave-2,slave-3,...它们怎么办？&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;显 然，应该发N次。实际上，在MySQL master内部，维护N个线程，每一个线程负责将二进制日志文件发往对应的slave。master既要负责写操作，还的维护N个线程，负担会很重。可以这样，slave-1是master的从，slave-1又是slave-2,slave-3,...的主，同时slave-1不再负责select。 slave-1将master的复制线程的负担，转移到自己的身上。这就是所谓的多级复制的概念。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;问题6：&lt;/strong&gt;当一个select发往MySQL proxy，可能这次由slave-2响应，下次由slave-3响应，这样的话，就无法利用查询缓存了。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;应该找一个共享式的缓存，比如memcache来解决。将slave-2,slave-3,...这些查询的结果都缓存至mamcache中。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;问题7：&lt;/strong&gt;随着应用的日益增长，读操作很多，我们可以扩展slave，但是如果master满足不了写操作了，怎么办呢？&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;scale on ?更好的服务器？ 没有最好的，只有更好的，太贵了。。。&lt;br/&gt;scale out ? 主从复制架构已经满足不了。&lt;br/&gt;可以分库【垂直拆分】，分表【水平拆分】。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;mysql-高并发环境解决方案&quot;&gt;&lt;strong&gt;3.mysql 高并发环境解决方案?&lt;/strong&gt;&lt;/h4&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;MySQL 高并发环境解决方案：&lt;/strong&gt; 分库 分表 分布式 增加二级缓存。。。。。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;需求分析：&lt;/strong&gt;互联网单位 每天大量数据读取，写入，并发性高。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;strong&gt;现有解决方式：&lt;/strong&gt;水平分库分表，由单点分布到多点数据库中，从而降低单点数据库压力。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;strong&gt;集群方案：&lt;/strong&gt;解决DB宕机带来的单点DB不能访问问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;&lt;strong&gt;读写分离策略：&lt;/strong&gt;极大限度提高了应用中Read数据的速度和并发量。无法解决高写入压力。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;数据库崩溃时事务的恢复机制redo日志和undo日志&quot;&gt;&lt;strong&gt;4.数据库崩溃时事务的恢复机制（REDO日志和UNDO日志）?&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;转载：&lt;a href=&quot;https://www.cnblogs.com/Bozh/archive/2013/03/18/2966494.html&quot;&gt;MySQL REDO日志和UNDO日志&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Undo Log:&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;Undo Log是为了实现事务的原子性，在MySQL数据库InnoDB存储引擎中，还用了Undo Log来实现多版本并发控制(简称：MVCC)。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;事务的原子性(Atomicity)事务中的所有操作，要么全部完成，要么不做任何操作，不能只做部分操作。如果在执行的过程中发生了错误，要回滚(Rollback)到事务开始前的状态，就像这个事务从来没有执行过。&lt;br/&gt;原理Undo Log的原理很简单，为了满足事务的原子性，在操作任何数据之前，首先将数据备份到一个地方（这个存储数据备份的地方称为UndoLog）。然后进行数据的修改。如果出现了错误或者用户执行了ROLLBACK语句，系统可以利用Undo Log中的备份将数据恢复到事务开始之前的状态。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;之所以能同时保证原子性和持久化，是因为以下&lt;strong&gt;特点：&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;15&quot;&gt;
&lt;p&gt;更新数据前记录Undo log。&lt;br/&gt;为了保证持久性，必须将数据在事务提交前写到磁盘。只要事务成功提交，数据必然已经持久化。&lt;br/&gt;Undo log必须先于数据持久化到磁盘。如果在G,H之间系统崩溃，undo log是完整的， 可以用来回滚事务。&lt;br/&gt;如果在A-F之间系统崩溃,因为数据没有持久化到磁盘。所以磁盘上的数据还是保持在事务开始前的状态。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缺陷：&lt;/strong&gt;每个事务提交前将数据和Undo Log写入磁盘，这样会导致大量的磁盘IO，因此性能很低。&lt;br/&gt;如果能够将数据缓存一段时间，就能减少IO提高性能。但是这样就会丧失事务的持久性。因此引入了另外一种机制来实现持久化，即Redo Log。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;strong&gt;Redo Log:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;原理和Undo Log相反，Redo Log记录的是新数据的备份。在事务提交前，只要将Redo Log持久化即可，不需要将数据持久化。当系统崩溃时，虽然数据没有持久化，但是Redo Log已经持久化。系统可以根据Redo Log的内容，将所有数据恢复到最新的状态。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&quot;八整理时参考的资料&quot;&gt;&lt;strong&gt;八、整理时参考的资料&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzIwMTY0NDU3Nw==&amp;amp;mid=2651936134&amp;amp;idx=1&amp;amp;sn=5213a59104f6d2a90bc18d878cafe417&amp;amp;chksm=8d0f3ac8ba78b3deb2ea3473906a37dd205b6e64bfbebe86cc00108242bfa4c49a7d1e509eca&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=0707k8Bdz85tDHyVotxEQ9of#rd&quot;&gt;java团长 数据库整理&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://my.oschina.net/yanpenglei/blog/1650277&quot; title=&quot;20个数据库常见面试题讲解 - 鹏磊 - 开源中国&quot;&gt;20个数据库常见面试题讲解 - 鹏磊 - 开源中国&quot;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://m.2cto.com/database/201710/688377.html&quot;&gt;34个数据库常见面试题讲解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://kb.cnblogs.com/page/45712/&quot;&gt;漫谈数据库索引_知识库_博客园&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/u011479200/article/details/78513632&quot;&gt;Mysql| 使用通配符进行模糊查询(like,%,_)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/lc0817/article/details/52757194&quot;&gt;MySQL存储引擎中的MyISAM和InnoDB区别详解&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/kevingrace/p/5685355.html&quot;&gt;MySQL存储引擎之MyISAM和Innodb总结性梳理&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/liangxw1/article/details/51197560&quot; class=&quot;uri&quot;&gt;https://blog.csdn.net/liangxw1/article/details/51197560&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 25 Oct 2018 15:51:00 +0000</pubDate>
<dc:creator>追寻自我</dc:creator>
<og:description>数据库面试知识点汇总 一、基本概念 1.主键、外键、超键、候选键 超键 ：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/wenxiaofei/p/9853682.html</dc:identifier>
</item>
<item>
<title>Java并发（10）- 简单聊聊JDK中的七大阻塞队列 - knock_小新</title>
<link>http://www.cnblogs.com/konck/p/9473677.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/konck/p/9473677.html</guid>
<description>&lt;h2 id=&quot;引言&quot;&gt;引言&lt;/h2&gt;
&lt;p&gt;JDK中除了上文提到的各种并发容器，还提供了丰富的阻塞队列。阻塞队列统一实现了BlockingQueue接口，BlockingQueue接口在java.util包Queue接口的基础上提供了put(e)以及take()两个阻塞方法。他的主要使用场景就是多线程下的生产者消费者模式，生产者线程通过put(e)方法将生产元素，消费者线程通过take()消费元素。除了阻塞功能，BlockingQueue接口还定义了定时的offer以及poll，以及一次性移除方法drainTo。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;//插入元素，队列满后会抛出异常
boolean add(E e);
//移除元素，队列为空时会抛出异常
E remove();

//插入元素，成功反会true
boolean offer(E e);
//移除元素
E poll();

//插入元素，队列满后会阻塞
void put(E e) throws InterruptedException;
//移除元素，队列空后会阻塞
E take() throws InterruptedException;

//限时插入
boolean offer(E e, long timeout, TimeUnit unit)
//限时移除
E poll(long timeout, TimeUnit unit);

//获取所有元素到Collection中
int drainTo(Collection&amp;lt;? super E&amp;gt; c);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;JDK1.8中的阻塞队列实现共有7个，分别是ArrayBlockingQueue、LinkedBlockingQueue、PriorityBlockingQueue、DelayQueue、SynchronousQueue、LinkedTransferQueue以及LinkedBlockingDeque，下面就来一一对他们进行一个简单的分析。&lt;/p&gt;
&lt;h2 id=&quot;arrayblockingqueue&quot;&gt;ArrayBlockingQueue&lt;/h2&gt;
&lt;p&gt;ArrayBlockingQueue是一个底层用数组实现的有界阻塞队列，有界是指他的容量大小是固定的，不能扩充容量，在初始化时就必须确定队列大小。它通过可重入的独占锁ReentrantLock来控制并发，Condition来实现阻塞。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;//通过数组来存储队列中的元素
final Object[] items;

//初始化一个固定的数组大小，默认使用非公平锁来控制并发
public ArrayBlockingQueue(int capacity) {
    this(capacity, false);
}

//初始化固定的items数组大小，初始化notEmpty以及notFull两个Condition来控制生产消费
public ArrayBlockingQueue(int capacity, boolean fair) {
    if (capacity &amp;lt;= 0)
        throw new IllegalArgumentException();
    this.items = new Object[capacity];
    lock = new ReentrantLock(fair);//通过ReentrantLock来控制并发
    notEmpty = lock.newCondition();
    notFull =  lock.newCondition();
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到ArrayBlockingQueue初始化了一个ReentrantLock以及两个Condition，用来控制并发下队列的生产消费。这里重点看下阻塞的put以及take方法：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;//插入元素到队列中
public void put(E e) throws InterruptedException {
    checkNotNull(e);
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly(); //获取独占锁
    try {
        while (count == items.length) //如果队列已满则通过await阻塞put方法
            notFull.await();
        enqueue(e); //插入元素
    } finally {
        lock.unlock();
    }
}

private void enqueue(E x) {
    // assert lock.getHoldCount() == 1;
    // assert items[putIndex] == null;
    final Object[] items = this.items;
    items[putIndex] = x;
    if (++putIndex == items.length) //插入元素后将putIndex+1，当队列使用完后重置为0
        putIndex = 0;
    count++;
    notEmpty.signal(); //队列添加元素后唤醒因notEmpty等待的消费线程
}

//移除队列中的元素
public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly(); //获取独占锁
    try {
        while (count == 0) //如果队列已空则通过await阻塞take方法
            notEmpty.await(); 
        return dequeue(); //移除元素
    } finally {
        lock.unlock();
    }
}

private E dequeue() {
    // assert lock.getHoldCount() == 1;
    // assert items[takeIndex] != null;
    final Object[] items = this.items;
    @SuppressWarnings(&quot;unchecked&quot;)
    E x = (E) items[takeIndex];
    items[takeIndex] = null;
    if (++takeIndex == items.length) //移除元素后将takeIndex+1，当队列使用完后重置为0
        takeIndex = 0;
    count--;
    if (itrs != null)
        itrs.elementDequeued();
    notFull.signal(); //队列消费元素后唤醒因notFull等待的消费线程
    return x;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在队列添加和移除元素的过程中使用putIndex、takeIndex以及count三个变量来控制生产消费元素的过程，putIndex负责记录下一个可添加元素的下标，takeIndex负责记录下一个可移除元素的下标，count记录了队列中的元素总量。队列满后通过notFull.await()来阻塞生产者线程，消费元素后通过notFull.signal()来唤醒阻塞的生产者线程。队列为空后通过notEmpty.await()来阻塞消费者线程，生产元素后通过notEmpty.signal()唤醒阻塞的消费者线程。&lt;/p&gt;
&lt;p&gt;限时插入以及移除方法在ArrayBlockingQueue中通过awaitNanos来实现，在给定的时间过后如果线程未被唤醒则直接返回。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public boolean offer(E e, long timeout, TimeUnit unit)
    throws InterruptedException {
    checkNotNull(e);
    long nanos = unit.toNanos(timeout); //获取定时时长
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        while (count == items.length) {
            if (nanos &amp;lt;= 0) //指定时长过后，线程仍然未被唤醒则返回false
                return false;
            nanos = notFull.awaitNanos(nanos); //指定时长内阻塞线程
        }
        enqueue(e);
        return true;
    } finally {
        lock.unlock();
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;还有一个比较重要的方法：drainTo，drainTo方法可以一次性获取队列中所有的元素，它减少了锁定队列的次数，使用得当在某些场景下对性能有不错的提升。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public int drainTo(Collection&amp;lt;? super E&amp;gt; c, int maxElements) {
    checkNotNull(c);
    if (c == this)
        throw new IllegalArgumentException();
    if (maxElements &amp;lt;= 0)
        return 0;
    final Object[] items = this.items;
    final ReentrantLock lock = this.lock; //仅获取一次锁
    lock.lock();
    try {
        int n = Math.min(maxElements, count); //获取队列中所有元素
        int take = takeIndex;
        int i = 0;
        try {
            while (i &amp;lt; n) {
                @SuppressWarnings(&quot;unchecked&quot;)
                E x = (E) items[take];
                c.add(x); //循环插入元素
                items[take] = null;
                if (++take == items.length)
                    take = 0;
                i++;
            }
            return n;
        } finally {
            // Restore invariants even if c.add() threw
            if (i &amp;gt; 0) {
                count -= i;
                takeIndex = take;
                if (itrs != null) {
                    if (count == 0)
                        itrs.queueIsEmpty();
                    else if (i &amp;gt; take)
                        itrs.takeIndexWrapped();
                }
                for (; i &amp;gt; 0 &amp;amp;&amp;amp; lock.hasWaiters(notFull); i--)
                    notFull.signal(); //唤醒等待的生产者线程
            }
        }
    } finally {
        lock.unlock();
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;linkedblockingqueue&quot;&gt;LinkedBlockingQueue&lt;/h2&gt;
&lt;p&gt;LinkedBlockingQueue是一个底层用单向链表实现的有界阻塞队列，和ArrayBlockingQueue一样，采用ReentrantLock来控制并发，不同的是它使用了两个独占锁来控制消费和生产。put以及take方法源码如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public void put(E e) throws InterruptedException {
    int c = -1;
    Node&amp;lt;E&amp;gt; node = new Node&amp;lt;E&amp;gt;(e);
    final ReentrantLock putLock = this.putLock;
    //因为使用了双锁，需要使用AtomicInteger计算元素总量，避免并发计算不准确
    final AtomicInteger count = this.count; 
    putLock.lockInterruptibly();
    try {
        while (count.get() == capacity) {
            notFull.await(); //队列已满，阻塞生产线程
        }
        enqueue(node); //插入元素到队列尾部
        c = count.getAndIncrement(); //count + 1
        if (c + 1 &amp;lt; capacity) //如果+1后队列还未满，通过其他生产线程继续生产
            notFull.signal();
    } finally {
        putLock.unlock();
    }
    if (c == 0) //只有当之前是空时，消费队列才会阻塞，否则是不需要通知的
        signalNotEmpty(); 
}

private void enqueue(Node&amp;lt;E&amp;gt; node) {
    //将新元素添加到链表末尾，然后将last指向尾部元素
    last = last.next = node;
}

public E take() throws InterruptedException {
    E x;
    int c = -1;
    final AtomicInteger count = this.count;
    final ReentrantLock takeLock = this.takeLock;
    takeLock.lockInterruptibly();
    try {
        while (count.get() == 0) {
            notEmpty.await(); //队列为空，阻塞消费线程
        }
        x = dequeue(); //消费一个元素
        c = count.getAndDecrement(); //count - 1
        if (c &amp;gt; 1) // 通知其他等待的消费线程继续消费
            notEmpty.signal();
    } finally {
        takeLock.unlock();
    }
    if (c == capacity) //只有当之前是满的，生产队列才会阻塞，否则是不需要通知的
        signalNotFull();
    return x;
}

//消费队列头部的下一个元素，同时将新头部置空
private E dequeue() {
    Node&amp;lt;E&amp;gt; h = head;
    Node&amp;lt;E&amp;gt; first = h.next;
    h.next = h; // help GC
    head = first;
    E x = first.item;
    first.item = null;
    return x;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到LinkedBlockingQueue通过takeLock和putLock两个锁来控制生产和消费，互不干扰，只要队列未满，生产线程可以一直生产，只要队列不为空，消费线程可以一直消费，不会相互因为独占锁而阻塞。&lt;/p&gt;
&lt;p&gt;看过了LinkedBlockingQueue以及ArrayBlockingQueue的底层实现，会发现一个问题，正常来说消费者和生产者可以并发执行对队列的吞吐量会有比较大的提升，那么为什么ArrayBlockingQueue中不使用双锁来实现队列的生产和消费呢？我的理解是ArrayBlockingQueue也能使用双锁来实现功能，但由于它底层使用了数组这种简单结构，相当于一个共享变量，如果通过两个锁，需要更加精确的锁控制，这也是为什么JDK1.7中的ConcurrentHashMap使用了分段锁来实现，将一个数组分为多个数组来提高并发量。LinkedBlockingQueue不存在这个问题，链表这种数据结构头尾节点都相对独立，存储上也不连续，双锁控制不存在复杂性。这是我的理解，如果你有更好的结论，请留言探讨。&lt;/p&gt;
&lt;h2 id=&quot;priorityblockingqueue&quot;&gt;PriorityBlockingQueue&lt;/h2&gt;
&lt;p&gt;PriorityBlockingQueue是一个底层由数组实现的无界队列，并带有排序功能，同样采用ReentrantLock来控制并发。由于是无界的，所以插入元素时不会阻塞，没有队列满的状态，只有队列为空的状态。通过这两点特征其实可以猜测它应该是有一个独占锁（底层数组）和一个Condition（只通知消费）来实现的。put以及take方法源码分析如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public void put(E e) {
    offer(e);
}

public boolean offer(E e) {
    if (e == null)
        throw new NullPointerException();
    final ReentrantLock lock = this.lock;
    lock.lock();
    int n, cap;
    Object[] array;
    //无界队列，队列长度不够时会扩容
    while ((n = size) &amp;gt;= (cap = (array = queue).length))
        tryGrow(array, cap);
    try {
        //通过comparator来实现优先级排序
        Comparator&amp;lt;? super E&amp;gt; cmp = comparator;
        if (cmp == null)
            siftUpComparable(n, e, array);
        else
            siftUpUsingComparator(n, e, array, cmp);
        size = n + 1;
        notEmpty.signal(); //和ArrayBlockingQueue一样，每次添加元素后通知消费线程
    } finally {
        lock.unlock();
    }
    return true;
}

public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    E result;
    try {
        while ( (result = dequeue()) == null)
            notEmpty.await(); //队列为空，阻塞消费线程
    } finally {
        lock.unlock();
    }
    return result;
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;delayqueue&quot;&gt;DelayQueue&lt;/h2&gt;
&lt;p&gt;DelayQueue也是一个无界队列，它是在PriorityQueue基础上实现的，先按延迟优先级排序，延迟时间短的排在前面。和PriorityBlockingQueue相似，底层也是数组，采用一个ReentrantLock来控制并发。由于是无界的，所以插入元素时不会阻塞，没有队列满的状态。能想到的最简单的使用场景一般有两个：一个是缓存过期，一个是定时执行的任务。但由于是无界的，缓存过期上一般使用的并不多。简单来看下put以及take方法：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;private final transient ReentrantLock lock = new ReentrantLock();
private final PriorityQueue&amp;lt;E&amp;gt; q = new PriorityQueue&amp;lt;E&amp;gt;();//优先级队列

public void put(E e) {
    offer(e);
}

public boolean offer(E e) {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        q.offer(e); //插入元素到优先级队列
        if (q.peek() == e) { //如果插入的元素在队列头部
            leader = null;
            available.signal(); //通知消费线程
        }
        return true;
    } finally {
        lock.unlock();
    }
}

public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        for (;;) {
            E first = q.peek(); //获取头部元素
            if (first == null)
                available.await(); //空队列阻塞
            else {
                long delay = first.getDelay(NANOSECONDS); //检查元素是否延迟到期
                if (delay &amp;lt;= 0)
                    return q.poll(); //到期则弹出元素
                first = null; // don't retain ref while waiting
                if (leader != null)
                    available.await();
                else {
                    Thread thisThread = Thread.currentThread();
                    leader = thisThread;
                    try {
                        available.awaitNanos(delay); //阻塞未到期的时间
                    } finally {
                        if (leader == thisThread)
                            leader = null;
                    }
                }
            }
        }
    } finally {
        if (leader == null &amp;amp;&amp;amp; q.peek() != null)
            available.signal();
        lock.unlock();
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;synchronousqueue&quot;&gt;SynchronousQueue&lt;/h2&gt;
&lt;p&gt;SynchronousQueue相比较之前的4个队列就比较特殊了，它是一个没有容量的队列，也就是说它内部时不会对数据进行存储，每进行一次put之后必须要进行一次take，否则相同线程继续put会阻塞。这种特性很适合做一些传递性的工作，一个线程生产，一个线程消费。内部分为公平和非公平访问两种模式，默认使用非公平，未使用锁，全部通过CAS操作来实现并发，吞吐量非常高。这里只对它的非公平实现下的take和put方法做下简单分析：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;//非公平情况下调用内部类TransferStack的transfer方法put
public void put(E e) throws InterruptedException {
    if (e == null) throw new NullPointerException();
    if (transferer.transfer(e, false, 0) == null) {
        Thread.interrupted();
        throw new InterruptedException();
    }
}
//非公平情况下调用内部类TransferStack的transfer方法take
public E take() throws InterruptedException {
    E e = transferer.transfer(null, false, 0);
    if (e != null)
        return e;
    Thread.interrupted();
    throw new InterruptedException();
}

//具体的put以及take方法，只有E的区别，通过E来区别REQUEST还是DATA模式
E transfer(E e, boolean timed, long nanos) {
    SNode s = null; // constructed/reused as needed
    int mode = (e == null) ? REQUEST : DATA;

    for (;;) {
        SNode h = head;
        //栈无元素或者元素和插入的元素模式相匹配，也就是说都是插入元素
        if (h == null || h.mode == mode) {  
            //有时间限制并且超时
            if (timed &amp;amp;&amp;amp; nanos &amp;lt;= 0) {      
                if (h != null &amp;amp;&amp;amp; h.isCancelled())
                    casHead(h, h.next);  // 重新设置头节点
                else
                    return null;
            } 
            //未超时cas操作尝试设置头节点
            else if (casHead(h, s = snode(s, e, h, mode))) {
                //自旋一段时间后未消费元素则挂起put线程
                SNode m = awaitFulfill(s, timed, nanos);
                if (m == s) {               // wait was cancelled
                    clean(s);
                    return null;
                }
                if ((h = head) != null &amp;amp;&amp;amp; h.next == s)
                    casHead(h, s.next);     // help s's fulfiller
                return (E) ((mode == REQUEST) ? m.item : s.item);
            }
        } 
        //栈不为空并且和头节点模式不匹配，存在元素则消费元素并重新设置head节点
        else if (!isFulfilling(h.mode)) { // try to fulfill
            if (h.isCancelled())            // already cancelled
                casHead(h, h.next);         // pop and retry
            else if (casHead(h, s=snode(s, e, h, FULFILLING|mode))) {
                for (;;) { // loop until matched or waiters disappear
                    SNode m = s.next;       // m is s's match
                    if (m == null) {        // all waiters are gone
                        casHead(s, null);   // pop fulfill node
                        s = null;           // use new node next time
                        break;              // restart main loop
                    }
                    SNode mn = m.next;
                    if (m.tryMatch(s)) {
                        casHead(s, mn);     // pop both s and m
                        return (E) ((mode == REQUEST) ? m.item : s.item);
                    } else                  // lost match
                        s.casNext(m, mn);   // help unlink
                }
            }
        }
        //节点正在匹配阶段 
        else {                            // help a fulfiller
            SNode m = h.next;               // m is h's match
            if (m == null)                  // waiter is gone
                casHead(h, null);           // pop fulfilling node
            else {
                SNode mn = m.next;
                if (m.tryMatch(h))          // help match
                    casHead(h, mn);         // pop both h and m
                else                        // lost match
                    h.casNext(m, mn);       // help unlink
            }
        }
    }
}

//先自旋后挂起的核心方法
SNode awaitFulfill(SNode s, boolean timed, long nanos) {
    final long deadline = timed ? System.nanoTime() + nanos : 0L;
    Thread w = Thread.currentThread();
    //计算自旋的次数
    int spins = (shouldSpin(s) ?
                    (timed ? maxTimedSpins : maxUntimedSpins) : 0);
    for (;;) {
        if (w.isInterrupted())
            s.tryCancel();
        SNode m = s.match;
        //匹配成功过返回节点
        if (m != null)
            return m;
        //超时控制
        if (timed) {
            nanos = deadline - System.nanoTime();
            if (nanos &amp;lt;= 0L) {
                s.tryCancel();
                continue;
            }
        }
        //自旋检查，是否进行下一次自旋
        if (spins &amp;gt; 0)
            spins = shouldSpin(s) ? (spins-1) : 0;
        else if (s.waiter == null)
            s.waiter = w; // establish waiter so can park next iter
        else if (!timed)
            LockSupport.park(this); //在这里挂起线程
        else if (nanos &amp;gt; spinForTimeoutThreshold)
            LockSupport.parkNanos(this, nanos);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;代码非常复杂，这里说下我所理解的核心逻辑。代码中可以看到put以及take方法都是通过调用transfer方法来实现的，然后通过参数mode来区别，在生产元素时如果是同一个线程多次put则会采取自旋的方式多次尝试put元素，可能自旋过程中元素会被消费，这样可以及时put，降低线程挂起的性能损耗，高吞吐量的核心也在这里，消费线程一样，空栈时也会先自旋，自旋失败然后通过线程的LockSupport.park方法挂起。&lt;/p&gt;
&lt;h2 id=&quot;linkedtransferqueue&quot;&gt;LinkedTransferQueue&lt;/h2&gt;
&lt;p&gt;LinkedTransferQueue是一个无界的阻塞队列，底层由链表实现。虽然和LinkedBlockingQueue一样也是链表实现的，但并发控制的实现上却很不一样，和SynchronousQueue类似，采用了大量的CAS操作，没有使用锁，由于是无界的，所以不会put生产线程不会阻塞，只会在take时阻塞消费线程，消费线程挂起时同样使用LockSupport.park方法。&lt;/p&gt;
&lt;p&gt;LinkedTransferQueue相比于以上的队列还提供了一些额外的功能，它实现了TransferQueue接口，有两个关键方法transfer(E e)和tryTransfer(E e)方法，transfer在没有消费时会阻塞，tryTransfer在没有消费时不会插入到队列中，也不会等待，直接返回false。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;private static final int NOW   = 0; // for untimed poll, tryTransfer
private static final int ASYNC = 1; // for offer, put, add
private static final int SYNC  = 2; // for transfer, take
private static final int TIMED = 3; // for timed poll, tryTransfer

//通过SYNC状态来实现生产阻塞
public void transfer(E e) throws InterruptedException {
    if (xfer(e, true, SYNC, 0) != null) {
        Thread.interrupted(); // failure possible only due to interrupt
        throw new InterruptedException();
    }
}
//通过NOW状态跳过添加元素以及阻塞
public boolean tryTransfer(E e) {
    return xfer(e, true, NOW, 0) == null;
}

//通过ASYNC状态跳过阻塞
public void put(E e) {
    xfer(e, true, ASYNC, 0);
}
//通过SYNC状态来实现消费阻塞
public E take() throws InterruptedException {
    E e = xfer(null, false, SYNC, 0);
    if (e != null)
        return e;
    Thread.interrupted();
    throw new InterruptedException();
}

//生产消费调用同一个方法，通过e是否为空，haveData，how等参数来区分具体逻辑
private E xfer(E e, boolean haveData, int how, long nanos) {
    if (haveData &amp;amp;&amp;amp; (e == null))
        throw new NullPointerException();
    Node s = null;                        // the node to append, if needed

    retry:
    for (;;) {                            // restart on append race
        //找出第一个可用节点
        for (Node h = head, p = h; p != null;) { // find &amp;amp; match first node
            boolean isData = p.isData;
            Object item = p.item;
            //队列为空时直接跳过
            if (item != p &amp;amp;&amp;amp; (item != null) == isData) { // unmatched
                //节点类型相同，跳过
                if (isData == haveData)   // can't match
                    break;
                if (p.casItem(item, e)) { // match
                    for (Node q = p; q != h;) {
                        Node n = q.next;  // update by 2 unless singleton
                        if (head == h &amp;amp;&amp;amp; casHead(h, n == null ? q : n)) {
                            h.forgetNext();
                            break;
                        }                 // advance and retry
                        if ((h = head)   == null ||
                            (q = h.next) == null || !q.isMatched())
                            break;        // unless slack &amp;lt; 2
                    }
                    LockSupport.unpark(p.waiter);
                    return LinkedTransferQueue.&amp;lt;E&amp;gt;cast(item);
                }
            }
            Node n = p.next;
            p = (p != n) ? n : (h = head); // Use head if p offlist
        }
        //插入节点或移除节点具体逻辑
        //tryTransfer方法会直接跳过并返回结果
        if (how != NOW) {                 // No matches available
            if (s == null)
                s = new Node(e, haveData);
            Node pred = tryAppend(s, haveData); //加入节点
            if (pred == null)
                continue retry;           // lost race vs opposite mode
            if (how != ASYNC)
                //自旋以及阻塞消费线程逻辑，和SynchronousQueue类似，先尝试自选，失败后挂起线程
                //transfer方法在没有消费线程时也会阻塞在这里
                return awaitMatch(s, pred, e, (how == TIMED), nanos);
        }
        return e; // not waiting
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;linkedblockingdeque&quot;&gt;LinkedBlockingDeque&lt;/h2&gt;
&lt;p&gt;LinkedBlockingDeque是一个有界的双端队列，底层采用一个双向的链表来实现，在LinkedBlockingQeque的Node实现多了指向前一个节点的变量prev。并发控制上和ArrayBlockingQueue类似，采用单个ReentrantLock来控制并发，这里是因为双端队列头尾都可以消费和生产，所以使用了一个共享锁。它实现了BlockingDeque接口，继承自BlockingQueue接口，多了addFirst，addLast，offerFirst，offerLast，peekFirst，peekLast等方法，用来头尾生产和消费。LinkedBlockingDeque的实现代码比较简单，基本就是综合了LinkedBlockingQeque和ArrayBlockingQueue的代码逻辑，这里就不做分析了。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;文章对JDK1.8中的7种阻塞队列都做了简单分析，帮助大家大致梳理的这7个队列的基本原理。总的来说每种阻塞队列都有它自己的应用场景，使用时可以先根据有界还是无界，然后在根据各自的特性来进行选择。&lt;/p&gt;
&lt;p&gt;有界阻塞队列包括：ArrayBlockingQueue、LinkedBlockingQueue以及LinkedBlockingDeque三种，LinkedBlockingDeque应用场景很少，一般用在“工作窃取”模式下。ArrayBlockingQueue和LinkedBlockingQueue基本就是数组和链表的区别。无界队列包括PriorityBlockingQueue、DelayQueue和LinkedTransferQueue。PriorityBlockingQueue用在需要排序的队列中。DelayQueue可以用来做一些定时任务或者缓存过期的场景。LinkedTransferQueue则相比较其他队列多了transfer功能。最后剩下一个不存储元素的队列SynchronousQueue，用来处理一些高效的传递性场景。&lt;/p&gt;
&lt;p&gt;参考资料：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;《Java并发编程的艺术》&lt;/li&gt;
&lt;li&gt;《Java并发编程实战》&lt;/li&gt;
&lt;/ul&gt;</description>
<pubDate>Thu, 25 Oct 2018 15:50:00 +0000</pubDate>
<dc:creator>knock_小新</dc:creator>
<og:description>引言 JDK中除了上文提到的各种并发容器，还提供了丰富的阻塞队列。阻塞队列统一实现了BlockingQueue接口，BlockingQueue接口在java.util包Queue接口的基础上提供</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/konck/p/9473677.html</dc:identifier>
</item>
<item>
<title>商品中心中台支持系统-规格设计 - 无涯Ⅱ</title>
<link>http://www.cnblogs.com/wlandwl/p/goods_format.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wlandwl/p/goods_format.html</guid>
<description>&lt;p class=&quot;toc&quot;&gt;目录&lt;/p&gt;
&lt;h2 id=&quot;商品中心中台支持系统-规格设计&quot;&gt;商品中心中台支持系统-规格设计&lt;/h2&gt;
&lt;h3 id=&quot;修订记录&quot;&gt;修订记录&lt;/h3&gt;
&lt;table&gt;&lt;thead/&gt;&lt;tbody&gt;&lt;tr class=&quot;odd&quot;&gt;&lt;td&gt;2018-10-25&lt;/td&gt;
&lt;td&gt;V1.0&lt;/td&gt;
&lt;td/&gt;
&lt;td&gt;初始版本&lt;/td&gt;
&lt;td&gt;无涯&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;h3 id=&quot;目录&quot;&gt;目录&lt;/h3&gt;
&lt;h3 id=&quot;规格设计&quot;&gt;1、规格设计&lt;/h3&gt;
&lt;p&gt;本文讲述电商系统构建中，商品中心规格模块的相关知识和数据存储设计。&lt;/p&gt;
&lt;h4 id=&quot;规格知识&quot;&gt;1.1、规格知识&lt;/h4&gt;
&lt;p&gt;商品规格是指一些足以反映商品品质的主要指标，如化学成分、含量、纯度、性能、容量、长短、粗细等。&lt;br/&gt;例如：买衣服的商品规格指的是尺寸的大小，一般的均码分大、中、小号;有的较细，上衣依据衣长、胸围、领长分大小，下裤依据裤长短、腰围分大小等等。&lt;br/&gt;应用场景：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1.为商品设置规格，便于商品通过规格买卖。&lt;/li&gt;
&lt;li&gt;2.通过规格切换选择商品。&lt;br/&gt;如京东商品规格切换界面：&lt;br/&gt;&lt;img src=&quot;http://apidoc.epetbar.com/upload/9f1cdedc7efafa873c921662108300bc&quot;/&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;规格管理&quot;&gt;1.2、规格管理&lt;/h4&gt;
&lt;h5 id=&quot;规格管理思维导图&quot;&gt;1.2.1、规格管理思维导图&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;http://apidoc.epetbar.com/upload/ef51f5bedb6d37b141f345bb8ea50b0a&quot;/&gt;&lt;br/&gt;规格与类目的关系主要为一个类目可设置关联一个或多个规格。具体模式放在类目模块中讲解。&lt;br/&gt;&lt;img src=&quot;http://apidoc.epetbar.com/upload/40f7cc815588a0f3592b35d5d95eea9d&quot;/&gt;&lt;br/&gt;商品规格模块包括规格项，规格明细，规格明细别名三个模块。规格明细别名主要是针对商品前端展示设计的，如规格明细为红色，规格明细别名可设置为深红色。规格明细别名是对一个具体规格明细值的进一步细化。商品设置规格时，实际是设置商品与规格明细别名的关系（所以任何规格都必须设置规格别名，没有规格别名的设置为规格明细名称）。&lt;br/&gt;&lt;strong&gt;其他方案：&lt;/strong&gt;&lt;br/&gt;商品规格设计的另外一种方案是将规格作为一种特殊的属性归类到属性体系中，这两种方案都能满足商品规格管理。本例还是将规格单独作为基础数据管理，规格与属性为两个独立的模块。&lt;/p&gt;
&lt;h4 id=&quot;应用模块示例&quot;&gt;1.3、应用模块示例&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;规格类型数据：&lt;/strong&gt;&lt;br/&gt;&lt;img src=&quot;http://apidoc.epetbar.com/upload/0971c0c3b9922e3fa4b425b1326dfbf2&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规格明细别名数据管理：&lt;/strong&gt;&lt;br/&gt;&lt;img src=&quot;http://apidoc.epetbar.com/upload/9063323752f16d8d8d703fb2f0fedf47&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规格值数据管理：&lt;/strong&gt;&lt;br/&gt;&lt;img src=&quot;http://apidoc.epetbar.com/upload/07eb481bd8eac323ec14fc3df80a3b1e&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;数据结构设计&quot;&gt;1.4、数据结构设计&lt;/h4&gt;
&lt;h5 id=&quot;数据表设计&quot;&gt;1.4.1、数据表设计&lt;/h5&gt;
&lt;p&gt;规格数据存储在规格项表，规格明细表，规格明细别名表中。其数据映射关系为一个规格项存在多个或一个规格明细值，一个规格明细存在多个或一个规格别名值。&lt;br/&gt;&lt;img src=&quot;http://apidoc.epetbar.com/upload/4554ab6962c0fbdfa9b878aa0b8130e5&quot;/&gt;&lt;/p&gt;
&lt;p&gt;字段说明：&lt;br/&gt;&lt;strong&gt;c_format_type规格类型表&lt;/strong&gt;&lt;br/&gt;fm_id:规格类型编码&lt;br/&gt;fm_name:规格项名称&lt;br/&gt;show_img:是否展示为图片模式&lt;br/&gt;&lt;strong&gt;c_format_detail规格明细表&lt;/strong&gt;&lt;br/&gt;fetail_id:规格明细编码&lt;br/&gt;fdetail_name:规格明细名称&lt;br/&gt;c_format_detail_alias规格明细别名表&lt;br/&gt;falias_id:规格明细别名编码&lt;br/&gt;falias_name:规格别名名称&lt;/p&gt;
&lt;h5 id=&quot;规格数据示例&quot;&gt;1.4.2、规格数据示例&lt;/h5&gt;
&lt;p&gt;常用规格数据归类如下：&lt;br/&gt;&lt;img src=&quot;http://apidoc.epetbar.com/upload/3f3f6829023b438b1530e3621bff7a0e&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;设计原则说明&quot;&gt;1.5、设计原则说明&lt;/h4&gt;
&lt;p&gt;规格数据表设计原则：&lt;br/&gt;1.基础信息字段细分独立。&lt;br/&gt;2.业务归类。&lt;br/&gt;3.为什么要设计规格明细别名？&lt;br/&gt;通过对商品规格设置数据的参考，若只设置规格项和规格明细值时，会出现一个规格项下面存在大量的规格明细值，就如同颜色一样，随着运营的需求，不同名称的颜色别名使得规格值数据偏多。不便于业务方快速选择规格值和维护规格值数据。本例通过引入规格明细别名，实则为代替规格明细值，规格明细如同是对这些别名做了一个规格分组。用户在设置商品规格时，可通过下拉单选设置规格明细值，规格别名值，这一些数据都是基础数据，一般都是初始化后，较少变动。当用户发现别名值不满足需求时，可通过添加别名完成运营需求。&lt;/p&gt;
</description>
<pubDate>Thu, 25 Oct 2018 15:30:00 +0000</pubDate>
<dc:creator>无涯Ⅱ</dc:creator>
<og:description>商品中心中台支持系统 规格设计 修订记录 |日期|版本|章节|描述|作者| | | | | | | | 2018 10 25 | V1.0 | | 初始版本 | 无涯| 目录 [TOC] 1、规格设计</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/wlandwl/p/goods_format.html</dc:identifier>
</item>
<item>
<title>目标检测-基于Pytorch实现Yolov3（1）- 搭建模型 - J博士</title>
<link>http://www.cnblogs.com/jacklu/p/9853599.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/jacklu/p/9853599.html</guid>
<description>&lt;p&gt;原文地址：&lt;a href=&quot;https://www.cnblogs.com/jacklu/p/9853599.html&quot; target=&quot;_blank&quot;&gt;https://www.cnblogs.com/jacklu/p/9853599.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本人前段时间在T厂做了目标检测的项目，对一些目标检测框架也有了一定理解。其中Yolov3速度非常快，效果也还可以，但在github上还没有完整的基于pytorch的yolov3代码，目前star最多的pytorch yolov3项目只能做预测，没有训练代码，而且我看了它的model写得不是很有层次。自己准备利用接下来的几个周末把这个坑填上。&lt;/p&gt;
&lt;p&gt;希望能够帮助开发者了解如何基于Pytorch实现一个强大的目标检测模型，同时可以方便的将模型应用到自己的数据集里。完整的源代码准备在文章结束后考虑发布在github上。&lt;/p&gt;
&lt;p&gt;准备的目录：&lt;/p&gt;
&lt;p&gt;&lt;span&gt;目标检测-基于Pytorch实现Yolov3（1）- 搭建模型 （model.py，最容易的部分，所以第一篇写这个）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;目标检测-基于Pytorch实现Yolov3（2）- 数据预处理及数据加载 (dataloader.py，非常重要的一部分，代码工作量最大，定制化只要在这一部分下功夫)&lt;/p&gt;
&lt;p&gt;目标检测-基于Pytorch实现Yolov3（3）- 目标函数 (loss.py，最重要的部分，直接决定了网络的效果，难度也是5部分里最大的)&lt;/p&gt;
&lt;p&gt;目标检测-基于Pytorch实现Yolov3（4）- 模型训练 (train.py，前面重要的3部分都做完了，这部分就是写完代码喝茶看曲线的时间)&lt;/p&gt;
&lt;p&gt;目标检测-基于Pytorch实现Yolov3（5）- 模型预测 (test.py，检验模型训练好坏，还有一些坑要填)&lt;/p&gt;
&lt;p&gt;代码主要参考github上基于keras的yolov3的实现，代码结构非常清晰。&lt;/p&gt;

&lt;p&gt;Yolo系列的作者把yolo网络叫做Darknet，其实其他神经网络库都已经把卷积层写好了，直接堆叠起来即可。&lt;/p&gt;
&lt;p&gt;darknet卷积模块是这个模型里最基本的网络单元，包括卷积层、batch norm(BN)层、激活函数，因此类型命名为 DarknetConv2D_BN_Leaky。原keras实现是卷积层加了L2正则化预防过拟合，Pytorch是把这个操作放到了Optimizer中，所以将在第三部分讲解。&lt;/p&gt;
&lt;p&gt;用Pytorch需要注意, 如果你训练的时候GPU显存不大，batch size设的很小，这时候你就要考虑训练数据集的分布情况。举个例子，加入你的batch size设成了1，但你数据每张图差别都很大，这会导致你的网络一直在震荡，即使网络能够训练到很低的training loss，&lt;/p&gt;
&lt;p&gt;在做预测的时候效果也不好，这主要是BN造成的。因为每批数据的统计量（均值和方差）都不同，而且差别大，这就导致网络训练学不到好的BN层的统计量。如果直接去掉BN层，你会发现网络训练非常慢，所以BN层还是要加的，好在Pytorch里的BN有个接口来控制要不要记住每批训练的统计量，即&lt;em&gt;track_running_stats=True&lt;/em&gt;，如果训练的batch size不能设特别大，就把它改成False。&lt;/p&gt;
&lt;p&gt;卷积层、BN层说完了，激活函数Yolo里用的是0.1的LeakReLU，本人实验发现和ReLU没什么明显的区别（水论文真是一门艺术，我的水文怎么就不中嘞？）&lt;/p&gt;
&lt;p&gt;结构很简答，这部分直接上代码，不画图了。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;46&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; torch.nn as nn
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; torch
&lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt; DarknetConv2D_BN_Leaky(nn.Module):
    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;__init__&lt;/span&gt;(self, numIn, numOut, ksize, stride = 1, padding = 1&lt;span&gt;):
        super(DarknetConv2D_BN_Leaky, self).&lt;/span&gt;&lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;()
        self.conv1 &lt;/span&gt;= nn.Conv2d(numIn, numOut, ksize, stride, padding)&lt;span&gt;#&lt;/span&gt;&lt;span&gt;regularizer': l2(5e-4)&lt;/span&gt;
        self.bn1 =&lt;span&gt; nn.BatchNorm2d(numOut)
        self.leakyReLU &lt;/span&gt;= nn.LeakyReLU(0.1&lt;span&gt;)

    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; forward(self, x):
        x &lt;/span&gt;=&lt;span&gt; self.conv1(x)
        x &lt;/span&gt;=&lt;span&gt; self.bn1(x)
        x &lt;/span&gt;=&lt;span&gt; self.leakyReLU(x)
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; x
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;残差模块是借鉴了ResNet，残差模块是为了保证深的模型能够得到很好的训练。残差模块ResidualBlock，对外接口有numIn, numOut, numBlock，分别控制模块的输入通道数，输出通道数（卷积核数）和残差模块的堆叠次数。下图是一个numBlock = 2 的模型，注意这里CONV是指上一部分说的Darknet卷积模块，第一个模块（D2）表示是这个卷积模块stride = 2，及顺便执行了2倍降采样操作。也就是说特征每经过一个残差模块，分辨率降为原来的一半。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/718161/201810/718161-20181025230632131-2014876526.png&quot; alt=&quot;&quot; width=&quot;451&quot; height=&quot;506&quot;/&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;52&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt;&lt;span&gt; ResidualBlock(nn.Module):
    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;(self, numIn, numOut, numBlock):
        super(ResidualBlock, self).&lt;/span&gt;&lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;()
        self.numBlock &lt;/span&gt;=&lt;span&gt; numBlock
        self.dark_conv1 &lt;/span&gt;= DarknetConv2D_BN_Leaky(numIn, numOut, ksize = 3, stride = 2, padding = 1&lt;span&gt;)
        self.dark_conv2 &lt;/span&gt;=&lt;span&gt; []
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; i &lt;span&gt;in&lt;/span&gt;&lt;span&gt; range(self.numBlock):
            layers &lt;/span&gt;=&lt;span&gt; []
            layers.append(DarknetConv2D_BN_Leaky(numOut, numOut&lt;/span&gt;//2, ksize = 1, stride = 1, padding =&lt;span&gt; 0))
            layers.append(DarknetConv2D_BN_Leaky(numOut&lt;/span&gt;//2, numOut, ksize = 3, stride = 1, padding = 1&lt;span&gt;))
            self.dark_conv2.append(nn.Sequential(&lt;/span&gt;*&lt;span&gt;layers))
        self.dark_conv2 &lt;/span&gt;=&lt;span&gt; nn.ModuleList(self.dark_conv2)
    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; forward(self, x):
        x &lt;/span&gt;=&lt;span&gt; self.dark_conv1(x)
        &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; convblock &lt;span&gt;in&lt;/span&gt;&lt;span&gt; self.dark_conv2:
            residual &lt;/span&gt;=&lt;span&gt; x
            x &lt;/span&gt;=&lt;span&gt; self.convblock(x)
            x &lt;/span&gt;= x +&lt;span&gt; residual
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; x
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;后端输出模块是一个三次降采样（三次升采样在下一部分介绍），这三次降采样+三次升采样，类似Encoder-Decoder的FCN模型。是为了在三种不同尺度上预测。本系列将在voc2007上训练，训练前输入图片要resize到256x256，那么这三种尺度分别是32x32,16x16,8x8。这一部分是因为图片中的目标有大有小，为了保证从不同尺度上找到最好尺度的特征图来进行预测。当然准确提升的同时，由于分辨率有提升，计算量又有一定的增加，索性我们这里的分辨率不大。下图所示为最后输出模块，这个模块有两个输出，一个是用作下一个模块的输入，一个是用于输出目标检测结果，即坐标、类别和目标置信度，这一部分将在下一篇详细介绍。注意红色的Conv不是DarknetConv2D_BN_Leaky，而是指普通的卷积模块。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/718161/201810/718161-20181025225943598-1761095508.png&quot; alt=&quot;&quot; width=&quot;427&quot; height=&quot;530&quot;/&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;69&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt;&lt;span&gt; LastLayer(nn.Module):
    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;(self, numIn, numOut, numOut2):
        super(LastLayer, self).&lt;/span&gt;&lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;()
        self.dark_conv1 &lt;/span&gt;= DarknetConv2D_BN_Leaky(numIn, numOut, ksize = 1, stride = 1, padding =&lt;span&gt; 0)
        self.dark_conv2 &lt;/span&gt;= DarknetConv2D_BN_Leaky(numOut, numOut*2, ksize = 3, stride = 1, padding = 1&lt;span&gt;)
        self.dark_conv3 &lt;/span&gt;= DarknetConv2D_BN_Leaky(numOut*2, numOut, ksize = 1, stride = 1, padding =&lt;span&gt; 0)
        self.dark_conv4 &lt;/span&gt;= DarknetConv2D_BN_Leaky(numOut, numOut*2, ksize = 3, stride = 1, padding = 1&lt;span&gt;)
        self.dark_conv5 &lt;/span&gt;= DarknetConv2D_BN_Leaky(numOut*2, numOut, ksize = 1, stride = 1, padding =&lt;span&gt; 0)
        
        self.dark_conv6 &lt;/span&gt;= DarknetConv2D_BN_Leaky(numOut, numOut*2, ksize = 3, stride = 1, padding = 1&lt;span&gt;)
        self.conv7 &lt;/span&gt;= nn.Conv2d(numOut*2, numOut2, 1, stride = 1, padding =&lt;span&gt; 0)
    
    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; forward(self, x):
        x &lt;/span&gt;=&lt;span&gt; self.dark_conv1(x)
        x &lt;/span&gt;=&lt;span&gt; self.dark_conv2(x)
        x &lt;/span&gt;=&lt;span&gt; self.dark_conv3(x)
        x &lt;/span&gt;=&lt;span&gt; self.dark_conv4(x)
        x &lt;/span&gt;=&lt;span&gt; self.dark_conv5(x)
        
        y &lt;/span&gt;=&lt;span&gt; self.dark_conv6(x)
        y &lt;/span&gt;=&lt;span&gt; self.conv7(y)
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; x,y
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;基本的模块已经定义好，Yolov3的模型就是把这些模型叠加起来。注意下图就是Yolov3的简化模型，数字表示该上一个模块的输出特征尺寸（CxHxW）,相应的颜色对应相应的模块&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/718161/201810/718161-20181025232024753-498318521.png&quot; alt=&quot;&quot; width=&quot;577&quot; height=&quot;471&quot;/&gt;&lt;/p&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;79&quot;&gt;
&lt;pre&gt;
&lt;span&gt;class&lt;/span&gt;&lt;span&gt; Yolov3(nn.Module):
    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt; &lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;(self, numAnchor, numClass):
        super(Yolov3, self).&lt;/span&gt;&lt;span&gt;__init__&lt;/span&gt;&lt;span&gt;()
        self.dark_conv1 &lt;/span&gt;= DarknetConv2D_BN_Leaky(3, 32, ksize = 3, stride = 1, padding = 1&lt;span&gt;)
        self.res1 &lt;/span&gt;= ResidualBlock(32, 64, 1&lt;span&gt;)
        self.res2 &lt;/span&gt;= ResidualBlock(64, 128, 2&lt;span&gt;)
        self.res3 &lt;/span&gt;= ResidualBlock(128, 256, 8&lt;span&gt;)
        self.res4 &lt;/span&gt;= ResidualBlock(256, 512, 8&lt;span&gt;)
        self.res5 &lt;/span&gt;= ResidualBlock(512, 1024, 4&lt;span&gt;)
        
        self.last1 &lt;/span&gt;= LastLayer(1024, 512, numAnchor*(numClass+5&lt;span&gt;))
        self.up1 &lt;/span&gt;= nn.Sequential(DarknetConv2D_BN_Leaky(512, 256, ksize = 1, stride = 1, padding =&lt;span&gt; 0),
                                 nn.Upsample(scale_factor&lt;/span&gt;=2&lt;span&gt;))
        self.last2 &lt;/span&gt;= LastLayer(768, 256, numAnchor*(numClass+5&lt;span&gt;))
        self.up2 &lt;/span&gt;= nn.Sequential(DarknetConv2D_BN_Leaky(256, 128, ksize = 1, stride = 1, padding =&lt;span&gt; 0),
                                 nn.Upsample(scale_factor&lt;/span&gt;=2&lt;span&gt;))
        self.last3 &lt;/span&gt;= LastLayer(384, 128, numAnchor*(numClass+5&lt;span&gt;))
        
    &lt;/span&gt;&lt;span&gt;def&lt;/span&gt;&lt;span&gt; forward(self, x):
        x &lt;/span&gt;= self.dark_conv1(x)&lt;span&gt;#&lt;/span&gt;&lt;span&gt;32x256x256 &lt;/span&gt;
        x = self.res1(x)&lt;span&gt;#&lt;/span&gt;&lt;span&gt;64x128x128&lt;/span&gt;
        x = self.res2(x)&lt;span&gt;#&lt;/span&gt;&lt;span&gt;128x64x64&lt;/span&gt;
        x3 = self.res3(x)&lt;span&gt;#&lt;/span&gt;&lt;span&gt;256x32x32&lt;/span&gt;
        x4 = self.res4(x3)&lt;span&gt;#&lt;/span&gt;&lt;span&gt;512x16x16&lt;/span&gt;
        x5 = self.res5(x4)&lt;span&gt;#&lt;/span&gt;&lt;span&gt;1024x8x8&lt;/span&gt;
&lt;span&gt;        
        x,y1 &lt;/span&gt;= self.last1(x5)&lt;span&gt;#&lt;/span&gt;&lt;span&gt;512x8x8, &lt;/span&gt;
        x = self.up1(x)&lt;span&gt;#&lt;/span&gt;&lt;span&gt;256x16x16&lt;/span&gt;
        x = torch.cat((x, x4), 1)&lt;span&gt;#&lt;/span&gt;&lt;span&gt;768x16x16&lt;/span&gt;
        x,y2 = self.last2(x)&lt;span&gt;#&lt;/span&gt;&lt;span&gt;256x16x16&lt;/span&gt;
        x = self.up2(x)&lt;span&gt;#&lt;/span&gt;&lt;span&gt;128x32x32&lt;/span&gt;
        x = torch.cat((x, x3), 1)&lt;span&gt;#&lt;/span&gt;&lt;span&gt;384x32x32&lt;/span&gt;
        x,y3 = self.last3(x)&lt;span&gt;#&lt;/span&gt;&lt;span&gt;128x32x32&lt;/span&gt;
        
        &lt;span&gt;return&lt;/span&gt; y1,y2,y3
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;到这里模型已经完成，模型代码结构非常清晰。有人可能会问，为什么要这种堆叠方式，其实我自己也觉得模型没什么特别的地方，自己根据新的需求定义网络结构完全可以，但是要注意模型深度增加时如何保证收敛，如何加速模型训练，同时输出特征的分辨率要计算好。&lt;/p&gt;

&lt;p&gt;参考资料&lt;/p&gt;
&lt;p&gt;Yolov3 论文：https://pjreddie.com/media/files/papers/YOLOv3.pdf&lt;/p&gt;
&lt;p&gt;Yolov3 Keras实现:https://github.com/qqwweee/keras-yolo3&lt;/p&gt;

</description>
<pubDate>Thu, 25 Oct 2018 15:24:00 +0000</pubDate>
<dc:creator>J博士</dc:creator>
<og:description>原文地址：https://www.cnblogs.com/jacklu/p/9853599.html 本人前段时间在T厂做了目标检测的项目，对一些目标检测框架也有了一定理解。其中Yolov3速度非常快</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/jacklu/p/9853599.html</dc:identifier>
</item>
<item>
<title>三高系统常用架构模式 - BloodyAngel</title>
<link>http://www.cnblogs.com/zgynhqf/p/9853591.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zgynhqf/p/9853591.html</guid>
<description>&lt;p&gt;总结一下三高（高性能、高并发、高可用）系统在架构时常见的&lt;strong&gt;模式及技术&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;面向互联网的三高系统，最关注的&lt;strong&gt;软件质量属性&lt;/strong&gt;是：性能、可用性、伸缩性、扩展性、安全性。&lt;/p&gt;
&lt;p&gt;而构建此类系统，最常见的&lt;strong&gt;架构模式&lt;/strong&gt;有：横向分层、纵向分割、分布式化、集群化、使用缓存、使用异步模式、使用冗余、自动化（发布、部署、监控）。&lt;/p&gt;
&lt;p&gt;具体来说，可以在不同层次&lt;strong&gt;常用的技术&lt;/strong&gt;有：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;前端架构&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;浏览器优化技术：合理布局，页面缓存，减少http请求数，页面压缩，减少 cookie 传输。&lt;/li&gt;
&lt;li&gt;CDN&lt;/li&gt;
&lt;li&gt;DNS负载均衡&lt;/li&gt;
&lt;li&gt;动静分离，静态资源独立部署&lt;/li&gt;
&lt;li&gt;动态图片独立提供服务&lt;/li&gt;
&lt;li&gt;反向代理&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;应用层架构&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;业务拆分&lt;/li&gt;
&lt;li&gt;负载均衡&lt;/li&gt;
&lt;li&gt;虚拟化服务器、容器化&lt;/li&gt;
&lt;li&gt;无状态（以及分布式 Session）&lt;/li&gt;
&lt;li&gt;分布式缓存&lt;/li&gt;
&lt;li&gt;异步、事件驱动架构、消息队列&lt;/li&gt;
&lt;li&gt;多线程&lt;/li&gt;
&lt;li&gt;动态页面静态化&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;服务层架构&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;分布式微服务（分级管理，超时设置，异步调用，服务降级，幂等性设计。）&lt;/li&gt;
&lt;li&gt;同应用层架构&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;存储层架构&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;DFS&lt;/li&gt;
&lt;li&gt;关系数据库路由&lt;/li&gt;
&lt;li&gt;No S QL 数据库&lt;/li&gt;
&lt;li&gt;数据同步&lt;/li&gt;
&lt;li&gt;数据冗余&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;安全架构&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Web攻击（XSS、Sql Injection）&lt;/li&gt;
&lt;li&gt;数据加密&lt;/li&gt;
&lt;li&gt;密钥管理&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;发布、运维&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;自动化测试与发布&lt;/li&gt;
&lt;li&gt;灰度发布&lt;/li&gt;
&lt;li&gt;浏览器数据采集&lt;/li&gt;
&lt;li&gt;服务器业务数据采集&lt;/li&gt;
&lt;li&gt;服务器性能数据采集&lt;/li&gt;
&lt;li&gt;系统监控&lt;/li&gt;
&lt;li&gt;系统报警&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;机房&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;散热、省电、定制服务器&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;暂时就写这么多，以后想到了再加……&lt;/p&gt;
</description>
<pubDate>Thu, 25 Oct 2018 15:20:00 +0000</pubDate>
<dc:creator>BloodyAngel</dc:creator>
<og:description>总结一下三高（高性能、高并发、高可用）系统在架构时常见的 模式及技术 。 面向互联网的三高系统，最关注的 软件质量属性 是：性能、可用性、伸缩性、扩展性、安全性。 而构建此类系统，最常见的 架构模式</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/zgynhqf/p/9853591.html</dc:identifier>
</item>
<item>
<title>Ubuntu18.04安装Python虚拟环境 - JacobHou</title>
<link>http://www.cnblogs.com/houzhiqing123/p/9853550.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/houzhiqing123/p/9853550.html</guid>
<description>&lt;p&gt;仅为使用Ubuntu18.04的Python开发人员作参考&lt;/p&gt;
&lt;h3&gt;1.安装Ubuntu18.04虚拟环境&lt;/h3&gt;
&lt;p&gt;sudo apt install virtualenv&lt;/p&gt;
&lt;p&gt;sudo apt install virtualenvwrapper&lt;/p&gt;
&lt;p&gt;安装完成之后，进入home目录，输入命令ls -al查看是否出现.virtualenvs目录，如果没有则手动创建.virtualenvs目录&lt;/p&gt;
&lt;h3&gt;2.安装Python环境中可以支持虚拟环境的模块(我这边使用的是Python3.6)&lt;/h3&gt;
&lt;p&gt;pip3 install virtualenv&lt;/p&gt;
&lt;p&gt;pip3 install virtualenvwrapper&lt;/p&gt;
&lt;h3&gt;3.配置虚拟管理目录&lt;/h3&gt;
&lt;p&gt;进入home目录，输入命令ls -al，找到.bashrc文件，修改.bashrc文件&lt;/p&gt;
&lt;p&gt;在.bashrc文件末尾添加两行：&lt;/p&gt;
&lt;p&gt;export WORKON_HOME=$HOME/.virtualenvs&lt;/p&gt;
&lt;p&gt;source /usr/share/virtualenvwrapper/virtualenvwrapper.sh&lt;/p&gt;
&lt;h3&gt;4.启用配置文件&lt;/h3&gt;
&lt;p&gt;source ~/.bashrc&lt;/p&gt;
&lt;h3&gt;5.检查是否可以创建虚拟环境&lt;/h3&gt;
&lt;p&gt;使用mkvirtualenv 项目名创建一个虚拟环境，如果成功则说明Ubuntu18.04虚拟环境创建成功&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;Python初学者，将学习路上遇到的一些经验分享给大家，欢迎大家积极评论并留言！&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 25 Oct 2018 15:09:00 +0000</pubDate>
<dc:creator>JacobHou</dc:creator>
<og:description>仅为使用Ubuntu18.04的Python开发人员作参考 1.安装Ubuntu18.04虚拟环境 sudo apt install virtualenv sudo apt install virtu</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/houzhiqing123/p/9853550.html</dc:identifier>
</item>
<item>
<title>小规模团队如何“微服务”管理 - wc的一些事一些情</title>
<link>http://www.cnblogs.com/wcd144140/p/9849367.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wcd144140/p/9849367.html</guid>
<description>&lt;p&gt;&lt;span&gt;“技术”和“管理”时常都会被个搁上台做对立面的比较，就好像做IT的就不需要学点社会学、经济学以及心理学什么的一样，这应该算是典型的钉子思维，结果也可能只有一个，那就是给自己添堵。仔细推敲一下，这都并非什么鱼和熊掌不可兼得的客观事物，本质就是“愿意”和“不愿意”而已。管理能力理应是每一个社会人必备的基本技能，自我管理的缺乏会造成管理者大量的精力浪费在这些“个人”身上，而不是把更多的管理精力投放在协同团队去拥抱市场、创新以及目标上。那么如何做好管理呢？当我面对这个问题时候，我会反问自己“我需要一个什么样的管理者？”。我可能需要他有高层次的大局思维为我们解点迷津，我还想他有资深的技能带我们过关斩将，我更愿意他有敏锐的市场触觉让我们走向未来的前沿……仅仅面对自身的回复足以让我默默地对自己说：好好学习吧。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/758472/201810/758472-20181025135101503-2037572740.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;1、精细化分工&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span&gt; 社会的进步和发展离不开“合作”，“自给自足”是远古的一种“局限”。就算你一个在家“直播”让自己财务自由了，但你终究离不开“平台”的协作。就算手机打着“苹果”商标，但它本质还是世界的共同出品。所以“分工”是一种进步和价值，这已经是一种共识，团队亦是如此。可能有些人会抱怨被大厂各种精细化的职能划分局限了自己的眼光，事实上，就算在小企业一样会存在各种各样分工，只不过在“小”的对立面让自己产生了“大”的错觉而已。万人军队需要分工，数人团队同样需要分工，《敢死队》说的就是这个道理。分工可以让我们专注自己所长，分工更能让“自动化”、“智能化”成为可能，例如“DevOps”。分工最让我深刻的一个觉悟是：“模糊边界的事物叫杂事，职责分明的事物叫专业”，就这一句话不知隐藏了多少成本和效能。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/758472/201810/758472-20181025135133109-918577411.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;2、全栈化能力&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span&gt; 钉子之所以为钉子，螺丝之所以为螺丝，本质就是自身视野的短缺。如果真正了解“分工”价值的人我想他不会抱怨各种“客观”的局限，这种抱怨恰恰就是自己主观的狭窄。有时候，我需要招聘一个前端开发，但我更愿意选择一个前端后端什么都能懂的开发。分工不等于“单栈”，反过来“全栈”不等于什么都要干，否则，这跟“自给自足”的落后思想没什么不同。“全栈”的言外之意就是综合能力，许多人把“综合”给量化了，有人把它量化为岗位范围，有人把它理解为企业范围，有人把它定义为领域范围，但也有许多人不为其设置范围。教科书并没有对其有明确的范围定义，所以，不要随意评价一个人的综合能力，因为那全都是自己“主观”的想法。但我可以明确且负责任地告诉伙伴们的是，“全栈”二字不断让我看到了自己的无知，让我产生压力，促使自己去学习，包括向你们学习。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/758472/201810/758472-20181025135205977-1310525119.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;3、个性化实践&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span&gt; “最大化发挥成员效能，集中化聚焦共同目标”是管理者的职责之一。分工需要放权，因为每一个成员都是各自领域的“专家”，事事亲力亲为是“中心化”的表现，局限了“分布式”的效能。每一个成员都可以专注于自己擅长的领域，并且谁都渴望能与更强的伙伴合作，但遇强的机遇背后需要自身的更加强大，分工领域之间强强联合形成一种正向的压力循环，效果必然1+1远远大于2。更重要的是，“个性化”是消除一切重复性工作的“利器”。因为人类极其厌恶那些限制个性化以及其价值发挥的重复性工作，这些可重复性且标准化的事情被自动化所取代是自然而然的结果，例如CICD。通过自动化手段控制“枯燥”，提高工作质量与效能的同时释放更多的时间和精力放飞自己的个性化想象与实践。无论对企业而言还是个人，这都是一种双赢的局面。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/758472/201810/758472-20181025135251766-661179309.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;4、共享化信息&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span&gt; “分工”并非只有好处没有坏处，最大的一个问题之一就是信息传播成本的巨大。根据自身的经验和统计发现，项目成本的80％体现在沟通上一点都不为过，其中信息不对称所产生的成本浪费约占沟通成本的50%以上，也就说，一个成本为100W的项目中可能隐藏着40W左右的利润增长空间。谁都渴望拥有一个默契的团队，谁都渴望跟一班志同道合的伙伴做一起想做的事情，谁都渴望大家在信息极度对等的状态下做事情。这些都是我曾经最理想化的想法，当我认清了这个理想化实时后，我知道我要做的不是被动地去“偶遇”这样一个团队，而是主动去“打造”这样一个团队。我可以通过“领取驱动设计”的理念去降低业务在项目过程流转所产生的折损，我同样可以通过“敏捷手段”减少不必要的错误理解，我还可以通过“规范化”过程让个职能之间无缝自动化对接，我甚至可以通过打造一个“微服务通用应用平台”让不同项目组共同聚焦在同一个平台上工作形成共享与贡献的正向发展大大减低不同项目组之间的“同一性”与“复用性”。手段永远不缺，缺的是主动思考的能力。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/758472/201810/758472-20181025135320067-806732972.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;5、统一化目标&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span&gt; 合作是一种社交行为，这里有一个非常重要的前提条件，就是成员之间又有一个共同的“目标”。所谓志同道合，“志”是首位，“道”即三观。和一个没有共同志向的人在一起，就算三观再合，还是无法共事，做个朋友可能倒是个不错的选择。管理者是一个凝聚团队的起点，思想和目标是根基。团队可以缺足，但不可缺脑。没有“灵魂”的团队如同行尸走肉，没有业务导向的系统架构形同摆设。成员离队，可以是志不同不相为谋，好聚好散。但成员迷失，可能存在目标模糊或目标失真的迹象。思想或目标并非一成不变，可随客观因素变化而变化。至于是否需要变化或者如何变化，这些都是对管理者最大的考验。有目标可能不会太难，但要有一个正确的目标却不会太容易。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/758472/201810/758472-20181025135349658-586109926.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;写在最后&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span&gt; 我对管理的理解，一切源自于“自我认知”。因为“自我深度学习”可以让自己了解到人性共性的一面，从而更好地自我管理以及让自己有更准确的维度去思考外界的事与物。团队可大或可小，事情可以不好做，或做不好。但根深蒂固的“个人理念”不可以轻易被动摇，因为它是指引自身行为的核心导向，包括团队目标的建立和思考。无论管理也好，还是被管也好，基本的自我管理意识不可或缺。&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Thu, 25 Oct 2018 14:48:00 +0000</pubDate>
<dc:creator>wc的一些事一些情</dc:creator>
<og:description>“技术”和“管理”时常都会被个搁上台做对立面的比较，就好像做IT的就不需要学点社会学、经济学以及心理学什么的一样，这应该算是典型的钉子思维，结果也可能只有一个，那就是给自己添堵。仔细推敲一下，这都并非</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/wcd144140/p/9849367.html</dc:identifier>
</item>
<item>
<title>java8 Stream使用案例 - jihite</title>
<link>http://www.cnblogs.com/kaituorensheng/p/9852462.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/kaituorensheng/p/9852462.html</guid>
<description>&lt;h3&gt;1. 原理&lt;/h3&gt;
&lt;p&gt;Stream 不是集合元素，它不是数据结构并不保存数据，它是有关算法和计算的，它更像一个高级版本的 Iterator。&lt;/p&gt;
&lt;p&gt;原始版本的 Iterator，用户只能显式地一个一个遍历元素并对其执行某些操作；&lt;/p&gt;
&lt;p&gt;高级版本的 Stream，用户只要给出需要对其包含的元素执行什么操作，比如:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;所有元素求和&lt;/li&gt;
&lt;li&gt;过滤掉长度大于 10 的字符串&lt;/li&gt;
&lt;li&gt;获取每个字符串的首字母&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Stream 就如同一个迭代器（Iterator），单向，不可往复，数据只能遍历一次，&lt;strong&gt;遍历过一次后即用尽了&lt;/strong&gt;，就好比流水从面前流过，一去不复返。&lt;/p&gt;
&lt;p&gt;而和迭代器又不同的是，Stream 可以&lt;strong&gt;并行化操作&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Stream 的另外一大特点是，数据源本身可以是&lt;strong&gt;无限的&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;2.使用步骤&lt;/h3&gt;
&lt;p&gt;获取一个数据源（source）→ 数据转换→执行操作获取想要的结果&lt;/p&gt;
&lt;p&gt;每次转换原有 Stream 对象不改变，返回一个新的 Stream对象（可以有多次转换），这就允许对其操作可以像链条一样排列，变成一个管道，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/408927/201810/408927-20181025184023503-1905393959.png&quot; alt=&quot;&quot; width=&quot;368&quot; height=&quot;321&quot;/&gt;&lt;/p&gt;
&lt;h3&gt;3. Stream的构造&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;45&quot;&gt;
&lt;pre&gt;
 &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; test4() {
        Stream stream &lt;/span&gt;= Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, 23&lt;span&gt;);
        stream.forEach(key &lt;/span&gt;-&amp;gt;&lt;span&gt; System.out.println(key));

        String[] array &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; String[]{&quot;abc&quot;, &quot;efg&quot;&lt;span&gt;};
        stream &lt;/span&gt;=&lt;span&gt; Stream.of(array);
        stream &lt;/span&gt;=&lt;span&gt; Arrays.stream(array);
        stream.forEach(key &lt;/span&gt;-&amp;gt;&lt;span&gt; System.out.println(key));

        List&lt;/span&gt;&amp;lt;String&amp;gt; list =&lt;span&gt; Arrays.asList(array);
        stream &lt;/span&gt;=&lt;span&gt; list.stream();

        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;IntStream、LongStream、DoubleStream&lt;/span&gt;
        IntStream stream2 = IntStream.of(1, 2, 3, 3&lt;span&gt;);
        DoubleStream stream4 &lt;/span&gt;= DoubleStream.of(1, 2, 3, 3.4&lt;span&gt;);

        stream2.forEach(key &lt;/span&gt;-&amp;gt;&lt;span&gt; System.out.println(key));
        stream4.forEach(key &lt;/span&gt;-&amp;gt;&lt;span&gt; System.out.println(key));
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:html;gutter:true;&quot;&gt;
a
b
c
23
abc
efg
1
2
3
3
1.0
2.0
3.0
3.4
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;4. Stream的转换&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; test6() {
        Stream stream &lt;/span&gt;= Stream.of(&quot;abc&quot;, &quot;def&quot;&lt;span&gt;);

        String[] array &lt;/span&gt;= (String[])stream.toArray(String[]::&lt;span&gt;new&lt;/span&gt;&lt;span&gt;);
        System.out.println(array.length);
        List&lt;/span&gt;&amp;lt;String&amp;gt; list = (List&amp;lt;String&amp;gt;)Stream.of(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;&lt;span&gt;).collect(Collectors.toList());
        String str &lt;/span&gt;= Stream.of(&quot;abc&quot;, &quot;mn&quot;&lt;span&gt;).collect(Collectors.joining()).toString();
        System.out.println(array);
        System.out.println(list);
        System.out.println(str);
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;34&quot;&gt;
&lt;pre class=&quot;brush:html;gutter:true;&quot;&gt;
2
[Ljava.lang.String;@17f052a3
[1, 2, 3]
abcmn
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;5.一个 Stream 只可以使用一次&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; test6_5() {
        Stream stream &lt;/span&gt;= Stream.of(1, 2, 3, 2&lt;span&gt;);
        System.out.println(&lt;/span&gt;&quot;count:&quot; +&lt;span&gt; stream.count());
        System.out.println(&lt;/span&gt;&quot;count:&quot; +&lt;span&gt; stream.count());
} &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;输出&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:html;gutter:true;&quot;&gt;
&lt;span&gt;Exception in thread &quot;main&quot; java.lang.IllegalStateException: stream has already been operated upon or closed
        at java.util.stream.AbstractPipeline.&amp;lt;init&amp;gt;(AbstractPipeline.java:203)
        at java.util.stream.LongPipeline.&amp;lt;init&amp;gt;(LongPipeline.java:91)
        at java.util.stream.LongPipeline$StatelessOp.&amp;lt;init&amp;gt;(LongPipeline.java:572)
        at java.util.stream.ReferencePipeline$5.&amp;lt;init&amp;gt;(ReferencePipeline.java:221)
        at java.util.stream.ReferencePipeline.mapToLong(ReferencePipeline.java:220)
        at java.util.stream.ReferencePipeline.count(ReferencePipeline.java:526)
        at streamTest.StreamTest.test6_5(StreamTest.java:68)
        at streamTest.StreamTest.main(StreamTest.java:181)&lt;/span&gt;
count:4
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;6.转换大写&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; test7() {
        List&lt;/span&gt;&amp;lt;String&amp;gt; list = Arrays.asList(&quot;a&quot;, &quot;MnM&quot;&lt;span&gt;);

        List&lt;/span&gt;&amp;lt;String&amp;gt; result =&lt;span&gt; list.stream().
                map(String::toUpperCase).
                collect(Collectors.toList());
        System.out.println(list);
        System.out.println(result);
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;输出&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot;&gt;
&lt;pre class=&quot;brush:html;gutter:true;&quot;&gt;
[a, MnM]
[A, MNM]
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;7.平方&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; test8() {
        List&lt;/span&gt;&amp;lt;Integer&amp;gt; list2 = Arrays.asList(1, 2, 4&lt;span&gt;);
        List&lt;/span&gt;&amp;lt;Integer&amp;gt; list3 =&lt;span&gt; list2.stream().
                map(key &lt;/span&gt;-&amp;gt; key *&lt;span&gt; key).
                collect(Collectors.toList());
        System.out.println(list2);
        System.out.println(list3);

    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;输出&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot;&gt;
&lt;pre class=&quot;brush:html;gutter:true;&quot;&gt;
[1, 2, 4]
[1, 4, 16]
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;8.找偶数&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; test8_5() {
        List&lt;/span&gt;&amp;lt;Integer&amp;gt; list2 = Arrays.asList(1, 2, 4&lt;span&gt;);
        List&lt;/span&gt;&amp;lt;Integer&amp;gt; list3 =&lt;span&gt; list2.stream().
                filter(key &lt;/span&gt;-&amp;gt; key % 2 == 0&lt;span&gt;).
                collect(Collectors.toList());
        System.out.println(list2);
        System.out.println(list3);
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;输出&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot;&gt;
&lt;pre class=&quot;brush:html;gutter:true;&quot;&gt;
[1, 2, 4]
[2, 4]
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;9. 区间值&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
 &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; test5() {&lt;/span&gt;&lt;span&gt;
        System.out.println(&lt;/span&gt;&quot;\n&quot;&lt;span&gt;);
        IntStream.range(&lt;/span&gt;1, 3&lt;span&gt;).forEach(System.out::println);
        System.out.println(&lt;/span&gt;&quot;\n&quot;&lt;span&gt;);
        IntStream.rangeClosed(&lt;/span&gt;1, 3&lt;span&gt;).forEach(System.out::println);
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;结果&lt;/p&gt;

&lt;h3&gt;10.并发&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
 &lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; test5_pa() {
        IntStream.rangeClosed(&lt;/span&gt;1, 10&lt;span&gt;).parallel().forEach(System.out::println);
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;输出&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:html;gutter:true;&quot;&gt;
3
7
1
5
2
8
10
6
9
4　　
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/puyangsky/p/7608741.html&quot; target=&quot;_blank&quot;&gt;是否并发思考&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;11. 新的Stream继续操作&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; test6_6() {
        Stream.of(&lt;/span&gt;&quot;one&quot;, &quot;two&quot;, &quot;three&quot;, &quot;four&quot;&lt;span&gt;)
                .filter(e &lt;/span&gt;-&amp;gt; e.length() &amp;gt; 3&lt;span&gt;)
                .peek(e &lt;/span&gt;-&amp;gt; System.out.println(&quot;Filtered value: &quot; +&lt;span&gt; e))
                .map(String::toUpperCase)
                .peek(e &lt;/span&gt;-&amp;gt; System.out.println(&quot;Mapped value: &quot; +&lt;span&gt; e))
                .collect(Collectors.toList());
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:html;gutter:true;&quot;&gt;
Filtered value: three
Mapped value: THREE
Filtered value: four
Mapped value: FOUR
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;12. Optional&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; print(String text) {
        System.out.println(&lt;/span&gt;&quot;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&quot;&lt;span&gt;);
        System.out.println(Optional.ofNullable(text));
        List&lt;/span&gt;&amp;lt;String&amp;gt; obj = &lt;span&gt;new&lt;/span&gt; ArrayList&amp;lt;&amp;gt;&lt;span&gt;();
        Optional.ofNullable(text).ifPresent(System.out::println);
        System.out.println(&lt;/span&gt;&quot;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;\n&quot;&lt;span&gt;);
    }
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;int&lt;/span&gt;&lt;span&gt; getLength(String text) {
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; Optional.ofNullable(text).map(String::length).orElse(-1&lt;span&gt;);
    }

    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; test14() {
        String strA &lt;/span&gt;= &quot; abcd &quot;, strB = &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
        print(strA);
        print(&lt;/span&gt;&quot;&quot;&lt;span&gt;);
        print(strB);

        System.out.println(getLength(strA));
        System.out.println(getLength(&lt;/span&gt;&quot;&quot;&lt;span&gt;));
        System.out.println(getLength(strB));
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:html;gutter:true;&quot;&gt;
&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;
Optional[ abcd ]
 abcd 
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;

&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;
Optional[]

&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;

&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;
Optional.empty
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;

6
0
-1
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;13. 字符串拼接、最值、求和、过滤&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;55&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; test15() {
        String concat &lt;/span&gt;= Stream.of(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;).reduce(&quot;&quot;&lt;span&gt;, String::concat);
        System.out.println(&lt;/span&gt;&quot;concat:&quot; +&lt;span&gt; concat);

        &lt;/span&gt;&lt;span&gt;double&lt;/span&gt; minValue = Stream.of(-1.5, 1.0, -3.0, -2.0&lt;span&gt;).reduce(Double.MAX_VALUE, Double::min);
        System.out.println(&lt;/span&gt;&quot;min:&quot; +&lt;span&gt; minValue);

        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; sumValue = Stream.of(1, 2, 3, 4).reduce(0&lt;span&gt;, Integer::sum);
        System.out.println(&lt;/span&gt;&quot;sum1:&quot; +&lt;span&gt; sumValue);

        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; sumValue2 = Stream.of(1, 2, 3, 4&lt;span&gt;).reduce(Integer::sum).get();
        System.out.println(&lt;/span&gt;&quot;sum2:&quot; +&lt;span&gt; sumValue2);

        concat &lt;/span&gt;= Stream.of(&quot;a&quot;, &quot;B&quot;, &quot;c&quot;, &quot;D&quot;, &quot;e&quot;, &quot;F&quot;).filter(x -&amp;gt; x.compareTo(&quot;Z&quot;) &amp;gt; 0).reduce(&quot;&quot;&lt;span&gt;, String::concat);
        System.out.println(&lt;/span&gt;&quot;concat:&quot; +&lt;span&gt; concat);
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;结果&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:html;gutter:true;&quot;&gt;
concat:ABC
min:-3.0
sum1:10
sum2:10
concat:ace
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;14. limit, skip&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; test16() {
        List&lt;/span&gt;&amp;lt;Person&amp;gt; persons = &lt;span&gt;new&lt;/span&gt; ArrayList&amp;lt;&amp;gt;&lt;span&gt;();
        IntStream.range(&lt;/span&gt;1, 1000).forEach(key-&amp;gt;persons.add(&lt;span&gt;new&lt;/span&gt; Person(key, &quot;jihite:&quot; +&lt;span&gt; key)));
        List&lt;/span&gt;&amp;lt;String&amp;gt; personList = persons.stream().map(Person::getName).limit(10).skip(3&lt;span&gt;).collect(Collectors.toList());
        System.out.println(personList);
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;输出&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;38&quot;&gt;
&lt;pre class=&quot;brush:html;gutter:true;&quot;&gt;
[jihite:4, jihite:5, jihite:6, jihite:7, jihite:8, jihite:9, jihite:10]
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;15.找出最长一行的长度&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; test19() &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; IOException {
        String path &lt;/span&gt;= &quot;**/Person.java&quot;&lt;span&gt;;
        BufferedReader br &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; BufferedReader(&lt;span&gt;new&lt;/span&gt;&lt;span&gt; FileReader(path));
        &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; longest =&lt;span&gt; br.lines()
                .mapToInt(String::length)
                .max()
                .getAsInt();
        br.close();
        System.out.println(longest);
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;输出&lt;/p&gt;

&lt;h3&gt;16.找出全文的单词，转小写，并排序&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; test20() &lt;span&gt;throws&lt;/span&gt;&lt;span&gt; IOException {
        String path &lt;/span&gt;= &quot;**/Person.java&quot;&lt;span&gt;;
        BufferedReader br &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; BufferedReader(&lt;span&gt;new&lt;/span&gt;&lt;span&gt; FileReader(path));
        List&lt;/span&gt;&amp;lt;String&amp;gt; words =&lt;span&gt; br.lines()
                .flatMap(line&lt;/span&gt;-&amp;gt;Stream.of(line.split(&quot; &quot;&lt;span&gt;)))
                .filter(word&lt;/span&gt;-&amp;gt;word.length()&amp;gt;0&lt;span&gt;)
                .map(String::toLowerCase)
                .distinct()
                .sorted()
                .collect(Collectors.toList());
        br.close();
        System.out.println(words);
        words.forEach(key&lt;/span&gt;-&amp;gt;&lt;span&gt; System.out.println(key));
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;输出&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;32&quot;&gt;
&lt;pre class=&quot;brush:html;gutter:true;&quot;&gt;
*
*/
/**
//
2018/10/24
21:40
=
@author:
@date:
@description:
class
getname()
int
name)
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;参考&lt;/h3&gt;
&lt;p id=&quot;ibm-pagetitle-h1&quot; class=&quot;ibm-h1&quot;&gt;&lt;a href=&quot;https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/&quot; target=&quot;_blank&quot;&gt;Java 8 中的 Streams API 详解&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Thu, 25 Oct 2018 14:26:00 +0000</pubDate>
<dc:creator>jihite</dc:creator>
<og:description>1. 原理 Stream 不是集合元素，它不是数据结构并不保存数据，它是有关算法和计算的，它更像一个高级版本的 Iterator。 原始版本的 Iterator，用户只能显式地一个一个遍历元素并对其执</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/kaituorensheng/p/9852462.html</dc:identifier>
</item>
<item>
<title>WCF入门三[WCF宿主] - 今天也要元气满满的哦</title>
<link>http://www.cnblogs.com/xwc1996/p/9833242.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xwc1996/p/9833242.html</guid>
<description>&lt;p&gt;&lt;strong&gt;一、概述&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　&lt;/strong&gt;WCF程序必须在宿主上运行，也就是WCF服务必须寄宿在某一个windows的进程中，可以是IIS、控制台程序、窗体程序、WAS以及所有.net程序等程序进程中。在我用VS2013创建WCF服务的时候有四个类型：WCF服务库、WCF服务应用程序、WCF工作流服务应用程序和联合服务库。现在处于初学阶段，主要学习用到的是WCF服务库和WCF服务应用程序，它们有什么区别呢？&lt;/p&gt;
&lt;p&gt;　　1.WCF服务库：相当于一个包含WCF服务的类库，本身不能执行，必须通过别的宿主程序(如控制台程序、WAS等)托管引用后才可以使用，可以提高代码的复用性。&lt;/p&gt;
&lt;p&gt;　　2.WCF服务应用程序：相比之下可以独立运行，基于IIS托管的程序。在开发基于IIS的WCF服务时比较多见，自学的时候也多用这个，在&lt;a href=&quot;https://www.cnblogs.com/xwc1996/p/9813728.html&quot; target=&quot;_blank&quot;&gt;WCF入门一[WCF概述]&lt;/a&gt;中就使用过。&lt;/p&gt;
&lt;p&gt;　　IIS的宿主实现在之前讲过，所以不再复述。这里我们先创建一个WCF服务库WcfServiceLibrary，将默认的文件IService1.cs和Service.cs删除，新建一个WCF服务Day.cs会生成Day,cs和IDay.cs两个文件，接口和实现如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;namespace&lt;/span&gt;&lt;span&gt; WcfServiceLibrary
{
    [ServiceContract]
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;interface&lt;/span&gt;&lt;span&gt; IDay
    {
        [OperationContract]
        &lt;/span&gt;&lt;span&gt;string&lt;/span&gt; ShowDay(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; day);
    }
}

&lt;/span&gt;&lt;span&gt;namespace&lt;/span&gt;&lt;span&gt; WcfServiceLibrary
{
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Day : IDay
    {
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;string&lt;/span&gt; ShowDay(&lt;span&gt;int&lt;/span&gt;&lt;span&gt; day)
        {
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;string&lt;/span&gt;.Format(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;WCF服务返回Day是：{0}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, day);
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　这里我们在新建WCF服务Day.cs的时候VS自动给在配置文件中加上了该服务的信息，也就是终结点的信息。这里和寄宿在IIS中由IIS监听不同，如果没有添加的话需要手动添加在配置文件中或者在程序代码中写终结点的相关配置细信息Behaviors、Address等，不过正常情况下都是依赖配置文件的。&lt;/p&gt;
&lt;p&gt;　　由于控制台程序、窗体程序、windows服务和.net程序等作为宿主都是一样的，可以通过读取配置文件或者代码配置终结点等服务信息来实现。以下主要用控制台程序通过这两点实现WCF宿主。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二、代码配置终结点信息&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　&lt;/strong&gt;　1.在解决方案下新建一个控制台程序ConsoleApplication。&lt;/p&gt;
&lt;p&gt;　　2.添加引用-&amp;gt;解决方案-&amp;gt;WcfServiceLibrary.dll。&lt;/p&gt;
&lt;p&gt;　　3.添加引用-&amp;gt;程序集-&amp;gt;System.ServiceModel。&lt;/p&gt;
&lt;p&gt;　　4.添加代码如下，具体请查看&lt;a href=&quot;http://msdn.microsoft.com/en-us/library/system.servicemodel.servicehost.aspx&quot; target=&quot;_blank&quot;&gt;&quot;MSDN ServiceHost&quot;&lt;/a&gt;：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;namespace&lt;/span&gt;&lt;span&gt; ConsoleApplication
{
    &lt;/span&gt;&lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
    {
        &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
        {
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;创建宿主的基地址&lt;/span&gt;
            Uri baseAddress = &lt;span&gt;new&lt;/span&gt; Uri(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http://192.168.3.30:8080/Day&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;创建宿主&lt;/span&gt;
            &lt;span&gt;using&lt;/span&gt; (ServiceHost host = &lt;span&gt;new&lt;/span&gt; ServiceHost(&lt;span&gt;typeof&lt;/span&gt;&lt;span&gt;(Day), baseAddress))
            {
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;向宿主中添加终结点&lt;/span&gt;
                host.AddServiceEndpoint(&lt;span&gt;typeof&lt;/span&gt;(IDay), &lt;span&gt;new&lt;/span&gt; WSHttpBinding(), &lt;span&gt;&quot;&quot;&lt;/span&gt;&lt;span&gt;);
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;将HttpGetEnabled属性设置为true&lt;/span&gt;
                ServiceMetadataBehavior smb = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ServiceMetadataBehavior();
                smb.HttpGetEnabled &lt;/span&gt;= &lt;span&gt;true&lt;/span&gt;&lt;span&gt;;
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;将行为添加到Behaviors中&lt;/span&gt;
&lt;span&gt;                host.Description.Behaviors.Add(smb);
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;打开宿主服务&lt;/span&gt;
&lt;span&gt;                host.Open();
                Console.WriteLine(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;WCF中的HTTP监听已启动....&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
                Console.ReadLine();
                host.Close();
            }
        }
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　6.启动控制台程序，如果启动不了的话，用管理员身份运行exe，启动WCF服务。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/988132/201810/988132-20181024220309796-511076521.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　7.新建一个控制台解决方案，并添加地址为http://192.168.3.30:8080/Day的服务引用。之后正常调用服务如下所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/988132/201810/988132-20181024220715769-1743838792.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三、读取配置文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　&lt;/strong&gt;1、2、3三个步骤同上，更改代码如下，这里是直接读取配置文件中的ServiceHost：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
    &lt;span&gt;class&lt;/span&gt;&lt;span&gt; Program
    {
        &lt;/span&gt;&lt;span&gt;static&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; Main(&lt;span&gt;string&lt;/span&gt;&lt;span&gt;[] args)
        {
            ServiceHost host &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; ServiceHost(&lt;span&gt;typeof&lt;/span&gt;&lt;span&gt;(Day));
            &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;打开宿主&lt;/span&gt;
&lt;span&gt;            host.Open();
            Console.Write(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;WCF中的HTTP监听已启动....&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
            Console.ReadKey();
            host.Close();
        }
    }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　在控制台应用程序的配置文件App.Config修改如下，这里的配置项必须要对否则启动会报错。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&amp;lt;?xml version=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;1.0&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; encoding=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;utf-8&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; ?&amp;gt;
&amp;lt;configuration&amp;gt;
    &amp;lt;startup&amp;gt; 
        &amp;lt;supportedRuntime version=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;v4.0&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; sku=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;.NETFramework,Version=v4.5&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; /&amp;gt;
    &amp;lt;/startup&amp;gt;
    &amp;lt;system.serviceModel&amp;gt;
      &amp;lt;services&amp;gt;
        &amp;lt;service name=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;WcfServiceLibrary.Day&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&amp;gt;
          &amp;lt;endpoint address=&lt;span&gt;&quot;&quot;&lt;/span&gt; binding=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;wsHttpBinding&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; contract=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;WcfServiceLibrary.IDay&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; /&amp;gt;
          &amp;lt;host&amp;gt;
            &amp;lt;baseAddresses&amp;gt;
              &amp;lt;add baseAddress=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http://192.168.3.30:8080/Day&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; /&amp;gt;
            &amp;lt;/baseAddresses&amp;gt;
          &amp;lt;/host&amp;gt;
        &amp;lt;/service&amp;gt;
      &amp;lt;/services&amp;gt;
      &amp;lt;behaviors&amp;gt;
        &amp;lt;serviceBehaviors&amp;gt;
          &amp;lt;behavior&amp;gt;
            &amp;lt;serviceMetadata httpGetEnabled=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;True&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;/&amp;gt;
            &amp;lt;serviceDebug includeExceptionDetailInFaults=&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;False&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;/&amp;gt;
          &amp;lt;/behavior&amp;gt;
        &amp;lt;/serviceBehaviors&amp;gt;
      &amp;lt;/behaviors&amp;gt;
    &amp;lt;/system.serviceModel&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　重复同上使用WCF服务。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;四、总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　&lt;/strong&gt;实现控制台宿主、winform宿主和windows服务宿主的代码就是以上两种方式，虽然宿主不同但是方法其实是相同的，可以根据以上的控制台宿主的实现来实现其他同类型的宿主，但是相比之下用IIS服务作为宿主还是最为主要的手段，更加的方便快捷。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;五、说明&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　&lt;/strong&gt;这个随笔是我自己学习流程的一个记录，和大家共勉。&lt;/p&gt;
</description>
<pubDate>Thu, 25 Oct 2018 14:25:00 +0000</pubDate>
<dc:creator>今天也要元气满满的哦</dc:creator>
<og:description>一、概述 WCF程序必须在宿主上运行，也就是WCF服务必须寄宿在某一个windows的进程中，可以是IIS、控制台程序、窗体程序、WAS以及所有.net程序等程序进程中。在我用VS2013创建WCF服</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/xwc1996/p/9833242.html</dc:identifier>
</item>
<item>
<title>[原创]K8 CMS GoastGuard 密码解密工具 - K8哥哥's_Blog</title>
<link>http://www.cnblogs.com/k8gege/p/9853319.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/k8gege/p/9853319.html</guid>
<description>&lt;p&gt;工具: K8 CMS GoastGuard PASS Decrypt&lt;br/&gt;编译: VS2012  C# (.NET Framework v4.5)&lt;br/&gt;组织: K8搞基大队[K8team]&lt;br/&gt;作者: K8拉登哥哥&lt;br/&gt;博客: &lt;a href=&quot;http://qqhack8.blog.163.com/&quot; target=&quot;_blank&quot;&gt;http://qqhack8.blog.163.com&lt;/a&gt;&lt;br/&gt;发布: 2017/11/24 15:36:46&lt;/p&gt;&lt;p&gt;简介: &lt;br/&gt;K8 CMS GoastGuard PASS Decrypt 由于iii为.net 4.5.2版本&lt;br/&gt;III其它版本不知是否一致 运行此工具也需要4.5.2版本&lt;br/&gt;win10或2012可直接运行&lt;/p&gt;&lt;p&gt;图片:&lt;/p&gt;
&lt;div&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1463611/201810/1463611-20181025222329357-1436016612.png&quot; alt=&quot;&quot;/&gt;&lt;/div&gt;
&lt;p&gt;功能: &lt;/p&gt;&lt;p&gt;&lt;span&gt;下载地址:&lt;/span&gt;&lt;br/&gt;文件: K8GoastGuardDecrypt.exe&lt;br/&gt;SHA1: B128949ABB0AFF73DED29C573D338D3B35F815F4&lt;br/&gt;平台: XP/Vista/Win7/Win8/2000/2003/2008/2012&lt;br/&gt;猛击: https://pan.baidu.com/s/1qnZFXbyS2OXxNlcU4UVf9g&lt;/p&gt;&lt;p&gt;提示:&lt;br/&gt;下载后一定要校验文件的SHA1值是否正确,如不符则可能文件损坏或被人捆木马.&lt;br/&gt;注意:&lt;br/&gt;在K8拉登哥哥BLOG里下载的,工具一但更新,旧版地址若是失效,将不再提供下载.&lt;/p&gt;
&lt;p&gt;本博客里任何文章/动画/教程以及各类软件/工具等仅供个人测试研究，&lt;br/&gt;请在下载后24小时内删除，不得用于商业或非法用途，否则后果自负。&lt;/p&gt;
</description>
<pubDate>Thu, 25 Oct 2018 14:16:00 +0000</pubDate>
<dc:creator>K8哥哥&amp;#39;s_Blog</dc:creator>
<og:description>工具: K8 CMS GoastGuard PASS Decrypt编译: VS2012 C# (.NET Framework v4.5)组织: K8</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/k8gege/p/9853319.html</dc:identifier>
</item>
</channel>
</rss>