<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>CSS魔法堂：那个被我们忽略的outline - ^_^肥仔John</title>
<link>http://www.cnblogs.com/fsjohnhuang/p/9753554.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/fsjohnhuang/p/9753554.html</guid>
<description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt; 在&lt;a href=&quot;https://www.cnblogs.com/fsjohnhuang/p/9741345.html&quot;&gt;CSS魔法堂：改变单选框颜色就这么吹毛求疵！&lt;/a&gt;中我们要模拟原生单选框通过&lt;code&gt;Tab&lt;/code&gt;键获得焦点的效果，这里涉及到一个常常被忽略的属性——&lt;code&gt;outline&lt;/code&gt;，由于之前对其印象确实有些模糊，于是本文打算对其进行稍微深入的研究^_^&lt;/p&gt;
&lt;h2 id=&quot;spec是这样描述它的&quot;&gt;Spec是这样描述它的&lt;/h2&gt;
&lt;h3 id=&quot;作用&quot;&gt;作用&lt;/h3&gt;
&lt;p&gt; 用于创建可视对象的轮廓(元素的border-box)，如表单按钮轮廓等。&lt;/p&gt;
&lt;h3 id=&quot;与border不同&quot;&gt;与border不同&lt;/h3&gt;
&lt;ol readability=&quot;-2&quot;&gt;&lt;li&gt;outline不占文档空间；&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;outline不一定是矩形。&lt;/p&gt;
&lt;h3 id=&quot;具体属性说明&quot;&gt;具体属性说明&lt;/h3&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;pre&gt;
&lt;code&gt;/* 轮廓线颜色 
 * invert表示为颜色反转，即使轮廓在不同的背景颜色中都可见 
 */
outline-color: invert | &amp;lt;color_name&amp;gt; | &amp;lt;hex_number&amp;gt; | &amp;lt;rgb_number&amp;gt; | inherit
/* 轮廓线样式 */
outline-style: none | dotted | dashed | solid | double | groove | ridge | inset | outset | inherit
/* 轮廓线宽度 */
outline-width: medium | thin | thick | &amp;lt;length&amp;gt; | inherit
/* 一次性设置轮廓线的颜色、样式 和 宽度 */
outline: &amp;lt;outline-color&amp;gt; &amp;lt;outline-style&amp;gt; &amp;lt;outline-width&amp;gt;;
/* 轮廓线的偏移量，大于0则轮廓扩大，小于0则轮廓缩小 */
outline-offset: 0px;&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;魔鬼在细节&quot;&gt;魔鬼在细节&lt;/h2&gt;
&lt;h3 id=&quot;兼容性&quot;&gt;兼容性&lt;/h3&gt;
&lt;p&gt; &lt;code&gt;outline&lt;/code&gt;作为CSS2.1规范，因此IE6/7/8(Q)均不支持，在IE8下写入正确的DOCTYPE则支持outline属性。&lt;br/&gt; &lt;code&gt;outline-offset&lt;/code&gt;则IE下均不支持。&lt;/p&gt;
&lt;h3 id=&quot;ie678q下隐藏outline&quot;&gt;IE6/7/8(Q)下隐藏outline&lt;/h3&gt;
&lt;p&gt;若要在IE6/7/8(Q)下隐藏outline效果，则在元素上添加&lt;code&gt;hideFocus&lt;/code&gt;特性即可。&lt;/p&gt;
&lt;h3 id=&quot;outline0和outlinenone的区别&quot;&gt;&lt;code&gt;outline:0&lt;/code&gt;和&lt;code&gt;outline:none&lt;/code&gt;的区别&lt;/h3&gt;
&lt;p&gt;在Chrome下执行如下代码&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;style type=&quot;text/css&quot;&amp;gt;
 .outline0{
   outline: 0;
 }
 .outline-none{
   outline: none;
 }
&amp;lt;/style&amp;gt;
&amp;lt;a href=&quot;#&quot; class=&quot;outline0&quot;&amp;gt;outline: 0&amp;lt;/a&amp;gt;
&amp;lt;a href=&quot;#&quot; class=&quot;outline-none&quot;&amp;gt;outline: none&amp;lt;/a&amp;gt;
&amp;lt;script type=&quot;text/javascript&quot;&amp;gt;
  const $ = document.querySelector.bind(document)
  const print = console.log.bind(console)
  const cssProps = [&quot;outline-width&quot;, &quot;outline-style&quot;, &quot;outline-color&quot;]
  const slctrs = [&quot;.outline0&quot;, &quot;.outline-none&quot;]
     
  slctrs.forEach(slctr =&amp;gt; {
    styles = window.getComputedStyle($(slctr))
      cssProps.forEach(cssProp =&amp;gt; {
        print(&quot;%s, %s is %s&quot;, slctr, cssProp, styles[cssProp])
      })
    })
&amp;lt;/script&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;结果：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;.outline0, outline-width is 0px
.outline0, outline-style is none
.outline0, outline-color is rgb(0, 0, 238)
.outline-none, outline-width is 0px
.outline-none, outline-style is none
.outline-none, outline-color is rgb(0, 0, 238)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt; &lt;code&gt;outline&lt;/code&gt;仅仅为设置单个或多个具体的&lt;code&gt;outline&lt;/code&gt;属性提供更便捷的API而已，因此&lt;code&gt;outline:0&lt;/code&gt;和&lt;code&gt;outline:none&lt;/code&gt;本质上效果是一致的。&lt;/p&gt;
&lt;h3 id=&quot;真心没法弄出圆角&quot;&gt;真心没法弄出圆角&lt;/h3&gt;
&lt;p&gt; 自从有了&lt;code&gt;border-radius&lt;/code&gt;后，我们就可以通过CSS制作圆角矩形、圆形等图形，甚至连&lt;code&gt;box-shadow&lt;/code&gt;也受到&lt;code&gt;border-radius&lt;/code&gt;影响从而实现元素阴影也能做到圆角的效果。那么&lt;code&gt;outline&lt;/code&gt;是否也能做出圆角的效果呢？答案是否定的。那是因为&lt;code&gt;outline&lt;/code&gt;的作用本来就是用于勾勒出元素所占的空间轮廓，通过&lt;code&gt;border-radius&lt;/code&gt;虽然实现了图形视觉上的圆角，但该元素所占位置空间一点都没有变化，还是那个有棱有角的方形。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;style type=&quot;text/css&quot;&amp;gt;
  .round{
    width: 100px;
    height: 100px;
    background: yellow;
    border-radius: 50%;
    outline: solid 1px red;
  }
&amp;lt;/style&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/347002/201810/347002-20181008115255968-914189070.png&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;轮廓的差异&quot;&gt;轮廓的差异&lt;/h3&gt;
&lt;p&gt; 在Chrome下&lt;code&gt;outline&lt;/code&gt;仅限于标识当前元素自身所占的位置空间（border-box），但在FireFox下则包含子孙元素所占的位置空间。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;style type=&quot;text/css&quot;&amp;gt;
  .outline{
    width: 13px;
    height: 13px;
    outline: 1px solid red;
  }
&amp;lt;/style&amp;gt;
&amp;lt;div class=&quot;outline&quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;script type=&quot;text/javascript&quot;&amp;gt;
  const el = document.querySelector(&quot;.outline&quot;)
  el.textContent = !!~navigator.appVersion.indexOf(&quot;Chrome&quot;) ? &quot;Chrome&quot; : &quot;FireFox&quot;
&amp;lt;/script&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/347002/201810/347002-20181008115247489-477407843.png&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt; 尊重原创，转载请注明来自：&lt;a href=&quot;https://www.cnblogs.com/fsjohnhuang/p/9753554.html&quot; class=&quot;uri&quot;&gt;https://www.cnblogs.com/fsjohnhuang/p/9753554.html&lt;/a&gt; ^_^肥仔John&lt;/p&gt;
&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.xuebuyuan.com/757567.html&quot; class=&quot;uri&quot;&gt;https://www.xuebuyuan.com/757567.html&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.zhangxinxu.com/wordpress/2010/01/%E9%A1%B5%E9%9D%A2%E5%8F%AF%E7%94%A8%E6%80%A7%E4%B9%8Boutline%E8%BD%AE%E5%BB%93%E5%A4%96%E6%A1%86%E7%9A%84%E4%B8%80%E4%BA%9B%E7%A0%94%E7%A9%B6/&quot;&gt;https://www.zhangxinxu.com/wordpress/2010/01/%E9%A1%B5%E9%9D%A2%E5%8F%AF%E7%94%A8%E6%80%A7%E4%B9%8Boutline%E8%BD%AE%E5%BB%93%E5%A4%96%E6%A1%86%E7%9A%84%E4%B8%80%E4%BA%9B%E7%A0%94%E7%A9%B6/&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 08 Oct 2018 22:20:00 +0000</pubDate>
<dc:creator>^_^肥仔John</dc:creator>
<og:description>前言  在</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/fsjohnhuang/p/9753554.html</dc:identifier>
</item>
<item>
<title>机器学习100天——实现简单线性回归(第二天) - summer哥</title>
<link>http://www.cnblogs.com/airnew/p/9758241.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/airnew/p/9758241.html</guid>
<description>&lt;hr/&gt;&lt;p&gt;layout: article&lt;br/&gt;title: 机器学习100天——实现简单线性回归(第二天)&lt;br/&gt;mathjax: true&lt;br/&gt;---&lt;/p&gt;
&lt;p&gt;线性回归算法的作用是使用单一特征来预测响应值。是一种根据自变量X预测因变量Y的方法。假设两个变量是线性相关的，那么我们要找到一个线性函数，根据特征或自变量X来精确预测响应值Y。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如何找到最佳拟合线&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在这个回归模型中，我们尝试通过寻找最佳拟合线来最小化预测的误差——根据线性回归预测的结果误差最小。我们尝试最小化观察值和预测值之间的长度，长度越小，误差就越小，反之亦然。&lt;/p&gt;
&lt;p&gt;我们将使用一个根据学生花费在学习上的小时数预测他们分数的百分比的例子学习如何使用线性回归模型。请看下图：&lt;br/&gt;&lt;img src=&quot;http://www.bigdata17.com/assets/images/linerregression.png&quot; title=&quot;线性回归&quot; alt=&quot;线性回归&quot;/&gt;&lt;br/&gt;线性回归模型为：&lt;br/&gt;$ y = b_0 + b_1x_1$&lt;br/&gt;将上图中的自变量和因变量代入到上面的模型中，则变为：&lt;br/&gt;$ Score = b_0 + b_1 * hours $&lt;/p&gt;
&lt;p&gt;线性回归其实就是解一元一次方程，求出截距和斜率。&lt;/p&gt;
&lt;p&gt;下面介绍使用Python实现线性回归算法的步骤。&lt;br/&gt;步骤1：数据预处理&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;导入相关库&lt;/li&gt;
&lt;li&gt;导入数据集&lt;/li&gt;
&lt;li&gt;检查缺失数据&lt;/li&gt;
&lt;li&gt;划分数据集&lt;/li&gt;
&lt;li&gt;使用简单线性回归模型进行特征缩放&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;步骤2：通过训练集来训练简单线性回归模型&lt;br/&gt;为了使用模型来训练数据集，我们将使用来自sklern.liner_model库的LinearRegression类，然后创建一个LinearRegression类对象regressor，最后使用该对象的fit()方法对数据集进行训练。&lt;/p&gt;
&lt;p&gt;步骤3：预测结果&lt;br/&gt;现在我们将预测来自训练集的观察结果。我们将把输出保存在向量Y_pred中。我们使用前一步中训练的回归模型regressor的LinearGression类的预测方法来对结果进行预测。&lt;/p&gt;
&lt;p&gt;步骤4：预测结果可视化&lt;br/&gt;使用matplotlib.pyplot库对我们的训练结果和测试结果做散点图，以查看我们的模型预测效果。&lt;/p&gt;
&lt;p&gt;具体实现代码如下：&lt;br/&gt;第一步：数据预处理&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;import pandas as pd  
import numpy as np  
import matplotlib.pyplot as plt  

dataset = pd.read_csv('studentscores.csv')  
X = dataset.iloc[ : ,   : 1 ].values  
Y = dataset.iloc[ : , 1 ].values  

from sklearn.model_selection import train_test_split  
X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size = 1/4, random_state = 0)  &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;第二步：通过训练集来训练简单线性回归模型&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;from sklearn.linear_model import LinearRegression  
regressor = LinearRegression()  
regressor = regressor.fit(X_train, Y_train)  &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;第三步：预测结果&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;Y_pred = regressor.predict(X_test)  &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;第四步：可视化&lt;br/&gt;训练结果可视化：&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;plt.scatter(X_train , Y_train, color = 'red')  
plt.plot(X_train , regressor.predict(X_train), color ='blue')  
plt.show()  &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试结果可视化：&lt;/p&gt;
&lt;pre class=&quot;python&quot;&gt;
&lt;code&gt;plt.scatter(X_test , Y_test, color = 'red')  
plt.plot(X_test , regressor.predict(X_test), color ='blue')  
plt.show()  &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试数据请加本人的微信公众号获取。&lt;/p&gt;
</description>
<pubDate>Mon, 08 Oct 2018 22:11:00 +0000</pubDate>
<dc:creator>summer哥</dc:creator>
<og:description>layout: article title: 机器学习100天——实现简单线性回归(第二天) mathjax: true 线性回归算法的作用是使用单一特征来预测响应值。是一种根据自变量X预测因变量Y的</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/airnew/p/9758241.html</dc:identifier>
</item>
<item>
<title>必须掌握的MySQL优化指南 - JaJian</title>
<link>http://www.cnblogs.com/jajian/p/9758192.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/jajian/p/9758192.html</guid>
<description>&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;当 MySQL 单表记录数过大时，增删改查性能都会急剧下降，本文会提供一些优化参考，大家可以参考以下步骤来优化。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201810/1162587-20181009015629000-3126157.png&quot;/&gt;&lt;/p&gt;

&lt;p&gt;除非单表数据未来会一直不断上涨，否则不要一开始就考虑拆分，拆分会带来逻辑、部署、运维的各种复杂度。&lt;/p&gt;
&lt;p&gt;一般以整型值为主的表在千万级以下，字符串为主的表在五百万以下是没有太大问题的。&lt;/p&gt;
&lt;p&gt;而事实上很多时候 MySQL 单表的性能依然有不少优化空间，甚至能正常支撑千万级以上的数据量。&lt;/p&gt;
&lt;h2 id=&quot;字段&quot;&gt;字段&lt;/h2&gt;
&lt;p&gt;关于字段：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;尽量使用 TINYINT、SMALLINT、MEDIUM_INT 作为整数类型而非 INT，如果非负则加上 UNSIGNED。&lt;/li&gt;
&lt;li&gt;VARCHAR 的长度只分配真正需要的空间。&lt;/li&gt;
&lt;li&gt;使用枚举或整数代替字符串类型。&lt;/li&gt;
&lt;li&gt;尽量使用 TIMESTAMP 而非 DATETIME。&lt;/li&gt;
&lt;li&gt;单表不要有太多字段，建议在 20 以内。&lt;/li&gt;
&lt;li&gt;避免使用 NULL 字段，很难查询优化且占用额外索引空间。&lt;/li&gt;
&lt;li&gt;用整型来存 IP。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;索引&quot;&gt;索引&lt;/h2&gt;
&lt;p&gt;关于索引：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;索引并不是越多越好，要根据查询有针对性的创建，考虑在 WHERE 和 ORDER BY 命令上涉及的列建立索引，可根据 EXPLAIN 来查看是否用了索引还是全表扫描。&lt;/li&gt;
&lt;li&gt;应尽量避免在 WHERE 子句中对字段进行 NULL 值判断，否则将导致引擎放弃使用索引而进行全表扫描。&lt;/li&gt;
&lt;li&gt;值分布很稀少的字段不适合建索引，例如“性别”这种只有两三个值的字段。&lt;/li&gt;
&lt;li&gt;字符字段只建前缀索引。&lt;/li&gt;
&lt;li&gt;字符字段最好不要做主键。&lt;/li&gt;
&lt;li&gt;不用外键，由程序保证约束。&lt;/li&gt;
&lt;li&gt;尽量不用 UNIQUE，由程序保证约束。&lt;/li&gt;
&lt;li&gt;使用多列索引时注意顺序和查询条件保持一致，同时删除不必要的单列索引。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;查询-sql&quot;&gt;查询 SQL&lt;/h2&gt;
&lt;p&gt;关于查询 SQL：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;可通过开启慢查询日志来找出较慢的 SQL。&lt;/li&gt;
&lt;li&gt;不做列运算：SELECT id WHERE age + 1 = 10，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边。&lt;/li&gt;
&lt;li&gt;SQL 语句尽可能简单：一条 SQL只能在一个 CPU 运算；大语句拆小语句，减少锁时间；一条大 SQL 可以堵死整个库。&lt;/li&gt;
&lt;li&gt;不用SELECT *。&lt;/li&gt;
&lt;li&gt;OR 改写成 IN：OR 的效率是 n 级别，IN 的效率是 log(n) 级别，IN 的个数建议控制在 200 以内。&lt;/li&gt;
&lt;li&gt;不用函数和触发器，在应用程序实现。&lt;/li&gt;
&lt;li&gt;避免 %xxx 式查询。&lt;/li&gt;
&lt;li&gt;少用 JOIN。&lt;/li&gt;
&lt;li&gt;使用同类型进行比较，比如用 '123' 和 '123' 比，123 和 123 比。&lt;/li&gt;
&lt;li&gt;尽量避免在 WHERE 子句中使用!=或&amp;lt;&amp;gt;操作符，否则引擎将放弃使用索引而进行全表扫描。&lt;/li&gt;
&lt;li&gt;对于连续数值，使用 BETWEEN 不用 IN：SELECT id FROM t WHERE num BETWEEN 1 AND 5。&lt;/li&gt;
&lt;li&gt;列表数据不要拿全表，要使用 LIMIT 来分页，每页数量也不要太大。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;引擎&quot;&gt;引擎&lt;/h2&gt;
&lt;p&gt;目前广泛使用的是 MyISAM 和 InnoDB 两种引擎：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MyISAM&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MyISAM 引擎是 MySQL 5.1 及之前版本的默认引擎，它的特点是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;不支持行锁，读取时对需要读到的所有表加锁，写入时则对表加排它锁。&lt;/li&gt;
&lt;li&gt;不支持事务。&lt;/li&gt;
&lt;li&gt;不支持外键。&lt;/li&gt;
&lt;li&gt;不支持崩溃后的安全恢复。&lt;/li&gt;
&lt;li&gt;在表有读取查询的同时，支持往表中插入新纪录。&lt;/li&gt;
&lt;li&gt;支持 BLOB 和 TEXT 的前 500 个字符索引，支持全文索引。&lt;/li&gt;
&lt;li&gt;支持延迟更新索引，极大提升写入性能。&lt;/li&gt;
&lt;li&gt;对于不会进行修改的表，支持压缩表，极大减少磁盘空间占用。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;InnoDB&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;InnoDB 在 MySQL 5.5 后成为默认索引，它的特点是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;支持行锁，采用 MVCC 来支持高并发。&lt;/li&gt;
&lt;li&gt;支持事务。&lt;/li&gt;
&lt;li&gt;支持外键。&lt;/li&gt;
&lt;li&gt;支持崩溃后的安全恢复。&lt;/li&gt;
&lt;li&gt;不支持全文索引。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;PS：据说 InnoDB 已经在 MySQL 5.6.4 支持全文索引了。&lt;/p&gt;
&lt;p&gt;总体来讲，MyISAM 适合 SELECT 密集型的表，而 InnoDB 适合 INSERT 和 UPDATE 密集型的表。&lt;/p&gt;
&lt;h2 id=&quot;系统调优参数&quot;&gt;系统调优参数&lt;/h2&gt;
&lt;p&gt;可以使用下面几个工具来做基准测试：&lt;/p&gt;
&lt;p&gt;调优参数内容较多，具体可参考官方文档，这里介绍一些比较重要的参数：&lt;/p&gt;
&lt;ul readability=&quot;0.5&quot;&gt;&lt;li&gt;&lt;strong&gt;back_log：back_log&lt;/strong&gt; 值可以指出在 MySQL 暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。&lt;br/&gt;也就是说，如果 MySQL 的连接数据达到 max_connections 时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即 back_log，如果等待连接的数量超过 back_log，将不被授予连接资源。可以从默认的 50 升至 500。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;wait_timeout&lt;/strong&gt;：数据库连接闲置时间，闲置连接会占用内存资源。可以从默认的 8 小时减到半小时。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;max_user_connection&lt;/strong&gt;：最大连接数，默认为 0 无上限，最好设一个合理上限。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;thread_concurrency&lt;/strong&gt;：并发线程数，设为 CPU 核数的两倍。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;skip_name_resolve&lt;/strong&gt;：禁止对外部连接进行 DNS 解析，消除 DNS 解析时间，但需要所有远程主机用 IP 访问。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;key_buffer_size&lt;/strong&gt;：索引块的缓存大小，增加会提升索引处理速度，对 MyISAM 表性能影响最大。&lt;br/&gt;对于内存 4G 左右，可设为 256M 或 384M，通过查询 show status like 'key_read%'，保证 key_reads / key_read_requests 在 0.1% 以下最好。&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;strong&gt;innodb_buffer_pool_size&lt;/strong&gt;：缓存数据块和索引块，对 InnoDB 表性能影响最大。&lt;br/&gt;通过查询 show status like 'Innodb_buffer_pool_read%'，保证 (Innodb_buffer_pool_read_requests – Innodb_buffer_pool_reads) / Innodb_buffer_pool_read_requests 越高越好。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;innodb_additional_mem_pool_size&lt;/strong&gt;：InnoDB 存储引擎用来存放数据字典信息以及一些内部数据结构的内存空间大小。&lt;br/&gt;当数据库对象非常多的时候，适当调整该参数的大小以确保所有数据都能存放在内存中提高访问效率，当过小的时候，MySQL 会记录 Warning 信息到数据库的错误日志中，这时就需要调整这个参数大小。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;innodb_log_buffer_size&lt;/strong&gt;：InnoDB 存储引擎的事务日志所使用的缓冲区，一般来说不建议超过 32MB。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;query_cache_size&lt;/strong&gt;：缓存 MySQL 中的 ResultSet，也就是一条 SQL 语句执行的结果集，所以仅仅只能针对 Select 语句。&lt;br/&gt;当某个表的数据有任何变化，都会导致所有引用了该表的 Select 语句在 Query Cache 中的缓存数据失效。&lt;br/&gt;所以，当我们数据变化非常频繁的情况下，使用 Query Cache 可能得不偿失。&lt;br/&gt;根据命中率(Qcache_hits/(Qcache_hits+Qcache_inserts)*100))进行调整，一般不建议太大，256MB 可能已经差不多了，大型的配置型静态数据可适当调大。可以通过命令 show status like 'Qcache_%' 查看目前系统 Query Cache 使用大小。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;read_buffer_size&lt;/strong&gt;：MySQL 读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySQL 会为它分配一段内存缓冲区。&lt;br/&gt;如果对表的顺序扫描请求非常频繁，可以通过增加该变量值以及内存缓冲区大小提高其性能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;sort_buffer_size&lt;/strong&gt;：MySQL 执行排序使用的缓冲大小。如果想要增加 ORDER BY 的速度，首先看是否可以让 MySQL 使用索引而不是额外的排序阶段。如果不能，可以尝试增加 sort_buffer_size 变量的大小。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;read_rnd_buffer_size&lt;/strong&gt;：MySQL 的随机读缓冲区大小。当按任意顺序读取行时(例如按照排序顺序)，将分配一个随机读缓存区。&lt;br/&gt;进行排序查询时，MySQL 会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。&lt;br/&gt;但 MySQL 会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;record_buffer&lt;/strong&gt;：每个进行一个顺序扫描的线程为其扫描的每张表分配这个大小的一个缓冲区。如果你做很多顺序扫描，可能想要增加该值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;thread_cache_size&lt;/strong&gt;：保存当前没有与连接关联但是准备为后面新的连接服务的线程，可以快速响应连接的线程请求而无需创建新的。&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;strong&gt;table_cache&lt;/strong&gt;：类似于 thread_cache _size，但用来缓存表文件，对 InnoDB 效果不大，主要用于 MyISAM。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;升级硬件&quot;&gt;升级硬件&lt;/h2&gt;
&lt;p&gt;Scale Up，这个不多说了，根据 MySQL 是 CPU 密集型还是 I/O 密集型，通过提升 CPU 和内存、使用 SSD，都能显著提升 MySQL 性能。&lt;/p&gt;

&lt;p&gt;也是目前常用的优化，从库读主库写，一般不要采用双主或多主引入很多复杂性，尽量采用文中的其他方案来提高性能。同时目前很多拆分的解决方案同时也兼顾考虑了读写分离。&lt;/p&gt;

&lt;p&gt;缓存可以发生在这些层次：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;MySQL 内部&lt;/strong&gt;：在系统调优参数介绍了相关设置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据访问层&lt;/strong&gt;：比如 MyBatis 针对 SQL 语句做缓存，而 Hibernate 可以精确到单个记录，这里缓存的对象主要是持久化对象 Persistence Object。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用服务层&lt;/strong&gt;：可以通过编程手段对缓存做到更精准的控制和更多的实现策略，这里缓存的对象是数据传输对象 Data Transfer Object。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Web 层&lt;/strong&gt;：针对 Web 页面做缓存。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;浏览器客户端&lt;/strong&gt;：用户端的缓存。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;可以根据实际情况在一个层次或多个层次结合加入缓存。这里重点介绍下服务层的缓存实现。&lt;/p&gt;
&lt;p&gt;目前主要有两种方式：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;直写式（Write Through）&lt;/strong&gt;：在数据写入数据库后，同时更新缓存，维持数据库与缓存的一致性。&lt;br/&gt;这也是当前大多数应用缓存框架如 Spring Cache 的工作方式。这种实现非常简单，同步好，但效率一般。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;回写式（Write Back）&lt;/strong&gt;：当有数据要写入数据库时，只会更新缓存，然后异步批量的将缓存数据同步到数据库上。&lt;br/&gt;这种实现比较复杂，需要较多的应用逻辑，同时可能会产生数据库与缓存的不同步，但效率非常高。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MySQL 在 5.1 版引入的分区是一种简单的水平拆分，用户需要在建表的时候加上分区参数，对应用是透明的无需修改代码。&lt;/p&gt;
&lt;p&gt;对用户来说，分区表是一个独立的逻辑表，但是底层由多个物理子表组成，实现分区的代码实际上是通过对一组底层表的对象封装，但对 SQL 层来说是一个完全封装底层的黑盒子。&lt;/p&gt;
&lt;p&gt;MySQL 实现分区的方式也意味着索引也是按照分区的子表定义，没有全局索引。&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201810/1162587-20181009015656027-557651321.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;用户的 SQL 语句是需要针对分区表做优化，SQL 条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区。&lt;/p&gt;
&lt;p&gt;可以通过 EXPLAIN PARTITIONS 来查看某条 SQL 语句会落在那些分区上，从而进行 SQL 优化。&lt;/p&gt;
&lt;p&gt;如下图 5 条记录落在两个分区上：&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;mysql&amp;gt; explain partitions select count(1) from user_partition where id in (1,2,3,4,5);
+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+
| id | select_type | table          | partitions | type  | possible_keys | key     | key_len | ref  | rows | Extra                    |
+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+
|  1 | SIMPLE      | user_partition | p1,p4      | range | PRIMARY       | PRIMARY | 8       | NULL |    5 | Using where; Using index |
+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+
1 row in set (0.00 sec)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;分区的好处是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;可以让单表存储更多的数据。&lt;/li&gt;
&lt;li&gt;分区表的数据更容易维护，可以通清除整个分区批量删除大量数据，也可以增加新的分区来支持新插入的数据。另外，还可以对一个独立分区进行优化、检查、修复等操作。&lt;/li&gt;
&lt;li&gt;部分查询能够从查询条件确定只落在少数分区上，速度会很快。&lt;/li&gt;
&lt;li&gt;分区表的数据还可以分布在不同的物理设备上，从而高效利用多个硬件设备。&lt;/li&gt;
&lt;li&gt;可以使用分区表来避免某些特殊瓶颈，例如 InnoDB 单个索引的互斥访问、 ext3 文件系统的 inode 锁竞争。&lt;/li&gt;
&lt;li&gt;可以备份和恢复单个分区。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;分区的限制和缺点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;一个表最多只能有 1024 个分区。&lt;/li&gt;
&lt;li&gt;如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来。&lt;/li&gt;
&lt;li&gt;分区表无法使用外键约束。&lt;/li&gt;
&lt;li&gt;NULL 值会使分区过滤无效。&lt;/li&gt;
&lt;li&gt;所有分区必须使用相同的存储引擎。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;分区的类型：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;RANGE 分区&lt;/strong&gt;：基于属于一个给定连续区间的列值，把多行分配给分区。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LIST 分区&lt;/strong&gt;：类似于按 RANGE 分区，区别在于 LIST 分区是基于列值匹配一个离散值集合中的某个值来进行选择。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HASH 分区&lt;/strong&gt;：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含 MySQL 中有效的、产生非负整数值的任何表达式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;KEY 分区&lt;/strong&gt;：类似于按 HASH 分区，区别在于 KEY 分区只支持计算一列或多列，且 MySQL 服务器提供其自身的哈希函数。必须有一列或多列包含整数值。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;分区适合的场景有&lt;/strong&gt;：最适合的场景数据的时间序列性比较强，则可以按时间来分区。&lt;/p&gt;
&lt;p&gt;如下所示：&lt;/p&gt;
&lt;pre class=&quot;sql&quot;&gt;
&lt;code&gt;CREATE TABLE members (
    firstname VARCHAR(25) NOT NULL,
    lastname VARCHAR(25) NOT NULL,
    username VARCHAR(16) NOT NULL,
    email VARCHAR(35),
    joined DATE NOT NULL
)PARTITION BY RANGE( YEAR(joined) ) (
    PARTITION p0 VALUES LESS THAN (1960),
    PARTITION p1 VALUES LESS THAN (1970),
    PARTITION p2 VALUES LESS THAN (1980),
    PARTITION p3 VALUES LESS THAN (1990),
    PARTITION p4 VALUES LESS THAN MAXVALUE
);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;查询时加上时间范围条件的效率会非常高，同时对于不需要的历史数据能很容易的批量删除。&lt;/p&gt;
&lt;p&gt;如果数据有明显的热点，而且除了这部分数据，其他数据很少被访问到，那么可以将热点数据单独放在一个分区，让这个分区的数据能够有机会都缓存在内存中，查询时只访问一个很小的分区表，能够有效使用索引和缓存。&lt;/p&gt;
&lt;p&gt;另外 MySQL 有一种早期的简单的分区实现 - 合并表（merge table），限制较多且缺乏优化，不建议使用，应该用新的分区机制来替代。&lt;/p&gt;

&lt;p&gt;垂直分库是根据数据库里面的数据表的相关性进行拆分，比如：一个数据库里面既存在用户数据，又存在订单数据，那么垂直拆分可以把用户数据放到用户库、把订单数据放到订单库。&lt;/p&gt;
&lt;p&gt;垂直分表是对数据表进行垂直拆分的一种方式，常见的是把一个多字段的大表按常用字段和非常用字段进行拆分，每个表里面的数据记录数一般情况下是相同的，只是字段不一样，使用主键关联。&lt;/p&gt;
&lt;p&gt;比如原始的用户表是：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201810/1162587-20181009015718181-1767688768.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;垂直拆分后是：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201810/1162587-20181009015728432-839617444.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;垂直拆分的优点是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;可以使得行数据变小，一个数据块(Block)就能存放更多的数据，在查询时就会减少 I/O 次数(每次查询时读取的 Block 就少)。&lt;/li&gt;
&lt;li&gt;可以达到最大化利用 Cache 的目的，具体在垂直拆分的时候可以将不常变的字段放一起，将经常改变的放一起。&lt;/li&gt;
&lt;li&gt;数据维护简单。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;缺点是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;主键出现冗余，需要管理冗余列。&lt;/li&gt;
&lt;li&gt;会引起表连接 JOIN 操作（增加 CPU 开销）可以通过在业务服务器上进行 JOIN 来减少数据库压力。&lt;/li&gt;
&lt;li&gt;依然存在单表数据量过大的问题（需要水平拆分）。&lt;/li&gt;
&lt;li&gt;事务处理复杂。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;水平拆分是通过某种策略将数据分片来存储，分库内分表和分库两部分，每片数据会分散到不同的 MySQL 表或库，以达到分布式的效果，能够支持非常大的数据量。前面的表分区本质上也是一种特殊的库内分表。&lt;/p&gt;
&lt;p&gt;库内分表，由于没有把表的数据分布到不同的机器上，仅仅是单纯的解决了单一表数据过大的问题。&lt;/p&gt;
&lt;p&gt;因此对于减轻 MySQL 服务器的压力来说，并没有太大的作用，大家还是竞争同一个物理机上的 IO、CPU、网络，这个就要通过分库来解决。&lt;/p&gt;
&lt;p&gt;前面垂直拆分的用户表如果进行水平拆分，结果是：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201810/1162587-20181009015744460-1627630786.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;实际情况中往往会是垂直拆分和水平拆分的结合，即将 Users_A_M 和 Users_N_Z 再拆成 Users 和 UserExtras，这样一共四张表。&lt;/p&gt;
&lt;p&gt;水平拆分的优点是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;不存在单库大数据和高并发的性能瓶颈。&lt;/li&gt;
&lt;li&gt;应用端改造较少。&lt;/li&gt;
&lt;li&gt;提高了系统的稳定性和负载能力。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;缺点是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;分片事务一致性难以解决。&lt;/li&gt;
&lt;li&gt;跨节点 JOIN 性能差，逻辑复杂。&lt;/li&gt;
&lt;li&gt;数据多次扩展难度跟维护量极大。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;分片原则&quot;&gt;分片原则&lt;/h2&gt;
&lt;p&gt;分片原则如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;能不分就不分，参考单表优化。&lt;/li&gt;
&lt;li&gt;分片数量尽量少，分片尽量均匀分布在多个数据结点上，因为一个查询 SQL 跨分片越多，则总体性能越差，虽然要好于所有数据在一个分片的结果，只在必要的时候进行扩容，增加分片数量。&lt;/li&gt;
&lt;li&gt;分片规则需要慎重选择做好提前规划，分片规则的选择，需要考虑数据的增长模式，数据的访问模式，分片关联性问题，以及分片扩容问题。&lt;/li&gt;
&lt;li&gt;最近的分片策略为范围分片，枚举分片，一致性 Hash 分片，这几种分片都有利于扩容。&lt;/li&gt;
&lt;li&gt;尽量不要在一个事务中的 SQL 跨越多个分片，分布式事务一直是个不好处理的问题。&lt;/li&gt;
&lt;li&gt;查询条件尽量优化，尽量避免 Select * 的方式，大量数据结果集下，会消耗大量带宽和 CPU 资源，查询尽量避免返回大量结果集，并且尽量为频繁使用的查询语句建立索引。&lt;/li&gt;
&lt;li&gt;通过数据冗余和表分区来降低跨库 JOIN 的可能。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这里特别强调一下分片规则的选择问题，如果某个表的数据有明显的时间特征，比如订单、交易记录等。&lt;/p&gt;
&lt;p&gt;他们通常比较合适用时间范围分片，因为具有时效性的数据，我们往往关注其近期的数据，查询条件中往往带有时间字段进行过滤。&lt;/p&gt;
&lt;p&gt;比较好的方案是，当前活跃的数据，采用跨度比较短的时间段进行分片，而历史性的数据，则采用比较长的跨度存储。&lt;/p&gt;
&lt;p&gt;总体上来说，分片的选择是取决于最频繁的查询 SQL 的条件，因为不带任何 Where 语句的查询 SQL，会遍历所有的分片，性能相对最差，因此这种 SQL 越多，对系统的影响越大，所以我们要尽量避免这种 SQL 的产生。&lt;/p&gt;
&lt;h2 id=&quot;解决方案&quot;&gt;解决方案&lt;/h2&gt;
&lt;p&gt;由于水平拆分牵涉的逻辑比较复杂，当前也有了不少比较成熟的解决方案。这些方案分为两大类：客户端架构和代理架构。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;客户端架构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过修改数据访问层，如 JDBC、Data Source、MyBatis，通过配置来管理多个数据源，直连数据库，并在模块内完成数据的分片整合，一般以 Jar 包的方式呈现。&lt;/p&gt;
&lt;p&gt;这是一个客户端架构的例子：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201810/1162587-20181009015800208-1525897649.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;可以看到分片的实现是和应用服务器在一起的，通过修改 Spring JDBC 层来实现。&lt;/p&gt;
&lt;p&gt;客户端架构的优点是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;应用直连数据库，降低外围系统依赖所带来的宕机风险。&lt;/li&gt;
&lt;li&gt;集成成本低，无需额外运维的组件。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;缺点是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;限于只能在数据库访问层上做文章，扩展性一般，对于比较复杂的系统可能会力不从心。&lt;/li&gt;
&lt;li&gt;将分片逻辑的压力放在应用服务器上，造成额外风险。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;代理架构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过独立的中间件来统一管理所有数据源和数据分片整合，后端数据库集群对前端应用程序透明，需要独立部署和运维代理组件。&lt;/p&gt;
&lt;p&gt;这是一个代理架构的例子：&lt;br/&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201810/1162587-20181009015833529-65319290.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;代理组件为了分流和防止单点，一般以集群形式存在，同时可能需要 ZooKeeper 之类的服务组件来管理。&lt;/p&gt;
&lt;p&gt;代理架构的优点是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;能够处理非常复杂的需求，不受数据库访问层原来实现的限制，扩展性强。&lt;/li&gt;
&lt;li&gt;对于应用服务器透明且没有增加任何额外负载。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;缺点是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;需部署和运维独立的代理中间件，成本高。&lt;/li&gt;
&lt;li&gt;应用需经过代理来连接数据库，网络上多了一跳，性能有损失且有额外风险。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1162587/201810/1162587-20181009015847808-2045531506.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;目前来说，业界还是有很多的方案可供选择，但应该如何进行选择？我认为，可以按以下思路来考虑：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;确定是使用客户端架构还是代理架构。中小型规模或是比较简单的场景倾向于选择客户端架构，复杂场景或大规模系统倾向选择代理架构。&lt;/li&gt;
&lt;li&gt;具体功能是否满足，比如需要跨节点 ORDER BY，那么支持该功能的优先考虑。&lt;/li&gt;
&lt;li&gt;不考虑一年内没有更新的产品，说明开发停滞，甚至无人维护和技术支持。&lt;/li&gt;
&lt;li&gt;最好按大公司→社区→小公司→个人这样的出品方顺序来选择。&lt;/li&gt;
&lt;li&gt;选择口碑较好的，比如 Github 星数、使用者数量质量和使用者反馈。&lt;/li&gt;
&lt;li&gt;开源的优先，往往项目有特殊需求可能需要改动源代码。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;按照上述思路，推荐以下选择：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;客户端架构：ShardingJDBC&lt;/li&gt;
&lt;li&gt;代理架构：MyCat 或者 Atlas&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目前也有一些开源数据库兼容 MySQL 协议，如：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;TiDB&lt;/li&gt;
&lt;li&gt;Cubrid&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;但其工业品质和 MySQL 尚有差距，且需要较大的运维投入，如果想将原始的 MySQL 迁移到可水平扩展的新数据库中，可以考虑一些云数据库：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;阿里云 PetaData&lt;/li&gt;
&lt;li&gt;阿里云 OceanBase&lt;/li&gt;
&lt;li&gt;腾讯云 DCDB&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 MySQL 上做 Sharding 是一种戴着镣铐的跳舞，事实上很多大表本身对 MySQL 这种 RDBMS 的需求并不大，并不要求 ACID。&lt;/p&gt;
&lt;p&gt;可以考虑将这些表迁移到 NoSQL，彻底解决水平扩展问题，例如：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;日志类、监控类、统计类数据&lt;/li&gt;
&lt;li&gt;非结构化或弱结构化数据&lt;/li&gt;
&lt;li&gt;对事务要求不强，且无太多关联操作的数据&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;参考资料：&lt;br/&gt;Mysql那点事&lt;br/&gt;Mysql策略&lt;br/&gt;MySQL：MySQL 5.6 Reference Manual&lt;br/&gt;来源：&lt;a href=&quot;https://www.cnblogs.com/toutou/p/9183795.html&quot;&gt;请叫我头头哥&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 08 Oct 2018 18:04:00 +0000</pubDate>
<dc:creator>JaJian</dc:creator>
<og:description>当 MySQL 单表记录数过大时，增删改查性能都会急剧下降，本文会提供一些优化参考，大家可以参考以下步骤来优化。 单表优化 除非单表数据未来会一直不断上涨，否则不要一开始就考虑拆分，拆分会带来逻辑、部</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/jajian/p/9758192.html</dc:identifier>
</item>
<item>
<title>结对编程项目总结  by：陈宏伟&amp;刘益 - CCC123123</title>
<link>http://www.cnblogs.com/wb995532169/p/9758129.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wb995532169/p/9758129.html</guid>
<description>&lt;p&gt;　　　　结对编程项目在欢快的国庆假期中也顺利结束了。从最初拿到结对编程项目的思考，再到一步一步实现，中间经历了一个漫长的过程。在我和队友的多次协商下，最终我们还是选择使用基于python来实现这一次结对编程项目，并且最终选择了以eric6 + pyqt5 +Anaconda3以及pycharm混搭的开发环境来实现了此次带UI的中小学生题目生成系统。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;设计实现：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　关于此次结对项目，我和队友总结了一下，主要分为两个方面，UI加上后台的实现，我们也进行了明确的分工，我去实现UI界面，队友实现后台系统，后期再根据我每个页面提供给队友的接口，把UI和后台实现进行整合。在实现的过程中，我们也遇到了很多困难，然后我们也对此分别进行了总结。&lt;/p&gt;
&lt;p&gt;UI的实现：&lt;/p&gt;
&lt;p&gt;　　起初最开始拿到结对编程项目的需求的时候，先是冷静分析了一波，UI的实现具体需要哪些页面，页面与页面之间的关系是什么，怎么去实现页面之间的相互跳转。起初分析完后，最开始是用的python自带的tkinter模块进行每一个界面的设计，但当设计第一个界面的时候，便出现了问题，关于label控件在背景图片上的显示问题，尝试了很多方法，画布，背景图片和label控件的组合方法或者分开来按照顺序贴图，但是设计出来都达不到自己预期所想要的效果。最终还是放弃了tkinter，选择了功能更为强大的pyqt5，加上以前学习UI所搭建好的eric6和Anconda3，最终实现了所想要的效果。&lt;/p&gt;

&lt;p&gt;后台的实现：&lt;/p&gt;
&lt;p&gt;　　因为队友最初的个人项目是用C++来写的，但是我们决定整个项目基于python来实现之后，队友还是选择了重新把C++代码改成了python代码，并且在以前所遇到的出题的出现的问题上进行了优化，还多加实现了项目所需要的其他功能，比如题目的计算，短信验证，统计成绩等等。尤其是在对题目进行计算的时候我们遇到了些许困难，队友最开始的时候想的是使用队列这一结构对题目答案进行计算，先只考虑小学的情况，用一个队列来保存算式里面的运算数，用另一个队列来保存算式里的运算符，定义括号长度从2开始递增，然后先对算式进行遍历，将括号长度为2包含的两个操作数放入到队列1里，然后将其中的运算符放入队列2里，依次类推，最终将所有运算数和操作符全部放完，再每次从队列1中取出两个元素，并从队列2中取出一个操作符，然后进行计算，将得到的值重新放入到队列1的队尾，一直循环，直到队列2为空，队列1里所得到的数值便是最后的计算结果。对于初中生和高中生来说，只需要先将加入的某数的平方开方或者三角函数替换为具体数值，再复用小学计算的方法便能实现。但最后还是有点小bug，最终我们根据查找资料，然后运用的python里面的自带的eval()函数进行计算，最终能算出具体的数值。&lt;/p&gt;

&lt;p&gt;组合的实现：&lt;br/&gt;　　在进行UI开发的时候，采用的思想是页面与逻辑的分离，每一个UI都有一个UI界面的py文件和一个具体控件逻辑行为实现的py文件，而控件逻辑行为实现的文件，恰好为我们后台代码与UI界面的结合提供了一个很好的接口，我们只需要将我们后台具体实现的某个页面所需要的代码糅合进槽函数中，便能实现后台与UI界面的完美融合。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1441246/201810/1441246-20181009002231691-1587727450.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;&lt;span&gt;成果展示：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1441246/201810/1441246-20181009003357972-20304764.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1441246/201810/1441246-20181009003239218-1892213017.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1441246/201810/1441246-20181009003315043-102335005.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1441246/201810/1441246-20181009003425454-456027079.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1441246/201810/1441246-20181009003446197-1145145588.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1441246/201810/1441246-20181009003457915-1282676577.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;






&lt;p&gt;&lt;strong&gt;&lt;span&gt;结对编程的经验教训：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　通过这次项目，我们深切体会到了结对编程的利弊。两个人一起做项目可以相互监督，互相促进，当遇到难点的时候还能共同研究讨论，以尽快解决问题，在这个过程中，整体的效率有了较为明显的提高。但是不同的人总有不同的想法，当意见产生分歧的时候就很糟糕，整个项目也会停滞不前，这个时候沟通就很重要，要综合两个人的想法，争取找到最好的解决办法，所以结对编程也是一个相互磨合的过程。总的来说，结对编程还是很有益处，我们能从对方身上学到很多东西，也有了合作完成项目的意识，是一个很好的经历。 &lt;/p&gt;
</description>
<pubDate>Mon, 08 Oct 2018 16:46:00 +0000</pubDate>
<dc:creator>CCC123123</dc:creator>
<og:description>结对编程项目在欢快的国庆假期中也顺利结束了。从最初拿到结对编程项目的思考，再到一步一步实现，中间经历了一个漫长的过程。在我和队友的多次协商下，最终我们还是选择使用基于python来实现这一次结对编程项</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/wb995532169/p/9758129.html</dc:identifier>
</item>
<item>
<title>设计shell脚本选项：getopt - 骏马金龙</title>
<link>http://www.cnblogs.com/f-ck-need-u/p/9758075.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/f-ck-need-u/p/9758075.html</guid>
<description>&lt;p&gt;&lt;strong&gt;man 1 getopt翻译&lt;/strong&gt;：&lt;a href=&quot;https://www.cnblogs.com/f-ck-need-u/p/9757959.html&quot; class=&quot;uri&quot;&gt;https://www.cnblogs.com/f-ck-need-u/p/9757959.html&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;写shell脚本的时候，通过while、case、shift来设计脚本的命令行选项是一件比较麻烦的事，因为Unix命令行的选项和参数自由度很高，支持短选项和长选项，参数可能是可选的，选项顺序可能是无所谓的，等等。&lt;/p&gt;
&lt;p&gt;bash下的getopt命令可以解析命令行的选项和参数，&lt;strong&gt;将散乱、自由的命令行选项和参数进行改造，得到一个完整的、规范化的参数列表，这样再使用while、case和shift进行处理就简单的太多了&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;getopt有不同的版本，本文介绍的是它的增强版(enhanced)，相比传统的getopt(也成为兼容版本的getopt)，它提供了引号保护的能力。另外，除了不同版本的getopt，bash还有一个内置命令getopts(注意，有个尾随的字符s)，也用来解析命令行选项，但只能解析短选项。&lt;/p&gt;
&lt;p&gt;要验证安装的getopt是增强版的还是传统版的，使用&lt;code&gt;getopt -T&lt;/code&gt;判断即可。如果它什么都不输出，则是增强版，此时它的退出状态码为4。如果输出&quot;--&quot;，则是传统版的getopt，此时它的退出状态码为0。如果想在脚本中进行版本检查，可以参考如下代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;getopt -T &amp;amp;&amp;gt;/dev/null;[ $? -ne 4 ] &amp;amp;&amp;amp; { echo &quot;not enhanced version&quot;;exit 1; }&lt;/code&gt;
&lt;/pre&gt;


&lt;p&gt;在学习getopt如何使用之前，必须先知道命令行的一些常识。这些，都可以通过getopt来实现，但有些实现起来可能会比较复杂。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.区分option、parameter、argument、option argument和non-option parament&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;parameter和argument都表示参数，前者通常表示独立性的参数，后者通常表示依赖于其它实体的参数。parameter的含义更广，argument可以看作parameter的一种。&lt;/p&gt;
&lt;p&gt;例如，定义函数时&lt;code&gt;function foo(x,y){CODE}&lt;/code&gt;，函数的参数x和y称为parameter。调用函数并传递参数时，&lt;code&gt;foo(arg1,arg2)&lt;/code&gt;中的arg1和arg2都是依赖于函数的，称为argument更合适，当然也可以称为更广泛的parameter。&lt;/p&gt;
&lt;p&gt;再例如，一个命令行：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;tar -zcf a.tar.gz /etc/pki&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;粗分的话，&lt;code&gt;-z&lt;/code&gt;、&lt;code&gt;-c&lt;/code&gt;、&lt;code&gt;-f&lt;/code&gt;、&lt;code&gt;a.tar.gz&lt;/code&gt;、&lt;code&gt;/etc/pki&lt;/code&gt;都可以称为parameter。细分的话：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&quot;-z -c -f&quot;称为选项，即option&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;a.tar.gz是选项&quot;-f&quot;的&lt;strong&gt;选项参数&lt;/strong&gt;(传递给选项的参数)，依赖于选项，称为argument更合适，更严格的称呼是option argument&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;/etc/pki既不属于选项，也不属于某个选项的参数，它称为&lt;strong&gt;非选项类型的参数&lt;/strong&gt;，对应的名称为non-option parameter&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;本文要介绍的是getopt，所以只考虑命令行参数的情况。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.短选项和长选项以及它们的&quot;潜规则&quot;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Linux中绝大多数命令都提供了短选项和长选项。一般来说，短选项是只使用一个&quot;-&quot;开头，选项部分只使用一个字符，长选项是使用两个短横线(即&quot;--&quot;)开头的。&lt;/p&gt;
&lt;p&gt;例如&quot;-a&quot;是短选项，&quot;--append&quot;是长选项。&lt;/p&gt;
&lt;p&gt;一般来说，选项的顺序是无所谓的，但并非绝对如此，有时候某些选项必须放在前面，必须放在某些选项的前面、后面。&lt;/p&gt;
&lt;p&gt;一般来说，短选项：&lt;/p&gt;
&lt;ul readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;3&quot;&gt;
&lt;p&gt;可以通过一个短横线&quot;-&quot;将多个短选项连接在一起，但如果连在一起的短选项有参数的话，则必须作为串联的最后一个字符。&lt;/p&gt;
&lt;p&gt;例如&quot;-avz&quot;其实会被解析为&quot;-a -v -z&quot;，&lt;code&gt;tar -zcf a.tar.gz&lt;/code&gt;串联了多个短选项，但&quot;-f&quot;选项有参数a.tar.gz，所以它必须作为串联选项的最后一个字符。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;短选项的参数可以和选项名称连在一起，也可以是用空白分隔。例如&lt;code&gt;-n 3&lt;/code&gt;和&lt;code&gt;-n3&lt;/code&gt;是等价的，数值3都是&quot;-n&quot;选项的参数值。&lt;br/&gt;&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;如果某个短选项的参数是可选的，那么它的参数必须紧跟在选项名后面，不能使用空格分开。至于为什么，见下面的第3项。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;一般来说，长选项：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;可以使用等号或空白连接两种方式提供选项参数。例如&lt;code&gt;--file=FILE&lt;/code&gt;或&lt;code&gt;--file FILE&lt;/code&gt;。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;如果某个长选项的参数是可选的，那么它的参数必须使用&quot;=&quot;连接。至于为什么，见下面的第3项。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;长选项一般可以缩写，只要不产生歧义即可。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;例如，ls命令，以&quot;a&quot;开头的长选项有3个。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ ls --help | grep -- '--a' 
  -a, --all                  do not ignore entries starting with .
  -A, --almost-all           do not list implied . and ..
      --author               with -l, print the author of each file&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果想要指定&lt;code&gt;--almost-all&lt;/code&gt;，可以缩写为&lt;code&gt;--alm&lt;/code&gt;；如果想要指定&lt;code&gt;--author&lt;/code&gt;，可以缩写为&lt;code&gt;--au&lt;/code&gt;。如果只缩写为&quot;--a&quot;，bash将给出错误提示，长选项出现歧义：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ ls --a
ls: option '--a' is ambiguous; possibilities: '--all' '--author' '--almost-all'
Try 'ls --help' for more information.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;3.不带参数的选项、可选参数的选项和带参数的选项&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;有不同类型的命令行选项，这些选项可能不需要参数，也可能参数是可选的，也可能是强制要求参数的。&lt;/p&gt;
&lt;p&gt;前面说了，如果某个选项的参数是可选的，那么它的参数必须不能使用空格将参数和选项分开。如果使用空格分隔，则无法判断它的下一个元素是该选项的参数还是非选项类型的参数。&lt;/p&gt;
&lt;p&gt;例如，&lt;code&gt;-c&lt;/code&gt;和&lt;code&gt;--config&lt;/code&gt;选项的参数是可选的，要向这两个选项提供参数，必须写成&lt;code&gt;-cFILE&lt;/code&gt;、&lt;code&gt;--config=FILE&lt;/code&gt;，如果写成&lt;code&gt;-c FILE&lt;/code&gt;、&lt;code&gt;--config FILE&lt;/code&gt;，那么getopt无法判断这个FILE是提供给选项的参数，还是非选项类型的参数。&lt;/p&gt;
&lt;p&gt;一般来说，使用可选参数的情况非常少，至少我目前回忆不起来这样的命令。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.使用&quot;--&quot;将选项(及它们的选项参数)与非选项类型参数进行分隔&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;unix的命令行中，总是可以在非选项类型的参数之前加上&quot;--&quot;，表示选项和选项参数到此为止，后面的都是非选项类型的参数。&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;seq -w -- 3
seq -w -- 1 3&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;分别表示3和&quot;1 3&quot;是seq的非选项类型参数，而&quot;--&quot;前面的一定是选项或选项参数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.命令行参数中的短横线开头的并不一定总是短选项，也可能是负数参数&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;例如seq命令：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;seq -w -5 -1 5&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中-5和-1都是负数非选项类型的参数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6.选项的依赖性和互斥性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;有些命令的选项是有依赖性和互斥性的。比如某个选项要和另一个选项一起使用，某个选项不能和另一个选项一起使用。&lt;/p&gt;
&lt;p&gt;例如&lt;code&gt;--manage --remove&lt;/code&gt;，只有在使用了&lt;code&gt;--manage&lt;/code&gt;的前提下才能使用&lt;code&gt;--remove&lt;/code&gt;，否则就应该报错。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7.模式化(模块化)类型的选项&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;很多unix命令都将选项进行模块化设计。例如ip命令，address模式、route模式、link模式等等。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;ip addr OPTIONS
ip route OPTIONS
ip link OPTIONS 
ip neigh OPTIONS&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;8.其他特性的选项&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;有些命令还有比较个性化的选项，比如head命令，&lt;code&gt;-n NUM&lt;/code&gt;选项，即可以指定为&lt;code&gt;-3&lt;/code&gt;，也可以指定为&lt;code&gt;-n 3&lt;/code&gt;或&lt;code&gt;-n3&lt;/code&gt;。&lt;/p&gt;


&lt;p&gt;bash的getopt命令经常用在shell脚本内部或函数内部，用来解析脚本执行或函数执行时传递的选项、参数。&lt;/p&gt;
&lt;p&gt;下面都以命令行为例解释getopt是如何解析参数的，但用来解析函数参数是一样的。&lt;/p&gt;

&lt;h2 id=&quot;getopt选项&quot;&gt;2.1 getopt选项&lt;/h2&gt;
&lt;p&gt;下面这个是最常用的getopt解析方式(有这个命令就够了)。如果要了解getopt更完整的语法，见man getopt。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;getopt -o SHORT_OPTIONS -l LONG_OPTIONS -n &quot;$0&quot; -- &quot;$@&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中：&lt;br/&gt;&lt;code&gt;-o SHORT_OPTIONS&lt;/code&gt;&lt;br/&gt;&lt;code&gt;--options SHORT_OPTIONS&lt;/code&gt;&lt;br/&gt;getopt通过&quot;-o&quot;选项收集命令行传递的短选项和它们对应的参数。关于SHORT_OPTIONS的格式见下一小节。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-l LONG_OPTIONS&lt;/code&gt;&lt;br/&gt;&lt;code&gt;--longoptions LONG_OPTIONS&lt;/code&gt;&lt;br/&gt;getopt通过&quot;-l&quot;选项收集命令行传递的长选项和它们对应的参数。可能从别人的脚本中经常看到&quot;--long&quot;，是等价的，前文已经解释过，长选项只要不产生歧义，是可以进行缩写的。关于LONG_OPTIONS的格式见下一小节。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-n NAME&lt;/code&gt;&lt;br/&gt;getopt在解析命令行时，如果解析出错(例如要求给参数的选项没带参数，使用了无法解析的选项等)将会报告错误信息，getopt将使用该NAME作为报错的脚本名称。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-- &quot;$@&quot;&lt;/code&gt;&lt;br/&gt;其中&lt;code&gt;--&lt;/code&gt;表示getopt命令自身的选项到此结束，后面的元素都是要被getopt解析的命令行参数。这里使用&lt;code&gt;&quot;$@&quot;&lt;/code&gt;，表示所有的命令行参数。注意，不能省略双引号。&lt;/p&gt;

&lt;h2 id=&quot;getopt如何解析选项和参数&quot;&gt;2.2 getopt如何解析选项和参数&lt;/h2&gt;
&lt;p&gt;getopt使用&quot;-o&quot;或&quot;-l&quot;解析短、长选项和参数时，将会对每个解析到的选项、参数进行输出，然后不断放进一个字符串中。这个字符串的内容就是完整的、规范化的选项和参数。&lt;/p&gt;
&lt;p&gt;getopt使用&quot;-o&quot;选项解析短选项时：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;多个短选项可以连在一起&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;如果某个要解析的选项需要一个参数，则在选项名后面跟一个冒号&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;如果某个要解析的选项的参数可选，则在选项名后面跟两个冒号&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;例如，&lt;code&gt;getopt -o ab:c::&lt;/code&gt;中，将解析为&lt;code&gt;-a -b arg_b -c [arg_c]&lt;/code&gt;，arg_b是-b选项必须的，arg_c是-c选项可选的参数，&quot;-a&quot;选项无需参数&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;getopt使用&quot;-l&quot;选项解析长选项时：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;可以一次性指定多个选项名称，需要使用逗号分隔它们&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;可以多次使用-l选项，多次解析长选项&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;如果某个要解析的选项需要一个参数，则在选项名后面跟一个冒号&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;如果某个要解析的选项的参数可选，则在选项名后面跟两个冒号&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;例如，&lt;code&gt;getopt -l add:,remove::,show&lt;/code&gt;中，将解析为&lt;code&gt;--add arg_add --remove [arg_rem] --show&lt;/code&gt;，其中arg_add是&lt;code&gt;--add&lt;/code&gt;选项必须的，&lt;code&gt;--remove&lt;/code&gt;选项的参数arg_rem是可选的，&lt;code&gt;--show&lt;/code&gt;无需参数&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;如果解析的是带参数的选项，则getopt生成的字符串中，会将选项的参数值作为该选项的下一个参数。如果解析的是可选参数的选项，如果为该选项设置了参数，则会将这个参数放在选项的下一个参数位置，如果没有为该选项设置参数，则会生成一个用引号包围的空字符串作为选项的下一个参数。&lt;/p&gt;
&lt;p&gt;getopt&lt;strong&gt;解析完选项和选项的参数后&lt;/strong&gt;，将解析非选项类型的参数(non-option parameter)。getopt为了让非选项类型的参数和选项、选项参数区分开，将在解析第一个非选项类型参数时加上一个&quot;--&quot;到字符串中，表示选项和选项参数到此结束，然后将所有的非选项类型参数放在这个&quot;--&quot;参数之后。&lt;/p&gt;
&lt;p&gt;默认情况下，该加强版本的getopt会将所有参数值(包括选项参数、非选项类型的参数)使用引号进行包围，以便保护空白字符和特殊字符。如果是兼容版本的getopt，则不会用引号保护，所以会破坏参数解析。&lt;/p&gt;
&lt;p&gt;看后面的示例就很容易理解了。&lt;/p&gt;

&lt;h2 id=&quot;示例分析getopt的解析方式&quot;&gt;2.3 示例分析getopt的解析方式&lt;/h2&gt;
&lt;p&gt;例如在脚本test.sh中，下面的getopt的结果保存到变量parameters中，然后输出getopt解析完成后得到的完整参数列表。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#!/usr/bin/env bash

parameters=`getopt -o ab:c:: --long add:,remove::,show -n &quot;$0&quot; -- &quot;$@&quot;`
echo &quot;$parameters&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果还不知道这里的&lt;code&gt;-o&lt;/code&gt;和&lt;code&gt;--long&lt;/code&gt;解析了什么东西，请回头仔细再看一遍。&lt;/p&gt;
&lt;p&gt;执行这个脚本，并给这个脚本传递一些选项和参数，这些脚本参数将被收集到&lt;code&gt;$@&lt;/code&gt;，然后被getopt解析。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ ./test.sh -a non-op_arg1 -b b_short_arg non-op_arg2 --rem --add /path --show -c non-op_arg3
 -a -b 'b_short_arg' --remove '' --add '/path' --show -c '' -- 'non-op_arg1' 'non-op_arg2' 'non-op_arg3'&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;首先可以看出，传递给脚本的参数都是无序的：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;长选项有：
&lt;ul&gt;&lt;li&gt;&lt;code&gt;--rem&lt;/code&gt;：是--remove的缩写形式，它的参数是可选的，但没有为它传递参数&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--add&lt;/code&gt;：并设置了该选项的参数/path&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--show&lt;/code&gt;：没有任何参数&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;短选项有：
&lt;ul&gt;&lt;li&gt;&lt;code&gt;-a&lt;/code&gt;：它是无需参数的选项，所以它后面的non-op_arg1是一个非选项类型的参数&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-b&lt;/code&gt;：它是必须带参数的选项，所以b_short_arg是它的参数&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-c&lt;/code&gt;：它的参数是可选的，这里没有给它提供参数(前面解释过，要给参数可选的选项提供参数，短选项时，参数和选项名称必须连在一起)。&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;非选项类型的参数有：
&lt;ul&gt;&lt;li&gt;non-op_arg1&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;non-op_arg2&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;non-op_arg3&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;从getopt的输出结果中，可以看出：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;先解析选项和选项参数&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;选项和选项参数是按照从左向右的方式进行解析的&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;参数都使用引号包围&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;那些参数可选的选项，当没有为它们提供参数时，将生成一个引号包围的空字符串参数&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;解析完所有的选项和选项参数后，开始解析非选项类型的参数&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;非选项类型的参数前面，会生成一个&quot;--&quot;字符串，它将选项(以及选项参数)与非选项类型的参数隔开了&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;getopt解析得到了完整、规范化的结果，当然要拿来应用。例如直接传递个函数，或者根据while、case、shift将选项、参数进行分割单独保存。&lt;/p&gt;
&lt;p&gt;如果要进行分割，由于getopt的解析结果通常保存在一个变量中，要解析这个结果字符串，需要使用eval函数将变量的内容进行还原，一般来说会将其设置为一个位置参数(因为shift只能操作位置变量)。&lt;/p&gt;
&lt;p&gt;一般来说，整个处理流程是这样的：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;parameters=$(getopt -o SHORT_OPTIONS -l LONG_OPTIONS -n &quot;$0&quot; -- &quot;$@&quot;)
[ $? != 0 ] &amp;amp;&amp;amp; exit 1
eval set -- &quot;$parameters&quot;   # 将$parameters设置为位置参数
while true ; do             # 循环解析位置参数
    case &quot;$1&quot; in
        -a|--longa) ...;shift ;;    # 不带参数的选项-a或--longa
        -b|--longb) ...;shift 2;;   # 带参数的选项-b或--longb
        -c|--longc)                 # 参数可选的选项-c或--longc
            case &quot;$2&quot; in 
                &quot;&quot;)...;shift 2;;  # 没有给可选参数
                *) ...;shift 2;;  # 给了可选参数
            esac;;
        --) ...; break ;;       # 开始解析非选项类型的参数，break后，它们都保留在$@中
        *) echo &quot;wrong&quot;;exit 1;;
    esac
done&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;需要注意，getopt解析既可以放在脚本中解析命令行参数，也可以放在某个函数中解析函数参数。&lt;/p&gt;


&lt;p&gt;getopt提供了两种扫描模式，只要在getopt的短选项前加上加号或负号，就能指定两种扫描模式，即&lt;code&gt;getopt -o [+-]SHORT_OPTS&lt;/code&gt;。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;+&lt;/code&gt;扫描模式：只要解析完选项、选项参数，解析到第一个非选项类型的参数后，就会停止解析，它会将所有没有解析的内容都当作非选项类型参数。所以这种情况下，非选项类型的参数都必须放在尾部，而不能放在某个待解析选项的前面。这种模式在区别负数和短选项时，非常有用。&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-&lt;/code&gt;扫描模式：会按照原始位置参数解析，并保留原始位置。这种模式一般用不上，因为破坏了getopt的优势：让选项完整、规范化。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;例如，对于命令行参数&lt;code&gt;-w -s -5 3 -2&lt;/code&gt;，要将-5识别为-s的参数，3和-2为非选项类型的参数，则：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ set -- -w -s -5 3 -2  # 设置位置参数
$ getopt -o +s:w -n &quot;$0&quot; -- &quot;$@&quot;
 -w -s '-5' -- '3' '-2'      # 解析结果&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意，上面的-5是被解析成了-s的参数，而不是选项或非选项类型的参数，因为-s选项必须要指定一个参数。&lt;/p&gt;
&lt;p&gt;上面的3必须不能是负数，因为&lt;strong&gt;getopt必须先扫描到一个正常的非选项型参数，才能将它后面的所有负数都当作非选项型参数&lt;/strong&gt;。至于如何将&lt;code&gt;-w -s -5 -3 -2&lt;/code&gt;中的-3和-2都解析为非选项型参数，目前我也不知道。&lt;/p&gt;
&lt;p&gt;使用&lt;code&gt;-&lt;/code&gt;扫描模式：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ set -- 3 -w 4 -s -5 a 3
$ getopt -o -s:w -n &quot;$0&quot; -- &quot;$@&quot;
 '3' -w '4' -s '-5' 'a' '3' --    # 解析结果&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到，上面的所有参数位置都是保持原样的，且将分隔符号&quot;--&quot;补在了最尾部。&lt;/p&gt;


&lt;p&gt;在前面&lt;a href=&quot;http://www.cnblogs.com/f-ck-need-u/p/9758075.html#blog1&quot;&gt;命令行选项的那些事&lt;/a&gt;中介绍了几种有&quot;个性&quot;的选项功能，包括：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;选项依赖：例如&quot;-a&quot;或&quot;--add&quot;要依赖于&quot;-m&quot;或&quot;--manage&quot;选项&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;选项互斥：例如&quot;-a&quot;或&quot;--add&quot;与&quot;-r&quot;或&quot;--remove&quot;是互斥的&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;识别负数参数：例如&lt;code&gt;-w -5 -3 5&lt;/code&gt;，其中-5和-3不是短选项，而是负数参数&lt;/li&gt;
&lt;li&gt;模式化选项：例如&lt;code&gt;script_name MODE OPTIONS&lt;/code&gt;的MODE部分，可以是manage模式(--manage,-m)，也可以使用add模式(--add,-a)&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;选项参数替代选项：例如&lt;code&gt;head -n 3&lt;/code&gt;可以替换为&lt;code&gt;head -3&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;这里介绍下用getopt解析参数后实现它们的思路。&lt;/p&gt;
&lt;p&gt;在getopt解析完成后，假设返回结果保存到了&lt;code&gt;$parameters&lt;/code&gt;变量中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.选项依赖性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这个其实很好实现，只需使用grep对&lt;code&gt;$parameters&lt;/code&gt;变量进行筛选一下即可。&lt;/p&gt;
&lt;p&gt;例如实现依赖性，只需：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;{ echo &quot;$parameters&quot; | grep -E '\-\-add|\-a ' | grep -E '\-\-manage|\-m '; } &amp;amp;&amp;gt;/dev/null
[ $? -ne 0 ] &amp;amp;&amp;amp; exit&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;2.选项互斥性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;要实现互斥性，只需：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;or_op=`echo &quot;$parameters&quot; | grep -Eo '\-\-add|\-a | \-\-remove|\-r ' | wc -l`
[ &quot;$or_op&quot; = &quot;2&quot; ] &amp;amp;&amp;amp; exit&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;3.识别负数参数&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;前面解释过，getopt提供了两种扫描模式，只要使用&lt;code&gt;+&lt;/code&gt;扫描模式，就能轻松区别负数参数和短选项。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.模式化选项&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一般来说，模式化选项都是命令行的第一个参数。所以，只需将&lt;code&gt;$parameter&lt;/code&gt;中&quot;--&quot;后面的第一个非选项类型的参数提取出来，就是所谓的模式了。当然，还得对这个参数进行一些判断，避免它不是模式参数。&lt;/p&gt;
&lt;p&gt;例如，要提供addr、show、route三种模式，那么其它的非选项类型参数值都不应该是模式参数。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;eval set -- &quot;$parameters&quot;
while true ; do
    case &quot;$1&quot; in
            ...
        --) 
            shift
            [ &quot;$x&quot; = &quot;addr&quot; -o &quot;$x&quot; = &quot;route&quot; -o &quot;$x&quot; = &quot;show&quot; ] &amp;amp;&amp;amp; MODE=$1
            shift
            break ;;
        *) echo &quot;wrong&quot;;exit 1;;
    esac
done&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;5.选项参数替代选项&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;就以&lt;code&gt;-n3&lt;/code&gt;和&lt;code&gt;-3&lt;/code&gt;为例，它的通用格式是&lt;code&gt;-n NUM&lt;/code&gt;和&lt;code&gt;-NUM&lt;/code&gt;。这个并不好实现，我能想到的方法是将这个&lt;code&gt;-NUM&lt;/code&gt;先从&lt;code&gt;$@&lt;/code&gt;中筛选出来，然后赋值。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;NUM=`echo &quot;$@&quot; | grep -Eo &quot;\-[0-9]+&quot;`
ARGS=`echo &quot;$@&quot; | sed -nr 's!(.*)-[0-9]+(.*)!\1\2!'p`
eval set -- &quot;$ARGS&quot;&lt;/code&gt;
&lt;/pre&gt;


&lt;p&gt;这里提供一个和seq命令功能相同的脚本seq.sh，然后设计这个脚本的选项。&lt;/p&gt;
&lt;p&gt;先看一下seq命令的各个选项说明：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;seq [OPTION]... LAST                  # 语法1
seq [OPTION]... FIRST LAST            # 语法2
seq [OPTION]... FIRST INCREMENT LAST  # 语法3

选项：
-s, --separator=STRING
使用指定的STRING分隔各数值，默认值为&quot;\n&quot;u

-w, --equal-width
使用0填充在前缀使所有数值长度相同

--help
显示帮助信息并退出

--version
输出版本信息并退出&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以下是脚本内容：和seq相比，只有两个问题：第一个起点数值FIRST不能为负数；不支持小数功能。其它功能完全相同&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;#!/usr/bin/env bash
###########################################################
#  author     : 骏马金龙                                   #
#  blog       : http://www.cnblogs.com/f-ck-need-u/       #
###########################################################

usage(){
cat &amp;lt;&amp;lt;'EOF'
Usage: $0 [OPTION]... LAST
  or:  $0 [OPTION]... FIRST LAST
  or:  $0 [OPTION]... FIRST INCREMENT LAST
EOF
}

# getopt的版本是增强版吗
getopt -T &amp;amp;&amp;gt;/dev/null;[ $? -ne 4 ] &amp;amp;&amp;amp; { echo &quot;not enhanced version&quot;;exit 1; }

# 参数解析
parameters=`getopt -o +s:w --long separator:,equal-width,help,version -n &quot;$0&quot; -- &quot;$@&quot;`
[ $? -ne 0 ] &amp;amp;&amp;amp; { echo &quot;Try '$0 --help' for more information.&quot;; exit 1; }

eval set -- &quot;$parameters&quot;

while true;do
    case &quot;$1&quot; in
        -w|--equal-width) ZERO_PAD=&quot;true&quot;; shift ;;
        -s|--separator) SEPARATOR=$2; shift 2 ;;
        --version) echo &quot;$0 version V1.0&quot;; exit ;;
        --help) usage;exit ;;
        --)
            shift
            FIRST=$1
            INCREMENT=$2
            LAST=$3
            break ;;
        *) usage;exit 1;;
    esac
done


# 用于生成序列数
function seq_func(){

    # 是否要使用printf填充0位？
    [ &quot;x$1&quot; = &quot;xtrue&quot; ] &amp;amp;&amp;amp; zero_pad=&quot;true&quot; &amp;amp;&amp;amp; shift
    
    # 设置first、step、last
    if [ $# -eq 1 ];then
        first=1
        step=1
        last=$1
    elif [ $# -eq 2 ];then
        first=$1
        step=1
        last=$2
    elif [ $# -eq 3 ]; then
        first=$1
        step=$2
        last=$3
    else
        echo &quot;$FUNCNAME: ARGS wrong...&quot;
        exit 1
    fi
    
    # 最后一个要输出的元素及其长度，决定要填充多少个0
    last_output=$[ last - ( last-first ) % step ]
    zero_pad_len=`[ ${#last_output} -gt ${#first} ] &amp;amp;&amp;amp; echo ${#last_output} || echo ${#first}`

    # 生成序列数
    if [ &quot;x$zero_pad&quot; = &quot;xtrue&quot; ];then
        # 填充0
        if [ $step -gt 0 ];then
            # 递增，填充0
            for((i=$first;i&amp;lt;=$last;i+=$step)){
                [ $last_output -eq $i ] &amp;amp;&amp;amp; { printf &quot;%0${zero_pad_len}i\n&quot; &quot;$i&quot;;return; }
                printf &quot;%0${zero_pad_len}i &quot; $i
            }
        else
            # 递减，填充0
            for((i=$first;i&amp;gt;=$last;i+=$step)){
                [ $last_output -eq $i ] &amp;amp;&amp;amp; { printf &quot;%0${zero_pad_len}i\n&quot; &quot;$i&quot;;return; }
                printf &quot;%0${zero_pad_len}i &quot; $i
            }
        fi
    else
        # 不填充0
        if [ $step -gt 0 ];then
            # 递增，不填充0
            for((i=$first;i&amp;lt;=$last;i+=$step)){
                [ $last_output -eq $i ] &amp;amp;&amp;amp; { printf &quot;%i\n&quot; &quot;$i&quot;;return; }
                printf &quot;%i &quot; $i
            }
        else
            # 递减，不填充0
            for((i=$first;i&amp;gt;=$last;i+=$step)){
                [ $last_output -eq $i ] &amp;amp;&amp;amp; { printf &quot;%i\n&quot; &quot;$i&quot;;return; }
                printf &quot;%i &quot; $i
            }
        fi
    fi
}

# 指定输出分隔符
: ${SEPARATOR=&quot;\n&quot;}

# 输出结果
seq_func $ZERO_PAD $SEPARATOR $FIRST $INCREMENT $LAST | tr &quot; &quot; &quot;$SEPARATOR&quot;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面解析选项的脚本缺陷在于无法解析FIRST为负数的情况，例如&lt;code&gt;./seq.sh -w -5 3&lt;/code&gt;将报错。但可以写为标准的&lt;code&gt;./seq.sh -w -- -5 -3&lt;/code&gt;语法。&lt;/p&gt;
</description>
<pubDate>Mon, 08 Oct 2018 16:05:00 +0000</pubDate>
<dc:creator>骏马金龙</dc:creator>
<og:description>man 1 getopt翻译 ：</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/f-ck-need-u/p/9758075.html</dc:identifier>
</item>
<item>
<title>dubbo+zipkin调用链监控(二) - min.jiang</title>
<link>http://www.cnblogs.com/ASPNET2008/p/9757980.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ASPNET2008/p/9757980.html</guid>
<description>&lt;p id=&quot;toc_0&quot;&gt;去年的时候写过&lt;a href=&quot;http://www.cnblogs.com/ASPNET2008/p/6709900.html&quot;&gt;dubbo+zipkin调用链监控&lt;/a&gt;,最近看到zipkin2配合brave实现起来会比我之前的实现要简单很多，因为brave将很多交互的内容都封装起来了，不需要自己去写具体的实现，比如如何去构建span，如何去上报数据。&lt;/p&gt;
&lt;h2 id=&quot;toc_1&quot;&gt;收集器抽象&lt;/h2&gt;
&lt;p&gt;由于zipkin支持http以及kafka两种方式上报数据，所以在配置上需要做下抽象。&lt;/p&gt;
&lt;h3 id=&quot;toc_2&quot;&gt;AbstractZipkinCollectorConfiguration&lt;/h3&gt;
&lt;p&gt;主要是针对下面两种收集方式的一些配置上的定义，最核心的是Sender接口的定义，http与kafka是两类完全不同的实现。&lt;/p&gt;
&lt;div readability=&quot;7&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public abstract Sender getSender();&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其次是协助性的构造函数，主要是配合构建收集器所需要的一些参数。&lt;/p&gt;
&lt;p&gt;如果是http收集，那么对应的是zipkin api域名，如果是kafka，对应的是kafka集群的地址&lt;/p&gt;
&lt;p&gt;仅在收集方式为kafka是有效，http时传空值即可。&lt;/p&gt;
&lt;div readability=&quot;10&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public AbstractZipkinCollectorConfiguration(String serviceName,String zipkinUrl,String topic){
    this.zipkinUrl=zipkinUrl;
    this.serviceName=serviceName;
    this.topic=topic;
    this.tracing=this.tracing();
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;配置上报方式,这里统一采用异常上传，并且配置上报的超时时间。&lt;/p&gt;
&lt;div readability=&quot;9&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;protected AsyncReporter&amp;lt;Span&amp;gt; spanReporter() {
    return AsyncReporter
            .builder(getSender())
            .closeTimeout(500, TimeUnit.MILLISECONDS)
            .build(SpanBytesEncoder.JSON_V2);
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;下面这两方法，是配合应用构建span使用的。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;注意那个sampler()方法，默认是什么也不做的意思，我们要想看到数据就需要配置成Sampler.ALWAYS_SAMPLE，这样才能真正将数据上报到zipkin服务器。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div readability=&quot;9&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;protected Tracing tracing() {
    this.tracing= Tracing
            .newBuilder()
            .localServiceName(this.serviceName)
            .sampler(Sampler.ALWAYS_SAMPLE)
            .spanReporter(spanReporter())
            .build();
    return this.tracing;
}

protected Tracing getTracing(){
    return this.tracing;
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;toc_3&quot;&gt;HttpZipkinCollectorConfiguration&lt;/h3&gt;
&lt;p&gt;主要是实现getSender方法，可以借用OkHttpSender这个对象来快速构建，api版本采用v2。&lt;/p&gt;
&lt;div readability=&quot;13&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class HttpZipkinCollectorConfiguration extends AbstractZipkinCollectorConfiguration {
    public HttpZipkinCollectorConfiguration(String serviceName,String zipkinUrl) {
        super(serviceName,zipkinUrl,null);
    }

    @Override
    public Sender getSender() {
        return OkHttpSender.create(super.getZipkinUrl()+&quot;/api/v2/spans&quot;);
    }
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;OkHttpSender这个类需要引用这个包&lt;/p&gt;
&lt;div readability=&quot;8&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-markup&quot;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;io.zipkin.reporter2&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;zipkin-sender-okhttp3&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${zipkin-reporter2.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;toc_4&quot;&gt;KafkaZipkinCollectorConfiguration&lt;/h3&gt;
&lt;p&gt;同样也是实现getSender方法&lt;/p&gt;
&lt;div readability=&quot;14&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public class KafkaZipkinCollectorConfiguration extends AbstractZipkinCollectorConfiguration {
    public KafkaZipkinCollectorConfiguration(String serviceName,String zipkinUrl,String topic) {
        super(serviceName,zipkinUrl,topic);
    }

    @Override
    public Sender getSender() {

        return KafkaSender
                .newBuilder()
                .bootstrapServers(super.getZipkinUrl())
                .topic(super.getTopic())
                .encoding(Encoding.JSON)
                .build();
    }
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;KafkaSender这个类需要引用这个包：&lt;/p&gt;
&lt;div readability=&quot;8&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-markup&quot;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;io.zipkin.reporter2&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;zipkin-sender-kafka11&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${zipkin-reporter2.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;toc_5&quot;&gt;收集器工厂&lt;/h2&gt;
&lt;p&gt;由于上面创建了两个收集器配置类，使用时只能是其中之一，所以实际运行的实例需要根据配置来动态生成。ZipkinCollectorConfigurationFactory就是负责生成收集器实例的。&lt;/p&gt;
&lt;div readability=&quot;14&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;private final AbstractZipkinCollectorConfiguration zipkinCollectorConfiguration;

@Autowired
public ZipkinCollectorConfigurationFactory(TraceConfig traceConfig){
    if(Objects.equal(&quot;kafka&quot;, traceConfig.getZipkinSendType())){
        zipkinCollectorConfiguration=new KafkaZipkinCollectorConfiguration(
                traceConfig.getApplicationName(),
                traceConfig.getZipkinUrl(),
                traceConfig.getZipkinKafkaTopic());
    }
    else {
        zipkinCollectorConfiguration = new HttpZipkinCollectorConfiguration(
                traceConfig.getApplicationName(),
                traceConfig.getZipkinUrl());
    }
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通过构建函数将我们的配置类TraceConfig注入进来，然后根据发送方式来构建实例。另外提供一个辅助函数：&lt;/p&gt;
&lt;div readability=&quot;7&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public Tracing getTracing(){
    return this.zipkinCollectorConfiguration.getTracing();
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;toc_6&quot;&gt;过滤器&lt;/h2&gt;
&lt;p&gt;在dubbo的过滤器中实现数据上传的功能逻辑相对简单，一般都在invoke方法执行前记录数据，然后方法执行完成后再次记录数据。这个逻辑不变，有变化的是数据上报的实现，上一个版本是通过发http请求实现需要编码，现在可以直接借用brave所提供的span来帮助我们完成，有两重要的方法:&lt;/p&gt;
&lt;p&gt;方法源码如下，在完成的时候会填写上完成的时间并上报数据，这一般应用于同步调用场景。&lt;/p&gt;
&lt;div readability=&quot;10&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public void finish(TraceContext context, long finishTimestamp) {
    MutableSpan span = this.spanMap.remove(context);
    if(span != null &amp;amp;&amp;amp; !this.noop.get()) {
        synchronized(span) {
            span.finish(Long.valueOf(finishTimestamp));
            this.reporter.report(span.toSpan());
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;&lt;li&gt;flush 与上面finish方法的不同点在于，在报数据时没有完成时间，这应该是适用于一些异步调用但不关心结果的场景，比如dubbo所提供的oneway方式调用。&lt;/li&gt;
&lt;/ul&gt;&lt;div readability=&quot;9&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;public void flush(TraceContext context) {
    MutableSpan span = this.spanMap.remove(context);
    if(span != null &amp;amp;&amp;amp; !this.noop.get()) {
        synchronized(span) {
            span.finish((Long)null);
            this.reporter.report(span.toSpan());
        }
    }
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;toc_7&quot;&gt;消费者&lt;/h3&gt;
&lt;p&gt;做为消费方，有一个核心功能就是将traceId以及spanId传递到服务提供方，这里还是通过dubbo提供的附加参数方式实现。&lt;/p&gt;
&lt;div readability=&quot;13&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Override
public Result invoke(Invoker&amp;lt;?&amp;gt; invoker, Invocation invocation) throws RpcException {
    if(!RpcTraceContext.getTraceConfig().isEnabled()){
        return invoker.invoke(invocation);
    }

    ZipkinCollectorConfigurationFactory zipkinCollectorConfigurationFactory=
            SpringContextUtils.getApplicationContext().getBean(ZipkinCollectorConfigurationFactory.class);
    Tracer tracer= zipkinCollectorConfigurationFactory.getTracing().tracer();

    if(null==RpcTraceContext.getTraceId()){
        RpcTraceContext.start();
        RpcTraceContext.setTraceId(IdUtils.get());
        RpcTraceContext.setParentId(null);
        RpcTraceContext.setSpanId(IdUtils.get());
    }
    else {
        RpcTraceContext.setParentId(RpcTraceContext.getSpanId());
        RpcTraceContext.setSpanId(IdUtils.get());
    }
    TraceContext traceContext= TraceContext.newBuilder()
            .traceId(RpcTraceContext.getTraceId())
            .parentId(RpcTraceContext.getParentId())
            .spanId(RpcTraceContext.getSpanId())
            .sampled(true)
            .build();

    Span span=tracer.toSpan(traceContext).start();

    invocation.getAttachments().put(RpcTraceContext.TRACE_ID_KEY, String.valueOf(span.context().traceId()));
    invocation.getAttachments().put(RpcTraceContext.SPAN_ID_KEY, String.valueOf(span.context().spanId()));

    Result result = invoker.invoke(invocation);

    span.finish();

    return result;
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;toc_8&quot;&gt;提供者&lt;/h3&gt;
&lt;div readability=&quot;12&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;@Override
    public Result invoke(Invoker&amp;lt;?&amp;gt; invoker, Invocation invocation) throws RpcException {
        if(!RpcTraceContext.getTraceConfig().isEnabled()){
            return invoker.invoke(invocation);
        }

        Map&amp;lt;String, String&amp;gt; attaches = invocation.getAttachments();
        if (!attaches.containsKey(RpcTraceContext.TRACE_ID_KEY)){
            return invoker.invoke(invocation);
        }

        Long traceId = Long.valueOf(attaches.get(RpcTraceContext.TRACE_ID_KEY));
        Long spanId = Long.valueOf(attaches.get(RpcTraceContext.SPAN_ID_KEY));

        attaches.remove(RpcTraceContext.TRACE_ID_KEY);
        attaches.remove(RpcTraceContext.SPAN_ID_KEY);
        RpcTraceContext.start();
        RpcTraceContext.setTraceId(traceId);
        RpcTraceContext.setParentId(spanId);
        RpcTraceContext.setSpanId(IdUtils.get());

        ZipkinCollectorConfigurationFactory zipkinCollectorConfigurationFactory=
                SpringContextUtils.getApplicationContext().getBean(ZipkinCollectorConfigurationFactory.class);
        Tracer tracer= zipkinCollectorConfigurationFactory.getTracing().tracer();

        TraceContext traceContext= TraceContext.newBuilder()
                .traceId(RpcTraceContext.getTraceId())
                .parentId(RpcTraceContext.getParentId())
                .spanId(RpcTraceContext.getSpanId())
                .sampled(true)
                .build();
        Span span = tracer.toSpan(traceContext).start();

        Result result = invoker.invoke(invocation);

        span.finish();

        return result;

    }&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;toc_9&quot;&gt;异常流程&lt;/h3&gt;
&lt;p&gt;上面无论是消费者的过滤器还是服务提供者的过滤器，均未考虑服务在调用invoker.invoke时出错的场景，如果出错，后面的span.finish方法将不会按预期执行，也就记录不了信息。所以需要针对此问题做优化：可以在finally块中执行finish方法。&lt;/p&gt;
&lt;div readability=&quot;7&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;try {
    result = invoker.invoke(invocation);
}
finally {
    span.finish();
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;toc_10&quot;&gt;消费者在调用服务时，异步调用问题&lt;/h3&gt;
&lt;p&gt;上面过滤器中调用span.finish都是基于同步模式，而由于dubbo除了同步调用外还提供了两种调用方式&lt;/p&gt;
&lt;p&gt;只发起请求并不等待结果的异步调用，无callback一说&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;针对上面两类异步再加上同步调用，我们要想准确记录服务真正的时间，需要在消费方的过滤器中做如下处理：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;创建一个用于回调的处理类，它的主要目的是为了在回调成功时记录时间，这里无论是成功还是失败。&lt;/p&gt;
&lt;div readability=&quot;9&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;private class AsyncSpanCallback implements ResponseCallback{

    private Span span;

    public AsyncSpanCallback(Span span){
        this.span=span;
    }

    @Override
    public void done(Object o) {
        span.finish();
    }

    @Override
    public void caught(Throwable throwable) {
        span.finish();
    }
}
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;再在调用invoke方法时,如果是oneway方式，则调用flush方法结果，如果是同步则直接调用finish方法，如果是异步则在回调时调用finish方法。&lt;/p&gt;
&lt;div readability=&quot;10&quot;&gt;
&lt;pre&gt;
&lt;code class=&quot;language-java&quot;&gt;
Result result = null;
boolean isOneway = RpcUtils.isOneway(invoker.getUrl(), invocation);
try {
    result = invoker.invoke(invocation);
}
finally {
    if(isOneway) {
        span.flush();
    }
    else if(!isAsync) {
        span.finish();
    }
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;toc_11&quot;&gt;待完善问题&lt;/h2&gt;
&lt;p&gt;过滤器中生成span的方式应该有更好的方法，还没有对brave做过多研究，后续想办法再优化下。另外我测试的场景是consumer调用provider，provider内部再调用provider2，我测试时发现第三步调用传递的parentId好像有点小问题，后续需要再确认下。&lt;/p&gt;
&lt;h2&gt;代码下载&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/jiangmin168168/jim-framework&quot;&gt;https://github.com/jiangmin168168/jim-framework&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 08 Oct 2018 15:32:00 +0000</pubDate>
<dc:creator>min.jiang</dc:creator>
<og:description>去年的时候写过dubbo+zipkin调用链监控,最近看到zipkin2配合brave实现起来会比我之前的实现要简单很多，因为brave将很多交互的内容都封装起来了，不需要自己去写具体的实现，比如如何</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/ASPNET2008/p/9757980.html</dc:identifier>
</item>
<item>
<title>结对编程总结+git使用与GitHub代码管理——by林玉俊&amp;唐宇涵 - pigeon唐</title>
<link>http://www.cnblogs.com/pigeontang/p/9757990.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/pigeontang/p/9757990.html</guid>
<description>
&lt;p&gt;&lt;span&gt;&lt;strong&gt;一、分析需求&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　在拿到结对编程项目需求文档后，我和队友第一件事就是讨论需求，分析项目给出的需求以及实现的一些细节。比如，登录界面的设置（注册、重置、登录按钮），注册界面的输入框设置（手机号、验证码、密码、确认密码），题目难度和数量界面的设置等这些逻辑流程问题。并大致对各个类需要实现的功能和接口进行了商定，这样方便了后期的合拢。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　下图为当时讨论时的笔记——&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008231001745-1685677378.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;二、编程实现&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　我负责的是用户手机注册并发送验证码到相应手机号部分和随机算式计算结果部分。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;EN-US&quot;&gt;1、接收验证码部分&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　最初是根据老师给的提示，在阿里云平台中申请短信服务，但短信签名的申请过程非常非常非常不顺利，总是因各种理由未通过，几经修改也无济于事。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008231107789-1565798401.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008231114200-971898395.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　后来便开始寻找其他平台，看是否能够申请到他们的短信签名。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;EN-US&quot;&gt;       其中，百度云、腾讯云、凌凯这三家平台成为了我们的第二条路。但是凌凯虽然稳定且老牌，但他不针对个人用户，而是面对高校、企业等有大规模发送短信需求的用户，虽然其有十分成熟的短信验证码功能，但我们因无资质只能放弃；百度云更是直接&lt;span lang=&quot;EN-US&quot;&gt;pass，因为其短信业务的开通需要公司执照，直接将我们扔出了门外。所幸，随后腾讯云给了我们一条生路。在开通了公众号后，成功通过了短信签名和短信正文模板的申请。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008231141973-421724608.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008231159962-1836255622.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008231210690-1758165240.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008231220114-2032557012.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;至此，我们得到了发送短信验证码的关键参数，并根据腾讯云提供的&lt;span lang=&quot;EN-US&quot;&gt;java API模板在完成参数配置后实现了向用户注册手机号发送短信验证码的功能。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008231248417-1232596317.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008231306768-444117205.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;EN-US&quot;&gt;2、随机算式计算部分&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　引用队友之前随机算式生成部分，随机算式计算类&lt;span lang=&quot;EN-US&quot;&gt;Calculater传入随机生成的&lt;span lang=&quot;EN-US&quot;&gt;String型算式，输出&lt;span lang=&quot;EN-US&quot;&gt;float型运算结果。运算过程中对“（”、“&lt;span lang=&quot;EN-US&quot;&gt;+”、“&lt;span lang=&quot;EN-US&quot;&gt;-”、“×”、“÷”、“）”、“&lt;span lang=&quot;EN-US&quot;&gt;=”这些操作符进行优先级的定义，并按照优先级分别将操作符和操作符左右的数字压入栈中。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;EN-US&quot;&gt;       下图为对操作符的优先级定义——&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008231347727-794430542.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　为了简化运算过程，我们对算式先进行了一些处理，将三角函数和平方开方部分先算出结果，将结果替换到原来的位置。在这里我最开始运用的是&lt;span lang=&quot;EN-US&quot;&gt;for循环将结果和原字符串位置进行移位，以达到替换的效果。但当平方数为&lt;span lang=&quot;EN-US&quot;&gt;10&lt;sup&gt;2&lt;/sup&gt;以上时这里就会出现字符串溢出的问题，所以我的队友提出了使用&lt;span lang=&quot;EN-US&quot;&gt;StringBuilder中的&lt;span lang=&quot;EN-US&quot;&gt;replace方法实现对字符串的替换并帮助我进行了修改，在这里感谢大佬援手。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　下图为对算式的提前处理部分——&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008231419473-2081635015.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008231432011-570793881.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span lang=&quot;EN-US&quot;&gt;Attention：在这里，我要向大家隆重介绍一个函数——&lt;span lang=&quot;EN-US&quot;&gt;eval()&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　这是多么神奇的一个函数呢，大概就是让我之前花在处理栈空错误的大把时间变成&lt;span lang=&quot;EN-US&quot;&gt;0。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　在抛出异常处理后，输入包含括号、数字（含小数）、&lt;span lang=&quot;EN-US&quot;&gt;+-×÷操作符的标准四则运算表达式后，一个回车便可计算出&lt;span lang=&quot;EN-US&quot;&gt;double类型的结果，可谓十分方便了……&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;　　实现如下——&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008231544444-463916419.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008231548402-125811548.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;三、合拢测试&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;       &lt;span&gt;在最后的合拢测试部分，随着测试次数的增多，很多&lt;span lang=&quot;EN-US&quot;&gt;bug也接连出现，再次感谢大佬&lt;span lang=&quot;EN-US&quot;&gt;carry，修改了如闪退、输入空、总分错误等&lt;span lang=&quot;EN-US&quot;&gt;bug。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008232050548-332712235.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span&gt;&lt;strong&gt;四、使用git以及GitHub进行代码管理&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;　　&lt;span&gt;在&lt;span lang=&quot;EN-US&quot;&gt;Java IDE中包含了&lt;span lang=&quot;EN-US&quot;&gt;git以及&lt;span lang=&quot;EN-US&quot;&gt;Github的功能整合，以&lt;span lang=&quot;EN-US&quot;&gt;IntelliJ IDEA为例，在“&lt;span lang=&quot;EN-US&quot;&gt;VCS-import into version control”里面可以通过&lt;span lang=&quot;EN-US&quot;&gt;”Create git repository”来创建项目的&lt;span lang=&quot;EN-US&quot;&gt;git：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008232133234-1910260788.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　&lt;span&gt;　然后就可以看到左下方出现了一个&lt;span lang=&quot;EN-US&quot;&gt;”Version control”的标签：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008232158486-560022354.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;可以通过&lt;span lang=&quot;EN-US&quot;&gt;commit来记录自己所做的更改。之后便会在“&lt;span lang=&quot;EN-US&quot;&gt;Version control”的“&lt;span lang=&quot;EN-US&quot;&gt;log”里面看到自己的&lt;span lang=&quot;EN-US&quot;&gt;commit了：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008232221107-1393988547.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;那么&lt;span lang=&quot;EN-US&quot;&gt;git有什么用呢？在本地工程中通过&lt;span lang=&quot;EN-US&quot;&gt;commit可以记录文件的改动，然后决定是否需要回退。可以设置分支来添加新功能，在功能可以实现时再将分支合并。而且，&lt;span lang=&quot;EN-US&quot;&gt;git可以将代码上传到&lt;span lang=&quot;EN-US&quot;&gt;GitHub上面，在“&lt;span lang=&quot;EN-US&quot;&gt;VCS-import into version control”里面通过&lt;span lang=&quot;EN-US&quot;&gt;”Share project on Github”来上传项目到自己的&lt;span lang=&quot;EN-US&quot;&gt;GitHub账户上，那么队友即使不在身边也可以让他&lt;span lang=&quot;EN-US&quot;&gt;/她通过&lt;span lang=&quot;EN-US&quot;&gt;GitHub来时刻获取代码的最新状态了。当你想要上传更改时，可以通过“&lt;span lang=&quot;EN-US&quot;&gt;push”命令来执行：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008232254013-1492347302.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;如果自己的项目是克隆自别人的&lt;span lang=&quot;EN-US&quot;&gt;GitHub仓库，可以通过“&lt;span lang=&quot;EN-US&quot;&gt;pull”指令获取项目的最新状态。如果上传了项目，那么就可以再&lt;span lang=&quot;EN-US&quot;&gt;GitHub的个人主页上看到了，而且也是会记录自己的项目历史的：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;span lang=&quot;EN-US&quot;&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008232319014-1999028080.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span&gt;&lt;strong&gt;五、以下为运行截图&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span&gt;登录界面——&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008232403880-1543624598.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span&gt;注册界面——&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008232423977-1273207571.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span&gt;当密码不符要求时——&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008232440993-1154302020.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span&gt;题目难度选择界面——&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008232457270-1823666831.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span&gt;题目数量设定界面——&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008232518311-2137702156.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span&gt;答题界面——&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008232536640-1002409352.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span&gt;分数显示界面——&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/1493358/201810/1493358-20181008232553293-54793030.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

</description>
<pubDate>Mon, 08 Oct 2018 15:31:00 +0000</pubDate>
<dc:creator>pigeon唐</dc:creator>
<og:description>一、分析需求 在拿到结对编程项目需求文档后，我和队友第一件事就是讨论需求，分析项目给出的需求以及实现的一些细节。比如，登录界面的设置（注册、重置、登录按钮），注册界面的输入框设置（手机号、验证码、密码</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/pigeontang/p/9757990.html</dc:identifier>
</item>
<item>
<title>php7新特性 - 尼古拉斯凯光</title>
<link>http://www.cnblogs.com/guangye/p/9661164.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/guangye/p/9661164.html</guid>
<description>&lt;p&gt; &lt;strong&gt;&lt;span&gt;一、前言&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　php7目前（截止2018-09-17），最新的稳定版本是7.2.10（http://php.net/downloads.php上可查看版本信息），目前还有不少项目是用5.6甚至更早的版本。相比于php5.x的版本，php7有不少新的改进，性能方面也是有不少提升。下面来详细讲下。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;二、新特性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;1、php7.0相比于php5.6的新特性&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;参考：http://php.net/manual/zh/migration70.new-features.php 下面所讲的内容都是来自于这篇文章，只是详细地解释。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.1  标量类型声明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;函数/方法中的参数，是可以加一个类型声明的，这个是php5.0就开始支持的，比如：&lt;/p&gt;
&lt;p&gt;function testClass(类名 $c)&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;function testArray(array $a)&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;php5.x支持的这个类型不多，php7增加了几个：&lt;/p&gt;
&lt;p&gt;参考：http://php.net/manual/zh/functions.arguments.php#functions.arguments.type-declaration&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/732423/201809/732423-20180917121142445-353654557.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里的意思是，方法的参数的类型，只支持上面列出的这些类型，如果是其他类型，php5报错致命错误，php7会报错TypeError的异常。&lt;/p&gt;
&lt;p&gt;举个例子：&lt;/p&gt;
&lt;p&gt;function test (boolean $b)&lt;/p&gt;
&lt;p&gt;{&lt;/p&gt;
&lt;p&gt;}&lt;/p&gt;
&lt;p&gt;test(true);&lt;/p&gt;
&lt;p&gt;执行结果：&lt;/p&gt;
&lt;pre&gt;
 Fatal error: Uncaught TypeError: Argument 1 passed to test() must be an instance of boolean, boolean given, called in - on line 1 and defined in -:1
&lt;/pre&gt;
&lt;p&gt;这里报错的原因是参数类型boolean不是一个合法的类型，上面截图中可以看到是bool才对，不能用boolean。这里有点不好理解，就是我们大多会认为boolean就是bool，所以这里应该是规定好的，就是只能用bool，不能用boolean。&lt;/p&gt;
&lt;p&gt;同理，用integer也是错的，要用int。 float是包含了float和double的，如果用double也是会报错的。再解释下，用boolean的时候，因为不是bool，也不是int、float、self、array等，所以这个boolean会被认为是class或者interface，&lt;/p&gt;
&lt;p&gt;报错信息里面展示的是参数必须是boolean（类或接口）的一个实例，但是调用时传入的参数是boolean类型（true的类型）。有点绕，但是应该不难理解。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.2 返回值类型声明&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/732423/201810/732423-20181008222001982-1625982837.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;返回值的类型，跟参数的类型一致。&lt;/p&gt;
&lt;p&gt; 【注意】在默认情况下，函数返回值如果和定义的不一致，会进行强制转换，在严格模式下，则会报错TypeError。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/732423/201810/732423-20181008222226568-1014255161.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这个例子这里是强制转换了类型。&lt;/p&gt;
&lt;p&gt; 函数返回值的说明参考：http://php.net/manual/zh/functions.returning-values.php#functions.returning-values.type-declaration&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.3 null合并运算符&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/732423/201810/732423-20181008223300640-268279448.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;1.4 太空船操作符&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;（暂时不清楚这个操作符有什么实际用处，后续了解清楚再补充上）&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/732423/201810/732423-20181008223758960-328951545.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt; 1.5 define允许定义常量数组&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/732423/201810/732423-20181008224103302-1482762825.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt; 我们来看下define的声明，参考：http://php.net/manual/zh/function.define.php&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/732423/201810/732423-20181008224153173-488404657.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这个新特性大概是为了丰富define的功能，const已经实现了这个功能了的。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.6 匿名类&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/732423/201810/732423-20181008225415920-484268121.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;详细的匿名类参考：http://php.net/manual/zh/language.oop5.anonymous.php&lt;/p&gt;

&lt;p&gt;【备注】考虑到篇幅问题，先跳过中间几个个人觉得不太常用的特性&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; 1.7 use分组命名空间&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/732423/201810/732423-20181008230021723-1859947719.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这里可以用一行代码引入同一个命名空间下的多个类，而不是之前那样需要每个类一行代码，算是一种优化。&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/732423/201810/732423-20181008232047476-386706921.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.8 新增整数整除的函数inidiv()&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/732423/201810/732423-20181008230236995-251317379.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;返回值为整型。&lt;/p&gt;
&lt;p&gt;参考：http://php.net/manual/zh/function.intdiv.php&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;1.9 新增的随机函数&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://img2018.cnblogs.com/blog/732423/201810/732423-20181008230547793-801639618.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;p&gt;http://php.net/manual/zh/function.random-bytes.php&lt;/p&gt;
&lt;p&gt;http://php.net/manual/zh/function.random-int.php&lt;/p&gt;


&lt;p&gt;&lt;span&gt;&lt;strong&gt;2、php7.1相对于php7.0的新特性&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;参考：http://php.net/manual/zh/migration71.new-features.php&lt;/p&gt;
&lt;p&gt;涉及的内容不多，直接看上面的url即可。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;3、php7.2相对于php7.1的新特性&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;参考：http://php.net/manual/zh/migration72.new-features.php&lt;/p&gt;
&lt;p&gt;涉及的内容不多，直接看上面的url即可。&lt;/p&gt;

</description>
<pubDate>Mon, 08 Oct 2018 15:23:00 +0000</pubDate>
<dc:creator>尼古拉斯凯光</dc:creator>
<og:description>一、前言 php7目前（截止2018-09-17），最新的稳定版本是7.2.10（http://php.net/downloads.php上可查看版本信息），目前还有不少项目是用5.6甚至更早的版本。</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/guangye/p/9661164.html</dc:identifier>
</item>
<item>
<title>Promise原理讲解 async+await应用（异步回调解决方案） - IT-caijw</title>
<link>http://www.cnblogs.com/caijw/p/9757916.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/caijw/p/9757916.html</guid>
<description>&lt;h4 id=&quot;异步编程&quot;&gt;1.异步编程&lt;/h4&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;在&lt;code&gt;JavaScript&lt;/code&gt;的世界中，所有代码都是&lt;code&gt;单线&lt;/code&gt;执行的。 由于这个“缺陷”，导致&lt;code&gt;JavaScript&lt;/code&gt;的所有网络操作，浏览器事件，都必须是异步执行。异步执行可以用:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;&lt;li&gt;回调函数&lt;/li&gt;
&lt;li&gt;发布订阅&lt;/li&gt;
&lt;li&gt;观察者模式&lt;/li&gt;
&lt;li&gt;promise&lt;/li&gt;
&lt;/ul&gt;&lt;hr/&gt;&lt;h5 id=&quot;回调函数&quot;&gt;1.1.回调函数&lt;/h5&gt;
&lt;pre&gt;
&lt;code&gt;function call(id, callback){
  return function(){
     callback(id+1);
  }
}
let fn = call(3, function(id){
  console.log(id);
})
fn();&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;lodash 里面的after函数实现方法&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function after(times, callback){
  return function(){
    //次数一直减少
    if(--times == 0){
      callback();
    }
  }
}
let fn = after(3, function(){
  console.log('after 被调用了三次');
})
fn();
fn();
fn();&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;接下来就是常见的读取数据的问题，回调函数的话，我们只能一层一层往下读取，很容易就进入了&lt;code&gt;回调地狱&lt;/code&gt;这个可怕的状态&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;let fs = require('fs');
let school = {}
fs.readFile('./age.txt', 'utf8', function (err, data) {
    school['name'] = data;
    fs.readFile('./name.txt', 'utf8', function (err, data) {
      school['age'] = data;//{ name: 'cjw', age: '18' }
    });
});
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;发布订阅&quot;&gt;1.2 发布订阅&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;发布者和订阅者是没有依赖关系的&lt;/code&gt;&lt;/p&gt;&lt;p&gt;你可能对发布订阅有点陌生，其实只要在DOM节点上面绑定过事件函数，那就使用过发布—订阅模式。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;document.body.addEventListener('click',function(){
  alert(2);
},false);
document.body.click();    //模拟用户点击&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;实现原理&lt;/code&gt;&lt;/p&gt;&lt;p&gt;首先用一个数组arr保存回调函数，然后触发emit的时候，arr里面的回调函数一一执行&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;let fs = require('fs');

let dep = {
    arr: [],//保存回调函数
    on(callback){
        this.arr.push(callback);
    },
    emit(){
        this.arr.forEach(item=&amp;gt;{
            item();
        })
    }
}

let school = {};
//这里先加一个回调函数 (订阅)
dep.on(function(){
    if(Object.keys(school).length === 2){
        console.log(school);//{ name: 'cjw', age: '18' }
    }
})
//
fs.readFile('./age.txt', 'utf8', function(err, data){
    school['name'] = data;
    dep.emit();//发布,调用dep.arr 里面的回调函数一一执行
})
fs.readFile('./name.txt', 'utf8', function(err, data){
    school['age'] = data;
    dep.emit();//发布
})
&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;观察者模式&quot;&gt;1.3 观察者模式&lt;br/&gt;&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;观察者模式 发布和订阅的 被观察者是依赖于观察者的&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;//观察者
class Observer{
    constructor(){
        this.arr = [];
        this.val = 1;
    }
    updateVal(val){
        this.val = val;
        this.notify();
    }
    notify(){
        this.arr.forEach(s=&amp;gt;s.update());
    }
    save(s){//保存一个对象
        this.arr.push(s);
    }
}
// 被观察者，被观察者有一个更新的方法。
class Subject{
    update(){
        console.log('update')
    }
}
let s = new Subject();
let observer = new Observer();
observer.save(s);//保存一个对象
observer.save(s);
observer.updateVal(21);//更新值的时候，被观察者也执行一个更新的方法&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;promise&quot;&gt;1.4 Promise&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;promise&lt;/code&gt;有以下两个特点:&lt;/p&gt;&lt;p&gt;&lt;code&gt;1&lt;/code&gt;.对象的状态不受外界影响。&lt;code&gt;Promise&lt;/code&gt;对象代表一个异步操作，有三种状态：&lt;code&gt;pending&lt;/code&gt;（进行中）、&lt;code&gt;fulfilled&lt;/code&gt;（已成功）和&lt;code&gt;rejected&lt;/code&gt;（已失败）。只有异步操作的结果，可以决定当前是哪一种状态，任何其他操作都无法改变这个状态。这也是Promise这个名字的由来，它的英语意思就是“承诺”，表示其他手段无法改变。&lt;/p&gt;&lt;p&gt;&lt;code&gt;2&lt;/code&gt;.一旦状态改变，就不会再变，任何时候都可以得到这个结果。&lt;code&gt;Promise&lt;/code&gt;对象的状态改变，只有两种可能：从&lt;code&gt;pending&lt;/code&gt;变为&lt;code&gt;fulfilled&lt;/code&gt;和从&lt;code&gt;pending&lt;/code&gt;变为&lt;code&gt;rejected&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;let fs = require('fs');
function read(url){
    return new Promise((resolve, reject)=&amp;gt;{
        fs.readFile(url, 'utf8', (err, data)=&amp;gt;{
            if(err) reject(err);
            resolve(data);
        })
    })
}
let school = {};
read('./name.txt').then(data=&amp;gt;{
    school['name'] = data;
    return read('age.txt');
}).then(data=&amp;gt;{
    school['age'] = data;
    console.log(school);//{ name: 'cjw', age: '18' }
})&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;promise用法与原理&quot;&gt;2.promise用法与原理&lt;/h4&gt;
&lt;h5 id=&quot;promise.prototype.then&quot;&gt;2.1 &lt;code&gt;Promise.prototype.then()&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;Promise&lt;/code&gt; 实例具有&lt;code&gt;then&lt;/code&gt;方法，也就是说，&lt;code&gt;then&lt;/code&gt;方法是定义在原型对象&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;//let Promise = require('./promise.js');
let p = new Promise((resolve, reject)=&amp;gt;{
    setTimeout(function(){     
        reject('成功');
    },100)
    reject('3');
})
p.then((value)=&amp;gt;{
    console.log(value);//3,这里是3因为，只能从一个状态panding到另一个状态
}, (reason)=&amp;gt;{
    console.log(reason);
})&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;基本概念&lt;/code&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;1.&lt;code&gt;new Promise&lt;/code&gt;时需要传递一个&lt;code&gt;executor&lt;/code&gt;执行器,执行器会立刻执行&lt;/p&gt;&lt;p&gt;2.执行器中传递了两个参数 &lt;code&gt;resolve&lt;/code&gt;成功的函数 他调用时可以传一个值 值可以是任何值 &lt;code&gt;reject&lt;/code&gt;失败的函数 他调用时可以传一个值 值可以是任何值&lt;/p&gt;&lt;p&gt;3.只能从&lt;code&gt;pending&lt;/code&gt;态转到成功或者失败&lt;/p&gt;&lt;p&gt;4.&lt;code&gt;promise&lt;/code&gt;实例。每个实例都有一个&lt;code&gt;then&lt;/code&gt;方法，这个方法传递两个参数，一个是成功另一个是失败&lt;/p&gt;&lt;p&gt;5.如果调用&lt;code&gt;then&lt;/code&gt;时 发现已经成功了会让成功函数执行并且把成功的内容当作参数传递到函数中&lt;/p&gt;&lt;p&gt;6.&lt;code&gt;promise&lt;/code&gt; 中可以同一个实例&lt;code&gt;then&lt;/code&gt;多次,如果状态是&lt;code&gt;pengding&lt;/code&gt;需要将函数存放起来 等待状态确定后 在依次将对应的函数执行 (发布订阅)&lt;/p&gt;&lt;p&gt;7.如果类执行时出现了异常 那就变成失败态&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Promise.prototype.then()&lt;/code&gt;的实现&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function Promise(executor){
    var self = this;
    self.status = 'pending';//从pending 转换为resolved rejected
    self.value = undefined;
    self.reason = undefined;
    self.onResolved = [];//专门存放成功的回调
    self.onRejected = [];//专门存放失败的回调
    //pending -&amp;gt; resolved
    function resolve(value){
        if(self.status === 'pending'){
            self.value = value;
            self.status = 'resolved';
            self.onResolved.forEach(fn=&amp;gt;fn());
        }
    }
     //pending -&amp;gt; rejected
    function reject(reason){
        if(self.status === 'pending'){
            self.reason = reason;
            self.status = 'rejected';
            self.onRejected.forEach(fn=&amp;gt;fn());
        }
    }
    try{
        executor(resolve, reject);
    }catch(e){
        reject(e);
    }
}
//then方法的实现
Promise.prototype.then = function(onfulfilled, onrejected){
   let self = this;
   if(self.status === 'resolved'){//判断状态，resolved时候，返回value
       onfulfilled(self.value);
   }
   if(self.status === 'rejected'){//判断状态，rejected时候，返回reason
       onrejected(self.reason);
   }

   if(self.status === 'pending'){
      self.onResolved.push(function(){
          onfulfilled(self.value);
      })
      self.onRejected.push(function(){
        onfulfilled(self.reason);
      })
   }
}
module.exports = Promise;&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;promise.prototype.catch&quot;&gt;2.2 &lt;code&gt;Promise.prototype.catch()&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;Promise.prototype.catch方法&lt;/code&gt;是&lt;code&gt;.then(null, rejection)&lt;/code&gt;的别名，用于指定发生错误时的回调函数。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;let p = new Promise((resolve, reject)=&amp;gt;{
    resolve();
})
p.then(data=&amp;gt;{
    throw new Error();
}).then(null).catch(err=&amp;gt;{
    console.log('catch', err)
}).then(null, err=&amp;gt;{
    console.log('err', err);
})&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;实现原理&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Promise.prototype.catch = function(onrejected){
    return this.then(null, onrejected);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;promise.all&quot;&gt;2.3 &lt;code&gt;Promise.all&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;Promise.all&lt;/code&gt;方法用于将多个 Promise 实例，包装成一个新的 &lt;code&gt;Promise&lt;/code&gt; 实例。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;const p = Promise.all([p1, p2, p3]);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;实现原理&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Promise.all = function (promises) {
    return new Promise((resolve, reject) =&amp;gt; {
        let results = []; let i = 0;
        function processData(index, data) {
        results[index] = data; // let arr = []  arr[2] = 100
        if (++i === promises.length) {
            resolve(results);
        }
        }
        for (let i = 0; i &amp;lt; promises.length; i++) {
        let p = promises[i];
        p.then((data) =&amp;gt; { // 成功后把结果和当前索引 关联起来
            processData(i, data);
        }, reject);
        }
    })
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;promise.race&quot;&gt;2.4 &lt;code&gt;Promise.race&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;Promise.race&lt;/code&gt;方法同样是将多个 &lt;code&gt;Promise&lt;/code&gt; 实例，包装成一个新的 &lt;code&gt;Promise&lt;/code&gt; 实例。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;const p = Promise.race([p1, p2, p3]);&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;上面代码中，只要&lt;code&gt;p1&lt;/code&gt;、&lt;code&gt;p2&lt;/code&gt;、&lt;code&gt;p3&lt;/code&gt;之中有一个实例率先改变状态，p的状态就跟着改变。那个率先改变的 &lt;code&gt;Promise&lt;/code&gt; 实例的返回值，就传递给p的回调函数。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;let Promise = require('./e2.promise');
let fs = require('mz/fs');

Promise.race([
    fs.readFile('./age.txt', 'utf8'),
    fs.readFile('./name.txt', 'utf8')
]).then(data=&amp;gt;{
    console.log(data);
})&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;实现原理&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Promise.race = function(promises){
    return new Promise((resolve, reject)=&amp;gt;{
        for(let i=0; i&amp;lt; promises.length; i++){
            let p = promises[i];
            p.then(resolve, reject);
        }
    })
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;promise.resolve&quot;&gt;2.5 &lt;code&gt;Promise.resolve&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;Promise.resolve方法允许调用时不带参数，直接返回一个resolved状态的 Promise 对象。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;const p = Promise.resolve();

p.then(function () {
  // ...
});&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;实现原理&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Promise.resolve = function(value){
    return new Promise((resolve, reject)=&amp;gt;{
        resolve(value);
    })
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;promise.reject&quot;&gt;2.6 &lt;code&gt;Promise.reject&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;Promise.reject方法允许调用时不带参数，直接返回一个rejected状态的 Promise 对象。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;const p = Promise.reject();

p.then(function () {
  // ...
});&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;实现原理&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Promise.reject = function(reason){
    return new Promise((resolve, reject)=&amp;gt;{
        reject(reason);
    })
}&lt;/code&gt;
&lt;/pre&gt;
&lt;h5 id=&quot;promise的一些扩展库&quot;&gt;2.7 &lt;code&gt;promise&lt;/code&gt;的一些扩展库&lt;/h5&gt;
&lt;p&gt;&lt;a href=&quot;https://www.npmjs.com/package/bluebird&quot;&gt;bluebird&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.npmjs.com/package/mz&quot;&gt;mz&lt;/a&gt;&lt;/p&gt;
&lt;h5 id=&quot;应用-async-await-generator-co&quot;&gt;2.8 应用 &lt;code&gt;async + await = generator + co&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;&lt;code&gt;generator&lt;/code&gt; 生产迭代器的&lt;/p&gt;&lt;p&gt;生成器函数 &lt;code&gt;* generator&lt;/code&gt; 一般配合 &lt;code&gt;yield&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;function * read() {
    yield 1;
    yield 2;
    yield 3;
    return 100
}
let it = read();
console.dir(it.next());
console.dir(it.next());
console.dir(it.next());
console.dir(it.next());
//结果：
{ value: 1, done: false }
{ value: 2, done: false }
{ value: 3, done: false }
{ value: 100, done: true }&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;promise + generator&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;let fs = require('mz/fs');
// let co = require('co');

function * read(){
    let age = yield fs.readFile('./age.txt', 'utf8');
    return age;
}

//co 原理
function co(it){
    return new Promise((resolve, reject)=&amp;gt;{
        function next(data){
            let { value, done } = it.next(data);
            if(!done){
                value.then(data=&amp;gt;{
                    next(data);
                }, reject)
            }else{
                resolve(value);
            }
        }
        next();
    })
}

co(read()).then(data=&amp;gt;{
    console.log(data);//18
}, err=&amp;gt;{
    console.log(err);
})&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;async + await&lt;/code&gt;是es7的语法&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;let fs = require('mz/fs');//这个mz库将nodejs里面的fs全部函数都promise化
// async 函数就是promise es7
// 回调的问题 不能try/catch 并发问题
async function read() { 
    let age = await fs.readFile('name.txt','utf8')
    return age
}
read().then(data=&amp;gt;{
  console.log(data);//cjw
})&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;手写一个promise-a&quot;&gt;3.手写一个promise A+&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://promisesaplus.com/&quot;&gt;promise A+ 规范传送门&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;测试代码是否符合a+ 规范 为了让其能测试&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;npm install promises-aplus-tests -g
promises-aplus-tests 文件名 可以测试&lt;/code&gt;
&lt;/pre&gt;
&lt;pre&gt;
&lt;code&gt;/*
 * @Author: caijw 
 * @Date: 2018-10-01 15:04:43 
 * @Last Modified by: caijw
 * @Last Modified time: 2018-10-08 22:41:06
 */
function Promise(executor){
    var self = this;
    self.status = 'pending';//从pending 转换为resolved rejected
    self.value = undefined;
    self.reason = undefined;
    self.onResolved = [];//专门存放成功的回调
    self.onRejected = [];//专门存放失败的回调
    //pending -&amp;gt; resolved
    function resolve(value){
        if(self.status === 'pending'){
            self.value = value;
            self.status = 'resolved';
            self.onResolved.forEach(fn=&amp;gt;fn());
        }
    }
     //pending -&amp;gt; rejected
    function reject(reason){
        if(self.status === 'pending'){
            self.reason = reason;
            self.status = 'rejected';
            self.onRejected.forEach(fn=&amp;gt;fn());
        }
    }
    try{
        executor(resolve, reject);
    }catch(e){
        reject(e);
    }
}

//这里主要就是递归循环，判断是否为promise，如果是promise就继续递归循环下去。
function resolvePromise(promise2, x, resolve, reject){
    if(promise2 === x){
        return reject(new TypeError('循环引用'));
    }

    let called;
    if(x!=null &amp;amp;&amp;amp; (typeof x === 'object' || typeof x === 'function')){
        try{
            let then = x.then;
            //假设他是一个promise，then方法就是一个函数
            if(typeof then === 'function'){
                then.call(x, (y)=&amp;gt;{
                    if(called) return;
                    called = true;
                    // 递归解析 如果resolve的是一个promise 就要不停的让resolve的结果进行处理
                    resolvePromise(promise2, y, resolve, reject);
                },(e)=&amp;gt;{
                    if(called) return;
                    called = true;
                    reject(e);
                })
            }else{//不是就返回
                resolve(x);
            }
        }catch(e){
            if(called) return;
            called = true;
            reject(e);
        }
        
    }else{
        resolve(x);
    }
}





//至返回错误的 catch 就是不写成功的回调的then方法
Promise.prototype.catch = function(onrejected){
    return this.then(null, onrejected);
}

//1.解决输出的顺序的问题
// all方法的参数 是一个数组，会按照数组的结果放到成功的回调里(只有全成功才算成功)
// race方法参数也是一个数组。会同时发起并发，但是以返回最快的结果为结果


Promise.race = function(promises){
    return new Promise((resolve, reject)=&amp;gt;{
        for(let i=0; i&amp;lt; promises.length; i++){
            let p = promises[i];
            p.then(resolve, reject);
        }
    })
}


Promise.reject = function(reason){
    return new Promise((resolve, reject)=&amp;gt;{
        reject(reason);
    })
}

Promise.resolve = function(value){
    return new Promise((resolve, reject)=&amp;gt;{
        resolve(value);
    })
}

Promise.all = function (promises) {
    return new Promise((resolve, reject) =&amp;gt; {
        let results = []; let i = 0;
        function processData(index, data) {
        results[index] = data; // let arr = []  arr[2] = 100
        if (++i === promises.length) {
            resolve(results);
        }
        }
        for (let i = 0; i &amp;lt; promises.length; i++) {
        let p = promises[i];
        p.then((data) =&amp;gt; { // 成功后把结果和当前索引 关联起来
            processData(i, data);
        }, reject);
        }
    })
}



//回调函数
Promise.prototype.then = function(onfulfilled, onrejected){
    // onfulfilled / onrejected是一个可选的参数
    onfulfilled = typeof onfulfilled == 'function' ? onfulfilled :  val=&amp;gt;val;
    onrejected = typeof onrejected === 'function' ? onrejected :err =&amp;gt; {
        throw err;
    }
   let self = this;
   
   let promise2;
   promise2 = new Promise((resolve, reject)=&amp;gt;{
        if(self.status === 'resolved'){
            setTimeout(()=&amp;gt;{
                try{
                    let x = onfulfilled(self.value);
                    resolvePromise(promise2, x, resolve, reject);
                }catch(e){
                    reject(e);
                }
            }, 0)
        }
        if(self.status === 'rejected'){
            setTimeout(()=&amp;gt;{
                try{
                    let x = onrejected(self.reason);
                    resolvePromise(promise2, x, resolve, reject);
                }catch(e){
                    reject(e);
                }
            }, 0)
            
        }
        if(self.status === 'pending'){
            self.onResolved.push(function(){
                setTimeout(()=&amp;gt;{
                    try{
                        let x = onfulfilled(self.value);
                        resolvePromise(promise2, x, resolve, reject);
                    }catch(e){
                        reject(e);
                    }
                }, 0)
            })
            self.onRejected.push(function(){
                setTimeout(()=&amp;gt;{
                    try{
                        let x = onrejected(self.reason);
                        resolvePromise(promise2, x, resolve, reject);
                    }catch(e){
                        reject(e);
                    }
                }, 0)
            })
        }
   })
   return promise2;
}
// 语法糖 简化问题 嵌套的问题 ，被废弃了
Promise.defer = Promise.deferred = function(){
    let dfd = {};
    dfd.promise = new Promise((resolve, reject)=&amp;gt;{
        dfd.resolve = resolve;
        dfd.reject = reject;
    })
    return dfd;
}

module.exports = Promise;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;参考文档&quot;&gt;参考文档&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;http://es6.ruanyifeng.com/#docs/promise&quot;&gt;ECMAScript 6 入门 Promise--阮一峰&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://juejin.im/post/5b58300b6fb9a04fea58a27e&quot;&gt;Hey, 你的Promise&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://juejin.im/post/5b5b52dbe51d4534c34a4a6e&quot;&gt;ES6版Promise实现，给你不一样的体验&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.ibm.com/developerworks/cn/web/wa-lo-bluebird-develop-asynchronous-javascript/index.html&quot;&gt;使用 Bluebird 开发异步的 JavaScript 程序&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Mon, 08 Oct 2018 15:13:00 +0000</pubDate>
<dc:creator>IT-caijw</dc:creator>
<og:description>&lt;! TOC</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/caijw/p/9757916.html</dc:identifier>
</item>
<item>
<title>一、Kafka初认识 - pony1223</title>
<link>http://www.cnblogs.com/pony1223/p/9757678.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/pony1223/p/9757678.html</guid>
<description>&lt;p&gt;&lt;strong&gt;1、Kafka使用背景&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在我们大量使用分布式数据库、分布式计算集群的时候，是否会遇到这样的一些问题：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;我们想分析下用户行为（pageviews），以便我们设计出更好的广告位&lt;/li&gt;
&lt;li&gt;我想对用户的搜索关键词进行统计，分析出当前的流行趋势&lt;/li&gt;
&lt;li&gt;有些数据，存储数据库浪费，直接存储硬盘效率又低 &lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;这些场景都有一个共同点：&lt;/p&gt;
&lt;p&gt;数据是由上游模块产生，上游模块，使用上游模块的数据计算、统计、分析，这个时候就可以使用消息系统，尤其是分布式消息系统！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、Kafka的定义&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;What is Kafka：它是一个分布式消息系统，由linkedin使用scala编写，用作LinkedIn的活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础。具有高水平扩展和高吞吐量。&lt;/p&gt;
&lt;p&gt;简单来说：&lt;/p&gt;
&lt;div readability=&quot;10&quot;&gt;
&lt;p&gt;举个例子，生产者消费者，生产者生产鸡蛋，消费者消费鸡蛋，生产者生产一个鸡蛋，消费者就消费一个鸡蛋，假设消费者消费鸡蛋的时候噎住了（系统宕机了），生产者还在生产鸡蛋，那新生产的鸡蛋就丢失了。再比如生产者很强劲（大交易量的情况），生产者1秒钟生产100个鸡蛋，消费者1秒钟只能吃50个鸡蛋，那要不了一会，消费者就吃不消了（消息堵塞，最终导致系统超时），消费者拒绝再吃了，”鸡蛋“又丢失了，这个时候我们放个篮子在它们中间，生产出来的鸡蛋都放到篮子里，消费者去篮子里拿鸡蛋，这样鸡蛋就不会丢失了，都在篮子里，而这个篮子就是”kafka“。&lt;br/&gt;鸡蛋其实就是“数据流”，系统之间的交互都是通过“数据流”来传输的（就是tcp、http什么的），也称为报文，也叫“消息”。&lt;br/&gt;消息队列满了，其实就是篮子满了，”鸡蛋“ 放不下了，那赶紧多放几个篮子，其实就是kafka的扩容。&lt;br/&gt;各位现在知道kafka是干什么的了吧，它就是那个&quot;篮子&quot;。&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;3、Kafka和其他主流分布式消息系统的对比&lt;/strong&gt; &lt;/p&gt;
&lt;div&gt;&lt;img src=&quot;https://images2015.cnblogs.com/blog/831021/201602/831021-20160222115519338-1279419718.png&quot; alt=&quot;&quot;/&gt;&lt;/div&gt;
&lt;p&gt;定义解释：&lt;/p&gt;
&lt;p&gt;1、Java 和 scala都是运行在JVM上的语言。&lt;/p&gt;
&lt;div readability=&quot;17&quot;&gt;
&lt;p&gt;2、erlang和最近比较火的和go语言一样是从代码级别就支持高并发的一种语言，所以RabbitMQ天生就有很高的并发性能，但是 有RabbitMQ严格按照AMQP进行实现，受到了很多限制。kafka的设计目标是高吞吐量，所以kafka自己设计了一套高性能但是不通用的协议，他也是仿照AMQP（ Advanced Message Queuing Protocol   高级消息队列协议）设计的。 &lt;/p&gt;
&lt;p&gt;3、事物的概念：在数据库中，多个操作一起提交，要么操作全部成功，要么全部失败。举个例子， 在转账的时候付款和收款，就是一个事物的例子，你给一个人转账，你转成功，并且对方正常行收到款项后，这个操作才算成功，有一方失败，那么这个操作就是失败的。 &lt;/p&gt;
&lt;div readability=&quot;15&quot;&gt;
&lt;p&gt;对应消在息队列中，就是多条消息一起发送，要么全部成功，要么全部失败。3个中只有ActiveMQ支持，这个是因为，RabbitMQ和Kafka为了更高的性能，而放弃了对事物的支持 。&lt;/p&gt;
&lt;div readability=&quot;21.5&quot;&gt;4、集群：多台服务器组成的整体叫做集群，这个整体对生产者和消费者来说，是透明的。其实对消费系统组成的集群添加一台服务器减少一台服务器对生产者和消费者都是无感之的。
&lt;p&gt;5、负载均衡，对消息系统来说负载均衡是大量的生产者和消费者向消息系统发出请求消息，系统必须均衡这些请求使得每一台服务器的请求达到平衡，而不是大量的请求，落到某一台或几台，使得这几台服务器高负荷或超负荷工作，严重情况下会停止服务或宕机。&lt;/p&gt;
&lt;p&gt;6、动态扩容是很多公司要求的技术之一，不支持动态扩容就意味着停止服务，这对很多公司来说是不可以接受的。 &lt;/p&gt;
&lt;p&gt;注：&lt;/p&gt;
&lt;div readability=&quot;14&quot;&gt;
&lt;p&gt;阿里巴巴的Metal,RocketMQ都有Kafka的影子，他们要么改造了Kafka或者借鉴了Kafka，最后Kafka的动态扩容是通过Zookeeper来实现的。 &lt;/p&gt;

&lt;p&gt;Zookeeper是一种在分布式系统中被广泛用来作为：分布式状态管理、分布式协调管理、分布式配置管理、和分布式锁服务的集群。kafka增加和减少服务器都会在Zookeeper节点上触发相应的事件kafka系统会捕获这些事件，进行新一轮的负载均衡，客户端也会捕获这些事件来进行新一轮的处理。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div&gt;
&lt;div&gt;
&lt;p&gt;&lt;strong&gt;1、 AMQP协议&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Advanced Message Queuing Protocol （高级消息队列协议）&lt;/p&gt;
&lt;div readability=&quot;15&quot;&gt;
&lt;p&gt;&lt;strong&gt;The Advanced Message Queuing Protocol (AMQP)：&lt;/strong&gt;&lt;span lang=&quot;ZH-CN&quot;&gt;是一个标准开放的应用层的消息中间件（Message Oriented Middleware&lt;span lang=&quot;ZH-CN&quot;&gt;）协议。AMQP&lt;span lang=&quot;ZH-CN&quot;&gt;定义了通过网络发送的字节流的数据格式。因此兼容性非常好，任何实现AMQP&lt;span lang=&quot;ZH-CN&quot;&gt;协议的程序都可以和与AMQP&lt;span lang=&quot;ZH-CN&quot;&gt;协议兼容的其他程序交互，可以很容易做到跨语言，跨平台。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;上面说的3种比较流行的消息队列协议，要么支持AMQP协议，要么借鉴了AMQP协议的思想进行了开发、实现、设计。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、 一些基本的概念&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div readability=&quot;16&quot;&gt;
&lt;p&gt;1、消费者：（Consumer）：从消息队列中请求消息的客户端应用程序&lt;/p&gt;
&lt;p&gt;2、生产者：（Producer）  ：向broker发布消息的应用程序&lt;/p&gt;
&lt;p&gt;3、AMQP服务端（broker）：用来接收生产者发送的消息并将这些消息路由给服务器中的队列，便于fafka将生产者发送的消息，动态的添加到磁盘并给每一条消息一个偏移量，所以对于kafka一个broker就是一个应用程序的实例&lt;/p&gt;
&lt;div readability=&quot;11&quot;&gt;kafka支持的客户端语言：Kafka客户端支持当前大部分主流语言，包括：C、C++、Erlang、Java、.net、perl、PHP、Python、Ruby、Go、Javascript
&lt;p&gt;可以使用以上任何一种语言和kafka服务器进行通信（即辨析自己的consumer从kafka集群订阅消息也可以自己写producer程序） &lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div&gt; &lt;img src=&quot;https://img2018.cnblogs.com/blog/401339/201810/401339-20181008222033084-1287477162.png&quot; alt=&quot;&quot;/&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;3、Kafka架构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;生产者生产消息、kafka集群、消费者获取消息这样一种架构，如下图：&lt;/p&gt;
&lt;div&gt;&lt;img src=&quot;https://images2015.cnblogs.com/blog/831021/201602/831021-20160222125238526-112967735.png&quot; alt=&quot;&quot;/&gt;&lt;/div&gt;
&lt;p&gt;kafka集群中的消息，是通过Topic（主题）来进行组织的，如下图：&lt;/p&gt;
&lt;div&gt;&lt;img src=&quot;https://images2015.cnblogs.com/blog/831021/201602/831021-20160222125343135-190706359.png&quot; alt=&quot;&quot;/&gt;&lt;/div&gt;
&lt;p&gt;一些基本的概念：&lt;/p&gt;
&lt;div readability=&quot;16&quot;&gt;
&lt;p&gt;1、主题（Topic）：一个主题类似新闻中的体育、娱乐、教育等分类概念，在实际工程中通常一个业务一个主题。&lt;/p&gt;
&lt;p&gt;2、分区（Partition）：一个Topic中的消息数据按照多个分区组织，分区是kafka消息队列组织的最小单位，一个分区可以看作是一个FIFO（ First Input First Output的缩写，先入先出队列）的队列。&lt;/p&gt;
&lt;p&gt;kafka分区是提高kafka性能的关键所在，当你发现你的集群性能不高时，常用手段就是增加Topic的分区，分区里面的消息是按照从新到老的顺序进行组织，消费者从队列头订阅消息，生产者从队列尾添加消息。&lt;/p&gt;

&lt;p&gt;工作图：&lt;/p&gt;
&lt;div&gt;&lt;img src=&quot;https://images2015.cnblogs.com/blog/831021/201602/831021-20160222125912869-944637205.png&quot; alt=&quot;&quot;/&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div readability=&quot;12&quot;&gt; 
&lt;p&gt;备份（Replication）：为了保证分布式可靠性，kafka0.8开始对每个分区的数据进行备份（不同的Broker上），防止其中一个Broker宕机造成分区上的数据不可用。&lt;/p&gt;
&lt;p&gt;kafka0.7是一个很大的改变：1、增加了备份2、增加了控制借点概念，增加了集群领导者选举 。&lt;/p&gt;
&lt;/div&gt;
&lt;div readability=&quot;60.5&quot;&gt;

&lt;p&gt;Kafka集群是把状态保存在Zookeeper中的，首先要搭建Zookeeper集群。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、软件环境&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;（3台服务器-我的测试）&lt;/p&gt;
&lt;p&gt;192.168.7.100 server1&lt;/p&gt;
&lt;p&gt;192.168.7.101 server2&lt;/p&gt;
&lt;p&gt;192.168.7.107 server3&lt;/p&gt;
&lt;div readability=&quot;17&quot;&gt;
&lt;p&gt;1、Linux服务器一台、三台、五台、（2*n+1），Zookeeper集群的工作是超过半数才能对外提供服务，3台中超过两台超过半数，允许1台挂掉 ，是否可以用偶数，其实没必要。&lt;/p&gt;
&lt;p&gt;如果有四台那么挂掉一台还剩下三台服务器，如果在挂掉一个就不行了，这里记住是超过半数。&lt;/p&gt;
&lt;p&gt;2、Java jdk1.7 zookeeper是用java写的所以他的需要JAVA环境，java是运行在java虚拟机上的&lt;/p&gt;
&lt;p&gt;3、Zookeeper的稳定版本Zookeeper 3.4.6版本 &lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2、配置&amp;amp;安装Zookeeper&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下面的操作是：3台服务器统一操作&lt;/p&gt;
&lt;p&gt;1、安装Java&lt;/p&gt;
&lt;div readability=&quot;10.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
yum list java*
yum -y install java-1.7.0-openjdk*
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2、下载Zookeeper&lt;/p&gt;
&lt;p&gt;首先要注意在生产环境中目录结构要定义好，防止在项目过多的时候找不到所需的项目&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
#我的目录统一放在/opt下面
#首先创建Zookeeper项目目录
mkdir zookeeper #项目目录
mkdir zkdata #存放快照日志
mkdir zkdatalog#存放事物日志
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;下载Zookeeper&lt;/p&gt;
&lt;/div&gt;
&lt;div readability=&quot;6.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
#下载软件
cd /opt/zookeeper/

wget http://mirrors.cnnic.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz

#解压软件
tar -zxvf zookeeper-3.4.6.tar.gz
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;3、修改配置文件&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;进入到解压好的目录里面的conf目录中，查看&lt;/p&gt;
&lt;div readability=&quot;67.5&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
#进入conf目录
/opt/zookeeper/zookeeper-3.4.6/conf
#查看
[root@192.168.7.107]$ ll
-rw-rw-r--. 1 1000 1000  535 Feb 20  2014 configuration.xsl
-rw-rw-r--. 1 1000 1000 2161 Feb 20  2014 log4j.properties
-rw-rw-r--. 1 1000 1000  922 Feb 20  2014 zoo_sample.cfg
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;#zoo_sample.cfg  这个文件是官方给我们的zookeeper的样板文件，给他复制一份命名为zoo.cfg，zoo.cfg是官方指定的文件命名规则。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3台服务器的配置文件&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/opt/zookeeper/zkdata
dataLogDir=/opt/zookeeper/zkdatalog
clientPort=12181
server.1=192.168.7.100:12888:13888
server.2=192.168.7.101:12888:13888
server.3=192.168.7.107:12888:13888
#server.1 这个1是服务器的标识也可以是其他的数字， 表示这个是第几号服务器，用来标识服务器，这个标识要写到快照目录下面myid文件里
#192.168.7.107为集群里的IP地址，第一个端口是master和slave之间的通信端口，默认是2888，第二个端口是leader选举的端口，集群刚启动的时候选举或者leader挂掉之后进行新的选举的端口默认是3888
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;配置文件解释：&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
#tickTime：
这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。
#initLimit：
这个配置项是用来配置 Zookeeper 接受客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 5个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 5*2000=10 秒
#syncLimit：
这个配置项标识 Leader 与Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是5*2000=10秒
#dataDir：
快照日志的存储路径
#dataLogDir：
事物日志的存储路径，如果不配置这个那么事物日志会默认存储到dataDir制定的目录，这样会严重影响zk的性能，当zk吞吐量较大的时候，产生的事物日志、快照日志太多
#clientPort：
这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。修改他的端口改大点
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;创建myid文件&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
#server1
echo &quot;1&quot; &amp;gt; /opt/zookeeper/zkdata/myid
#server2
echo &quot;2&quot; &amp;gt; /opt/zookeeper/zkdata/myid
#server3
echo &quot;3&quot; &amp;gt; /opt/zookeeper/zkdata/myid
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt; 4、重要配置说明&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1、myid文件和server.myid  在快照目录下存放的标识本台服务器的文件，他是整个zk集群用来发现彼此的一个重要标识。&lt;/p&gt;
&lt;p&gt;2、zoo.cfg 文件是zookeeper配置文件 在conf目录里。&lt;/p&gt;
&lt;p&gt;3、log4j.properties文件是zk的日志输出文件 在conf目录里用java写的程序基本上有个共同点日志都用log4j，来进行管理。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
# Define some &lt;span&gt;default&lt;/span&gt;&lt;span&gt; values that can be overridden by system properties
zookeeper.root.logger&lt;/span&gt;=&lt;span&gt;INFO, CONSOLE  #日志级别
zookeeper.console.threshold&lt;/span&gt;=&lt;span&gt;INFO  #使用下面的console来打印日志
zookeeper.log.dir&lt;/span&gt;=&lt;span&gt;.    #日志打印到那里，是咱们启动zookeeper的目录 （建议设置统一的日志目录路径）
zookeeper.log.file&lt;/span&gt;=&lt;span&gt;zookeeper.log
zookeeper.log.threshold&lt;/span&gt;=&lt;span&gt;DEBUG
zookeeper.tracelog.dir&lt;/span&gt;=&lt;span&gt;.
zookeeper.tracelog.file&lt;/span&gt;=&lt;span&gt;zookeeper_trace.log

#
# ZooKeeper Logging Configuration
#

# Format is &lt;/span&gt;&quot;&amp;lt;default threshold&amp;gt; (, &amp;lt;appender&amp;gt;)+
&lt;span&gt;
# DEFAULT: console appender only
log4j.rootLogger&lt;/span&gt;=&lt;span&gt;${zookeeper.root.logger}

# Example with rolling log file
#log4j.rootLogger&lt;/span&gt;=&lt;span&gt;DEBUG, CONSOLE, ROLLINGFILE

# Example with rolling log file and tracing
#log4j.rootLogger&lt;/span&gt;=&lt;span&gt;TRACE, CONSOLE, ROLLINGFILE, TRACEFILE

#
# Log INFO level and above messages to the console
#
log4j.appender.CONSOLE&lt;/span&gt;=&lt;span&gt;org.apache.log4j.ConsoleAppender
log4j.appender.CONSOLE.Threshold&lt;/span&gt;=&lt;span&gt;${zookeeper.console.threshold}
log4j.appender.CONSOLE.layout&lt;/span&gt;=&lt;span&gt;org.apache.log4j.PatternLayout
log4j.appender.CONSOLE.layout.ConversionPattern&lt;/span&gt;=%d{ISO8601} [myid:%X{myid}] - %-5p [%t:%C{1}@%L] - %m%&lt;span&gt;n


# Add ROLLINGFILE to rootLogger to get log file output
#    Log DEBUG level and above messages to a log file
log4j.appender.ROLLINGFILE&lt;/span&gt;=&lt;span&gt;org.apache.log4j.RollingFileAppender
log4j.appender.ROLLINGFILE.Threshold&lt;/span&gt;=&lt;span&gt;${zookeeper.log.threshold}
log4j.appender.ROLLINGFILE.File&lt;/span&gt;=${zookeeper.log.dir}/&lt;span&gt;${zookeeper.log.file}

# Max log file size of 10MB
log4j.appender.ROLLINGFILE.MaxFileSize&lt;/span&gt;=&lt;span&gt;10MB
# uncomment the next line to limit number of backup files
#log4j.appender.ROLLINGFILE.MaxBackupIndex&lt;/span&gt;=10&lt;span&gt;

log4j.appender.ROLLINGFILE.layout&lt;/span&gt;=&lt;span&gt;org.apache.log4j.PatternLayout
log4j.appender.ROLLINGFILE.layout.ConversionPattern&lt;/span&gt;=%d{ISO8601} [myid:%X{myid}] - %-5p [%t:%C{1}@%L] - %m%&lt;span&gt;n


#
# Add TRACEFILE to rootLogger to get log file output
#    Log DEBUG level and above messages to a log file
log4j.appender.TRACEFILE&lt;/span&gt;=&lt;span&gt;org.apache.log4j.FileAppender
log4j.appender.TRACEFILE.Threshold&lt;/span&gt;=&lt;span&gt;TRACE
log4j.appender.TRACEFILE.File&lt;/span&gt;=${zookeeper.tracelog.dir}/&lt;span&gt;${zookeeper.tracelog.file}

log4j.appender.TRACEFILE.layout&lt;/span&gt;=&lt;span&gt;org.apache.log4j.PatternLayout
### Notice we are including log4j&lt;/span&gt;'s NDC here (%x)
log4j.appender.TRACEFILE.layout.ConversionPattern=%d{ISO8601} [myid:%X{myid}] - %-5p [%t:%C{1}@%L][%x] - %m%&lt;span&gt;n

configuration &lt;/span&gt;&lt;span&gt;for&lt;/span&gt; log4j
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;4、zkEnv.sh和zkServer.sh文件&lt;/p&gt;
&lt;p&gt;zkServer.sh 主的管理程序文件&lt;/p&gt;
&lt;p&gt;zkEnv.sh 是主要配置，zookeeper集群启动时配置环境变量的文件&lt;/p&gt;
&lt;p&gt;5、还有一个需要注意&lt;/p&gt;
&lt;p&gt;ZooKeeper server &lt;strong&gt;will not remove old snapshots and log files&lt;/strong&gt; when using the default configuration (see autopurge below), this is the responsibility of the operator&lt;/p&gt;
&lt;p&gt;zookeeper不会主动的清除旧的快照和日志文件，这个是操作者的责任。&lt;/p&gt;
&lt;p&gt;但是可以通过命令去定期的清理。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;

&lt;pre&gt;
#!/bin/bash 
 
#snapshot file dir 
dataDir=/opt/zookeeper/zkdata/version-2
#tran log dir 
dataLogDir=/opt/zookeeper/zkdatalog/version-2

#Leave 66 files 
count=66 
count=$[$count+1] 
ls -t $dataLogDir/log.* | tail -n +$count | xargs rm -f 
ls -t $dataDir/snapshot.* | tail -n +$count | xargs rm -f 

#以上这个脚本定义了删除对应两个目录中的文件，保留最新的66个文件，可以将他写到crontab中，设置为每天凌晨2点执行一次就可以了。


#zk log dir   del the zookeeper log
#logDir=
#ls -t $logDir/zookeeper.log.* | tail -n +$count | xargs rm -f
&lt;/pre&gt;

&lt;/div&gt;
&lt;p&gt;其他方法：&lt;/p&gt;
&lt;p&gt;第二种：使用ZK的工具类PurgeTxnLog，它的实现了一种简单的历史文件清理策略，可以在这里看一下他的使用方法 http://zookeeper.apache.org/doc/r3.4.6/zookeeperAdmin.html &lt;/p&gt;
&lt;p&gt;第三种：对于上面这个执行，ZK自己已经写好了脚本，在bin/zkCleanup.sh中，所以直接使用这个脚本也是可以执行清理工作的。&lt;/p&gt;
&lt;p&gt;第四种：从3.4.0开始，zookeeper提供了自动清理snapshot和事务日志的功能，通过配置 autopurge.snapRetainCount 和 autopurge.purgeInterval 这两个参数能够实现定时清理了。这两个参数都是在zoo.cfg中配置的：&lt;/p&gt;
&lt;div readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;strong&gt;autopurge.purgeInterval&lt;/strong&gt;  这个参数指定了清理频率，单位是小时，需要填写一个1或更大的整数，默认是0，表示不开启自己清理功能。&lt;/p&gt;
&lt;/div&gt;
&lt;div readability=&quot;16.5&quot;&gt;
&lt;p&gt;&lt;strong&gt;autopurge.snapRetainCount&lt;/strong&gt; 这个参数和上面的参数搭配使用，这个参数指定了需要保留的文件数目。默认是保留3个。&lt;/p&gt;

&lt;p&gt;推荐使用第一种方法，对于运维人员来说，将日志清理工作独立出来，便于统一管理也更可控。毕竟zk自带的一些工具并不怎么给力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5、启动服务并查看&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1、启动服务&lt;/p&gt;
&lt;div readability=&quot;17&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
#进入到Zookeeper的bin目录下
cd /opt/zookeeper/zookeeper-3.4.6/bin
#启动服务（3台都需要操作）
./zkServer.sh start
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2、检查服务状态&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
#检查服务器状态
./zkServer.sh status
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;通过status就能看到状态：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
./zkServer.sh status
JMX enabled by default
Using config: /opt/zookeeper/zookeeper-3.4.6/bin/../conf/zoo.cfg  #配置文件
Mode: follower  #他是否为领导
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;zk集群一般只有一个leader，多个follower，主一般是相应客户端的读写请求，而从主同步数据，当主挂掉之后就会从follower里投票选举一个leader出来。&lt;/p&gt;
&lt;p&gt;可以用“jps”查看zk的进程，这个是zk的整个工程的main&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
#执行命令jps
20348 Jps
4233 QuorumPeerMain 
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;1、软件环境&lt;/strong&gt;&lt;/p&gt;
&lt;div readability=&quot;10&quot;&gt;
&lt;p&gt;1、linux一台或多台，大于等于2&lt;/p&gt;
&lt;p&gt;2、已经搭建好的zookeeper集群&lt;/p&gt;
&lt;div readability=&quot;7&quot;&gt;3、软件版本kafka_2.11-0.9.0.1.tgz&lt;a href=&quot;http://apache.opencas.org/kafka/0.9.0.1/kafka_2.11-0.9.0.1.tgz&quot;&gt;&lt;br/&gt;&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2、创建目录并下载安装软件&lt;/strong&gt;&lt;/p&gt;
&lt;div readability=&quot;7&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;

&lt;pre&gt;
#创建目录
cd /opt/
mkdir kafka #创建项目目录
cd kafka
mkdir kafkalogs #创建kafka消息目录，主要存放kafka消息

#下载软件
wget  http://apache.opencas.org/kafka/0.9.0.1/kafka_2.11-0.9.0.1.tgz

#解压软件
tar -zxvf kafka_2.11-0.9.0.1.tgz
&lt;/pre&gt;

&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;3、修改配置文件&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;进入到config目录&lt;/p&gt;
&lt;div readability=&quot;66&quot;&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
cd /opt/kafka/kafka_2.11-0.9.0.1/config/
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;主要关注：server.properties 这个文件即可，我们可以发现在目录下：&lt;/p&gt;
&lt;p&gt;有很多文件，这里可以发现有Zookeeper文件，我们可以根据Kafka内带的zk集群来启动，但是建议使用独立的zk集群&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;

&lt;pre&gt;
-rw-r--r--. 1 root root 5699 Feb 22 09:41 192.168.7.101
-rw-r--r--. 1 root root  906 Feb 12 08:37 connect-console-sink.properties
-rw-r--r--. 1 root root  909 Feb 12 08:37 connect-console-source.properties
-rw-r--r--. 1 root root 2110 Feb 12 08:37 connect-distributed.properties
-rw-r--r--. 1 root root  922 Feb 12 08:38 connect-file-sink.properties
-rw-r--r--. 1 root root  920 Feb 12 08:38 connect-file-source.properties
-rw-r--r--. 1 root root 1074 Feb 12 08:37 connect-log4j.properties
-rw-r--r--. 1 root root 2055 Feb 12 08:37 connect-standalone.properties
-rw-r--r--. 1 root root 1199 Feb 12 08:37 consumer.properties
-rw-r--r--. 1 root root 4369 Feb 12 08:37 log4j.properties
-rw-r--r--. 1 root root 2228 Feb 12 08:38 producer.properties
-rw-r--r--. 1 root root 5699 Feb 15 18:10 server.properties
-rw-r--r--. 1 root root 3325 Feb 12 08:37 test-log4j.properties
-rw-r--r--. 1 root root 1032 Feb 12 08:37 tools-log4j.properties
-rw-r--r--. 1 root root 1023 Feb 12 08:37 zookeeper.properties
&lt;/pre&gt;

&lt;/div&gt;
&lt;p&gt;修改配置文件：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;

&lt;pre&gt;
broker.id=0  #当前机器在集群中的唯一标识，和zookeeper的myid性质一样
port=19092 #当前kafka对外提供服务的端口默认是9092
host.name=192.168.7.100 #这个参数默认是关闭的，在0.8.1有个bug，DNS解析问题，失败率的问题。
num.network.threads=3 #这个是borker进行网络处理的线程数
num.io.threads=8 #这个是borker进行I/O处理的线程数
log.dirs=/opt/kafka/kafkalogs/ #消息存放的目录，这个目录可以配置为“，”逗号分割的表达式，上面的num.io.threads要大于这个目录的个数这个目录，如果配置多个目录，新创建的topic他把消息持久化的地方是，当前以逗号分割的目录中，那个分区数最少就放那一个
socket.send.buffer.bytes=102400 #发送缓冲区buffer大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后在发送，能提高性能
socket.receive.buffer.bytes=102400 #kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘
socket.request.max.bytes=104857600 #这个参数是向kafka请求消息或者向kafka发送消息的请请求的最大数，这个值不能超过java的堆栈大小
num.partitions=1 #默认的分区数，一个topic默认1个分区数
log.retention.hours=168 #默认消息的最大持久化时间，168小时，7天
message.max.byte=5242880  #消息保存的最大值5M
default.replication.factor=2  #kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务
replica.fetch.max.bytes=5242880  #取消息的最大直接数
log.segment.bytes=1073741824 #这个参数是：因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件
log.retention.check.interval.ms=300000 #每隔300000毫秒去检查上面配置的log失效时间（log.retention.hours=168 ），到目录查看是否有过期的消息如果有，删除
log.cleaner.enable=false #是否启用log压缩，一般不用启用，启用的话可以提高性能
zookeeper.connect=192.168.7.100:12181,192.168.7.101:12181,192.168.7.107:1218 #设置zookeeper的连接端口
&lt;/pre&gt;

&lt;/div&gt;
&lt;p&gt;上面是参数的解释，实际的修改项为：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;

&lt;pre&gt;
#broker.id=0  每台服务器的broker.id都不能相同


#hostname
host.name=192.168.7.100

#在log.retention.hours=168 下面新增下面三项
message.max.byte=5242880
default.replication.factor=2
replica.fetch.max.bytes=5242880

#设置zookeeper的连接端口
zookeeper.connect=192.168.7.100:12181,192.168.7.101:12181,192.168.7.107:12181
&lt;/pre&gt;

&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;4、启动Kafka集群并测试&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1、启动服务&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
#从后台启动Kafka集群（3台都需要启动）
cd
&lt;/pre&gt;
&lt;pre&gt;
/opt/kafka/kafka_2.11-0.9.0.1//bin #进入到kafka的bin目录 &lt;br/&gt;./kafka-server-start.sh -daemon ../config/server.properties
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2、检查服务是否启动&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
#执行命令jps
20348 Jps
4233 QuorumPeerMain
18991 Kafka
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;3、创建Topic来验证是否创建成功&lt;/p&gt;
&lt;p&gt;更多请看官方文档：http://kafka.apache.org/documentation.html&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;

&lt;pre&gt;
#创建Topic
./kafka-topics.sh --create --zookeeper 192.168.7.100:12181 --replication-factor 2 --partitions 1 --topic shuaige
#解释
--replication-factor 2   #复制两份
--partitions 1 #创建1个分区
--topic #主题为shuaige

'''在一台服务器上创建一个发布者'''
#创建一个broker，发布者
./kafka-console-producer.sh --broker-list 192.168.7.100:19092 --topic shuaige

'''在一台服务器上创建一个订阅者'''
./kafka-console-consumer.sh --zookeeper localhost:12181 --topic shuaige --from-beginning
&lt;/pre&gt;

&lt;/div&gt;
&lt;p&gt;测试（在发布者那里发布消息看看订阅者那里是否能正常收到~）：&lt;/p&gt;
&lt;p&gt;4、其他命令&lt;/p&gt;
&lt;p&gt;大部分命令可以去官方文档查看&lt;/p&gt;
&lt;p&gt;4.1、查看topic&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
./kafka-topics.sh --list --zookeeper localhost:12181
#就会显示我们创建的所有topic
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;4.2、查看topic状态&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;

&lt;pre&gt;
/kafka-topics.sh --describe --zookeeper localhost:12181 --topic shuaige
#下面是显示信息
Topic:ssports    PartitionCount:1    ReplicationFactor:2    Configs:
    Topic: shuaige    Partition: 0    Leader: 1    Replicas: 0,1    Isr: 1
#分区为为1  复制因子为2   他的  shuaige的分区为0 
#Replicas: 0,1   复制的为0，1
# 
&lt;/pre&gt;

&lt;/div&gt;
&lt;p&gt; OKkafka集群搭建完毕&lt;/p&gt;
&lt;p&gt;5、其他说明标注&lt;/p&gt;
&lt;p&gt;5.1、日志说明&lt;/p&gt;
&lt;p&gt;默认kafka的日志是保存在/opt/kafka/kafka_2.10-0.9.0.0/logs目录下的，这里说几个需要注意的日志&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
server.log #kafka的运行日志
state-change.log  #kafka他是用zookeeper来保存状态，所以他可能会进行切换，切换的日志就保存在这里

controller.log #kafka选择一个节点作为“controller”,当发现有节点down掉的时候它负责在游泳分区的所有节点中选择新的leader,这使得Kafka可以批量的高效的管理所有分区节点的主从关系。如果controller down掉了，活着的节点中的一个会备切换为新的controller.
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;5.2、上面的大家你完成之后可以登录zk来查看zk的目录情况&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;47&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#使用客户端进入zk
.&lt;/span&gt;/zkCli.sh -server 127.0.0.1:12181  #默认是不用加’-&lt;span&gt;server‘参数的因为我们修改了他的端口

#查看目录情况 执行“ls &lt;/span&gt;/&lt;span&gt;”
[zk: &lt;/span&gt;127.0.0.1:12181(CONNECTED) 0] ls /&lt;span&gt;

#显示结果：[consumers, config, controller, isr_change_notification, admin, brokers, zookeeper, controller_epoch]
&lt;/span&gt;&lt;span&gt;'''
&lt;/span&gt;&lt;span&gt;上面的显示结果中：只有zookeeper是，zookeeper原生的，其他都是Kafka创建的
&lt;/span&gt;&lt;span&gt;'''
&lt;/span&gt;&lt;span&gt;
#标注一个重要的
[zk: &lt;/span&gt;127.0.0.1:12181(CONNECTED) 1] get /brokers/ids/0&lt;span&gt;
{&lt;/span&gt;&quot;jmx_port&quot;:-1,&quot;timestamp&quot;:&quot;1456125963355&quot;,&quot;endpoints&quot;:[&quot;PLAINTEXT://192.168.7.100:19092&quot;],&quot;host&quot;:&quot;192.168.7.100&quot;,&quot;version&quot;:2,&quot;port&quot;:19092&lt;span&gt;}
cZxid &lt;/span&gt;= 0x1000001c1&lt;span&gt;
ctime &lt;/span&gt;= Mon Feb 22 15:26:03 CST 2016&lt;span&gt;
mZxid &lt;/span&gt;= 0x1000001c1&lt;span&gt;
mtime &lt;/span&gt;= Mon Feb 22 15:26:03 CST 2016&lt;span&gt;
pZxid &lt;/span&gt;= 0x1000001c1&lt;span&gt;
cversion &lt;/span&gt;= 0&lt;span&gt;
dataVersion &lt;/span&gt;= 0&lt;span&gt;
aclVersion &lt;/span&gt;= 0&lt;span&gt;
ephemeralOwner &lt;/span&gt;= 0x152e40aead20016&lt;span&gt;
dataLength &lt;/span&gt;= 139&lt;span&gt;
numChildren &lt;/span&gt;= 0&lt;span&gt;
[zk: &lt;/span&gt;127.0.0.1:12181(CONNECTED) 2&lt;span&gt;] 

#还有一个是查看partion
[zk: &lt;/span&gt;127.0.0.1:12181(CONNECTED) 7] get /brokers/topics/shuaige/partitions/0
&lt;span&gt;null&lt;/span&gt;&lt;span&gt;
cZxid &lt;/span&gt;= 0x100000029&lt;span&gt;
ctime &lt;/span&gt;= Mon Feb 22 10:05:11 CST 2016&lt;span&gt;
mZxid &lt;/span&gt;= 0x100000029&lt;span&gt;
mtime &lt;/span&gt;= Mon Feb 22 10:05:11 CST 2016&lt;span&gt;
pZxid &lt;/span&gt;= 0x10000002a&lt;span&gt;
cversion &lt;/span&gt;= 1&lt;span&gt;
dataVersion &lt;/span&gt;= 0&lt;span&gt;
aclVersion &lt;/span&gt;= 0&lt;span&gt;
ephemeralOwner &lt;/span&gt;= 0x0&lt;span&gt;
dataLength &lt;/span&gt;= 0&lt;span&gt;
numChildren &lt;/span&gt;= 1&lt;span&gt;
[zk: &lt;/span&gt;127.0.0.1:12181(CONNECTED) 8] 
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;参考资料说明：&lt;/p&gt;
&lt;p&gt;《极客学院kafka学习视频》&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
</description>
<pubDate>Mon, 08 Oct 2018 14:35:00 +0000</pubDate>
<dc:creator>pony1223</dc:creator>
<og:description>一、kafka使用背景 1、Kafka使用背景 在我们大量使用分布式数据库、分布式计算集群的时候，是否会遇到这样的一些问题： 这些场景都有一个共同点： 数据是由上游模块产生，上游模块，使用上游模块的数</og:description>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/pony1223/p/9757678.html</dc:identifier>
</item>
</channel>
</rss>