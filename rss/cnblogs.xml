<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>一个超级简单的demo带你走进redux的大坑 - 谢晗阳</title>
<link>http://www.cnblogs.com/xiedashuaige/p/8228222.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xiedashuaige/p/8228222.html</guid>
<description>&lt;div class=&quot;cnblogs_code&quot; readability=&quot;45&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; import React, { Component } from 'react'&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; import ReactDOM from 'react-dom'&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; import { createStore } from 'redux'&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; import { Provider, connect } from 'react-redux'&lt;span&gt;;
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; 
&lt;span&gt; 6&lt;/span&gt; 
&lt;span&gt; 7&lt;/span&gt; &lt;span&gt;class App extends Component{
&lt;/span&gt;&lt;span&gt; 8&lt;/span&gt; &lt;span&gt;    render(){
&lt;/span&gt;&lt;span&gt; 9&lt;/span&gt;         const {count, plus, minus} = &lt;span&gt;this&lt;/span&gt;&lt;span&gt;.props;
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt;         &lt;span&gt;return&lt;/span&gt;&lt;span&gt; (
&lt;/span&gt;&lt;span&gt;11&lt;/span&gt;             &amp;lt;div&amp;gt;
&lt;span&gt;12&lt;/span&gt;                 &amp;lt;button onClick={minus}&amp;gt;-&amp;lt;/button&amp;gt;
&lt;span&gt;13&lt;/span&gt;                 &amp;lt;p&amp;gt;{count}&amp;lt;/p&amp;gt;
&lt;span&gt;14&lt;/span&gt;                 &amp;lt;button onClick={plus}&amp;gt;+&amp;lt;/button&amp;gt;
&lt;span&gt;15&lt;/span&gt;             &amp;lt;/div&amp;gt;
&lt;span&gt;16&lt;/span&gt; &lt;span&gt;        )
&lt;/span&gt;&lt;span&gt;17&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;18&lt;/span&gt; &lt;span&gt;}
&lt;/span&gt;&lt;span&gt;19&lt;/span&gt; 
&lt;span&gt;20&lt;/span&gt; 
&lt;span&gt;21&lt;/span&gt; 
&lt;span&gt;22&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt;action&lt;/span&gt;
&lt;span&gt;23&lt;/span&gt; const plusAcion =&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;24&lt;/span&gt;     type: 'PLUS'&lt;span&gt;,
&lt;/span&gt;&lt;span&gt;25&lt;/span&gt;     count: 10
&lt;span&gt;26&lt;/span&gt; &lt;span&gt;}
&lt;/span&gt;&lt;span&gt;27&lt;/span&gt; 
&lt;span&gt;28&lt;/span&gt; const minusAction =&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;29&lt;/span&gt;     type: 'MINUS'&lt;span&gt;,
&lt;/span&gt;&lt;span&gt;30&lt;/span&gt;     count: 20
&lt;span&gt;31&lt;/span&gt; &lt;span&gt;}
&lt;/span&gt;&lt;span&gt;32&lt;/span&gt; 
&lt;span&gt;33&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt;reducer&lt;/span&gt;
&lt;span&gt;34&lt;/span&gt; const initialState =&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;35&lt;/span&gt;     count: 0
&lt;span&gt;36&lt;/span&gt; &lt;span&gt;}
&lt;/span&gt;&lt;span&gt;37&lt;/span&gt; const reducer = (state = initialState, action) =&amp;gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;38&lt;/span&gt;     &lt;span&gt;switch&lt;/span&gt;&lt;span&gt; (action.type) {
&lt;/span&gt;&lt;span&gt;39&lt;/span&gt;         &lt;span&gt;case&lt;/span&gt; 'PLUS'&lt;span&gt; :
&lt;/span&gt;&lt;span&gt;40&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;41&lt;/span&gt;                 count: state.count +&lt;span&gt; action.count
&lt;/span&gt;&lt;span&gt;42&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;43&lt;/span&gt;         &lt;span&gt;case&lt;/span&gt; 'MINUS'&lt;span&gt; :
&lt;/span&gt;&lt;span&gt;44&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; {
&lt;/span&gt;&lt;span&gt;45&lt;/span&gt;                 count: state.count -&lt;span&gt; action.count
&lt;/span&gt;&lt;span&gt;46&lt;/span&gt; &lt;span&gt;            }
&lt;/span&gt;&lt;span&gt;47&lt;/span&gt;         &lt;span&gt;default&lt;/span&gt;&lt;span&gt;:
&lt;/span&gt;&lt;span&gt;48&lt;/span&gt;             &lt;span&gt;return&lt;/span&gt;&lt;span&gt; initialState;
&lt;/span&gt;&lt;span&gt;49&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;50&lt;/span&gt; &lt;span&gt;}
&lt;/span&gt;&lt;span&gt;51&lt;/span&gt; 
&lt;span&gt;52&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt;store&lt;/span&gt;
&lt;span&gt;53&lt;/span&gt; let store =&lt;span&gt; createStore(reducer)
&lt;/span&gt;&lt;span&gt;54&lt;/span&gt; 
&lt;span&gt;55&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt;映射Redux state到组件的属性&lt;/span&gt;
&lt;span&gt;56&lt;/span&gt; &lt;span&gt;function&lt;/span&gt;&lt;span&gt; mapStateToProps(state) {
&lt;/span&gt;&lt;span&gt;57&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt;&lt;span&gt; { count: state.count }
&lt;/span&gt;&lt;span&gt;58&lt;/span&gt; &lt;span&gt;}
&lt;/span&gt;&lt;span&gt;59&lt;/span&gt; 
&lt;span&gt;60&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt;映射Redux actions到组件的属性&lt;/span&gt;
&lt;span&gt;61&lt;/span&gt; &lt;span&gt;function&lt;/span&gt;&lt;span&gt; mapDispatchToProps(dispatch){
&lt;/span&gt;&lt;span&gt;62&lt;/span&gt;     &lt;span&gt;return&lt;/span&gt;&lt;span&gt;{
&lt;/span&gt;&lt;span&gt;63&lt;/span&gt;         plus:()=&amp;gt;&lt;span&gt;dispatch(plusAcion),
&lt;/span&gt;&lt;span&gt;64&lt;/span&gt;         minus:()=&amp;gt;&lt;span&gt;dispatch(minusAction)
&lt;/span&gt;&lt;span&gt;65&lt;/span&gt; &lt;span&gt;    }
&lt;/span&gt;&lt;span&gt;66&lt;/span&gt; &lt;span&gt;}
&lt;/span&gt;&lt;span&gt;67&lt;/span&gt; 
&lt;span&gt;68&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt;连接组件&lt;/span&gt;
&lt;span&gt;69&lt;/span&gt; App =&lt;span&gt; connect(mapStateToProps, mapDispatchToProps)(App)
&lt;/span&gt;&lt;span&gt;70&lt;/span&gt; 
&lt;span&gt;71&lt;/span&gt; &lt;span&gt;//&lt;/span&gt;&lt;span&gt;渲染组件&lt;/span&gt;
&lt;span&gt;72&lt;/span&gt; &lt;span&gt;ReactDOM.render(
&lt;/span&gt;&lt;span&gt;73&lt;/span&gt;     &amp;lt;Provider store={store}&amp;gt;
&lt;span&gt;74&lt;/span&gt;         &amp;lt;App /&amp;gt;
&lt;span&gt;75&lt;/span&gt;     &amp;lt;/Provider&amp;gt;,
&lt;span&gt;76&lt;/span&gt;     document.getElementById('root'&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;77&lt;/span&gt; )
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;用户在界面上点击加号或者减号&lt;/p&gt;
&lt;p&gt;通过点击的那个函数在mapDispatchToProps映射上找到对于的action&lt;/p&gt;
&lt;p&gt;然后action就去找组件绑定的store&lt;/p&gt;
&lt;p&gt;store对应着reducer&lt;/p&gt;
&lt;p&gt;reducer执行当前type对应的那个switch，更改state上面的数据&lt;/p&gt;
&lt;p&gt;数据通过mapStateToProps映射到了组件上&lt;/p&gt;
</description>
<pubDate>Sun, 07 Jan 2018 07:53:00 +0000</pubDate>
<dc:creator>谢晗阳</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/xiedashuaige/p/8228222.html</dc:identifier>
</item>
<item>
<title>【JDK1.8】JDK1.8集合源码阅读——LinkedList - joemsu</title>
<link>http://www.cnblogs.com/joemsu/p/8228010.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/joemsu/p/8228010.html</guid>
<description>&lt;h2 id=&quot;一前言&quot;&gt;一、前言&lt;/h2&gt;
&lt;p&gt;这次我们来看一下常见的List中的第二个——LinkedList，在前面分析ArrayList的时候，我们提到，LinkedList是链表的结构，其实它跟我们在分析map的时候讲到的LinkedHashMap的结构有一定的相似，但是相对简单很多，今天再详细的看一下它的具体结构，以及使用的场景等。&lt;/p&gt;

&lt;h2 id=&quot;二linkedlist结构概览&quot;&gt;二、LinkedList结构概览&lt;/h2&gt;
&lt;p&gt;在看具体的结构之前我们先来看一下它的继承关系：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1256203/201801/1256203-20180107143446956-993921609.png&quot; alt=&quot;LinkedListExtends&quot;/&gt;&lt;/p&gt;
&lt;p&gt;与ArrayList不同的是，LinkedList继承了&lt;strong&gt;AbstractSequentialList&lt;/strong&gt;，从&lt;em&gt;Sequential&lt;/em&gt;这个单词可以看出，该抽象类实现的是顺序访问的结构，因为可以推测可能和链表有关。&lt;/p&gt;
&lt;p&gt;另外值得注意的是&lt;strong&gt;Deque&lt;/strong&gt;这个接口，这个类名字的由来是“double ended queue”，也就是&lt;strong&gt;双向队列&lt;/strong&gt;，即从头部和尾部都可以进行队列的操作。&lt;/p&gt;
&lt;p&gt;所以综上的话，我们可以知道，LinkedList是一个双向链表的数据结构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1256203/201801/1256203-20180107143511315-840404764.png&quot; alt=&quot;LinkedListStruct&quot;/&gt;&lt;/p&gt;
&lt;p&gt;从头部和尾部都可以对LinkedList进行遍历。&lt;/p&gt;

&lt;h2 id=&quot;三linkedlist源码阅读&quot;&gt;三、LinkedList源码阅读&lt;/h2&gt;
&lt;h3 id=&quot;linkedlist成员变量&quot;&gt;3.1 LinkedList成员变量&lt;/h3&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span class=&quot;co&quot;&gt;// list中的元素个数&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;transient&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; size = &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;;
&lt;span class=&quot;co&quot;&gt;// 链表的头节点&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;transient&lt;/span&gt; Node&amp;lt;E&amp;gt; first;
&lt;span class=&quot;co&quot;&gt;// 链表的尾节点&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;transient&lt;/span&gt; Node&amp;lt;E&amp;gt; last;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其中叫做&lt;code&gt;Node&lt;/code&gt;的内部类节点就是实现链表的关键：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;12&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span class=&quot;kw&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;class&lt;/span&gt; Node&amp;lt;E&amp;gt; {
  &lt;span class=&quot;co&quot;&gt;// 实际存放的元素&lt;/span&gt;
  E item;
  &lt;span class=&quot;co&quot;&gt;// 后一个元素&lt;/span&gt;
  Node&amp;lt;E&amp;gt; next;
  &lt;span class=&quot;co&quot;&gt;// 前一个元素&lt;/span&gt;
  Node&amp;lt;E&amp;gt; prev;
  &lt;span class=&quot;co&quot;&gt;// 构造函数元素顺序分别为前，自己，后。就像排队一样&lt;/span&gt;
  Node(Node&amp;lt;E&amp;gt; prev, E element, Node&amp;lt;E&amp;gt; next) {
    &lt;span class=&quot;kw&quot;&gt;this&lt;/span&gt;.&lt;span class=&quot;fu&quot;&gt;item&lt;/span&gt; = element;
    &lt;span class=&quot;kw&quot;&gt;this&lt;/span&gt;.&lt;span class=&quot;fu&quot;&gt;next&lt;/span&gt; = next;
    &lt;span class=&quot;kw&quot;&gt;this&lt;/span&gt;.&lt;span class=&quot;fu&quot;&gt;prev&lt;/span&gt; = prev;
  }
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;linkedlist构造方法&quot;&gt;3.2 LinkedList构造方法&lt;/h3&gt;
&lt;p&gt;由于采用的是链表结构，所以LinkedList不像ArrayList一样，有指定容量的构造方法，所以这里主要说一下传集合的构造方法。&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; LinkedList(Collection&amp;lt;? &lt;span class=&quot;kw&quot;&gt;extends&lt;/span&gt; E&amp;gt; c) {
  &lt;span class=&quot;co&quot;&gt;// 调用无参数的构造方法，其实里面什么都没有&lt;/span&gt;
  &lt;span class=&quot;kw&quot;&gt;this&lt;/span&gt;();
  &lt;span class=&quot;co&quot;&gt;// 将c集合里的元素添加进list&lt;/span&gt;
  &lt;span class=&quot;fu&quot;&gt;addAll&lt;/span&gt;(c);
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;考虑到&lt;code&gt;addAll(Collection&amp;lt;? extends E&amp;gt; c)&lt;/code&gt;作为public方法，所以要考虑到在list已经存在元素的情况下，在链表末尾添加元素：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;15&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;addAll&lt;/span&gt;(Collection&amp;lt;? &lt;span class=&quot;kw&quot;&gt;extends&lt;/span&gt; E&amp;gt; c) {
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;addAll&lt;/span&gt;(size, c);
}

&lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;addAll&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; index, Collection&amp;lt;? &lt;span class=&quot;kw&quot;&gt;extends&lt;/span&gt; E&amp;gt; c) {
  &lt;span class=&quot;co&quot;&gt;// 检查index是否在正确，即在0-size之间&lt;/span&gt;
  &lt;span class=&quot;fu&quot;&gt;checkPositionIndex&lt;/span&gt;(index);
  &lt;span class=&quot;co&quot;&gt;// 将collection转为数组&lt;/span&gt;
  Object[] a = c.&lt;span class=&quot;fu&quot;&gt;toArray&lt;/span&gt;();
  &lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; numNew = a.&lt;span class=&quot;fu&quot;&gt;length&lt;/span&gt;;
  &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (numNew == &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;)
    &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;false&lt;/span&gt;;
  &lt;span class=&quot;co&quot;&gt;// pred为前置元素， succ为后继元素&lt;/span&gt;
  Node&amp;lt;E&amp;gt; pred, succ;
  &lt;span class=&quot;co&quot;&gt;// 对pred，succ进行初始化。&lt;/span&gt;
  &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (index == size) {
    &lt;span class=&quot;co&quot;&gt;// index == size，说明要插入元素的位置就在链表的末尾，后置元素为null，前一个元素就是last&lt;/span&gt;
    succ = &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;;
    pred = last;
  &lt;span class=&quot;co&quot;&gt;// index != size， 说明在链表的中间插入，这是pred为原来index的prev，succ为原来的元素&lt;/span&gt;
  } &lt;span class=&quot;kw&quot;&gt;else&lt;/span&gt; {
    succ = &lt;span class=&quot;fu&quot;&gt;node&lt;/span&gt;(index);
    pred = succ.&lt;span class=&quot;fu&quot;&gt;prev&lt;/span&gt;;
  }
  &lt;span class=&quot;co&quot;&gt;// 搞清了前后元素的关系，就是遍历数组，逐个添加&lt;/span&gt;
  &lt;span class=&quot;kw&quot;&gt;for&lt;/span&gt; (Object o : a) {
    &lt;span class=&quot;fu&quot;&gt;@SuppressWarnings&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&quot;unchecked&quot;&lt;/span&gt;) E e = (E) o;
    Node&amp;lt;E&amp;gt; newNode = &lt;span class=&quot;kw&quot;&gt;new&lt;/span&gt; Node&amp;lt;&amp;gt;(pred, e, &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;);
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (pred == &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;)
      first = newNode;
    &lt;span class=&quot;kw&quot;&gt;else&lt;/span&gt;
      pred.&lt;span class=&quot;fu&quot;&gt;next&lt;/span&gt; = newNode;
    pred = newNode;
  }

  &lt;span class=&quot;co&quot;&gt;// 如果后继元素为空，那么插入完后的最后一个元素，就prev就是last&lt;/span&gt;
  &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (succ == &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;) {
    last = pred;
  &lt;span class=&quot;co&quot;&gt;// 否则就维护最后一个元素和之前的元素之间的关系&lt;/span&gt;
  } &lt;span class=&quot;kw&quot;&gt;else&lt;/span&gt; {
    pred.&lt;span class=&quot;fu&quot;&gt;next&lt;/span&gt; = succ;
    succ.&lt;span class=&quot;fu&quot;&gt;prev&lt;/span&gt; = pred;
  }
  
  size += numNew;
  modCount++;
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;true&lt;/span&gt;;
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;对于遍历Collection插入链表的逻辑应该是挺清晰的：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;按照前-自己-后的关系调用Node的构造方法，进行初始化。&lt;/li&gt;
&lt;li&gt;由于可能存在前一个元素pred为空的可能（构造函数调用），判断pred为空，则初始化的元素就是头节点&lt;/li&gt;
&lt;li&gt;否则就维护pred与新节点newNode直接的关系。&lt;/li&gt;
&lt;li&gt;将新节点作为pred，为下一个元素插入做准备&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;另外，作为双向链表，&lt;code&gt;node(int index)&lt;/code&gt;方法也利用了这个特性，来更快的遍历：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;Node&amp;lt;E&amp;gt; &lt;span class=&quot;fu&quot;&gt;node&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; index) {
  &lt;span class=&quot;co&quot;&gt;// 如果index在链表的前半部分，则从头部节点开始遍历&lt;/span&gt;
  &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (index &amp;lt; (size &amp;gt;&amp;gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)) {
    Node&amp;lt;E&amp;gt; x = first;
    &lt;span class=&quot;kw&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; i = &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;; i &amp;lt; index; i++)
      x = x.&lt;span class=&quot;fu&quot;&gt;next&lt;/span&gt;;
    &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; x;
  &lt;span class=&quot;co&quot;&gt;// 如果index在链表的后半部分，则从尾部节点开始遍历&lt;/span&gt;
  } &lt;span class=&quot;kw&quot;&gt;else&lt;/span&gt; {
    Node&amp;lt;E&amp;gt; x = last;
    &lt;span class=&quot;kw&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; i = size - &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;; i &amp;gt; index; i--)
      x = x.&lt;span class=&quot;fu&quot;&gt;prev&lt;/span&gt;;
    &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; x;
  }
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;对于前半部分的元素采用从头开始遍历，后半段的元素采用尾部开始遍历。&lt;/p&gt;
&lt;h3 id=&quot;linkedlist的重要方法&quot;&gt;3.3 LinkedList的重要方法&lt;/h3&gt;
&lt;h4 id=&quot;adde-e&quot;&gt;3.3.1 add(E e)&lt;/h4&gt;
&lt;p&gt;先说一下具体思路，作为链表结构，那么添加元素就是在链表的末尾插入元素，这个过程中要考虑：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;末尾元素为null，该如何处理&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;sourceCode&quot; readability=&quot;12&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;add&lt;/span&gt;(E e) {
  &lt;span class=&quot;fu&quot;&gt;linkLast&lt;/span&gt;(e);
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;true&lt;/span&gt;;
}

&lt;span class=&quot;dt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;linkLast&lt;/span&gt;(E e) {
  &lt;span class=&quot;co&quot;&gt;// 记录last节点&lt;/span&gt;
  &lt;span class=&quot;dt&quot;&gt;final&lt;/span&gt; Node&amp;lt;E&amp;gt; l = last;
  &lt;span class=&quot;co&quot;&gt;// 初始化新的节点&lt;/span&gt;
  &lt;span class=&quot;dt&quot;&gt;final&lt;/span&gt; Node&amp;lt;E&amp;gt; newNode = &lt;span class=&quot;kw&quot;&gt;new&lt;/span&gt; Node&amp;lt;&amp;gt;(l, e, &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;);
  last = newNode;
  &lt;span class=&quot;co&quot;&gt;// 对last节点进行判断&lt;/span&gt;
  &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (l == &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;)
    first = newNode;
  &lt;span class=&quot;kw&quot;&gt;else&lt;/span&gt;
    l.&lt;span class=&quot;fu&quot;&gt;next&lt;/span&gt; = newNode;
  &lt;span class=&quot;co&quot;&gt;// 元素数量+1&lt;/span&gt;
  size++;
  &lt;span class=&quot;co&quot;&gt;// 添加修改次数&lt;/span&gt;
  modCount++;
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;大体处理和LinkedHashMap的&lt;code&gt;linkNodeLast&lt;/code&gt;差不多。&lt;/p&gt;

&lt;h4 id=&quot;removeobject-o&quot;&gt;3.3.2 remove(Object o)&lt;/h4&gt;
&lt;p&gt;同样先说一下具体处理的思路：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;由于插入的元素可能为null，所以要对o进行判断，否则不论是o为null还是遍历的时候元素为null，都会导致报空指针异常&lt;/li&gt;
&lt;li&gt;找到元素后，对前后的元素关系重新维护，要考虑到元素是否在头尾的情况&lt;/li&gt;
&lt;/ol&gt;&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;remove&lt;/span&gt;(Object o) {
  &lt;span class=&quot;co&quot;&gt;// 是否为空的判断&lt;/span&gt;
  &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (o == &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;) {
    &lt;span class=&quot;co&quot;&gt;// 遍历链表寻找元素&lt;/span&gt;
    &lt;span class=&quot;kw&quot;&gt;for&lt;/span&gt; (Node&amp;lt;E&amp;gt; x = first; x != &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;; x = x.&lt;span class=&quot;fu&quot;&gt;next&lt;/span&gt;) {
      &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (x.&lt;span class=&quot;fu&quot;&gt;item&lt;/span&gt; == &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;) {
        &lt;span class=&quot;co&quot;&gt;// 找到后，重新维护删除元素的前后元素的关系&lt;/span&gt;
        &lt;span class=&quot;fu&quot;&gt;unlink&lt;/span&gt;(x);
        &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;true&lt;/span&gt;;
      }
    }
  &lt;span class=&quot;co&quot;&gt;// 与上相同&lt;/span&gt;
  } &lt;span class=&quot;kw&quot;&gt;else&lt;/span&gt; {
    &lt;span class=&quot;kw&quot;&gt;for&lt;/span&gt; (Node&amp;lt;E&amp;gt; x = first; x != &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;; x = x.&lt;span class=&quot;fu&quot;&gt;next&lt;/span&gt;) {
      &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (o.&lt;span class=&quot;fu&quot;&gt;equals&lt;/span&gt;(x.&lt;span class=&quot;fu&quot;&gt;item&lt;/span&gt;)) {
        &lt;span class=&quot;fu&quot;&gt;unlink&lt;/span&gt;(x);
        &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;true&lt;/span&gt;;
      }
    }
  }
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;false&lt;/span&gt;;
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;在&lt;code&gt;unlink&lt;/code&gt;的时候，就需要考虑前面提到的第二点：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;E &lt;span class=&quot;fu&quot;&gt;unlink&lt;/span&gt;(Node&amp;lt;E&amp;gt; x) {
  &lt;span class=&quot;dt&quot;&gt;final&lt;/span&gt; E element = x.&lt;span class=&quot;fu&quot;&gt;item&lt;/span&gt;;
  &lt;span class=&quot;co&quot;&gt;// 记录前后元素&lt;/span&gt;
  &lt;span class=&quot;dt&quot;&gt;final&lt;/span&gt; Node&amp;lt;E&amp;gt; next = x.&lt;span class=&quot;fu&quot;&gt;next&lt;/span&gt;;
  &lt;span class=&quot;dt&quot;&gt;final&lt;/span&gt; Node&amp;lt;E&amp;gt; prev = x.&lt;span class=&quot;fu&quot;&gt;prev&lt;/span&gt;;
  &lt;span class=&quot;co&quot;&gt;// prev为null说明x节点为first节点，则删除后，next为first&lt;/span&gt;
  &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (prev == &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;) {
    first = next;
  &lt;span class=&quot;co&quot;&gt;// 否则 prev的下一个元素为x的next&lt;/span&gt;
  } &lt;span class=&quot;kw&quot;&gt;else&lt;/span&gt; {
    prev.&lt;span class=&quot;fu&quot;&gt;next&lt;/span&gt; = next;
    &lt;span class=&quot;co&quot;&gt;// 设为null，方便prev的GC&lt;/span&gt;
    x.&lt;span class=&quot;fu&quot;&gt;prev&lt;/span&gt; = &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;;
  }
  &lt;span class=&quot;co&quot;&gt;// 同上&lt;/span&gt;
  &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (next == &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;) {
    last = prev;
  } &lt;span class=&quot;kw&quot;&gt;else&lt;/span&gt; {
    next.&lt;span class=&quot;fu&quot;&gt;prev&lt;/span&gt; = prev;
    &lt;span class=&quot;co&quot;&gt;// 设为null，方便next的GC&lt;/span&gt;
    x.&lt;span class=&quot;fu&quot;&gt;next&lt;/span&gt; = &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;;
  }
  &lt;span class=&quot;co&quot;&gt;// 设为null，方便GC&lt;/span&gt;
  x.&lt;span class=&quot;fu&quot;&gt;item&lt;/span&gt; = &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;;
  size--;
  modCount++;
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; element;
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h4 id=&quot;listiteratorint-index&quot;&gt;3.3.3 listIterator(int index)&lt;/h4&gt;
&lt;p&gt;最后笔者再对迭代器中的实现做一下简要的分析。&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; Iterator&amp;lt;E&amp;gt; &lt;span class=&quot;fu&quot;&gt;iterator&lt;/span&gt;() {
  &lt;span class=&quot;co&quot;&gt;// 调用AbstractList中的方法&lt;/span&gt;
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;listIterator&lt;/span&gt;();
}

&lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; ListIterator&amp;lt;E&amp;gt; &lt;span class=&quot;fu&quot;&gt;listIterator&lt;/span&gt;() {
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;listIterator&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;);
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;iterator()&lt;/code&gt;调用的其实是&lt;code&gt;listIterator()&lt;/code&gt;方法，对于不同的实现类，都会实现不同的方法。而在LinkedList中，是怎么样的呢：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; ListIterator&amp;lt;E&amp;gt; &lt;span class=&quot;fu&quot;&gt;listIterator&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; index) {
  &lt;span class=&quot;fu&quot;&gt;checkPositionIndex&lt;/span&gt;(index);
  &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;ListItr&lt;/span&gt;(index);
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;调用的是返回的是ListItr对象。&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span class=&quot;kw&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;class&lt;/span&gt; ListItr &lt;span class=&quot;kw&quot;&gt;implements&lt;/span&gt; ListIterator&amp;lt;E&amp;gt; {
  &lt;span class=&quot;co&quot;&gt;// 记录上次返回的元素&lt;/span&gt;
  &lt;span class=&quot;kw&quot;&gt;private&lt;/span&gt; Node&amp;lt;E&amp;gt; lastReturned;
  &lt;span class=&quot;co&quot;&gt;// 记录下一个元素&lt;/span&gt;
  &lt;span class=&quot;kw&quot;&gt;private&lt;/span&gt; Node&amp;lt;E&amp;gt; next;
  &lt;span class=&quot;kw&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; nextIndex;
  &lt;span class=&quot;co&quot;&gt;// 用来判断迭代过程中，是否有对元素的改动&lt;/span&gt;
  &lt;span class=&quot;kw&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; expectedModCount = modCount;

  &lt;span class=&quot;fu&quot;&gt;ListItr&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; index) {
    &lt;span class=&quot;co&quot;&gt;// 初始化next，以便在next方法中返回&lt;/span&gt;
    next = (index == size) ? &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt; : &lt;span class=&quot;fu&quot;&gt;node&lt;/span&gt;(index);
    nextIndex = index;
  }

  &lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;hasNext&lt;/span&gt;() {
    &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; nextIndex &amp;lt; size;
  }

  &lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; E &lt;span class=&quot;fu&quot;&gt;next&lt;/span&gt;() {
    &lt;span class=&quot;co&quot;&gt;// 判断是否有对元素的改动，有则抛出异常&lt;/span&gt;
    &lt;span class=&quot;fu&quot;&gt;checkForComodification&lt;/span&gt;();
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (!&lt;span class=&quot;fu&quot;&gt;hasNext&lt;/span&gt;())
      &lt;span class=&quot;kw&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;new&lt;/span&gt; NoSuchElementException();
    &lt;span class=&quot;co&quot;&gt;// next()当中的next元素就是要返回的结果&lt;/span&gt;
    lastReturned = next;
    next = next.&lt;span class=&quot;fu&quot;&gt;next&lt;/span&gt;;
    nextIndex++;
    &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; lastReturned.&lt;span class=&quot;fu&quot;&gt;item&lt;/span&gt;;
  }
  
  &lt;span class=&quot;dt&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;checkForComodification&lt;/span&gt;() {
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (modCount != expectedModCount)
      &lt;span class=&quot;kw&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;new&lt;/span&gt; ConcurrentModificationException();
  }
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;从源码就就可以知道为什么我们在迭代的过程中对集合进行了修改，就会抛出异常，这么做的目的就是为了防止多线程操作同一个集合而出现的问题。&lt;/p&gt;

&lt;h2 id=&quot;四linkedlist的使用场景&quot;&gt;四、LinkedList的使用场景&lt;/h2&gt;
&lt;p&gt;LinkedList作为链表结构的特性，可以保证其在端点操作：如插入以及删除等，速度比ArrayList快，道理很简单，ArrayList在删除后，每次都要把后面的元素往前移（虽然采用的是拷贝方法），而LinkedList只要重新维护前后元素的关系就可以了。&lt;/p&gt;
&lt;p&gt;引用Java编程思想里的话：&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;最佳的做法可能是将ArrayList作为默认选择，只有你需要使用额外的功能（个人理解为对Queue的操作），或者当程序的性能因为经常从表中间进行插入和删除而变差的时候，才去选择LinkedList。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;五总结&quot;&gt;五、总结&lt;/h2&gt;
&lt;p&gt;对于在集合中间进行频繁的插入和删除操作，或者需要使用队列特性的时候，我们可以考虑选用LinkedList。最后谢谢各位园友观看，如果有描述不对的地方欢迎指正，与大家共同进步！&lt;/p&gt;


</description>
<pubDate>Sun, 07 Jan 2018 06:40:00 +0000</pubDate>
<dc:creator>joemsu</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/joemsu/p/8228010.html</dc:identifier>
</item>
<item>
<title>适合小白/外行的git与github最基础最浅显教程 - eleven_yw</title>
<link>http://www.cnblogs.com/yaoxiaowen/p/8227873.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yaoxiaowen/p/8227873.html</guid>
<description>&lt;h3 id=&quot;首先声明这是适合小白外行初学者学生看的最基础最简单的git与github教程已经能使用svngit等工具的朋友请不要看这篇文章来浪费时间了&quot;&gt;首先声明，这是适合&lt;strong&gt;小白/外行/初学者/学生&lt;/strong&gt;看的最基础最简单的git与github教程，已经能使用svn，git等工具的朋友请不要看这篇文章来浪费时间了。&lt;/h3&gt;
&lt;p&gt;想进一步学习git的，推荐去&lt;a href=&quot;https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/&quot;&gt;廖雪峰博客&lt;/a&gt;学习。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;这是之前帮助几个外行的朋友写的最基础git教程，仅让他们理解基本概念，能够简单使用。当然教程写的也算用心，所以就重新整理一下放到博客上了。(其实主要是因为这段太忙了，没时间写新文章了，写一篇好的文章真的太耗费心血了。所以手头正好有一篇之前写的教程就整理一下发表吧)。期望能让&lt;strong&gt;小白/外行/初学者/学生&lt;/strong&gt;能理解版本控制工具的基本概念与使用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;这篇教程共计一万八千字，花了我的很多时间精力，不过最后有人依旧没学会，不得不说，这真的是一个很悲伤的故事。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;必须记住的六条命令&quot;&gt;&lt;em&gt;必须记住的六条命令。&lt;/em&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;cd&lt;/code&gt;:用来切换工作目录,最常用的一个命令。简单来讲，&lt;code&gt;cd A文件夹&lt;/code&gt;就是进入到&lt;code&gt;A文件夹&lt;/code&gt;里面的意思。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git status .&lt;/code&gt;：查看当前路径下的的状态。git下&lt;strong&gt;最最常用&lt;/strong&gt;的一个命令。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git add .&lt;/code&gt;: 把工作区的所有变化，(就是你的所有改动)，都添加到 版本库/暂存区。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git commit -m &quot;提交时说明信息&quot;&lt;/code&gt;: 更进一步提交，并说明提交log。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git push&lt;/code&gt;: 把版本库的所有更新内容， 都推送到远程服务器。(就是推代码/推上去)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git pull&lt;/code&gt;: 把代码从远程服务器拉取到本地。(俗称拉代码)&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;当我们修改了本地代码，向远程服务器推送时，我们的操作步骤如下:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;code&gt;git add .&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git commit -m &quot;提交时说明信息&quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git push&lt;/code&gt;&lt;br/&gt;&lt;strong&gt;当我们想更新本地代码，就是把服务器上最新的代码拉取下来，只需要执行一个命令。&lt;/strong&gt;&lt;br/&gt;&lt;code&gt;git pull&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;h4 id=&quot;这三条命令建议记住&quot;&gt;&lt;em&gt;这三条命令建议记住。&lt;/em&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;git log&lt;/code&gt;:查看提交历史，与各次的提交说明。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git diff&lt;/code&gt;:比较工作区与暂存区的差异，就是比较看看你到底都做了什么修改。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git clone url地址&lt;/code&gt;: 将远程服务器上项目克隆到新创建的目录中（第一次拉项目时使用， 后面的更新都用 &lt;code&gt;git pull&lt;/code&gt;了）。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h4 id=&quot;其他问题&quot;&gt;&lt;em&gt;其他问题&lt;/em&gt;&lt;/h4&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;操作时 双击&lt;code&gt;tab&lt;/code&gt;键的自动提示/补全功能。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;q&lt;/code&gt;或者&lt;code&gt;:q&lt;/code&gt;等命令代表退出(quit)。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ctrl+f&lt;/code&gt;,&lt;code&gt;ctrl+b&lt;/code&gt;快捷键在termial可以翻页，就是 上一页，下一页&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;h3 id=&quot;最重要的内容再强调一遍&quot;&gt;&lt;strong&gt;最重要的内容再强调一遍:&lt;/strong&gt;&lt;/h3&gt;
&lt;h3 id=&quot;这是给小白外行初学者学生看的最基础最简单的git与github教程已经能使用svngit等工具的朋友就不要看这篇文章来浪费时间了&quot;&gt;&lt;strong&gt;这是给&lt;em&gt;小白/外行/初学者/学生&lt;/em&gt;看的最基础最简单的git与github教程，已经能使用svn，git等工具的朋友就不要看这篇文章来浪费时间了。&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;另外，这篇文章也不是讲述git安装的，或者github账户创建，key上传的。类似的文章网上遍地都是，自己去搜索吧。&lt;/p&gt;

&lt;p&gt;git是一个分布式版本控制系统。简单来讲，如果有几个人同时开发维护一个项目的代码，那么我们就找个中央服务器，放置一份公共的代码，每个人在各自的电脑上去修改各自的代码，然后修改完，提交到中央服务器。这样大家拉代码时，就能更新到其他人修改的内容了。。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;Notice:代码只是为了便于说明。版本控制系统，管理的是文件，所以任何文件都可以。图片啦，视频文件啦，二进制文件啦，没有什么不可以的。只是我们为了行文方便，直接说代码文件。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;本教程会讲述 命令行 操作。不过也有很多人 使用图形化界面软件 比如&lt;code&gt;source tree&lt;/code&gt;或者 俗称的&lt;code&gt;小乌龟&lt;/code&gt;软件 来操作。但是基底的原理是一样的。&lt;code&gt;source tree&lt;/code&gt; 软件操作也只是命令行的 封装。并且图形化操作更加直观一些。熟悉了命令行，图形化软件操作自然也会。不会命令行，图形化软件操作也可以会，但是会理解的比较肤浅。更重要的是会了其中一个，学习另一个就非常容易了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;本篇文章之所以采用 终端(termial)命令行的方式，除了我本人平时一直使用命令行操作之外，还有重要的一点，命令行具有更广泛的适用性。换句话说，你熟悉了 git的命令行，那么利用命令行进行其他操作，比如java，python，运行测试脚本等，对你来说很easy，理解了最底层的原理，学习图形化软件也会很容易，毕竟图形化软件那么多，你永远学不完的，但是理解了底层的，就能以不变应万变。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;理解几个概念&quot;&gt;理解几个概念&lt;/h2&gt;
&lt;p&gt;工作区（Working Directory）， 版本库（Repository）/暂存区 ，（中央/远程）服务器.&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;服务器&lt;/strong&gt;的概念已经清楚了。叫做 中央服务器/远程服务器都行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;工作区&lt;/strong&gt;:就是你电脑的工作目录&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;版本库&lt;/strong&gt;:工作区有一个隐藏的 &lt;code&gt;.git&lt;/code&gt;文件夹，这个是叫做 版本库(有些文章也叫 &lt;strong&gt;暂存区&lt;/strong&gt;，不管叫什么，知道这个意思就好)。&lt;code&gt;.git&lt;/code&gt; 是隐藏文件夹。该文件内的内容很重要，因为git的控制配置等信息，都在这个隐藏文件夹里。电脑如果设置不显示隐藏文件夹，那么就会看不到。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我电脑上的一个项目，可以看到什么是工作区，暂存区.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图片名称：工作区与暂存区.png&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107125105768-428728899.png&quot; alt=&quot;工作区与暂存区.png-65.6kB&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;为什么存在一个-版本库&quot;&gt;为什么存在一个 &lt;strong&gt;版本库&lt;/strong&gt;？&lt;/h4&gt;
&lt;p&gt;我修改过的代码，直接从 &lt;strong&gt;工作区&lt;/strong&gt;提交到&lt;strong&gt;服务器&lt;/strong&gt;不就行了嘛，为什么还要这么麻烦。&lt;code&gt;svn&lt;/code&gt; 等集中式版本管理系统就是这么做的，简单明了，但是如果你没网络时怎么办？所以有了 &lt;strong&gt;版本库&lt;/strong&gt;，那么你可以把代码先从工作区提交到版本库，等待有网络了，可以再提交到服务器。&lt;/p&gt;
&lt;h4 id=&quot;gitignore文件是干啥的&quot;&gt;&lt;code&gt;.gitignore&lt;/code&gt;文件是干啥的?&lt;/h4&gt;
&lt;p&gt;工作区的目录下面，总会存在很多乱七八糟的文件，比如你本地的配置，编译生成的中间文件等，这些文件你不想(或不能)提交到 服务器。那怎么办呢。就把这些文件的规则写到 &lt;code&gt;.gitignore&lt;/code&gt;文件中，这样git就会 ignore(忽略)这些文件，git就会像没看到这些文件一样。&lt;/p&gt;
&lt;p&gt;比如我的&lt;code&gt;.gitignore&lt;/code&gt;文件有些内容如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107125311065-1084858984.png&quot; alt=&quot;git忽略文件.png-3.6kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这几句话的意思是 所有apk后缀的文件，class后缀的文件都忽略，&lt;code&gt;bin/&lt;/code&gt;和&lt;code&gt;gen/&lt;/code&gt;目录下的文件也忽略。说的通俗一点，就是你git别管这些文件了，这些和git没屁关系。我不管怎么倒腾这些文件，都和git没关系。另外, &lt;code&gt;.gitignore&lt;/code&gt; 文件中，&lt;code&gt;#&lt;/code&gt;号开头的行 代表注释，就像 编程文件中的&lt;code&gt;//&lt;/code&gt;开头的行一样。&lt;/p&gt;
&lt;h2 id=&quot;几个简单的命令&quot;&gt;几个简单的命令。&lt;/h2&gt;
&lt;p&gt;怎么创建一个被git控制的项目，后面再讲，这里先讲述几个基本命令。&lt;/p&gt;
&lt;p&gt;在此之前，先熟悉一个 &lt;code&gt;cd&lt;/code&gt;命令。&lt;/p&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;&lt;code&gt;cd&lt;/code&gt;命令用来切换工作目录,linux,mac环境下最常用的一个命令。 简单来讲，&lt;code&gt;cd A文件夹&lt;/code&gt;就是进入到A文件夹里面的意思。比如我要进入d盘我的代码文件夹, 输入命令 &lt;code&gt;cd /d/code/github_blog/&lt;/code&gt;然后回车。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;假设你在一个项目中修改了某些文件。&lt;/p&gt;
&lt;p&gt;你想看看当前目录下是什么状态，命令 &lt;code&gt;git status .&lt;/code&gt;。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;code&gt;.&lt;/code&gt; : 一个点代表当前目录，&lt;code&gt;..&lt;/code&gt;：两个点 代表上级目录。 (这和git无关，这是 计算机基本的常识)。那么请思考,&lt;code&gt;cd ..&lt;/code&gt;,这个命令是啥意思？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;但是你敲命令的时候，记不清楚了，或者 打错了了。看看termial会有什么反应?&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ git satds
git: 'satds' is not a git command. See 'git --help'.

Did you mean this?
        status&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;有很多的概念和操作，都和什么git无关,都是计算机领域中的基本常识，或者 所有(至少绝大部分)软件都遵循的操作常识，git自然也同样遵循这样概念和操作，这些内容我会用斜体的 &lt;em&gt;计算机常识&lt;/em&gt; 来标注。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;&lt;code&gt;$ git satds&lt;/code&gt;一行，&lt;strong&gt;$&lt;/strong&gt; 代表的是命令行的开始，后面的内容代表的就是你的输入内容。而 它的下一行就是系统反馈/回应 你的内容。(或者说系统输出)。(&lt;em&gt;计算机常识&lt;/em&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;你看到什么？git会问你， 它不认识这个命令啊，你是不是敲错了，你可以用&lt;code&gt;git --help&lt;/code&gt;寻求帮助哦。另外你是不是想打 &lt;code&gt;status&lt;/code&gt; 这个词呢？ 所以git的命令根本 不用背，有个简单的印象就好。&lt;/p&gt;
&lt;p&gt;甚至，你在敲打命令的时候，根本不用敲完，输入头几个字符，然后直接 敲击 &lt;code&gt;tab&lt;/code&gt;键，看看会发生什么?&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ git sta //敲击 tab
stage    stash    status&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;系统直接提示你了，&lt;code&gt;sta&lt;/code&gt;开头的命令有三个，就看你想用哪个了，这是为了你记忆。&lt;br/&gt;而你敲击 &lt;code&gt;git stat&lt;/code&gt;之后，再敲击 &lt;code&gt;tab&lt;/code&gt;,再看看 会发生什么。因为此时 &lt;code&gt;stat&lt;/code&gt;开头的命令只剩下一个了&lt;code&gt;status&lt;/code&gt;,所以你也只能打这个命令了。所以git自动帮你补全了。。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;点击&lt;code&gt;tab&lt;/code&gt;键的 自动提示/补全功能很有用，绝大部分命令行操作都有这个快捷键，毕竟那么长的命令，文件路径等，记忆很难，打字也很累。不过有些termial情况，是点击一次&lt;code&gt;tab&lt;/code&gt;键，而有些则是双击&lt;code&gt;tab&lt;/code&gt;键，反正你可以总是双击&lt;code&gt;tab&lt;/code&gt;键，这总不会错。(&lt;em&gt;计算机常识&lt;/em&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;费了好大劲，我们终于输入了正确的字符。看看 命令行 会输出什么内容。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图片名称：git_status.png&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107125432753-1060517396.png&quot; alt=&quot;git_status.png-11.5kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;我在测试前，做了以下几件事情：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;新建立一个 &lt;code&gt;test0908.txt&lt;/code&gt; 文件。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;CachedThreadPool.java&lt;/code&gt; 文件中修改了一些内容。&lt;/li&gt;
&lt;li&gt;删除了 &lt;code&gt;DirectThread&lt;/code&gt;文件。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;然后你看看 git 输出的内容。我们逐行进行分析。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;On branch master
Your branch is up-to-date with 'origin/master'.  &lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;第一行不用管，这是 分支(branch)的概念，基础教程不涉及分支。(想进一步学习了去&lt;a href=&quot;https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/&quot;&gt;廖雪峰的博客&lt;/a&gt;)&lt;br/&gt;第二行：你的分支与远程分支已经同步了。（就是远程服务器并不比你的代码新）&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Changes not staged for commit:
  (use &quot;git add/rm &amp;lt;file&amp;gt;...&quot; to update what will be committed)
  (use &quot;git checkout -- &amp;lt;file&amp;gt;...&quot; to discard changes in working directory)

        modified:   java/src/thread_runnable/CachedThreadPool.java
        deleted:    java/src/thread_runnable/DirectThread.java&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;翻译一下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;改变还没有到提交阶段呢。
(使用   `git add &amp;lt;file&amp;gt;...`  命令 来更新 你的提交。)
(使用 `git checkout -- &amp;lt;file&amp;gt;...`命令来放弃你工作区的修改 )
 然后下面 列出了你修改的具体文件。
 `modified`代表修改，`deleted`代表 删除。(还有add表示增加，像svn中就直接简写M，D，A了，如果如果看到了这些简写了,要明白什么意思)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;提示内容已经非常明明白白的告诉你了，你的修改内容，以及你下一步可以怎么做了。&lt;br/&gt;你可以 使用&lt;code&gt;git add&lt;/code&gt;命令来提交;也可以使用 &lt;code&gt;git checkout&lt;/code&gt; 来放弃修改。(就是 把工作区重新变干净,把你修改的东西都恢复了，就像 &lt;code&gt;ctrl+z&lt;/code&gt;一样)。&lt;/p&gt;
&lt;p&gt;然后还有几行：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Untracked files:
  (use &quot;git add &amp;lt;file&amp;gt;...&quot; to include in what will be committed)

        test0908.txt

no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;翻译如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;未跟踪的文件
(使用 `git add &amp;lt;file&amp;gt;...` 命令会包括下面这些提交)
  你添加的文件名
 现在还没走到commit地步呢。(可以使用 `git add` 或者  `git commit -a`)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;首先 &lt;code&gt;test0908.txt&lt;/code&gt;为什么是 &lt;code&gt;Untracked files&lt;/code&gt;,因为我刚才就说了，我的这个文件是 新添加的，git之前没见过这个文件(git刚刚第一次见到这个文件，所以感觉很面生，不认识啊)。所以它说这个文件未跟踪，而上面那两个文件 &lt;code&gt;CachedThreadPool.java&lt;/code&gt;和&lt;code&gt;DirectThread.java&lt;/code&gt;这两个文件，因为之前早就添加了,所以git系统会认识这两个文件。&lt;/p&gt;
&lt;p&gt;那么现在工作区就是这个样子了。&lt;/p&gt;
&lt;p&gt;我想看看我具体到某个文件进行了什么修改。该怎么操作呢。&lt;br/&gt;&lt;code&gt;git diff&lt;/code&gt; 操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107125630503-127603544.png&quot; alt=&quot;git_diff.png-38kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这个内容显示的有些乱七八糟。&lt;/p&gt;
&lt;p&gt;首先你看到 它列出了第一个文件&lt;br/&gt;&lt;code&gt;diff --git a/java/src/thread_runnable/CachedThreadPool.java b/java/src/thread_runnable/CachedThreadPool.java&lt;/code&gt;&lt;br/&gt;前面一个a，后面一个b，其实就是代表你修改前后的文件。(不用关心这些)。&lt;br/&gt;然后下面，是具体内容，&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;所有 &lt;code&gt;+&lt;/code&gt; 开头的，代表的都是你添加的内容，&lt;/li&gt;
&lt;li&gt;所有 &lt;code&gt;-&lt;/code&gt;开头的，代表的都是你删除的内容。&lt;/li&gt;
&lt;li&gt;那些既没有&quot;+&quot;也没有&quot;-&quot;开头的行，就是和你修改区域的相关上下文，有了这些上下文，可以更好的帮你回想起来，你到底都修改了什么了。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;并且它们显示的颜色也不同。&lt;/p&gt;
&lt;p&gt;然后它列出了你修改的的第二个文件。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;diff --git a/java/src/thread_runnable/DirectThread.java b/java/src/thread_runnable/DirectThread.java
deleted file mode 100644&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;它也提示你了，你把这个文件删除了。&lt;br/&gt;而具体的提示，则全部是红色的 &lt;code&gt;-&lt;/code&gt;号区域。为什么是全部是 &lt;code&gt;-&lt;/code&gt;号区域，因为你把这个文件都删除了，那自然是相当于你把所有的内容都删除了。&lt;/p&gt;
&lt;p&gt;为什么 你添加的 &lt;code&gt;test0908.txt&lt;/code&gt; 文件没有被这个命令提示，因为 这个文件还没有被跟踪，再说，也没必要显示啊。因为这个文件的所有内容 都是你新添加的。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;我把termial的界面调整到最大了。所以可以全部输出，如果文件改动很多/termial界面太小，一屏幕输出不完。那么 &lt;code&gt;ctrl+f&lt;/code&gt;,&lt;code&gt;ctrl+b&lt;/code&gt;快捷键分别显示 上一页，下一页，&lt;code&gt;q&lt;/code&gt;或者&lt;code&gt;:q&lt;/code&gt;等命令代表退出(quit)。(&lt;em&gt;计算机常识&lt;/em&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;上面虽然解释了&lt;code&gt;git diff&lt;/code&gt; 命令的意思。但是这个显示的确让人眼花缭乱。而 &lt;code&gt;source tree&lt;/code&gt;等图形化工具，关于这个对比显示，的确直观了很多。&lt;/p&gt;
&lt;p&gt;图形化界面是类似下面这样显示的，看着 直观了许多。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图片名称：git_diff_图形化界面.png&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107125728565-1223288166.png&quot; alt=&quot;git_diff_图形化界面.png-113.8kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;(其实eclipse等IDE，都附带了类似的工具帮助你比较你都修改了什么，显示结果用图形化界面形式来显示，比较直观，不过这里就不做具体说明了。但是&lt;code&gt;git diff&lt;/code&gt;的确比较少用，因为这种termial输出看的眼睛都花了)&lt;/p&gt;
&lt;p&gt;我们 已经知道了工作区的状态，也知道修改了哪些内容。&lt;br/&gt;那么下面该做什么呢。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git status .&lt;/code&gt;时，已经很清楚的提示下一步命令是什么了。&lt;/p&gt;
&lt;p&gt;我们先把文件从 工作区提交到 版本库。&lt;br/&gt;本次提交时，你可以只添加某一个文件，其他文件你没修完还不想提交呢: &lt;code&gt;git add java/src/thread_runnable/CachedThreadPool.java&lt;/code&gt;&lt;br/&gt;也可以 一次提交两个文件(文件中间空格分割): &lt;code&gt;git add java/src/thread_runnable/CachedThreadPool.java test0908.txt&lt;/code&gt;&lt;br/&gt;你当然也可以一起提交所有的修改。&lt;code&gt;git add .&lt;/code&gt;(一般常用的就是这个命令,修改了就全部添加，省的麻烦)&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;思考一下最后一个命令为什么是这样，不要忘记一个点&lt;code&gt;.&lt;/code&gt;代表什么。&lt;br/&gt;更别忘记了刚才强调的&lt;code&gt;tab&lt;/code&gt;快捷键， 否则那么长的文件路径打字累不累啊。(当然，你复制粘贴也可以的)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;好。我们把 所有文件提交了，&lt;br/&gt;&lt;code&gt;$ git add .&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这一步没有没有任何输出。&lt;/p&gt;
&lt;p&gt;此时 &lt;code&gt;git status .&lt;/code&gt;看看 什么状态。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图片名称：git_status_after_add.png&lt;/em&gt;&lt;br/&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107125821237-1636389232.png&quot; alt=&quot;git_status_after_add.png-19.4kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;提示区域已经告诉我们了可以怎么做了。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;你可以使用 `git reset HEAD &amp;lt;file&amp;gt;...` 来恢复上一步操作。&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这里提示了怎么进行恢复。而上面那句话是啥？你可以进行&lt;code&gt;committed&lt;/code&gt;啊,(当然，git直接提示使用&lt;code&gt;git commit&lt;/code&gt;进行更进一步的提交才完美。)&lt;br/&gt;然后 我执行 下面命令，进行更进一步的提交操作。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git commit -m &quot;我这只是一次提交测试，进行教学的提交测试&quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;命令的 &lt;code&gt;-m &quot;提交说明&quot;&lt;/code&gt; 是添加说明的。&lt;/p&gt;
&lt;p&gt;此时你的代码改动都已经放到了 &lt;strong&gt;版本库&lt;/strong&gt;了。&lt;/p&gt;
&lt;p&gt;然后再 &lt;code&gt;git status .&lt;/code&gt;,看看提示了什么:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图片名称：git_status_after_commit.png&lt;/em&gt;&lt;br/&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107132912034-1410430464.png&quot; alt=&quot;git_status_after_commit.png-25.5kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;下面几句话值得注意：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Your branch is ahead of 'origin/master' by 1 commit.
  (use &quot;git push&quot; to publish your local commits)
nothing to commit, working directory clean&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;origin&lt;/code&gt;是原点，远程的意思。所以这句话是这个意思。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;你可以 使用 `git push` 来向远程 发布你的 变化。(其实就是推送到远程服务器&amp;gt;)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;那么我们就 &lt;code&gt;git push&lt;/code&gt;吧。。把 版本库的东西，推送到远程服务器。因为你写了代码，本来就是为了提交到远程服务器嘛。。&lt;/p&gt;
&lt;p&gt;我们来看看 &lt;code&gt;git push&lt;/code&gt;之后，提示了什么。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图片名称：git_push .png&lt;/em&gt;&lt;br/&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107125932987-924155777.png&quot; alt=&quot;git_push .png-30.6kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这次操作输出的内容也是让人眼花缭乱，上面的那一部分同样是相关提示，告诉我们可以使用更详细的命令，这个区域不用管。我也没研究过什么内容，关注一下我红框画出来的内容。&lt;/p&gt;
&lt;p&gt;其实在输入&lt;code&gt;git push&lt;/code&gt;命令时，输出会停留在下面这一行，等待你输入密码。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Enter passphrase for key '/c/Users/Administrator/.ssh/id_rsa':&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个是我们在最初设置git环境时，设置的ssh密码，比如我的电脑上设置的是 123456。输入了密码，然后才能输出下面那些内容，代表此时我们的操作已经完成了。&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;有些人的电脑上，使用 &lt;code&gt;git push&lt;/code&gt;时， 并没有输入密码这一步骤，那是因为他们在最初配置git环境时，把密码这步省略了(或者记住了密码)，所以他们不用输入密码。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;下面这几句内容。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Counting objects: 7, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (5/5), done.
Writing objects: 100% (7/7), 671 bytes | 0 bytes/s, done.
Total 7 (delta 4), reused 0 (delta 0)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;是一些push时的 提示内容，不必关心(反正我也看不懂)。。&lt;br/&gt;再下面两句。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;To git@git.oschina.net:yaowen369/ConcurrentDemo.git
   5c53c8f..0e522fe  master -&amp;gt; master&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;To 代表的意思是目的地，你本地提交到了哪里？因为我的这个项目放在了 &lt;code&gt;oschina&lt;/code&gt; 托管网站上了，(oschina地址:&lt;a href=&quot;http://git.oschina.net/&quot; class=&quot;uri&quot;&gt;http://git.oschina.net/&lt;/a&gt;) 所以就是说，我的代码被提交到了 那个地址了。 本地master分支到 远程master分支。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;&lt;code&gt;oschina&lt;/code&gt;和github一样，都是代码托管网站。（当然，你托管其他文件自然也可以）。类似的网站有很多，还有&lt;code&gt;gitlab&lt;/code&gt;之类的， 不过github最有名罢了。 所谓托管，意思就是相当于他们提供了一个远程服务器，供你放置你的文件。这个问题下面的内容会讲到。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;到了这个步骤，我们修改的内容，都已经被提交到了远程服务器上，虽然有时候敲击命令时，&lt;code&gt;termial&lt;/code&gt;提示了我们很多乱七八糟看不懂的内容，但是这不重要，看不懂也很正常，完全看懂也没必要，因为我们的目的已经达到了，就是 把本地修改 提交到了 远程服务器上了。&lt;/p&gt;
&lt;p&gt;此时我们再使用 &lt;code&gt;git status&lt;/code&gt;，看看当前状态是什么。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图片名称：git_status_after_pull.png&lt;/em&gt;&lt;br/&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107130053831-965346904.png&quot; alt=&quot;git_status_after_pull.png-14.9kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上面的意思是说&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;你当前的分支已经和`origin/master`一样新了(就是内容一致了)。
没有什么东西要提交，你的工作区很干净。&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;此时，我打开了我的mac电脑，我的mac电脑上也有这个项目。我有时候在公司电脑上写代码，有时候在自己的mac电脑上写代码，所以有了git，都可以方便的在不同电脑上切换。&lt;/p&gt;
&lt;p&gt;我在自己的mac电脑上，进入到对应的代码目录，使用了 &lt;code&gt;git pull&lt;/code&gt;命令，看看什么反应。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;有些时候，也会要求你输入&lt;code&gt;ssh&lt;/code&gt;的命令，才能拉代码，直接输入之前设置的123456密码就行了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;图片名称：git_pull.png-&lt;/em&gt;&lt;br/&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107130155987-1191666878.png&quot; alt=&quot;git_pull.png-149.1kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;最上面的那几句话不用看(我也看不懂,也完全没看懂的必要)。&lt;br/&gt;只看最重要的部分&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;From https://git.oschina.net/yaowen369/ConcurrentDemo 

   5c53c8f..0e522fe  master     -&amp;gt; origin/master
Updating 5c53c8f..0e522fe
Fast-forward
 java/src/thread_runnable/CachedThreadPool.java |  5 ++++-
 java/src/thread_runnable/DirectThread.java     | 24 ------------------------
 test0908.txt                                   |  1 +&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这个文件从 &lt;code&gt;oschina&lt;/code&gt;远程服务器拉下来了，并且这次 拉取 更新了那些文件呢。。就是下面三个。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; java/src/thread_runnable/CachedThreadPool.java |  5 ++++-
 java/src/thread_runnable/DirectThread.java     | 24 ------------------------
 test0908.txt                                   |  1 +&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;这不就是我在自己办公电脑上修改的那三个文件吗？并且看到后面的 &lt;code&gt;+&lt;/code&gt;,&lt;code&gt;-&lt;/code&gt; 符号，它还告诉你了，有些我们添加内容了，有些我们删除内容了。所以到了这个时候，&lt;br/&gt;我们通过&lt;code&gt;status&lt;/code&gt;,&lt;code&gt;add&lt;/code&gt;,&lt;code&gt;commit&lt;/code&gt;，&lt;code&gt;push&lt;/code&gt;,&lt;code&gt;pull&lt;/code&gt;这五个简单的命令，我们就能简单的使用 git了。。这已经能满足我们日常80%的需求了。（对于一个人开发的项目，而不是 团队多人开发模式来讲，这五个命令已经能满足95%的日常需求了）&lt;/p&gt;
&lt;p&gt;至于有些命令的提示输出内容等，看不懂就看不懂了，都看懂又有啥用。我们只要会用就可以了。比如 &lt;code&gt;git push&lt;/code&gt;命令之后，termial提示输出了那么多的内容，你只要简单的能看懂，我们推送成功(还是失败)了这就ok了。其他的不用管。&lt;/p&gt;
&lt;h2 id=&quot;冲突问题&quot;&gt;冲突问题&lt;/h2&gt;
&lt;p&gt;可是人生哪有处处都如意的时候呢，代码也是如此。如果A和B都同时修改了同一个文件会发生什么呢，此时就会发生冲突。&lt;/p&gt;
&lt;p&gt;比如张三修改了 A.java文件上传到了中央服务器，然后李四在本地也修改了 A.java文件，李四想提交文件时，会提示因为冲突而无法提交。系统要求你先把代码拉下来，合并了A.java的冲突(这个合并过程，其实有时候git会自动合并，但是复杂的合并git做不了，所以就要求李四自己去合并冲突)，然后李四才能提交上去。。。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;当然，你工作电脑上提交，然后 自己私人笔记本上又修改了同一个文件，这和上面是同样的意思，只是 我们用张三李四来方便表达。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;所以为了避免潜在冲突一个好习惯就是 你在修改你的代码之前，先&lt;code&gt;git pull&lt;/code&gt;一下，把服务器的最新代码拉下来,这是一个好习惯。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;因此我们开发时，有时候早晨来了第一件事情，就是先把代码&lt;code&gt;git pull&lt;/code&gt;一下，进行更新。这是个好的开发习惯。避免你写了很多代码，你同事也写了很多代码，然后冲突了，你们俩合并的时候，比较浪费时间。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我现在就实际做一个冲突的demo，演示冲突是怎么发生的，又怎么解决。其实都很好解决。。&lt;/p&gt;
&lt;p&gt;我在自己的mac电脑上修改了 &lt;code&gt;FixedThreadPool.java&lt;/code&gt;文件，然后 在mac电脑上 操作了 &lt;code&gt;add&lt;/code&gt;,&lt;code&gt;commit&lt;/code&gt;,&lt;code&gt;push&lt;/code&gt;操作，提交到了远程服务器上。&lt;/p&gt;
&lt;p&gt;而同时，我在自己的工作电脑上， 也对 &lt;code&gt;FixedThreadPool.java&lt;/code&gt;文件 进行了修改。然后我在自己的工作电脑上， 执行了&lt;code&gt;add&lt;/code&gt;,&lt;code&gt;commit&lt;/code&gt;操作，现在我要提交了，我执行了 &lt;code&gt;push&lt;/code&gt;操作，看看会发生什么。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图片名称：git_push_error_because_confilt.png&lt;/em&gt;&lt;br/&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107130318362-1966304377.png&quot; alt=&quot;git_push_error_because_confilt.png-63.2kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;此时再看看对方 termial提示了什么。输出了一大串内容，前面的内容不用关心。&lt;br/&gt;我们只看最后一段主要内容。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;To git@git.oschina.net:yaowen369/ConcurrentDemo.git
 ! [rejected]        master -&amp;gt; master (fetch first)
error: failed to push some refs to 'git@git.oschina.net:yaowen369/ConcurrentDemo.git'
hint: Updates were rejected because the remote contains work that you do
hint: not have locally. This is usually caused by another repository pushing
hint: to the same ref. You may want to first integrate the remote changes
hint: (e.g., 'git pull ...') before pushing again.
hint: See the 'Note about fast-forwards' in 'git push --help' for details.
&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;翻译其中的主要内容：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt; ! [拒绝]        master -&amp;gt; master (fetch first)
错误：向'git@git.oschina.net:yaowen369/ConcurrentDemo.git'执行 `push`时，发生了某些错误。
提示：更新之所以被拒绝是因为 远程分支包含了你本地没有的内容，这通常是因为 另一个库推送了同样的文件(ref是索引的意思，可以翻译成文件)。你可以在推送之前先合并这些远程的变化(比如，试试 git pull)。

你可以看看 `git push --help`中的 `Note about fast-forwards`了解更多的细节。&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;10&quot;&gt;
&lt;p&gt;其实在命令行中，help是很有用的，可以提示很多有用的帮助信息，不过有些termial要求直接 命令后面输入 help就好了，有些要求输入 &lt;code&gt;-help&lt;/code&gt;,有些要求输入 &lt;code&gt;--help&lt;/code&gt;,或者有些直接输入 &lt;code&gt;-h&lt;/code&gt;/&lt;code&gt;--h&lt;/code&gt;也行，但是我们始终要有这个意识，因为太多东西不用记忆，有个大概的印象就好。(&lt;em&gt;计算机常识&lt;/em&gt;)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;看到这些提示内容，即使你第一次碰到这个问题，你下一步准备怎么做？人家已经给你提示了啊。直接 &lt;code&gt;git pull&lt;/code&gt;啊。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Notice&lt;/strong&gt;:在你输入 &lt;code&gt;git pull&lt;/code&gt;时，有时候termial会要求你输入密码，有时候不会，但是 很快的，termial就会完全的跳转到一个新的页面，这应该是你第一个碰到这种情况。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图片名称：git_pull_confilit_vi.png&lt;/em&gt;&lt;br/&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107130439206-526349209.png&quot; alt=&quot;git_pull_confilit_vi.png-35kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这其实是个&lt;code&gt;vi&lt;/code&gt;编辑器，(&lt;code&gt;vim&lt;/code&gt;是&lt;code&gt;vi&lt;/code&gt;的升级版，因为&lt;code&gt;vim&lt;/code&gt;颜色高亮做的比较好，看起来更舒服)。&lt;br/&gt;我们在之前执行 &lt;code&gt;git commit -m &quot;相关提交的log内容&quot;&lt;/code&gt;这个命令时， 直接输入 一行提交说明内容，所以没那么复杂，我们就写一句话 说明一下而已(搞那么复杂干啥子)。但是你如果执行 &lt;code&gt;git commit&lt;/code&gt;, 不带&lt;code&gt;-m&lt;/code&gt; 然后你直接敲击回车，也会进入这个vi页面。(因为你没使用一行的提交说明模式，系统会以为你想长篇大论的去写提交信息呢，所以专门给你准备个编译器，你好好写吧，想写多少，就写多少)&lt;/p&gt;
&lt;p&gt;说简单点，vi和你的&lt;code&gt;word&lt;/code&gt;,&lt;code&gt;notepad&lt;/code&gt;,&lt;code&gt;sublime text&lt;/code&gt;没啥区别，包括和你电脑上新建个 &lt;code&gt;文本文档&lt;/code&gt;，都是一回事， 都只是一个&lt;strong&gt;文本编译器&lt;/strong&gt;， 但是这个 vi的历史可比后面的那几个历史早太多了，上世纪八十年代，电脑图形化界面还没发明呢，当时电脑操作都是黑乎乎的命令行窗口操作(其实现在window，linux也可以直接黑乎乎的termial操作，只是那么多命令，大家都记不住，有了鼠标和图形化界面，黑乎乎的命令行操作都被忘记了，只剩下程序员使用termial了)。&lt;code&gt;word&lt;/code&gt; 等更无从谈起，但是大家很多时候也要 编译文本啊，又没有word等，所以vi就是一个当时环境下的 termial环境操作的 &lt;strong&gt;文本编译器&lt;/strong&gt;，完全 键盘操作，有无数复杂的 快捷键，你使用vi操作，完全不用接触鼠标，所以操作也比较快(当然是在你比较熟悉快捷键的情况下，否则你就尴尬了)。&lt;/p&gt;
&lt;p&gt;我们这里呢，不讨论vi。vi的操作是另一个话题。(其实也不是难，而是那么多复杂的快捷键组记忆着比较困难而已)。&lt;/p&gt;
&lt;p&gt;我们可以看看 它上面的内容说了什么。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Please enter a commit message to explain why this merge is necessary, 

Lines starting with '#' will be ignored&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;翻译内容：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;请输入一些提交内容来解释为什么这次合并是必须的。
以`#`号开头的行都会被忽略（注释的作用）&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其实上面那句&lt;code&gt;Merge branch 'master' of git.oschina.net:yaowen369/ConcurrentDemo&lt;/code&gt;,就是它默认帮你生成的 提交信息。&lt;br/&gt;反正你不用管（因为你要搞定这个，这是另一个学习内容，但是你学习这些完全没必要，虽然也不难。这也是source tree等软件的好处，使用了 source tree等图形化软件，你怎么着也不会碰到vi界面），还记得 怎么退出不？&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;输入&lt;code&gt;:q&lt;/code&gt;, 字符&lt;code&gt;q&lt;/code&gt;代表是退出(quit)的意思，不过这个 &lt;code&gt;vi&lt;/code&gt;的退出要 一个冒号+q，所以你输入 &lt;code&gt;:q&lt;/code&gt;，直接退出就好了。(git有些界面退出也是&lt;code&gt;:q&lt;/code&gt;,只是你输入命令操作的时候，git自动帮你前缀一个冒号了，所以给你省事了而已)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;你输入 &lt;code&gt;:q&lt;/code&gt;，注意左下角。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107130604628-1960249763.png&quot; alt=&quot;vi_q.png-60.2kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;vi当中&lt;code&gt;:&lt;/code&gt; 开头的都是命令模式，命令模式显示都在左下角。你输入 &lt;code&gt;:q&lt;/code&gt;回车后， 左下角出现了这么一行红色的文字。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;E37: No write since last change (add ! to override)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;你输入&lt;code&gt;:q&lt;/code&gt;竟然没用，相关区域提示你，因为这个文件你啥都没改动，所以你要加个&lt;code&gt;!&lt;/code&gt;号去覆盖(其实就是强制退出模式)。 然后你直接输入 &lt;code&gt;:q!&lt;/code&gt;就好了。(直接输入&lt;code&gt;:&lt;/code&gt;号就好了，那行红色的提示就消失了，然后你接着输入&lt;code&gt;q!&lt;/code&gt;就好了，你试图用键盘上的&lt;code&gt;delte&lt;/code&gt;等按键去删除红色文字没用的)&lt;/p&gt;
&lt;p&gt;还要讨论vi的相关内容。但是不讨论用户十有八九又会碰到这个问题，当年我第一次碰到vi问题，连怎么退出都搞不定，急的满头大汗。所以不得不讨论。&lt;/p&gt;
&lt;p&gt;终于我们退出了 &lt;code&gt;vi&lt;/code&gt;，看看具体提示了什么。。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107130703753-298527112.png&quot; alt=&quot;confilit_after_vi.png-29.1kB&quot;/&gt;&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;红色方框内的内容不要管，那是因为我第一次在vi中输入命令 时，输错了 &lt;code&gt;:!q&lt;/code&gt;，所以vi提示 q命令找不到，我又重新进入输入了 &lt;code&gt;:q!&lt;/code&gt;，就ok了。。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们看重点内容：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Auto-merging java/src/thread_runnable/FixedThreadPool.java

Merge made by the 'recursive' strategy.
 java/src/thread_runnable/FixedThreadPool.java | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;注意：&lt;code&gt;Auto-merging&lt;/code&gt;自动合并了。也就是说， 因为我刚才测试的冲突比较简单，所以 git自动比较合并了。(比如张三修改了文件的第一行，李四修改了文件的最后一行，这种简单的，git就能自动合并，但是张三李四都修改了 文件的第一行，那就只能手动合并了)。&lt;/p&gt;
&lt;p&gt;那么此时你使用&lt;code&gt;git status&lt;/code&gt;来查看状态，&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ git status .
On branch master
Your branch is ahead of 'origin/master' by 2 commits.
  (use &quot;git push&quot; to publish your local commits)
nothing to commit, working directory clean&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;你的工作区很干净，没啥可commit的，但是 注意上面那句话&lt;br/&gt;&lt;code&gt;Your branch is ahead of 'origin/master' by 2 commits.&lt;/code&gt;&lt;br/&gt;你当前的分支领先 远程分支 两次提交。&lt;/p&gt;
&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;为啥是两次，因为本来你就commit了一次，然后 &lt;code&gt;git pull&lt;/code&gt;时，又自动合并commit一次，所以就两次了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;不用关心几次，看到重点就对了，你当前的分支领先远程分支。&lt;br/&gt;另外，扯了这么大一段，别忘记了最初咱们的目的是什么，咱们最初的目标就是 推送代码到远程服务器。&lt;/p&gt;
&lt;p&gt;所以接下来直接 &lt;code&gt;git push&lt;/code&gt;，将 代码直接推送到远程服务器就好了。&lt;/p&gt;
&lt;p&gt;这次的冲突因为我制造的比较简单，所以自动合并了，但是有些冲突比较复杂，git无法自动合并，&lt;br/&gt;那么此时就需要你手动合并了。&lt;/p&gt;
&lt;p&gt;下面的demo直接借用了网上别人的代码冲突内容 ，我针对输出进行解释。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ git pull
Auto-merging test.txt
CONFLICT (content): Merge conflict in test.txt
Automatic merge failed; fix conflicts and then commit the result.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;系统提示你，&lt;code&gt;test.txt&lt;/code&gt;文件冲突了，自动合并失败了，你需要解决冲突，然后并提交。。&lt;/p&gt;
&lt;p&gt;好，我打开&lt;code&gt;test.txt&lt;/code&gt;文件，会看到下面的情况。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Git has a mutable index called stage.
Git tracks changes of files.
&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt; HEAD
Creating a new branch is quick &amp;amp; simple.
=======
Creating a new branch is quick AND simple.
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; feature1&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;其中冲突的部分都是用 &lt;code&gt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&lt;/code&gt;，&lt;code&gt;=======&lt;/code&gt;，&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;来进行标记了，他们都代表了不同分支(或者远程/本地)不同的内容，你自己看着代码，把&lt;code&gt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&lt;/code&gt;，&lt;code&gt;=======&lt;/code&gt;，&lt;code&gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;进行删除，该删除的代码部分也进行删除。&lt;/p&gt;
&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;如果是你自己写的代码，你肯定知道该删除那些内容，如果不是你写的代码，比如李四写的，那么你要叫着李四讨论，把你们两个的代码合并掉。李四写的代码你又不了解业务逻辑，你不和他讨论， 就瞎合并，这在多人团队中，是大忌。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;因为你可能把李四写的代码给覆盖掉。而程序员基本上写完某个文件就不再关心了，所以李四也不知道你把他的内容覆盖掉了，这肯定会引起问题，如果测试人员能发现业务逻辑不对，那还好,最多被测试人员提个代码臭骂一顿，但如果测试不能发现，那等着线上事故吧。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;比如上面的那段冲突，我们合并成如下形式，并进行文件保存。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;Creating a new branch is quick and simple.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;合并之后，相当于你又重新 修改了文件。&lt;br/&gt;所以在此重新进行提交步骤。。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;$ git add readme.txt 
$ git commit -m &quot;老子把冲突合并了&quot;
[master 59bc1cb] 老子把冲突合并了&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;最后再push就好了。。&lt;/p&gt;
&lt;p&gt;到了这里我们就理解了平时的提交代码，拉取代码的步骤，以及怎么解决冲突。&lt;br/&gt;我们再来学习一个命令。&lt;code&gt;git log&lt;/code&gt;：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git log&lt;/code&gt;: 查看之前每次提交的说明信息:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107130829846-390932882.png&quot; alt=&quot;git_log.png-78kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;直接看输出应该一目了然了。每次提交的版本号。作者，时间，提交的信息说明 都直接列出来了。咱们之前在 &lt;code&gt;git commit -m &quot;说明信息&quot;&lt;/code&gt;，这里就有用了，否则那么多次提交，谁也没本事都记住啊。&lt;/p&gt;
&lt;p&gt;尤其是你注意最上面那个 说明信息：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;commit fb095209cc6adf53a98035cc7661d109a2024de9
Merge: 5b90fa3 c63c40b
Author: yaowen &amp;lt;yw43194@ly.com&amp;gt;
Date:   Sat Sep 9 11:45:40 2017 +0800

    Merge branch 'master' of git.oschina.net:yaowen369/ConcurrentDemo
&lt;/code&gt;
&lt;/pre&gt;
&lt;blockquote readability=&quot;13&quot;&gt;
&lt;p&gt;最上面的是 版本号(就是那一长串奇怪的字符串),git的版本号是一长串字符串，而svn的版本号就是很简单的1，2 ，3, 4阿拉伯数字,简单来讲，因为svn你每次提交拉取时，都是直接与中央服务器交互，而git则是先与版本库(暂存区)交互，多人都使用git来提交代码，他们本地的电脑时间都不一定准确，不能使用1, 2, 3，4作为版本号，因为不能简单的依据时间戳来比较。而svn则可以直接使用服务器时间。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这次提交信息，还很贴心的给你提示了，你这次提交其实是一个 合并冲突操作&lt;code&gt;merge&lt;/code&gt;，并且提交的说明信息&lt;code&gt;Merge branch 'master' of git.oschina.net:yaowen369/ConcurrentDemo&lt;/code&gt;,就是刚才合并时系统帮我们生成的。（因为当时我们在vi界面并没有修改默认的提交说明信息啊）。&lt;/p&gt;
&lt;blockquote readability=&quot;9&quot;&gt;
&lt;p&gt;注意右下角的冒号, 因为我这个项目提交很多次了，所以log说明比较多，一页显示不完，你还记得怎么上下翻页，怎么退出log提示不？(翻页一般用不到，因为我们一般看提交log也都是看最近的几次说明，不过怎么退出这肯定是要知道额)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;那么下面我们要讨论怎么结合github使用。&lt;/p&gt;
&lt;h2 id=&quot;github&quot;&gt;github&lt;/h2&gt;
&lt;p&gt;我们为什么要使用github，因为我们需要一个远程服务器啊。&lt;/p&gt;
&lt;p&gt;在本文最初的时候，就说了需要一个远程服务器，我们上面那么多的操作，都是客服端的操作。都是假设我们已经搭建好了远程服务器，而在公司里，也已经搭建好了代码服务器，所以我们平时的代码等都是发布到那里的，但是单独的个人的小项目，你代码托管到哪里呢？当然，你可以用自己的电脑搭建个git服务器，但是这是一个非常复杂的过程。所以我们就可以托管到github上之类的，这样不就给我们省了很多事情吗？反正又不要钱，对吧。&lt;/p&gt;
&lt;p&gt;github账号的创建，ssh key的上传自己去google搜索吧，我们就直接来创建一个项目..&lt;/p&gt;
&lt;p&gt;图片名字：github_new_repository.png&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107131615612-660605808.png&quot; alt=&quot;github_new_repository.png-65kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;注意那个箭头，点击加号， &lt;code&gt;New repository&lt;/code&gt;， 这就是创建一个新项目的意思。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图片名称：github_create_new_repository.png&lt;/em&gt;&lt;br/&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107131936799-2136921399.png&quot; alt=&quot;github_create_new_repository.png-53.3kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;关于这个界面：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;Repository name&lt;/code&gt;: 项目的名字，我这次的项目就叫做 &lt;code&gt;TeachDemo&lt;/code&gt;(这个名字后面会说明，和你eclipse的项目名字保持一致最好)。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Description (optional)&lt;/code&gt;，描述(可选)，这个不用多介绍了。&lt;/li&gt;
&lt;li&gt;我们只能创建&lt;code&gt;Public&lt;/code&gt;,因为 private是要money的。(不过oschina上你可以免费创建私有项目，你可以创建个项目，放你的一些电子书之类的不那么隐私的资料)。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Initialize this repository with a README&lt;/code&gt;,是否初始化一个 readme文件，是markdown格式的， 建议 勾选吧。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Add .gitigonre&lt;/code&gt;：这时候再说看不懂这栏啥意思，那就说明之前的文章都白写了。既然你写java代码，那就选择个java的。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Add a license&lt;/code&gt;:这个不用管。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;此时我们填写和勾选都已经完毕了, 点击蓝色确认按钮吧 &lt;strong&gt;Create repository&lt;/strong&gt;,&lt;br/&gt;此时进入了这个页面。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107132111846-1665594008.png&quot; alt=&quot;github_teachDemo_ok.png-60kB&quot;/&gt;&lt;br/&gt;此时该项目创建ok了。。。你会看到项目当中给你初始化了两个文件，&lt;code&gt;.gitignore&lt;/code&gt;，&lt;code&gt;README.md&lt;/code&gt;文件，这都是刚才我们勾选要求创建的。注意左边的蓝色的 &lt;strong&gt;Clone or download&lt;/strong&gt;按钮，点击会出现下面界面，然后鼠标放在右边那个小图标上，会直接给予提示 &lt;code&gt;Copy to clipboard&lt;/code&gt;。(这几个英文要是还看不懂，那让别学编程了)。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107132207128-571635648.png&quot; alt=&quot;github_ok_can_clone.png-21.4kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;也就是说，我们点击那个 小图标，会把前面的那个 ssh地址。&lt;code&gt;git@github.com:yaowen369/TeachDemo.git&lt;/code&gt;复制到剪切板，(这不就是&lt;code&gt;ctrl+c&lt;/code&gt;嘛)。&lt;/p&gt;
&lt;p&gt;我们的项目已经创建完毕了，换句话说，我们已经在远程服务器上创建了这个项目，那么下面我们的本地就已经可以用了。&lt;/p&gt;
&lt;p&gt;在你的电脑上，看你平时喜欢把代码项目放在哪里，就像我平时代码都是放在D盘的某个文件夹，所以我是这样操作的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107132344018-1905791989.png&quot; alt=&quot;termial_git_clone.png-24.7kB&quot;/&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;cd /d/code/github_blog/

git clone git@github.com:yaowen369/TeachDemo.git&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;我先通过cd命令进入了 d盘的&lt;code&gt;code/github_blog/&lt;/code&gt;文件夹下，然后我再clone这个代码。&lt;/p&gt;
&lt;p&gt;先来解释这两条命令。&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;git clone&lt;/code&gt; : 将远程服务器上的项目克隆到新创建的目录中，解释简单点，将你在远程服务器上的项目，第一次拉到本地,供你在本地使用。其实严格来讲， 该过程是将 项目代码，从服务器拉到 本地版本库，然后再从 版本库解析到 工作区。不过你关心那么多干嘛？记得 这个命令是 你在第一次想拉取某个本地没有的项目时使用就行了。(为什么是第一次？ 因为你第一次使用 &lt;code&gt;git clone&lt;/code&gt;在本地弄好之后，今后再更新服务器上的代码就使用 &lt;code&gt;git pull&lt;/code&gt;了。)。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;那么现在你理解github那个 标签为什么叫做 &lt;code&gt;Clone or download&lt;/code&gt;了吧。(如果你想查看github项目，直接下载也行。clone也行)&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;p&gt;好的。现在我们已经将 服务器上的代码，拉到本地了。 但是这个目录不是你eclipse下的项目目录。你又不想重现创建项目，我想将eclipse下的某个项目直接和github的远程服务器发生关联，因为你平时写代码都是用eclipse啊。其实很简单，将我D盘这个文件夹的所有文件，都复制到 你eclipse的某个项目的目录下，就好了。。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;图片名称：teach_demo_on_d.png&lt;/em&gt;&lt;br/&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/918357/201801/918357-20180107132504268-1031816118.png&quot; alt=&quot;teach_demo_on_d.png-61.8kB&quot;/&gt;&lt;/p&gt;
&lt;p&gt;说简单点，将该目录下的 所有文件 都复制到 你eclipse的项目的代码路径下就ok了。。。&lt;br/&gt;注意以下几点：&lt;/p&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;某些人的电脑上可能没有打开 &lt;code&gt;显示隐藏文件&lt;/code&gt;选项，所以要打开这个，因为你复制过程中，真正起作用的就是 &lt;code&gt;.git&lt;/code&gt;文件夹，最重要的隐藏文件都漏掉了，那你复制还有啥用？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;因为我们在 github上给项目取的名字就叫做 &lt;code&gt;TeachDemo&lt;/code&gt;,为了保险起见，我们建议这个名字和eclipse工程中你的项目名称保持一致。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;7&quot;&gt;
&lt;p&gt;另外 关于代码路径，建议不要带中文字符，因为有些时候，带中文路径的代码，编译等可能有很奇怪的问题，所以你看我的电脑中代码的文件路径全都是英文的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们已经拷贝完成了，然后你再 利用termial 进入到 你的 eclipse下的项目路径，然后 &lt;code&gt;git status&lt;/code&gt;，你看看会发生什么。下面的操作就会了吧。&lt;/p&gt;

&lt;p&gt;到了这里，我们的基础教程都已经讲完了,只要求你记住六个名字，六个英文字符而已。会了以上的内容，对于你一个人开发项目来说，基本上 已经能应付95%的需求了。更进一步的内容，你可以去&lt;a href=&quot;https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/&quot;&gt;廖雪峰的博客&lt;/a&gt;上学习。他写的比较通俗易懂，并且涵盖了平时团队多人开发所使用的所有基本操作了。&lt;/p&gt;
&lt;p&gt;有以下几点想说:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;整篇文章，就是在讲述 &lt;code&gt;status&lt;/code&gt;,&lt;code&gt;add&lt;/code&gt;,&lt;code&gt;commit&lt;/code&gt;,&lt;code&gt;push&lt;/code&gt;,&lt;code&gt;pull&lt;/code&gt;,外加一个&lt;code&gt;cd&lt;/code&gt;,记住这六个命令，六个单词就够了，&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;更重要的是,这几个命令，借助 &lt;code&gt;git status&lt;/code&gt;,&lt;code&gt;tab&lt;/code&gt;键自动补全/提示功能，下一步该做什么很简单啊，有些东西掌握了方法剩下的学习成本很低的。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;包括什么学习java，学习python，你会了其中任何一门，剩下的掌握其他的，都很容易。 你学习java，那么多的api方法你怎么记得住? 所以要知道查询API文档的重要性，只要有个大概印象，然后知道怎么搜索，能上google，百度这就够了了，否则那么多东西谁能记得住呢？&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;当然， 不管是git，还是java，或者任何一个领域学科。你要想深入的去理解学习，那真的很难，要想精通，那对于我们这种人来说基本是不可能的，git的命令多如牛毛，你要想成为git的专家级人才，那学习过程，难的令人发指，但是问题是，对于我们平时使用来说，就那几个命令就够了啊，你要想成为该领域的专家那就是 另外一回事了。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;ul&gt;&lt;li&gt;另外，英语水平不要太差，不过我想大学出来的，再加上各种翻译软件，google，百度，这也不是个什么难的问题。&lt;/li&gt;
&lt;/ul&gt;&lt;/blockquote&gt;
&lt;hr/&gt;
</description>
<pubDate>Sun, 07 Jan 2018 06:19:00 +0000</pubDate>
<dc:creator>eleven_yw</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/yaoxiaowen/p/8227873.html</dc:identifier>
</item>
<item>
<title>【原创】重复造轮子之高仿EntityFramework - 田乃翔</title>
<link>http://www.cnblogs.com/yiting/p/7979705.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yiting/p/7979705.html</guid>
<description>&lt;p&gt;&lt;span&gt;在上一篇《&lt;a href=&quot;http://www.cnblogs.com/yiting/p/5600262.html&quot; target=&quot;_blank&quot;&gt;【原创】打造基于Dapper的数据访问层&lt;/a&gt;》中，Dapper在应付多表自由关联、分组查询、匿名查询等应用场景时经常要手动写SQL语句。看着代码里满屏的红色SQL字符串，简直头大，于是便萌生重复造ORM这个轮子的念头。本ORM在API设计上最大程度地借鉴 EF 的写法，支持链式查询（点标记）、查询表达式、聚合查询、分组排序、批量插入、批量更新、批量删除、1:1关系外键等。在实体绑定层面，使用 Emit 来动态构建绑定指令，性能最大限度地接近原生水平。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/89702/201801/89702-20180106204855909-1170605487.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; 7000笔记录循环读1000次，同时加载1：1关系的外键，速度比 EF 稍快。&lt;/p&gt;
&lt;p&gt;&lt;span&gt;1. 单表查询&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 查询表达式&lt;/span&gt;
&lt;span&gt;var&lt;/span&gt; query = &lt;span&gt;from&lt;/span&gt; a &lt;span&gt;in&lt;/span&gt; context.GetTable&amp;lt;Inte_CRM.Demo&amp;gt;&lt;span&gt;()
            &lt;/span&gt;&lt;span&gt;select&lt;/span&gt;&lt;span&gt; a;
&lt;/span&gt;&lt;span&gt;var&lt;/span&gt; r1 =&lt;span&gt; query.ToList();
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 点标记&lt;/span&gt;
query = context.GetTable&amp;lt;Inte_CRM.Demo&amp;gt;&lt;span&gt;();
r1 &lt;/span&gt;=&lt;span&gt; query.ToList();
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;SQL=&amp;gt; 
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;SELECT 
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t0.[DemoId] AS [DemoId],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t0.[DemoCode] AS [DemoCode],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t0.[DemoName] AS [DemoName],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;...
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t0.[DemoLong] AS [DemoLong],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t0.[DemoLong_Nullable] AS [DemoLong_Nullable]
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;FROM [Sys_Demo] t0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2. 关联查询&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;47&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; INNER JOIN&lt;/span&gt;
&lt;span&gt;var&lt;/span&gt; query =
    &lt;span&gt;from&lt;/span&gt; a &lt;span&gt;in&lt;/span&gt; context.GetTable&amp;lt;Inte_CRM.CRM_SaleOrder&amp;gt;&lt;span&gt;()
    join b &lt;/span&gt;&lt;span&gt;in&lt;/span&gt; context.GetTable&amp;lt;Inte_CRM.Client&amp;gt;&lt;span&gt;() on a.ClientId equals b.ClientId
    join c &lt;/span&gt;&lt;span&gt;in&lt;/span&gt; context.GetTable&amp;lt;Inte_CRM.CloudServer&amp;gt;&lt;span&gt;() on b.CloudServerId equals c.CloudServerId
    &lt;/span&gt;&lt;span&gt;where&lt;/span&gt; a.ClientId &amp;gt; &lt;span&gt;0&lt;/span&gt;
    &lt;span&gt;select&lt;/span&gt;&lt;span&gt; a;
&lt;/span&gt;&lt;span&gt;var&lt;/span&gt; r1 =&lt;span&gt; query.ToList();
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 点标记&lt;/span&gt;
query =&lt;span&gt; context
    .GetTable&lt;/span&gt;&amp;lt;Inte_CRM.CRM_SaleOrder&amp;gt;&lt;span&gt;()
    .Join(context.GetTable&lt;/span&gt;&amp;lt;Inte_CRM.Client&amp;gt;(), a =&amp;gt; a.ClientId, b =&amp;gt; b.ClientId, (a, b) =&amp;gt; &lt;span&gt;new&lt;/span&gt; { Sale = a, Buyer =&lt;span&gt; b })
    .Join(context.GetTable&lt;/span&gt;&amp;lt;Inte_CRM.CloudServer&amp;gt;(), b =&amp;gt; b.Buyer.CloudServerId, c =&amp;gt; c.CloudServerId, (a, c) =&amp;gt; &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Inte_CRM.CRM_SaleOrder { })
    .Where(a &lt;/span&gt;=&amp;gt; a.ClientId &amp;gt; &lt;span&gt;0&lt;/span&gt;&lt;span&gt;);
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;r1 = query.ToList();
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;SQL=&amp;gt;
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;SELECT 
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t0.[OrderId] AS [OrderId],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t0.[OrderNo] AS [OrderNo],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t0.[Remark] AS [Remark],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t0.[ClientId] AS [ClientId]
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;FROM [CRM_SaleOrder] t0 
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;INNER JOIN [Bas_Client] t1 ON t0.[ClientId] = t1.[ClientId]
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;INNER JOIN [Sys_CloudServer] t2 ON t1.[CloudServerId] = t2.[CloudServerId]
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;WHERE t0.[ClientId] &amp;gt; 0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;3. 分组分页&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 分组后再分页&lt;/span&gt;
query =
    &lt;span&gt;from&lt;/span&gt; a &lt;span&gt;in&lt;/span&gt; context.GetTable&amp;lt;Inte_CRM.Client&amp;gt;&lt;span&gt;()
    &lt;/span&gt;&lt;span&gt;where&lt;/span&gt; a.ClientName == &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;TAN&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
    group a by &lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; { a.ClientId, a.ClientName } into g
    &lt;/span&gt;&lt;span&gt;where&lt;/span&gt; g.Key.ClientId &amp;gt; &lt;span&gt;0&lt;/span&gt;
    &lt;span&gt;orderby&lt;/span&gt; &lt;span&gt;new&lt;/span&gt;&lt;span&gt; { g.Key.ClientName, g.Key.ClientId }
    &lt;/span&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;new&lt;/span&gt;&lt;span&gt;
    {
        Id &lt;/span&gt;=&lt;span&gt; g.Key.ClientId,
        Name &lt;/span&gt;= g.Min(a =&amp;gt;&lt;span&gt; a.ClientId)
    };
query &lt;/span&gt;= query.Skip(&lt;span&gt;2&lt;/span&gt;).Take(&lt;span&gt;3&lt;/span&gt;&lt;span&gt;);
r1 &lt;/span&gt;=&lt;span&gt; query.ToList();
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;SQL=&amp;gt; 
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;SELECT 
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t0.[Id],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t0.[Name]
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;FROM ( 
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    SELECT 
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    t0.[ClientId] AS [Id],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    MIN(t0.[ClientId]) AS [Name],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    t0.[ClientName] AS [ClientName]
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    FROM [Bas_Client] t0 
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    WHERE t0.[ClientName] = N'TAN'
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    GROUP BY t0.[ClientId],t0.[ClientName]
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;    Having t0.[ClientId] &amp;gt; 0
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; ) t0
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;ORDER BY t0.[ClientName]
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;OFFSET 2 ROWS FETCH NEXT 3 ROWS ONLY &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;4. 批量插入&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
context.Insert&amp;lt;Inte_CRM.Thin&amp;gt;&lt;span&gt;(collection);
context.SubmitChanges();
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;SQL=&amp;gt; 
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;INSERT INTO[Sys_Thin]
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;([ThinId],[ThinName])
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;VALUES
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;(2, N'002'),(3,N'003')&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;5. 导航属性&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;56&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 更简单的赋值方式 
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 适用场景：在显示列表时只想显示外键表的一两个字段&lt;/span&gt;
query =
    &lt;span&gt;from&lt;/span&gt; a &lt;span&gt;in&lt;/span&gt; context.GetTable&amp;lt;Inte_CRM.CRM_SaleOrder&amp;gt;&lt;span&gt;()
    &lt;/span&gt;&lt;span&gt;select&lt;/span&gt; &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Inte_CRM.CRM_SaleOrder(a)
    {
        Client &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Inte_CRM.Client(a.Client)
        {
            CloudServer &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Inte_CRM.CloudServer
            {
                CloudServerId &lt;/span&gt;=&lt;span&gt; a.Client.CloudServer.CloudServerId,
                CloudServerName &lt;/span&gt;=&lt;span&gt; a.Client.CloudServer.CloudServerName
            }
        },
        HeavyBuyer &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Inte_CRM.Client
        {
            ClientId &lt;/span&gt;= a.Client.ClientId + &lt;span&gt;10&lt;/span&gt;&lt;span&gt;,
            ClientName &lt;/span&gt;= a.Client.ClientName + &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;_heavy&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
            CloudServer &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Inte_CRM.CloudServer
            {
                CloudServerId &lt;/span&gt;= a.Client.CloudServer.CloudServerId + &lt;span&gt;10&lt;/span&gt;&lt;span&gt;,
                CloudServerName &lt;/span&gt;= a.Client.CloudServer.CloudServerName + &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;_heavy&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
            }
        }
    };
r1 &lt;/span&gt;=&lt;span&gt; query.ToList();
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;SQL=&amp;gt;
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;SELECT 
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t0.[OrderId] AS [OrderId],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t0.[OrderNo] AS [OrderNo],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t0.[Remark] AS [Remark],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t0.[ClientId] AS [ClientId],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t1.[ClientId] AS [ClientId1],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t1.[ClientCode] AS [ClientCode],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t1.[ClientName] AS [ClientName],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t1.[State] AS [State],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t1.[ActiveDate] AS [ActiveDate],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t1.[CloudServerId] AS [CloudServerId],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t2.[CloudServerId] AS [CloudServerId1],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t2.[CloudServerName] AS [CloudServerName],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t1.[ClientId] + 10 AS [ClientId2],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t1.[ClientName] + N'_heavy' AS [ClientName1],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t2.[CloudServerId] + 10 AS [CloudServerId2],
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;t2.[CloudServerName] + N'_heavy' AS [CloudServerName1]
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;FROM [CRM_SaleOrder] t0 
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;LEFT JOIN [Bas_Client] t1 ON t0.[ClientId] = t1.[ClientId]
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;LEFT JOIN [Sys_CloudServer] t2 ON t1.[CloudServerId] = t2.[CloudServerId]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;其它更多示例在源码的 demo 中有详细说明，源码地址：&lt;a href=&quot;https://github.com/TANZAME/Inte.XFramework&quot; target=&quot;_blank&quot;&gt;https://github.com/TANZAME/Inte.XFramework&lt;/a&gt;&lt;/p&gt;

</description>
<pubDate>Sun, 07 Jan 2018 05:36:00 +0000</pubDate>
<dc:creator>田乃翔</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/yiting/p/7979705.html</dc:identifier>
</item>
<item>
<title>springMVC(6)---处理模型数据 - 雨点的名字</title>
<link>http://www.cnblogs.com/qdhxhz/p/8207047.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qdhxhz/p/8207047.html</guid>
<description>&lt;p&gt;        之前一篇博客，写个怎么获取前段数据：&lt;a href=&quot;http://www.cnblogs.com/qdhxhz/p/8076274.html&quot; target=&quot;_blank&quot;&gt;springMVC(2)---获取前段数据&lt;/a&gt;，这篇文章写怎么从后端往前端传入数据。&lt;/p&gt;
&lt;p&gt;         &lt;span&gt;&lt;strong&gt;&lt;span&gt;模型数据类型&lt;/span&gt;                                            &lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;         SpringMVC 提供了以下几种途径输出模型数据:&lt;/p&gt;
&lt;p&gt;　　–&lt;span&gt; &lt;span&gt;&lt;strong&gt;ModelAndView: &lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;处理方法返回值类型为 ModelAndView时, 方法体即可通过该对象添加模型数据&lt;br/&gt;　　–&lt;span&gt;&lt;strong&gt;&lt;span&gt; Map及Model:&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;入参为org.springframework.ui.Model、org.springframework.ui.ModelMap 或 &lt;a href=&quot;http://lib.csdn.net/base/javase&quot;&gt;Java&lt;/a&gt;.uti.Map 时，处理方法返回时，Map中的数据会自动添加到模型中。&lt;br/&gt;　　&lt;span&gt;– &lt;strong&gt;&lt;span&gt;@SessionAttributes:&lt;/span&gt; &lt;/strong&gt;&lt;/span&gt;将模型中的某个属性暂存到HttpSession 中，以便多个请求之间可以共享这个属性&lt;br/&gt;　　–&lt;span&gt;&lt;strong&gt;&lt;span&gt; @ModelAttribute:&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt; 方法入参标注该注解后, 入参的对象就会放到数据模型中。&lt;/p&gt;
&lt;p&gt;        &lt;span&gt;&lt;strong&gt;&lt;span&gt; 一.ModelAndView                                       &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;p1&quot;&gt;      目标方法的返回值可以是ModelAndView类型，其中可以包含视图和模型信息&lt;/p&gt;
&lt;p class=&quot;p1&quot;&gt;      &lt;span class=&quot;s1&quot;&gt;springmvc会把ModelAndView的model中数据放在request域对象中&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
@RequestMapping(&quot;/springmvc&quot;&lt;span&gt;)
  @Controller
  &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; SpringMVCTest {
      &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; String SUCCESS = &quot;success&quot;&lt;span&gt;;
  &lt;/span&gt;&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
   * 目标方法的返回值可以是ModelAndView类型
   * 其中可以包含视图和模型信息
   * springmvc会把ModelAndView的model中数据放在request域对象中
   * &lt;/span&gt;&lt;span&gt;@return&lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
     @RequestMapping(&lt;/span&gt;&quot;/testModelAndView&quot;&lt;span&gt;)
     &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; ModelAndView testModelAndView(){
         String viewName&lt;/span&gt;=&lt;span&gt;SUCCESS;
         &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;添加模型视图&lt;/span&gt;
         ModelAndView modelAndView=&lt;span&gt;new&lt;/span&gt;&lt;span&gt; ModelAndView(viewName);
         &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;添加模型数据到ModelAndView中&lt;/span&gt;
         modelAndView.addObject(&quot;time&quot;, &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Date());
         &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; modelAndView;
     }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    &lt;span&gt;&lt;strong&gt;&lt;span&gt; index.jsp&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
 &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;a &lt;/span&gt;&lt;span&gt;href&lt;/span&gt;&lt;span&gt;=&quot;springmvc/testModelAndView&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;Test ModelAndView&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    &lt;span&gt;&lt;strong&gt;&lt;span&gt;success.jsp&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;html&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;h4&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;Success Page&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;h4&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;
     time:${requestScope.time}
 &lt;/span&gt;&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;html&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2&gt;      &lt;span&gt;  &lt;span&gt;二.Map 及 Model                                            &lt;/span&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;         入参为org.springframework.ui.Model、org.springframework.ui.ModelMap 或 java.uti.Map 时，处理方法返回时，Map 中的数据会自动添加到模型中&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt; Controller类&lt;br/&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
     @RequestMapping(&quot;/testMap&quot;&lt;span&gt;)
     &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; String testMap(Map&amp;lt;String, Object&amp;gt;&lt;span&gt; map)
     {
         map.put(&lt;/span&gt;&quot;names&quot;, Arrays.asList(&quot;tom&quot;, &quot;jerry&quot;, &quot;mike&quot;&lt;span&gt;));
         &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &quot;success&quot;;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;  index.jsp&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;a &lt;/span&gt;&lt;span&gt;href&lt;/span&gt;&lt;span&gt;=&quot;springmvc/testMap&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;Test Map&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;  success.jsp&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
map: ${requestScope.names }
&lt;/pre&gt;&lt;/div&gt;
&lt;p class=&quot;p1&quot;&gt; &lt;span&gt;&lt;strong&gt;&lt;span&gt;界面&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;p1&quot;&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1090617/201801/1090617-20180105220024362-541525331.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt; 三.@SessionAttributes                                                 &lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;如果希望在多个请求之间共用某个模型属性数据，则可以在控制器类标注一个 &lt;em&gt;&lt;strong&gt;@SessionAttributes&lt;/strong&gt;&lt;/em&gt;，SpringMVC 会将模型中对应的属性暂存到 HTTPSession 中。&lt;/p&gt;
&lt;p&gt;@SessionAttributes 除了可以通过&lt;span&gt;&lt;strong&gt;属性名&lt;/strong&gt;&lt;/span&gt;指定需要放到会话中的属性外，还可以通过模型属性的&lt;span&gt;&lt;strong&gt;对象类型&lt;/strong&gt;&lt;/span&gt;指定哪些模型属性需要放到会话中。&lt;/p&gt;
&lt;p&gt;1. @SessionAttributes&lt;span&gt;(&lt;strong&gt;types&lt;/strong&gt;&lt;/span&gt;=User.class)会将隐含模型中所有类型为 User 的属性添加到会话中&lt;/p&gt;
&lt;p&gt;2. @SessionAttributes(&lt;span&gt;&lt;strong&gt;value&lt;/strong&gt;&lt;/span&gt;={&quot;user1&quot;, &quot;user2&quot;})将名为 user1 和 user2 的模型属性添加到会话中&lt;/p&gt;
&lt;p&gt;3. @SessionAttributes(types={&quot;User.class&quot;, &quot;Dept.class&quot;})将模型中所有类型为 User 及 Dept 的属性添加到会话中&lt;/p&gt;
&lt;p&gt;4. @SessionAtributes(value={&quot;user1&quot;, &quot;user2&quot;}, types={Dept.class})将名为 user1 和 user2 的模型属性添加到会话中，同时将所有类型为 Dept 的模型属性添加到会话中&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span&gt;  controller类&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;41&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt;SessionAttributes只能放在类上,不能在方法上&lt;/span&gt;
 @SessionAttributes(value={&quot;user&quot;}, types={String.&lt;span&gt;class&lt;/span&gt;&lt;span&gt;})
  @RequestMapping(&lt;/span&gt;&quot;/springmvc&quot;&lt;span&gt;)
  @Controller
  &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; SessionController
  {
      &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; String SUCCESS = &quot;success&quot;&lt;span&gt;;
      
  　　@RequestMapping(&lt;/span&gt;&quot;/testSessionAttributes&quot;&lt;span&gt;)
     &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; String testSessionAttributes(Map&amp;lt;String, Object&amp;gt;&lt;span&gt; map)
     {
         User user &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; User(&quot;Jack&quot;, &quot;123&quot;&lt;span&gt;);
         map.put(&lt;/span&gt;&quot;user&quot;&lt;span&gt;, user);
         map.put(&lt;/span&gt;&quot;msg&quot;, &quot;hello&quot;&lt;span&gt;);
         &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; SUCCESS;
  }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; &lt;span&gt;&lt;strong&gt; index.jsp&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;a &lt;/span&gt;&lt;span&gt;href&lt;/span&gt;&lt;span&gt;=&quot;springmvc/testSessionAttributes&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;Test SessionAttributes&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt; success.jsp&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt; request user: ${requestScope.user }

 request msg: ${requestScope.msg }

 session user: ${sessionScope.user }

 session msg: ${sessionScope.msg }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;最终&lt;/strong&gt;request和session都有相应值，由此我们可以得出:&lt;/p&gt;
&lt;p&gt;被 @SessionAttributes 注解修饰后，模型属性不仅存在于请求域还存在于会话域。除了可以通过value属性值指定需要放到会话中的属性外，还可以根据types属性值指定哪些类型的模型属性需要放到会话中。&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;&lt;strong&gt;四.@ModelAttribute                                                &lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;     @ModelAttribute&lt;/strong&gt;注解只支持一个属性value，类型是为String，代表绑定的属性名称。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;     @ModelAttribute&lt;/strong&gt;会优先于@RequestMapping执行，也会在Controller中每个方法执行前被执行，所以当一个Controller中有映射到多个Url时，需要谨慎使用&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;(1)先讲下基本理解，网上讲的无非就那么几种&lt;/strong&gt;&lt;/span&gt;：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt;     @ModelAttribute
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; myModel3(Model model) {
            model.addAttribute(&lt;/span&gt;&quot;name&quot;, &quot;SHANHY&quot;&lt;span&gt;);
            model.addAttribute(&lt;/span&gt;&quot;age&quot;, &quot;28&quot;&lt;span&gt;);
        }
    
     &lt;/span&gt;&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
      * 这个相当于 model.addAttribute(&quot;name&quot;, name);
      &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
     @ModelAttribute(&lt;/span&gt;&quot;name&quot;&lt;span&gt;)
     &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; String userModelfirst(@RequestParam(&quot;name&quot;&lt;span&gt;) String name){
       &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; name;   
        }

     &lt;/span&gt;&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     * 这个相当于 model.addAttribute(&quot;string&quot;, name);
     * 因为你自己没有设置model的key值，所以它会默认value的类型第一个字母小写作为key值
     * 如果你是User对象，那它会默认key值为&quot;user&quot;,这个在实际开发中并不适用
     * 因为太局限了，我们很难接受 key 为 string、int、user 等等这样的。
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
    @ModelAttribute
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; String myModel1(@RequestParam(required = &lt;span&gt;false&lt;/span&gt;&lt;span&gt;) String name) {
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; name;
      }&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;(2)RequestMapping方法中取ModelAttribute方法中的值&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;  &lt;span&gt; &lt;span&gt; modelattr.jsp&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span&gt;&lt;br/&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;%&lt;/span&gt;&lt;span&gt;@ page language&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;java&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; contentType&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;text/html; charset=UTF-8&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
    pageEncoding&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UTF-8&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;%&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;html&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;body&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;!--&lt;/span&gt;&lt;span&gt; 这里我输入用户名：李四       密码：5678 &lt;/span&gt;&lt;span&gt;--&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;form &lt;/span&gt;&lt;span&gt;action&lt;/span&gt;&lt;span&gt;=&quot;modelattr/test1&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;label&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;用户名：&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;label&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;input &lt;/span&gt;&lt;span&gt;type&lt;/span&gt;&lt;span&gt;=&quot;text&quot;&lt;/span&gt;&lt;span&gt; id&lt;/span&gt;&lt;span&gt;=&quot;name&quot;&lt;/span&gt;&lt;span&gt; name&lt;/span&gt;&lt;span&gt;=&quot;name&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;input&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span&gt;br&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span&gt;br&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;label&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;密码：&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;label&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;input &lt;/span&gt;&lt;span&gt;type&lt;/span&gt;&lt;span&gt;=&quot;text&quot;&lt;/span&gt;&lt;span&gt; id&lt;/span&gt;&lt;span&gt;=&quot;pwd&quot;&lt;/span&gt;&lt;span&gt; name&lt;/span&gt;&lt;span&gt;=&quot;pwd&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;input&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span&gt;br&lt;/span&gt;&lt;span&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span&gt;br&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;input &lt;/span&gt;&lt;span&gt;type&lt;/span&gt;&lt;span&gt;=&quot;submit&quot;&lt;/span&gt;&lt;span&gt; value&lt;/span&gt;&lt;span&gt;=&quot;登录&quot;&lt;/span&gt;&lt;span&gt;/&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;form&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;body&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;html&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;  &lt;strong&gt;&lt;span&gt; &lt;span&gt;ModelAttrController类&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.springframework.stereotype.Controller;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.springframework.ui.Model;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.springframework.web.bind.annotation.ModelAttribute;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.springframework.web.bind.annotation.RequestMapping;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.springframework.web.bind.annotation.RequestParam;


@Controller
@RequestMapping(value&lt;/span&gt;=&quot;/modelattr&quot;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ModelAttrController {
    
    
     @ModelAttribute
        &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt;&lt;span&gt; Model1(Model model) {
            model.addAttribute(&lt;/span&gt;&quot;name&quot;, &quot;张三&quot;&lt;span&gt;);
            model.addAttribute(&lt;/span&gt;&quot;pwd&quot;, &quot;1234&quot;&lt;span&gt;);
        }     
 
     
    &lt;/span&gt;&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     *  test1方法中，有两个值是通过Model1方法中放入的
     *  有两个值是通过前端获取的我们看后台打印结果
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt; 
    @RequestMapping(value&lt;/span&gt;=&quot;/test1&quot;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; String test1(
            @ModelAttribute(&lt;/span&gt;&quot;name&quot;&lt;span&gt;) String str2,
            @ModelAttribute(&lt;/span&gt;&quot;pwd&quot;&lt;span&gt;) String str3,
            @RequestParam(&lt;/span&gt;&quot;name&quot;&lt;span&gt;) String name,
            @RequestParam(&lt;/span&gt;&quot;pwd&quot;&lt;span&gt;) String pwd) {
        
        System.out.println(&lt;/span&gt;&quot;name=&quot;+str2+&quot;,pwd=&quot;+&lt;span&gt;str3);
        System.out.println(&lt;/span&gt;&quot;name=&quot;+name+&quot;,pwd=&quot;+&lt;span&gt;pwd);
                 
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
    }        
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;后台打印结果：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1090617/201801/1090617-20180107115308659-2091607109.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;(3)有关更新，具体看案例&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;  &lt;span&gt;&lt;strong&gt;modelPerson.jsp&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;html&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;body&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
    &lt;span&gt;&amp;lt;!--&lt;/span&gt;&lt;span&gt;  
         模拟修改操作
          1. 原始数据为: 1, zhangsan, 123456,12
          2. 密码不能被修改.
          3. 表单回显, 模拟操作直接在表单填写对应的属性值
      &lt;/span&gt;&lt;span&gt;--&amp;gt;&lt;/span&gt;
      &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;form &lt;/span&gt;&lt;span&gt;action&lt;/span&gt;&lt;span&gt;=&quot;modelattr/person&quot;&lt;/span&gt;&lt;span&gt; method&lt;/span&gt;&lt;span&gt;=&quot;Post&quot;&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
          &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;input &lt;/span&gt;&lt;span&gt;type&lt;/span&gt;&lt;span&gt;=&quot;hidden&quot;&lt;/span&gt;&lt;span&gt; name&lt;/span&gt;&lt;span&gt;=&quot;id&quot;&lt;/span&gt;&lt;span&gt; value&lt;/span&gt;&lt;span&gt;=&quot;1&quot;&lt;/span&gt;&lt;span&gt;/&amp;gt;&lt;/span&gt;&lt;span&gt;
         name: &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;input &lt;/span&gt;&lt;span&gt;type&lt;/span&gt;&lt;span&gt;=&quot;text&quot;&lt;/span&gt;&lt;span&gt; name&lt;/span&gt;&lt;span&gt;=&quot;name&quot;&lt;/span&gt;&lt;span&gt; value&lt;/span&gt;&lt;span&gt;=&quot;zhangsan&quot;&lt;/span&gt;&lt;span&gt;/&amp;gt;&lt;/span&gt;
         &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;br&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;
         age: &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;input &lt;/span&gt;&lt;span&gt;type&lt;/span&gt;&lt;span&gt;=&quot;text&quot;&lt;/span&gt;&lt;span&gt; name&lt;/span&gt;&lt;span&gt;=&quot;age&quot;&lt;/span&gt;&lt;span&gt; value&lt;/span&gt;&lt;span&gt;=&quot;12&quot;&lt;/span&gt;&lt;span&gt;/&amp;gt;&lt;/span&gt;
         &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;br&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
         &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;input &lt;/span&gt;&lt;span&gt;type&lt;/span&gt;&lt;span&gt;=&quot;submit&quot;&lt;/span&gt;&lt;span&gt; value&lt;/span&gt;&lt;span&gt;=&quot;Submit&quot;&lt;/span&gt;&lt;span&gt;/&amp;gt;&lt;/span&gt;
     &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;form&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;body&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;html&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;  &lt;span&gt; &lt;span&gt;&lt;strong&gt;ModelAttrController类&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.springframework.stereotype.Controller;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.springframework.web.bind.annotation.ModelAttribute;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.springframework.web.bind.annotation.RequestMapping;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.springframework.web.bind.annotation.RequestMethod;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.springframework.web.bind.annotation.RequestParam;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; com.ssm.model.Person;

@Controller
@RequestMapping(value&lt;/span&gt;=&quot;/modelattr&quot;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ModelAttrController {
    
    &lt;/span&gt;&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     *1： 因为password我在界面上是没有输入的，所以我通过id去数据库找到这条数据，就能获得它的password
     *2：Person领域对象就id name password  age 四个属性都是String形
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
    @ModelAttribute
         &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;void&lt;/span&gt; getUser(@RequestParam(value=&quot;id&quot;,required=&lt;span&gt;false&lt;/span&gt;&lt;span&gt;) String id, 
                 Map&lt;/span&gt;&amp;lt;String, Object&amp;gt;&lt;span&gt; map){
            &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;(id != &lt;span&gt;null&lt;/span&gt;&lt;span&gt;){
                &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;模拟从数据库中获取对象&lt;/span&gt;
                Person person = &lt;span&gt;new&lt;/span&gt; Person(&quot;1&quot;, &quot;lisi&quot;, &quot;123456&quot;, &quot;24&quot;&lt;span&gt;);
                System.out.println(&lt;/span&gt;&quot;从数据库中获取一个对象: &quot; +&lt;span&gt; person);
                map.put(&lt;/span&gt;&quot;person&quot;&lt;span&gt;, person);
            }
        }
    
    @RequestMapping(value&lt;/span&gt;=&quot;/person&quot;, method=&lt;span&gt;RequestMethod.POST)
         &lt;/span&gt;&lt;span&gt;public&lt;/span&gt;&lt;span&gt; String testModelAttribute(Person person){
             System.out.println(&lt;/span&gt;&quot;修改: &quot; +&lt;span&gt; person);
             
             &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; &lt;span&gt;null&lt;/span&gt;&lt;span&gt;;
         }
   &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;
    * 总结几点：
    * 1：map.put(&quot;person&quot;, person);中的key值，一定要和Person person中的形参一致，否则报错
    * 2：如果去掉@ModelAttribute注解和getUser方法，直接testModelAttribute(Person person)会报错
    * java.lang.NoSuchMethodException: com.ssm.model.Person.&amp;lt;init&amp;gt;()
    * 3：最后修改的那个person其实就是从数据库中和前端界面传来的集合体，就是说如果前端有值那就覆盖数据库中对于
    * 属性的值，如果前段没有值那就还是用数据库中属性的值
    &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
     
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;  &lt;strong&gt;&lt;span&gt; &lt;span&gt;后台打印结果&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://images2017.cnblogs.com/blog/1090617/201801/1090617-20180107124413628-498799741.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;(4)@ModelAttribute和@RequestMapping同时注释的有返回值的方法&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt; &lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.springframework.stereotype.Controller;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.springframework.web.bind.annotation.ModelAttribute;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.springframework.web.bind.annotation.RequestMapping;
&lt;/span&gt;&lt;span&gt;import&lt;/span&gt;&lt;span&gt; org.springframework.web.bind.annotation.RequestParam;


@Controller
@RequestMapping(value&lt;/span&gt;=&quot;/modelattr&quot;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ModelAttrController {

     
    @ModelAttribute(value&lt;/span&gt;=&quot;username&quot;&lt;span&gt;)  
    @RequestMapping(&lt;/span&gt;&quot;/person&quot;&lt;span&gt;)  
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; String login(@RequestParam(&quot;name&quot;&lt;span&gt;) String name){  
    
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; name;  
    }  
    &lt;/span&gt;&lt;span&gt;/**&lt;/span&gt;&lt;span&gt;
     * 这种情况比较有意思：以前return name;都是作为返回路径
     * 现在它变成了value值
     * model.addAttribute(&quot;username&quot;, name);
     * 那它的映射还是@RequestMapping中的value值这里指：modelattr/person
     * 我之前路径为：&lt;/span&gt;&lt;span&gt;http://localhost&lt;/span&gt;&lt;span&gt;:8080/ssm/modelattr/person
     * 那么返回路径为：&lt;/span&gt;&lt;span&gt;http://localhost&lt;/span&gt;&lt;span&gt;:8080/ssm/WEB-INF/jsp/modelattr/person.jsp
     &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
    
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt; &lt;span&gt;&lt;strong&gt;先看WEB-INF/jsp/modelattr/person.jsp&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1090617/201801/1090617-20180107130403909-314071349.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;内容&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;%&lt;/span&gt;&lt;span&gt;@ page language&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;java&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; contentType&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;text/html; charset=UTF-8&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
    pageEncoding&lt;/span&gt;&lt;span&gt;=&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;UTF-8&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;%&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;html&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;head&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;body&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;h1&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;Person返回成功&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;h1&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;body&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;html&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;最后我们看界面&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1090617/201801/1090617-20180107130536971-300537846.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;有关处理模型数据就讲到这了，如果哪里讲的不周全也欢迎多多指教。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;想的太多，做的太少，中间的落差就是烦恼，要么去做，要么别想 &lt;/strong&gt;少尉【13】&lt;/span&gt;&lt;/p&gt;

</description>
<pubDate>Sun, 07 Jan 2018 05:11:00 +0000</pubDate>
<dc:creator>雨点的名字</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/qdhxhz/p/8207047.html</dc:identifier>
</item>
<item>
<title>项目微管理 - 总结也是新的开始 - 沙场秋点兵</title>
<link>http://www.cnblogs.com/dxy1982/p/8227796.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/dxy1982/p/8227796.html</guid>
<description>&lt;p&gt;　　时间都去哪了？听着这首耳熟能详的旋律，感叹着飞速流逝的年华，我渐渐的陷入到沉思之中。&lt;/p&gt;
&lt;p&gt;　　时间过的真的很快，从一名程序员到接手一个一线项目团队一晃已经2年多了。在这段时间里，我接触了各种各样的人，处理了各式各样的事。在这个过程中，我逐渐的体会到了程序员和项目经理之间的诸多不同，在这些差别中，最让我感受深刻的就是：程序员是用程序去和计算机与同伴沟通，而项目经理更多的是使用自然语言和流程来与人打交道。&lt;/p&gt;
&lt;p&gt;　　为了能快速的适应这种变化，也为了更好的完成这份工作，我花了大量的时间和精力去学习项目管理的相关知识，并且积极尝试将它们运用到实际的项目中来。在这个痛并快乐着的过程中，我思考了很多，也收获了很多，姑且不管我得到的是对还是错，我想把这个过程记录下来，变成一个个小故事；这样，闲来的时候拿着它们读一读，我觉得是不错的一件事，再说了，对正在经历这样一种转换的同学，或者期望经历这样一种转换的同学，万一能有点共鸣，也说不定呢。&lt;/p&gt;
&lt;p&gt;　　有了这个想法以后，我开始利用每周几次坐地铁的时间，持续不断的整理这些点滴和心得，（哎呦，颈椎又抱怨了，^_^，我甚至一度都想称这些内容为“我和魔都一号线的那些事”），它们将会包括以下一些内容：&lt;/p&gt;

&lt;div readability=&quot;7.5&quot;&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
0. 引子 - OJ离职
1. 孤军 - 单枪匹马修改软件架构
2. 招聘 - 艰难的招聘过程
3. 学弟 - 学生与职业经理人
4. 规范 - 代码即沟通
5. 经理 - 无中生有
6. 始计 - 计划的制定和实施
7. 流程 - 工作流程
8. 质量 - Bug的含义
9. 工匠 - 精益求精
10. 文档 - 测试文档的建立
11. 管理 - 不断的自我学习
12. 新人 - 招聘的转机
13. 预热 - 开发培训
14. 质疑 - 新人秀
15. 三体 - 团队正式成立
16. 双赢 - 利益共同体
17. 嘴遁 - 沟通最重要
18. 单挑 - 及时反馈
19. 三思 - 克制发火的冲动
20. 互联 - 不做信息孤岛
21. 会议 - 高效会议
22. 横向 - 左右管理，
23. 反向 - 向上管理
24. 打卡 - 管理的失败
25. 惊喜 - 生日小礼物
26. 反馈 - 培训的不足
27. 转正 - 试用期和转正考核
28. 绩效 - 阶段考核
29. 方向 - 指标与目标
30. 系统 - 目标管理
31. 奖惩 - 有奖无惩
32. 根本 - 以人为本
33. 单飞 - 独自锻炼
34. 创新 - 创新是一张网
35. 求变 - 强弱转化
36. 转化 - 做好且只做好一件事
37. 激情 - 信任总是在反复试探中建立
38. 信任 - 团队活动
39. 迷思 - 煤矿中报警的金丝雀
40. 筑基 - 构建自己的知识体系
41. 常规 - 常规任务的陪练
42. 组合 - 平时练兵，战时组合
43. 嫌隙 - 个性和工作方式不同导致的冲突
44. 刺头 - 不是刺头我们还不要
45. 绸缪 - 风险控制
46. 标志 - 团队的标志
47. 展示 - 个人的展示
48. 游戏 - 游戏为什么好玩
49. 数据 - 数据时代
50. 领导 - 陪练的人
51. 全栈 - 互联网思维下的精英
52. 授权 - 细节授权与监控进度
53. 估算 - 项目进度控制
54. 危机 - 快速解决问题
55. 架构 - 快速稳定发布
56. 离职 - 好聚好散
57. 演化 - 从平衡到新的平衡
58. 团队 - 大口吃肉，大口喝酒
59. 年终 - 年终考核
60. 平台 - 金字塔与扁平化
61. 无为 - 改革还是革命
62. 交接 - 岗前培训
&lt;/pre&gt;&lt;/div&gt;

&lt;/div&gt;

</description>
<pubDate>Sun, 07 Jan 2018 04:52:00 +0000</pubDate>
<dc:creator>沙场秋点兵</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/dxy1982/p/8227796.html</dc:identifier>
</item>
<item>
<title>我在博客园的这一年 - xybaby</title>
<link>http://www.cnblogs.com/xybaby/p/8227687.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/xybaby/p/8227687.html</guid>
<description>&lt;p&gt;　　今天是2018年1月7号，在去年的今天，也就是2017年1月7号，我在博客园写下了自己的第一篇博客《&lt;a id=&quot;ArchiveMonth1_Days_ctl00_Entries_TitleUrl_16&quot; class=&quot;entrylistItemTitle&quot; href=&quot;http://www.cnblogs.com/xybaby/p/6259823.html&quot;&gt;Python 小而美的函数&lt;/a&gt;》，从此，与博客园结下了不解之缘。在此，回顾我在博客园的这一年，也是希望18年能够继续努力。&lt;/p&gt;
&lt;p&gt;　　我写文章的初衷很简单，就是觉得自己的记性越来越差，看过的东西很快就忘了。虽然有云笔记，但是纪录下来的东西多是复制粘贴，很多别人的话语，自己全盘接收，并没有多少思考；即使有自己的思考，也都是只言片语，不系统。在写博客的过程中，必然会有更多的思考，对知识的记忆也更加深刻，即使日后查看也更加有条理、更全面。而且，博客写出来除了自己看，也会公开给别人看，自然也希望得到认可与肯定，所以也会尽力把知识弄明白，把文章写清楚。&lt;/p&gt;
&lt;p&gt;　　这一年，也看到好几篇文章写程序员为什么应该写博客，其中一篇是《暗时间》里面的“&lt;a href=&quot;http://mindhacks.cn/2009/02/15/why-you-should-start-blogging-now/&quot; target=&quot;_blank&quot;&gt;为什么你应该从现在开始就写博客&lt;/a&gt;”，（这里并不是打广告，《暗时间》是我2017年认真读过的几本书中最好之一）。在这篇文章中，作者指出了写有价值博客的一些好处：&lt;/p&gt;
&lt;blockquote readability=&quot;17&quot;&gt;
&lt;p&gt;&lt;span&gt;1) 能够交到很多志同道合的朋友&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;2) 书写是为了更好的思考&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;3) “教”是最好的“学”&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;4) 讨论是绝佳的反思&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;5) 激励你去持续学习和思考&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;6) 学会持之以恒地做一件事情&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;7) 一个长期的价值博客是一份很好的简历&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;　　于我而言，我所能感受到的好处是第2、5、6点。&lt;/p&gt;
&lt;p&gt; 　　第2点，“&lt;strong&gt;书写是为了更好的思考&lt;/strong&gt;”，在这个知识爆炸的时代，我们每天都会接收到大量的资讯。对我自己而言，也会订阅大牛的博客，关注一堆技术相关的公众号。即使是一篇很好的文章，绝大多数只是看过，觉得很厉害，并不会去认真思考，自然没有多少真正的收获。而在写一篇文章的时候，就会认真去思考相关的技术细节，真正的搞懂。有时候我也会去看自己以前的文章或者笔记，也经常会有新的想法，发现一些以前认知错误的地方，所谓温故而知新，这个“故”就是以前的文章吧。&lt;/p&gt;
&lt;p&gt; 　　第3点，“&lt;strong&gt;激励你去持续学习和思考&lt;/strong&gt;”，学习这个事情，事实上一直都在做，只不过今天看看这，明天看看那，看过就忘，好比猴子扳玉米。写博客的一个好处，就是写出一篇文章之后（或者在思考这篇文章的时候），总会发现相关的、在当前时间点自己还太懂的知识。比如，我在学习、总结Python yield的时候，知道了greenlet这个东西，但这个知识我之前并不了解，于是去学习greenlet，学习玩greenlet之后，又了解到了gevent。又比如，我在学习MongoDB的时候，有很多疑问，接收到了很多新名字、新概念，于是开始学习分布式存储，然后是分布式系统。本质就是，越求知越知道自己的无知。&lt;/p&gt;
&lt;p&gt; 　　第6点，“&lt;strong&gt;学会持之以恒地做一件事情&lt;/strong&gt;”。过去的一年，给自己定了很多目标，比如坚持锻炼，比如每天看一点非技术相关的书籍，然而不幸的是，都没有坚持下来。唯一坚持下来的事情就是写博客，保证每月有一定的产出，这个感觉还不错。&lt;/p&gt;
&lt;p&gt;　　关于其他的几点，比如“讨论是绝佳的反思”，我则觉得做得并不好。当然，文章质量肯定是最重要的一个因素，平台也是其中一个因素。&lt;/p&gt;
&lt;p&gt;　　就我而言，虽然在过去的一年里收获了一百多个关注、一百个评论，但评论大多都是“顶'，‘赞”，“已收藏”。我并不知道我的文章对读者而言是否有用，这个过程是单向的，即我将内容输出到读者，而我的期望是双向的，希望能得到读者的反馈。尤其是，我的文章中，很多都是作为一个初学者的学习与总结，并不是该领域大牛的布道，我也会在文章中注明，希望园友们指正与讨论，作为我自己，真的希望有大牛能不吝指教。&lt;/p&gt;
&lt;div readability=&quot;13.672727272727&quot;&gt;　　而博客园作为平台，每天会产生大量的文章，优秀的文章也很多，读者花在每一篇博文上的时间也就不会太多。据我观察，即使是置顶的文章、推荐数、评论数较多的文章，真正有价值的评论与讨论也并不多。另外，可能跟平台的目标受众有关，博客园经常被称之为.Net的博客园，.Net相关的文章都是很吃香的，而其他领域、编程语言相关的文章则读者较少。从博客园&lt;a href=&quot;https://www.cnblogs.com/expert/&quot; target=&quot;_blank&quot;&gt;推荐博客排行&lt;/a&gt;的前10名就可以发现，大多数都是asp net相关的。这个就跟微信公众号有较大差异，微信公众号都是针对一个具体的领域，目标受众更加确定，所以一篇文章的阅读数、点赞数、评论都会相对多一些。&lt;/div&gt;
&lt;p&gt;　　2017年博客园因为被攻击、以及阿里云服务的事情停止服务了好几次，说来也搞笑，攻击一个技术分享网站干啥呢。&lt;/p&gt;

&lt;p&gt;　　每一个博客作者的文章类型都不太一样，有的喜欢写教程类的；有的喜欢写科普类的；有的主要用于记录工作中遇到的问题或者感悟；有的产出不高，但每篇都很深入、全面，质量很高。对我自己而言，文章主要有两类，一种是对已经掌握的知识的总结，比如Python的一些文章；另一种是在学习的过程中的思考与总结，后者相对来说，会多一些。因此，从文章的发布就能看出我过去的一年中学了哪些新知识，简单总结一下&lt;/p&gt;
&lt;blockquote readability=&quot;19&quot;&gt;
&lt;p&gt;17年1、2月：总结Python基础、学习协程（greenlet，gevent）、Python web（bottle，gunicorn）&lt;/p&gt;
&lt;p&gt;17年3、4月：回顾操作系统相关知识（非科班出身，操作系统相关知识以前自己看过一些，工作以来已经忘得差不多）&lt;/p&gt;
&lt;p&gt;17年5月：MongoDB&lt;/p&gt;
&lt;p&gt;17年6、8月：分布式存储&lt;/p&gt;
&lt;p&gt;17年7月：对Python语言的一点思考&lt;/p&gt;
&lt;p&gt;17年9月：Python内存相关总结&lt;/p&gt;
&lt;p&gt;17年10、11月：分布式系统，分布式事务&lt;/p&gt;
&lt;p&gt;17年12月：总结Linux 进程相关&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;　　回过头来看看，一年的时间里似乎也没有学到多少新知识，作为一个经常加班的业务程序员，周末还得陪陪小孩，学习的时间确实不多。不过，至少开始稍微有点规划的学习，开始了写博客，也算有点收获&lt;/p&gt;
&lt;p&gt;　　希望在2018年，能够继续坚持下去，每月能至少有两三篇产出。目前的学习计划，还是主要学习分布式系统。有园友告诉我，分布式系统还是应该多实践，确实，我也愈加深刻的认识到，新知识如果不经过实践，是很难掌握的，很多细节、权衡与取舍都只有在实践的时候才会注意到，因此，还是很希望能够参与一个相关的项目，退而求其次，看看开源项目的代码。另外，还希望系统学习、回顾一下Linux和网络相关的知识，这两部分虽然工作中一直有用到，不过感觉不全面，也有很多没明白的地方。不过坦白的说，我自己更多的还是受工作、项目驱动，需要用到啥，再去学啥，所以也不要立太多flag。&lt;/p&gt;

&lt;p&gt;　　最后，非常感谢给我点赞、关注我的园友们，愿大家在2018年继续努力，共同进步。Day by day，not day after day。&lt;/p&gt;
</description>
<pubDate>Sun, 07 Jan 2018 03:57:00 +0000</pubDate>
<dc:creator>xybaby</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/xybaby/p/8227687.html</dc:identifier>
</item>
<item>
<title>使用XML序列化实现系统配置 - 开源研究系列文章 - lzhdim</title>
<link>http://www.cnblogs.com/lzhdim/p/8227581.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/lzhdim/p/8227581.html</guid>
<description>&lt;p&gt;　　在实际的C#软件系统开发过程中，会遇到系统配置的保存问题，以及系统存储问题。在以前的系统开发过程中，笔者使用的是INI文件配置管理的方式。到了现在，INI文件配置保存仍然是一个平常使用的方式。在博客园里，笔者看到过有些朋友使用JSON文件的保存配置管理方式。但是，今天笔者带来的是XML存储系统配置信息的方式，无论是JSON还是XML，都需要使用到序列化的方式进行存储，这样才是直接的面向对象编程方式。&lt;/p&gt;
&lt;p&gt;　　下面就对XML序列化方式做一个介绍。&lt;/p&gt;
&lt;p&gt;　　&lt;span&gt;一、首先，添加解决方案中的相关类库；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　先添加相关类库Magical.Framework；&lt;/p&gt;
&lt;p&gt; 　　&lt;img src=&quot;https://images.cnblogs.com/cnblogs_com/lzhdim/1143763/o_1.png&quot; alt=&quot;&quot; width=&quot;329&quot; height=&quot;535&quot;/&gt;&lt;/p&gt;

&lt;p&gt;　　&lt;span&gt;二、其次，建立主程序项目；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　添加主程序项目，添加数据对象TestModule及操作类库UserCofigHelper；&lt;/p&gt;
&lt;p&gt; 　　&lt;img src=&quot;https://images.cnblogs.com/cnblogs_com/lzhdim/1143763/o_2.png&quot; alt=&quot;&quot; width=&quot;323&quot; height=&quot;244&quot;/&gt;&lt;/p&gt;

&lt;p&gt;　　&lt;span&gt;三、添加代码；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　添加主窗体组件；&lt;/p&gt;
&lt;p&gt; 　　&lt;img src=&quot;https://images.cnblogs.com/cnblogs_com/lzhdim/1143763/o_3.png&quot; alt=&quot;&quot; width=&quot;413&quot; height=&quot;300&quot;/&gt;&lt;/p&gt;

&lt;p&gt;　　代码：&lt;/p&gt;
&lt;p&gt; 　　&lt;img src=&quot;https://images.cnblogs.com/cnblogs_com/lzhdim/1143763/o_4.png&quot; alt=&quot;&quot; width=&quot;561&quot; height=&quot;576&quot;/&gt;&lt;/p&gt;

&lt;p&gt;　　&lt;span&gt;四、测试；&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　点击“序列化为文件”按钮，将文本框中的数据序列化为XML文件文本；&lt;/p&gt;
&lt;p&gt; 　　&lt;img src=&quot;https://images.cnblogs.com/cnblogs_com/lzhdim/1143763/o_5.png&quot; alt=&quot;&quot; width=&quot;389&quot; height=&quot;292&quot;/&gt;&lt;/p&gt;

&lt;p&gt;　　点击“反序列化为对象”按钮将XML文本反序列化为对象文本；&lt;/p&gt;


&lt;p&gt;         上面简要介绍了XML序列化系统配置文件的方法及代码，希望能够对需要的朋友们有一定帮助。&lt;/p&gt;
&lt;p&gt;         这里提供解决方案下载：&lt;a title=&quot;https://pan.baidu.com/s/1eSxYQII&quot; href=&quot;https://pan.baidu.com/s/1eSxYQII&quot; target=&quot;_blank&quot;&gt;https://pan.baidu.com/s/1eSxYQII&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 07 Jan 2018 03:19:00 +0000</pubDate>
<dc:creator>lzhdim</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/lzhdim/p/8227581.html</dc:identifier>
</item>
<item>
<title>一点解决版本冲突的应急思路、怎样在所有jar包文件中搜索冲突的方法？ - 等你归去来</title>
<link>http://www.cnblogs.com/yougewe/p/8227447.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/yougewe/p/8227447.html</guid>
<description>&lt;p&gt;　　maven是一个很好的项目管理工具，你可以轻松的定义一个引用，从而达到使用别人写好的库的作用。且maven可以轻松地和jenkins配合，从而使打包部署变得更容易。&lt;/p&gt;
&lt;p&gt;　　但是也因为这样，我们变得更傻瓜了，以致于有时候都忘了一些原始的基础的方法了，当然这不是本文的目的，本文的目的在于，如何解决一些maven带来的冲突问题。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;问题1： jenkins 打包失败了，导致我无法安装代码到测试环境，怎么办？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　答： 一般我们都会基于jenkins做一些二次开发，以适应公司内部的需求，或者优化一些修改化的东西。 但是由于jenkins本身还是比较复杂的，有时候难免我们搞不清楚其原理，从而导致一些无法打包的问题。 当然，我这边遇到的问题一般都是由于jenkins的缓存机制导致的问题，所以，在我本地可以打包的代码，放到jenkins上就死活打不了包，因为我依赖的一个jar包，由于被jenkins缓存了一个老版本的包，里面没有我新的东西从而导致打包失败，看起来短时间内无法解决这个缓存问题。&lt;/p&gt;
&lt;p&gt;　　　　于是，我通过本地ide工具打好war包后，上传到服务器的tomcat目录，等待tomcat自动部署完成后就可以重新启动新代码了，从而绕过了jenkins失败的问题了。　&lt;/p&gt;
&lt;p&gt;　　　　针对jar包，则更为方便，直接本地生成jar包，然后替换服务器上的相应包，重启服务即可。&lt;/p&gt;
&lt;p&gt;　　　　总之，这里的解决方案就是，当工具出了问题的时候，我们就不能再依赖工具了，回到原始状态解决问题。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;问题2： 当我们运行了代码（war/jar）后，报某个方法未找到，即：java.lang.NoSuchMethodError:， 仔细查看代码，其实是有该方法的，如何排查？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　答： 针对该问题，一般情况下都是由于引入了多个相同功能的jar包，且包路径完全一致，而在类加载器加载时，可能会加载到你不想要加载的类，从而导致没有该方法。&lt;/p&gt;
&lt;p&gt;　　　　解决办法就是，删除不是自己的引用，从而达到使用自己意图的类。maven中即表现为排除某个依赖，如：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
       &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;com.xx.activity&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;abc&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;version&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;2.0.13-SNAPSHOT&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;version&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;classifier&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;dubbo&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;classifier&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;exclusions&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
                &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;exclusion&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
                    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;com.meidusa.venus&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;groupId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
                    &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;venus-backend&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;artifactId&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
                &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;exclusion&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;exclusions&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;dependency&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　　　但是，还有个问题，那就是如何才能找到是引用了哪个包，才导致的冲突呢？因为你从本地代码来看，没有一点异常。&lt;/p&gt;
&lt;p&gt;　　　　我们可以直接搜索整个包的引用，并解开其中的代码，查看是冲突的类（冲突方法比较难找出来），当然是直接在服务器上进行查找了。&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:bash;gutter:true;&quot;&gt;
find . -name '*.jar' -exec jar -tvf {} \; | grep EE   # 即找出所有的jar包，再解压出其文件列表，再搜索冲突的类名
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　　　如果有发现两个相同的结果，那么就是冲突了，解决该冲突即可。&lt;/p&gt;
&lt;p&gt;　　　　当然，如果引入的jar文件不多，或者你有基本方向怀疑是哪个包冲突了，那么，直接将该包下载下来，用反编译工具（如jd-gui）编译出来，查看其内部情况，便一目了然。&lt;/p&gt;

&lt;p&gt;&lt;span&gt;&lt;strong&gt;问题3： 发现tomcat启动异常快，而且很多加载流程都没有，就直接启动了，实际上各个应有的服务都不存在，这怎么排查？&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;　　答： 这种问题比较没有头绪，解决起来也基本靠运气。 这里tomcat看起来正常启动了，但是实际上很多事情都没做，没加载。从另一个角度来说，就是加载中断了。最麻烦的是日志中一点信息都不会给出。一般可以先从代码的改动处开始排查，以一段一段的代码还原方式为主要排查手段。&lt;/p&gt;
&lt;p&gt;       　　其中有一很关键的问题就是，你引用了一个jdk版本比你自己的运行环境高的jar包，按照jvm的加载原理，其会先检查class文件的版本号，如果高于自己所能加载的版本，那么，它就直接拒绝加载了，而并不会检查该class文件是否引用了一些不认识的特性。如果jvm不加载类了，那么你后续流程就无法进行了。&lt;/p&gt;
&lt;p&gt;　　　   如果确实是因为jar包版本导致的问题，那么，问题就好解决了。 1. 要么叫给你提供jar包的同学将其打包的jdk版本降到你需要的版本就可以了。  2. 升级自己的jvm运行环境，升级jdk, 当然这个风险可能会有，小心行事。&lt;/p&gt;

&lt;p&gt;　　以上，就是一点点问题排查心得，聊以慰藉。也希望对有类似的问题的同学指明一个方向。&lt;/p&gt;
&lt;p&gt;　　遇到问题的时候我们往往是这样，一个问题，可能几天下来也不一定能解决，但是到真正解决了的时候，发现其实很简单。然后，也许下一次，又继续！&lt;/p&gt;
</description>
<pubDate>Sun, 07 Jan 2018 02:12:00 +0000</pubDate>
<dc:creator>等你归去来</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/yougewe/p/8227447.html</dc:identifier>
</item>
<item>
<title>Keras 学习之旅（一） - xinet</title>
<link>http://www.cnblogs.com/q735613050/p/8227446.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/q735613050/p/8227446.html</guid>
<description>&lt;hr/&gt;&lt;p&gt;软件环境(Windows):&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Visual Studio&lt;/li&gt;
&lt;li&gt;Anaconda&lt;/li&gt;
&lt;li&gt;CUDA&lt;/li&gt;
&lt;li&gt;MinGW-w64&lt;/li&gt;
&lt;li&gt;conda install -c anaconda mingw libpython&lt;/li&gt;
&lt;li&gt;CNTK&lt;/li&gt;
&lt;li&gt;TensorFlow-gpu&lt;/li&gt;
&lt;li&gt;Keras-gpu&lt;/li&gt;
&lt;li&gt;Theano&lt;/li&gt;
&lt;li&gt;MKL&lt;/li&gt;
&lt;li&gt;CuDNN&lt;/li&gt;
&lt;/ul&gt;&lt;hr/&gt;&lt;p&gt;参考书籍：谢梁 , 鲁颖 , 劳虹岚.Keras快速上手：基于Python的深度学习实战&lt;/p&gt;
&lt;h3 id=&quot;keras-简介&quot;&gt;Keras 简介&lt;/h3&gt;
&lt;p&gt;Keras 这个名字来源于希腊古典史诗《奥德赛》的牛角之门（Gate of Horn）：&lt;code&gt;Those that come through the Ivory Gate cheat us with empty promises that never see fullfillment.Those that come through the Gate of Horn inform the dreamer of trut.&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&quot;keras-的优点&quot;&gt;Keras 的优点：&lt;/h4&gt;
&lt;ol readability=&quot;0.5&quot;&gt;&lt;li&gt;Keras 在设计时以人为本，强调快速建模，用户可以快速地将所需模型的结构映射到 Keras 代码中，尽可能减少编写代码的工作量。&lt;/li&gt;
&lt;li&gt;支持现有的常见结构，比如 CNN、RNN 等。&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;高度模块化，用户几乎能够任意组合各种模块来构造所需的模型:&lt;br/&gt;在 Keras 中，任何神经网络模型都可以被描述为一个图模型或者序列模型，其中的部件被划分为：&lt;br/&gt;- 神经网络层&lt;br/&gt;- 损失函数&lt;br/&gt;- 激活函数&lt;br/&gt;- 初始化方法&lt;br/&gt;- 正则化方法&lt;br/&gt;- 优化引擎&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;基于 Python，用户很容易实现模块的自定义操作。&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;能在 CPU　和　GPU　之间无缝切换。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;hr/&gt;
&lt;h3 id=&quot;关于keras模型&quot;&gt;关于Keras模型&lt;/h3&gt;
&lt;p&gt;Keras 有两种类型的模型，序列模型（Sequential）和 函数式模型（Model），函数式模型应用更为广泛，序列模型是函数式模型的一种特殊情况。函数式模型也叫通用模型。&lt;/p&gt;
&lt;p&gt;两类模型均有有两个主要的方法：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;model.summary()&lt;/code&gt;：打印出模型概况，它实际调用的是&lt;code&gt;keras.utils.print_summary&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model.get_config()&lt;/code&gt;:返回包含模型配置信息的 Python 字典。模型也可以从它的 &lt;code&gt;config&lt;/code&gt; 信息中重构回去&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;对于 Model: &lt;code&gt;Model.from_config&lt;/code&gt; 我不会使用。&lt;/p&gt;
&lt;p&gt;对于 Sequential:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;config &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; model.get_config()
model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential.from_config(config)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;model.get_layer()&lt;/code&gt;：依据层名或下标获得层对象&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model.get_weights()&lt;/code&gt;：返回模型权重张量的列表，类型为 &lt;code&gt;numpy.array&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model.set_weights()&lt;/code&gt;：从 &lt;code&gt;numpy.array&lt;/code&gt; 里将权重载入给模型，要求数组具有与 &lt;code&gt;model.get_weights()&lt;/code&gt; 相同的形状。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;sequential-序列模型&quot;&gt;1.1 Sequential 序列模型&lt;/h2&gt;
&lt;p&gt;序列模型是函数式模型的简略版（即序列模型是通用模型的一个子类），为最简单的线性、从头到尾的结构顺序，不分叉。即这种模型各层之间是依次顺序的线性关系，在第 &lt;span class=&quot;math inline&quot;&gt;\(k\)&lt;/span&gt; 层和 &lt;span class=&quot;math inline&quot;&gt;\(k+1\)&lt;/span&gt; 层之间可以加上各种元素来构造神经网络。这些元素可以通过一个列表来制定，然后作为参数传递给序列模型来生成相应的模型。&lt;/p&gt;
&lt;p&gt;Sequential模型的基本组件:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;code&gt;model.add&lt;/code&gt;，添加层；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model.compile&lt;/code&gt;,模型训练的 BP 模式设置；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model.fit&lt;/code&gt;，模型训练参数设置 + 训练；&lt;/li&gt;
&lt;li&gt;模型评估&lt;/li&gt;
&lt;li&gt;模型预测&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;add添加层&quot;&gt;1.1.1 add：添加层&lt;/h3&gt;
&lt;p&gt;序贯模型是多个网络层的线性堆叠，也就是“一条路走到黑”。&lt;br/&gt;可以通过向 Sequential 模型传递一个 layer 的 &lt;code&gt;list&lt;/code&gt; 来构造该模型：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;15&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Sequential
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Dense, Activation

model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential([Dense(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, input_shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;784&lt;/span&gt;,)),
                    Activation(&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;),
                    Dense(&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;),
                    Activation(&lt;span class=&quot;st&quot;&gt;'softmax'&lt;/span&gt;),
                   ])&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;Using TensorFlow backend.&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;也可以通过 &lt;code&gt;.add()&lt;/code&gt; 方法一个个的将 layer 加入模型中：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential()
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, input_shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;784&lt;/span&gt;,)))
model.add(Activation(&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;))
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;))
model.add(Activation(&lt;span class=&quot;st&quot;&gt;'softmax'&lt;/span&gt;))&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;指定输入数据的-shape&quot;&gt;1.1.2 指定输入数据的 shape&lt;/h3&gt;
&lt;p&gt;模型需要知道输入数据的 shape，因此，&lt;code&gt;Sequential&lt;/code&gt; 的第一层需要接受一个关于输入数据 shape 的参数，后面的各个层则可以自动的推导出中间数据的shape，因此不需要为每个层都指定这个参数。有几种方法来为第一层指定输入数据的 shape：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;传递一个&lt;code&gt;input_shape&lt;/code&gt;的关键字参数给第一层，&lt;code&gt;input_shape&lt;/code&gt;是一个 tuple 类型的数据，其中也可以填入 &lt;code&gt;None&lt;/code&gt; ，如果填入 &lt;code&gt;None&lt;/code&gt; 则表示此位置可能是任何正整数。数据的 &lt;code&gt;batch&lt;/code&gt; 大小不应包含在其中。&lt;/li&gt;
&lt;li&gt;有些2D层，如 &lt;code&gt;Dense&lt;/code&gt;，支持通过指定其输入维度 &lt;code&gt;input_dim&lt;/code&gt; 来隐含的指定输入数据 shape,是一个 Int 类型的数据。一些 3D 的时域层支持通过参数&lt;code&gt;input_dim&lt;/code&gt; 和&lt;code&gt;input_length&lt;/code&gt; 来指定输入 shape。&lt;/li&gt;
&lt;li&gt;如果你需要为输入指定一个固定大小的 &lt;code&gt;batch_size&lt;/code&gt;（常用于 stateful RNN 网络），可以传递 &lt;code&gt;batch_size&lt;/code&gt; 参数到一个层中，例如你想指定输入张量的&lt;code&gt;batch&lt;/code&gt; 大小是 &lt;span class=&quot;math inline&quot;&gt;\(32\)&lt;/span&gt;，数据shape是 &lt;span class=&quot;math inline&quot;&gt;\((6，8)\)&lt;/span&gt;，则你需要传递 &lt;code&gt;batch_size=32&lt;/code&gt; 和 &lt;code&gt;input_shape=(6,8)&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;sourceCode&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential()
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, input_dim&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;784&lt;/span&gt;))
model.summary()&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_6 (Dense)              (None, 32)                25120     
=================================================================
Total params: 25,120
Trainable params: 25,120
Non-trainable params: 0
_________________________________________________________________&lt;/code&gt;
&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;9&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential()
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, input_shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;784&lt;/span&gt;,)))
model.summary()&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_8 (Dense)              (None, 32)                25120     
=================================================================
Total params: 25,120
Trainable params: 25,120
Non-trainable params: 0
_________________________________________________________________&lt;/code&gt;
&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential()
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, input_shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; (&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;)))
model.summary()&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_9 (Dense)              (None, 32, 32, 100)       400       
=================================================================
Total params: 400
Trainable params: 400
Non-trainable params: 0
_________________________________________________________________&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Param 是 &lt;span class=&quot;math inline&quot;&gt;\(400\)&lt;/span&gt;：&lt;span class=&quot;math inline&quot;&gt;\(3 \times 100 + 100\)&lt;/span&gt; （包含偏置项）&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;12&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential()
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, input_shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; (&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;), batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;))
model.summary()&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_10 (Dense)             (64, 32, 32, 100)         400       
=================================================================
Total params: 400
Trainable params: 400
Non-trainable params: 0
_________________________________________________________________&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;编译&quot;&gt;1.1.3 编译&lt;/h3&gt;
&lt;p&gt;在训练模型之前，我们需要通过 &lt;code&gt;compile&lt;/code&gt; 来对学习过程进行配置。&lt;br/&gt;&lt;code&gt;compile&lt;/code&gt;接收三个参数：&lt;/p&gt;
&lt;ul readability=&quot;4.3485576923077&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;优化器 &lt;code&gt;optimizer&lt;/code&gt;：该参数可指定为已预定义的优化器名，如 &lt;code&gt;rmsprop、adagrad&lt;/code&gt; ，或一个&lt;code&gt;Optimizer&lt;/code&gt; 类的对象，详情见&lt;a href=&quot;http://keras-cn.readthedocs.io/en/latest/other/optimizers/&quot;&gt;优化器optimizers&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0.92626728110599&quot;&gt;
&lt;p&gt;损失函数 &lt;code&gt;loss&lt;/code&gt;：该参数为模型试图最小化的目标函数，它可为预定义的损失函数名，如 &lt;code&gt;categorical_crossentropy、mse&lt;/code&gt;，也可以为一个自定义损失函数。详情见&lt;a href=&quot;http://keras-cn.readthedocs.io/en/latest/other/objectives/&quot;&gt;损失函数loss&lt;/a&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;指标列表 &lt;code&gt;metrics&lt;/code&gt;：对分类问题，我们一般将该列表设置为 &lt;code&gt;metrics=['accuracy']&lt;/code&gt;。指标可以是一个预定义指标的名字,也可以是一个用户定制的函数。指标函数应该返回单个张量，或一个完成 &lt;code&gt;metric_name - &amp;gt; metric_value&lt;/code&gt;映射的字典。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sample_weight_mode&lt;/code&gt;：如果你需要按时间步为样本赋权（ 2D 权矩阵），将该值设为 “&lt;code&gt;temporal&lt;/code&gt;”。&lt;br/&gt;默认为 “&lt;code&gt;None&lt;/code&gt;”，代表按样本赋权（1D 权）。在下面 &lt;code&gt;fit&lt;/code&gt; 函数的解释中有相关的参考内容。&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;code&gt;kwargs&lt;/code&gt;： 使用 TensorFlow 作为后端请忽略该参数，若使用 Theano 作为后端，&lt;code&gt;kwargs&lt;/code&gt; 的值将会传递给 &lt;code&gt;K.function&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;注意：&lt;/p&gt;
&lt;p&gt;模型在使用前必须编译，否则在调用 &lt;code&gt;fit&lt;/code&gt; 或 &lt;code&gt;evaluate&lt;/code&gt; 时会抛出异常。&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;19&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# For a multi-class classification problem&lt;/span&gt;
model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'rmsprop'&lt;/span&gt;,
              loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'categorical_crossentropy'&lt;/span&gt;,
              metrics&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[&lt;span class=&quot;st&quot;&gt;'accuracy'&lt;/span&gt;])

&lt;span class=&quot;co&quot;&gt;# For a binary classification problem&lt;/span&gt;
model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'rmsprop'&lt;/span&gt;,
              loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'binary_crossentropy'&lt;/span&gt;,
              metrics&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[&lt;span class=&quot;st&quot;&gt;'accuracy'&lt;/span&gt;])

&lt;span class=&quot;co&quot;&gt;# For a mean squared error regression problem&lt;/span&gt;
model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'rmsprop'&lt;/span&gt;,
              loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'mse'&lt;/span&gt;)

&lt;span class=&quot;co&quot;&gt;# For custom metrics&lt;/span&gt;
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; keras.backend &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; K

&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; mean_pred(y_true, y_pred):
    &lt;span class=&quot;cf&quot;&gt;return&lt;/span&gt; K.mean(y_pred)

model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'rmsprop'&lt;/span&gt;,
              loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'binary_crossentropy'&lt;/span&gt;,
              metrics&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[&lt;span class=&quot;st&quot;&gt;'accuracy'&lt;/span&gt;, mean_pred])&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;训练&quot;&gt;1.1.3 训练&lt;/h3&gt;
&lt;p&gt;Keras以 Numpy 数组作为输入数据和标签的数据类型。训练模型一般使用 &lt;code&gt;fit&lt;/code&gt; 函数:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;fit(self, x, y, batch_size=32, epochs=10, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;本函数将模型训练 &lt;code&gt;epochs&lt;/code&gt; 轮，其参数有：&lt;/p&gt;
&lt;ul readability=&quot;11.935828877005&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;code&gt;x&lt;/code&gt;：输入数据。如果模型只有一个输入，那么 &lt;code&gt;x&lt;/code&gt; 的类型是 numpy array，如果模型有多个输入，那么 &lt;code&gt;x&lt;/code&gt; 的类型应当为 list，list 的元素是对应于各个输入的 numpy array&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;y&lt;/code&gt;：标签，numpy array&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;batch_size&lt;/code&gt;：整数，指定进行梯度下降时每个 batch 包含的样本数。训练时一个 batch 的样本会被计算一次梯度下降，使目标函数优化一步。&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;epochs&lt;/code&gt;：整数，训练的轮数，每个 epoch 会把训练集轮一遍。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;code&gt;verbose&lt;/code&gt;：日志显示，&lt;code&gt;0&lt;/code&gt; 为不在标准输出流输出日志信息，&lt;code&gt;1&lt;/code&gt; 为输出进度条记录，&lt;code&gt;2&lt;/code&gt; 为每个epoch输出一行记录&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;code&gt;callbacks&lt;/code&gt;：list，其中的元素是 keras.callbacks.Callback 的对象。这个 list 中的回调函数将会在训练过程中的适当时机被调用，参考&lt;a href=&quot;http://keras-cn.readthedocs.io/en/latest/other/callbacks/&quot;&gt;回调函数&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;validation_split&lt;/code&gt;：&lt;span class=&quot;math inline&quot;&gt;\(0 - 1\)&lt;/span&gt; 之间的浮点数，用来指定训练集的一定比例数据作为验证集。验证集将不参与训练，并在每个 epoch 结束后测试的模型的指标，如损失函数、精确度等。
&lt;ul&gt;&lt;li&gt;注意，validation_split 的划分在 shuffle 之前，因此如果你的数据本身是有序的，需要先手工打乱再指定validation_split，否则可能会出现验证集样本不均匀。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;code&gt;validation_data&lt;/code&gt;：形式为 &lt;code&gt;(X, y)&lt;/code&gt; 的 tuple，是指定的验证集。此参数将覆盖 validation_spilt。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;code&gt;shuffle&lt;/code&gt;：布尔值或字符串，一般为布尔值，表示是否在训练过程中随机打乱输入样本的顺序。若为字符串 “batch”，则是用来处理 HDF5 数据的特殊情况，它将在 batch 内部将数据打乱。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;&lt;code&gt;class_weight&lt;/code&gt;：字典，将不同的类别映射为不同的权值，该参数用来在训练过程中调整损失函数（只能用于训练）&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;2&quot;&gt;
&lt;p&gt;&lt;code&gt;sample_weight&lt;/code&gt;：权值的numpy array，用于在训练时调整损失函数（仅用于训练）。可以传递一个 1D 的与样本等长的向量用于对样本进行 &lt;span class=&quot;math inline&quot;&gt;\(1\)&lt;/span&gt; 对 &lt;span class=&quot;math inline&quot;&gt;\(1\)&lt;/span&gt; 的加权，或者在面对时序数据时，传递一个的形式为 &lt;code&gt;(samples，sequence_length)&lt;/code&gt; 的矩阵来为每个时间步上的样本赋不同的权。这种情况下请确定在编译模型时添加了 &lt;code&gt;sample_weight_mode='temporal'&lt;/code&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;initial_epoch&lt;/code&gt;: 从该参数指定的 epoch 开始训练，在继续之前的训练时有用。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;fit函数返回一个 History 的对象，其 History.history 属性记录了损失函数和其他指标的数值随 epoch 变化的情况，如果有验证集的话，也包含了验证集的这些指标变化情况&lt;/p&gt;
&lt;p&gt;注意：&lt;br/&gt;要与之后的 &lt;code&gt;fit_generator&lt;/code&gt; 做区别，两者输入 x/y 不同。&lt;/p&gt;
&lt;h4 id=&quot;案例一简单的2分类&quot;&gt;案例一：简单的2分类&lt;/h4&gt;
&lt;p&gt;&lt;span class=&quot;math inline&quot;&gt;\(epoch = batch\_size \times iteration\)&lt;/span&gt; ,&lt;span class=&quot;math inline&quot;&gt;\(10\)&lt;/span&gt; 次 epoch 代表训练十次训练集&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;25&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Sequential
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Dense, Activation

&lt;span class=&quot;co&quot;&gt;# 模型搭建阶段&lt;/span&gt;
model&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential()  &lt;span class=&quot;co&quot;&gt;# 代表类的初始化&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;# Dense(32) is a fully-connected layer with 32 hidden units.&lt;/span&gt;
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;, input_dim&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;))

model.add(Dense(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'sigmoid'&lt;/span&gt;))

&lt;span class=&quot;co&quot;&gt;# For custom metrics&lt;/span&gt;
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; keras.backend &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; K

&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; mean_pred(y_true, y_pred):
    &lt;span class=&quot;cf&quot;&gt;return&lt;/span&gt; K.mean(y_pred)

model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'rmsprop'&lt;/span&gt;,
              loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'binary_crossentropy'&lt;/span&gt;,
              metrics&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[&lt;span class=&quot;st&quot;&gt;'accuracy'&lt;/span&gt;, mean_pred])

&lt;span class=&quot;co&quot;&gt;# Generate dummy data&lt;/span&gt;
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; np
data &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; np.random.random((&lt;span class=&quot;dv&quot;&gt;1000&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;))
labels &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; np.random.randint(&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1000&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;))

&lt;span class=&quot;co&quot;&gt;# Train the model, iterating on the data in batches of 32 samples&lt;/span&gt;
model.fit(data, labels, epochs &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;Using TensorFlow backend.


Epoch 1/10
1000/1000 [==============================] - 3s - loss: 0.7218 - acc: 0.4780 - mean_pred: 0.5181     
Epoch 2/10
1000/1000 [==============================] - 0s - loss: 0.7083 - acc: 0.4990 - mean_pred: 0.5042     
Epoch 3/10
1000/1000 [==============================] - 0s - loss: 0.7053 - acc: 0.4850 - mean_pred: 0.5174     
Epoch 4/10
1000/1000 [==============================] - 0s - loss: 0.6978 - acc: 0.5400 - mean_pred: 0.5074     
Epoch 5/10
1000/1000 [==============================] - 0s - loss: 0.6938 - acc: 0.5250 - mean_pred: 0.5088     
Epoch 6/10
1000/1000 [==============================] - 0s - loss: 0.6887 - acc: 0.5290 - mean_pred: 0.5196     
Epoch 7/10
1000/1000 [==============================] - 0s - loss: 0.6847 - acc: 0.5570 - mean_pred: 0.5052     
Epoch 8/10
1000/1000 [==============================] - 0s - loss: 0.6797 - acc: 0.5530 - mean_pred: 0.5134     
Epoch 9/10
1000/1000 [==============================] - 0s - loss: 0.6749 - acc: 0.5790 - mean_pred: 0.5126     
Epoch 10/10
1000/1000 [==============================] - 0s - loss: 0.6728 - acc: 0.5920 - mean_pred: 0.5118     





&amp;lt;keras.callbacks.History at 0x1eafe9b9240&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;evaluate-模型评估&quot;&gt;1.1.4 evaluate 模型评估&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;本函数按 batch 计算在某些输入数据上模型的误差，其参数有：&lt;/p&gt;
&lt;ul readability=&quot;1&quot;&gt;&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;x&lt;/code&gt;：输入数据，与 fit 一样，是 numpy array 或 numpy array 的 list&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;y&lt;/code&gt;：标签，numpy array&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;batch_size&lt;/code&gt;：整数，含义同 fit 的同名参数&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;verbose&lt;/code&gt;：含义同fit的同名参数，但只能取0或1&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;sample_weight&lt;/code&gt;：numpy array，含义同 fit 的同名参数&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;本函数返回一个测试误差的标量值（如果模型没有其他评价指标），或一个标量的 list（如果模型还有其他的评价指标）。&lt;code&gt;model.metrics_names&lt;/code&gt;将给出 list 中各个值的含义。&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;9&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model.evaluate(data, labels, batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt; 512/1000 [==============&amp;gt;...............] - ETA: 0s




[0.62733754062652591, 0.68200000000000005, 0.54467054557800298]&lt;/code&gt;
&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model.metrics_names&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;['loss', 'acc', 'mean_pred']&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;predict-模型预测&quot;&gt;1.1.5 predict 模型预测&lt;/h3&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;17&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;predict(&lt;span class=&quot;va&quot;&gt;self&lt;/span&gt;, x, batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, verbose&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;)
predict_classes(&lt;span class=&quot;va&quot;&gt;self&lt;/span&gt;, x, batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, verbose&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)
predict_proba(&lt;span class=&quot;va&quot;&gt;self&lt;/span&gt;, x, batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, verbose&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;predict&lt;/code&gt; 函数按 batch 获得输入数据对应的输出，函数的返回值是预测值的 numpy array 其参数有：&lt;/li&gt;
&lt;li&gt;&lt;code&gt;predict_classes&lt;/code&gt;：本函数按batch产生输入数据的类别预测结果；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;predict_proba&lt;/code&gt;：本函数按 batch 产生输入数据属于各个类别的概率&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;sourceCode&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model.predict_proba?&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;sourceCode&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model.predict(data[:&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;])&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;array([[ 0.39388809],
       [ 0.39062682],
       [ 0.59655035],
       [ 0.53066045],
       [ 0.56720185]], dtype=float32)&lt;/code&gt;
&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model.predict_classes(data[:&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;])&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;5/5 [==============================] - 0s





array([[0],
       [0],
       [1],
       [1],
       [1]])&lt;/code&gt;
&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model.predict_proba(data[:&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;])&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;5/5 [==============================] - 0s





array([[ 0.39388809],
       [ 0.39062682],
       [ 0.59655035],
       [ 0.53066045],
       [ 0.56720185]], dtype=float32)&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;on_batch-的结果模型检查&quot;&gt;1.1.6 &lt;code&gt;on_batch&lt;/code&gt; 的结果，模型检查&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;train_on_batch&lt;/code&gt;：本函数在一个 batch 的数据上进行一次参数更新，函数返回训练误差的标量值或标量值的 list，与 evaluate 的情形相同。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;test_on_batch&lt;/code&gt;：本函数在一个 batch 的样本上对模型进行评估，函数的返回与 evaluate 的情形相同&lt;/li&gt;
&lt;li&gt;&lt;code&gt;predict_on_batch&lt;/code&gt;：本函数在一个 batch 的样本上对模型进行测试，函数返回模型在一个 batch 上的预测结果&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;sourceCode&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model.train_on_batch(data, labels)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;[0.62733746, 0.68199992, 0.54467058]&lt;/code&gt;
&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model.train_on_batch(data, labels)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;[0.62483531, 0.68799996, 0.52803379]&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;fit_generator&quot;&gt;1.1.7 fit_generator&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;利用 Python 的生成器，逐个生成数据的 batch 并进行训练。&lt;/li&gt;
&lt;li&gt;生成器与模型将并行执行以提高效率。&lt;/li&gt;
&lt;li&gt;例如，该函数允许我们在 CPU 上进行实时的数据提升，同时在 GPU 上进行模型训练&lt;br/&gt;参考链接：&lt;a href=&quot;http://keras-cn.readthedocs.io/en/latest/models/sequential/&quot; class=&quot;uri&quot;&gt;http://keras-cn.readthedocs.io/en/latest/models/sequential/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;有了该函数，图像分类训练任务变得很简单。&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;20&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model.fit_generator(generator, steps_per_epoch, epochs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, verbose&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, callbacks&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;None&lt;/span&gt;, validation_data&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;None&lt;/span&gt;, validation_steps&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;None&lt;/span&gt;, class_weight&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;None&lt;/span&gt;, max_queue_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, workers&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, use_multiprocessing&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;False&lt;/span&gt;, initial_epoch&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;函数的参数是：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;generator&lt;/code&gt;：生成器函数，生成器的输出应该为：
&lt;ul&gt;&lt;li&gt;一个形如 &lt;code&gt;(inputs，targets)&lt;/code&gt; 的tuple&lt;/li&gt;
&lt;li&gt;一个形如 &lt;code&gt;(inputs, targets,sample_weight)&lt;/code&gt; 的 tuple。&lt;br/&gt;所有的返回值都应该包含相同数目的样本。生成器将无限在数据集上循环。每个 epoch 以经过模型的样本数达到 samples_per_epoch 时，记一个 epoch 结束。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;steps_per_epoch&lt;/code&gt;：整数，当生成器返回 &lt;code&gt;steps_per_epoch&lt;/code&gt; 次数据时计一个 epoch 结束，执行下一个 epoch&lt;/li&gt;
&lt;li&gt;&lt;code&gt;epochs&lt;/code&gt;：整数，数据迭代的轮数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;verbose&lt;/code&gt;：日志显示，&lt;code&gt;0&lt;/code&gt; 为不在标准输出流输出日志信息，&lt;code&gt;1&lt;/code&gt; 为输出进度条记录，&lt;code&gt;2&lt;/code&gt; 为每个 epoch 输出一行记录&lt;/li&gt;
&lt;li&gt;&lt;code&gt;validation_data&lt;/code&gt;：具有以下三种形式之一
&lt;ul&gt;&lt;li&gt;生成验证集的生成器&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;一个形如 &lt;code&gt;(inputs,targets)&lt;/code&gt; 的tuple&lt;/li&gt;
&lt;li&gt;一个形如 &lt;code&gt;(inputs,targets，sample_weights)&lt;/code&gt; 的tuple&lt;/li&gt;
&lt;li&gt;&lt;code&gt;validation_steps&lt;/code&gt;: 当 &lt;code&gt;validation_data&lt;/code&gt; 为生成器时，本参数指定验证集的生成器返回次数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;class_weight&lt;/code&gt;：规定类别权重的字典，将类别映射为权重，常用于处理样本不均衡问题。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sample_weight&lt;/code&gt;：权值的 numpy array，用于在训练时调整损失函数（仅用于训练）。可以传递一个1D的与样本等长的向量用于对样本进行 &lt;span class=&quot;math inline&quot;&gt;\(1\)&lt;/span&gt; 对&lt;span class=&quot;math inline&quot;&gt;\(1\)&lt;/span&gt; 的加权，或者在面对时序数据时，传递一个的形式为 &lt;code&gt;(samples，sequence_length)&lt;/code&gt; 的矩阵来为每个时间步上的样本赋不同的权。这种情况下请确定在编译模型时添加了&lt;code&gt;sample_weight_mode='temporal'&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;workers&lt;/code&gt;：最大进程数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max_q_size&lt;/code&gt;：生成器队列的最大容量&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pickle_safe&lt;/code&gt;: 若为真，则使用基于进程的线程。由于该实现依赖多进程，不能传递 &lt;code&gt;non picklable&lt;/code&gt;（无法被 pickle 序列化）的参数到生成器中，因为无法轻易将它们传入子进程中。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;initial_epoch&lt;/code&gt;: 从该参数指定的 epoch 开始训练，在继续之前的训练时有用。&lt;br/&gt;函数返回一个 History 对象。&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;例子&quot;&gt;例子&lt;/h4&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;14&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; generate_arrays_from_file(path):
        &lt;span class=&quot;cf&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;:
            f &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bu&quot;&gt;open&lt;/span&gt;(path)
            &lt;span class=&quot;cf&quot;&gt;for&lt;/span&gt; line &lt;span class=&quot;op&quot;&gt;in&lt;/span&gt; f:
                &lt;span class=&quot;co&quot;&gt;# create Numpy arrays of input data&lt;/span&gt;
                &lt;span class=&quot;co&quot;&gt;# and labels, from each line in the file&lt;/span&gt;
                x, y &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; process_line(line)
                &lt;span class=&quot;cf&quot;&gt;yield&lt;/span&gt; (x, y)
            f.close()

model.fit_generator(generate_arrays_from_file(&lt;span class=&quot;st&quot;&gt;'/my_file.txt'&lt;/span&gt;), steps_per_epoch&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;1000&lt;/span&gt;, epochs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;其他的两个辅助的内容&quot;&gt;1.1.8 其他的两个辅助的内容：&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;evaluate_generator&lt;/code&gt;：本函数使用一个生成器作为数据源评估模型，生成器应返回与 test_on_batch 的输入数据相同类型的数据。该函数的参数与 fit_generator 同名参数含义相同，steps 是生成器要返回数据的轮数。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;predcit_generator&lt;/code&gt;：本函数使用一个生成器作为数据源预测模型，生成器应返回与 test_on_batch 的输入数据相同类型的数据。该函数的参数与 fit_generator 同名参数含义相同，steps 是生成器要返回数据的轮数。&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;案例二多分类-vgg的卷积神经网络&quot;&gt;案例二:多分类-VGG的卷积神经网络&lt;/h3&gt;
&lt;p&gt;注意：&lt;code&gt;keras.utils.to_categorical&lt;/code&gt; 的用法：&lt;/p&gt;
&lt;p&gt;类似于 One-Hot 编码：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;keras.utils.to_categorical(y, num_classes&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;None&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;55&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# -*- coding:utf-8 -*-&lt;/span&gt;

&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; np
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; keras
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Sequential
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Dense, Dropout, Flatten
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Conv2D, MaxPooling2D
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.optimizers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; SGD
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.utils &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; np_utils

&lt;span class=&quot;co&quot;&gt;# Generate dummy data&lt;/span&gt;
x_train &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; np.random.random((&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;))
&lt;span class=&quot;co&quot;&gt;# 100张图片，每张 100*100*3&lt;/span&gt;
y_train &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; keras.utils.to_categorical(np.random.randint(&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)), num_classes&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;)
&lt;span class=&quot;co&quot;&gt;# 100*10&lt;/span&gt;
x_test &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; np.random.random((&lt;span class=&quot;dv&quot;&gt;20&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;))
y_test &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; keras.utils.to_categorical(np.random.randint(&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;20&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)), num_classes&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;)
&lt;span class=&quot;co&quot;&gt;# 20*100&lt;/span&gt;

model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential()&lt;span class=&quot;co&quot;&gt;#最简单的线性、从头到尾的结构顺序，不分叉&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# input: 100x100 images with 3 channels -&amp;gt; (100, 100, 3) tensors.&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# this applies 32 convolution filters of size 3x3 each.&lt;/span&gt;
model.add(Conv2D(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, (&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;), activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;, input_shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;)))
model.add(Conv2D(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, (&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;), activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;))
model.add(MaxPooling2D(pool_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;)))
model.add(Dropout(&lt;span class=&quot;fl&quot;&gt;0.25&lt;/span&gt;))

model.add(Conv2D(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, (&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;), activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;))
model.add(Conv2D(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, (&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;), activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;))
model.add(MaxPooling2D(pool_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;)))
model.add(Dropout(&lt;span class=&quot;fl&quot;&gt;0.25&lt;/span&gt;))

model.add(Flatten())
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;256&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;))
model.add(Dropout(&lt;span class=&quot;fl&quot;&gt;0.5&lt;/span&gt;))
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'softmax'&lt;/span&gt;))

sgd &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; SGD(lr&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.01&lt;/span&gt;, decay&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;1e-6&lt;/span&gt;, momentum&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.9&lt;/span&gt;, nesterov&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;)
model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'categorical_crossentropy'&lt;/span&gt;, optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;sgd)

model.fit(x_train, y_train, batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, epochs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;)
score &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; model.evaluate(x_test, y_test, batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;)
score&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;Epoch 1/10
100/100 [==============================] - 1s - loss: 2.3800     
Epoch 2/10
100/100 [==============================] - 0s - loss: 2.3484     
Epoch 3/10
100/100 [==============================] - 0s - loss: 2.3034     
Epoch 4/10
100/100 [==============================] - 0s - loss: 2.2938     
Epoch 5/10
100/100 [==============================] - 0s - loss: 2.2874     
Epoch 6/10
100/100 [==============================] - 0s - loss: 2.2873     
Epoch 7/10
100/100 [==============================] - 0s - loss: 2.3132     - ETA: 0s - loss: 2.31
Epoch 8/10
100/100 [==============================] - 0s - loss: 2.2866     
Epoch 9/10
100/100 [==============================] - 0s - loss: 2.2814     
Epoch 10/10
100/100 [==============================] - 0s - loss: 2.2856     
20/20 [==============================] - 0s





2.2700035572052002&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;使用lstm的序列分类&quot;&gt;使用LSTM的序列分类&lt;/h3&gt;
&lt;h3 id=&quot;采用stateful-lstm的相同模型&quot;&gt;采用stateful LSTM的相同模型&lt;/h3&gt;
&lt;p&gt;stateful LSTM的特点是，在处理过一个batch的训练数据后，其内部状态（记忆）会被作为下一个batch的训练数据的初始状态。状态LSTM使得我们可以在合理的计算复杂度内处理较长序列&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Sequential
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; LSTM, Dense
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; np

data_dim &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;16&lt;/span&gt;
timesteps &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;8&lt;/span&gt;
num_classes &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;
batch_size &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;# Expected input batch shape: (batch_size, timesteps, data_dim)&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# Note that we have to provide the full batch_input_shape since the network is stateful.&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# the sample of index i in batch k is the follow-up for the sample i in batch k-1.&lt;/span&gt;
model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential()
model.add(LSTM(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, return_sequences&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;, stateful&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;,
               batch_input_shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(batch_size, timesteps, data_dim)))
model.add(LSTM(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, return_sequences&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;, stateful&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;))
model.add(LSTM(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, stateful&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;))
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'softmax'&lt;/span&gt;))

model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'categorical_crossentropy'&lt;/span&gt;,
              optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'rmsprop'&lt;/span&gt;,
              metrics&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[&lt;span class=&quot;st&quot;&gt;'accuracy'&lt;/span&gt;])

&lt;span class=&quot;co&quot;&gt;# Generate dummy training data&lt;/span&gt;
x_train &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; np.random.random((batch_size &lt;span class=&quot;op&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, timesteps, data_dim))
y_train &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; np.random.random((batch_size &lt;span class=&quot;op&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, num_classes))

&lt;span class=&quot;co&quot;&gt;# Generate dummy validation data&lt;/span&gt;
x_val &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; np.random.random((batch_size &lt;span class=&quot;op&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, timesteps, data_dim))
y_val &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; np.random.random((batch_size &lt;span class=&quot;op&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, num_classes))

model.fit(x_train, y_train,
          batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;batch_size, epochs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;, shuffle&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;False&lt;/span&gt;,
          validation_data&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(x_val, y_val))&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;Train on 320 samples, validate on 96 samples
Epoch 1/5
320/320 [==============================] - 2s - loss: 11.4843 - acc: 0.1062 - val_loss: 11.2222 - val_acc: 0.1042
Epoch 2/5
320/320 [==============================] - 0s - loss: 11.4815 - acc: 0.1031 - val_loss: 11.2207 - val_acc: 0.1250
Epoch 3/5
320/320 [==============================] - 0s - loss: 11.4799 - acc: 0.0844 - val_loss: 11.2202 - val_acc: 0.1562
Epoch 4/5
320/320 [==============================] - 0s - loss: 11.4790 - acc: 0.1000 - val_loss: 11.2198 - val_acc: 0.1562
Epoch 5/5
320/320 [==============================] - 0s - loss: 11.4780 - acc: 0.1094 - val_loss: 11.2194 - val_acc: 0.1250





&amp;lt;keras.callbacks.History at 0x1ab0e78ff28&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;keras-faq&quot;&gt;Keras FAQ：&lt;/h4&gt;
&lt;p&gt;常见问题: &lt;a href=&quot;http://keras-cn.readthedocs.io/en/latest/for_beginners/FAQ/&quot; class=&quot;uri&quot;&gt;http://keras-cn.readthedocs.io/en/latest/for_beginners/FAQ/&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;model通用模型或者称为函数式functional模型&quot;&gt;1.2 Model（通用模型）（或者称为函数式（Functional）模型）&lt;/h2&gt;
&lt;p&gt;函数式模型称作 Functional，但它的类名是 &lt;code&gt;Model&lt;/code&gt;，因此我们有时候也用 Model 来代表函数式模型。&lt;/p&gt;
&lt;p&gt;Keras函数式模型接口是用户定义多输出模型、非循环有向模型或具有共享层的模型等复杂模型的途径。函数式模型是最广泛的一类模型，序贯模型（Sequential）只是它的一种特殊情况。更多关于序列模型的资料参考： &lt;a href=&quot;http://keras-cn.readthedocs.io/en/latest/models/sequential/#sequential&quot;&gt;序贯模型API&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;通用模型可以用来设计非常复杂、任意拓扑结构的神经网络。类似于序列模型，通用模型采用&lt;strong&gt;函数化的应用接口&lt;/strong&gt;来定义模型。&lt;/p&gt;
&lt;p&gt;在定义的时候，从输入的多维矩阵开始，然后定义各层及其要素，最后定义输出层。将输入层与输出层作为参数纳入通用模型中就可以定义一个模型对象，并进行编译和拟合。&lt;/p&gt;
&lt;p&gt;函数式模型基本属性与训练流程：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;code&gt;model.layers&lt;/code&gt;，添加层信息；&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model.compile&lt;/code&gt;,模型训练的BP模式设置；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model.fit&lt;/code&gt;，模型训练参数设置 + 训练；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;evaluate&lt;/code&gt;，模型评估；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;predict&lt;/code&gt; 模型预测&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;常用model属性&quot;&gt;1.2.1 常用Model属性&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;model.layers&lt;/code&gt;：组成模型图的各个层&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model.inputs&lt;/code&gt;：模型的输入张量列表&lt;/li&gt;
&lt;li&gt;&lt;code&gt;model.outputs&lt;/code&gt;：模型的输出张量列表&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;compile-训练模式设置&quot;&gt;1.2.2 compile 训练模式设置&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;compile(self, optimizer, loss, metrics=None, loss_weights=None, sample_weight_mode=None)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;本函数编译模型以供训练，参数有&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;optimizer&lt;/code&gt;：优化器，为预定义优化器名或优化器对象&lt;/li&gt;
&lt;li&gt;&lt;code&gt;loss&lt;/code&gt;：损失函数，为预定义损失函数名或一个目标函数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;metrics&lt;/code&gt;：列表，包含评估模型在训练和测试时的性能的指标，典型用法是&lt;code&gt;metrics=['accuracy']&lt;/code&gt;如果要在多输出模型中为不同的输出指定不同的指标，可像该参数传递一个字典，例如 &lt;code&gt;metrics={'ouput_a': 'accuracy'}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sample_weight_mode&lt;/code&gt;：如果你需要按时间步为样本赋权（ 2D 权矩阵），将该值设为 “&lt;code&gt;temporal&lt;/code&gt;”。默认为 “&lt;code&gt;None&lt;/code&gt;”，代表按样本赋权（1D权）。&lt;br/&gt;如果模型有多个输出，可以向该参数传入指定 &lt;code&gt;sample_weight_mode&lt;/code&gt; 的字典或列表。在下面 &lt;code&gt;fit&lt;/code&gt; 函数的解释中有相关的参考内容。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;【Tips】如果你只是载入模型并利用其 &lt;code&gt;predict&lt;/code&gt;，可以不用进行 &lt;code&gt;compile&lt;/code&gt;。在Keras中，&lt;code&gt;compile&lt;/code&gt; 主要完成损失函数和优化器的一些配置，是为训练服务的。&lt;code&gt;predict&lt;/code&gt; 会在内部进行符号函数的编译工作（通过调用&lt;code&gt;_make_predict_function&lt;/code&gt; 生成函数）&lt;/p&gt;
&lt;h3 id=&quot;fit-模型训练参数设置-训练&quot;&gt;1.2.3 &lt;code&gt;fit&lt;/code&gt; 模型训练参数设置 + 训练&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;fit(self, x=None, y=None, batch_size=32, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;与序列模型类似&lt;/p&gt;
&lt;h3 id=&quot;evaluate模型评估&quot;&gt;1.2.4 &lt;code&gt;evaluate&lt;/code&gt;，模型评估&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;与序列模型类似&lt;/p&gt;
&lt;h3 id=&quot;predict-模型预测-1&quot;&gt;1.2.5 &lt;code&gt;predict&lt;/code&gt; 模型预测&lt;/h3&gt;
&lt;p&gt;predict(self, x, batch_size=32, verbose=0)&lt;/p&gt;
&lt;p&gt;与序列模型类似&lt;/p&gt;
&lt;h3 id=&quot;模型检查&quot;&gt;1.2.6 模型检查&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;&lt;code&gt;train_on_batch&lt;/code&gt;：本函数在一个 batch 的数据上进行一次参数更新，函数返回训练误差的标量值或标量值的 list，与 evaluate 的情形相同。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;test_on_batch&lt;/code&gt;：本函数在一个 batch 的样本上对模型进行评估，函数的返回与 evaluate 的情形相同&lt;/li&gt;
&lt;li&gt;&lt;code&gt;predict_on_batch&lt;/code&gt;：本函数在一个 batch 的样本上对模型进行测试，函数返回模型在一个 batch 上的预测结果&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;与序列模型类似&lt;/p&gt;
&lt;h3 id=&quot;fit_generator-1&quot;&gt;1.2.7 &lt;code&gt;fit_generator&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;fit_generator(self, generator, steps_per_epoch, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_q_size=10, workers=1, pickle_safe=False, initial_epoch=0) evaluate_generator(self, generator, steps, max_q_size=10, workers=1, pickle_safe=False)&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&quot;案例三全连接网络&quot;&gt;案例三：全连接网络&lt;/h4&gt;
&lt;p&gt;在开始前，有几个概念需要澄清：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;层对象接受张量为参数，返回一个张量。&lt;/li&gt;
&lt;li&gt;输入是张量，输出也是张量的一个框架就是一个模型，通过 &lt;code&gt;Model&lt;/code&gt; 定义。&lt;/li&gt;
&lt;li&gt;这样的模型可以被像Keras的 &lt;code&gt;Sequential&lt;/code&gt; 一样被训练&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;sourceCode&quot; readability=&quot;26&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; keras
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Input, Dense
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Model

&lt;span class=&quot;co&quot;&gt;# 层实例接受张量为参数，返回一个张量&lt;/span&gt;
inputs &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;,))

&lt;span class=&quot;co&quot;&gt;# a layer instance is callable on a tensor, and returns a tensor&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# 输入inputs，输出x&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# (inputs)代表输入&lt;/span&gt;
x &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;)(inputs)
&lt;span class=&quot;co&quot;&gt;# 输入x，输出x&lt;/span&gt;
x &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;)(x)

predictions &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'softmax'&lt;/span&gt;)(x)
&lt;span class=&quot;co&quot;&gt;# 输入x，输出分类&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;# This creates a model that includes&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# the Input layer and three Dense layers&lt;/span&gt;
model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Model(inputs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;inputs, outputs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;predictions)
model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'rmsprop'&lt;/span&gt;,
              loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'categorical_crossentropy'&lt;/span&gt;,
              metrics&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[&lt;span class=&quot;st&quot;&gt;'accuracy'&lt;/span&gt;])

&lt;span class=&quot;co&quot;&gt;# Generate dummy data&lt;/span&gt;
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; np
data &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; np.random.random((&lt;span class=&quot;dv&quot;&gt;1000&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;))
labels &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; keras.utils.to_categorical(np.random.randint(&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1000&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)), num_classes&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;)

&lt;span class=&quot;co&quot;&gt;# Train the model&lt;/span&gt;
model.fit(data, labels, batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, epochs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;) &lt;span class=&quot;co&quot;&gt;# starts training&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;Epoch 1/10
1000/1000 [==============================] - 0s - loss: 2.2130 - acc: 0.4650        
Epoch 2/10
1000/1000 [==============================] - 0s - loss: 0.7474 - acc: 0.4980     
Epoch 3/10
1000/1000 [==============================] - 0s - loss: 0.7158 - acc: 0.5050     
Epoch 4/10
1000/1000 [==============================] - 0s - loss: 0.7039 - acc: 0.5260     
Epoch 5/10
1000/1000 [==============================] - 0s - loss: 0.7060 - acc: 0.5280     
Epoch 6/10
1000/1000 [==============================] - 0s - loss: 0.6979 - acc: 0.5270     
Epoch 7/10
1000/1000 [==============================] - 0s - loss: 0.6854 - acc: 0.5570     
Epoch 8/10
1000/1000 [==============================] - 0s - loss: 0.6920 - acc: 0.5300     
Epoch 9/10
1000/1000 [==============================] - 0s - loss: 0.6862 - acc: 0.5620     
Epoch 10/10
1000/1000 [==============================] - 0s - loss: 0.6766 - acc: 0.5750     





&amp;lt;keras.callbacks.History at 0x1ec3dd2d5c0&amp;gt;&lt;/code&gt;
&lt;/pre&gt;

&lt;pre&gt;
&lt;code&gt;&amp;lt;tf.Tensor 'input_4:0' shape=(?, 100) dtype=float32&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到结构与序贯模型完全不一样，其中 &lt;code&gt;x = Dense(64, activation='relu')(inputs)&lt;/code&gt; 中：&lt;code&gt;(input)&lt;/code&gt;代表输入；&lt;code&gt;x&lt;/code&gt; 代表输出&lt;br/&gt;&lt;code&gt;model = Model(inputs=inputs, outputs=predictions)&lt;/code&gt; 该句是函数式模型的经典，可以同时输入两个 &lt;code&gt;input&lt;/code&gt;，然后输出 &lt;code&gt;output&lt;/code&gt;两个。&lt;/p&gt;
&lt;p&gt;下面的时间序列模型，我不懂。。。。。。。。。&lt;/p&gt;
&lt;h4 id=&quot;案例四视频处理&quot;&gt;案例四：视频处理&lt;/h4&gt;
&lt;p&gt;现在用来做迁移学习；&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;15&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;x &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;,))
&lt;span class=&quot;co&quot;&gt;# This works, and returns the 10-way softmax we defined above.&lt;/span&gt;
y &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; model(x)
&lt;span class=&quot;co&quot;&gt;# model里面存着权重，然后输入 x，输出结果，用来作 fine-tuning&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;# 分类 -&amp;gt; 视频、实时处理&lt;/span&gt;
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; TimeDistributed

&lt;span class=&quot;co&quot;&gt;# Input tensor for sequences of 20 timesteps,&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# each containing a 100-dimensional vector&lt;/span&gt;
input_sequences &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;20&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;))
&lt;span class=&quot;co&quot;&gt;# 20个时间间隔，输入 100 维度的数据&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;# This applies our previous model to every timestep in the input sequences.&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# the output of the previous model was a 10-way softmax,&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# so the output of the layer below will be a sequence of 20 vectors of size 10.&lt;/span&gt;
processed_sequences &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; TimeDistributed(model)(input_sequences)  &lt;span class=&quot;co&quot;&gt;# Model是已经训练好的&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;sourceCode&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;processed_sequences&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;tf.Tensor 'time_distributed_1/Reshape_1:0' shape=(?, 20, 100) dtype=float32&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;案例五双输入双模型输出lstm-时序预测&quot;&gt;案例五：双输入、双模型输出：LSTM 时序预测&lt;/h4&gt;
&lt;p&gt;本案例很好，可以了解到 Model 的精髓在于他的任意性，给编译者很多的便利。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;输入：
&lt;ul&gt;&lt;li&gt;新闻语料；新闻语料对应的时间&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;输出：
&lt;ul&gt;&lt;li&gt;新闻语料的预测模型；新闻语料+对应时间的预测模型&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h5 id=&quot;模型一只针对新闻语料的-lstm-模型&quot;&gt;模型一：只针对新闻语料的 LSTM 模型&lt;/h5&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;22&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Input, Embedding, LSTM, Dense
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Model

&lt;span class=&quot;co&quot;&gt;# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# Note that we can name any layer by passing it a &quot;name&quot; argument.&lt;/span&gt;
main_input &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;,), dtype&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'int32'&lt;/span&gt;, name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'main_input'&lt;/span&gt;)
&lt;span class=&quot;co&quot;&gt;# 一个100词的 BOW 序列&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;# This embedding layer will encode the input sequence&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# into a sequence of dense 512-dimensional vectors.&lt;/span&gt;
x &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Embedding(output_dim&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;512&lt;/span&gt;, input_dim&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10000&lt;/span&gt;, input_length&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;)(main_input)
&lt;span class=&quot;co&quot;&gt;# Embedding 层，把 100 维度再 encode 成 512 的句向量，10000 指的是词典单词总数&lt;/span&gt;


&lt;span class=&quot;co&quot;&gt;# A LSTM will transform the vector sequence into a single vector,&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# containing information about the entire sequence&lt;/span&gt;
lstm_out &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; LSTM(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;)(x)
&lt;span class=&quot;co&quot;&gt;# ？ 32什么意思？？？？？？？？？？？？？？？？？？？？？&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;#然后，我们插入一个额外的损失，使得即使在主损失很高的情况下，LSTM 和 Embedding 层也可以平滑的训练。&lt;/span&gt;

auxiliary_output &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'sigmoid'&lt;/span&gt;, name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'aux_output'&lt;/span&gt;)(lstm_out)
&lt;span class=&quot;co&quot;&gt;#再然后，我们将LSTM与额外的输入数据串联起来组成输入，送入模型中：&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# 模型一：只针对以上的序列做的预测模型&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h5 id=&quot;组合模型新闻语料时序&quot;&gt;组合模型：新闻语料+时序&lt;/h5&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;22&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# 模型二：组合模型&lt;/span&gt;
auxiliary_input &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;,), name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'aux_input'&lt;/span&gt;)  &lt;span class=&quot;co&quot;&gt;# 新加入的一个Input,5维度&lt;/span&gt;
x &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; keras.layers.concatenate([lstm_out, auxiliary_input])   &lt;span class=&quot;co&quot;&gt;# 组合起来，对应起来&lt;/span&gt;


&lt;span class=&quot;co&quot;&gt;# We stack a deep densely-connected network on top&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# 组合模型的形式&lt;/span&gt;
x &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;)(x)
x &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;)(x)
x &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;)(x)
&lt;span class=&quot;co&quot;&gt;# And finally we add the main logistic regression layer&lt;/span&gt;
main_output &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'sigmoid'&lt;/span&gt;, name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'main_output'&lt;/span&gt;)(x)


&lt;span class=&quot;co&quot;&gt;#最后，我们定义整个2输入，2输出的模型：&lt;/span&gt;
model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Model(inputs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[main_input, auxiliary_input], outputs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[main_output, auxiliary_output])
&lt;span class=&quot;co&quot;&gt;#模型定义完毕，下一步编译模型。&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#我们给额外的损失赋0.2的权重。我们可以通过关键字参数loss_weights或loss来为不同的输出设置不同的损失函数或权值。&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#这两个参数均可为Python的列表或字典。这里我们给loss传递单个损失函数，这个损失函数会被应用于所有输出上。&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其中：&lt;code&gt;Model(inputs=[main_input, auxiliary_input]&lt;/code&gt;, &lt;code&gt;outputs=[main_output, auxiliary_output])&lt;/code&gt; 是核心，&lt;br/&gt;&lt;code&gt;Input&lt;/code&gt; 两个内容，&lt;code&gt;outputs&lt;/code&gt; 两个模型：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;28&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# 训练方式一：两个模型一个loss&lt;/span&gt;
model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'rmsprop'&lt;/span&gt;, loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'binary_crossentropy'&lt;/span&gt;,
              loss_weights&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;., &lt;span class=&quot;fl&quot;&gt;0.2&lt;/span&gt;])
&lt;span class=&quot;co&quot;&gt;#编译完成后，我们通过传递训练数据和目标值训练该模型：&lt;/span&gt;

model.fit([headline_data, additional_data], [labels, labels],
          epochs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;50&lt;/span&gt;, batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;)

&lt;span class=&quot;co&quot;&gt;# 训练方式二：两个模型,两个Loss&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#因为我们输入和输出是被命名过的（在定义时传递了“name”参数），我们也可以用下面的方式编译和训练模型：&lt;/span&gt;
model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'rmsprop'&lt;/span&gt;,
              loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;{&lt;span class=&quot;st&quot;&gt;'main_output'&lt;/span&gt;: &lt;span class=&quot;st&quot;&gt;'binary_crossentropy'&lt;/span&gt;, &lt;span class=&quot;st&quot;&gt;'aux_output'&lt;/span&gt;: &lt;span class=&quot;st&quot;&gt;'binary_crossentropy'&lt;/span&gt;},
              loss_weights&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;{&lt;span class=&quot;st&quot;&gt;'main_output'&lt;/span&gt;: &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;., &lt;span class=&quot;st&quot;&gt;'aux_output'&lt;/span&gt;: &lt;span class=&quot;fl&quot;&gt;0.2&lt;/span&gt;})

&lt;span class=&quot;co&quot;&gt;# And trained it via:&lt;/span&gt;
model.fit({&lt;span class=&quot;st&quot;&gt;'main_input'&lt;/span&gt;: headline_data, &lt;span class=&quot;st&quot;&gt;'aux_input'&lt;/span&gt;: additional_data},
          {&lt;span class=&quot;st&quot;&gt;'main_output'&lt;/span&gt;: labels, &lt;span class=&quot;st&quot;&gt;'aux_output'&lt;/span&gt;: labels},
          epochs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;50&lt;/span&gt;, batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;因为输入两个，输出两个模型，所以可以分为设置不同的模型训练参数&lt;/p&gt;
&lt;h4 id=&quot;案例六共享层对应关系相似性&quot;&gt;案例六：共享层：对应关系、相似性&lt;/h4&gt;
&lt;p&gt;一个节点，分成两个分支出去&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;25&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; keras
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Input, LSTM, Dense
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Model

tweet_a &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;140&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;256&lt;/span&gt;))
tweet_b &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;140&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;256&lt;/span&gt;))
&lt;span class=&quot;co&quot;&gt;#若要对不同的输入共享同一层，就初始化该层一次，然后多次调用它&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# 140个单词，每个单词256维度，词向量&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# &lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;# This layer can take as input a matrix&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# and will return a vector of size 64&lt;/span&gt;
shared_lstm &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; LSTM(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;)
&lt;span class=&quot;co&quot;&gt;# 返回一个64规模的向量&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;# When we reuse the same layer instance&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# multiple times, the weights of the layer&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# are also being reused&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# (it is effectively *the same* layer)&lt;/span&gt;
encoded_a &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; shared_lstm(tweet_a)
encoded_b &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; shared_lstm(tweet_b)

&lt;span class=&quot;co&quot;&gt;# We can then concatenate the two vectors:&lt;/span&gt;
    &lt;span class=&quot;co&quot;&gt;# 连接两个结果&lt;/span&gt;
    &lt;span class=&quot;co&quot;&gt;# axis=-1？？？？？&lt;/span&gt;
merged_vector &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; keras.layers.concatenate([encoded_a, encoded_b], axis&lt;span class=&quot;op&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)

&lt;span class=&quot;co&quot;&gt;# And add a logistic regression on top&lt;/span&gt;
predictions &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'sigmoid'&lt;/span&gt;)(merged_vector)
&lt;span class=&quot;co&quot;&gt;# 其中的1 代表什么？？？？&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;# We define a trainable model linking the&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# tweet inputs to the predictions&lt;/span&gt;
model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Model(inputs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[tweet_a, tweet_b], outputs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;predictions)

model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'rmsprop'&lt;/span&gt;,
              loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'binary_crossentropy'&lt;/span&gt;,
              metrics&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[&lt;span class=&quot;st&quot;&gt;'accuracy'&lt;/span&gt;])
model.fit([data_a, data_b], labels, epochs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;)
&lt;span class=&quot;co&quot;&gt;# 训练模型，然后预测&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&quot;案例七抽取层节点内容&quot;&gt;案例七：抽取层节点内容&lt;/h4&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;35&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# 1、单节点&lt;/span&gt;
a &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;140&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;256&lt;/span&gt;))
lstm &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; LSTM(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;)
encoded_a &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; lstm(a)
&lt;span class=&quot;cf&quot;&gt;assert&lt;/span&gt; lstm.output &lt;span class=&quot;op&quot;&gt;==&lt;/span&gt; encoded_a
&lt;span class=&quot;co&quot;&gt;# 抽取获得encoded_a的输出张量&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;# 2、多节点&lt;/span&gt;
a &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;140&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;256&lt;/span&gt;))
b &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;140&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;256&lt;/span&gt;))

lstm &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; LSTM(&lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;)
encoded_a &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; lstm(a)
encoded_b &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; lstm(b)

&lt;span class=&quot;cf&quot;&gt;assert&lt;/span&gt; lstm.get_output_at(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;) &lt;span class=&quot;op&quot;&gt;==&lt;/span&gt; encoded_a
&lt;span class=&quot;cf&quot;&gt;assert&lt;/span&gt; lstm.get_output_at(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;) &lt;span class=&quot;op&quot;&gt;==&lt;/span&gt; encoded_b

&lt;span class=&quot;co&quot;&gt;# 3、图像层节点&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# 对于input_shape和output_shape也是一样，如果一个层只有一个节点，&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#或所有的节点都有相同的输入或输出shape，&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#那么input_shape和output_shape都是没有歧义的，并也只返回一个值。&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#但是，例如你把一个相同的Conv2D应用于一个大小为(3,32,32)的数据，&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#然后又将其应用于一个(3,64,64)的数据，那么此时该层就具有了多个输入和输出的shape，&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#你就需要显式的指定节点的下标，来表明你想取的是哪个了&lt;/span&gt;
a &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;))
b &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;))

conv &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Conv2D(&lt;span class=&quot;dv&quot;&gt;16&lt;/span&gt;, (&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;), padding&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'same'&lt;/span&gt;)
conved_a &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; conv(a)

&lt;span class=&quot;co&quot;&gt;# Only one input so far, the following will work:&lt;/span&gt;
&lt;span class=&quot;cf&quot;&gt;assert&lt;/span&gt; conv.input_shape &lt;span class=&quot;op&quot;&gt;==&lt;/span&gt; (&lt;span class=&quot;va&quot;&gt;None&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;)

conved_b &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; conv(b)
&lt;span class=&quot;co&quot;&gt;# now the `.input_shape` property wouldn't work, but this does:&lt;/span&gt;
&lt;span class=&quot;cf&quot;&gt;assert&lt;/span&gt; conv.get_input_shape_at(&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;) &lt;span class=&quot;op&quot;&gt;==&lt;/span&gt; (&lt;span class=&quot;va&quot;&gt;None&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;32&lt;/span&gt;)
&lt;span class=&quot;cf&quot;&gt;assert&lt;/span&gt; conv.get_input_shape_at(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;) &lt;span class=&quot;op&quot;&gt;==&lt;/span&gt; (&lt;span class=&quot;va&quot;&gt;None&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h4 id=&quot;案例八视觉问答模型&quot;&gt;案例八：视觉问答模型&lt;/h4&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;58&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;#这个模型将自然语言的问题和图片分别映射为特征向量，&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;#将二者合并后训练一个logistic回归层，从一系列可能的回答中挑选一个。&lt;/span&gt;
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Conv2D, MaxPooling2D, Flatten
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Input, LSTM, Embedding, Dense
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Model, Sequential

&lt;span class=&quot;co&quot;&gt;# First, let's define a vision model using a Sequential model.&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# This model will encode an image into a vector.&lt;/span&gt;
vision_model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential()
vision_model.add(Conv2D(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, (&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;) activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;, padding&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'same'&lt;/span&gt;, input_shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;224&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;224&lt;/span&gt;)))
vision_model.add(Conv2D(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, (&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;), activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;))
vision_model.add(MaxPooling2D((&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;)))
vision_model.add(Conv2D(&lt;span class=&quot;dv&quot;&gt;128&lt;/span&gt;, (&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;), activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;, padding&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'same'&lt;/span&gt;))
vision_model.add(Conv2D(&lt;span class=&quot;dv&quot;&gt;128&lt;/span&gt;, (&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;), activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;))
vision_model.add(MaxPooling2D((&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;)))
vision_model.add(Conv2D(&lt;span class=&quot;dv&quot;&gt;256&lt;/span&gt;, (&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;), activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;, padding&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'same'&lt;/span&gt;))
vision_model.add(Conv2D(&lt;span class=&quot;dv&quot;&gt;256&lt;/span&gt;, (&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;), activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;))
vision_model.add(Conv2D(&lt;span class=&quot;dv&quot;&gt;256&lt;/span&gt;, (&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;), activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;))
vision_model.add(MaxPooling2D((&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;)))
vision_model.add(Flatten())

&lt;span class=&quot;co&quot;&gt;# Now let's get a tensor with the output of our vision model:&lt;/span&gt;
image_input &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;224&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;224&lt;/span&gt;))
encoded_image &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; vision_model(image_input)

&lt;span class=&quot;co&quot;&gt;# Next, let's define a language model to encode the question into a vector.&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# Each question will be at most 100 word long,&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# and we will index words as integers from 1 to 9999.&lt;/span&gt;
question_input &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;,), dtype&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'int32'&lt;/span&gt;)
embedded_question &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Embedding(input_dim&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10000&lt;/span&gt;, output_dim&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;256&lt;/span&gt;, input_length&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;)(question_input)
encoded_question &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; LSTM(&lt;span class=&quot;dv&quot;&gt;256&lt;/span&gt;)(embedded_question)

&lt;span class=&quot;co&quot;&gt;# Let's concatenate the question vector and the image vector:&lt;/span&gt;
merged &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; keras.layers.concatenate([encoded_question, encoded_image])

&lt;span class=&quot;co&quot;&gt;# And let's train a logistic regression over 1000 words on top:&lt;/span&gt;
output &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;1000&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'softmax'&lt;/span&gt;)(merged)

&lt;span class=&quot;co&quot;&gt;# This is our final model:&lt;/span&gt;
vqa_model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Model(inputs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[image_input, question_input], outputs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;output)

&lt;span class=&quot;co&quot;&gt;# The next stage would be training this model on actual data.&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;延伸一fine-tuning-时如何加载-no_top-的权重&quot;&gt;延伸一：&lt;code&gt;fine-tuning&lt;/code&gt; 时如何加载 &lt;code&gt;No_top&lt;/code&gt; 的权重&lt;/h2&gt;
&lt;p&gt;如果你需要加载权重到不同的网络结构（有些层一样）中，例如 &lt;code&gt;fine-tune&lt;/code&gt; 或 &lt;code&gt;transfer-learning&lt;/code&gt;，你可以通过层名字来加载模型：&lt;br/&gt;&lt;code&gt;model.load_weights(‘my_model_weights.h5’, by_name=True)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;例如：&lt;br/&gt;假如原模型为：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;11&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;    model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential()
    model.add(Dense(&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, input_dim&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&quot;dense_1&quot;&lt;/span&gt;))
    model.add(Dense(&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&quot;dense_2&quot;&lt;/span&gt;))
    ...
    model.save_weights(fname)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;新模型为：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;14&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential()
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, input_dim&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&quot;dense_1&quot;&lt;/span&gt;))  &lt;span class=&quot;co&quot;&gt;# will be loaded&lt;/span&gt;
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&quot;new_dense&quot;&lt;/span&gt;))  &lt;span class=&quot;co&quot;&gt;# will not be loaded&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;# load weights from first model; will only affect the first layer, dense_1.&lt;/span&gt;
model.load_weights(fname, by_name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;hr/&gt;
&lt;hr/&gt;&lt;hr/&gt;
&lt;p&gt;引自：&lt;a href=&quot;http://blog.csdn.net/sinat_26917383/article/details/72857454&quot; class=&quot;uri&quot;&gt;http://blog.csdn.net/sinat_26917383/article/details/72857454&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;keras网络结构&quot;&gt;3.1 keras网络结构&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;http://static.zybuluo.com/xinet/j1pxfsuir0x1hbhtl01bqank/20170604101316305.jpg&quot; alt=&quot;20170604101316305.jpg-330.5kB&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;keras网络配置&quot;&gt;3.2 keras网络配置&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;http://static.zybuluo.com/xinet/xxss3cpw58w4k7up6brkor64/20170604101328219.jpg&quot; alt=&quot;20170604101328219.jpg-214.2kB&quot;/&gt;&lt;br/&gt;其中回调函数 &lt;code&gt;callbacks&lt;/code&gt; 是keras&lt;/p&gt;
&lt;h2 id=&quot;keras预处理功能&quot;&gt;3.3 keras预处理功能&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;http://static.zybuluo.com/xinet/x8v8w0v2c06ja04hq1s9kd4f/20170604101335306.jpg&quot; alt=&quot;20170604101335306.jpg-49.7kB&quot;/&gt;&lt;/p&gt;
&lt;h2 id=&quot;模型的节点信息提取&quot;&gt;3.4 模型的节点信息提取&lt;/h2&gt;
&lt;h3 id=&quot;对于序列模型&quot;&gt;对于序列模型&lt;/h3&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;42&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;op&quot;&gt;%%&lt;/span&gt;time
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; keras
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Sequential 
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Dense 
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; np

&lt;span class=&quot;co&quot;&gt;# 实现 Lenet&lt;/span&gt;
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; keras
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.datasets &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; mnist 
(x_train, y_train), (x_test,y_test) &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; mnist.load_data()

x_train&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;x_train.reshape(&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;28&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;28&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)
x_test&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;x_test.reshape(&lt;span class=&quot;op&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;28&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;28&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)
x_train&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;x_train&lt;span class=&quot;op&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;255&lt;/span&gt;.
x_test&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;x_test&lt;span class=&quot;op&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;255&lt;/span&gt;.
y_train&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;keras.utils.to_categorical(y_train)
y_test&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;keras.utils.to_categorical(y_test)

&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Conv2D, MaxPool2D, Dense, Flatten
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Sequential 
lenet&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;Sequential()
lenet.add(Conv2D(&lt;span class=&quot;dv&quot;&gt;6&lt;/span&gt;, kernel_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;,strides&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, padding&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'same'&lt;/span&gt;, input_shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;28&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;28&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)))
lenet.add(MaxPool2D(pool_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;,strides&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;))
lenet.add(Conv2D(&lt;span class=&quot;dv&quot;&gt;16&lt;/span&gt;, kernel_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;, strides&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, padding&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'valid'&lt;/span&gt;))
lenet.add(MaxPool2D(pool_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, strides&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;))
lenet.add(Flatten())
lenet.add(Dense(&lt;span class=&quot;dv&quot;&gt;120&lt;/span&gt;))
lenet.add(Dense(&lt;span class=&quot;dv&quot;&gt;84&lt;/span&gt;))
lenet.add(Dense(&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'softmax'&lt;/span&gt;))

lenet.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'sgd'&lt;/span&gt;,loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'categorical_crossentropy'&lt;/span&gt;,metrics&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[&lt;span class=&quot;st&quot;&gt;'accuracy'&lt;/span&gt;])    &lt;span class=&quot;co&quot;&gt;# 编译模型&lt;/span&gt;

lenet.fit(x_train,y_train,batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;,epochs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;20&lt;/span&gt;,validation_data&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[x_test,y_test], verbose&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;)  &lt;span class=&quot;co&quot;&gt;# 训练模型&lt;/span&gt;

lenet.save(&lt;span class=&quot;st&quot;&gt;'E:/Graphs/Models/myletnet.h5'&lt;/span&gt;)  &lt;span class=&quot;co&quot;&gt;# 保存模型&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;Wall time: 2min 48s&lt;/code&gt;
&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# 节点信息提取&lt;/span&gt;
config &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; lenet.get_config()  &lt;span class=&quot;co&quot;&gt;# 把 lenet 模型中的信息提取出来&lt;/span&gt;
config[&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;]&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;{'class_name': 'Conv2D',
 'config': {'activation': 'linear',
  'activity_regularizer': None,
  'batch_input_shape': (None, 28, 28, 1),
  'bias_constraint': None,
  'bias_initializer': {'class_name': 'Zeros', 'config': {}},
  'bias_regularizer': None,
  'data_format': 'channels_last',
  'dilation_rate': (1, 1),
  'dtype': 'float32',
  'filters': 6,
  'kernel_constraint': None,
  'kernel_initializer': {'class_name': 'VarianceScaling',
   'config': {'distribution': 'uniform',
    'mode': 'fan_avg',
    'scale': 1.0,
    'seed': None}},
  'kernel_regularizer': None,
  'kernel_size': (3, 3),
  'name': 'conv2d_7',
  'padding': 'same',
  'strides': (1, 1),
  'trainable': True,
  'use_bias': True}}&lt;/code&gt;
&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential.from_config(config)   &lt;span class=&quot;co&quot;&gt;# 将提取的信息传给新的模型， 重构一个新的 Model 模型，fine-tuning 比较好用&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;模型概况查询保存及载入&quot;&gt;3.5 模型概况查询、保存及载入&lt;/h2&gt;
&lt;h3 id=&quot;模型概括打印&quot;&gt;1、模型概括打印&lt;/h3&gt;
&lt;div class=&quot;sourceCode&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model.summary()&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_7 (Conv2D)            (None, 28, 28, 6)         60        
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 14, 14, 6)         0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 10, 10, 16)        2416      
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 5, 5, 16)          0         
_________________________________________________________________
flatten_4 (Flatten)          (None, 400)               0         
_________________________________________________________________
dense_34 (Dense)             (None, 120)               48120     
_________________________________________________________________
dense_35 (Dense)             (None, 84)                10164     
_________________________________________________________________
dense_36 (Dense)             (None, 10)                850       
=================================================================
Total params: 61,610
Trainable params: 61,610
Non-trainable params: 0
_________________________________________________________________&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;权重获取&quot;&gt;2、权重获取&lt;/h3&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model.get_layer(&lt;span class=&quot;st&quot;&gt;'conv2d_7'&lt;/span&gt; )      &lt;span class=&quot;co&quot;&gt;# 依据层名或下标获得层对象&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;&amp;lt;keras.layers.convolutional.Conv2D at 0x1ed425bce10&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;weights &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; model.get_weights()    &lt;span class=&quot;co&quot;&gt;#返回模型权重张量的列表，类型为 numpy array&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model.set_weights(weights)    &lt;span class=&quot;co&quot;&gt;#从 numpy array 里将权重载入给模型，要求数组具有与 model.get_weights() 相同的形状。&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# 查看 model 中 Layer 的信息&lt;/span&gt;
model.layers &lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;[&amp;lt;keras.layers.convolutional.Conv2D at 0x1ed425bce10&amp;gt;,
 &amp;lt;keras.layers.pooling.MaxPooling2D at 0x1ed4267a4a8&amp;gt;,
 &amp;lt;keras.layers.convolutional.Conv2D at 0x1ed4267a898&amp;gt;,
 &amp;lt;keras.layers.pooling.MaxPooling2D at 0x1ed4266bb00&amp;gt;,
 &amp;lt;keras.layers.core.Flatten at 0x1ed4267ebe0&amp;gt;,
 &amp;lt;keras.layers.core.Dense at 0x1ed426774a8&amp;gt;,
 &amp;lt;keras.layers.core.Dense at 0x1ed42684940&amp;gt;,
 &amp;lt;keras.layers.core.Dense at 0x1ed4268edd8&amp;gt;]&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;模型保存与加载&quot;&gt;3.6 模型保存与加载&lt;/h2&gt;
&lt;p&gt;引用：&lt;a href=&quot;http://blog.csdn.net/jiandanjinxin/article/details/77152530&quot;&gt;keras如何保存模型&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;使用 &lt;code&gt;model.save(filepath)&lt;/code&gt; 将 Keras 模型和权重保存在一个 HDF5 文件中，该文件将包含：
&lt;ul&gt;&lt;li&gt;模型的结构(以便重构该模型)&lt;/li&gt;
&lt;li&gt;模型的权重&lt;/li&gt;
&lt;li&gt;训练配置（损失函数，优化器等）&lt;/li&gt;
&lt;li&gt;优化器的状态(以便于从上次训练中断的地方开始)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;keras.models.load_model(filepath)&lt;/code&gt; 来重新实例化你的模型，如果文件中存储了训练配置的话，该函数还会同时完成模型的编译&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;sourceCode&quot; readability=&quot;12&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# 将模型权重保存到指定路径，文件类型是HDF5（后缀是.h5）&lt;/span&gt;
filepath &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'E:/Graphs/Models/lenet.h5'&lt;/span&gt;
model.save_weights(filepath)

&lt;span class=&quot;co&quot;&gt;# 从 HDF5 文件中加载权重到当前模型中, 默认情况下模型的结构将保持不变。&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# 如果想将权重载入不同的模型（有些层相同）中，则设置 by_name=True，只有名字匹配的层才会载入权重&lt;/span&gt;
model.load_weights(filepath, by_name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;False&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;11&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;json_string &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; model.to_json()  &lt;span class=&quot;co&quot;&gt;# 等价于 json_string = model.get_config()  &lt;/span&gt;
&lt;span class=&quot;bu&quot;&gt;open&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'E:/Graphs/Models/lenet.json'&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;'w'&lt;/span&gt;).write(json_string)    
model.save_weights(&lt;span class=&quot;st&quot;&gt;'E:/Graphs/Models/lenet_weights.h5'&lt;/span&gt;)   

&lt;span class=&quot;co&quot;&gt;#加载模型数据和weights  &lt;/span&gt;
model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; model_from_json(&lt;span class=&quot;bu&quot;&gt;open&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'E:/Graphs/Models/lenet.json'&lt;/span&gt;).read())    
model.load_weights(&lt;span class=&quot;st&quot;&gt;'E:/Graphs/Models/lenet_weights.h5'&lt;/span&gt;)     &lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;只保存模型结构而不包含其权重或配置信息&quot;&gt;3.6.1 只保存模型结构,而不包含其权重或配置信息&lt;/h3&gt;
&lt;ul&gt;&lt;li&gt;保存成 &lt;code&gt;json&lt;/code&gt; 格式的文件&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# save as JSON&lt;/span&gt;
json_string &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; model.to_json()  
&lt;span class=&quot;bu&quot;&gt;open&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'E:/Graphs/Models/my_model_architecture.json'&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;'w'&lt;/span&gt;).write(json_string)   
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; model_from_json
model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; model_from_json(&lt;span class=&quot;bu&quot;&gt;open&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'E:/Graphs/Models/my_model_architecture.json'&lt;/span&gt;).read())  &lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ul&gt;&lt;li&gt;保存成 &lt;code&gt;yaml&lt;/code&gt; 文件&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# save as YAML  &lt;/span&gt;
yaml_string &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; model.to_yaml()  
&lt;span class=&quot;bu&quot;&gt;open&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'E:/Graphs/Models/my_model_architectrue.yaml'&lt;/span&gt;,&lt;span class=&quot;st&quot;&gt;'w'&lt;/span&gt;).write(yaml_string)
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; model_from_yaml
model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; model_from_yaml(&lt;span class=&quot;bu&quot;&gt;open&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'E:/Graphs/Models/my_model_architectrue.yaml'&lt;/span&gt;).read())&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这些操作将把模型序列化为json或yaml文件，这些文件对人而言也是友好的，如果需要的话你甚至可以手动打开这些文件并进行编辑。当然，你也可以从保存好的json文件或yaml文件中载入模型&lt;/p&gt;
&lt;h3 id=&quot;实时保存模型结构训练出来的权重及优化器状态并调用&quot;&gt;3.6.2 实时保存模型结构、训练出来的权重、及优化器状态并调用&lt;/h3&gt;
&lt;p&gt;keras 的 &lt;code&gt;callback&lt;/code&gt; 参数可以帮助我们实现在训练过程中的适当时机被调用。实现实时保存训练模型以及训练参数&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;14&quot;&gt;
&lt;pre class=&quot;sourceCode json&quot;&gt;
&lt;code class=&quot;sourceCode json&quot;&gt;&lt;span class=&quot;er&quot;&gt;keras.callbacks.ModelCheckpoint(&lt;/span&gt;
    &lt;span class=&quot;er&quot;&gt;filepath,&lt;/span&gt; 
    &lt;span class=&quot;er&quot;&gt;monitor='val_loss',&lt;/span&gt; 
    &lt;span class=&quot;er&quot;&gt;verbose=0,&lt;/span&gt; 
    &lt;span class=&quot;er&quot;&gt;save_best_only=False,&lt;/span&gt; 
    &lt;span class=&quot;er&quot;&gt;save_weights_only=False,&lt;/span&gt; 
    &lt;span class=&quot;er&quot;&gt;mode='auto',&lt;/span&gt; 
    &lt;span class=&quot;er&quot;&gt;period=1&lt;/span&gt;
&lt;span class=&quot;er&quot;&gt;)&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;ol&gt;&lt;li&gt;&lt;code&gt;filename&lt;/code&gt;：字符串，保存模型的路径&lt;/li&gt;
&lt;li&gt;&lt;code&gt;monitor&lt;/code&gt;：需要监视的值&lt;/li&gt;
&lt;li&gt;verbose：信息展示模式，&lt;code&gt;0&lt;/code&gt; 或 &lt;code&gt;1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;save_best_only：当设置为True时，将只保存在验证集上性能最好的模型&lt;/li&gt;
&lt;li&gt;mode：‘auto’，‘min’，‘max’之一，在save_best_only=True时决定性能最佳模型的评判准则，例如，当监测值为val_acc时，模式应为max，当检测值为val_loss时，模式应为min。在auto模式下，评价准则由被监测值的名字自动推断。&lt;/li&gt;
&lt;li&gt;save_weights_only：若设置为True，则只保存模型权重，否则将保存整个模型（包括模型结构，配置信息等）&lt;/li&gt;
&lt;li&gt;period：CheckPoint之间的间隔的epoch数&lt;/li&gt;
&lt;/ol&gt;&lt;h3 id=&quot;示例&quot;&gt;3.6.3 示例&lt;/h3&gt;
&lt;p&gt;假如原模型为：&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;36&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;x&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;np.array([[&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;],[&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;],[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;],[&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]])
y&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;np.array([&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]).T

model&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;Sequential()
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;,input_shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(x.shape[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;],),activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;, name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'layer1'&lt;/span&gt;))
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;,activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;,name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'layer2'&lt;/span&gt;))
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'sigmoid'&lt;/span&gt;,name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'layer3'&lt;/span&gt;))
model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'sgd'&lt;/span&gt;,loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'mean_squared_error'&lt;/span&gt;)

model.fit(x,y,epochs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;200&lt;/span&gt;, verbose&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;)   &lt;span class=&quot;co&quot;&gt;# 训练&lt;/span&gt;
model.save_weights(&lt;span class=&quot;st&quot;&gt;'E:/Graphs/Models/my_weights.h5'&lt;/span&gt;)
model.predict(x[&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;:&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;])   &lt;span class=&quot;co&quot;&gt;# 预测&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;array([[ 0.38783705]], dtype=float32)&lt;/code&gt;
&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;15&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# 新模型&lt;/span&gt;
model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential()
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, input_dim&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;, name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&quot;layer_1&quot;&lt;/span&gt;))  &lt;span class=&quot;co&quot;&gt;# will be loaded&lt;/span&gt;
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&quot;new_dense&quot;&lt;/span&gt;))  &lt;span class=&quot;co&quot;&gt;# will not be loaded&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;# load weights from first model; will only affect the first layer, dense_1.&lt;/span&gt;
model.load_weights(&lt;span class=&quot;st&quot;&gt;'E:/Graphs/Models/my_weights.h5'&lt;/span&gt;, by_name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;sourceCode&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;model.predict(x[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;:&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;])&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;array([[-0.27631092, -0.35040742, -0.2807056 , -0.22762418, -0.31791407,
        -0.0897391 ,  0.02615392, -0.15040982,  0.19909057, -0.38647971]], dtype=float32)&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;how-to-check-point-deep-learning-models-in-keras&quot;&gt;3.7 How to Check-Point Deep Learning Models in Keras&lt;/h2&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;44&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# Checkpoint the weights when validation accuracy improves&lt;/span&gt;
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Sequential
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Dense
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.callbacks &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; ModelCheckpoint
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; plt
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; np

x&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;np.array([[&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;],[&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;],[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;],[&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]])
y&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;np.array([&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]).T

model&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;Sequential()
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;,input_shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(x.shape[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;],),activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;, name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'layer1'&lt;/span&gt;))
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;,activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;,name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'layer2'&lt;/span&gt;))
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;,activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'sigmoid'&lt;/span&gt;,name&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'layer3'&lt;/span&gt;))
&lt;span class=&quot;co&quot;&gt;# Compile model&lt;/span&gt;
model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'binary_crossentropy'&lt;/span&gt;, optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'adam'&lt;/span&gt;, metrics&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[&lt;span class=&quot;st&quot;&gt;'accuracy'&lt;/span&gt;])

filepath&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&quot;E:/Graphs/Models/weights-improvement-&lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;{epoch:02d}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;{val_acc:.2f}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;.hdf5&quot;&lt;/span&gt;
checkpoint &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; ModelCheckpoint(filepath, monitor&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'val_acc'&lt;/span&gt;, verbose&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, save_best_only&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;, mode&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'max'&lt;/span&gt;)
callbacks_list &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; [checkpoint]
&lt;span class=&quot;co&quot;&gt;# Fit the model&lt;/span&gt;
model.fit(x, y, validation_split&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.33&lt;/span&gt;, epochs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;150&lt;/span&gt;, batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, callbacks&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;callbacks_list, verbose&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;Epoch 00000: val_acc improved from -inf to 1.00000, saving model to E:/Graphs/Models/weights-improvement-00-1.00.hdf5
Epoch 00001: val_acc did not improve
Epoch 00002: val_acc did not improve
Epoch 00003: val_acc did not improve
Epoch 00004: val_acc did not improve
Epoch 00005: val_acc did not improve
Epoch 00006: val_acc did not improve
Epoch 00007: val_acc did not improve
Epoch 00008: val_acc did not improve
Epoch 00009: val_acc did not improve
Epoch 00010: val_acc did not improve
Epoch 00011: val_acc did not improve
Epoch 00012: val_acc did not improve
Epoch 00013: val_acc did not improve
Epoch 00014: val_acc did not improve
Epoch 00015: val_acc did not improve
Epoch 00016: val_acc did not improve
Epoch 00017: val_acc did not improve
Epoch 00018: val_acc did not improve
Epoch 00019: val_acc did not improve
Epoch 00020: val_acc did not improve
Epoch 00021: val_acc did not improve
Epoch 00022: val_acc did not improve
Epoch 00023: val_acc did not improve
Epoch 00024: val_acc did not improve
Epoch 00025: val_acc did not improve
Epoch 00026: val_acc did not improve
Epoch 00027: val_acc did not improve
Epoch 00028: val_acc did not improve
Epoch 00029: val_acc did not improve
Epoch 00030: val_acc did not improve
Epoch 00031: val_acc did not improve
Epoch 00032: val_acc did not improve
Epoch 00033: val_acc did not improve
Epoch 00034: val_acc did not improve
Epoch 00035: val_acc did not improve
Epoch 00036: val_acc did not improve
Epoch 00037: val_acc did not improve
Epoch 00038: val_acc did not improve
Epoch 00039: val_acc did not improve
Epoch 00040: val_acc did not improve
Epoch 00041: val_acc did not improve
Epoch 00042: val_acc did not improve
Epoch 00043: val_acc did not improve
Epoch 00044: val_acc did not improve
Epoch 00045: val_acc did not improve
Epoch 00046: val_acc did not improve
Epoch 00047: val_acc did not improve
Epoch 00048: val_acc did not improve
Epoch 00049: val_acc did not improve
Epoch 00050: val_acc did not improve
Epoch 00051: val_acc did not improve
Epoch 00052: val_acc did not improve
Epoch 00053: val_acc did not improve
Epoch 00054: val_acc did not improve
Epoch 00055: val_acc did not improve
Epoch 00056: val_acc did not improve
Epoch 00057: val_acc did not improve
Epoch 00058: val_acc did not improve
Epoch 00059: val_acc did not improve
Epoch 00060: val_acc did not improve
Epoch 00061: val_acc did not improve
Epoch 00062: val_acc did not improve
Epoch 00063: val_acc did not improve
Epoch 00064: val_acc did not improve
Epoch 00065: val_acc did not improve
Epoch 00066: val_acc did not improve
Epoch 00067: val_acc did not improve
Epoch 00068: val_acc did not improve
Epoch 00069: val_acc did not improve
Epoch 00070: val_acc did not improve
Epoch 00071: val_acc did not improve
Epoch 00072: val_acc did not improve
Epoch 00073: val_acc did not improve
Epoch 00074: val_acc did not improve
Epoch 00075: val_acc did not improve
Epoch 00076: val_acc did not improve
Epoch 00077: val_acc did not improve
Epoch 00078: val_acc did not improve
Epoch 00079: val_acc did not improve
Epoch 00080: val_acc did not improve
Epoch 00081: val_acc did not improve
Epoch 00082: val_acc did not improve
Epoch 00083: val_acc did not improve
Epoch 00084: val_acc did not improve
Epoch 00085: val_acc did not improve
Epoch 00086: val_acc did not improve
Epoch 00087: val_acc did not improve
Epoch 00088: val_acc did not improve
Epoch 00089: val_acc did not improve
Epoch 00090: val_acc did not improve
Epoch 00091: val_acc did not improve
Epoch 00092: val_acc did not improve
Epoch 00093: val_acc did not improve
Epoch 00094: val_acc did not improve
Epoch 00095: val_acc did not improve
Epoch 00096: val_acc did not improve
Epoch 00097: val_acc did not improve
Epoch 00098: val_acc did not improve
Epoch 00099: val_acc did not improve
Epoch 00100: val_acc did not improve
Epoch 00101: val_acc did not improve
Epoch 00102: val_acc did not improve
Epoch 00103: val_acc did not improve
Epoch 00104: val_acc did not improve
Epoch 00105: val_acc did not improve
Epoch 00106: val_acc did not improve
Epoch 00107: val_acc did not improve
Epoch 00108: val_acc did not improve
Epoch 00109: val_acc did not improve
Epoch 00110: val_acc did not improve
Epoch 00111: val_acc did not improve
Epoch 00112: val_acc did not improve
Epoch 00113: val_acc did not improve
Epoch 00114: val_acc did not improve
Epoch 00115: val_acc did not improve
Epoch 00116: val_acc did not improve
Epoch 00117: val_acc did not improve
Epoch 00118: val_acc did not improve
Epoch 00119: val_acc did not improve
Epoch 00120: val_acc did not improve
Epoch 00121: val_acc did not improve
Epoch 00122: val_acc did not improve
Epoch 00123: val_acc did not improve
Epoch 00124: val_acc did not improve
Epoch 00125: val_acc did not improve
Epoch 00126: val_acc did not improve
Epoch 00127: val_acc did not improve
Epoch 00128: val_acc did not improve
Epoch 00129: val_acc did not improve
Epoch 00130: val_acc did not improve
Epoch 00131: val_acc did not improve
Epoch 00132: val_acc did not improve
Epoch 00133: val_acc did not improve
Epoch 00134: val_acc did not improve
Epoch 00135: val_acc did not improve
Epoch 00136: val_acc did not improve
Epoch 00137: val_acc did not improve
Epoch 00138: val_acc did not improve
Epoch 00139: val_acc did not improve
Epoch 00140: val_acc did not improve
Epoch 00141: val_acc did not improve
Epoch 00142: val_acc did not improve
Epoch 00143: val_acc did not improve
Epoch 00144: val_acc did not improve
Epoch 00145: val_acc did not improve
Epoch 00146: val_acc did not improve
Epoch 00147: val_acc did not improve
Epoch 00148: val_acc did not improve
Epoch 00149: val_acc did not improve





&amp;lt;keras.callbacks.History at 0x1ed46f00ac8&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;checkpoint-best-neural-network-model-only&quot;&gt;3.8 Checkpoint Best Neural Network Model Only&lt;/h3&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# Checkpoint the weights for best model on validation accuracy&lt;/span&gt;
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; keras
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Input, Dense
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Model
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.callbacks &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; ModelCheckpoint
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; plt

&lt;span class=&quot;co&quot;&gt;# 层实例接受张量为参数，返回一个张量&lt;/span&gt;
inputs &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;,))

&lt;span class=&quot;co&quot;&gt;# a layer instance is callable on a tensor, and returns a tensor&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# 输入inputs，输出x&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# (inputs)代表输入&lt;/span&gt;
x &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;)(inputs)

x &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;)(x)
&lt;span class=&quot;co&quot;&gt;# 输入x，输出x&lt;/span&gt;
predictions &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'softmax'&lt;/span&gt;)(x)
&lt;span class=&quot;co&quot;&gt;# 输入x，输出分类&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;# This creates a model that includes&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# the Input layer and three Dense layers&lt;/span&gt;
model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Model(inputs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;inputs, outputs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;predictions)
model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'rmsprop'&lt;/span&gt;,
              loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'categorical_crossentropy'&lt;/span&gt;,
              metrics&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[&lt;span class=&quot;st&quot;&gt;'accuracy'&lt;/span&gt;])

&lt;span class=&quot;co&quot;&gt;# Generate dummy data&lt;/span&gt;
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; np
data &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; np.random.random((&lt;span class=&quot;dv&quot;&gt;1000&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;))
labels &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; keras.utils.to_categorical(np.random.randint(&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1000&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)), num_classes&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;)

&lt;span class=&quot;co&quot;&gt;# checkpoint&lt;/span&gt;
filepath&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&quot;E:/Graphs/Models/weights.best.hdf5&quot;&lt;/span&gt;
checkpoint &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; ModelCheckpoint(filepath, monitor&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'val_acc'&lt;/span&gt;, verbose&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, save_best_only&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;, mode&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'max'&lt;/span&gt;)
callbacks_list &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; [checkpoint]
&lt;span class=&quot;co&quot;&gt;# Fit the model&lt;/span&gt;
model.fit(data, labels, validation_split&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;fl&quot;&gt;0.33&lt;/span&gt;, epochs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;15&lt;/span&gt;, batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, callbacks&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;callbacks_list, verbose&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;)&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;Epoch 00000: val_acc improved from -inf to 0.48036, saving model to E:/Graphs/Models/weights.best.hdf5
Epoch 00001: val_acc improved from 0.48036 to 0.51360, saving model to E:/Graphs/Models/weights.best.hdf5
Epoch 00002: val_acc did not improve
Epoch 00003: val_acc did not improve
Epoch 00004: val_acc improved from 0.51360 to 0.52568, saving model to E:/Graphs/Models/weights.best.hdf5
Epoch 00005: val_acc did not improve
Epoch 00006: val_acc improved from 0.52568 to 0.52568, saving model to E:/Graphs/Models/weights.best.hdf5
Epoch 00007: val_acc did not improve
Epoch 00008: val_acc did not improve
Epoch 00009: val_acc did not improve
Epoch 00010: val_acc did not improve
Epoch 00011: val_acc did not improve
Epoch 00012: val_acc did not improve
Epoch 00013: val_acc did not improve
Epoch 00014: val_acc did not improve





&amp;lt;keras.callbacks.History at 0x1a276ec1be0&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;loading-a-check-pointed-neural-network-model&quot;&gt;3.9 Loading a Check-Pointed Neural Network Model&lt;/h3&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;26&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# How to load and use weights from a checkpoint&lt;/span&gt;
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Sequential
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Dense
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.callbacks &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; ModelCheckpoint
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; matplotlib.pyplot &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; plt

&lt;span class=&quot;co&quot;&gt;# create model&lt;/span&gt;
model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Sequential()
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, input_dim&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, kernel_initializer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'uniform'&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;))
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, kernel_initializer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'uniform'&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;))
model.add(Dense(&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;, kernel_initializer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'uniform'&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'sigmoid'&lt;/span&gt;))
&lt;span class=&quot;co&quot;&gt;# load weights&lt;/span&gt;
model.load_weights(&lt;span class=&quot;st&quot;&gt;&quot;E:/Graphs/Models/weights.best.hdf5&quot;&lt;/span&gt;)
&lt;span class=&quot;co&quot;&gt;# Compile model (required to make predictions)&lt;/span&gt;
model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'binary_crossentropy'&lt;/span&gt;, optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'adam'&lt;/span&gt;, metrics&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[&lt;span class=&quot;st&quot;&gt;'accuracy'&lt;/span&gt;])
&lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&quot;Created model and loaded weights from file&quot;&lt;/span&gt;)

&lt;span class=&quot;co&quot;&gt;# Generate dummy data&lt;/span&gt;
&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; numpy &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; np
data &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; np.random.random((&lt;span class=&quot;dv&quot;&gt;1000&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;))
labels &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; keras.utils.to_categorical(np.random.randint(&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;1000&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;)), num_classes&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;)

&lt;span class=&quot;co&quot;&gt;# estimate accuracy on whole dataset using loaded weights&lt;/span&gt;
scores &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; model.evaluate(data, labels, verbose&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;)
&lt;span class=&quot;bu&quot;&gt;print&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;%.2f%%&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;%&lt;/span&gt; (model.metrics_names[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;], scores[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]&lt;span class=&quot;op&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;))&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;Created model and loaded weights from file
acc: 99.00%&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;如何在-keras-中设定-gpu-使用的大小&quot;&gt;3.10 如何在 keras 中设定 GPU 使用的大小&lt;/h2&gt;
&lt;p&gt;本节来源于：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/23250782&quot;&gt;深度学习theano/tensorflow多显卡多人使用问题集&lt;/a&gt;（参见：&lt;a href=&quot;https://github.com/keras-team/keras/issues/1538&quot;&gt;Limit the resource usage for tensorflow backend · Issue #1538 · fchollet/keras · GitHub&lt;/a&gt;）&lt;/p&gt;
&lt;p&gt;在使用 keras 时候会出现总是占满 GPU 显存的情况，可以通过重设 backend 的 GPU 占用情况来进行调节。&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;9&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; tensorflow &lt;span class=&quot;im&quot;&gt;as&lt;/span&gt; tf
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.backend.tensorflow_backend &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; set_session
config &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;fl&quot;&gt;0.3&lt;/span&gt;
set_session(tf.Session(config&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;config))&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;需要注意的是，虽然代码或配置层面设置了对显存占用百分比阈值，但在实际运行中如果达到了这个阈值，程序有需要的话还是会突破这个阈值。换而言之如果跑在一个大数据集上还是会用到更多的显存。以上的显存限制仅仅为了在跑小数据集时避免对显存的浪费而已。&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id=&quot;更科学地训练与保存模型&quot;&gt;更科学地训练与保存模型&lt;/h2&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;17&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.datasets &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; mnist
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Model
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Dense, Activation, Flatten, Input
(x_train, y_train), (x_test, y_test) &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; mnist.load_data()
y_train &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; keras.utils.to_categorical(y_train, &lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;)
y_test &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; keras.utils.to_categorical(y_test, &lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;)
x_train.shape&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;(60000, 28, 28)&lt;/code&gt;
&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;18&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; keras
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.layers &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Input, Dense
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.models &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; Model
&lt;span class=&quot;im&quot;&gt;from&lt;/span&gt; keras.callbacks &lt;span class=&quot;im&quot;&gt;import&lt;/span&gt; ModelCheckpoint

&lt;span class=&quot;co&quot;&gt;# 层实例接受张量为参数，返回一个张量&lt;/span&gt;
inputs &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Input(shape&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;28&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;28&lt;/span&gt;))

x &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Flatten()(inputs)
x &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;)(x)
x &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'relu'&lt;/span&gt;)(x)

predictions &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Dense(&lt;span class=&quot;dv&quot;&gt;10&lt;/span&gt;, activation&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'softmax'&lt;/span&gt;)(x)
&lt;span class=&quot;co&quot;&gt;# 输入x，输出分类&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;# This creates a model that includes&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;# the Input layer and three Dense layers&lt;/span&gt;
model &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; Model(inputs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;inputs, outputs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;predictions)
model.&lt;span class=&quot;bu&quot;&gt;compile&lt;/span&gt;(optimizer&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'rmsprop'&lt;/span&gt;,
              loss&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'categorical_crossentropy'&lt;/span&gt;,
              metrics&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[&lt;span class=&quot;st&quot;&gt;'accuracy'&lt;/span&gt;])

model.summary()&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         (None, 28, 28)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 784)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 64)                50240     
_________________________________________________________________
dense_17 (Dense)             (None, 64)                4160      
_________________________________________________________________
dense_18 (Dense)             (None, 10)                650       
=================================================================
Total params: 55,050
Trainable params: 55,050
Non-trainable params: 0
_________________________________________________________________&lt;/code&gt;
&lt;/pre&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;21&quot;&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;
&lt;code class=&quot;sourceCode python&quot;&gt;filepath &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;'E:/Graphs/Models/model-ep&lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;{epoch:03d}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;-loss&lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;{loss:.3f}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;-val_loss&lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;{val_loss:.3f}&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;.h5'&lt;/span&gt;
checkpoint &lt;span class=&quot;op&quot;&gt;=&lt;/span&gt; ModelCheckpoint(filepath, monitor&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'val_loss'&lt;/span&gt;, verbose&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, save_best_only&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;True&lt;/span&gt;, mode&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;'min'&lt;/span&gt;)
&lt;span class=&quot;co&quot;&gt;# fit model&lt;/span&gt;
model.fit(x_train, y_train, epochs&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;20&lt;/span&gt;, verbose&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;, batch_size&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;dv&quot;&gt;64&lt;/span&gt;, callbacks&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;[checkpoint], validation_data&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;(x_test, y_test))&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;pre&gt;
&lt;code&gt;Train on 60000 samples, validate on 10000 samples
Epoch 1/20
Epoch 00000: val_loss improved from inf to 6.25477, saving model to E:/Graphs/Models/model-ep000-loss6.835-val_loss6.255.h5
10s - loss: 6.8349 - acc: 0.5660 - val_loss: 6.2548 - val_acc: 0.6063
Epoch 2/20
Epoch 00001: val_loss improved from 6.25477 to 5.75301, saving model to E:/Graphs/Models/model-ep001-loss5.981-val_loss5.753.h5
7s - loss: 5.9805 - acc: 0.6246 - val_loss: 5.7530 - val_acc: 0.6395
Epoch 3/20
Epoch 00002: val_loss did not improve
5s - loss: 5.8032 - acc: 0.6368 - val_loss: 5.9562 - val_acc: 0.6270
Epoch 4/20
Epoch 00003: val_loss improved from 5.75301 to 5.69140, saving model to E:/Graphs/Models/model-ep003-loss5.816-val_loss5.691.h5
7s - loss: 5.8163 - acc: 0.6363 - val_loss: 5.6914 - val_acc: 0.6451
Epoch 5/20
Epoch 00004: val_loss did not improve
6s - loss: 5.7578 - acc: 0.6404 - val_loss: 5.8904 - val_acc: 0.6317
Epoch 6/20
Epoch 00005: val_loss did not improve
7s - loss: 5.7435 - acc: 0.6417 - val_loss: 5.8636 - val_acc: 0.6342
Epoch 7/20
Epoch 00006: val_loss improved from 5.69140 to 5.68394, saving model to E:/Graphs/Models/model-ep006-loss5.674-val_loss5.684.h5
7s - loss: 5.6743 - acc: 0.6458 - val_loss: 5.6839 - val_acc: 0.6457
Epoch 8/20
Epoch 00007: val_loss improved from 5.68394 to 5.62847, saving model to E:/Graphs/Models/model-ep007-loss5.655-val_loss5.628.h5
6s - loss: 5.6552 - acc: 0.6472 - val_loss: 5.6285 - val_acc: 0.6488
Epoch 9/20
Epoch 00008: val_loss did not improve
6s - loss: 5.6277 - acc: 0.6493 - val_loss: 5.7295 - val_acc: 0.6422
Epoch 10/20
Epoch 00009: val_loss improved from 5.62847 to 5.55242, saving model to E:/Graphs/Models/model-ep009-loss5.577-val_loss5.552.h5
6s - loss: 5.5769 - acc: 0.6524 - val_loss: 5.5524 - val_acc: 0.6540
Epoch 11/20
Epoch 00010: val_loss improved from 5.55242 to 5.53212, saving model to E:/Graphs/Models/model-ep010-loss5.537-val_loss5.532.h5
6s - loss: 5.5374 - acc: 0.6550 - val_loss: 5.5321 - val_acc: 0.6560
Epoch 12/20
Epoch 00011: val_loss improved from 5.53212 to 5.53056, saving model to E:/Graphs/Models/model-ep011-loss5.549-val_loss5.531.h5
6s - loss: 5.5492 - acc: 0.6543 - val_loss: 5.5306 - val_acc: 0.6553
Epoch 13/20
Epoch 00012: val_loss improved from 5.53056 to 5.48013, saving model to E:/Graphs/Models/model-ep012-loss5.558-val_loss5.480.h5
7s - loss: 5.5579 - acc: 0.6538 - val_loss: 5.4801 - val_acc: 0.6587
Epoch 14/20
Epoch 00013: val_loss did not improve
6s - loss: 5.5490 - acc: 0.6547 - val_loss: 5.5233 - val_acc: 0.6561
Epoch 15/20
Epoch 00014: val_loss did not improve
7s - loss: 5.5563 - acc: 0.6541 - val_loss: 5.4960 - val_acc: 0.6580
Epoch 16/20
Epoch 00015: val_loss did not improve
6s - loss: 5.5364 - acc: 0.6554 - val_loss: 5.5200 - val_acc: 0.6567
Epoch 17/20
Epoch 00016: val_loss did not improve
6s - loss: 5.5081 - acc: 0.6571 - val_loss: 5.5577 - val_acc: 0.6544
Epoch 18/20
Epoch 00017: val_loss did not improve
6s - loss: 5.5281 - acc: 0.6560 - val_loss: 5.5768 - val_acc: 0.6530
Epoch 19/20
Epoch 00018: val_loss did not improve
6s - loss: 5.5146 - acc: 0.6567 - val_loss: 5.7057 - val_acc: 0.6447
Epoch 20/20
Epoch 00019: val_loss improved from 5.48013 to 5.46820, saving model to E:/Graphs/Models/model-ep019-loss5.476-val_loss5.468.h5
7s - loss: 5.4757 - acc: 0.6592 - val_loss: 5.4682 - val_acc: 0.6601





&amp;lt;keras.callbacks.History at 0x25b5ae27630&amp;gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;如果 val_loss 提高了就会保存，没有提高就不会保存。&lt;/p&gt;

</description>
<pubDate>Sun, 07 Jan 2018 02:11:00 +0000</pubDate>
<dc:creator>xinet</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/q735613050/p/8227446.html</dc:identifier>
</item>
</channel>
</rss>