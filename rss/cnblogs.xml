<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>Spark实战（一）SparkStreaming集成Kafka - FrankDeng</title>
<link>http://www.cnblogs.com/frankdeng/p/9308585.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/frankdeng/p/9308585.html</guid>
<description>&lt;h2 id=&quot;spark-streaming-kafka-integration-guide&quot; class=&quot;title&quot;&gt;&lt;span&gt;Spark Streaming + Kafka集成指南&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;Kafka项目在版本0.8和0.10之间引入了一个新的消费者API，因此有两个独立的相应Spark Streaming包可用。&lt;/span&gt;&lt;span&gt;请选择正确的包， &lt;/span&gt;&lt;span&gt;请注意，0.8集成与后来的0.9和0.10代理兼容，但0.10集成与早期的代理不兼容。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：从Spark 2.3.0开始，不推荐使用Kafka 0.8支持。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Spark Streaming从Kafka接收数据，转换为spark streaming中的数据结构Dstream。数据接收方式有&lt;/span&gt;&lt;span&gt;两种 ：1 使用Receiver接收的旧方法：2使用Direct拉取的新方法（在Spark 1.3中引入）。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://spark.apache.org/docs/1.6.3/streaming-kafka-integration.html&quot; target=&quot;_blank&quot;&gt;https://spark.apache.org/docs/1.6.3/streaming-kafka-integration.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://spark.apache.org/docs/2.3.1/streaming-kafka-0-10-integration.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;https://spark.apache.org/docs/2.3.1/streaming-kafka-0-10-integration.html&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;基于receiver的方式&quot;&gt;Receiver方式&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;     Received是使用Kafka高级Consumer API实现的。&lt;/span&gt;&lt;span&gt;与所有接收器一样，&lt;/span&gt;&lt;/span&gt;从Kafka通过Receiver接收的数据存储在Spark Executor的内存中，然后由Spark Streaming启动的job来处理数据。然而默认配置下，这种方式可能会因为底层的失败而丢失数据（请参阅&lt;a href=&quot;https://spark.apache.org/docs/1.4.0/streaming-programming-guide.html#receiver-reliability&quot;&gt;接收器可靠性&lt;/a&gt;）。如果要启用高可靠机制，确保零数据丢失，要启用Spark Streaming的预写日志机制（Write Ahead Log，（已引入）在Spark 1.2）。该机制会同步地将接收到的Kafka数据保存到分布式文件系统（比如HDFS）上的预写日志中，以便底层节点在发生故障时也可以使用预写日志中的数据进行恢复。&lt;/p&gt;
&lt;p&gt;如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1385722/201807/1385722-20180715211535349-1558536234.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;接下来，我们将讨论如何在流应用程序中使用此方法。&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;1 链接 &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;对于使用Maven项目定义的Scala / Java应用程序&lt;/span&gt;&lt;/span&gt;时，我们需要添加相应的依赖包：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&amp;lt;dependency&amp;gt;&amp;lt;!-- Spark Streaming Kafka --&amp;gt;
    &amp;lt;groupId&amp;gt;org.apache.spark&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spark-streaming-kafka_2.&lt;span&gt;10&lt;/span&gt;&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;&lt;span&gt;1.6&lt;/span&gt;.&lt;span&gt;3&lt;/span&gt;&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;2 编程 &lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;在流应用程序代码中，导入&lt;/span&gt;&lt;/span&gt;&lt;code&gt;KafkaUtils&lt;/code&gt;&lt;span&gt;&lt;span&gt;并创建输入DStream，如下所示。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Scala编程：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import org.apache.spark.streaming.kafka._

   val kafkaStream &lt;/span&gt;=&lt;span&gt; KafkaUtils.createStream(streamingContext, 
     [ZK quorum], [consumer group id], [per&lt;/span&gt;-topic number of Kafka partitions to consume])
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Java编程&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
 import org.apache.spark.streaming.kafka.*&lt;span&gt;;

 JavaPairReceiverInputDStream&lt;/span&gt;&amp;lt;String, String&amp;gt; kafkaStream =&lt;span&gt; 
     KafkaUtils.createStream(streamingContext,
     [ZK quorum], [consumer group id], [per&lt;/span&gt;-topic number of Kafka partitions to consume]);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;还有几个需要注意的点：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;Kafka中topic的partition与Spark Streaming中生成的RDD的partition无关，因此，在KafkaUtils.createStream()中，增加某个topic的partition的数量，只会增加单个Receiver消费topic的线程数，也就是读取Kafka中topic partition的线程数量，它不会增加Spark在处理数据时的并行性。&lt;/li&gt;
&lt;li&gt;可以使用不同的consumer group和topic创建多个Kafka输入DStream，以使用多个receiver并行接收数据。&lt;/li&gt;
&lt;li&gt;如果已使用HDFS等复制文件系统启用了“预读日志”，则接收的数据已在日志中复制。因此，输入流的存储级别的存储级别&lt;code&gt;S&lt;span&gt;torageLevel.MEMORY_AND_DISK_SER&lt;/span&gt;&lt;/code&gt;&lt;span&gt;（即，使用&lt;code&gt;KafkaUtils.createStream(..., StorageLevel.MEMORY_AND_DISK_SER)&lt;/code&gt;）。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;3 部署&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;与任何Spark应用程序一样，&lt;/span&gt;&lt;/span&gt;&lt;code&gt;spark-submit&lt;/code&gt;&lt;span&gt;&lt;span&gt;用于启动应用程序。&lt;/span&gt;&lt;span&gt;但是，Scala / Java应用程序和Python应用程序的细节略有不同。&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;对于Scala和Java应用程序，如果您使用SBT或Maven进行项目管理，则将&lt;/span&gt;&lt;code&gt;spark-streaming-kafka_2.10&lt;/code&gt;&lt;span&gt;&lt;span&gt;其及其依赖项&lt;/span&gt;&lt;span&gt;打包&lt;/span&gt;&lt;span&gt;到应用程序JAR中。&lt;/span&gt;&lt;span&gt;确保&lt;/span&gt;&lt;/span&gt;&lt;code&gt;spark-core_2.10&lt;/code&gt;&lt;span&gt;并&lt;/span&gt;&lt;code&gt;spark-streaming_2.10&lt;/code&gt;&lt;span&gt;标记为&lt;/span&gt;&lt;code&gt;provided&lt;/code&gt;&lt;span&gt;&lt;span&gt;Spark安装中已存在的依赖项。&lt;/span&gt;&lt;span&gt;然后使用&lt;/span&gt;&lt;/span&gt;&lt;code&gt;spark-submit&lt;/code&gt;&lt;span&gt;&lt;span&gt;启动应用程序&lt;/span&gt;&lt;/span&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;对于缺少SBT / Maven项目管理的Python应用程序，&lt;/span&gt;&lt;code&gt;spark-streaming-kafka_2.10&lt;/code&gt;&lt;span&gt;可以直接将其依赖项添加到&lt;/span&gt;&lt;code&gt;spark-submit&lt;/code&gt;&lt;span&gt;使用中&lt;/span&gt;&lt;code&gt;--packages&lt;/code&gt;&lt;span&gt;&lt;span&gt;。&lt;/span&gt;&lt;span&gt;那是，&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
 ./bin/spark-submit --packages org.apache.spark:spark-streaming-kafka_2.&lt;span&gt;10&lt;/span&gt;:&lt;span&gt;1.6&lt;/span&gt;.&lt;span&gt;3&lt;/span&gt; ...
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;另外，您也可以下载Maven构件的JAR &lt;/span&gt;&lt;code&gt;spark-streaming-kafka-assembly&lt;/code&gt;&lt;span&gt;从 &lt;/span&gt;&lt;a href=&quot;http://search.maven.org/#search|ga|1|a%3A%22spark-streaming-kafka-assembly_2.10%22%20AND%20v%3A%221.6.3%22&quot;&gt;Maven仓库&lt;/a&gt;&lt;span&gt;，并将其添加到&lt;/span&gt;&lt;code&gt;spark-submit&lt;/code&gt;&lt;span&gt;用&lt;/span&gt;&lt;code&gt;--jars&lt;/code&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;直接读取方式&quot;&gt;Direct方式&lt;/h2&gt;
&lt;p&gt;在spark1.3之后，引入了Direct方式。不同于Receiver的方式，Direct方式没有receiver这一层，其会周期性的获取Kafka中每个topic的每个partition中的最新offsets，之后根据设定的maxRatePerPartition来处理每个batch。其形式如下图：&lt;br/&gt;&lt;img src=&quot;https://images2015.cnblogs.com/blog/524764/201612/524764-20161228154450976-162798485.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;这种方法相较于Receiver方式的优势在于：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;简化的并行&lt;/strong&gt;：在Receiver的方式中我们提到创建多个Receiver之后利用union来合并成一个Dstream的方式提高数据传输并行度。而在Direct方式中，&lt;strong&gt;Kafka中的partition与RDD中的partition是一一对应&lt;/strong&gt;的并行读取Kafka数据，这种映射关系也更利于理解和优化。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;高效&lt;/strong&gt;：在Receiver的方式中，为了达到0数据丢失需要将数据存入Write Ahead Log中，这样在Kafka和日志中就保存了两份数据，浪费！而第二种方式不存在这个问题，只要我们Kafka的数据保留时间足够长，我们都能够从Kafka进行数据恢复。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;精确一次&lt;/strong&gt;：在Receiver的方式中，使用的是Kafka的高阶API接口从Zookeeper中获取offset值，这也是传统的从Kafka中读取数据的方式，但由于Spark Streaming消费的数据和Zookeeper中记录的offset不同步，这种方式偶尔会造成数据重复消费。而第二种方式，直接使用了简单的低阶Kafka API，Offsets则利用Spark Streaming的checkpoints进行记录，消除了这种不一致性。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;span&gt;&lt;span&gt;请注意，此方法的一个缺点是它不会更新Zookeeper中的偏移量，因此基于Zookeeper的Kafka监视工具将不会显示进度。&lt;/span&gt;&lt;span&gt;但是，您可以在每个批处理中访问此方法处理的偏移量，并自行更新Zookeeper。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;接下来，我们将讨论如何在流应用程序中使用此方法。&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;1 链接&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.apache.spark&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;spark-streaming-kafka-&lt;span&gt;0&lt;/span&gt;-10_2.&lt;span&gt;11&lt;/span&gt;&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;&lt;span&gt;2.3&lt;/span&gt;.&lt;span&gt;1&lt;/span&gt;&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;2 编程&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;请注意，导入的命名空间包括版本org.apache.spark.streaming.kafka010&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;&lt;span&gt;Scala编程&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;49&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import org.apache.kafka.clients.consumer.ConsumerRecord
import org.apache.kafka.common.serialization.StringDeserializer
import org.apache.spark.streaming.kafka010._
import org.apache.spark.streaming.kafka010.LocationStrategies.PreferConsistent
import org.apache.spark.streaming.kafka010.ConsumerStrategies.Subscribe

val kafkaParams &lt;/span&gt;=&lt;span&gt; Map[String, Object](
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;bootstrap.servers&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;localhost:9092,anotherhost:9092&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;key.deserializer&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt;&lt;span&gt; classOf[StringDeserializer],
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;value.deserializer&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt;&lt;span&gt; classOf[StringDeserializer],
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;group.id&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;use_a_separate_group_id_for_each_stream&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;auto.offset.reset&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;latest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;enable.auto.commit&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; (&lt;span&gt;false&lt;/span&gt;&lt;span&gt;: java.lang.Boolean)
)

val topics &lt;/span&gt;= Array(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;topicA&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;topicB&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
val stream &lt;/span&gt;=&lt;span&gt; KafkaUtils.createDirectStream[String, String](
  streamingContext,
  PreferConsistent,
  Subscribe[String, String](topics, kafkaParams)
)

stream.map(record &lt;/span&gt;=&amp;gt; (record.key, record.value))
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;codetabs tab-content&quot; readability=&quot;31.553221288515&quot;&gt;
&lt;div id=&quot;tab_scala_0&quot; class=&quot;tab-pane active&quot; data-lang=&quot;scala&quot; readability=&quot;9.7086834733894&quot;&gt;
&lt;p&gt;&lt;span&gt;流中的每个项目都是&lt;/span&gt;&lt;a href=&quot;http://kafka.apache.org/0100/javadoc/org/apache/kafka/clients/consumer/ConsumerRecord.html&quot;&gt;ConsumerRecord&lt;/a&gt;，有关可能的kafkaParams，请参阅&lt;a href=&quot;http://kafka.apache.org/documentation.html#newconsumerconfigs&quot;&gt;Kafka使用者配置文档&lt;/a&gt;。如果Spark批处理持续时间大于默认的Kafka心跳会话超时（30秒），请适当增加heartbeat.interval.ms和session.timeout.ms。对于大于5分钟的批次，这将需要在代理上更改group.max.session.timeout.ms。请注意，该示例将enable.auto.commit设置为false，有关讨论，请参阅&lt;a href=&quot;https://spark.apache.org/docs/2.3.1/streaming-kafka-0-10-integration.html#storing-offsets&quot;&gt;存储偏移&lt;/a&gt;。&lt;/p&gt;
&lt;h3&gt;3 Direct方式案例&lt;/h3&gt;
&lt;div class=&quot;cnblogs_code&quot; onclick=&quot;cnblogs_code_show('9ddfd338-b05a-40a8-875a-05dc6cf169b7')&quot; readability=&quot;43&quot;&gt;&lt;img id=&quot;code_img_closed_9ddfd338-b05a-40a8-875a-05dc6cf169b7&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_9ddfd338-b05a-40a8-875a-05dc6cf169b7&quot; class=&quot;code_img_opened&quot; onclick=&quot;cnblogs_code_hide('9ddfd338-b05a-40a8-875a-05dc6cf169b7',event)&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_9ddfd338-b05a-40a8-875a-05dc6cf169b7&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;81&quot;&gt;
&lt;pre&gt;
&lt;span&gt;package bigdata.spark
 
import kafka.serializer.{StringDecoder, Decoder}
import org.apache.spark.streaming.kafka.KafkaUtils
import org.apache.spark.streaming.{Seconds, StreamingContext}
import org.apache.spark.{SparkContext, SparkConf}
 
import scala.reflect.ClassTag
 
&lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt;*
  * Created by Administrator on 2017/4/28.
  &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;
&lt;span&gt;object&lt;/span&gt;&lt;span&gt; SparkStreamDemo {
  def main(args: Array[String]) {
 
    val conf &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; SparkConf()
    conf.setAppName(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;spark_streaming&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    conf.setMaster(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;local[*]&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
 
    val sc &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; SparkContext(conf)
    sc.setCheckpointDir(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;D:/checkpoints&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    sc.setLogLevel(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ERROR&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
 
    val ssc &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt; StreamingContext(sc, Seconds(&lt;span&gt;5&lt;/span&gt;&lt;span&gt;))
 
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; val topics = Map(&quot;spark&quot; -&amp;gt; 2)&lt;/span&gt;
&lt;span&gt; 
    val kafkaParams &lt;/span&gt;=&lt;span&gt; Map[String, String](
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;bootstrap.servers&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;m1:9092,m2:9092,m3:9092&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;group.id&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;spark&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
      &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;auto.offset.reset&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;smallest&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
    )
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 直连方式拉取数据，这种方式不会修改数据的偏移量，需要手动的更新&lt;/span&gt;
    val lines =  KafkaUtils.createDirectStream[String, String, StringDecoder, StringDecoder](ssc, kafkaParams, Set(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;spark&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)).map(_._2)
    &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; val lines = KafkaUtils.createStream(ssc, &quot;m1:2181,m2:2181,m3:2181&quot;, &quot;spark&quot;, topics).map(_._2)&lt;/span&gt;
&lt;span&gt; 
    val ds1 &lt;/span&gt;= lines.flatMap(_.split(&lt;span&gt;&quot;&lt;/span&gt; &lt;span&gt;&quot;&lt;/span&gt;)).map((_, &lt;span&gt;1&lt;/span&gt;&lt;span&gt;))
 
    val ds2 &lt;/span&gt;= ds1.updateStateByKey[Int]((x:Seq[Int], y:Option[Int]) =&amp;gt;&lt;span&gt; {
      Some(x.sum &lt;/span&gt;+ y.getOrElse(&lt;span&gt;0&lt;/span&gt;&lt;span&gt;))
    })
 
    ds2.print()
 
    ssc.start()
    ssc.awaitTermination()
 
  }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&quot;spark向kafka中写入数据&quot;&gt;Spark向kafka中写入数据&lt;/h2&gt;
&lt;p&gt;上文阐述了Spark如何从Kafka中流式的读取数据，下面我整理向Kafka中写数据。与读数据不同，Spark并没有提供统一的接口用于写入Kafka，所以我们需要使用底层Kafka接口进行包装。&lt;br/&gt;最直接的做法我们可以想到如下这种方式：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;43&quot;&gt;
&lt;pre&gt;
input.foreachRDD(rdd =&amp;gt;
  &lt;span&gt;//&lt;/span&gt;&lt;span&gt; 不能在这里创建KafkaProducer&lt;/span&gt;
  rdd.foreachPartition(partition =&amp;gt;&lt;span&gt;
    partition.&lt;/span&gt;&lt;span&gt;foreach&lt;/span&gt;&lt;span&gt;{
      &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; x:String=&amp;gt;&lt;span&gt;{
        val props &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; HashMap[String, Object]()
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokers)
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
          &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;org.apache.kafka.common.serialization.StringSerializer&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
          &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;org.apache.kafka.common.serialization.StringSerializer&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
        println(x)
        val producer &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; KafkaProducer[String,String](props)
        val message&lt;/span&gt;=&lt;span&gt;new&lt;/span&gt; ProducerRecord[String, String](&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;output&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,&lt;span&gt;null&lt;/span&gt;&lt;span&gt;,x)
        producer.send(message)
      }
    }
  )
) &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;但是这种方式缺点很明显，对于每个partition的每条记录，我们都需要创建KafkaProducer，然后利用producer进行输出操作，注意这里我们并不能将KafkaProducer的新建任务放在foreachPartition外边，因为KafkaProducer是不可序列化的（not serializable）。显然这种做法是不灵活且低效的，因为每条记录都需要建立一次连接。如何解决呢？&lt;/p&gt;
&lt;p&gt;1.首先，我们需要将KafkaProducer利用lazy val的方式进行包装如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;55&quot;&gt;
&lt;pre&gt;
&lt;span&gt;import java.util.concurrent.Future
import org.apache.kafka.clients.producer.{ KafkaProducer, ProducerRecord, RecordMetadata }
&lt;/span&gt;&lt;span&gt;class&lt;/span&gt; KafkaSink[K, V](createProducer: () =&amp;gt;&lt;span&gt; KafkaProducer[K, V]) extends Serializable {
  &lt;/span&gt;&lt;span&gt;/*&lt;/span&gt;&lt;span&gt; This is the key idea that allows us to work around running into
     NotSerializableExceptions. &lt;/span&gt;&lt;span&gt;*/&lt;/span&gt;&lt;span&gt;
  lazy val producer &lt;/span&gt;=&lt;span&gt; createProducer()
  def send(topic: String, key: K, value: V): Future[RecordMetadata] &lt;/span&gt;=&lt;span&gt;
    producer.send(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; ProducerRecord[K, V](topic, key, value))
  def send(topic: String, value: V): Future[RecordMetadata] &lt;/span&gt;=&lt;span&gt;
    producer.send(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; ProducerRecord[K, V](topic, value))
}

&lt;/span&gt;&lt;span&gt;object&lt;/span&gt;&lt;span&gt; KafkaSink {
  import scala.collection.JavaConversions._
  def apply[K, V](config: Map[String, Object]): KafkaSink[K, V] &lt;/span&gt;=&lt;span&gt; {
    val createProducerFunc &lt;/span&gt;= () =&amp;gt;&lt;span&gt; {
      val producer &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; KafkaProducer[K, V](config)
      sys.addShutdownHook {
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; Ensure that, on executor JVM shutdown, the Kafka producer sends
        &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; any buffered messages to Kafka before shutting down.&lt;/span&gt;
&lt;span&gt;        producer.close()
      }
      producer
    }
    &lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; KafkaSink(createProducerFunc)
  }
  def apply[K, V](config: java.util.Properties): KafkaSink[K, V] &lt;/span&gt;=&lt;span&gt; apply(config.toMap)
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;2.之后我们利用广播变量的形式，将KafkaProducer广播到每一个executor，如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;40&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 广播KafkaSink&lt;/span&gt;
val kafkaProducer: Broadcast[KafkaSink[String, String]] =&lt;span&gt; {
  val kafkaProducerConfig &lt;/span&gt;=&lt;span&gt; {
    val p &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Properties()
    p.setProperty(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;bootstrap.servers&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, Conf.brokers)
    p.setProperty(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;key.serializer&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, classOf[StringSerializer].getName)
    p.setProperty(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;value.serializer&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;, classOf[StringSerializer].getName)
    p
  }
  log.warn(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;kafka producer init done!&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
  ssc.sparkContext.broadcast(KafkaSink[String, String](kafkaProducerConfig))
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这样我们就能在每个executor中愉快的将数据输入到kafka当中：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt;输出到kafka&lt;/span&gt;
segmentedStream.foreachRDD(rdd =&amp;gt;&lt;span&gt; {
  &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;rdd.isEmpty) {
    rdd.&lt;/span&gt;&lt;span&gt;foreach&lt;/span&gt;(record =&amp;gt;&lt;span&gt; {
      kafkaProducer.value.send(Conf.outTopics, record._1.toString, record._2)
      &lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; do something else&lt;/span&gt;
&lt;span&gt;    })
  }
})&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;spark-streamingkafka应用&quot;&gt;Spark streaming+Kafka应用&lt;/h2&gt;
&lt;p&gt;一般Spark Streaming进行流式处理，首先利用上文我们阐述的Direct方式从Kafka拉取batch，之后经过分词、统计等相关处理，回写到DB上（一般为Hbase或者Mysql），由此高效实时的完成每天大量数据的词频统计任务。&lt;/p&gt;
&lt;h2 id=&quot;spark-streamingkafka调优&quot;&gt;Spark streaming+Kafka调优&lt;/h2&gt;
&lt;p&gt;Spark streaming+Kafka的使用中，当数据量较小，很多时候默认配置和使用便能够满足情况，但是当数据量大的时候，就需要进行一定的调整和优化，而这种调整和优化本身也是不同的场景需要不同的配置。&lt;/p&gt;
&lt;h3 id=&quot;合理的批处理时间batchduration&quot;&gt;1 合理的批处理时间（batchDuration）&lt;/h3&gt;
&lt;p&gt;几乎所有的Spark Streaming调优文档都会提及批处理时间的调整，在StreamingContext初始化的时候，有一个参数便是批处理时间的设定。如果这个值设置的过短，即个batchDuration所产生的Job并不能在这期间完成处理，那么就会造成数据不断堆积，最终导致Spark Streaming发生阻塞。而且，一般对于batchDuration的设置不会小于500ms，因为过小会导致SparkStreaming频繁的提交作业，对整个streaming造成额外的负担。在平时的应用中，根据不同的应用场景和硬件配置，我设在1~10s之间，我们可以根据SparkStreaming的可视化监控界面，观察Total Delay来进行batchDuration的调整，如下图：&lt;br/&gt;&lt;img src=&quot;https://images2015.cnblogs.com/blog/524764/201701/524764-20170103171142066-1054088549.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;合理的kafka拉取量maxrateperpartition重要&quot;&gt;2 合理的Kafka拉取量（maxRatePerPartition重要）&lt;/h3&gt;
&lt;p&gt;对于Spark Streaming消费kafka中数据的应用场景，这个配置是非常关键的，配置参数为：spark.streaming.kafka.maxRatePerPartition。这个参数默认是没有上线的，即kafka当中有多少数据它就会直接全部拉出。而根据生产者写入Kafka的速率以及消费者本身处理数据的速度，同时这个参数需要结合上面的batchDuration，使得每个partition拉取在每个batchDuration期间拉取的数据能够顺利的处理完毕，做到尽可能高的吞吐量，而这个参数的调整可以参考可视化监控界面中的Input Rate和Processing Time，如下图：&lt;br/&gt;&lt;img src=&quot;https://images2015.cnblogs.com/blog/524764/201701/524764-20170103172311159-1621531817.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://images2015.cnblogs.com/blog/524764/201701/524764-20170103172338941-153218465.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;缓存反复使用的dstreamrdd&quot;&gt;3 缓存反复使用的Dstream（RDD）&lt;/h3&gt;
&lt;p&gt;Spark中的RDD和SparkStreaming中的Dstream，如果被反复的使用，最好利用cache()，将该数据流缓存起来，防止过度的调度资源造成的网络开销。可以参考观察Scheduling Delay参数，如下图：&lt;br/&gt;&lt;img src=&quot;https://images2015.cnblogs.com/blog/524764/201701/524764-20170103185139331-147812384.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h3 id=&quot;设置合理的gc&quot;&gt;4 设置合理的GC&lt;/h3&gt;
&lt;p&gt;长期使用Java的小伙伴都知道，JVM中的垃圾回收机制，可以让我们不过多的关注与内存的分配回收，更加专注于业务逻辑，JVM都会为我们搞定。对JVM有些了解的小伙伴应该知道，在Java虚拟机中，将内存分为了初生代（eden generation）、年轻代（young generation）、老年代（old generation）以及永久代（permanent generation），其中每次GC都是需要耗费一定时间的，尤其是老年代的GC回收，需要对内存碎片进行整理，通常采用标记-清楚的做法。同样的在Spark程序中，JVM GC的频率和时间也是影响整个Spark效率的关键因素。在通常的使用中建议：&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;hljs cpp&quot;&gt;--conf &lt;span class=&quot;hljs-string&quot;&gt;&quot;spark.executor.extraJavaOptions=-XX:+UseConcMarkSweepGC&quot;&lt;/span&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;设置合理的cpu资源数&quot;&gt;5 设置合理的CPU资源数&lt;/h3&gt;
&lt;p&gt;CPU的core数量，每个executor可以占用一个或多个core，可以通过观察CPU的使用率变化来了解计算资源的使用情况，例如，很常见的一种浪费是一个executor占用了多个core，但是总的CPU使用率却不高（因为一个executor并不总能充分利用多核的能力），这个时候可以考虑让么个executor占用更少的core，同时worker下面增加更多的executor，或者一台host上面增加更多的worker来增加并行执行的executor的数量，从而增加CPU利用率。但是增加executor的时候需要考虑好内存消耗，因为一台机器的内存分配给越多的executor，每个executor的内存就越小，以致出现过多的数据spill over甚至out of memory的情况。&lt;/p&gt;
&lt;h3 id=&quot;设置合理的parallelism&quot;&gt;6 设置合理的parallelism&lt;/h3&gt;
&lt;p&gt;partition和parallelism，partition指的就是数据分片的数量，每一次task只能处理一个partition的数据，这个值太小了会导致每片数据量太大，导致内存压力，或者诸多executor的计算能力无法利用充分；但是如果太大了则会导致分片太多，执行效率降低。在执行action类型操作的时候（比如各种reduce操作），partition的数量会选择parent RDD中最大的那一个。而parallelism则指的是在RDD进行reduce类操作的时候，默认返回数据的paritition数量（而在进行map类操作的时候，partition数量通常取自parent RDD中较大的一个，而且也不会涉及shuffle，因此这个parallelism的参数没有影响）。所以说，这两个概念密切相关，都是涉及到数据分片的，作用方式其实是统一的。通过spark.default.parallelism可以设置默认的分片数量，而很多RDD的操作都可以指定一个partition参数来显式控制具体的分片数量。&lt;br/&gt;在SparkStreaming+kafka的使用中，我们采用了Direct连接方式，前文阐述过Spark中的partition和Kafka中的Partition是一一对应的，我们一般默认设置为Kafka中Partition的数量。&lt;/p&gt;
&lt;h3 id=&quot;使用高性能的算子&quot;&gt;7 使用高性能的算子&lt;/h3&gt;
&lt;p&gt;这里参考了美团技术团队的博文，并没有做过具体的性能测试，其建议如下：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;使用reduceByKey/aggregateByKey替代groupByKey&lt;/li&gt;
&lt;li&gt;使用mapPartitions替代普通map&lt;/li&gt;
&lt;li&gt;使用foreachPartitions替代foreach&lt;/li&gt;
&lt;li&gt;使用filter之后进行coalesce操作&lt;/li&gt;
&lt;li&gt;使用repartitionAndSortWithinPartitions替代repartition与sort类操作&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;使用kryo优化序列化性能&quot;&gt;8 使用Kryo优化序列化性能&lt;/h3&gt;
&lt;p&gt;这个优化原则我本身也没有经过测试，但是好多优化文档有提到，这里也记录下来。&lt;br/&gt;在Spark中，主要有三个地方涉及到了序列化：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;在算子函数中使用到外部变量时，该变量会被序列化后进行网络传输（见“原则七：广播大变量”中的讲解）。&lt;/li&gt;
&lt;li&gt;将自定义的类型作为RDD的泛型类型时（比如JavaRDD，Student是自定义类型），所有自定义类型对象，都会进行序列化。因此这种情况下，也要求自定义的类必须实现Serializable接口。&lt;/li&gt;
&lt;li&gt;使用可序列化的持久化策略时（比如MEMORY_ONLY_SER），Spark会将RDD中的每个partition都序列化成一个大的字节数组。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;对于这三种出现序列化的地方，我们都可以通过使用Kryo序列化类库，来优化序列化和反序列化的性能。Spark默认使用的是Java的序列化机制，也就是ObjectOutputStream/ObjectInputStream API来进行序列化和反序列化。但是Spark同时支持使用Kryo序列化库，Kryo序列化类库的性能比Java序列化类库的性能要高很多。官方介绍，Kryo序列化机制比Java序列化机制，性能高10倍左右。Spark之所以默认没有使用Kryo作为序列化类库，是因为Kryo要求最好要注册所有需要进行序列化的自定义类型，因此对于开发者来说，这种方式比较麻烦。&lt;/p&gt;
&lt;p&gt;以下是使用Kryo的代码示例，我们只要设置序列化类，再注册要序列化的自定义类型即可（比如算子函数中使用到的外部变量类型、作为RDD泛型类型的自定义类型等）：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 创建SparkConf对象。&lt;/span&gt;
val conf = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; SparkConf().setMaster(...).setAppName(...)
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 设置序列化器为KryoSerializer。&lt;/span&gt;
conf.&lt;span&gt;set&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;spark.serializer&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;org.apache.spark.serializer.KryoSerializer&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt; 注册要序列化的自定义类型。&lt;/span&gt;
conf.registerKryoClasses(Array(classOf[MyClass1], classOf[MyClass2]))
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;结果&quot;&gt;结果&lt;/h3&gt;
&lt;p&gt;经过种种调试优化，我们最终要达到的目的是，Spark Streaming能够实时的拉取Kafka当中的数据，并且能够保持稳定，如下图所示：&lt;br/&gt;&lt;img src=&quot;https://images2015.cnblogs.com/blog/524764/201701/524764-20170103174522644-1161173395.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;当然不同的应用场景会有不同的图形，这是本文词频统计优化稳定后的监控图，我们可以看到Processing Time这一柱形图中有一Stable的虚线，而大多数Batch都能够在这一虚线下处理完毕，说明整体Spark Streaming是运行稳定的。&lt;/p&gt;
</description>
<pubDate>Sun, 15 Jul 2018 15:49:00 +0000</pubDate>
<dc:creator>FrankDeng</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/frankdeng/p/9308585.html</dc:identifier>
</item>
<item>
<title>Python爬虫之用脚本登录Github并查看信息 - 张丶耀庆</title>
<link>http://www.cnblogs.com/littlesky1124/p/9315617.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/littlesky1124/p/9315617.html</guid>
<description>&lt;h3&gt;前言分析目标网站的登录方式&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;　　目标地址：&lt;/strong&gt;&lt;/span&gt;&lt;strong&gt;https://github.com/login    &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　登录方式做出分析：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　　　　　第一，用form表单方式提交信息，&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　　　　　第二，有csrf_token,&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　　　　　第三 ，是以post请求发送用户名和密码时，需要第一次get请求的cookie&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　　　　　第四，登录成功以后，请求其他页面是只需要带第一次登录成功以后返回的cookie就可以。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;　　&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;以get发送的请求获取我们想要的token和cookie&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1367493/201807/1367493-20180715225935275-119889209.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt; &lt;img src=&quot;https://images2018.cnblogs.com/blog/1367493/201807/1367493-20180715225943882-1167738032.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;代码：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;38&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
import requests   
from bs4 import BeautifulSoup

r1 = requests.get('https://github.com/login')

soup = BeautifulSoup(r1.text,features='lxml')  #生成soup 对象

s1 = soup.find(name='input',attrs={'name':'authenticity_token'}).get('value')  
#查到我们要的token

r1_cookies = r1.cookies.get_dict()  # 下次提交用户名时用的cookie


# print(r1_cookies)   

# print(s1)


#结果：：

{'logged_in': 'no', '_gh_sess': 'VDFWa2hJWjFMb1hpRUFLRDVhUmc3MXg1Tk02TDhsUnhDMERuNGpyT2Y4STlQZ2xCV1lCZEFhK21wdFR1bkpGYUV0WEJzcDEydWFzcm93&lt;br/&gt;aVc4Nk91Q2JicmtRV0NIQ0lRSWM4aFhrSVFYbCtCczBwdnhVN0YySVJJNUFpQnhyTzNuRkJwNDJZUWxUcEk2M2JkM3VSMDdXVHNOY1htQkthckJQZDJyUVR2RzBNUkU3VnltRVF2U&lt;br/&gt;m1admU3c3YzSGlyVnVZVm0ycnA1eUhET1JRVWNLN0pSbndKWjljMGttNG5URWJ1eU8rQjZXNEMxVEthcGVObDFBY2gvc2ZzWXcvWWZab29wQWJyU0l6cmZscWhBQUlzYTA3dTRtb&lt;br/&gt;3l1S0hDYytHY2V1SUhEWlZvVlZoSWZpTzBjNmlidFF2dzI2bWgtLTJON1lqbm5jWUtSYmtiVEM1clJPakE9PQ%3D%3D--897dbc36c123940c8eae5d86f276dead8318fd6c'}
pRz0wapEbu5shksGCeSN0FijWoU9ALw8EPUsXlqgcw1Ezirl0VbSKvkTYqIe8VhxhPH2H/uzGaV6XX+yjTGoVA==&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt;获取这两个值就可以，进行下一步发送登录请求：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;&lt;span&gt;第二步post方式提交用户名密码&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1367493/201807/1367493-20180715231911532-109904705.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;


&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1367493/201807/1367493-20180715231918979-1149765884.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;span&gt; 代码：：&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;42&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
这个代码接着上面的get请求，只是post请求的部分，

r2 = requests.post(
    'https://github.com/session',
    data ={
        'commit':'Sign in',
        'utf8':'✓',
        'authenticity_token':s1,
        'login':'541756569@qq.com',
        'password':'用户名密码'                  # 填上正确的用户名即可
    },
    cookies = r1.cookies.get_dict(),       # 这里需要第一次的cookie
)

print(r2.cookies.get_dict())      # 这个是成功以后的cookie
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt; &lt;span&gt;成功以后就返回登录页面的信息。&lt;/span&gt;&lt;/p&gt;

&lt;h3&gt;基于post登录成功后查看个人详情页。&lt;/h3&gt;
&lt;p&gt;　这里只需要带着登录成功以后的cookie 就可以&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;45&quot;&gt;
&lt;pre class=&quot;brush:python;gutter:true;&quot;&gt;
  #完整代码


import requests
from bs4 import BeautifulSoup

r1 = requests.get('https://github.com/login')

soup = BeautifulSoup(r1.text,features='lxml')

s1 = soup.find(name='input',attrs={'name':'authenticity_token'}).get('value')
r1_cookies = r1.cookies.get_dict()
print(r1_cookies)
print(s1)


r2 = requests.post(
    'https://github.com/session',
    data ={
        'commit':'Sign in',
        'utf8':'✓',
        'authenticity_token':s1,
        'login':'541756569@qq.com',
        'password':'密码'
    },
    cookies = r1.cookies.get_dict(),
)


查看个人详情页


print(r2.cookies.get_dict())

 r3 = requests.get(
       'https://github.com/13131052183/product',   #查看个人的详情页
        cookies = r2.cookies.get_dict()

 )

 print(r3.text)
&lt;/pre&gt;&lt;/div&gt;


</description>
<pubDate>Sun, 15 Jul 2018 15:33:00 +0000</pubDate>
<dc:creator>张丶耀庆</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/littlesky1124/p/9315617.html</dc:identifier>
</item>
<item>
<title>day32_Hibernate学习笔记_04 - 黑泽明军</title>
<link>http://www.cnblogs.com/chenmingjun/p/9315610.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/chenmingjun/p/9315610.html</guid>
<description>&lt;h2 id=&quot;hhbernate_log4j&quot;&gt;&lt;span&gt;&lt;strong&gt;一、Hbernate中的日志框架_整合log4j(了解)&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;Hibernate 利用 Simple Logging Facade for Java (SLF4J)&lt;br/&gt;来记录不同系统事件的日志。SLF4J 可以根据你选择的绑定把日志输出到几个日志框架（NOP、Simple、log4j version&lt;br/&gt;1.2、JDK 1.4 logging、JCL 或 logback）上。&lt;/li&gt;
&lt;li&gt;slf4j 核心jar：slf4j-api-1.6.1.jar 。slf4j 是日志框架，将其他优秀的日志第三方进行了整合。&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/01.png&quot; alt=&quot;&quot;/&gt;&lt;/li&gt;
&lt;li&gt;整合导入jar包，添加至构建路径&lt;br/&gt;  1、log4j 核心包：log4j-1.2.17.jar&lt;br/&gt;  2、过渡jar（整合jar）：slf4j-log4j12-1.7.5.jar&lt;/li&gt;
&lt;li&gt;导入配置文件，该文件在 &lt;strong&gt;\hibernate-distribution-3.6.10.Final\project\etc&lt;/strong&gt; 中，拷贝至项目的src 目录下&lt;br/&gt;  log4j.properties，此配置文件配置log4j 如何输出日志。&lt;/li&gt;
&lt;li&gt;编写配置文件内容：&lt;br/&gt;  1、记录器&lt;br/&gt;  2、输出源&lt;br/&gt;  3、布局&lt;/li&gt;
&lt;li&gt;记录器：&lt;br/&gt;  例如：log4j.rootLogger=info, stdout, file&lt;br/&gt;  格式：log4j.rootLogger=日志级别, 输出源1, 输出源2, ……&lt;br/&gt;  log4j 日志级别：fatal 致命错误、error 错误、warn 警告、info 信息、debug 调试信息、trace 堆栈信息 （&lt;strong&gt;输出信息多少：日志信息量逐渐增加&lt;/strong&gt;），&lt;span&gt;项目上线时用error&lt;/span&gt;，&lt;span&gt;项目开发中用info&lt;/span&gt;。&lt;/li&gt;
&lt;li&gt;输出源：&lt;br/&gt;  例如：log4j.appender.file=org.apache.log4j.FileAppender&lt;br/&gt;  格式：log4j.appender.输出源的名称=输出源的实现类&lt;br/&gt;    输出源的名称：自定义&lt;br/&gt;    输出源的实现类：log4j提供&lt;br/&gt;  输出源的属性，例如：log4j.appender.file.File=d:\mylog.log&lt;br/&gt;  输出源的属性格式：log4j.appender.名称.属性=值&lt;br/&gt;  每一个输出源对应一个实现类，实现类都是属性（setter），底层执行setter方法进行赋值。&lt;/li&gt;
&lt;li&gt;常见的输出源实现类：&lt;br/&gt;  org.apache.log4j.FileAppender 输出文件中&lt;br/&gt;    file，表示文件输出位置&lt;br/&gt;  org.apache.log4j.ConsoleAppender 输出到控制台&lt;br/&gt;    Target，表示使用哪种输出方式，在控制台打印内容，取值：System.out / System.err&lt;/li&gt;
&lt;li&gt;布局 =&amp;gt; 确定输出格式&lt;br/&gt;  例如：log4j.appender.stdout.layout=org.apache.log4j.PatternLayout&lt;br/&gt;  格式：log4j.appender.数据源.layout=org.apache.log4j.PatternLayout&lt;br/&gt;  布局属性：log4j.appender. 数据源.layout.ConversionPattern=值&lt;br/&gt;    例如1：log4j.appender.stdout.layout.ConversionPattern=&lt;strong&gt;&lt;code&gt;%d{ABSOLUTE} %5p %c{1}:%L - %m%n&lt;/code&gt;&lt;/strong&gt;&lt;br/&gt;    输出为：21:57:26,197 INFO SessionFactoryImpl:927 - closing&lt;br/&gt;    例如2：log4j.appender.logfile.layout.ConversionPattern=&lt;strong&gt;&lt;code&gt;%d %p [%c] - %m%n&lt;/code&gt;&lt;/strong&gt;&lt;br/&gt;    输出为：closing&lt;/li&gt;
&lt;li&gt;扩展：对指定的目录设置日志级别&lt;br/&gt;  例如：log4j.logger.org.hibernate.transaction=debug&lt;br/&gt;  格式：log4j.logger.包结构=级别&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;hhibernate&quot;&gt;&lt;span&gt;&lt;strong&gt;二、Hibernate的关联关系映射（一对一）（了解）&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;情况1：主表的主键，与从表的外键（唯一），形成主外键关系。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;情况2：主表的主键，与从表的主键，形成主外键关系 （从表的主键又是外键，即主键同步）-- &lt;strong&gt;推荐使用该方式&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;如下图所示：&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/02_%E4%B8%80%E5%AF%B9%E4%B8%80%E5%85%B3%E7%B3%BB.png&quot; alt=&quot;&quot;/&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;h211&quot;&gt;&lt;span&gt;&lt;strong&gt;2.1、情况1示例&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Company.hbm.xml&lt;/p&gt;
&lt;pre readability=&quot;8&quot;&gt;
&lt;code class=&quot;hljs xml&quot; readability=&quot;10&quot;&gt;&lt;span class=&quot;hljs-meta&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&lt;/span&gt;&lt;p&gt;&lt;span class=&quot;hljs-meta&quot;&gt;&amp;lt;!DOCTYPE hibernate-mapping PUBLIC &lt;br/&gt;&quot;-//Hibernate/Hibernate Mapping DTD 3.0//EN&quot;&lt;br/&gt;&quot;http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd&quot;&amp;gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;hibernate-mapping&lt;/span&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;package&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;com.itheima.domain&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;Company&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;table&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;t_company&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;cid&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;column&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;cid&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;generator&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;native&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;generator&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;id&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;property&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;cname&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;column&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;cname&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;type&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;string&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;one-to-one&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;address&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;Address&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;property-ref&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;company&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;one-to-one&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;class&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;hibernate-mapping&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Address.hbm.xml&lt;/p&gt;
&lt;pre readability=&quot;8&quot;&gt;
&lt;code class=&quot;hljs xml&quot; readability=&quot;10&quot;&gt;&lt;span class=&quot;hljs-meta&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&lt;/span&gt;&lt;p&gt;&lt;span class=&quot;hljs-meta&quot;&gt;&amp;lt;!DOCTYPE hibernate-mapping PUBLIC &lt;br/&gt;&quot;-//Hibernate/Hibernate Mapping DTD 3.0//EN&quot;&lt;br/&gt;&quot;http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd&quot;&amp;gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;hibernate-mapping&lt;/span&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;package&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;com.itheima.domain&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;Address&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;table&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;t_address&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;aid&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;column&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;aid&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;generator&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;native&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;generator&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;id&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;property&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;aname&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;column&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;aname&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;type&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;string&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;many-to-one&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;company&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;Company&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;column&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;company_id&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;unique&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;true&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;many-to-one&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;class&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;hibernate-mapping&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试代码如下：&lt;/p&gt;
&lt;pre readability=&quot;15&quot;&gt;
&lt;code class=&quot;hljs java&quot; readability=&quot;24&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;package&lt;/span&gt; com.itheima.a_one2one;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; org.hibernate.Session;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; org.junit.Test;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; com.itheima.domain.Address;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; com.itheima.domain.Company;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; com.itheima.utils.HibernateUtils;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Demo1&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@Test&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;fun1&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;Session session = HibernateUtils.openSession();&lt;br/&gt;session.beginTransaction();&lt;/p&gt;&lt;p&gt;Company c = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; Company();&lt;br/&gt;c.setCname(&lt;span class=&quot;hljs-string&quot;&gt;&quot;传智播客&quot;&lt;/span&gt;);&lt;/p&gt;&lt;p&gt;Address a = &lt;span class=&quot;hljs-keyword&quot;&gt;new&lt;/span&gt; Address();&lt;br/&gt;a.setAname(&lt;span class=&quot;hljs-string&quot;&gt;&quot;北京市朝阳区平房乡红门村28号&quot;&lt;/span&gt;);&lt;/p&gt;&lt;p&gt;&lt;br/&gt;a.setCompany(c); &lt;/p&gt;&lt;p&gt;session.save(c);&lt;br/&gt;session.save(a);&lt;/p&gt;&lt;p&gt;session.getTransaction().commit();&lt;br/&gt;session.close();&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@Test&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;fun2&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;Session session = HibernateUtils.openSession();&lt;br/&gt;session.beginTransaction();&lt;/p&gt;&lt;p&gt;Company c = (Company) session.get(Company.class, &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;);&lt;br/&gt;System.out.println(c);&lt;/p&gt;&lt;p&gt;session.getTransaction().commit();&lt;br/&gt;session.close();&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h3 id=&quot;h222&quot;&gt;&lt;span&gt;&lt;strong&gt;2.2、情况2示例&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Company.hbm.xml&lt;/p&gt;
&lt;pre readability=&quot;7.5&quot;&gt;
&lt;code class=&quot;hljs xml&quot; readability=&quot;9&quot;&gt;&lt;span class=&quot;hljs-meta&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&lt;/span&gt;&lt;p&gt;&lt;span class=&quot;hljs-meta&quot;&gt;&amp;lt;!DOCTYPE hibernate-mapping PUBLIC &lt;br/&gt;&quot;-//Hibernate/Hibernate Mapping DTD 3.0//EN&quot;&lt;br/&gt;&quot;http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd&quot;&amp;gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;hibernate-mapping&lt;/span&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;package&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;com.itheima.domain&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;Company&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;table&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;t_company&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;cid&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;column&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;cid&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;generator&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;native&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;generator&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;id&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;property&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;cname&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;column&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;cname&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;type&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;string&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;one-to-one&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;address&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;Address&quot;&lt;/span&gt; &amp;gt;&lt;/span&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;one-to-one&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;class&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;hibernate-mapping&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;Address.hbm.xml&lt;/p&gt;
&lt;pre readability=&quot;8&quot;&gt;
&lt;code class=&quot;hljs xml&quot; readability=&quot;10&quot;&gt;&lt;span class=&quot;hljs-meta&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&lt;/span&gt;&lt;p&gt;&lt;span class=&quot;hljs-meta&quot;&gt;&amp;lt;!DOCTYPE hibernate-mapping PUBLIC &lt;br/&gt;&quot;-//Hibernate/Hibernate Mapping DTD 3.0//EN&quot;&lt;br/&gt;&quot;http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd&quot;&amp;gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;hibernate-mapping&lt;/span&gt;  &lt;span class=&quot;hljs-attr&quot;&gt;package&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;com.itheima.domain&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;Address&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;table&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;t_address&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;aid&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;column&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;aid&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;generator&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;foreign&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;param&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;property&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;company&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;param&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;generator&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;id&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;property&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;aname&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;column&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;aname&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;type&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;string&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;one-to-one&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;name&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;company&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;class&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;Company&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;constrained&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;true&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;one-to-one&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;class&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;hibernate-mapping&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;测试代码同上：&lt;/p&gt;
&lt;h2 id=&quot;h&quot;&gt;&lt;span&gt;&lt;strong&gt;三、二级缓存【掌握】&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
&lt;h3 id=&quot;h31&quot;&gt;&lt;span&gt;&lt;strong&gt;3.1、介绍&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;h4 id=&quot;h311&quot;&gt;&lt;span&gt;&lt;strong&gt;3.1.1、缓存&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;  缓存(Cache)：是计算机领域非常通用的概念。它介&lt;strong&gt;于应用程序&lt;/strong&gt;和&lt;strong&gt;永久性数据存储源&lt;/strong&gt;（如硬盘上的文件或者数据库）之间，其作用是&lt;strong&gt;&lt;code&gt;降低应用程序直接读写硬盘&lt;/code&gt;&lt;/strong&gt;（永久性数据存储源）的频率，从而提高应用的运行&lt;strong&gt;&lt;code&gt;性能&lt;/code&gt;&lt;/strong&gt;。缓存中的数据是数据存储源中数据的拷贝。缓存的物理介质通常是&lt;strong&gt;&lt;code&gt;内存&lt;/code&gt;&lt;/strong&gt;。&lt;br/&gt;  缓存：程序 &amp;lt;-- （内存） --&amp;gt; 硬盘&lt;/p&gt;
&lt;h4 id=&quot;h312&quot;&gt;&lt;span&gt;&lt;strong&gt;3.1.2、什么是二级缓存？&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;Hibernate 提供缓存机制：一级缓存、二级缓存。&lt;br/&gt;&lt;strong&gt;&lt;code&gt;一级缓存&lt;/code&gt;&lt;/strong&gt;：Session 级别缓存，在一次请求中共享数据。（当前有多少个线程连接到数据库，就会有多少个一级缓存。）&lt;br/&gt;&lt;strong&gt;&lt;code&gt;二级缓存&lt;/code&gt;&lt;/strong&gt;：SessionFactory 级别缓存，整个应用程序共享一个会话工厂，共享一个二级缓存。（二级缓存中存放的是经常使用的、不经常被修改的数据。）&lt;/li&gt;
&lt;li&gt;SessionFactory的缓存两部分：&lt;br/&gt;&lt;strong&gt;&lt;code&gt;内置缓存&lt;/code&gt;&lt;/strong&gt;：使用一个Map，用于存放&lt;strong&gt;&lt;code&gt;配置信息&lt;/code&gt;&lt;/strong&gt;，如预定义的HQL语句等，提供给Hibernate框架自己使用，对外只读。不能操作。&lt;br/&gt;&lt;strong&gt;&lt;code&gt;外置缓存&lt;/code&gt;&lt;/strong&gt;：使用另一个Map，用于存放&lt;strong&gt;&lt;code&gt;用户自定义数据&lt;/code&gt;&lt;/strong&gt;。默认不开启。对于外置缓存，Hibernate只提供规范（接口），需要第三方实现类，所以我们使用二级缓存，还得导入第三方的jar包。外置缓存又称为二级缓存。&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;h313&quot;&gt;&lt;span&gt;&lt;strong&gt;3.1.3、二级缓存的内部结构&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;二级缓存就是由4部分构成：&lt;br/&gt;  类级别缓存&lt;br/&gt;  集合级别缓存&lt;br/&gt;  时间戳缓存&lt;br/&gt;  &lt;strong&gt;查询级别缓存(二级缓存的第2大部分:三级缓存)&lt;/strong&gt;&lt;br/&gt;内部结构如下所示：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/03.png&quot; alt=&quot;&quot;/&gt;&lt;h4 id=&quot;h314&quot;&gt;&lt;span&gt;&lt;strong&gt;3.1.4、并发访问策略&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;访问策略：读写型（read-write）、只读型（read-only）&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/04.png&quot; alt=&quot;&quot;/&gt;&lt;h4 id=&quot;h315&quot;&gt;&lt;span&gt;&lt;strong&gt;3.1.5、应用场景&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;适合放入二级缓存中的数据：&lt;br/&gt;很少被修改&lt;br/&gt;不是很重要的数据，允许出现偶尔的并发问题&lt;/li&gt;
&lt;li&gt;不适合放入二级缓存中的数据：&lt;br/&gt;经常被修改&lt;br/&gt;财务数据，绝对不允许出现并发问题&lt;br/&gt;与其他应用数据共享的数据&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;h316&quot;&gt;&lt;span&gt;&lt;strong&gt;3.1.6、二级缓存提供商（即实现了二级缓存接口的厂商）&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;EHCache&lt;/strong&gt;：可作为进程（单机）范围内的缓存，存放数据的物理介质可以是内存或硬盘，对 Hibernate 的查询缓存提供了支持。且&lt;strong&gt;支持集群&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;span&gt;OpenSymphony：可作为进程范围内的缓存，存放数据的物理介质可以是内存或硬盘。提供了丰富的缓存数据过期策略，对 Hibernate 的查询缓存提供了支持。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;SwarmCache：可作为集群范围内的缓存，但不支持 Hibernate 的查询缓存。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;JBoss Cache：可作为集群范围内的缓存，支持 Hibernate 的查询缓存。&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/05.png&quot; alt=&quot;&quot;/&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3 id=&quot;h32&quot;&gt;&lt;span&gt;&lt;strong&gt;3.2、配置&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;  配置即操作：亦即使用二级缓存提供商的提供的jar。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;1、导入jar包并添加至构建路径：ehcache-1.5.0.jar(核心包)、commons-logging.jar(依赖包)、backport-util-concurrent.jar(依赖包)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;2、开启二级缓存（我要使用二级缓存）&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;3、确定二级缓存提供商（我要使用哪个二级缓存）&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;4、确定需要缓存内容&lt;br/&gt;  (1)配置需要缓存的类&lt;br/&gt;  (2)配置需要缓存的集合&lt;/li&gt;
&lt;li&gt;&lt;span&gt;5、配置ehcache的自定义配置文件&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;h321jar&quot;&gt;&lt;span&gt;&lt;strong&gt;3.2.1、导入jar包并添加至构建路径&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/06.png&quot; alt=&quot;&quot;/&gt;&lt;h4 id=&quot;h322&quot;&gt;&lt;span&gt;&lt;strong&gt;3.2.2、开启二级缓存（我要使用二级缓存）&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;　　先在 hibernate.properties 中找到对应的键和值：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/07.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;　　再在 hibernate.cfg.xml 中配置开启二级缓存：&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/08.png&quot; alt=&quot;&quot;/&gt;&lt;h4 id=&quot;h323&quot;&gt;&lt;span&gt;&lt;strong&gt;3.2.3、确定二级缓存提供商(我要使用哪个二级缓存)&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;　　先在 hibernate.properties 中找到对应的键和值：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/09.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;　　再在 hibernate.cfg.xml 中配置确定二级缓存提供商：&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/10.png&quot; alt=&quot;&quot;/&gt;&lt;h4 id=&quot;h324&quot;&gt;&lt;span&gt;&lt;strong&gt;3.2.4、确定缓存内容&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;　　在 hibernate.cfg.xml 中确定 &lt;code&gt;类级别缓存&lt;/code&gt; 和 &lt;code&gt;集合级别缓存&lt;/code&gt; 配置项：&lt;br/&gt;　　先确定这两个缓存所在配置文件中的位置：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/11.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;　　具体配置：&lt;br/&gt;&lt;img title=&quot;、&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/12.png&quot; alt=&quot;、&quot;/&gt;&lt;br/&gt;&lt;h4 id=&quot;h325ehcache&quot;&gt;&lt;span&gt;&lt;strong&gt;3.2.5、ehcache配置文件&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;步骤1：从jar包复制 &lt;code&gt;ehcache-failsafe.xml&lt;/code&gt; 文件&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/13.png&quot; alt=&quot;&quot;/&gt;&lt;/li&gt;
&lt;li&gt;步骤2：将 &lt;code&gt;ehcache-failsafe.xml&lt;/code&gt; 重命名 &lt;code&gt;ehcache.xml&lt;/code&gt;&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/14.png&quot; alt=&quot;&quot;/&gt;&lt;/li&gt;
&lt;li&gt;步骤3：将修改后的 &lt;code&gt;ehcache.xml&lt;/code&gt;，拷贝到src下&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/15.png&quot; alt=&quot;&quot;/&gt;&lt;/li&gt;
&lt;li&gt;步骤4：删除掉 &lt;code&gt;ehcache.xml&lt;/code&gt; 文件中无用的注释，得到清爽的 &lt;code&gt;ehcache.xml&lt;/code&gt; 文件，文件内容如下：&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;ehcache.xml&lt;/p&gt;
&lt;pre&gt;
&lt;code class=&quot;xml language-xml hljs&quot;&gt; &lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;ehcache&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;xmlns:xsi&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;xsi:noNamespaceSchemaLocation&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;../config/ehcache.xsd&quot;&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;diskStore&lt;/span&gt; &lt;span class=&quot;hljs-attr&quot;&gt;path&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;java.io.tmpdir&quot;&lt;/span&gt;/&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;&lt;span class=&quot;hljs-name&quot;&gt;defaultCache&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-attr&quot;&gt;maxElementsInMemory&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;10000&quot;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-attr&quot;&gt;eternal&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;false&quot;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-attr&quot;&gt;timeToIdleSeconds&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;120&quot;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-attr&quot;&gt;timeToLiveSeconds&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;120&quot;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-attr&quot;&gt;overflowToDisk&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-attr&quot;&gt;maxElementsOnDisk&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;10000000&quot;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-attr&quot;&gt;diskPersistent&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;false&quot;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-attr&quot;&gt;diskExpiryThreadIntervalSeconds&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;120&quot;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-attr&quot;&gt;memoryStoreEvictionPolicy&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;LRU&quot;&lt;/span&gt;&lt;br/&gt;/&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-tag&quot;&gt;&amp;lt;/&lt;span class=&quot;hljs-name&quot;&gt;ehcache&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;br/&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;　　一般，该文件的配置不是我们的工作，我们使用默认的配置即可，如果想配置，请看下文的 &lt;code&gt;3.4、ehcache配置文件详解&lt;/code&gt; 。&lt;/p&gt;
&lt;h3 id=&quot;h33&quot;&gt;&lt;span&gt;&lt;strong&gt;3.3、演示&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;h4 id=&quot;h331&quot;&gt;&lt;span&gt;&lt;strong&gt;3.3.1、证明二级缓存存在&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;　　示例代码如下：见类缓存中的示例代码&lt;/p&gt;
&lt;h4 id=&quot;h332&quot;&gt;&lt;span&gt;&lt;strong&gt;3.3.2、类缓存&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;类缓存：只存放数据&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;一级缓存：存放对象本身&lt;br/&gt;如下图所示：&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/16.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;示例代码如下：&lt;/li&gt;
&lt;/ul&gt;&lt;pre readability=&quot;11&quot;&gt;
&lt;code class=&quot;hljs kotlin&quot; readability=&quot;16&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;package&lt;/span&gt; com.itheima.a_one2one;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; org.hibernate.Session;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; org.junit.Test;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; com.itheima.domain.Customer;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; com.itheima.utils.HibernateUtils;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Demo1&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@Test&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; void fun1() {&lt;br/&gt;Session session = HibernateUtils.openSession();&lt;br/&gt;session.beginTransaction();&lt;/p&gt;&lt;p&gt;&lt;br/&gt;Customer c1 = (Customer) session.&lt;span class=&quot;hljs-keyword&quot;&gt;get&lt;/span&gt;(Customer.&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt;, &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;); &lt;br/&gt;session.clear(); &lt;br/&gt;Customer c2 = (Customer) session.&lt;span class=&quot;hljs-keyword&quot;&gt;get&lt;/span&gt;(Customer.&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt;, &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;); &lt;/p&gt;&lt;p&gt;&lt;br/&gt;System.&lt;span class=&quot;hljs-keyword&quot;&gt;out&lt;/span&gt;.println(c1 == c2); &lt;br/&gt;&lt;/p&gt;&lt;p&gt;session.getTransaction().commit();&lt;br/&gt;session.close();&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;h333&quot;&gt;&lt;span&gt;&lt;strong&gt;3.3.3、集合缓存&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;　　如下图所示：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/17.png&quot; alt=&quot;&quot;/&gt;&lt;p&gt;&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/18.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;　　示例代码如下：
&lt;/p&gt;&lt;pre readability=&quot;13&quot;&gt;
&lt;code class=&quot;hljs kotlin&quot; readability=&quot;20&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;package&lt;/span&gt; com.itheima.a_one2one;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; java.util.Iterator;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; org.hibernate.Session;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; org.junit.Test;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; com.itheima.domain.Customer;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; com.itheima.domain.Order;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; com.itheima.utils.HibernateUtils;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Demo2&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@Test&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; void fun1() {&lt;br/&gt;Session session = HibernateUtils.openSession();&lt;br/&gt;session.beginTransaction();&lt;/p&gt;&lt;p&gt;Customer c1 = (Customer) session.&lt;span class=&quot;hljs-keyword&quot;&gt;get&lt;/span&gt;(Customer.&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt;, &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;); &lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;for&lt;/span&gt; (Order o : c1.getOrders()) { &lt;br/&gt;System.&lt;span class=&quot;hljs-keyword&quot;&gt;out&lt;/span&gt;.println(o.getOname());&lt;br/&gt;}&lt;/p&gt;&lt;p&gt;session.clear(); &lt;/p&gt;&lt;p&gt;&lt;br/&gt;Customer c2 = (Customer) session.&lt;span class=&quot;hljs-keyword&quot;&gt;get&lt;/span&gt;(Customer.&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt;, &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;); &lt;br/&gt;Iterator&amp;lt;Order&amp;gt; it = c2.getOrders().iterator(); &lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;while&lt;/span&gt; (it.hasNext()) {&lt;br/&gt;Order o = it.next();&lt;br/&gt;System.&lt;span class=&quot;hljs-keyword&quot;&gt;out&lt;/span&gt;.println(o.getOname());&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;p&gt;session.getTransaction().commit();&lt;br/&gt;session.close();&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;h334&quot;&gt;&lt;span&gt;&lt;strong&gt;3.3.4、查询缓存&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;查询缓存又称为三级缓存（民间叫法）&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span&gt;查询缓存默认不使用。需要手动开启。&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;查询缓存：将HQL语句与查询结果进行绑定。通过HQL相同语句可以缓存内容。&lt;br/&gt;默认情况Query对象只将查询结果存放在一级和二级缓存中，不从一级或二级缓存中获取。&lt;br/&gt;查询缓存就是让Query可以从二级缓存中获得内容。&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;步骤一：开启查询缓存&lt;br/&gt;　　先在 hibernate.properties 中找到对应的键和值：&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/19.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;　　再在 hibernate.cfg.xml 中配置开启查询缓存：&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/20.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;步骤二：在查询query对象时，需要设置缓存内容（&lt;code&gt;注意：存放和查询 都需要设置&lt;/code&gt;）&lt;br/&gt;&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/21.png&quot; alt=&quot;&quot;/&gt;&lt;br/&gt;　　示例代码如下：
&lt;pre readability=&quot;11&quot;&gt;
&lt;code class=&quot;hljs cpp&quot; readability=&quot;16&quot;&gt;package com.itheima.a_one2one;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; java.util.List;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; org.hibernate.Query;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; org.hibernate.Session;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; org.junit.Test;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; com.itheima.domain.Customer;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; com.itheima.utils.HibernateUtils;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Demo3&lt;/span&gt; {&lt;/span&gt;&lt;br/&gt;@SuppressWarnings({ &lt;span class=&quot;hljs-string&quot;&gt;&quot;unused&quot;&lt;/span&gt;, &lt;span class=&quot;hljs-string&quot;&gt;&quot;unchecked&quot;&lt;/span&gt; })&lt;br/&gt;@Test&lt;br/&gt;&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;fun1&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;Session session = HibernateUtils.openSession();&lt;br/&gt;session.beginTransaction();&lt;/p&gt;&lt;p&gt;Query query = session.createQuery(&lt;span class=&quot;hljs-string&quot;&gt;&quot;from Customer&quot;&lt;/span&gt;);&lt;br/&gt;query.setCacheable(&lt;span class=&quot;hljs-literal&quot;&gt;true&lt;/span&gt;); &lt;br/&gt;List&amp;lt;Customer&amp;gt; &lt;span class=&quot;hljs-built_in&quot;&gt;list&lt;/span&gt; = query.&lt;span class=&quot;hljs-built_in&quot;&gt;list&lt;/span&gt;(); &lt;/p&gt;&lt;p&gt;session.clear(); &lt;/p&gt;&lt;p&gt;Query query2 = session.createQuery(&lt;span class=&quot;hljs-string&quot;&gt;&quot;select c from Customer c&quot;&lt;/span&gt;);&lt;br/&gt;query2.setCacheable(&lt;span class=&quot;hljs-literal&quot;&gt;true&lt;/span&gt;);&lt;br/&gt;List&amp;lt;Customer&amp;gt; list2 = query2.&lt;span class=&quot;hljs-built_in&quot;&gt;list&lt;/span&gt;(); &lt;/p&gt;&lt;p&gt;session.getTransaction().commit();&lt;br/&gt;session.close();&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h4 id=&quot;h335&quot;&gt;&lt;span&gt;&lt;strong&gt;3.3.5、时间戳缓存&lt;/strong&gt;&lt;/span&gt;&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;&lt;span&gt;时间戳：任何操作都在时间戳中记录操作时间。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;　　示例代码如下：&lt;/p&gt;
&lt;pre readability=&quot;11.5&quot;&gt;
&lt;code class=&quot;hljs kotlin&quot; readability=&quot;17&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;package&lt;/span&gt; com.itheima.a_one2one;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; org.hibernate.Session;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; org.junit.Test;&lt;/p&gt;&lt;p&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; com.itheima.domain.Customer;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;import&lt;/span&gt; com.itheima.utils.HibernateUtils;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-class&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;Demo4&lt;/span&gt; &lt;/span&gt;{&lt;br/&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@SuppressWarnings(&lt;span class=&quot;hljs-meta-string&quot;&gt;&quot;unused&quot;&lt;/span&gt;)&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-meta&quot;&gt;@Test&lt;/span&gt;&lt;br/&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; void fun1() {&lt;br/&gt;Session session = HibernateUtils.openSession();&lt;br/&gt;session.beginTransaction();&lt;/p&gt;&lt;p&gt;Customer c1 = (Customer) session.&lt;span class=&quot;hljs-keyword&quot;&gt;get&lt;/span&gt;(Customer.&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt;, &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;); &lt;br/&gt;session.createQuery(&lt;span class=&quot;hljs-string&quot;&gt;&quot;update Customer set cname=:cname where cid =:cid&quot;&lt;/span&gt;).setString(&lt;span class=&quot;hljs-string&quot;&gt;&quot;cname&quot;&lt;/span&gt;, &lt;span class=&quot;hljs-string&quot;&gt;&quot;rose&quot;&lt;/span&gt;).setInteger(&lt;span class=&quot;hljs-string&quot;&gt;&quot;cid&quot;&lt;/span&gt;, &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;).executeUpdate(); &lt;br/&gt;session.clear(); &lt;br/&gt;Customer c2 = (Customer) session.&lt;span class=&quot;hljs-keyword&quot;&gt;get&lt;/span&gt;(Customer.&lt;span class=&quot;hljs-keyword&quot;&gt;class&lt;/span&gt;, &lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;); &lt;/p&gt;&lt;p&gt;session.getTransaction().commit();&lt;br/&gt;session.close();&lt;br/&gt;}&lt;br/&gt;}&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;　　&lt;span&gt;&lt;strong&gt;二级缓存中类缓存、集合缓存、查询缓存、时间戳缓存的总结图：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;img title=&quot;&quot; src=&quot;http://pbwya9suz.bkt.clouddn.com/23.png&quot; alt=&quot;&quot;/&gt;&lt;h3 id=&quot;h34ehcache&quot;&gt;&lt;span&gt;&lt;strong&gt;3.4、ehcache配置文件详解&lt;/strong&gt;&lt;/span&gt;&lt;/h3&gt;
&lt;pre readability=&quot;11&quot;&gt;
&lt;code class=&quot;hljs lua&quot; readability=&quot;16&quot;&gt;&amp;lt;ehcache xmlns:xsi=&lt;span class=&quot;hljs-string&quot;&gt;&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&lt;/span&gt; xsi:noNamespaceSchemaLocation=&lt;span class=&quot;hljs-string&quot;&gt;&quot;../config/ehcache.xsd&quot;&lt;/span&gt;&amp;gt;&lt;br/&gt;&amp;lt;diskStore &lt;span class=&quot;hljs-built_in&quot;&gt;path&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;java.io.tmpdir&quot;&lt;/span&gt;/&amp;gt;&lt;br/&gt;&amp;lt;defaultCache&lt;br/&gt;maxElementsInMemory=&lt;span class=&quot;hljs-string&quot;&gt;&quot;10000&quot;&lt;/span&gt;&lt;br/&gt;eternal=&lt;span class=&quot;hljs-string&quot;&gt;&quot;false&quot;&lt;/span&gt;&lt;br/&gt;timeToIdleSeconds=&lt;span class=&quot;hljs-string&quot;&gt;&quot;120&quot;&lt;/span&gt;&lt;br/&gt;timeToLiveSeconds=&lt;span class=&quot;hljs-string&quot;&gt;&quot;120&quot;&lt;/span&gt;&lt;br/&gt;overflowToDisk=&lt;span class=&quot;hljs-string&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;br/&gt;maxElementsOnDisk=&lt;span class=&quot;hljs-string&quot;&gt;&quot;10000000&quot;&lt;/span&gt;&lt;br/&gt;diskPersistent=&lt;span class=&quot;hljs-string&quot;&gt;&quot;false&quot;&lt;/span&gt;&lt;br/&gt;diskExpiryThreadIntervalSeconds=&lt;span class=&quot;hljs-string&quot;&gt;&quot;120&quot;&lt;/span&gt;&lt;br/&gt;memoryStoreEvictionPolicy=&lt;span class=&quot;hljs-string&quot;&gt;&quot;LRU&quot;&lt;/span&gt;&lt;br/&gt;/&amp;gt;&lt;br/&gt;&amp;lt;/ehcache&amp;gt;&lt;p&gt;&amp;lt;!&lt;br/&gt;&amp;lt;diskStore &lt;span class=&quot;hljs-built_in&quot;&gt;path&lt;/span&gt;=&lt;span class=&quot;hljs-string&quot;&gt;&quot;java.io.tmpdir&quot;&lt;/span&gt;/&amp;gt;  设置临时文件存放位置。（缓存一般写入内存，一定程度时，写入硬盘。）&lt;/p&gt;&lt;p&gt;缓存详细设置&lt;br/&gt;&amp;lt;defaultCache /&amp;gt;    所有的缓存对象默认的配置&lt;br/&gt;&amp;lt;cache name=&lt;span class=&quot;hljs-string&quot;&gt;&quot;类&quot;&lt;/span&gt;&amp;gt;    指定对象单独配置&lt;/p&gt;&lt;p&gt;参数设置&lt;br/&gt;maxElementsInMemory=&lt;span class=&quot;hljs-string&quot;&gt;&quot;10000&quot;&lt;/span&gt;     内存最大数（类内存中存储对象数据的散列的最大数）&lt;br/&gt;eternal=&lt;span class=&quot;hljs-string&quot;&gt;&quot;false&quot;&lt;/span&gt;                 是否永久（内存常驻留）&lt;br/&gt;timeToIdleSeconds=&lt;span class=&quot;hljs-string&quot;&gt;&quot;120&quot;&lt;/span&gt;         对象在内存中最多空闲多少秒&lt;br/&gt;timeToLiveSeconds=&lt;span class=&quot;hljs-string&quot;&gt;&quot;120&quot;&lt;/span&gt;         对象在内存中最多存活多少秒&lt;br/&gt;overflowToDisk=&lt;span class=&quot;hljs-string&quot;&gt;&quot;true&quot;&lt;/span&gt;           内存满了，是否写入到硬盘&lt;br/&gt;maxElementsOnDisk=&lt;span class=&quot;hljs-string&quot;&gt;&quot;10000000&quot;&lt;/span&gt;    硬盘最大数（硬盘中存储对象数据的散列的最大数）&lt;br/&gt;diskPersistent=&lt;span class=&quot;hljs-string&quot;&gt;&quot;false&quot;&lt;/span&gt;          关闭JVM，是否将内存保存硬盘中&lt;br/&gt;diskExpiryThreadIntervalSeconds=&lt;span class=&quot;hljs-string&quot;&gt;&quot;120&quot;&lt;/span&gt;  轮询&lt;br/&gt;memoryStoreEvictionPolicy=&lt;span class=&quot;hljs-string&quot;&gt;&quot;LRU&quot;&lt;/span&gt;&lt;br/&gt;Least Recently Used (specified as LRU)&lt;br/&gt;First In First Out (specified as FIFO) &lt;br/&gt;Less Frequently Used (specified as LFU)&lt;/p&gt;&lt;p&gt;•maxElementsInMemory    设置基于内存的缓存中可存放的对象最大数目 &lt;br/&gt;•eternal                设置对象是否为永久的，&lt;span class=&quot;hljs-literal&quot;&gt;true&lt;/span&gt;表示永不过期，此时将忽略timeToIdleSeconds 和 timeToLiveSeconds属性，默认值是&lt;span class=&quot;hljs-literal&quot;&gt;false&lt;/span&gt; &lt;br/&gt;•timeToIdleSeconds      设置对象空闲最长时间，以秒为单位，超过这个时间，对象过期。当对象过期时，EHCache会把它从缓存中清除。如果此值为&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;，表示对象可以无限期地处于空闲状态。 &lt;br/&gt;•timeToLiveSeconds      设置对象生存最长时间，超过这个时间，对象过期。&lt;br/&gt;如果此值为&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;，表示对象可以无限期地存在于缓存中。该属性值必须大于或等于 timeToIdleSeconds属性值。&lt;br/&gt;•overflowToDisk         设置基于内在的缓存中的对象数目达到上限后，是否把溢出的对象写到基于硬盘的缓存中 。&lt;br/&gt;•diskPersistent         当jvm结束时是否持久化对象，默认是&lt;span class=&quot;hljs-literal&quot;&gt;false&lt;/span&gt;&lt;br/&gt;•diskExpiryThreadIntervalSeconds    指定专门用于清除过期对象的监听线程的轮询时间。&lt;br/&gt;•memoryStoreEvictionPolicy          当内存缓存达到最大，有新的element加入的时候，移除缓存中element的策略。&lt;br/&gt;默认是LRU（移除最近最少使用的元素），可选的有LFU（移除最不常使用的元素）和FIFO（先进先出） 。&lt;br/&gt;&lt;/p&gt;&lt;/code&gt;
&lt;/pre&gt;
&lt;h2 id=&quot;hhibernate-1&quot;&gt;&lt;span&gt;&lt;strong&gt;四、Hibernate小案例&lt;/strong&gt;&lt;/span&gt;&lt;/h2&gt;
</description>
<pubDate>Sun, 15 Jul 2018 15:30:00 +0000</pubDate>
<dc:creator>黑泽明军</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/chenmingjun/p/9315610.html</dc:identifier>
</item>
<item>
<title>Mini2440上的第一个程序——点亮Led - icuic</title>
<link>http://www.cnblogs.com/outs/p/9315162.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/outs/p/9315162.html</guid>
<description>&lt;p&gt;手头的Mini2440搁置了两年半之后，我再次决定拿出它，重新尝试嵌入式Linux的学习。&lt;/p&gt;
&lt;p&gt;我使用的是友善之臂的Mini2440开发板、韦东山的《嵌入式Linux应用开发完成手册》及其视频教程。所以，本篇文章中所涉及到的各种软件均可在以下两处找到：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://pan.baidu.com/s/1dEAqyy9&quot; target=&quot;_blank&quot;&gt;Mini2440开发板的配套光盘&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://eyun.baidu.com/s/3b1UtLc&quot; target=&quot;_blank&quot;&gt;韦东山JZ2440开发板的光盘&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;JZ2440是韦东山出品的开发板，作为《嵌入式Linux应用开发完全手册》的配套硬件，它和Mini2440相差无几，所以我这里用的是Mini2440。&lt;/p&gt;
&lt;h2 id=&quot;一目标&quot;&gt;一、目标&lt;/h2&gt;
&lt;p&gt;动手之前先确定好一个小目标——这一次，我们的目标是在Mini2440上点亮LED，怎么样，听起来很简单吧。&lt;br/&gt;但是做起来，可并不是很简单喏，主要是因为会涉及到比较多的软件，下一节会对各软件做个大致的介绍，你只要知道各个软件是用来做什么的就可以了，先不必细究。&lt;/p&gt;
&lt;h2 id=&quot;二开发环境&quot;&gt;二、开发环境&lt;/h2&gt;
&lt;p&gt;硬件平台：Mini2440 (64M Nand flash)&lt;/p&gt;&lt;p&gt;软件编译平台：Ubuntu 9.10&lt;br/&gt;以下是你接下来会依次接触到的软件或是工具：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;vi或是vim: Linux下的文本编辑器，你可以把它想象成Windows下的记事本。我们会使用它来编写代码和Makefile文件。&lt;/li&gt;
&lt;li&gt;Makefile: Makefile是一个文本文件，它里面的内容描述了如何根据源文件生成目标文件，即我们所需要的bin文件。在第2.2节会让你编写Makefile文件。&lt;/li&gt;
&lt;li&gt;make: make是一个工具，它以Makefile作为其输入，根据Makefile内描述的规则，生成目标文件。&lt;/li&gt;
&lt;li&gt;VMWare tools: VMWare tools是VMWare里面的一项工具，我们这里用它来实现Windows和Ubuntu虚拟机之间的文件共享，它在1.2节会提及。&lt;/li&gt;
&lt;li&gt;Terminal: 终端。类似于Windows中的命令行，在2.3节我们会使用到它。&lt;/li&gt;
&lt;li&gt;Jlink:Segger公司出品的仿真器，本文中我们仅用它来烧录Mini2440开发板上的Nor Flash。&lt;/li&gt;
&lt;li&gt;supervivi: 友善之臂开发的类似于u-boot的程序，它通常被烧录至Mini2440开发板上的Nand Flash或是Nor Flash中。&lt;/li&gt;
&lt;li&gt;dnw:与supervivi配合使用，完成向开发板下载程序的工具软件。&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;三操作步骤&quot;&gt;三、操作步骤&lt;/h2&gt;
&lt;h3 id=&quot;搭建编译环境&quot;&gt;1. 搭建编译环境&lt;/h3&gt;
&lt;h4 id=&quot;vmware与ubuntu9.10-的下载与安装&quot;&gt;1.1 VMWare与Ubuntu9.10 的下载与安装&lt;/h4&gt;
&lt;p&gt;下载&lt;a href=&quot;https://eyun.baidu.com/s/3b1UtLc&quot; target=&quot;_blank&quot;&gt;JZ2440的配套光盘&lt;/a&gt;，光盘里面有VMWare和已经安装好编译工具链的Ubuntu。&lt;/p&gt;&lt;p&gt;下载完成之后安装VMWare，然后用VMWare打开Ubuntu。整个过程比较简单，网上有很多教程。&lt;/p&gt;&lt;p&gt;介绍一下大致的工作流程：&lt;/p&gt;&lt;p&gt;我们将Windows作为主机，在Windows上，我们可以通过VMWare访问虚拟机Ubuntu。而Ubuntu仅仅作为编译环境，其余的大部分操作还是在Windows上完成。使用Ubuntu的最终目的是生成可供下载至Mini2440的bin文件，然后在Windows上通过相应的工具将这个bin文件烧录至2440开发板。&lt;/p&gt;&lt;p&gt;那么，你可能要问了，这两个不同的操作系统之间，可以互相访问吗，生成的bin文件要如何在两者之间传递呢？&lt;/p&gt;&lt;p&gt;不着急，我们接下来就会来解决这个问题了。&lt;/p&gt;
&lt;h4 id=&quot;在windows与ubuntu之间设置共享文件夹&quot;&gt;1.2 在Windows与Ubuntu之间设置共享文件夹&lt;/h4&gt;
&lt;p&gt;接下来在主机（通常是Windows）与虚拟机（这里是Ubunbu）之间设置共享文件夹，主要是安装VMWare tools，这里不再赘述，网络上有相应的&lt;a href=&quot;https://www.cnblogs.com/huangjianxin/p/6343881.html&quot; target=&quot;_blank&quot;&gt;教程&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;刚才一口气做了这么多事，让我们先来休息一会儿，想一想我们都已经完成了哪些事了。&lt;/p&gt;&lt;p&gt;到现在为止，我们已经在Windows上安装好了VMWare，通过VMWAre我们可以使用Ubuntu系统，接下来，我们将在Ubuntu中编写点亮Led的代码，以及描述如何生成可供下载至Mini2440的bin文件。通过在1.2节设置的共享文件夹，在Windows上，我们可以取到这个bin文件，并通过相应的工具将它烧录至Mini2440。&lt;/p&gt;
&lt;h3 id=&quot;编写led程序和makefile&quot;&gt;2. 编写led程序和Makefile&lt;/h3&gt;
&lt;h4 id=&quot;通过vi输入led_on.s&quot;&gt;2.1 通过vi输入led_on.s&lt;/h4&gt;
&lt;p&gt;你可能是头一次听说vi,还不知道如何使用。关于vim，网上也很大把的教程，同时，这里也有vi的&lt;a href=&quot;https://eyun.baidu.com/s/3b1UtLc#sharelink/path=%2F100ask%E5%88%86%E4%BA%AB%E7%9A%84%E6%89%80%E6%9C%89%E6%96%87%E4%BB%B6%2F005_ARM%E8%A3%B8%E6%9C%BA1%E6%9C%9F%E5%8A%A0%E5%BC%BA%E7%89%88(%E6%96%B01%E6%9C%9F)%2F%E8%A7%86%E9%A2%91%2F%E7%AC%AC004%E8%AF%BE_vi%E&quot;&gt;视频教程&lt;/a&gt;。你只需要掌握几个简单的操作，例如如何新建文件，如何输入并保存文件即可。&lt;/p&gt;&lt;p&gt;在你学会使用vi后，请新建一个名为led_on.s的文件，它的内容如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;.text
.global _start
_start:
    LDR R0,=0x56000010
    MOV R1,#0x00015400
    STR R1,[R0]

    LDR R0,=0x56000014
    MOV R1,#0x000000C0
    STR R1,[R0]
MAIN_LOOP:
    B   MAIN_LOOP&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;以上汇编代码主要做了两件事：&lt;/p&gt;
&lt;ol readability=&quot;-0.5&quot;&gt;&lt;li readability=&quot;2&quot;&gt;将位于0x56000010地址的GPBCON寄存器的内容写为0x00015400,什么意思呢？GPBCON寄存器是用来配置GPB的控制寄存器，通过它，可以分别指定GPB上每一位的功能——是作为输入引脚，或是作为输出引脚，抑或是其它的功能。&lt;p&gt;通过查看Mini2440的原理图，我们可以看到，开发板上的4个led分别连接到了CPU(S3C2440)的GPB5/GPB6/GPB7和GPB8。&lt;/p&gt;&lt;p&gt;所以，我们需要在GPBCON寄存器上，需要将GPB5/6/7/8配置为输出功能。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;将位于0x56000014地址的GPBDAT寄存器的内容写为0x000000C0。GPBDAT寄存器是用来控制各个引脚上的电平的，是高电平1还是低电平0.&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;如果你仍然有些疑惑，那你可以看看这个&lt;a href=&quot;https://www.bilibili.com/video/av15503339/?p=10&quot;&gt;视频教程&lt;/a&gt;的前半小时的内容。当然，对于这段代码的内容不太理解也没有关系，知道它大致做了些什么事情就可以啦！&lt;br/&gt;&lt;/p&gt;
&lt;h4 id=&quot;通过vim输入makefile&quot;&gt;2.2 通过vim输入Makefile&lt;/h4&gt;
&lt;p&gt;使用vi新建一个名为Makefile的文件，它的内容如下：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;led_on.bin:led_on.s
    arm-linux-gcc -g -c -o led_on.o led_on.s
    arm-linux-ld -Ttext 0x00000000 -g led_on.o -o led_on_elf
    arm-linux-objcopy -O binary -S led_on_elf led_on.bin
clean:
    rm -f led_on.bin led_on_elf *.o&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;同样地，前面的视频教程也有对这个Makefile文件的讲解。&lt;/p&gt;
&lt;h4 id=&quot;生成可执行文件led_on.bin&quot;&gt;2.3 生成可执行文件led_on.bin&lt;/h4&gt;
&lt;p&gt;在Ubuntu中打开终端，cd至led_on.s和Makefile所在的目录，执行以下命令，生成led_on.bin。&lt;br/&gt;&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;make&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;至此，我们已经生成了将要下载到Mini2440开发板中的led_on.bin文件。&lt;/p&gt;
&lt;h3 id=&quot;mini2440的启动模式&quot;&gt;3 Mini2440的启动模式&lt;/h3&gt;
&lt;p&gt;Mini2440有两种启动模式，分别是从Nand Flash启动和从Nor Flash 启动，两种启动模式通过开关S2控制。&lt;/p&gt;&lt;p&gt;在 NAND Flash 启动模式下，上电之后，Nand Flash 最前面的4K 空间的内容会被拷贝至S3C2440 （Mini2440开发板上的主芯片）中的片内SRAM中，接着从SRAM的0地址处开始执行。&lt;/p&gt;&lt;p&gt;在 Nor Flash 启动模式下(非 Nand Flash 启动模式)，Nor Flash 起始处就被映射为 0地址，接着从Nor Flash的0地址处开始执行。&lt;/p&gt;&lt;p&gt;在本文中，我们将使用Nor Flash模式启动，通过烧录至Nor Flash的Supervivi，将2.3生成的led_on.bin烧录至SDRAM处执行。&lt;/p&gt;&lt;p&gt;SDRAM 地址空间： 0x30000000 ~ 0x34000000&lt;/p&gt;
&lt;h3 id=&quot;烧录supervivi至nor-flash&quot;&gt;4 烧录supervivi至Nor Flash&lt;/h3&gt;
&lt;h4 id=&quot;判断nor-flash中是否已经烧录supervivi&quot;&gt;4.1 判断Nor Flash中是否已经烧录supervivi&lt;/h4&gt;
&lt;p&gt;使用直连串口线连接Mini2440开发板的串口 0 和 PC 机的串口，在Windows上打开并设置好串口助手（115200，8N1），将Mini2440上的开关S2拨至Nor Flash启动模式，然后将开发板上电，如果串口助手上没有打印出以下内容，则需要根据4.2及其以后的步骤烧录supervivi至Nor Flash.&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/508474/201807/508474-20180715220656026-875972802.png&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;通过jlink将supervivi烧录至nor-flash&quot;&gt;4.2通过JLink将supervivi烧录至Nor Flash&lt;/h4&gt;
&lt;h5 id=&quot;按照下图连接好jlink&quot;&gt;4.2.1 按照下图连接好Jlink&lt;/h5&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/508474/201807/508474-20180715220646647-581211518.png&quot;/&gt;&lt;/p&gt;
&lt;h5 id=&quot;安装jflash配合jlink使用&quot;&gt;4.2.2 安装JFlash（配合JLink使用）&lt;/h5&gt;
&lt;p&gt;在Mini2440光盘里可以找到安装文件&lt;/p&gt;
&lt;h5 id=&quot;通过jflash烧录supervivi至nor-flash&quot;&gt;4.2.3 通过JFlash烧录supervivi至Nor Flash&lt;/h5&gt;
&lt;p&gt;打开JFlash，依次打开Options-&amp;gt;Project settings…,按照下图配置。&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/508474/201807/508474-20180715220607147-1683079900.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通过File-&amp;gt;Open data file…导入supervivi-64M.bin（注意区分应该选64M还是128M的，我的Mini2440上的Nand Flash是64M的）,地址填写0，表示bin文件将烧录至Nor Flash的0地址处。&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/508474/201807/508474-20180715220557596-1006459622.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;依次选择Target-&amp;gt;Auto，等待烧录完成。&lt;/p&gt;
&lt;h5 id=&quot;在windows上安装dnw&quot;&gt;4.2.4 在Windows上安装dnw&lt;/h5&gt;
&lt;p&gt;参照&lt;a href=&quot;http://112.124.9.243/arm9net/mini2440/mini2440um-20110421.zip&quot;&gt;Mini2440用户手册&lt;/a&gt;的2.2.3节安装dnw&lt;/p&gt;
&lt;h5 id=&quot;烧录led_on.bin至sdram并执行&quot;&gt;4.2.5 烧录led_on.bin至SDRAM并执行&lt;/h5&gt;
&lt;h6 id=&quot;打开dnw依次选择configuration在download-address处填写0x32000000表示接下来的supervivi将被烧录至0x32000000即sdram处&quot;&gt;4.2.5.1 打开dnw,依次选择Configuration,在Download Address处填写0x32000000,表示接下来的supervivi将被烧录至0x32000000,即SDRAM处。&lt;/h6&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/508474/201807/508474-20180715220539367-236118888.png&quot;/&gt;&lt;/p&gt;
&lt;h6 id=&quot;开发板上电串口助手将打印以下信息输入d&quot;&gt;4.2.5.2 开发板上电，串口助手将打印以下信息，输入d&lt;/h6&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/508474/201807/508474-20180715220148782-1633869977.png&quot;/&gt;&lt;/p&gt;
&lt;h6 id=&quot;在dnw中依次选择usb-port-transmitrestore在弹出的窗口中选择led_on.bin等待下载完成&quot;&gt;4.2.5.3 在dnw中依次选择USB Port-&amp;gt;Transmit/Restore,在弹出的窗口中选择led_on.bin，等待下载完成。&lt;/h6&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/508474/201807/508474-20180715215957021-1528692313.png&quot;/&gt;&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/508474/201807/508474-20180715220431553-1203545788.png&quot;/&gt;&lt;/p&gt;
&lt;h6 id=&quot;观察开发板上的led&quot;&gt;4.2.5.4 观察开发板上的LED。&lt;/h6&gt;
&lt;p&gt;4个Led中，Led1和Led4应该是被点亮，而Led2和Led3则是熄灭的。&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;至此，总算是把Led给点亮了，虽然整个过程有一些繁琐，但是并没有多大的难度，主要是涉及到比较多的工具软件，如果有哪个步骤卡住了，你可以先尝试在网络上搜索一下，如果自己无法解决，欢迎留言。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/508474/201807/508474-20180715231526345-1133554053.png&quot; width=&quot;205&quot; hegiht=&quot;205&quot; align=&quot;center&quot;/&gt;&lt;/p&gt;
&lt;p&gt;如果你看了这篇文章，觉得有一点点收获，那就给点打赏，给我更大的写作动力吧。&lt;/p&gt;
</description>
<pubDate>Sun, 15 Jul 2018 15:25:00 +0000</pubDate>
<dc:creator>icuic</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/outs/p/9315162.html</dc:identifier>
</item>
<item>
<title>Helm - Kubernetes服务编排的利器 - 编程玩家</title>
<link>http://www.cnblogs.com/Erik_Xu/p/8893725.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Erik_Xu/p/8893725.html</guid>
<description>&lt;p&gt;　　在Kubernetes中部署容器云应用（容器或微服务编排）是一项有挑战性的工作，Helm就是为了简化在Kubernetes中安装部署容器云应用的一个客户端工具。通过Helm能够帮助开发者定义、安装和升级Kubernetes中的容器云应用。同时，也可以通过Helm进行容器云应用的分享。&lt;/p&gt;
&lt;p&gt;　　Helm的整体架构如下图（图片来源-&lt;a href=&quot;https://www.kubernetes.org.cn/4009.html&quot; target=&quot;_blank&quot;&gt;Kubernetes中文社区&lt;/a&gt;）所示：&lt;/p&gt;
&lt;p&gt;　　&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201807/182190-20180715184059602-960919767.jpg&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;　　Helm架构由Helm客户端、Tiller服务器端和Chart仓库所组成；Tiller部署在Kubernetes中，Helm客户端从Chart仓库中获取Chart安装包，并将其安装部署到Kubernetes集群中。 &lt;/p&gt;

&lt;p&gt;Helm是管理Kubernetes包的工具，Helm能提供以下能力：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;创建新的charts&lt;/li&gt;
&lt;li&gt;将charts打包成tgz文件&lt;/li&gt;
&lt;li&gt;与chart仓库交互&lt;/li&gt;
&lt;li&gt;安装和卸载Kubernetes的应用&lt;/li&gt;
&lt;li&gt;管理使用Helm安装的charts的生命周期&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在Helm中，有三个需要了解的重要概念：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;chart：是创建Kubernetes应用实例的信息集合&lt;/li&gt;
&lt;li&gt;config：创建发布对象的chart的配置信息&lt;/li&gt;
&lt;li&gt;release：chart的运行实例，包含特定的config&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;&lt;strong&gt;注：有些文件或镜像在国内可能无法下载，可以通过此地址获取：&lt;a href=&quot;https://pan.baidu.com/s/1yVUCz7wGYie8hkzQaNc3eg&quot; target=&quot;_blank&quot;&gt;https://pan.baidu.com/s/1yVUCz7wGYie8hkzQaNc3eg&lt;/a&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;1. 在Master中下载安装Helm的客户端，可根据需要下载对应的版本，这里使用的版本是2.8.2。&lt;/p&gt;
&lt;p&gt;curl -LO https://storage.googleapis.com/kubernetes-helm/helm-v2.8.2-linux-amd64.tar.gz&lt;/p&gt;
&lt;p&gt;tar xzf helm-v2.8.2-linux-amd64.tar.gz&lt;/p&gt;
&lt;p&gt;mv linux-amd64/helm /usr/local/bin&lt;/p&gt;

&lt;p&gt;helm version查看信息：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201807/182190-20180715201911454-1161067886.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;服务端Tiller还未安装，因此无法获取信息。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;注：如果helm-v2.8.2-linux-amd64.tar.gz无法下载，可以从上面的链接中获取。&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt; 2. 安装Tiller。&lt;/p&gt;
&lt;p&gt;helm init&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201805/182190-20180501112940961-313985438.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;注：如果初始化失败，可以把&lt;em&gt;&lt;strong&gt;上面的链接中的.helm目录拷贝到master的root目录下。tiller的镜像文件也可以从目录获取。&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;em&gt;&lt;strong&gt;如果出现了“Error:Get https://10.96.0.1:443/version:dial tcp 10.96.0.1:443:i/o timeout.”的问题，可以参考我的回答来解决：&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/kubernetes/helm/issues/3347#issuecomment-385468128&quot; target=&quot;_blank&quot;&gt;&lt;em&gt;&lt;strong&gt;&lt;em&gt;&lt;strong&gt;https://github.com/kubernetes/helm/issues/3347#issuecomment-385468128&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;使用helm version查看Helm版本，如下表示客户端、服务端都安装完成：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201804/182190-20180420215056705-307225939.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;Kubernetes 1.6+版本加入了RBAC的机制，因此需要添加Role Binding：&lt;/p&gt;
&lt;p&gt;kubectl create clusterrolebinding add-on-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:default&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201805/182190-20180501113139931-413628239.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;1. 打包jar&lt;/p&gt;
&lt;p&gt;mvn package&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201804/182190-20180422161710941-1124004827.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;2. 准备Dockerfile&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
FROM java:8u111-&lt;span&gt;jre
RUN mkdir &lt;/span&gt;/&lt;span&gt;app
COPY . &lt;/span&gt;/&lt;span&gt;app
WORKDIR &lt;/span&gt;/&lt;span&gt;app
CMD [&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;java&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;-Xmx4g&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;-Djava.security.egd=file:/dev/./urandom&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;-jar&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;hello-1.0.0.jar&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;]
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;3. 拷贝打包好的jar包以及Dockerfile到node虚拟机&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201804/182190-20180422164139983-488536250.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;4. 打包docker镜像&lt;/p&gt;
&lt;p&gt;docker build -t hello:1.0.0 .&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201804/182190-20180422164353487-422619796.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;1. 发布项目&lt;/p&gt;
&lt;p&gt;dotnet publish -c Release&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201804/182190-20180422164006815-1306929257.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;2. 准备Dockerfile&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
FROM microsoft/aspnetcore:&lt;span&gt;2.0&lt;/span&gt;&lt;span&gt;
COPY . &lt;/span&gt;/&lt;span&gt;app
WORKDIR &lt;/span&gt;/&lt;span&gt;app

EXPOSE &lt;/span&gt;&lt;span&gt;5000&lt;/span&gt;/&lt;span&gt;tcp
ENV ASPNETCORE_URLS http:&lt;/span&gt;&lt;span&gt;//&lt;/span&gt;&lt;span&gt;*:5000&lt;/span&gt;
&lt;span&gt;
ENTRYPOINT [&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;dotnet&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;HelloTest.dll&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;]
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;3. 拷贝打包好的程序包以及Dockerfile到node虚拟机&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201804/182190-20180422164212411-2117961459.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;4. 打包docker镜像&lt;/p&gt;
&lt;p&gt;docker build -t hello-test:1.0.0 .&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201804/182190-20180422164456370-610986344.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;这里演示如何通过helm完成上面两个微服务的部署。&lt;/p&gt;

&lt;p&gt;1. 创建chart&lt;/p&gt;
&lt;p&gt;helm create hello-test&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201804/182190-20180422211325003-151846610.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;2. 在templates目录中放入相应的部署脚本&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201804/182190-20180422212147458-149959617.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;3. 打包chart&lt;/p&gt;
&lt;p&gt;helm package hello-test&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201804/182190-20180422212314402-855088375.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;4. 检查chart&lt;/p&gt;
&lt;p&gt;helm lint hello-test&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201804/182190-20180422212415273-1251307476.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;缺少chart的图标，但不影响，可以忽略。&lt;/p&gt;

&lt;p&gt;5. 调试chart&lt;/p&gt;
&lt;p&gt;helm install ./hello-test-0.1.0.tgz --debug --dry-run&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201805/182190-20180501113551446-560995053.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;调试模式不会真的部署，通过helm list来查看：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201805/182190-20180501113644426-562885082.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;6. 通过chart部署release&lt;/p&gt;
&lt;p&gt;helm install --name hello-test ./hello-test-0.1.0.tgz&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201805/182190-20180501114015716-362660958.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;helm ls&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201805/182190-20180501114050133-1278943278.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;kubectl get po&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201805/182190-20180501114115463-2116797685.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;查看结果&lt;/p&gt;
&lt;p&gt;java服务： &lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201807/182190-20180715211020307-819020043.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;.Net Core服务（调用java服务）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201807/182190-20180715211102057-1406656142.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;7. 删除release&lt;/p&gt;
&lt;p&gt;helm delete hello-test&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201805/182190-20180501114332485-1472492970.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;kubectl get po&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201805/182190-20180501114407762-780290751.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;helm ls -a&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201805/182190-20180501114450507-1297824962.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;hello-test还在，但状态是DELETED，表示可以重用。如果想彻底删除，可以通过helm delete hello-test --purge来删除&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201805/182190-20180501114658307-374799154.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;使用的组件是：&lt;a href=&quot;https://github.com/qmfrederik/helm/&quot; target=&quot;_blank&quot;&gt;https://github.com/qmfrederik/helm/&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;1. 核心代码：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;46&quot;&gt;
&lt;pre&gt;
[Route(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;api/releases&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)]
&lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; ReleaseController : Controller
{
    [HttpPost(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;{name}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)]
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;async&lt;/span&gt; Task&amp;lt;IActionResult&amp;gt; Install(&lt;span&gt;string&lt;/span&gt;&lt;span&gt; name, IFormFile file)
    {
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; client = &lt;span&gt;await&lt;/span&gt;&lt;span&gt; GetClient();

        &lt;/span&gt;&lt;span&gt;using&lt;/span&gt; (&lt;span&gt;var&lt;/span&gt; stream = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; MemoryStream())
        {
            &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; file.CopyToAsync(stream);
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; chart =&lt;span&gt; ChartPackage.Open(stream);
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; release = &lt;span&gt;await&lt;/span&gt; client.InstallRelease(chart.Serialize(), &lt;span&gt;string&lt;/span&gt;.Empty, name, &lt;span&gt;true&lt;/span&gt;&lt;span&gt;);
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Ok(release.Manifest);
        }
    }

    [HttpDelete(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;{name}/{purge}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)]
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;async&lt;/span&gt; Task&amp;lt;IActionResult&amp;gt; Uninstall(&lt;span&gt;string&lt;/span&gt; name, &lt;span&gt;bool&lt;/span&gt;&lt;span&gt; purge)
    {
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; client = &lt;span&gt;await&lt;/span&gt;&lt;span&gt; GetClient();
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; result = &lt;span&gt;await&lt;/span&gt;&lt;span&gt; client.UninstallRelease(name, purge);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Ok(result.Info);
    }

    [HttpPut(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;{name}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)]
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;async&lt;/span&gt; Task&amp;lt;IActionResult&amp;gt; Update(&lt;span&gt;string&lt;/span&gt;&lt;span&gt; name, IFormFile file)
    {
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; client = &lt;span&gt;await&lt;/span&gt;&lt;span&gt; GetClient();

        &lt;/span&gt;&lt;span&gt;using&lt;/span&gt; (&lt;span&gt;var&lt;/span&gt; stream = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; MemoryStream())
        {
            &lt;/span&gt;&lt;span&gt;await&lt;/span&gt;&lt;span&gt; file.CopyToAsync(stream);
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; chart =&lt;span&gt; ChartPackage.Open(stream);
            &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; release = &lt;span&gt;await&lt;/span&gt; client.UpdateRelease(chart.Serialize(), &lt;span&gt;string&lt;/span&gt;&lt;span&gt;.Empty, name);
            &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Ok(release.Manifest);
        }
    }

    [HttpPut(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;{name}/{version}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)]
    &lt;/span&gt;&lt;span&gt;public&lt;/span&gt; &lt;span&gt;async&lt;/span&gt; Task&amp;lt;IActionResult&amp;gt; Rollback(&lt;span&gt;string&lt;/span&gt; name, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; version)
    {
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; client = &lt;span&gt;await&lt;/span&gt;&lt;span&gt; GetClient();
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; result = &lt;span&gt;await&lt;/span&gt;&lt;span&gt; client.RollbackRelease(name, version);
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; Ok(result.Info);
    }

    &lt;/span&gt;&lt;span&gt;private&lt;/span&gt; &lt;span&gt;static&lt;/span&gt; &lt;span&gt;async&lt;/span&gt; Task&amp;lt;TillerClient&amp;gt;&lt;span&gt; GetClient()
    {
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; kubeconfig = System.IO.File.ReadAllText(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;admin.conf&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; config =&lt;span&gt; KubernetesClientConfiguration.BuildConfigFromConfigFile(kubeconfig: kubeconfig);
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; kubernetes = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Kubernetes(config);

        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; locator = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; TillerLocator(kubernetes);
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; endPoint = &lt;span&gt;await&lt;/span&gt;&lt;span&gt; locator.Locate();
        &lt;/span&gt;&lt;span&gt;var&lt;/span&gt; client = &lt;span&gt;new&lt;/span&gt;&lt;span&gt; TillerClient(endPoint.ToString());
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; client;
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;注：这里需要获取Kubernetes的admin.config的证书，该证书在master节点上：/etc/kubernetes/admin.conf。&lt;/p&gt;

&lt;p&gt;2. 参考上述准备.Net Core微服务的步骤，完成helm-client的镜像打包及部署。&lt;/p&gt;
&lt;p&gt;注：需要把admin.conf拷贝到镜像中：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201807/182190-20180715214026796-517667785.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;3. 准备yaml文件helm-client.yaml并完成部署&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: helm-client
  labels:
    app: helm-client
  namespace: default
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: helm-client
    spec:
      nodeSelector:
        kubernetes.io/role: node
      containers:
      - name: helm-client
        image: helm-client:1.0.0
        ports:
        - containerPort: 5000

---

kind: Service
apiVersion: v1
metadata:
  name: helm-client
  labels:
    app: helm-client
  namespace: default
spec:
  selector:
    app: helm-client
  type: NodePort
  ports:
  - name: helm-client
    nodePort: 30000
    port: 5000
    protocol: TCP
    targetPort: 5000&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201807/182190-20180715214229729-88076189.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;4. 检查效果&lt;/p&gt;
&lt;p&gt;安装：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201807/182190-20180715220731312-474160066.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201807/182190-20180715220755544-1360893086.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;删除：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201807/182190-20180715220844576-1050981962.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/182190/201807/182190-20180715220906788-220656306.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;p&gt;&lt;a href=&quot;https://github.com/ErikXu/HelmTutorial&quot; target=&quot;_blank&quot;&gt;https://github.com/ErikXu/HelmTutorial&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 15 Jul 2018 14:24:00 +0000</pubDate>
<dc:creator>编程玩家</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/Erik_Xu/p/8893725.html</dc:identifier>
</item>
<item>
<title>吴恩达《深度学习》第四门课（1）卷积神经网络 - ysyouaremyall</title>
<link>http://www.cnblogs.com/ys99/p/9315193.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ys99/p/9315193.html</guid>
<description>&lt;h2&gt;1.1计算机视觉&lt;/h2&gt;
&lt;p&gt;（1）计算机视觉的应用包括图像分类、目标检测、图像分割、风格迁移等，下图展示了风格迁移案例：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1326691/201807/1326691-20180715191424015-1718806106.png&quot; alt=&quot;&quot; width=&quot;252&quot; height=&quot;232&quot;/&gt;&lt;/p&gt;
&lt;p&gt;（2）图像的特征量非常之大，比如一个3通道的1000*1000的照片，其特征为3*1000*1000达到300万，如果第一个隐藏层有1000个单元那么W[1]有20亿个参数，计算量不仅大，而且由于图像样本相对于特征实在是太少，导致很容易过拟合，所以需要其他的方式来连接，即卷积。&lt;/p&gt;
&lt;h2&gt;1.2边缘检测示例&lt;/h2&gt;
&lt;p&gt;（1）卷积运算是输入图像与过滤器（也叫核）进行的运算，得到输出图像。卷积核与图像对应的位置相乘求和得到一个新值，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1326691/201807/1326691-20180715192813581-812792648.png&quot; alt=&quot;&quot; width=&quot;524&quot; height=&quot;253&quot;/&gt;&lt;/p&gt;
&lt;p&gt;输出中第一个绿色框的值为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1326691/201807/1326691-20180715192916187-2013518174.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;（2）每个不同的核可以检测到不同的边缘特性，如下面的核就可以检测到图像的垂直特性，即输入图像中的边缘会在输出图像中用白色显示出来，非边缘部分显示为黑色或灰色。同理还有其他水平边缘检测等各种核（过滤器）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1326691/201807/1326691-20180715193109688-240741323.png&quot; alt=&quot;&quot; width=&quot;489&quot; height=&quot;270&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;1.3更多边缘检测的内容&lt;/h2&gt;
&lt;p&gt;（1）除了上面提到的卷积核，还有其他许多卷积核，把上面3*3的卷积核看成9个参数，然后不是通过人工的确定，而是通过神经网络来学习这些参数，这就是卷积神经网络。&lt;/p&gt;
&lt;h2&gt;1.4Padding&lt;/h2&gt;
&lt;p&gt;（1）边缘不填充会有两个缺点：第一是随着不断卷积，图像会变得越来越小，有时你可不想让它变小；第二是最角落的点只被使用了一次，这意味着在下传的过程中丢掉了图像边缘位置的信息。如下图所示（角落的绿色点只被计算了一次，中间红色点可以被计算多次）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1326691/201807/1326691-20180715195112121-476321527.png&quot; alt=&quot;&quot; width=&quot;354&quot; height=&quot;175&quot;/&gt;&lt;/p&gt;
&lt;p&gt;（2）Padding经常可以设置成为两个参数：第一个是Valid，即不做填充；第二个是Same，即输出尺寸与输入尺寸相等。&lt;/p&gt;
&lt;p&gt;（3）在步长为1是有公式：n+2p-f+1为输出的尺寸。其中n是输入的尺寸（比如说宽），f是卷积核的大小（比如3），p是每一边额外添加的列数（如添加一列就为1）。所以根据这个式子很容易计算出用Same参数时，p=(f-1)/2，注意此处前提都是步长为1。&lt;/p&gt;
&lt;h2&gt;1.5卷积步长&lt;/h2&gt;
&lt;p&gt;（1）输入与输出的尺寸关系如下，注意当结果不是整数时是向下取整。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1326691/201807/1326691-20180715200528306-1299747574.png&quot; alt=&quot;&quot; width=&quot;426&quot; height=&quot;224&quot;/&gt;&lt;/p&gt;
&lt;p&gt;（2）在深度学习的卷积没有必要像数学或者信号处理教材中，先将卷积核顺时针旋转90°，然后在水平翻转，最后再进行与上面相同的卷积运算。深度学习直接忽略了那些旋转翻转的步骤。影响不大。&lt;/p&gt;
&lt;h2&gt;1.6三维卷积&lt;/h2&gt;
&lt;p&gt;（1）三维的卷积方法如下图所示，卷积核的通道数与输入图像的通道数相同，输出图像的通道数为所使用的卷积核的个数，至于高和宽还是按照上面提到的公式计算：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1326691/201807/1326691-20180715202322547-461219626.png&quot; alt=&quot;&quot; width=&quot;592&quot; height=&quot;301&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;1.7单层卷积网络&lt;/h2&gt;
&lt;p&gt;（1）每一个卷积核的输出对应一个实数b（偏差），然后在进行激活函数的非线性转换得到输出，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1326691/201807/1326691-20180715203955622-1529973153.png&quot; alt=&quot;&quot; width=&quot;616&quot; height=&quot;344&quot;/&gt;&lt;/p&gt;
&lt;p&gt;（2）参数个数的计算：比如10个卷积核3*3*3，b的个数跟卷积核个数相同，所以总的参数为（3*3*3+1）*10=280，不管输入尺寸多大，参数个数始终保持不变，而在全连接网络中参数个数是会随着输入不同而不同的。&lt;/p&gt;
&lt;p&gt;（3）一些符号如下所示，习惯上w用m*n&lt;sub&gt;H&lt;sup&gt;[l]&lt;/sup&gt;&lt;/sub&gt;*n&lt;sub&gt;W&lt;/sub&gt;&lt;sup&gt;[l]&lt;/sup&gt;*n&lt;sub&gt;C&lt;/sub&gt;&lt;sup&gt;[l]&lt;/sup&gt;表示，b用1*1*1*n&lt;sub&gt;C&lt;/sub&gt;&lt;sup&gt;[l]&lt;/sup&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1326691/201807/1326691-20180715204628520-1093977882.png&quot; alt=&quot;&quot; width=&quot;563&quot; height=&quot;284&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;1.8简答的卷积网络示例&lt;/h2&gt;
&lt;p&gt;（1）案例图如下：最核心的就是要会计算输出尺寸（公式（（n+2p-f）/s）+1，向下取整）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1326691/201807/1326691-20180715205407331-682602711.png&quot; alt=&quot;&quot; width=&quot;661&quot; height=&quot;375&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;1.9池化层&lt;/h2&gt;
&lt;p&gt;（1）池化层中没有需要学习的参数，所以通常不把池化层当做独立的一层来看。&lt;/p&gt;
&lt;p&gt;（2）池化层是一般不会设置padding，即一般padding为0。&lt;/p&gt;
&lt;p&gt;（3）fitter为2，stride为2是最常见的参数设置，尺寸图像缩小为原来的一半。&lt;/p&gt;
&lt;p&gt;（4）卷积时用的尺寸计算公式同样适用于池化层，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1326691/201807/1326691-20180715210605138-650287159.png&quot; alt=&quot;&quot; width=&quot;519&quot; height=&quot;242&quot;/&gt;&lt;/p&gt;
&lt;p&gt;（5）最大池化层比平均池化层更为常用。&lt;/p&gt;
&lt;h2&gt;1.10卷积神经网络示例&lt;/h2&gt;
&lt;p&gt;（1）下面是一个0-9数组分类的网络，包括了卷积层、池化层、全连接层：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1326691/201807/1326691-20180715211656241-371831262.png&quot; alt=&quot;&quot; width=&quot;571&quot; height=&quot;315&quot;/&gt;&lt;/p&gt;
&lt;p&gt;（2）一般而言，不断卷积之后，图像的高度和宽度会变小，通道数（深度）会增加。&lt;/p&gt;
&lt;p&gt;（3）在神经网络中，另一个常见的模式就是一个或多个卷积层之后跟随一个池化层，然后一个或多个卷积层之后跟随一个池化层，然后跟几个全连接层，最后是一个softmax.&lt;/p&gt;
&lt;p&gt;（4）下面是针对上面网络的一些输出和参数的个数，&lt;strong&gt;其中参数一栏最后三行的值应该是48000+120、10080+84、840+10&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1326691/201807/1326691-20180715213733735-2118754597.png&quot; alt=&quot;&quot; width=&quot;575&quot; height=&quot;307&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;1.11为什么使用卷积&lt;/h2&gt;
&lt;p&gt;（1）卷积网络的参数远少于全连接的原因主要有两点：第一是参数共享，如左上角用一个垂直的卷积核检测，那么这个卷积核也同样适用于图像的其他区域；第二是稀疏连接，如某个输出值只与特定的几个值相连接（如九个值）。&lt;/p&gt;
&lt;p&gt;（2）卷积神经网络善于捕捉偏移不变形，例如把图像往右平移几个像素，对于网络而言没什么影响。&lt;/p&gt;
</description>
<pubDate>Sun, 15 Jul 2018 14:03:00 +0000</pubDate>
<dc:creator>ysyouaremyall</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/ys99/p/9315193.html</dc:identifier>
</item>
<item>
<title>Java并发编程-CAS - lingjiango</title>
<link>http://www.cnblogs.com/iou123lg/p/9314826.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/iou123lg/p/9314826.html</guid>
<description>&lt;p&gt;　　&lt;a href=&quot;https://www.cnblogs.com/iou123lg/p/9280639.html&quot; target=&quot;_blank&quot;&gt;上一篇文章&lt;/a&gt;，学习了并发编程中的volatile，最后取了网上流传很广的一张图来结尾，从图中可以看出除了volatile变量的读写，还有一个叫做CAS的东西，所以这篇文章再来学习CAS。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、 &lt;/strong&gt; &lt;strong&gt;并发编程三要素-原子性、可见性、有序性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　在讨论CAS前，我想先讨论一下并发编程的三要素，这个应该可以帮助理解CAS的作用等。其实上一篇提到的Java内存模型就是围绕着在并发过程中如何处理原子性、可见性和有序性这3个特征来建立的，所以我理解Java编程实现如果满足了这3个特性，就是线程安全的，可以支持并发访问。&lt;/p&gt;
&lt;p&gt;原子性：指的是一个操作不能再继续拆分，要么一次操作完成，要么就是不执行。在Java中，为了保证原子性，提供了两个高级的字节码指令（monitorenter和monitorexit），这个就是关键字synchronized，可以看&lt;a href=&quot;https://www.cnblogs.com/iou123lg/p/9190572.html&quot; target=&quot;_blank&quot;&gt;Java并发编程-synchronized&lt;/a&gt;。&lt;strong&gt;我理解其实还有一种操作也是可以满足原子性的，就是CAS。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可见性：指的是一个变量在被一个线程更改后，其他的线程能立即看到最新的值。&lt;/p&gt;
&lt;p&gt;有序性：指的是程序的执行按照代码的先后顺序执行。对于可见性和有序性，Java提供了关键字volatile，volatile禁止指令重排，保证了有序性，同时volatile可以保证变量的读写及时从缓存中刷新到主存，也就保证了可见性，可以看&lt;a href=&quot;https://www.cnblogs.com/iou123lg/p/9280639.html&quot; target=&quot;_blank&quot;&gt;Java并发编程-volatile&lt;/a&gt;。除此以外，synchronized是可见性和有序性另外一种实现，同步方法和同步代码块保证一个变量在同一时间只能有一个线程访问，这就是一种先后顺序，而对于可见性保证，只能有一个线程操作变量，那么其他线程只能在前一个线程操作完成后才可以看到变量最新的值。&lt;/p&gt;
&lt;p&gt;我们可以发现synchronized一次性满足了3个特性，那么我们是不是可以大胆的认为&lt;strong&gt;CAS+volatile组合在一起也可以满足3个特性&lt;/strong&gt;。         &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、 &lt;/strong&gt; &lt;strong&gt;CAS&lt;/strong&gt;&lt;strong&gt;介绍&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　CAS全称compare-and-swap，是计算机科学中一种实现多线程原子操作的指令，它比较内存中当前存在的值和外部给定的期望值，只有两者相等时，才将这个内存值修改为新的给定值。CAS操作包含三个操作数，需要读写的内存位置（V）、拟比较的预期原值（A）和拟写入的新值（B），如果V的值和A的值匹配，则将V的值更新为B，否则不做任何操作。多线程尝试使用CAS更新同一变量时，只有一个线程可以操作成功，其他的线程都会失败，失败的线程不会被挂起，只是在此次竞争中被告知失败，下次可以继续尝试CAS操作的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、  CAS&lt;/strong&gt;&lt;strong&gt;背后实现&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　JUC下的atomic类都是通过CAS来实现的，下面就以AtomicInteger为例来阐述CAS的实现。直接看方法compareAndSet，调用了unsafe类的compareAndSwapInt方法：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; compareAndSet(&lt;span&gt;int&lt;/span&gt; expect, &lt;span&gt;int&lt;/span&gt;&lt;span&gt; update) {
        &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; unsafe.compareAndSwapInt(&lt;span&gt;this&lt;/span&gt;&lt;span&gt;, valueOffset, expect, update);
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　其中四个参数分别表示对象、对象的地址（定位到V）、预期值（A）、修改值（B）。&lt;/p&gt;
&lt;p&gt;　　再看unsafe类的方法，这是一个native方法，所以只能继续放看openJDK的代码。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;public&lt;/span&gt; &lt;span&gt;final&lt;/span&gt; &lt;span&gt;native&lt;/span&gt; &lt;span&gt;boolean&lt;/span&gt; compareAndSwapInt(Object var1, &lt;span&gt;long&lt;/span&gt; var2, &lt;span&gt;int&lt;/span&gt; var4, &lt;span&gt;int&lt;/span&gt; var5);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　在unsafe.cpp找到方法CompareAndSwapInt，可以依次看到变量obj、offset、e和x，其中addr就是当前内存位置指针，最终再调用Atomic类的cmpxchg方法。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;44&quot;&gt;
&lt;pre&gt;
UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject &lt;span&gt;unsafe&lt;/span&gt;&lt;span&gt;, jobject obj, jlong offset, jint e, jint x))
  UnsafeWrapper(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;Unsafe_CompareAndSwapInt&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
  oop p &lt;/span&gt;=&lt;span&gt; JNIHandles::resolve(obj);
  jint&lt;/span&gt;* addr = (jint *&lt;span&gt;) index_oop_from_field_offset_long(p, offset);
  &lt;/span&gt;&lt;span&gt;return&lt;/span&gt; (jint)(Atomic::cmpxchg(x, addr, e)) ==&lt;span&gt; e;
UNSAFE_END&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　找到类atomic.hpp，从变量命名上基本可以见名知义。&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;static&lt;/span&gt; jint     cmpxchg    (jint     exchange_value, &lt;span&gt;volatile&lt;/span&gt; jint*     dest, jint     compare_value);
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　和volatile类型，CAS也是依赖不同的CPU会有不同的实现，在src/os_cpu目录下可以看到不同的实现，以atomic_linux_x86.inline.hpp为例，是这么实现的：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;42&quot;&gt;
&lt;pre&gt;
inline jint     Atomic::cmpxchg    (jint     exchange_value, &lt;span&gt;volatile&lt;/span&gt; jint*&lt;span&gt;     dest, jint     compare_value) {
  &lt;/span&gt;&lt;span&gt;int&lt;/span&gt; mp =&lt;span&gt; os::is_MP();
  __asm__ &lt;/span&gt;&lt;span&gt;volatile&lt;/span&gt; (LOCK_IF_MP(%&lt;span&gt;4&lt;/span&gt;) &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;cmpxchgl %1,(%3)&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
                    : &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;=a&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; (exchange_value)
                    : &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;r&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; (exchange_value), &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;a&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; (compare_value), &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;r&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; (dest), &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;r&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; (mp)
                    : &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;cc&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;memory&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;);
  &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; exchange_value;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;　　底层是通过指令cmpxchgl来实现，如果程序是多核环境下，还会先在cmpxchgl前生成lock指令前缀，反之如果是在单核环境下就不需要生成lock指令前缀。为什么多核要生成lock指令前缀？因为CAS是一个原子操作，原子操作隐射到计算机的实现，多核CPU的时候，如果这个操作给到了多个CPU，就破坏了原子性，所以多核环境肯定得先加一个lock指令，不管这个它是以总线锁还是以缓存锁来实现的，单核就不存在这样的问题了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4、&lt;/strong&gt;  &lt;strong&gt;CAS&lt;/strong&gt;&lt;strong&gt;存在的问题&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.1  ABA&lt;/strong&gt;&lt;strong&gt;问题&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A→B→A就会变成1A→2B→3A。&lt;/p&gt;
&lt;p&gt;　　关于ABA问题的举例，参考链接里面有篇文章其实说的很清楚了，不过我认为他这个例子好像描述的有点问题，应该是线程1希望A替换为B，执行操作CAS（A,B），此时线程2做了个操作，将A→B变成了A→C，A的版本已经发生了变化，再执行线程1时会认为A还是那个A，链表变成B→C，如果有B.next=null，C这个节点就丢失了。&lt;/p&gt;
&lt;p&gt;　　从Java 1.5开始，JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.2  &lt;/strong&gt;&lt;strong&gt;循环时间长开销大&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　一般CAS操作都是在不停的自旋，这个操作本身就有可能会失败的，如果一直不停的失败，则会给CPU带来非常大的开销。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.3  &lt;/strong&gt;&lt;strong&gt;只能保证一个共享变量的原子操作&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;　　看了CAS的实现就知道这个只能针对一个共享变量，如果是多个共享变量就只能使用synchronized。除此之外，可以考虑使用AtomicReference来包装多个变量，通过这种方式来处理多个共享变量的情况。&lt;/p&gt;
&lt;p&gt;参考资料：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/lingjiango/ConcurrentProgramPractice&quot;&gt;https://github.com/lingjiango/ConcurrentProgramPractice&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Compare-and-swap&quot;&gt;https://en.wikipedia.org/wiki/Compare-and-swap&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://cmsblogs.com/?p=2235&quot;&gt;http://cmsblogs.com/?p=2235&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Sun, 15 Jul 2018 13:15:00 +0000</pubDate>
<dc:creator>lingjiango</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/iou123lg/p/9314826.html</dc:identifier>
</item>
<item>
<title>男程序猿和女程序猿的网恋—相见（二） - 56899◎か</title>
<link>http://www.cnblogs.com/qy1234/p/9314821.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qy1234/p/9314821.html</guid>
<description>
&lt;p&gt;        &lt;span&gt;  离着接近要见面的日子越来越近，我开始有一点不安……&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;span&gt;         我把我网恋的事以及相见事，告诉我表哥，闺蜜们，她们听到后都是反对的，觉得不靠谱，我试图说服他们，他不是骗子，其实我也是内心在说服自己。&lt;/span&gt;&lt;/p&gt;
&lt;div&gt;&lt;br/&gt;&lt;span&gt;         我把大家反对我和他见面事告诉他，他给我打电话，给我做很多思想工作，大概意思是你要相信我，我不会骗你&lt;img src=&quot;file:///C:/Users/25339/AppData/Local/Temp/2T5E)$9%7BR%5D_)R31DF0Y7OA3.png&quot; alt=&quot;&quot;/&gt;的。&lt;/span&gt;&lt;/div&gt;
&lt;p&gt;&lt;br/&gt;&lt;span&gt;         我快要去见他时候，我们闺蜜三人相聚，三人晚上睡一张床讨论的话题关于是他，她们帮我各种分析，最后代代说：“我听你对他的描述，我觉得你可以见一见，为了不让自己后悔错过。”  YY说：“你一个女孩子去找他，为什么不是他来找你，我觉得很不安全，危险不要去，而且我觉得他人不好，我讨厌他。”  那晚我们聊了很久……&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;span&gt;        到了约定相见日子，我拉着行李箱，背着一个双肩背包，手中拿着一张票（票是他在网上帮我订的），我瞒着父母说我回去北京上班，其实是奔向重庆找他。&lt;/span&gt;&lt;/p&gt;
&lt;div&gt;&lt;br/&gt;&lt;span&gt;        我上了火车&lt;img src=&quot;file:///C:/Users/25339/AppData/Local/Temp/8$5@H@K$RPP7Q6SQZ813OC4.png&quot; alt=&quot;&quot;/&gt;，给他发了消息，他让我注意安全，我们一直聊；我们都很开心，小激动，再过几个小时，我们就可以见面了&lt;img src=&quot;file:///C:/Users/25339/AppData/Local/Temp/2T5E)$9%7BR%5D_)R31DF0Y7OA3.png&quot; alt=&quot;&quot;/&gt;。&lt;/span&gt;&lt;/div&gt;
&lt;p&gt;&lt;br/&gt;&lt;span&gt;        他给我发消息，已经从家里出发了，来火车站接我 ；火车到重庆北目的地，我给他发消息，我已经下火车了，他说他已经在出口站等我了。我走出出口站，我给他打电话，他告诉我，他具体位置方向，我按照他所指方向前行，然后他告诉我已经看到你，你站在原地不动，我来找你……&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;   &lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;span&gt;    附加图片：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;      &lt;span&gt;他寄给我的书和写的信&lt;/span&gt;&lt;/p&gt;
&lt;div readability=&quot;7&quot;&gt;   &lt;img src=&quot;https://images2018.cnblogs.com/blog/992081/201807/992081-20180715210202249-706533997.png&quot; alt=&quot;&quot;/&gt;        


&lt;br/&gt;              &lt;br/&gt; &lt;/div&gt;
</description>
<pubDate>Sun, 15 Jul 2018 13:03:00 +0000</pubDate>
<dc:creator>56899◎か</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/qy1234/p/9314821.html</dc:identifier>
</item>
<item>
<title>TensorFlow中的设备管理（一）——Device的创建与注册机制 - DeepLearningStack</title>
<link>http://www.cnblogs.com/deep-learning-stacks/p/9313700.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/deep-learning-stacks/p/9313700.html</guid>
<description>&lt;p&gt;作为一款优秀的异构深度学习算法框架，TensorFlow可以在多种设备上运行算法程序，包括CPU，GPU，Google开发的TPU等。因为TensorFlow的架构特性非常好，可扩展性很强，所以也支持用户自定义补充其他计算设备，比如可以接入FPGA甚至是自定义芯片等。虽然在Google发布的TensorFlow white paper中并没有过多的描述设备管理相关的内容，只是从较高层面上阐述了Device以及Job的命名规则，但是其设备管理模块确实是处于架构中比较核心的地位。本文将从架构层面出发，详细阐述当前TensorFlow源码中关于设备管理的设计思想和相关细节，理解这部分内容不但可以加深对TensorFlow源码的理解，还可以有能力接入一些自定义的设备。本文是TensorFlow设备管理的第一篇文章，为了能让读者更好的切入到TensorFlow源码阅读过程中，先从较为简单地Device的创建和注册机制开始。读者也可以一边对照本文一边对照源码进行阅读和梳理，并欢迎大家提出各种相关的意见和建议。&lt;/p&gt;

&lt;p&gt;Google在2015年发布的第一版&lt;a href=&quot;http://download.tensorflow.org/paper/whitepaper2015.pdf&quot; target=&quot;_blank&quot;&gt;TensorFlow white paper&lt;/a&gt;中，从功能角度上阐述了Device的相关内容，我们可以总结出关键的几点如下：&lt;/p&gt;
&lt;p&gt;1. 在TensorFlow中的Device有着特殊的命名规则，无论在单机还是分布式任务中，都能依靠命名确定唯一的Device，它是Device的唯一标识符；&lt;/p&gt;
&lt;p&gt;2. TensorFlow使用注册机制将实现多种Device的添加管理；&lt;/p&gt;
&lt;p&gt;3. 每个Device自己管理Memory的分配和释放。&lt;/p&gt;
&lt;p&gt;Device的命名一般使用&lt;span&gt;/job:&lt;span&gt;{job_name}&lt;/span&gt;/task:&lt;span&gt;{job_id}&lt;/span&gt;/device:&lt;span&gt;{type}&lt;/span&gt;:&lt;span&gt;{device_id}&lt;/span&gt;&lt;/span&gt;的格式，这是为了更好的支持分布式任务。例如&lt;span&gt;/job:worker/task:17/device:gpu:3&lt;/span&gt;就表示该Device是ID为17的worker上的ID为GPU设备。至于分布式中的相关概念会在其他文章中详细阐述，在这里我们只需要知道Device的命名可以帮助我们在任务中定位到具体的某个唯一Device即可。&lt;/p&gt;

&lt;p&gt;TensorFlow有两处涉及到了设备管理，一处存在于TensorFlow的core中，另一部分存在于XLA中。本文只会阐述TensorFlow core中的内容，关于XLA部分的讲解可以参见其他blog。TensorFlow使用工厂来创建各种各样的Device，并且几乎为每一种Device都实现了对应的DeviceFactory。初读代码时可能会被各种Device类名搞混，下面先从TensorFlow中已经有的Device类出发，给出各种Device的类说明。&lt;/p&gt;
&lt;h2&gt;Device相关类图&lt;/h2&gt;
&lt;p&gt;TensorFlow对不同种类的Device做了多层级的抽象，下面的类图是从当前TensorFlow源码中梳理出的比较重要的部分。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1437153/201807/1437153-20180715153923763-811813878.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上图中的每个类（class）都可以在TensorFlow的源码中找到，因为当前TensorFlow的进化过程比较快，代码结构并不处于一个十分稳定的状态，所以上述类图中的类结构关系可能在未来发生一些变化，这一点从注释中也可以看出一些端倪，但是大的架构不会发生变化，所以梳理类结构也是十分有意义的。下面将对每个类的作用进行简单地阐述，读者在理解这些类的作用以及关系后再去阅读源码就会非常清晰了。&lt;/p&gt;
&lt;p&gt;1. DeviceAttributes：在TensorFlow源码中并不能直接找到这个类的c++定义，其实它是由protobuf编译出来的。其含义也很好理解，是对特定Device属性的封装，比如Device的type，存储的限制等等；&lt;/p&gt;
&lt;p&gt;2. DeviceBase：定义了Device用到的基本方法，比较重要的是GetAllocator和MakeTensorFromProto，前者返回存储器的分配器，后者是从Proto中生成Tensor，该方法必须被重写；&lt;/p&gt;
&lt;p&gt;3. Device：这个类比DeviceBase更加具体，新包含了一些用于计算调用的方法，比如Compute函数就会调用某Op的Compute计算；&lt;/p&gt;
&lt;p&gt;4. RemoteDevice：这个类会在分布式时使用，在此暂时不进行阐述；&lt;/p&gt;
&lt;p&gt;5. SingleThreadedCpuDevice：这是一个仅有单个线程的CPU Device抽象，它和ThreadPoolDevice不同，只被用于in expensive的Op计算，这样做的好处是避免了一些thread初始化工作；&lt;/p&gt;
&lt;p&gt;6. ThreadPoolDevice：这就是CPU Device的实现；&lt;/p&gt;
&lt;p&gt;7. RenamedDevice：Device的封装类，封装时会再取一个新的Device name；&lt;/p&gt;
&lt;p&gt;8. GPUCompatibleCPUDevice：这也是CPU Device的实现，和ThreadPoolDevice不同的是，它更多的是为了和GPU进行交互而存在，从其使用的CudaHostAllocator就可以看出这一点；&lt;/p&gt;
&lt;p&gt;9. BaseGPUDevice，GPUDevice：这两个类都和GPU Device的实现有关，其中GPU Device类只是在继承BaseGPUDevice的基础上重写了Allocator，但没有理解这样设计的深层次原因。&lt;/p&gt;
&lt;h2&gt;DeviceFactory相关类图&lt;/h2&gt;
&lt;p&gt;上文提到过，TensorFlow中的Device是通过注册机制添加到运行的进程中的。注册机制在开源代码中是十分常见的设计技巧，它涉及到了一种非常经典的设计模式——工厂模式。在定义每个Device时，通过利用C++事先定义好的宏（Macro）将类对象主动注册到工厂中，这样就可以达到在程序启动完毕时，工厂里已经储备有各种各样所需要的内容。在TensorFlow中存在多处使用工厂模式的例子，比如本文阐述的Device管理，以及Session管理等。在其他开源框架中我们也能够看到这一模式，比如Caffe中的Layer也使用的是工厂模式。&lt;/p&gt;
&lt;p&gt;从源码中可以看到，TensorFlow在启动时会调用一系列static的函数，这些函数是通过宏（Macro）展开得到的。对于设备管理模块来说，每种Device都由对应的Factory负责管理，而每种DeviceFactory会在程序启动时注册到全局唯一的static device factory表中。下面的类图展示了各种DeviceFactory之间的继承关系。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1437153/201807/1437153-20180715165802006-2075049362.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;h2&gt;DeviceFactory的注册机制&lt;/h2&gt;
&lt;p&gt;在理清了上一小节中Device相关类的继承关系和说明之后，对于上图中各种DeviceFactory之间的继承关系就很好理解了。这里面比较陌生的类是Registrar，这可以看做是一个带有模板的控制类，它只负责一件事——各种DeviceFactory向全局表的注册。在代码层面，注册函数的调用是通过宏实现的，该宏通过传入DeviceFactory的类名称即可触发Regsitrar的调用逻辑，在每个DeviceFactory的C++实现文件后面都会引用此宏。下图形象的展示了注册的过程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1437153/201807/1437153-20180715183617143-1673917085.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;有了上述的DeviceFactory的注册后，就可以在使用时根据使用的Device类型，从对应的DeviceFactory中“获取”想要的Device了。&lt;/p&gt;
&lt;h2&gt;Device的创建&lt;/h2&gt;
&lt;p&gt; 有了DeviceFactory之后，我们就可以从Factory中拿到各种各样的Device了。真正从Factory中取出Device的过程是在Session创建时进行的，调用的函数是DeviceFactory中的static函数AddDevices。它会遍历全局device factories表中全部的DeviceFactory并取出，然后逐个调用每个具体XXDeviceFactory的CreateDevices函数，将创建的Device放进vector数组中。下面给出一个简化版的时序图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1437153/201807/1437153-20180715224428168-734476370.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;上述的时序图描述的较为简单，实际上DeviceFactory的static函数调用AddDevices时会先将CPU Device创建出来，如果没有可用的CPU Device，那么程序就会直接报错退出（一般情况下不会发生此类情况）。这是因为TensorFlow需要保证当没有其他Device存在时，至少还有CPU可以完成整体程序的计算和调度运行。创建CPU Device之后，就会去遍历所有DeviceFactory，把所有能够创建的Device全部创建出来放入vector数组中。&lt;/p&gt;

&lt;p&gt;本文主要阐述了TensorFlow设备管理模块中的设备创建于注册机制，它是TensorFlow进行设备管理的第一步，也是最简单的部分。想要深入TensorFlow源码的新人可以先从此模块开始阅读，进而熟悉TensorFlow的Coding style。Device的创建和注册过程触发于程序运行的初始阶段，因为创建Device时使用了工厂模式，所以此处涉及到了各种DeviceFactory的定义和注册。在TensorFlow的C++代码中，各种DeviceFactory在实现文件中通过宏主动将自己注册到全局表中，这样做的目的不但减少了大量重复的注册代码，还与Device的创建解耦合，是一个非常经典常见的编码技巧。至于Device的创建是在创建Session时才会触发，这个过程十分简单。至于设备管理模块中涉及到的其他内容将在后续blog中补充。&lt;/p&gt;
</description>
<pubDate>Sun, 15 Jul 2018 12:35:00 +0000</pubDate>
<dc:creator>DeepLearningStack</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/deep-learning-stacks/p/9313700.html</dc:identifier>
</item>
<item>
<title>相机IMU融合四部曲（三）:MSF详细解读与使用 - 极品巧克力</title>
<link>http://www.cnblogs.com/ilekoaiq/p/9311357.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/ilekoaiq/p/9311357.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;相机IMU融合四部曲（三）:MSF详细解读与使用&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;极品巧克力&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;通过前两篇文章，《D-LG-EKF详细解读》和《误差状态四元数详细解读》，已经把相机和IMU融合的理论全部都推导一遍了。而且《误差状态四元数》还对实际操作中的可能遇到的一些情况，进行指导。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这些理论都已经比较完整了，那么，该如何在实际当中操作呢？该如何用到实际产品中呢？误差状态四元数，是有开源的程序的，但是它是集成在rtslam（ &lt;a href=&quot;https://www.openrobots.org/wiki/rtslam/&quot;&gt;https://www.openrobots.org/wiki/rtslam/&lt;/a&gt; ）里面的，不方便提取出来使用。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;但还有另外一个开源的程序，ETH的MSF（https://github.com/ethz-asl/ethzasl_msf），它是独立的一个开源程序，可以比较方便地用在自己的工程里面，并且它的理论与误差状态四元数很接近，稍微有点不同，所以MSF开源程序就成了一个不错的选择。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;所以，我把MSF的程序全部都通读一遍之后，结合程序来推导MSF的理论，总结成本文，包括MSF的实验，与各位分享。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;1.基本模型&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;基本模型如下图所示。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;MSF的可扩展性很好，程序里可以接入新的传感器，比如GPS，激光雷达，码盘等。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234404645-1909464007.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;主要的理论还是误差状态四元数里面的理论。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;相比于《卡尔曼四元数带外参融合方法》，它的方法更好。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先，它的核心状态里面没有重力在世界坐标系下的表示。因为它用的就是《误差状态四元数》里面的5.3.1的方法，直接就是以水平坐标系为世界坐标系。只是初始位置根据当前加速度计的测量值和理论重力计算出来，初始位置&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234405092-220691816.png&quot; alt=&quot;&quot;/&gt;带着一个协方差而已。因为反正最后都是要转换到水平坐标系下的，所以这种方法反而更加方便。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;而且，IMU的世界坐标系和相机的世界坐标系，也不用绑在一起，同时建立。可以在IMU开启一小段时间以后，相机再获取它的世界坐标系。但相隔时间应该还是要尽量短点，因为位移单靠IMU的加速度计的积分，时间久了会很不准确，如果有轮子码盘的话，则又可以好一些。调整&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234405379-515761644.png&quot; alt=&quot;&quot;/&gt;的目的，可能是因为世界坐标系和相机的世界坐标系，在时间戳上并不对应得很好，所以需要微调。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;或者，为了避免这样的麻烦，直接把IMU的世界坐标系和相机的世界坐标系，绑在一起，同时建立。这样子，&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234405608-2101559754.png&quot; alt=&quot;&quot;/&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234405822-1674690781.png&quot; alt=&quot;&quot;/&gt;&lt;span&gt;也应该用ETH的手眼标定方法，借用棋盘格先标定好，再固定住。&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234406046-1429879359.png&quot; alt=&quot;&quot;/&gt;就直接用尺子量好，固定住。如果用双目相机的话，就不用考虑&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234406369-1315470638.png&quot; alt=&quot;&quot;/&gt;了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;（如果加上轮速计的话，怎么更新呢？它的作用与IMU是相同的，都是相对值，而不是绝对值。所以，它应该与IMU实时融合，在主状态与相机融合后，IMU预测出一个位姿态，轮速计预测出一个位姿，然后两者融合出主状态。只有主状态才能与相机位姿融合。融合的话，可以用误差状态的思想来融合。）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;所以，参考《误差状态四元数详细解读》，一个简单鲁棒的IMU与相机融合的模型应该是这样的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;核心状态为，&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234406586-1753008248.png&quot; alt=&quot;&quot;/&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;核心状态上的扰动为，&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234406832-1732564244.png&quot; alt=&quot;&quot;/&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;运动模型跟《误差状态四元数》里面的一样，&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234407117-1896225793.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;则相机位姿的观测方程为，&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234407413-6340273.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;使用《误差状态四元数》里面的公式，&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234407698-1873671440.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;其中，&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234407962-1559077620.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;首先，要计算第一项关于&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234408207-1808566615.png&quot; alt=&quot;&quot;/&gt;的雅克比，&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234408523-191650577.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;则用&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234409000-1847331503.png&quot; alt=&quot;&quot;/&gt;表示上式，则雅克比计算如下，&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234409215-816699871.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然后，第二项，&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234409435-337659049.png&quot; alt=&quot;&quot;/&gt;要转成三个元素的形式，即角轴李代数的形式。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234409735-1561723449.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;用matlab程序，解出上面的式子，以及关于&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234410050-972717866.png&quot; alt=&quot;&quot;/&gt;的雅克比。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;syms &lt;span&gt;qicw &lt;span&gt;&lt;span&gt;qicx &lt;span&gt;&lt;span&gt;qicy &lt;span&gt;&lt;span&gt;qicz &lt;span&gt;&lt;span&gt;thetax &lt;span&gt;&lt;span&gt;thetay &lt;span&gt;&lt;span&gt;thetaz &lt;span&gt;&lt;span&gt;...&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;qwiw &lt;span&gt;&lt;span&gt;qwix &lt;span&gt;&lt;span&gt;qwiy &lt;span&gt;&lt;span&gt;qwiz &lt;span&gt;&lt;span&gt;qzocw &lt;span&gt;&lt;span&gt;qzocx &lt;span&gt;&lt;span&gt;qzocy &lt;span&gt;&lt;span&gt;qzocz &lt;span&gt;&lt;span&gt;real&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;q1=[qicw,-qicx,-qicy,-qicz]';&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;q2=[1,-1/2*thetax,-1/2*thetay,-1/2*thetaz]';&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;q3=[qwiw,-qwix,-qwiy,-qwiz]';&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;q4=[qicw,qicx,qicy,qicz]';&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;q5=[qzocw,qzocx,qzocy,qzocz]';&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;temp = quaternion_mul(q1,q2);&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;temp = quaternion_mul(temp,q3);&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;temp = quaternion_mul(temp,q4);&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;temp = quaternion_mul(temp,q5);&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;temp&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;J=jacobian(2*temp(2:4,:),[thetax,thetay,thetaz])&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;simplify(J)&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span&gt;雅克比可以是，把temp转换成角轴，再关于&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234410531-1893545995.png&quot; alt=&quot;&quot;/&gt;求导。或者，角轴直接近似等于temp向量部分的2倍，再关于&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234410849-2042470025.png&quot; alt=&quot;&quot;/&gt;求导，像上面的matlab程序这样。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这样子计算虽然准确，但是太麻烦了。论文里还用了近似的方法。为了方便地求雅克比，认为测量值近似为预测值直接转换出来，即，&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234411047-1898367379.png&quot; alt=&quot;&quot;/&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234411305-757537611.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;这时候，上式转换成角轴，就是，向量部分的2倍，即，&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234411542-1752043948.png&quot; alt=&quot;&quot;/&gt;。所以，雅克比为，&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234411787-308616480.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;（这种用近似的方法，来算雅克比，虽然不如从原始公式上推导准确，但是可以极大地简化计算，也许可以给D-LG-EKF里面计算H矩阵时借鉴。）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;所以，就得到了雅克比矩阵&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234412031-697287879.png&quot; alt=&quot;&quot;/&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234412284-101040635.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然后，&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234412549-387600139.png&quot; alt=&quot;&quot;/&gt;。就可以计算了。其余的流程，就跟《误差状态四元数》里面一样了。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;2.对延时的处理&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;前提条件是，各个传感器的时间戳得是同一个时间源的，或者，时间戳很稳定，可以通过一些方法把它们时间戳之间的对应关系找到。不同传感器的时间戳能准确对应上。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然后，因为测量值有时候会过一段时间才处理完，所以，把滤波中的状态都记录起来，然后，当有测量值过来的时候，更新对应时刻的状态。然后继续往后预测。如果有多个不同传感器的测量值，也是如此操作。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;3.计算相对测量&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;如果要融合单目相机。考虑到单目尺度的情况，怕有时候尺度会突然发生变化。为了应对这种情况，就都计算相对测量，就是两个时刻之间的相对位姿态，这样子，这一段的尺度&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234412760-1919613644.png&quot; alt=&quot;&quot;/&gt;就可以滤得比较准确。然后，再把优化后的值，加入到原来的状态中，方法跟《误差状态四元数》中的传播差不多，就是把新滤出来的这段位姿的均值和扰动，加到原先状态的均值和扰动中去，整合出新的均值和扰动。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;而如果要融合的是轮子码盘的话，则不必用这样的方法。因为虽然轮子码盘也有尺度问题，但是尺度是较稳定的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如果是双目相机的话，也不必考虑这种尺度突然变化的情况。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;4.准确地计算每帧的协方差&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;为了更好地与GPS融合，就需要当前状态需要有准确的协方差。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;而以前计算出来的相机位姿的协方差是不准确的，没有考虑到累积误差造成的影响。造成了与IMU融合后的状态协方差也是不准确的。得准确地计算出要融合的每帧图像的协方差。这协方差，就是通过全局BA的方法，计算出来的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;但其实为了简化。如果真的要与GPS融合的话。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;在即时建图的情况下，用上一段的方法。但是视觉的误差累积还是很可观的，所以如果是远距离的话，应该以GPS为外界绝对测量，视觉只是用来计算相对测量的。只能用短距离的视觉相对测量。在主状态之后，以此为起点，视觉的相对测量值与IMU的相对测量值融合，融合出相对测量状态，再把相对状态的均值和扰动合并进主状态以及主状态扰动，主状态再与GPS融合，融合出新的主状态。融合的话，可以用误差状态的思想来融合。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;如果已经提前建图，回环检测都做了，地图点固定且准确了，则视觉协方差就是当前帧的协方差，不必通过全局BA算出。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;5. MSF方法总结&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;MSF的方法考虑得很全面，这个理论框架，可以用来融合多种传感器。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;我上面思考出来的方法，还考虑了与轮速计码盘，GPS融合的具体操作情况，以后需要时再用。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;6.实验与改进&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;MSF的安装与跑例程，可以参考这篇文章，&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.liuxiao.org/2016/07/ros-%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%8D%A1%E5%B0%94%E6%9B%BC%E8%9E%8D%E5%90%88%E6%A1%86%E6%9E%B6-ethzasl-msf-framework-%E7%BC%96%E8%AF%91%E4%B8%8E%E4%BD%BF%E7%94%A8/&quot;&gt;&lt;span&gt;http://www.liuxiao.org/2016/07/ros-%E5%A4%9A%E4%BC%A0%E6%84%9F%E5%99%A8%E5%8D%A1%E5%B0%94%E6%9B%BC%E8%9E%8D%E5%90%88%E6%A1%86%E6%9E%B6-ethzasl-msf-framework-%E7%BC%96%E8%AF%91%E4%B8%8E%E4%BD%BF%E7%94%A8/&lt;/span&gt;&lt;/a&gt;&lt;span&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;然后，我自己用ORBSLAM2跑Euroc的V201数据集，生成轨迹数据，和IMU数据一起送入到MSF中运行。为什么要跑标准数据集呢？因为标准数据集提供了IMU噪声的真实参数，可以直接拿来使用，而且有真实的轨迹，groundtruth，可以用来评价融合结果的好坏。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;可是运行结果却总是发散，融合后的轨迹锯齿非常严重。可是在理论上来讲，它应该能取得比较好的效果的呀？所以猜测应该是程序与理论没有对应上。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;只好从程序里去查问题的原因。将程序里的所有的计算过程与算法公式一一对应起来之后，最终发现，是由程序里的2个地方导致的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;1.MSF程序有个隐含的假设，即图像的世界坐标系是水平的。而我送的是以第一帧为世界坐标系的，而V201的第一帧并不是水平的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;2. 经过仔细推导程序的计算过程，发现MSF程序中的qwv，本质上是qvw，这个导致参数的初值给错了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;将以上两个问题改过来之后，MSF就可以正常运行我自己提供的数据了。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;其中，在y轴上的结果如下。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234413135-477850943.png&quot; alt=&quot;&quot;/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234413461-1033638093.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234413748-366547881.png&quot; alt=&quot;&quot;/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234414029-1752380317.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;以上，黑色的线是真实值，绿色的线是ORBSLAM通过图像计算出来的位姿，红色的线是图像位姿和IMU融合后的结果，线上的每一个点都代表一个输出数据。可以看出，msf融合后的结果，不仅可以把位姿的输出频率提高到和IMU一样的频率，还可以让轨迹更加接近真实值。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;但是，msf有一个缺点，那就是IMU的bias收敛得很慢，猜测是由于&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234414423-536561574.png&quot; alt=&quot;&quot;/&gt;近似造成的。如下图所示。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234414680-607106504.png&quot; alt=&quot;&quot;/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/699318/201807/699318-20180714234414981-1395212357.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;上图是加速度计的bias的收敛情况，和陀螺仪的bias的收敛情况。也许可以通过修改这部分的公式，让bias收敛得更快。&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;7.参考文献&lt;/h2&gt;
&lt;ol readability=&quot;1&quot;&gt;&lt;li readability=&quot;5&quot;&gt;
&lt;p&gt;&lt;span&gt;Lynen S, Achtelik M W, Weiss S, et al. A robust and modular multi-sensor fusion approach applied to MAV navigation[C]// Ieee/rsj International Conference on Intelligent Robots and Systems. IEEE, 2013:3923-3929.&lt;/span&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</description>
<pubDate>Sun, 15 Jul 2018 12:29:00 +0000</pubDate>
<dc:creator>极品巧克力</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/ilekoaiq/p/9311357.html</dc:identifier>
</item>
</channel>
</rss>