<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="css/feed.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:media="http://search.yahoo.com/mrss/" xmlns:og="http://ogp.me/ns#">
<channel>
<atom:link rel="self" href="http://192.168.1.4/fivefilters/makefulltextfeed.php?url=feed.cnblogs.com%2Fblog%2Fsitehome%2Frss&amp;max=10&amp;links=preserve&amp;exc=" />
<atom:link rel="alternate" title="Source URL" href="http://feed.cnblogs.com/blog/sitehome/rss" />
<atom:link rel="related" title="Subscribe to feed" href="http://www.subtome.com/#/subscribe?feeds=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D&amp;back=http%3A%2F%2F192.168.1.4%2Ffivefilters%2Fmakefulltextfeed.php%3Furl%3Dfeed.cnblogs.com%252Fblog%252Fsitehome%252Frss%26max%3D10%26links%3Dpreserve%26exc%3D" />
<title>博客园_首页</title>
<link></link>
<description>代码改变世界</description>
<item>
<title>路飞学城-14天集训，第一天 - 印第安老瓶子</title>
<link>http://www.cnblogs.com/wangcc7/p/8514778.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/wangcc7/p/8514778.html</guid>
<description>&lt;p&gt;在python3中有6个标准的数据类型：数字（number）、字符串（string）、列表（list）、元祖（tuple）、集合（sets）、字典（dict）。&lt;/p&gt;

&lt;p&gt;布尔类型有两种：真  and   假  。  6,&amp;lt;7  返回 true   6&amp;gt;7  返回false&lt;/p&gt;

&lt;p&gt;单引号、双引号、多引号的区别：如下图所示，单引号和双引号是没有区别的，   str1 = 'python'     str2 = &quot;python&quot;&lt;/p&gt;
&lt;p&gt;如果字符串中有双引号，为了避免使用转义符，你可以使用单引号来定义这个字符串&lt;/p&gt;
&lt;p&gt;str1 = &lt;span class=&quot;string&quot;&gt;&quot;List of name:\nHua Li\nChao Deng&quot;               str1 = &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;字符串格式化例子：如下&lt;/p&gt;
&lt;pre&gt;
name = input(&quot;name:&quot;)&lt;br/&gt;age = int(input(&quot;age:&quot;))&lt;br/&gt;job = input(&quot;job:&quot;)&lt;br/&gt;hostname =input(&quot;hostname:&quot;)&lt;br/&gt;info =&quot;&quot;&quot;&lt;br/&gt;--------info   of   as----&lt;br/&gt;name:      %s&lt;br/&gt;age :      %d&lt;br/&gt;job :      %s&lt;br/&gt;hostname:  %s&lt;br/&gt;&quot;&quot;&quot;% (name,age,job,hostname)&lt;br/&gt;print(info)
&lt;/pre&gt;
&lt;pre class=&quot;article&quot;&gt;
&lt;strong&gt;基础需求：
让用户输入用户名密码
认证成功后显示欢迎信息
输错三次后退出程序&lt;br/&gt;&lt;/strong&gt;&lt;br/&gt;思路：这里的思路是什么呢，就是while循环，加if 、else就可以实现。
&lt;/pre&gt;
&lt;pre readability=&quot;6&quot;&gt;
# count = 0&lt;br/&gt;# lock= []&lt;br/&gt;# #user：user   passws=123&lt;br/&gt;# f = open('bleak_user','r')&lt;br/&gt;# lock_file=f.readlines()&lt;br/&gt;# f.close()&lt;br/&gt;# while count &amp;lt;=2:&lt;br/&gt;#    user = input(&quot;please input user :&quot;)&lt;br/&gt;#    passwd = input(&quot;please input passwd :&quot;)&lt;br/&gt;#    if user ==&quot;user&quot; and passwd==&quot;123&quot;:&lt;br/&gt;#        print(&quot;login success !!&quot;)&lt;br/&gt;#        break&lt;br/&gt;#    else:&lt;br/&gt;#        print(&quot;login false&quot;)&lt;br/&gt;#        for i in lock_file:&lt;br/&gt;#            line=i.strip('\n')&lt;br/&gt;#            lock.append(line)&lt;br/&gt;#        count+=1&lt;br/&gt;#        print(count)&lt;p&gt;# a=[&quot;list&quot;,123]&lt;br/&gt;# print(a)
&lt;/p&gt;&lt;/pre&gt;
&lt;pre class=&quot;article&quot;&gt;
&lt;strong&gt;升级需求：
可以支持多个用户登录 (提示，通过列表存多个账户信息)
用户3次认证失败后，退出程序，再次启动程序尝试登录时，还是锁定状态（提示:需把用户锁定的状态存到文件里）&lt;/strong&gt;
&lt;/pre&gt;
&lt;pre readability=&quot;24&quot;&gt;
count = 0&lt;br/&gt;user_pass = []&lt;br/&gt;lock = []&lt;br/&gt;flag = 1&lt;br/&gt;username=input(&quot;please input user :&quot;)     #输入用户名&lt;p&gt;f = open('bleak_user','r')                #打开文件  只读&lt;br/&gt;lock_file = f.readlines()                 #以行模式读出来&lt;br/&gt;f.close()                                 #关闭文件&lt;/p&gt;&lt;p&gt;for i in lock_file:                       #循环打开的文件&lt;br/&gt;line = i.strip('\n')                  #设置分隔符（行）&lt;br/&gt;lock.append(line)                     #添加到列表lock&lt;/p&gt;&lt;p&gt;if username  in lock:                     #if判断&lt;br/&gt;print(&quot;%s 在黑名单里 !!&quot; %username)     #打印输出&lt;br/&gt;else:                                      #否则进入循环&lt;br/&gt;while True:&lt;br/&gt;count += 1                         #count + 1 =count&lt;br/&gt;passwd = input(&quot;please input passwd :&quot;)&lt;br/&gt;f = open('user_info','r')          #打开user_info文件  只读&lt;br/&gt;user_file=f.readlines()            #以行读文件&lt;br/&gt;#        print(type(user_file),&quot;------------------&quot;)&lt;br/&gt;#        print(user_file)&lt;br/&gt;f.close()                           #关闭&lt;br/&gt;for i in user_file:                 #循环&lt;br/&gt;user_pass = i.strip().split(',') #格式化文件，去掉字符串头尾，以，分割文件&lt;br/&gt;#            print(user_pass)&lt;br/&gt;#            print(type(user_pass))&lt;br/&gt;if username ==user_pass[0] and passwd ==user_pass[1]:    #判断是否属于&lt;br/&gt;flag = True                                           #真&lt;br/&gt;break      　　　　　　　　　　　　     　　　　　　　　　　　#结束循环&lt;br/&gt;else:&lt;br/&gt;continue                             　　　　　　　　　　　#返回循环头&lt;/p&gt;&lt;p&gt;if flag is True:&lt;br/&gt;print('恭喜，登陆成功！')&lt;br/&gt;break&lt;br/&gt;else:&lt;br/&gt;if count == 3:                           #输入错误&lt;br/&gt;print(&quot;尝试三次后，密码错误，&quot;)         &lt;br/&gt;lock_file=open('bleak_user','a')      #以追加打开文件    &lt;br/&gt;lock_file.write('%s\n' %username)     #写入输入错误3次的用户名，&lt;br/&gt;lock_file.close()                     #关闭文件&lt;br/&gt;break                                 #结束循环
&lt;/p&gt;&lt;/pre&gt;</description>
<pubDate>Tue, 06 Mar 2018 07:51:00 +0000</pubDate>
<dc:creator>印第安老瓶子</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/wangcc7/p/8514778.html</dc:identifier>
</item>
<item>
<title>Unity引擎与C#脚本简介 - 腾讯云+社区</title>
<link>http://www.cnblogs.com/qcloud1001/p/8514781.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/qcloud1001/p/8514781.html</guid>
<description>&lt;p&gt;欢迎大家前往&lt;a href=&quot;https://cloud.tencent.com/developer&quot; target=&quot;_blank&quot;&gt;腾讯云+社区&lt;/a&gt;，获取更多腾讯海量技术实践干货哦~&lt;/p&gt;
&lt;blockquote readability=&quot;2.7777777777778&quot;&gt;
&lt;p&gt;由 &lt;a href=&quot;https://cloud.tencent.com/developer/user/156648&quot; target=&quot;_blank&quot;&gt;QQ会员技术团队&lt;/a&gt; 发布在云+社区&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;1. Unity编辑器基础&lt;/h2&gt;
&lt;p&gt;从原理上讲，游戏开发就是将一系列变动的场景呈现在玩家面前，并根据玩家的输入修改游戏画面；而游戏画面则是通过调用目标操作系统上的图形图像库来绘制的。比较知名的图形图像库有Windows上的DirectX，*nix系统、macOS和iOS等系统上用到的OpenGL以及Android用到的Vulkan等。&lt;/p&gt;
&lt;p&gt;一般来讲，底层的图形图像API只能进行最基本的三角形绘制，但是，因为是通过计算机的GPU进行的操作，具有并行计算的优势，在短短六十分之一秒时间内，也可以绘制出成千上万个三角形，而这么多小三角形堆叠起来看，视觉效果也就和真实场景差别不大了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ask.qcloudimg.com/http-save/yehe-156648/4qndosog9v.jpeg?imageView2/0/w/1620&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;[ 图一：古墓丽影劳拉变化图 ]&lt;/p&gt;
&lt;p&gt;现代游戏引擎一般都会把游戏人物的“建模”工作交给第三方，引擎本身只负责游戏场景和人物的绘制以及内部交互逻辑。第三方建模软件通过模拟人物的真实3D外观来将虚拟人物表面“三角形化”，附带上游戏人物在做出不同动作时的外观数据，最后生成游戏引擎可识别格式的文件，这个过程就是所谓的3D建模。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ask.qcloudimg.com/http-save/yehe-156648/j93aanrfum.jpeg?imageView2/0/w/1620&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;[ 图二：绘制流程 ]&lt;/p&gt;
&lt;p&gt;3D模型制作完成后，会由游戏引擎进行绘制，这个过程一般称作“着色”（Shading）。着色的核心是叫做“着色器(Shader)”的GPU程序 - GPU通过输入一些参数信息，然后执行着色器程序就能生成最终的游戏图像。&lt;/p&gt;
&lt;p&gt;GPU需要的参数信息主要有两种：一是纹理，二是材质。&lt;/p&gt;
&lt;p&gt;纹理是指一个模型的表面，可以理解成一件衣服平铺起来的样子。如果是一个三维物体，其表面的纹理可以想象成是把它的表面拆开，然后压扁后的样子。什么是材质呢？材质（Material）从字面上理解的话就是材料，比如木头和大理石，看起来就是不一样的效果。同样的纹理，用不一样的材质来绘制，会得到不一样的效果图，因为材质有一些关键的参数，会影响着色器的绘制效果。&lt;/p&gt;
&lt;p&gt;比较重要的一个参数是反射率(Albedo)。&lt;/p&gt;
&lt;p&gt;光滑材质的反射率比较高，看起来就会亮一些。在自然白光的照射下，这样的材质看起来会偏白，如果沿着光照方向看过去，会出现光斑效果（太阳光照射下的湖面看起来会有一种很耀眼的效果）。粗糙材质的反射率比较低，看起来就比较柔和。典型的高反射率材质比如光滑的金属表面，典型的低反射率材质有布料、地面等。在3D场景中，反射率高的物体受周围物体的影响更大。譬如，一个平静的湖面会倒映出地面的建筑物。因此，高反射率的材质通常需要更多的绘制步骤。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ask.qcloudimg.com/http-save/yehe-156648/9butb5mqpi.jpeg?imageView2/0/w/1620&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;[ 图三：一个金属球体在场景中的效果图 ]&lt;/p&gt;
&lt;p&gt;材质的另一个重要参数是法向图(Normal Map)。&lt;/p&gt;
&lt;p&gt;法向就是物体表面的方向。法向图表示的是材质的表面细节，比如凹槽、斑点、凸起或者空洞等，法向图通常以纹理图来表示。然而不同于一般的纹理图，法向图的每个像素点称作“纹素（texel）”，它表示的是纹理在此位置处的光照反射方向，纹素的RGB分量分别对应反射方向的XYZ分量。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ask.qcloudimg.com/http-save/yehe-156648/qgn1k0dcur.jpeg?imageView2/0/w/1620&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;[ 图四：法向图示例 ]&lt;/p&gt;
&lt;p&gt;一个3D模型的表面纹理被分割成一个个小三角形，而法向图就表示此表面的每个像素点位置的光照反射方向。方向不同的三角形绘制出来和周围的三角形看起来颜色是不同的，从而产生了视觉上的凸起/凹陷效果。这种物体的表面细节，如果在3D建模阶段通过修改模型外观的方式来实现的话，会增加很多物体表面的细小的绘制操作。通过材质的法向图来实现，将物体“表面”和物体的实际皮肤剥离开了，可以实现同一个人物穿上不同衣服的效果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ask.qcloudimg.com/http-save/yehe-156648/wbs7yc3ar4.jpeg?imageView2/0/w/1620&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;[ 图五：绘制效果图 ]&lt;/p&gt;
&lt;p&gt;如上图所示，右边的物体采用左边的法向图来绘制，注意看凸起位置的颜色&lt;/p&gt;
&lt;h2&gt;2. C#脚本语言&lt;/h2&gt;
&lt;h3&gt;2.1 为什么需要脚本？&lt;/h3&gt;
&lt;p&gt;长久以来，游戏引擎开发都采用底层语言如C++来进行，这对于游戏上层开发来说，并不友好。很难想象如果使用一款引擎修改某个人物的动作，还需要直接调用C++底层的接口，这样既不安全，也不方便。因此，一般引擎从设计之初就会把封装好的绘制接口通过某些上层语言暴露出来，给游戏制作方使用。这些上层语言就叫做游戏脚本语言。&lt;/p&gt;
&lt;p&gt;lua是脚本语言里面比较流行的一种，因其虚拟机小巧、API丰富、可灵活定制而深受游戏引擎开发商的喜爱。Unity使用了C#和Unity Script（现已废弃）来作为脚本语言。C#语言因为建立在.NET IL之上而具有跨平台扩展性。这样，游戏开发者只需要一套代码就可在多个平台运行。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ask.qcloudimg.com/http-save/yehe-156648/0lrrzlig6p.jpeg?imageView2/0/w/1620&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;[ 图六：.NET CIL和CLR ]&lt;/p&gt;
&lt;h3&gt;2.2 IL是什么？&lt;/h3&gt;
&lt;p&gt;IL（Intermediate Language，在.NET平台下是CIL，Common Intermediate Language）是一种中间语言格式，类似于Java的字节码（byte code），这种格式的代码需要一个虚拟机来“解释”执行。IL的所有指令都是基于虚拟堆栈的：调用函数前，先将参数push到虚拟堆栈里面；函数执行的时候，从虚拟堆栈里面取出参数，然后将结果压入虚拟堆栈。由于调用方式简单，IL语言的指令集也比较精简。&lt;/p&gt;
&lt;p&gt;IL作为脚本语言的独到之处在于可以将C#上层语言的各种特性（如泛型、协程等）转换成基本的IL指令集，但是这样的转换也是有代价的 — 转换后的IL指令比普通的函数调用多出数倍。因此，在游戏开发中，不宜在每一帧中都进行这一类的调用。&lt;/p&gt;
&lt;p&gt;另外，IL语言执行需要一个虚拟机翻译成目标平台的机器码，虽然.NET虚拟机已经比较高效了（可参考.NET与Java的对比），但是和平台原生代码比起来，依然有一些差距。在iOS平台上，由于苹果禁止使用JIT方式，IL指令需要预先编译成目标平台库文件，然后在最终二进制文件打包的时候作为第三方库链接进去。Unity游戏几乎所有的游戏逻辑都是通过脚本来实现的，一个大型游戏，成千上万个脚本，AOT方式打包造成的效率低下，是不得不考虑的问题。因此，Unity在5.3.4版本中引入了il2cpp技术。&lt;/p&gt;
&lt;h3&gt;2.3 il2cpp原理&lt;/h3&gt;
&lt;p&gt;顾名思义，il2cpp就是把中间语言转换成cpp代码的工具。上面我们讲到，在iOS平台上，由于无法使用JIT方式执行IL指令，所以需要先将游戏脚本打包成.NET Managed Assembly（这里的Managed是指二进制文件是在.NET层面打包的，可能会依赖.NET底层库，可以理解为“安全的”库文件。另外有些库文件是通过直接封装C/C++接口方式生成的，由于有如指针之类的底层内存操作，所以称作是Unmanaged Assembly），然后和.NET CLR的Assembly链接之后生成最终的平台二进制文件。il2cpp的作用是去掉链接.NET CLR的步骤，将C#脚本生成的Managed Assembly“翻译”成C++文件，最后用目标平台的编译器编译这些C++文件来生成最终的游戏可执行文件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ask.qcloudimg.com/http-save/yehe-156648/ytjrwnjh9h.jpeg?imageView2/0/w/1620&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;[ 图七：il2cpp工作原理示意图 ]&lt;/p&gt;
&lt;p&gt;il2cpp会先读取.NET二进制文件，解析其中的符号，然后将其中C#方法转换成对应的C方法。虽然名为il2cpp，但其实它只用到了很少部分的C++特性，绝大多数转换后的代码都是C函数。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://ask.qcloudimg.com/http-save/yehe-156648/or1cakstie.jpeg?imageView2/0/w/1620&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;[ 图八：il2cpp转换后的代码示例 ]&lt;/p&gt;
&lt;p&gt;在游戏运行前，il2cpp会启动一个小的虚拟机，用于动态解析C方法。其会将所有方法的签名放在一个叫做global-metadata.dat的文件里，方法调用的时候会先从此文件里读取C函数地址，然后再调用。&lt;/p&gt;
&lt;p&gt;获取函数指针的方法是这个：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
inline Il2CppMethodPointer il2cpp_codegen_resolve_icall (&lt;span&gt;const&lt;/span&gt; &lt;span&gt;char&lt;/span&gt;*&lt;span&gt; name){
    Il2CppMethodPointer method &lt;/span&gt;= il2cpp::vm::InternalCalls::Resolve (name);    &lt;span&gt;if&lt;/span&gt; (!&lt;span&gt;method)
    {
        il2cpp::vm::Exception::Raise(il2cpp::vm::Exception::GetMissingMethodException(name));
    }    &lt;/span&gt;&lt;span&gt;return&lt;/span&gt;&lt;span&gt; method;
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;[ 图九：获取函数指针 ]&lt;/p&gt;
&lt;p&gt;Unity确保了所有采用il2cpp平台实现的游戏，其metadata的格式都是一样的。metadata加载时采用了内存映射技术，上述函数实际上会从一张内存的数据表里查找方法名对应的键值，也即目标函数的地址。&lt;/p&gt;
&lt;p&gt;为何Unity要采用文件来记录方法名？一是游戏有动态解析方法的需求；再者是这样可以隐藏掉游戏内部逻辑的实现，起到一部分混淆的作用；最后还有一个重要的原因是Unity编辑器里可以设置脚本执行时候的延迟时间，而这些信息可以很方便的放在文件里。&lt;/p&gt;
&lt;p&gt;Unity C#层面的接口暴露给游戏开发者，开发者通过C#脚本编写游戏逻辑，然后通过il2cpp将脚本翻译成C++文件，接着链接上Unity C#接口的底层C++实现，最终生成游戏的二进制文件，这就是Unity游戏开发的大致过程。&lt;/p&gt;
&lt;p&gt;按照Unity的说法，通过il2cpp方式打包有多种好处：&lt;/p&gt;
&lt;ol class=&quot;ol-level-0&quot;&gt;&lt;li&gt;跨平台兼容性更好。基本上所有游戏平台都支持C++代码，而.NET/Mono运行时却不一定能在所有平台上运行；&lt;/li&gt;
&lt;li&gt;效率更高。Unity给出的数据显示采用il2cpp打包之后，游戏的执行效率提升了1.5到2.0倍。&lt;/li&gt;
&lt;/ol&gt;&lt;p&gt;以上就是游戏开发的一些基本知识。&lt;/p&gt;
&lt;h2&gt;相关阅读&lt;/h2&gt;
&lt;p&gt;&lt;span data-sheets-value=&quot;{&amp;quot;1&amp;quot;:2,&amp;quot;2&amp;quot;:&amp;quot;基于腾讯云的视频聊天研究&amp;quot;}&quot; data-sheets-userformat=&quot;{&amp;quot;2&amp;quot;:1,&amp;quot;3&amp;quot;:[null,0]}&quot;&gt;&lt;a class=&quot;in-cell-link&quot; href=&quot;https://cloud.tencent.com/developer/article/1005508&quot; target=&quot;_blank&quot;&gt;基于腾讯云的视频聊天研究&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-sheets-value=&quot;{&amp;quot;1&amp;quot;:2,&amp;quot;2&amp;quot;:&amp;quot;基于腾讯云的视频聊天研究&amp;quot;}&quot; data-sheets-userformat=&quot;{&amp;quot;2&amp;quot;:1,&amp;quot;3&amp;quot;:[null,0]}&quot;&gt;&lt;span data-sheets-value=&quot;{&amp;quot;1&amp;quot;:2,&amp;quot;2&amp;quot;:&amp;quot;ios微信内存监控&amp;quot;}&quot; data-sheets-userformat=&quot;{&amp;quot;2&amp;quot;:1,&amp;quot;3&amp;quot;:[null,0]}&quot;&gt;&lt;a class=&quot;in-cell-link&quot; href=&quot;https://cloud.tencent.com/developer/article/1048715&quot; target=&quot;_blank&quot;&gt;ios微信内存监控&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-sheets-value=&quot;{&amp;quot;1&amp;quot;:2,&amp;quot;2&amp;quot;:&amp;quot;2017年数据库技术盘点&amp;quot;}&quot; data-sheets-userformat=&quot;{&amp;quot;2&amp;quot;:1,&amp;quot;3&amp;quot;:[null,0]}&quot;&gt;&lt;a class=&quot;in-cell-link&quot; href=&quot;https://cloud.tencent.com/developer/article/1047725&quot; target=&quot;_blank&quot;&gt;2017年数据库技术盘点&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;p&gt;&lt;span data-sheets-value=&quot;{&amp;quot;1&amp;quot;:2,&amp;quot;2&amp;quot;:&amp;quot;2017年数据库技术盘点&amp;quot;}&quot; data-sheets-userformat=&quot;{&amp;quot;2&amp;quot;:1,&amp;quot;3&amp;quot;:[null,0]}&quot;&gt;此文已由作者授权腾讯云+社区发布，转载请注明&lt;a href=&quot;https://cloud.tencent.com/developer/article/1047768&quot; target=&quot;_blank&quot;&gt;文章出处&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span data-sheets-value=&quot;{&amp;quot;1&amp;quot;:2,&amp;quot;2&amp;quot;:&amp;quot;2017年数据库技术盘点&amp;quot;}&quot; data-sheets-userformat=&quot;{&amp;quot;2&amp;quot;:1,&amp;quot;3&amp;quot;:[null,0]}&quot;&gt;原文链接：&lt;a href=&quot;https://cloud.tencent.com/developer/article/1047768&quot; target=&quot;_blank&quot;&gt;https://cloud.tencent.com/developer/article/1047768&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 06 Mar 2018 07:51:00 +0000</pubDate>
<dc:creator>腾讯云+社区</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/qcloud1001/p/8514781.html</dc:identifier>
</item>
<item>
<title>浅谈 Glide - BitmapPool 的存储时机 &amp; 解答 ViewTarget 在同一View显示不同的图片时，总用同一个 Bitmap 引用的原因 - 指尖下的幽灵</title>
<link>http://www.cnblogs.com/linguanh/p/8514643.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/linguanh/p/8514643.html</guid>
<description>&lt;blockquote readability=&quot;5&quot;&gt;
&lt;p&gt;作者：林冠宏 / 指尖下的幽灵&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;0.80357142857143&quot;&gt;
&lt;p&gt;掘金：&lt;a href=&quot;https://juejin.im/user/587f0dfe128fe100570ce2d8&quot; class=&quot;uri&quot;&gt;https://juejin.im/user/587f0dfe128fe100570ce2d8&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;1.0975609756098&quot;&gt;
&lt;p&gt;博客：&lt;a href=&quot;http://www.cnblogs.com/linguanh/&quot; class=&quot;uri&quot;&gt;http://www.cnblogs.com/linguanh/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;1.3095238095238&quot;&gt;
&lt;p&gt;GitHub ： &lt;a href=&quot;https://github.com/af913337456/&quot; class=&quot;uri&quot;&gt;https://github.com/af913337456/&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote readability=&quot;1.2179487179487&quot;&gt;
&lt;p&gt;腾讯云专栏： &lt;a href=&quot;https://cloud.tencent.com/developer/user/1148436/activities&quot; class=&quot;uri&quot;&gt;https://cloud.tencent.com/developer/user/1148436/activities&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr/&gt;&lt;p&gt;这两天在改造我的私人APP &lt;a href=&quot;https://coolapk.com/apk/com.example.asus.lghwxautoreply&quot;&gt;非ROOT版微信自动回复&lt;/a&gt;， 使之可以&lt;code&gt;多开&lt;/code&gt;的时候，碰到一个这样的问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Glide 在使用&lt;code&gt;默认的Targer方式下&lt;/code&gt;，同一个 View 加载不同 &lt;code&gt;URL&lt;/code&gt; 图片的时候，返回的 &lt;code&gt;Bitmap 引用地址&lt;/code&gt;是一样的，但图片像素不一样。默认的 Target 有 ： BitmapImageViewTarget.java，DrawableImageViewTarget.java&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;默认的方式代码如下:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;19&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;
&lt;span class=&quot;kw&quot;&gt;private&lt;/span&gt; Bitmap lastTimeQrCodeBitmap;

&lt;span class=&quot;kw&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;showQrCodeImage&lt;/span&gt;(&lt;span class=&quot;dt&quot;&gt;final&lt;/span&gt; ImageView i){
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt;(wechatCoreApi == &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;)
        &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;;
    Glide.&lt;span class=&quot;fu&quot;&gt;with&lt;/span&gt;(context)
            .&lt;span class=&quot;fu&quot;&gt;load&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&quot;xxxxxxxxxxxxxxxxxxx&quot;&lt;/span&gt;)
            .&lt;span class=&quot;fu&quot;&gt;asBitmap&lt;/span&gt;()
            .&lt;span class=&quot;fu&quot;&gt;override&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;400&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;400&lt;/span&gt;)
            .&lt;span class=&quot;fu&quot;&gt;skipMemoryCache&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;true&lt;/span&gt;)
            .&lt;span class=&quot;fu&quot;&gt;listener&lt;/span&gt;(
                    &lt;span class=&quot;kw&quot;&gt;new&lt;/span&gt; RequestListener&amp;lt;String, Bitmap&amp;gt;() {
                        &lt;span class=&quot;fu&quot;&gt;@Override&lt;/span&gt;
                        &lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;onException&lt;/span&gt;(Exception e, String model, Target&amp;lt;Bitmap&amp;gt; target, &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; isFirstResource) {
                            &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;false&lt;/span&gt;;
                        }
    
                        &lt;span class=&quot;fu&quot;&gt;@Override&lt;/span&gt;
                        &lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;onResourceReady&lt;/span&gt;(Bitmap resource, String model, Target&amp;lt;Bitmap&amp;gt; target, &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; isFromMemoryCache, &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; isFirstResource) {
                            &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt;(resource != &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;){
                                &lt;span class=&quot;co&quot;&gt;// 这里打印出加载回来的 Bitmap 的内存地址&lt;/span&gt;
                                LogUitls.&lt;span class=&quot;fu&quot;&gt;e&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&quot;resource ===&amp;gt; &quot;&lt;/span&gt;+resource.&lt;span class=&quot;fu&quot;&gt;toString&lt;/span&gt;());
                                lastTimeQrCodeBitmap = resource;
                            }
                            &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;false&lt;/span&gt;;
                        }
                    }
            )
            .&lt;span class=&quot;fu&quot;&gt;into&lt;/span&gt;(i);
    }&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;很普通的一个函数，没过多的操作，仅仅是在 &lt;code&gt;onResourceReady&lt;/code&gt; 处做了加载回来的 &lt;code&gt;Bitmap&lt;/code&gt; 的保存工作。之所要保存它，是因为这个&lt;code&gt;APP要实现多开&lt;/code&gt;，每一个页面其对应的有一个&lt;code&gt;二维码图片&lt;/code&gt;，每一个二维码图片的 bitmap 是不同的，这样在切换的时候，就可以对应显示出属于当前页面的 bitmap。&lt;/p&gt;
&lt;p&gt;上面说的是存每个页面对应的 Bitmap，却没有去存 &lt;code&gt;ImageView&lt;/code&gt;，你可能会问为什么？原因就是为了&lt;code&gt;节省一个 ImageView 的内存&lt;/code&gt;，如果存 ImageView，它自然也携带了当前的 Bitmap 内存，以及它内部的其他变量的内存等。如果单独存 Bitmap，这样在APP中切换页面的时候，其实也就是切换数据，更新数据即可。&lt;/p&gt;
&lt;h4 id=&quot;结合上面的语言来看那么上面代码应该是没问题的而事实上是有问题因为同时具备了下面两点&quot;&gt;结合上面的语言来看，那么上面代码应该是没问题的。而事实上是有问题，因为同时具备了&lt;code&gt;下面两点&lt;/code&gt;：&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;传参进来的 ImageView 总是同一个，即 &lt;code&gt;into(ImageView)&lt;/code&gt;，&lt;code&gt;ImageView&lt;/code&gt; 总是同一个&lt;/li&gt;
&lt;li&gt;使用了默认的 &lt;code&gt;into(ImageView)&lt;/code&gt; 函数，这个内部默认使用了&lt;code&gt;BitmapImageViewTarget&lt;/code&gt;:&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;code&gt;BitmapImageViewTarget extends ImageViewTarget extends ViewTarget extends BaseTarget&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这两点就导致了，在 &lt;code&gt;onResourceReady&lt;/code&gt; 返回的 &lt;code&gt;resource&lt;/code&gt; 内存地址总是同一个。简单修改以下，打破上面两点任一一点，就能验证，例如下面的代码，我们不采用继承于 &lt;code&gt;ViewTarger&lt;/code&gt; 的 &lt;code&gt;Target&lt;/code&gt;。而使用 &lt;code&gt;SimpleTarget extends BaseTarget&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;20&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt; Glide.&lt;span class=&quot;fu&quot;&gt;with&lt;/span&gt;(context)
        .&lt;span class=&quot;fu&quot;&gt;load&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&quot;xxxxxx&quot;&lt;/span&gt;)
        .&lt;span class=&quot;fu&quot;&gt;asBitmap&lt;/span&gt;()
        .&lt;span class=&quot;fu&quot;&gt;override&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;400&lt;/span&gt;,&lt;span class=&quot;dv&quot;&gt;400&lt;/span&gt;)
        .&lt;span class=&quot;fu&quot;&gt;skipMemoryCache&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;true&lt;/span&gt;)
        .&lt;span class=&quot;fu&quot;&gt;listener&lt;/span&gt;(
                &lt;span class=&quot;kw&quot;&gt;new&lt;/span&gt; RequestListener&amp;lt;String, Bitmap&amp;gt;() {
                    &lt;span class=&quot;fu&quot;&gt;@Override&lt;/span&gt;
                    &lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;onException&lt;/span&gt;(Exception e, String model, Target&amp;lt;Bitmap&amp;gt; target, &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; isFirstResource) {
                        &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;false&lt;/span&gt;;
                    }

                    &lt;span class=&quot;fu&quot;&gt;@Override&lt;/span&gt;
                    &lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;onResourceReady&lt;/span&gt;(Bitmap resource, String model, Target&amp;lt;Bitmap&amp;gt; target, &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; isFromMemoryCache, &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; isFirstResource) {
                        &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt;(resource != &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;){
                            LogUitls.&lt;span class=&quot;fu&quot;&gt;e&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;&quot;resource ===&amp;gt; &quot;&lt;/span&gt;+resource.&lt;span class=&quot;fu&quot;&gt;toString&lt;/span&gt;());
                            lastTimeQrCodeBitmap = resource;
                            i.&lt;span class=&quot;fu&quot;&gt;setImageBitmap&lt;/span&gt;(lastTimeQrCodeBitmap); &lt;span class=&quot;co&quot;&gt;// 手动显示&lt;/span&gt;
                        }
                        &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;false&lt;/span&gt;;
                    }
                }
        )
        .&lt;span class=&quot;fu&quot;&gt;into&lt;/span&gt;(
                &lt;span class=&quot;kw&quot;&gt;new&lt;/span&gt; SimpleTarget&amp;lt;Bitmap&amp;gt;() {
                    &lt;span class=&quot;fu&quot;&gt;@Override&lt;/span&gt;
                    &lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;onResourceReady&lt;/span&gt;(Bitmap resource, GlideAnimation&amp;lt;? &lt;span class=&quot;kw&quot;&gt;super&lt;/span&gt; Bitmap&amp;gt; glideAnimation) {
                        &lt;span class=&quot;co&quot;&gt;// 这里的 onResourceReady:resource 和上面的是一样的&lt;/span&gt;
                    }
                }
        );&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这个时候依然传参是同一个 &lt;code&gt;ImageView&lt;/code&gt; 也&lt;code&gt;不会&lt;/code&gt;造成 &lt;code&gt;onResourceReady&lt;/code&gt; 返回的 &lt;code&gt;resource&lt;/code&gt; 内存地址总是同一个的情况。&lt;/p&gt;
&lt;h3 id=&quot;那么到底是什么原因导致了&quot;&gt;那么到底是什么原因导致了：&lt;/h3&gt;
&lt;h4 id=&quot;glide-在满足下面两点的时候加载返回的-bitmap-引用地址是一样的但图片像素不一样&quot;&gt;Glide 在满足下面两点的时候，加载返回的 &lt;code&gt;Bitmap 引用地址&lt;/code&gt;是一样的，但图片像素不一样？&lt;/h4&gt;
&lt;ul&gt;&lt;li&gt;传参进来的 ImageView 总是同一个，即 &lt;code&gt;into(ImageView)&lt;/code&gt;，&lt;code&gt;ImageView&lt;/code&gt; 总是同一个&lt;/li&gt;
&lt;li&gt;使用了默认的 &lt;code&gt;into(ImageView)&lt;/code&gt; 函数，这个内部默认使用了&lt;code&gt;BitmapImageViewTarget&lt;/code&gt;:&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;code&gt;BitmapImageViewTarget extends ImageViewTarget extends ViewTarget extends BaseTarget&lt;/code&gt;&lt;/p&gt;
&lt;h4 id=&quot;为了解答此问题我在网上搜索了很多几乎不沾边后面通过分析源码-和-调试源码找出调用链得到如下的答案&quot;&gt;为了解答此问题，我在网上搜索了很多，几乎不沾边。后面通过&lt;code&gt;分析源码&lt;/code&gt; 和 &lt;code&gt;调试源码找出调用链&lt;/code&gt;得到如下的答案。&lt;/h4&gt;
&lt;p&gt;我先给出结论，下面再做基于 &lt;code&gt;Glide 4.0&lt;/code&gt; 的源码简析。&lt;/p&gt;
&lt;ol readability=&quot;2.5&quot;&gt;&lt;li readability=&quot;1&quot;&gt;
&lt;p&gt;&lt;code&gt;ViewTarget&lt;/code&gt; 内部使用 &lt;code&gt;View.setTag&lt;/code&gt; 做了 &lt;code&gt;Request&lt;/code&gt; 的缓存保存。导致同一个 &lt;code&gt;View&lt;/code&gt; 多次传入 &lt;code&gt;into(...)&lt;/code&gt;&lt;br/&gt;方法的时候，总能找到上一次请求的 &lt;code&gt;Request&lt;/code&gt;。&lt;code&gt;Request&lt;/code&gt; 是 &lt;code&gt;Glide&lt;/code&gt; 源码里面的一个接口，这里的缓存保存是保存的都是它的实现类。&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;glide&lt;/code&gt; 默认的加载形式中 &lt;code&gt;Target&lt;/code&gt; 都继承了 &lt;code&gt;ViewTarget&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;-1&quot;&gt;
&lt;p&gt;&lt;code&gt;SimpleTarget&lt;/code&gt; 没有继承 &lt;code&gt;ViewTarget&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;glide&lt;/code&gt; 在每次请求开始的时候会去调用 &lt;code&gt;target.getRequest()&lt;/code&gt;，如果获取的 &lt;code&gt;request&lt;/code&gt; 不为 &lt;code&gt;null&lt;/code&gt;，那么它就会去释放上一个请求的一些资源，最后会调用到 &lt;code&gt;BitmapPool.put(Bitmap)&lt;/code&gt; 把上一次的 &lt;code&gt;Bitmap&lt;/code&gt; 缓存起来。如果 &lt;code&gt;request&lt;/code&gt; 获取的是 null，那么就不会缓存上一次加载成功的 &lt;code&gt;Bitmap&lt;/code&gt;。&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;最后在加载图片并解码完成后，在从 &lt;code&gt;BitmapPool&lt;/code&gt; 中寻找缓存的时候，就能找到上面的缓存的，擦除像素，加入新图片的像素，最终返回 &lt;code&gt;Bitmap&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;&lt;h4 id=&quot;其中第4点就是-bitmappool-的存储时机具体见下面的源码简析&quot;&gt;其中第4点就是 &lt;code&gt;BitmapPool&lt;/code&gt; 的存储时机。具体见下面的源码简析&lt;/h4&gt;
&lt;h2 id=&quot;源码简析&quot;&gt;源码简析：&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Glide&lt;/code&gt; 的 &lt;code&gt;into&lt;/code&gt; 方法，位于 &lt;code&gt;RequestBuilder.java&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;16&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span class=&quot;kw&quot;&gt;private&lt;/span&gt; &amp;lt;Y &lt;span class=&quot;kw&quot;&gt;extends&lt;/span&gt; Target&amp;lt;TranscodeType&amp;gt;&amp;gt; Y &lt;span class=&quot;fu&quot;&gt;into&lt;/span&gt;(
      &lt;span class=&quot;fu&quot;&gt;@NonNull&lt;/span&gt; Y target,
      &lt;span class=&quot;fu&quot;&gt;@Nullable&lt;/span&gt; RequestListener&amp;lt;TranscodeType&amp;gt; targetListener,
      &lt;span class=&quot;fu&quot;&gt;@NonNull&lt;/span&gt; RequestOptions options) 
{
    Util.&lt;span class=&quot;fu&quot;&gt;assertMainThread&lt;/span&gt;();
    Preconditions.&lt;span class=&quot;fu&quot;&gt;checkNotNull&lt;/span&gt;(target);
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (!isModelSet) {
      &lt;span class=&quot;kw&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;new&lt;/span&gt; IllegalArgumentException(&lt;span class=&quot;st&quot;&gt;&quot;You must call #load() before calling #into()&quot;&lt;/span&gt;);
    }
    options = options.&lt;span class=&quot;fu&quot;&gt;autoClone&lt;/span&gt;();
    Request request = &lt;span class=&quot;fu&quot;&gt;buildRequest&lt;/span&gt;(target, targetListener, options);

    Request previous = target.&lt;span class=&quot;fu&quot;&gt;getRequest&lt;/span&gt;();
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (request.&lt;span class=&quot;fu&quot;&gt;isEquivalentTo&lt;/span&gt;(previous) &amp;amp;&amp;amp; !&lt;span class=&quot;fu&quot;&gt;isSkipMemoryCacheWithCompletePreviousRequest&lt;/span&gt;(options, previous))
    {
        request.&lt;span class=&quot;fu&quot;&gt;recycle&lt;/span&gt;();
        previous.&lt;span class=&quot;fu&quot;&gt;begin&lt;/span&gt;();
      }
      &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; target;
    }
    requestManager.&lt;span class=&quot;fu&quot;&gt;clear&lt;/span&gt;(target);  &lt;span class=&quot;co&quot;&gt;// 进入这里&lt;/span&gt;
    target.&lt;span class=&quot;fu&quot;&gt;setRequest&lt;/span&gt;(request);
    requestManager.&lt;span class=&quot;fu&quot;&gt;track&lt;/span&gt;(target, request);

    &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; target;
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;进入 &lt;code&gt;requestManager.clear(target);&lt;/code&gt; 里面。位于 &lt;code&gt;RequestManager.java&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;clear&lt;/span&gt;(&lt;span class=&quot;fu&quot;&gt;@Nullable&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;final&lt;/span&gt; Target&amp;lt;?&amp;gt; target) {
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (target == &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;) {
      &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;;
    }
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (Util.&lt;span class=&quot;fu&quot;&gt;isOnMainThread&lt;/span&gt;()) {
      &lt;span class=&quot;fu&quot;&gt;untrackOrDelegate&lt;/span&gt;(target); &lt;span class=&quot;co&quot;&gt;// 进入这里 --- ①&lt;/span&gt;
    } &lt;span class=&quot;kw&quot;&gt;else&lt;/span&gt; {
      mainHandler.&lt;span class=&quot;fu&quot;&gt;post&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;new&lt;/span&gt; Runnable() {
        &lt;span class=&quot;fu&quot;&gt;@Override&lt;/span&gt;
        &lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;run&lt;/span&gt;() {
          &lt;span class=&quot;fu&quot;&gt;clear&lt;/span&gt;(target); &lt;span class=&quot;co&quot;&gt;// 如果是子线程调用 glide，那么最终 post 了这个 msg 也是进入到上面 ① 处&lt;/span&gt;
        }
      });
    }
  }
  
  
&lt;span class=&quot;kw&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;untrackOrDelegate&lt;/span&gt;(&lt;span class=&quot;fu&quot;&gt;@NonNull&lt;/span&gt; Target&amp;lt;?&amp;gt; target) {
    &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; isOwnedByUs = &lt;span class=&quot;fu&quot;&gt;untrack&lt;/span&gt;(target); &lt;span class=&quot;co&quot;&gt;// 进入这里&lt;/span&gt;
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (!isOwnedByUs &amp;amp;&amp;amp; !glide.&lt;span class=&quot;fu&quot;&gt;removeFromManagers&lt;/span&gt;(target) &amp;amp;&amp;amp; target.&lt;span class=&quot;fu&quot;&gt;getRequest&lt;/span&gt;() != &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;) {
      Request request = target.&lt;span class=&quot;fu&quot;&gt;getRequest&lt;/span&gt;();
      target.&lt;span class=&quot;fu&quot;&gt;setRequest&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;);
      request.&lt;span class=&quot;fu&quot;&gt;clear&lt;/span&gt;();
    }
}

&lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;untrack&lt;/span&gt;(&lt;span class=&quot;fu&quot;&gt;@NonNull&lt;/span&gt; Target&amp;lt;?&amp;gt; target) {
    Request request = target.&lt;span class=&quot;fu&quot;&gt;getRequest&lt;/span&gt;();
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (request == &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;) {  &lt;span class=&quot;co&quot;&gt;// 对应结论中的第一点，如果是同一个 View，那么它不为 null&lt;/span&gt;
      &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;true&lt;/span&gt;;
    }
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (requestTracker.&lt;span class=&quot;fu&quot;&gt;clearRemoveAndRecycle&lt;/span&gt;(request)) { &lt;span class=&quot;co&quot;&gt;// 不为 null，进入这里的判断&lt;/span&gt;
      targetTracker.&lt;span class=&quot;fu&quot;&gt;untrack&lt;/span&gt;(target);
      target.&lt;span class=&quot;fu&quot;&gt;setRequest&lt;/span&gt;(&lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;);
      &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;true&lt;/span&gt;;
    } &lt;span class=&quot;kw&quot;&gt;else&lt;/span&gt; {
      &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;false&lt;/span&gt;;
    }
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;进入到 &lt;code&gt;clearRemoveAndRecycle&lt;/code&gt;，位于 &lt;code&gt;RequestTracker.java&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;12&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;clearRemoveAndRecycle&lt;/span&gt;(&lt;span class=&quot;fu&quot;&gt;@Nullable&lt;/span&gt; Request request) {
    &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;clearRemoveAndMaybeRecycle&lt;/span&gt;(request, &lt;span class=&quot;co&quot;&gt;/*isSafeToRecycle=*/&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;true&lt;/span&gt;);
}

&lt;span class=&quot;kw&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;clearRemoveAndMaybeRecycle&lt;/span&gt;(&lt;span class=&quot;fu&quot;&gt;@Nullable&lt;/span&gt; Request request, &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; isSafeToRecycle) {
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (request == &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;) {
      &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;true&lt;/span&gt;;
    }
    &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; isOwnedByUs = requests.&lt;span class=&quot;fu&quot;&gt;remove&lt;/span&gt;(request); &lt;span class=&quot;co&quot;&gt;// 这里的 remove 是会返回 true 的，因为这个 request 不是 null&lt;/span&gt;
    isOwnedByUs = pendingRequests.&lt;span class=&quot;fu&quot;&gt;remove&lt;/span&gt;(request) || isOwnedByUs;
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (isOwnedByUs) {
      request.&lt;span class=&quot;fu&quot;&gt;clear&lt;/span&gt;(); &lt;span class=&quot;co&quot;&gt;// 最后进入这里，这里的 Request 的实现类是 SingleRequest&lt;/span&gt;
      &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (isSafeToRecycle) {
        request.&lt;span class=&quot;fu&quot;&gt;recycle&lt;/span&gt;();
      }
    }
    &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; isOwnedByUs;
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;进入 &lt;code&gt;SingleRequest.java&lt;/code&gt; 的 &lt;code&gt;clear()&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span class=&quot;fu&quot;&gt;@Override&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;clear&lt;/span&gt;() {
    Util.&lt;span class=&quot;fu&quot;&gt;assertMainThread&lt;/span&gt;();
    &lt;span class=&quot;fu&quot;&gt;assertNotCallingCallbacks&lt;/span&gt;();
    stateVerifier.&lt;span class=&quot;fu&quot;&gt;throwIfRecycled&lt;/span&gt;();
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (status == Status.&lt;span class=&quot;fu&quot;&gt;CLEARED&lt;/span&gt;) {
      &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt;;
    }
    &lt;span class=&quot;fu&quot;&gt;cancel&lt;/span&gt;();
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (resource != &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;) {
      &lt;span class=&quot;fu&quot;&gt;releaseResource&lt;/span&gt;(resource); &lt;span class=&quot;co&quot;&gt;// 进入这里&lt;/span&gt;
    }
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;fu&quot;&gt;canNotifyCleared&lt;/span&gt;()) {
      target.&lt;span class=&quot;fu&quot;&gt;onLoadCleared&lt;/span&gt;(&lt;span class=&quot;fu&quot;&gt;getPlaceholderDrawable&lt;/span&gt;());
    }
    status = Status.&lt;span class=&quot;fu&quot;&gt;CLEARED&lt;/span&gt;;
}

&lt;span class=&quot;kw&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;releaseResource&lt;/span&gt;(Resource&amp;lt;?&amp;gt; resource) {
    engine.&lt;span class=&quot;fu&quot;&gt;release&lt;/span&gt;(resource);
    &lt;span class=&quot;kw&quot;&gt;this&lt;/span&gt;.&lt;span class=&quot;fu&quot;&gt;resource&lt;/span&gt; = &lt;span class=&quot;kw&quot;&gt;null&lt;/span&gt;;
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;之后的流程还很多步，相当之复杂。它们最终会走到 &lt;code&gt;BitmapResource.java&lt;/code&gt; 里面的&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span class=&quot;fu&quot;&gt;@Override&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;recycle&lt;/span&gt;() {
    bitmapPool.&lt;span class=&quot;fu&quot;&gt;put&lt;/span&gt;(bitmap); &lt;span class=&quot;co&quot;&gt;// 这里就把上一次加载返回过的 bitmap 给缓存起来了。&lt;/span&gt;
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;当我们不使用 &lt;code&gt;ViewTarget&lt;/code&gt; 的 &lt;code&gt;Target&lt;/code&gt; 的时候，就不会有上面的流程，因为 &lt;code&gt;BaseTarget.java&lt;/code&gt; 内部的 &lt;code&gt;getRequest&lt;/code&gt; 是 null，而 &lt;code&gt;SimpleTarget extends BaseTarget&lt;/code&gt;，这也是为什么 &lt;code&gt;SimpleTarget.java&lt;/code&gt; 能够达到每次请求返回的 &lt;code&gt;Bitmap&lt;/code&gt; 内存地址不一样的原因。&lt;/p&gt;
&lt;h3 id=&quot;bitmappool.get-的时机&quot;&gt;BitmapPool.get 的时机。&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Glide&lt;/code&gt; 加载图片最后的解码代码在 &lt;code&gt;Downsampler.java&lt;/code&gt; 里面。它在里面调用了 &lt;code&gt;decodeFromWrappedStreams&lt;/code&gt;，并在 &lt;code&gt;decodeStream&lt;/code&gt; 之前，调用了 &lt;code&gt;setInBitmap&lt;/code&gt;，而 &lt;code&gt;setInBitmap&lt;/code&gt; 内部就有这么一行：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;options.inBitmap = bitmapPool.getDirty(width, height, expectedConfig);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;它从 &lt;code&gt;bitmapPool&lt;/code&gt; 获取&lt;code&gt;擦除了像素&lt;/code&gt;的 Bitmap 对象。&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;24&quot;&gt;
&lt;pre class=&quot;sourceCode java&quot;&gt;
&lt;code class=&quot;sourceCode java&quot;&gt;&lt;span class=&quot;kw&quot;&gt;private&lt;/span&gt; Bitmap &lt;span class=&quot;fu&quot;&gt;decodeFromWrappedStreams&lt;/span&gt;(InputStream is,
      BitmapFactory.&lt;span class=&quot;fu&quot;&gt;Options&lt;/span&gt; options, DownsampleStrategy downsampleStrategy,
      DecodeFormat decodeFormat, &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; isHardwareConfigAllowed, &lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; requestedWidth,
      &lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; requestedHeight, &lt;span class=&quot;dt&quot;&gt;boolean&lt;/span&gt; fixBitmapToRequestedDimensions,
      DecodeCallbacks callbacks) &lt;span class=&quot;kw&quot;&gt;throws&lt;/span&gt; IOException
{
    ....
    &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; ((options.&lt;span class=&quot;fu&quot;&gt;inSampleSize&lt;/span&gt; == &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt; || isKitKatOrGreater) &amp;amp;&amp;amp; &lt;span class=&quot;fu&quot;&gt;shouldUsePool&lt;/span&gt;(imageType))
    {
      ....
      &lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; (expectedWidth &amp;gt; &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt; &amp;amp;&amp;amp; expectedHeight &amp;gt; &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;) {
        &lt;span class=&quot;co&quot;&gt;// setInBitmap&lt;/span&gt;
        &lt;span class=&quot;fu&quot;&gt;setInBitmap&lt;/span&gt;(options, bitmapPool, expectedWidth, expectedHeight);
      }
    }
    Bitmap downsampled = &lt;span class=&quot;fu&quot;&gt;decodeStream&lt;/span&gt;(is, options, callbacks, bitmapPool);
    ...
    &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; rotated;
}&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;

</description>
<pubDate>Tue, 06 Mar 2018 07:35:00 +0000</pubDate>
<dc:creator>指尖下的幽灵</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/linguanh/p/8514643.html</dc:identifier>
</item>
<item>
<title>我的Java设计模式-责任链模式 - Android_jet</title>
<link>http://www.cnblogs.com/AndroidJet/p/8514620.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/AndroidJet/p/8514620.html</guid>
<description>&lt;p&gt;今天来说说程序员小猿和产品就关于需求发生的故事。前不久，小猿收到了产品的需求。&lt;/p&gt;
&lt;p&gt;产品经理：小猿，为了迎合大众屌丝用户的口味，我们要放一张图，要露点的。&lt;/p&gt;
&lt;p&gt;小猿：......露点？你大爷的，让身为正义与纯洁化身的我做这种需求，还露点。&lt;/p&gt;
&lt;p&gt;产品经理：误会误会，是放一张暴露一点点的，尺寸不大。&lt;/p&gt;
&lt;p&gt;小猿：尼玛~能说清楚些吗，需求模棱两可的。不干，我要上报boss。&lt;/p&gt;
&lt;p&gt;产品经理也一阵无语，这豆丁的事还上报boss。话说这上报也得走程序是吧，技术经理就不干了，“凭什么要跳过我，得经过我才能到boss”。咦~这一层一层上报就涉及到这次的&lt;strong&gt;责任链模式&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;一责任链模式&quot;&gt;一、责任链模式&lt;/h2&gt;
&lt;h3 id=&quot;定义&quot;&gt;定义&lt;/h3&gt;
&lt;p&gt;  &lt;strong&gt;创建多个对象，使这些对象形成一条链，并沿着这条链传递请求，直到链上的某一个对象决定处理此请求。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&quot;特点&quot;&gt;特点&lt;/h3&gt;
&lt;p&gt;1）接收请求的对象连接成&lt;strong&gt;一条链&lt;/strong&gt;，对象之间存在层级关系。&lt;/p&gt;
&lt;p&gt;2）这些对象可处理请求，也可传递请求，直到有对象处理该请求。&lt;/p&gt;
&lt;h3 id=&quot;uml&quot;&gt;UML&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/5596129-37a83fab8d44ab20.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700&quot; alt=&quot;责任链模式UML图.png&quot;/&gt;&lt;/p&gt;
&lt;p&gt;责任链模式涉及到的角色如下所示：&lt;/p&gt;
&lt;p&gt;  &lt;strong&gt;- 抽象处理者角色：定义了处理请求的接口或者抽象类，提供了处理请求的的方法和设置下一个处理者的方法。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;  &lt;strong&gt;- 具体处理者角色：实现或者继承抽象这角色，具体逻辑根据实际的架构来定，后面会提到。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;二实战&quot;&gt;二、实战&lt;/h2&gt;
&lt;p&gt;先来看抽象处理者角色代码：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public abstract class Handler {
    private Handler nextHandler;
    private int level;
    public Handler(int level) {
        this.level = level;
    }

    // 处理请求传递，注意final，子类不可重写
    public final void handleMessage(Demand demand) {
        if (level == demand.demandLevel()) {
            this.report(demand);
        } else {
            if (this.nextHandler != null) {
                System.out.println(&quot;事情太严重，需报告上一级&quot;);
                this.nextHandler.handleMessage(demand);
            } else {
                System.out.println(&quot;我就是boss，没有上头&quot;);
            }
        }
    }

    public void setNextHandler(Handler handler) {
        this.nextHandler = handler;
    }

    // 抽象方法，子类实现
    public abstract void report(Demand demand);
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;在抽象处理者角色定义了处理请求的抽象方法，以及下一级传递的对象方法，重点在handleMessage处理请求传递的方法，下面会解释为什么要这样写，继续往下看。&lt;/p&gt;
&lt;p&gt;下面是具体处理者角色，继承抽象处理者角色，在我们情景中有两个具体处理者，分别是技术经理和boss。&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;// 技术经理
public class TechnicalManager extends Handler {
    public TechnicalManager() {
        super(1);
    }

    @Override
    public void report(Demand demand) {
        System.out.println(&quot;需求：&quot; + demand.detail());
        System.out.println(getClass().getSimpleName() + &quot;：小猿我挺你，这个需求不干&quot;);
    }
}

// boss
public class Boss extends Handler {
    public Boss() {
        super(2);
    }

    @Override
    public void report(Demand demand) {
        System.out.println(&quot;需求：&quot; + demand.detail());
        System.out.println(getClass().getSimpleName() + &quot;：你们打一架吧，打赢的做决定&quot;);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到具体处理者的代码很简洁，重写了report方法，实现各自的业务逻辑，这都归功于父类中handleMessage这个方法。&lt;/p&gt;
&lt;p&gt;两个角色都定义好了，来看客户端如何实现：&lt;/p&gt;
&lt;pre&gt;
&lt;code&gt;public class Client {
    public static void main(String[] args) {
        Demand demandA = new DemandA(); // 请求等级低
        Demand demandB = new DemandB(); // 请求等级高

        Boss boss = new Boss();
        TechnicalManager technicalManager = new TechnicalManager();
        technicalManager.setNextHandler(boss); // 设置下一级

        technicalManager.handleMessage(demandA);
        System.out.println(&quot;============================&quot;);
        technicalManager.handleMessage(demandB);
    }
}&lt;/code&gt;
&lt;/pre&gt;
&lt;p&gt;可以看到在客户端中的重点是设置下一级的处理者，这样多个处理者对象就会形成一条链。运行客户端，结果如下：&lt;/p&gt;
&lt;blockquote readability=&quot;15&quot;&gt;
&lt;p&gt;需求：加一张露一点点的图&lt;/p&gt;
&lt;p&gt;TechnicalManager：小猿我挺你，这个需求不干&lt;/p&gt;
&lt;p&gt;============================&lt;/p&gt;
&lt;p&gt;需求：加一张露一点点的图&lt;/p&gt;
&lt;p&gt;TechnicalManager：事情太严重，需报告上一级&lt;/p&gt;
&lt;p&gt;Boss：你们打一架吧，打赢的做决定&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从结果可以看到，级别低的请求技术经理自己处理，级别高的传递给了下一级的Boss，这样就&lt;strong&gt;形成一条链&lt;/strong&gt;，而这也是责任链的核心所在。注意，&lt;strong&gt;在请求的传递过程中，请求是不会发生变化的&lt;/strong&gt;。需求不会从“加一张露一点点的图”变成了“加一张露点的图”，这等着boss请到办公室喝茶吧。&lt;/p&gt;
&lt;h2 id=&quot;三扩展&quot;&gt;三、扩展&lt;/h2&gt;
&lt;h3 id=&quot;责任链模板方法&quot;&gt;责任链+模板方法&lt;/h3&gt;
&lt;p&gt;回头看看上面的代码，抽象类中定义了几个方法，一个是final修饰的handleMessage，一个是抽象方法report，还有一个是setNextHandler。这刚好是模板方法模式中的三个基本方法，分别是具体方法（抽象类声明并实现，子类不实现）、抽象方法（抽象类声明，子类必须实现）、钩子方法（抽象类声明并实现，子类可扩展）。handleMessage方法加了final修饰，子类不可重写，而handleMessage正是把传递请求工作交给父类Handler，子类不需要处理传递的工作。而report则是抽象方法，子类必须重写该方法，子类处理请求的业务逻辑。setNextHandler是钩子方法，在这里我们并没有实现。&lt;/p&gt;
&lt;p&gt;这样结合模板方法模式的好处在哪？首先加了handleMessage方法，把请求的传递判断从子类中剥离出来，让子类在report方法中专心处理请求的业务逻辑，做到了单一职责原则。再者是子类的实现变得简单了，不需要进行传递的判断，非常有利于快速扩展。&lt;/p&gt;
&lt;h3 id=&quot;责任链模式vs观察者模式&quot;&gt;责任链模式VS观察者模式&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://www.jianshu.com/p/d5a758dd2795&quot;&gt;&lt;strong&gt;观察者模式&lt;/strong&gt;&lt;/a&gt;我在之前有些过，不了解的可以先看看。责任链模式和观察者模式存在一个共同点，就是传递&lt;strong&gt;责任链模式是一级一级的传递，形成一条链，链节点（处理者）之间是存在传递关系的&lt;/strong&gt;。而观察者模式的被观察者向观察者们的传递，&lt;strong&gt;并不是具体观察者之间的传递，观察者之间是不存在关联的&lt;/strong&gt;。拿小猿的经历来说，在责任链模式中是请求从技术经理到boss，有层级关系，而对于观察者模式是从被观察者小猿发出，作为观察者的技术经理和boss都会收到小猿的通知，是扩散式的，技术经理和boss并没有层级关系。这是责任链模式和观察者模式的区别，也是责任链模式的核心。&lt;/p&gt;
&lt;h2 id=&quot;四责任链模式的优缺点&quot;&gt;四、责任链模式的优缺点&lt;/h2&gt;
&lt;h3 id=&quot;优点&quot;&gt;优点&lt;/h3&gt;
&lt;p&gt;1）降低耦合度：客户端不需要知道请求由哪个处理者处理，而处理者也不需要知道处理者之间的传递关系，由系统灵活的组织和分配。&lt;/p&gt;
&lt;p&gt;2）良好的扩展性：增加处理者的实现很简单，只需重写处理请求业务逻辑的方法。&lt;/p&gt;
&lt;h3 id=&quot;缺点&quot;&gt;缺点&lt;/h3&gt;
&lt;p&gt;1）请求会从链头发出，直到有处理者响应，在责任链比较长的时候会影响系统性能。&lt;/p&gt;
&lt;p&gt;2）请求递归，调试排错比较麻烦。&lt;/p&gt;
&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;责任链模式在实际项目中可以用到的地方还是比较多的，比如会员等级系统，会员等级之间构成一条链，用户发起一个请求，系统只要把请求分发到责任链模式的入口，直到传递到与用户会员匹配的等级，这样各个会员等级的业务逻辑就会变成很清晰。这篇折腾了很久，主要是想把责任链的核心阐述清楚，让大家能够容易理解，也让我重新思考了责任链模式的核心。下一篇是“还没想好”，您的点赞和关注是我的动力哦，再会！&lt;/p&gt;
&lt;p&gt;设计模式Java&lt;strong&gt;源码GitHub下载&lt;/strong&gt;：&lt;a href=&quot;https://github.com/jetLee92/DesignPattern&quot;&gt;&lt;strong&gt;https://github.com/jetLee92/DesignPattern&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 06 Mar 2018 07:33:00 +0000</pubDate>
<dc:creator>Android_jet</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/AndroidJet/p/8514620.html</dc:identifier>
</item>
<item>
<title>流处理与消息队列------《Designing Data-Intensive Applications》读书笔记16 - HappenLee</title>
<link>http://www.cnblogs.com/happenlee/p/8514109.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/happenlee/p/8514109.html</guid>
<description>&lt;blockquote readability=&quot;8&quot;&gt;
&lt;p&gt;上一篇聊了聊批处理的缺点，对于无界数据来说，&lt;strong&gt;流处理&lt;/strong&gt;会是更好的选择，“流”指的是随着时间的推移逐步增加的数据。消息队列可以将这些流组织起来，快速的在应用程序中给予反馈。但是消息队列与传统的数据库之间又存在着“剪不断，理还乱”的“纠葛”，最后我们将探讨通过消息队列之中与时序有关的一些问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;文件是批处理作业的输入和输出，而在流处理之中，作业的输入输出等价物是什么呢？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在流处理之中，当输入是文件时，第一个处理步骤通常是将其解析为一连串的记录。&lt;strong&gt;在流处理之中，记录通常被称为事件，每个事件都是一个小的、独立的、不可变的对象，通常每个事件包含一个时间戳，表明事件产生的时间。&lt;/strong&gt; 在流处理之中，事件由生产者产生，然后可能由多个对应消费者，相关的事件通常被分组到同一个主题之中。&lt;/p&gt;
&lt;p&gt;可以由数据库来串联生产者与消费者：生产者可以将事件写入数据库，之后每一个消费者定期轮询数据库检查新出现的事件。但是数据库是不适合这种频繁轮询的操作的，&lt;strong&gt;因为轮询的次数越多，返回新事件的百分比越低，由此产生额外的开销也就越高。&lt;/strong&gt; (&lt;strong&gt;其实可以通过触发器的方式实现，但是数据库触发器也是基于数据库内部的关联的表进行操作的&lt;/strong&gt;），所以引入了&lt;strong&gt;消息系统&lt;/strong&gt;来处理流处理的需求。&lt;/p&gt;
&lt;h3 id=&quot;消息系统&quot;&gt;1.消息系统&lt;/h3&gt;
&lt;p&gt;消息系统的运行逻辑很简单：&lt;strong&gt;由生产者发送包含事件的消息，然后将消息推送给消费者，可以由多个生产者节点发送消息到同一个主题，并允许多个消费节点在一个主题中接收消息。&lt;/strong&gt; 但是消息系统会有这样几个问题：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;
&lt;ol&gt;&lt;li&gt;如果生产者发送消息的速度比消费者处理的速度快，系统会怎么样处理呢 ?
&lt;ul&gt;&lt;li&gt;删除消息&lt;/li&gt;
&lt;li&gt;在队列中缓存消息&lt;/li&gt;
&lt;li&gt;负反馈（也称为流量控制，阻止生产者发送更多消息）&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;&lt;li&gt;如果节点崩溃或暂时离线，会出现消息丢失吗？消息系统与数据库相似，需要实现消息持久化需要一些进行磁盘读写或消息复制，这显然是有代价的。如果可以容忍消息丢失，那么可以在同一硬件上获得更高的吞吐量和更低的延迟。&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;消息的传递机制&quot;&gt;消息的传递机制&lt;/h4&gt;
&lt;p&gt;许多消息系统使用生产者和消费者之间的直接网络通信，而无需通过中间节点，如ZeroMQ 采取了TCP/IP组播的形式。所以如果消费者在网络上公开服务，生产者可以直接通过HTTP或RPC请求将消息推送给消费者。虽然直接消息传递的系统在通常情况下在协议检测和消息重传的机制下工作的很好，但是&lt;strong&gt;应用程序通常需要能够容忍消息丢失的情况，因为有一个问题很明显生产者和消费者不一定时刻在线。&lt;/strong&gt; 而如果消费者离线，它可能错过消息。有些协议允许生产者重试失败的消息，但一旦生产者崩溃，这种方法可能失效，因为重试的消息的缓冲区会丢失。&lt;/p&gt;
&lt;p&gt;而另一种广泛使用方案是通过&lt;strong&gt;消息队列&lt;/strong&gt;来发送消息，&lt;strong&gt;它作为与生产者和消费者的中间连接而存在，生产者将消息写入消息队列，而消费者从消息队列读取需要接收的消息。&lt;/strong&gt; 通过消息队列传输的数据，系统容忍消费者和生产者的在线问题，消息持久性选择被交给了消息队列。&lt;strong&gt;这时我们可以更加灵活的处理消息，有些消息可以仅仅保存在内存中，而某些消息将写入磁盘，以便在消息队列崩溃时不会丢失这些消息。&lt;/strong&gt; 面对处理速度缓慢的消费者，消息队列通常允许无界的排队规则，而不是丢弃消息或负反馈调整，这些机制都成为可以定制的选项。 但是&lt;strong&gt;消息队列的消息传递是异步的：当生产者发送消息时，它通常只等待消息队列的确认，而不会等到消费者处理消息。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;与数据库的区别与联系&quot;&gt;与数据库的区别与联系&lt;/h4&gt;
&lt;p&gt;消息系统在许多性质上与数据库非常相似，但是依然存在一些重要的差异：&lt;/p&gt;
&lt;ul readability=&quot;1.5&quot;&gt;&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;数据库会持久化的保存数据，直到数据被显式删除，&lt;strong&gt;而大多数消息系统将消息成功地传递给消费者时自动删除它，所以消息系统不适合作为长期存储。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;数据库通常通过索引来分类检索数据，&lt;strong&gt;而消息系统通常通过主题配置的模式来分类检索数据的。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li readability=&quot;0&quot;&gt;
&lt;p&gt;数据库的读写操作都是主动的，&lt;strong&gt;而消息系统不支持随机查询，当数据发生变化时，它会通知消费者。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;h4 id=&quot;消息的分发与确认&quot;&gt;消息的分发与确认&lt;/h4&gt;
&lt;p&gt;当多个消费者读取消息时，消息系统存在两种分发模型：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;负载均衡&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;每个消息传递给所有消费者中的一个，由所有消费者共享处理主题中的消息的工作。消息队列可以任意的向消费者分配消息，来实现负载均衡。&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;消息广播&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;每条消息都传递给所有的消费者。消息广播使所有消费者收到同样的消息，而不影响彼此流，相当于有几个不同的批处理作业读取相同的输入文件。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/8552201-0ba0d5d2b78776a4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;负载均衡与消息广播&quot;/&gt;&lt;/p&gt;
&lt;p&gt;这两种模式可以进行合并：例如，两个独立的消费者组可以各自订阅一个主题，使得每个组集体接收所有消息，但在每个组中，只有一个节点接收每个消息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;消费者可能在任意时刻崩溃，所以向消费者传递的消息未必会被处理或者只是在崩溃前部分处理它。&lt;/strong&gt; 为了保证消息不丢失，消息代理使用确认机制：&lt;strong&gt;消费者需要明确反馈给消息队列，对应的消息得到了处理，消息队列会在队列之中移除对应的消息。&lt;/strong&gt; 如果消费者的连接关闭或超时，而消息队列没有收到确认，则它假定消息没有被处理，因此它将消息再次发送给另一个消费者。（&lt;strong&gt;注意，可能会出现消息完全被处理的情况，但是确认在网络中丢失了，再次处理消息时需要确保消息的处理是幂等的。&lt;/strong&gt;）所以如下图所示，这种情况会导致消息的交付顺序与生产者的发送的顺序不一致：&lt;br/&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/8552201-cc4eac2df9314e95.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;M3与M4的交付顺序与生产者的发送的顺序不一致：&quot;/&gt;&lt;/p&gt;
&lt;p&gt;通常来说如果消息是完全独立的，那么消息的重新排序不会产生问题，但是如果消息之间有因果依赖关系，这回导致因果的不一致性，为了避免这个问题，可以为每个消费者使用单独的队列，但是这样就失去了&lt;strong&gt;负载均衡&lt;/strong&gt;的优势。&lt;/p&gt;
&lt;h4 id=&quot;日志与消息系统&quot;&gt;日志与消息系统&lt;/h4&gt;
&lt;p&gt;对于有持久化需求的消息队列，则考虑通过日志来实现持久化存储，来满足消息队列低延迟的要求。在前文之中我们讨论过日志的模式，同样相同的日志模型可以用来实现消息队列的持久化：生产者将消息追加到日志的末尾，而消费者通过依次读取日志来接收消息。如下图所示：为了比单个磁盘所能提供更高的吞吐量，可以对日志进行分区操作。在不同的代理节点上托管不同的分区，使每个分区保存独立的日志：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/8552201-c69eedf2029acf15.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;日志的分区读写&quot;/&gt;&lt;/p&gt;
&lt;p&gt;在每个分区之中，每个消息都会有一个单调递增的序列号，这样能够保证分区之中所有的消息是完全有序的，而不同分区之间的消息则没有顺序保证。通过这种方式可以很容易地分辨出哪些消息已被处理，&lt;strong&gt;比当前偏移量小的消息已经被处理，而后面的消息还没有被处理。&lt;/strong&gt;因此，消息队列不需要追踪每一个消息，它只需要定期记录消费者偏移。这样有助于提高基于日志系统的吞吐量。&lt;strong&gt;而一旦消费者节点失效，则消费者组中的另一个节点被分配到日志分区，并开始在最后记录的偏移量上消费消息。&lt;/strong&gt; 但如果之前的消息处理了偏移量之后的消息，但没有记录新的偏移量，则这些消息会被二次处理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果消费者无法跟上生产者发送消息的速率，则日志记录消息可以作为一种缓冲机制 。&lt;/strong&gt; 当一个消费者所需要的消息比比日志上保留的信息要老，它将丢失过旧消息。所以需要监视消费者的消费速率，如果它显著落后，则发出警报。由于基于日志的磁盘缓冲区很大，有足够的时间让管理员介入。即使消费者落后太多，开始出现丢失消息的情况，也只有单个消费者受到影响，它不会破坏其他消费者的运行。 前文提到的消息确认是一种破坏性的操作，因为它会导致消息被消息队列删除。而在基于日志的消息队列中，消息的读取时只读的操作，不会改变日志。这使得基于日志的消息队列更像是前文提及的批处理过程。&lt;/p&gt;
&lt;h3 id=&quot;与数据库共同工作&quot;&gt;2.与数据库共同工作&lt;/h3&gt;
&lt;p&gt;上文已经提到过，没有一个系统能够满足所有的数据存储、查询和处理需求。在实践中，应用需要结合不同的技术来满足要求，所以本节我们来看看消息队列与数据库是怎么样并肩作战的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;变化数据捕获（CDC）&lt;/strong&gt; 是常常被使用到的技术，通过观察所有写入数据库的数据变化并将它们转换成可复制到其他系统数据的过程。如下图所示，通过捕获到数据库中的更改，并继续对搜索索引等应用更改，通过以相同的顺序应用更改日志，搜索索引中的数据与数据库中的数据相匹配。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/8552201-d19a71d113674cf8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;图片.png&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;变化数据捕获的实现&quot;&gt;变化数据捕获的实现&lt;/h4&gt;
&lt;p&gt;变化数据捕获是一种机制，用于确保对记录系统的所有更改也反映在派生数据系统中，以便派生系统具有准确的数据副本。 从本质上讲，更改数据捕获使一个数据库成为Leader，并将其他数据系统变成Follower。&lt;strong&gt;基于日志的消息队列很适合从源数据库接受消息的变化，并且保留的消息的顺序。&lt;/strong&gt; 数据库的触发器同样可用于实现变化数据捕获，通过观察数据表的所有变化并将变化添加到记录表之中，但是触发器会带显著的性能开销。变化数据捕获通常是异步的：记录数据库系统在提交之后不会等待更改应用于消费者。&lt;/p&gt;
&lt;h4 id=&quot;快照与日志压缩&quot;&gt;快照与日志压缩&lt;/h4&gt;
&lt;p&gt;如果拥有对数据库所做的所有更改的日志，那么可以通过日志来重建数据库的整个状态。但是将所有更改保存在内存中，会耗费大量的磁盘空间，并且载入并应用日志将耗费太长的时间，因此需要截断日志并配合快照来使用。构建一个新的全文索引需要整个数据库的完整副本，这里可以通过快照开始，并且载入快照后生成的日志便可以将索引恢复到最新的状态。所以&lt;strong&gt;数据库快照必须与日志中的偏移量相对应，以便确定在处理完快照后，在哪一点开始应用日志更改。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因为只能保留有限的日志记录，所以每次需要添加新的派生数据系统时，都需要经历快照的过程。这增加了系统的复杂性，而&lt;strong&gt;日志压缩&lt;/strong&gt;提供了一个很好的替代方案，日志压缩的原理很简单：&lt;strong&gt;存储引擎周期性地查找具有相同Key的日志记录，丢弃重复的记录，并且只保存每个Key的最新值。&lt;/strong&gt; 日志的压缩和合并过程在后台运行，如果需要重建派生数据系统（如：搜索索引）时，可以从压缩日志中启动一个新的用户，并依次扫描日志中的所有消息，就可以获取数据库内容的完整副本，而不必通过额外的快照。&lt;/p&gt;
&lt;h3 id=&quot;流处理的时间依赖&quot;&gt;3.流处理的时间依赖&lt;/h3&gt;
&lt;p&gt;流处理与数据库相比最核心的差别是:&lt;strong&gt;查询和数据之间的关系是相反的。&lt;/strong&gt;通常，数据库会持久地存储数据，而查询是一个临时的操作。而流处理反转两者的角色：查询是长期存储的，输入流的事件不断地流过，并寻找查询模式匹配的数据。所以，二者的应用场景也差距很大，流处理擅长监控变化的数据并且给予反馈。一旦涉及到变化，则是一个时间敏感问题，数据是随着时间的推移而变化的，流处理通常需要处理时间，特别是用于分析的数据变化时，需要使用时间窗口。例如 “过去五分钟的平均时间”。许多流处理框架使用了本地系统时钟来确定时间窗口。如果事件的发生和事件的处理之间的延迟很小，这个模型就十分简单易行。然而，前文我们提到了，事件很有可能会产生延迟，事件的处理可能明显晚于事件的发生。&lt;/p&gt;
&lt;h4 id=&quot;事件时间与处理时间&quot;&gt;事件时间与处理时间&lt;/h4&gt;
&lt;p&gt;有许多原因会导致处理的延迟如：排队、网络故障，消息队列处理缓慢，代码的bug等。&lt;strong&gt;消息延迟会导致事件的不可预知排序。&lt;/strong&gt;例如，假设用户首先创建一个Web请求（由Web服务器A处理），然后再进行第二个请求（由服务器B处理）。a和b发出描述它们所处理请求的事件，但b事件在事件发生前到达消息代理。现在流处理器将首先看到b事件，然后才是a事件，尽管它们实际上是以相反的顺序发生的。&lt;/p&gt;
&lt;p&gt;事件发生的时间和事件的处理时间是两个完全不同的概念，混淆他们会导致数据的损坏。如下图所示，Web服务器上事件发生的频率是稳定的，但是流处理器需要定期处理事件，可能这时会停下来一分钟，处理挤压的事件，如果这时以事件的处理事件来测量数据，会导致异常的波动结果。&lt;br/&gt;&lt;img src=&quot;http://upload-images.jianshu.io/upload_images/8552201-d2117dd840c901f2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240&quot; alt=&quot;错误的选择时间导致了结果的异常波动&quot;/&gt;&lt;/p&gt;
&lt;h4 id=&quot;如何确定时间戳&quot;&gt;如何确定时间戳&lt;/h4&gt;
&lt;p&gt;确定事件的时间戳是一件很困难的事，按理来说，事件上的时间戳应该是与用户交互发生的时间，但是，用户控制的设备上的时钟通常不能被信任，因为它可能是偶然或故意设置到错误的时间。服务器接收到事件的时间（根据服务器的时钟）更可能是准确的，但在描述用户交互方面没有什么意义。所以这里有&lt;strong&gt;三个时间戳的法则&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;由第三个时间戳减去第二个时间戳，可以估计设备时钟和服务器时钟之间的偏移量，通过这样的方式来估计事件实际发生的真实时间。&lt;/p&gt;
&lt;h3 id=&quot;小结&quot;&gt;小结：&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;通过流处理与批处理，我们可以完成一个分布式系统需要的绝大多数计算任务。我们用了16篇的时间走完了对这本书绝大多数内容的梳理，最后一章是一篇大杂烩，作者带领我们展望自己对于未来数据系统发展的看法，也对之前的内容做了总结。&lt;/strong&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 06 Mar 2018 06:15:00 +0000</pubDate>
<dc:creator>HappenLee</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/happenlee/p/8514109.html</dc:identifier>
</item>
<item>
<title>沉淀，再出发——在Ubuntu Kylin15.04中配置Hadoop单机/伪分布式系统经验分享 - 精心出精品</title>
<link>http://www.cnblogs.com/zyrblog/p/8503123.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/zyrblog/p/8503123.html</guid>
<description>&lt;p&gt;&lt;span&gt;&lt;strong&gt;在Ubuntu Kylin15.04中配置Hadoop单机/伪分布式系统经验分享&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;一、工作准备&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;span&gt;  首先，明确工作的重心，在Ubuntu Kylin15.04中配置Hadoop集群，这里我是用的双系统中的Ubuntu来配制的，不是虚拟机。在网上有很多配置的方案，我看了一下Ubuntu的版本有14.x,16.x等等，唯独缺少15.x，后来我也了解到，15.x出来一段时间就被下一个版本所替代了，可能有一定的问题吧，可是我还是觉得这个版本的用起来很舒服，但是当我安装了Ubuntu kylin15.04之后，网络配置成功，我开始使用sudo apt-get update更新一下软件源的时候，就遇到了非常大的麻烦，具体的介绍可以参考我的拙作&lt;/span&gt;&lt;a href=&quot;http://www.cnblogs.com/zyrblog/p/8495187.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;Ubuntu版本更替所引发的“血案”&lt;/span&gt;&lt;/a&gt;&lt;span&gt;，经过了一番斗争，我总算在打算安装16.x之前找到了解决办法，实现了一次技术上的沉淀！之后安装Hadoop集群总算是踏上了高速列车。解决了系统的问题，我们需要使用的原来还有vim或者gedit文本编辑工具，SSH,openssh-server,当然了Ubuntu默认是安装了openssh-client的，我们可以再安装一次，之后需要java的jre和jdk，需要hadoop，基本上需要这么多基本的原料，有了这些东西，我们就可以使用shell来尽情的发挥了。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;39&quot;&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;1、vim或者gedit文本编辑工具；&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;2、ssh,openssh-server,openssh-client；&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;3、jre和jdk,这里安装的是openjdk-7-jre openjdk-7-jdk；&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;4、Hadoop 2.x.y；&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;5、Ubuntu Kylin15.04；&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;&lt;span&gt; &lt;span&gt;&lt;strong&gt;二、创建hadoop用户&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt; &lt;span&gt;  这一步是保证操作的纯洁性，至于是不是必须要以hadoop为用户名，这个地方还有待考证，不过作为初学者，我们就先从最基本的开始理解，主要的操作如下，增加用户名为hadoop，并且使用bash作为shell，之后设置密码，然后为hadoop赋予sudo权限，最后退出原系统，登录我们新创建的系统。&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;strong&gt;sudo useradd -m hadoop -s /bin/bash
sudo passwd hadoop
sudo adduser hadoop sudo&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt; 三、更新apt，并且安装一些工具软件&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;   3.1、&lt;/strong&gt;到了这里，我们&lt;strong&gt;使用新创建的用户登录系统&lt;/strong&gt;，然后打开shell，在shell中运行如下命令,&lt;span&gt;&lt;strong&gt;更新软件源&lt;/strong&gt;&lt;/span&gt;：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;strong&gt;sudo apt-get clean
sudo apt-get update
sudo apt-get upgrade&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;   如果中途失败，提示get不到源，或者网络失败，我们的排查思路是，首先ping 公网，看看能不能够连接成功，其次检查DNS，/etc/hosts等，判断是不是域名系统的问题，最后我们使用源的IP来ping，如果都没有问题，那我们的问题可能就在于‘源’已经失去维护了，从以前的仓库中移除了，遇到这个问题，请参考我的拙作&lt;a href=&quot;http://www.cnblogs.com/zyrblog/p/8495187.html&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;Ubuntu版本更替所引发的“血案”&lt;/span&gt;&lt;/a&gt;，基本上可以解决问题。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;   &lt;strong&gt;3.2、然后更新vim,安装ssh工具，具体操作如下：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;strong&gt;&lt;span&gt;sudo apt-get install vim

sudo apt-get install ssh
sudo apt-get install openssh-server
sudo apt-get install openssh-client&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;   安装完成以后测试一下是否能够登陆localhost，自己登陆自己来测试是否可以使用ssh协议。如果不成功，我们启动一下ssh，并且使用ps和grep来看一下是否出现sshd，如果有代表程序启动成功，登录localhost会显示登录的结果，如果提示要更新或什么的不用理会。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;strong&gt;&lt;span&gt;ssh localhost
sudo /etc/init.d/ssh start
ps -e | grep ssh&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;       &lt;span&gt;之后我们生成并导出公钥，使得公钥可信任，我们每一次ssh就不用输入密码了。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;span&gt;&lt;strong&gt;cd ~/.ssh/
ssh-keygen -t rsa&lt;/strong&gt;&lt;/span&gt;
      Generating public/private rsa key pair.
      Enter file in which to save the key (/home/hadoop/.ssh/id_rsa): 
      Enter passphrase (empty for no passphrase): 
      Enter same passphrase again: 
      Your identification has been saved in /home/hadoop/.ssh/id_rsa.
      Your public key has been saved in /home/hadoop/.ssh/id_rsa.pub.
      The key fingerprint is:
      35:1f:b0:20:dc:03:0d:52:00:9b:34:51:7f:95:60:b6 hadoop@zyr-Aspire-V5-551G
&lt;strong&gt;&lt;span&gt;cat ./id_rsa.pub &amp;gt;&amp;gt; ./authorized_keys&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;&lt;img id=&quot;code_img_closed_e0785043-c8a6-44cf-b360-d28b13654e00&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_e0785043-c8a6-44cf-b360-d28b13654e00&quot; class=&quot;code_img_opened&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_e0785043-c8a6-44cf-b360-d28b13654e00&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;61&quot;&gt;
&lt;pre&gt;
&lt;span&gt;⦁    hadoop@zyr-Aspire-V5-551G:~$ ssh localhost
⦁    Welcome to Ubuntu 15.04 (GNU/Linux 3.19.0-15-generic x86_64)
⦁    
⦁     * Documentation:  https://help.ubuntu.com/
⦁    
⦁    15 packages can be updated.
⦁    9 updates are security updates.
⦁    
⦁    Your Ubuntu release is not supported anymore.
⦁    For upgrade information, please visit:
⦁    http://www.ubuntu.com/releaseendoflife
⦁    
⦁    New release '16.04.4 LTS' available.
⦁    Run 'do-release-upgrade' to upgrade to it.
⦁    
⦁    Last login: Sat Mar  3 10:32:05 2018 from localhost&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;p&gt; &lt;span&gt;  &lt;strong&gt;3.3、安装JAVA环境&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;   在这里我们使用openjdk和openjre，这是非官方的开源的，安装起来更容易，更方便。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;strong&gt;sudo apt-get install openjdk-7-jre openjdk-7-jdk&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;   之后我们需要找到这些文件的安装路径：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:~$ &lt;span&gt;&lt;strong&gt;dpkg -L openjdk-7-jdk | grep '/bin/javac'&lt;/strong&gt;&lt;/span&gt;
&lt;span&gt;&lt;strong&gt;/usr/lib/jvm/java-7-openjdk-amd64&lt;/strong&gt;&lt;/span&gt;/bin/javac&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;  可以看到就是&lt;span&gt;&lt;span&gt;&lt;strong&gt;/usr/lib/jvm/java-7-openjdk-amd64&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;安装路径，在这里我们使用的hadoop是2.9.0，java的环境是1.7.x，亲测通过，在&lt;span&gt;&lt;strong&gt;&lt;a href=&quot;https://wiki.apache.org/hadoop/HadoopJavaVersions&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;官网&lt;/span&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;上有这样的说法，当hadoop版本超过一定的级别的时候(2.7)，必须使用java1.7以及之上的版本。之后我们修改环境变量，在开头增加&lt;span&gt;&lt;span&gt;export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64/&lt;/span&gt;&lt;/span&gt;，并且保存退出，然后使用&lt;span&gt;&lt;span&gt;&lt;strong&gt;source ~/.bashrc&lt;/strong&gt;&lt;span&gt;进&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;行更新，通过下面的命令来测试java是否安装成功，环境变量是否匹配，系统是否正在使用我们配置的环境变量等信息。至此，java环境设置完成。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;strong&gt;&lt;span&gt;vim ~/.bashrc&lt;/span&gt;&lt;/strong&gt;
hadoop@zyr-Aspire-V5-551G:~$ &lt;span&gt;&lt;strong&gt;cat ~/.bashrc&lt;/strong&gt;&lt;/span&gt;
&lt;span&gt;export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64/&lt;/span&gt;

# ~/.bashrc: executed by bash(1) for non-login shells.
# see /usr/share/doc/bash/examples/startup-files (in the package bash-doc)
# for examples
   ……


&lt;span&gt;&lt;strong&gt;source ~/.bashrc&lt;/strong&gt;&lt;/span&gt;

hadoop@zyr-Aspire-V5-551G:~$ &lt;strong&gt;&lt;span&gt;echo $JAVA_HOME&lt;/span&gt;&lt;/strong&gt;
/usr/lib/jvm/java-7-openjdk-amd64/

hadoop@zyr-Aspire-V5-551G:~$ &lt;span&gt;&lt;strong&gt;java -version&lt;/strong&gt;&lt;/span&gt;
java version &quot;1.7.0_95&quot;
OpenJDK Runtime Environment (IcedTea 2.6.4) (7u95-2.6.4-0ubuntu0.15.04.1)
OpenJDK 64-Bit Server VM (build 24.95-b01, mixed mode)

hadoop@zyr-Aspire-V5-551G:~$ &lt;span&gt;&lt;strong&gt;$JAVA_HOME/bin/java -version&lt;/strong&gt;&lt;/span&gt;
java version &quot;1.7.0_95&quot;
OpenJDK Runtime Environment (IcedTea 2.6.4) (7u95-2.6.4-0ubuntu0.15.04.1)
OpenJDK 64-Bit Server VM (build 24.95-b01, mixed mode)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt; 四、&lt;span&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;/span&gt;Hadoop&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;  4.1、下载Hadoop&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;  通过 &lt;a href=&quot;http://mirror.bit.edu.cn/apache/hadoop/common/&quot; target=&quot;_blank&quot;&gt;&lt;span&gt;&lt;strong&gt;http://mirror.bit.edu.cn/apache/hadoop/common/&lt;/strong&gt;&lt;/span&gt;&lt;/a&gt; 或者 &lt;a href=&quot;http://mirrors.cnnic.cn/apache/hadoop/common/&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;&lt;span&gt;http://mirrors.cnnic.cn/apache/hadoop/common/&lt;/span&gt;&lt;/strong&gt;&lt;/a&gt; 下载Hadoop的所有版本，一般选择下载最新的稳定版本，下载 “stable” 下的 hadoop-2.x.y.tar.gz 这个格式的文件，我们可以直接使用，简单的解压，并且放到相应的文件夹即可；另一个包含 src 的则是 Hadoop 源代码，需要进行编译才可使用，我们可以拿来作为学习，在后期研究Hadoop的架构，因为Hadoop是用java语言写的，所以通俗易读。另外要保证下载文件的安全性、完整性、可用性、不可否认性、可控性等，最好的是找到一个含有hash校验码的下载源，不过笔者亲测这个下载源是可靠的。通过浏览器下载即可，之后进行保存，记住保存的位置，便于我们后期的操作。在这里笔者使用的是次新版的2.9.0，如下图所示。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1157683/201803/1157683-20180303214506791-621807262.png&quot; alt=&quot;&quot; width=&quot;473&quot; height=&quot;245&quot;/&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;  &lt;strong&gt;4.2、安装Hadoop&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;   下载之后，我们将该压缩文件解压到&lt;strong&gt;/usr/local&lt;/strong&gt;这个文件夹下，其实别的地方也是可以的，但是放在这里见名知意，恰到好处。之后我们进入这个文件夹下，通过mv的重命名功能将版本号去掉，改为hadoop，并且修改该文件夹的权限，使得该文件夹拥有hadoop的权限。并且我们使用ll命令来查看一下local下面的文件布局。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:~$ &lt;strong&gt;&lt;span&gt;sudo tar -zxf ~/Downloads/hadoop-2.9.0.tar.gz -C /usr/local&lt;/span&gt;&lt;/strong&gt;
[sudo] password for hadoop: 
hadoop@zyr-Aspire-V5-551G:~$&lt;span&gt;&lt;strong&gt; cd /usr/local/&lt;/strong&gt;&lt;/span&gt;
hadoop@zyr-Aspire-V5-551G:/usr/local$ &lt;strong&gt;&lt;span&gt;sudo mv ./hadoop-2.9.0/ ./hadoop  &lt;/span&gt; &lt;/strong&gt;
hadoop@zyr-Aspire-V5-551G:/usr/local$ &lt;strong&gt;&lt;span&gt;sudo chown -R hadoop ./hadoop&lt;/span&gt;&lt;/strong&gt;
hadoop@zyr-Aspire-V5-551G:/usr/local$ &lt;span&gt;&lt;strong&gt;ll&lt;/strong&gt;&lt;/span&gt; 
total 44
drwxr-xr-x 11 root   root 4096  3月  3 11:07 ./
drwxr-xr-x 10 root   root 4096  4月 23  2015 ../
drwxr-xr-x  2 root   root 4096  4月 23  2015 bin/
drwxr-xr-x  2 root   root 4096  4月 23  2015 etc/
drwxr-xr-x  2 root   root 4096  4月 23  2015 games/
&lt;span&gt;&lt;strong&gt;drwxr-xr-x  9 hadoop zyr  4096 11月 14 07:28 hadoop/&lt;/strong&gt;&lt;/span&gt;
drwxr-xr-x  2 root   root 4096  4月 23  2015 include/
drwxr-xr-x  4 root   root 4096  4月 23  2015 lib/
lrwxrwxrwx  1 root   root    9  3月  2 20:16 man -&amp;gt; share/man/
drwxr-xr-x  2 root   root 4096  4月 23  2015 sbin/
drwxr-xr-x  8 root   root 4096  4月 23  2015 share/
drwxr-xr-x  2 root   root 4096  4月 23  2015 src/&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;     &lt;span&gt;解压之后就相当于安装了，这点我们要记住，特别的方便，之后我们开始检验一下安装的结果，通过 &lt;span&gt;&lt;strong&gt;&lt;span&gt;./bin/hadoop version&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;命令来判断是否安装成功，如下是安装成功之后的结果。到这里我们总算是安装好了hadoop，其实也并不复杂，但是从无到有的过程，每一步的细节都是非常值得我们注意的。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local$&lt;span&gt;&lt;strong&gt; cd hadoop/&lt;/strong&gt;&lt;/span&gt;
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;strong&gt;&lt;span&gt; ./bin/hadoop version&lt;/span&gt;&lt;/strong&gt;
Hadoop 2.9.0
Subversion https://git-wip-us.apache.org/repos/asf/hadoop.git -r 756ebc8394e473ac25feac05fa493f6d612e6c50
Compiled by arsuresh on 2017-11-13T23:15Z
Compiled with protoc 2.5.0
From source with checksum 0a76a9a32a5257331741f8d5932f183
This command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.0.jar&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt; 五、单机&lt;span&gt;Hadoop测试&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;  到了这里，我们其实只是完成了单机上的Hadoop的安装，但是这些步骤在分布式上面是一样的，需要勤加练习，这样的Hadoop系统远不是集群系统，但是却迈出了关键性的一步，因为在一些学术研究中，到了这里我们就可以开发map reduce程序了，如果程序不是非常复杂，我们在单机上就可以完成，值得喜悦的是在Hadoop的安装包中早就集成了一些样例，我们可以通过这些样例来测试一下我们的Hadoop，比如WordCount、GREP 【正则表达式】等等，但是在我们兴奋之前，需要认识到，我们这样的程序并没有用到HDFS，而是使用的我们OS自带的文件系统FS，但是至少说这是一个里程碑。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;  我们首先切换到相关目录，然后创建一个input文件夹（名字无特殊要求），然后将一些文件放进去，这里我们放入的是一些配置文件来作为数据源，并且通过Hadoop自带的样例程序来测试一下我们的安装是不是成功的。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;strong&gt;&lt;span&gt;cd /usr/local/hadoop
mkdir ./input
cp ./etc/hadoop/*.xml ./input&lt;/span&gt;&lt;/strong&gt;

hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;span&gt;&lt;strong&gt; ls ./etc/hadoop/&lt;/strong&gt;&lt;/span&gt;
capacity-scheduler.xml      httpfs-env.sh            mapred-env.sh
configuration.xsl           httpfs-log4j.properties  mapred-queues.xml.template
container-executor.cfg      httpfs-signature.secret  mapred-site.xml.template
core-site.xml               httpfs-site.xml          slaves
hadoop-env.cmd              kms-acls.xml             ssl-client.xml.example
hadoop-env.sh               kms-env.sh               ssl-server.xml.example
hadoop-metrics2.properties  kms-log4j.properties     yarn-env.cmd
hadoop-metrics.properties   kms-site.xml             yarn-env.sh
hadoop-policy.xml           log4j.properties         yarn-site.xml
hdfs-site.xml               mapred-env.cmd&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;   我们使用如下&lt;/span&gt;&lt;span&gt;命令来测试我们的程序，首先我们可以执行一下&lt;span&gt;&lt;strong&gt;./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar&lt;/strong&gt;&lt;/span&gt;来看一下我们有哪些样例程序，然后我们使用其中的grep程序来从所有的输入文件中统计满足&lt;strong&gt;&lt;span&gt;'dfs[a-z.]+'&lt;/span&gt;&lt;/strong&gt;正则表达式的单词的个数是多少。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;span&gt;&lt;strong&gt; ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.0.jar&lt;/strong&gt;&lt;/span&gt;
An example program must be given as the first argument.
Valid program names are:
  aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.
  aggregatewordhist: An Aggregate based map/reduce program that computes the histogram of the words in the input files.
  bbp: A map/reduce program that uses Bailey-Borwein-Plouffe to compute exact digits of Pi.
  dbcount: An example job that count the pageview counts from a database.
  distbbp: A map/reduce program that uses a BBP-type formula to compute exact bits of Pi.
 &lt;span&gt; grep:&lt;/span&gt; A map/reduce program that counts the matches of a regex in the input.
  join: A job that effects a join over sorted, equally partitioned datasets
  multifilewc: A job that counts words from several files.
  pentomino: A map/reduce tile laying program to find solutions to pentomino problems.
  pi: A map/reduce program that estimates Pi using a quasi-Monte Carlo method.
  randomtextwriter: A map/reduce program that writes 10GB of random textual data per node.
  randomwriter: A map/reduce program that writes 10GB of random data per node.
  secondarysort: An example defining a secondary sort to the reduce.
  sort: A map/reduce program that sorts the data written by the random writer.
  sudoku: A sudoku solver.
  teragen: Generate data for the terasort
  terasort: Run the terasort
  teravalidate: Checking results of terasort
 &lt;strong&gt;&lt;span&gt; wordcount:&lt;/span&gt;&lt;/strong&gt; A map/reduce program that counts the words in the input files.
  wordmean: A map/reduce program that counts the average length of the words in the input files.
  wordmedian: A map/reduce program that counts the median length of the words in the input files.
  wordstandarddeviation: A map/reduce program that counts the standard deviation of the length of the words in the input files.

Eg:
      &lt;strong&gt; ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.0.jar  wordcount ./input  ./output&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    &lt;span&gt;  真正MapReduce命令：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;span&gt;&lt;strong&gt; ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep ./input ./output 'dfs[a-z.]+'&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;     &lt;span&gt;执行的结果是喜人的，我在这里将结果贴出来，但因为太长了，所以就缩进了。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;63.5&quot;&gt;&lt;img id=&quot;code_img_closed_3c0677ab-2fc0-4e10-b071-ef349087a919&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_3c0677ab-2fc0-4e10-b071-ef349087a919&quot; class=&quot;code_img_opened&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_3c0677ab-2fc0-4e10-b071-ef349087a919&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;122&quot;&gt;
&lt;pre&gt;
&lt;span&gt;  1&lt;/span&gt; &lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep ./input ./output 'dfs[a-z.]+'
&lt;/span&gt;&lt;span&gt;  2&lt;/span&gt; &lt;span&gt;18/03/03 11:20:28 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
&lt;/span&gt;&lt;span&gt;  3&lt;/span&gt; &lt;span&gt;18/03/03 11:20:28 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
&lt;/span&gt;&lt;span&gt;  4&lt;/span&gt; &lt;span&gt;18/03/03 11:20:28 INFO input.FileInputFormat: Total input files to process : 8
&lt;/span&gt;&lt;span&gt;  5&lt;/span&gt; &lt;span&gt;18/03/03 11:20:28 INFO mapreduce.JobSubmitter: number of splits:8
&lt;/span&gt;&lt;span&gt;  6&lt;/span&gt; &lt;span&gt;18/03/03 11:20:30 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local325822439_0001
&lt;/span&gt;&lt;span&gt;  7&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
&lt;/span&gt;&lt;span&gt;  8&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapreduce.Job: Running job: job_local325822439_0001
&lt;/span&gt;&lt;span&gt;  9&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.LocalJobRunner: OutputCommitter set in config null
&lt;/span&gt;&lt;span&gt; 10&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
&lt;/span&gt;&lt;span&gt; 11&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
&lt;/span&gt;&lt;span&gt; 12&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
&lt;/span&gt;&lt;span&gt; 13&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.LocalJobRunner: Waiting for map tasks
&lt;/span&gt;&lt;span&gt; 14&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.LocalJobRunner: Starting task: attempt_local325822439_0001_m_000000_0
&lt;/span&gt;&lt;span&gt; 15&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
&lt;/span&gt;&lt;span&gt; 16&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
&lt;/span&gt;&lt;span&gt; 17&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
&lt;/span&gt;&lt;span&gt; 18&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.MapTask: Processing split: file:/usr/local/hadoop/input/hadoop-policy.xml:0+10206
&lt;/span&gt;&lt;span&gt; 19&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
&lt;/span&gt;&lt;span&gt; 20&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
&lt;/span&gt;&lt;span&gt; 21&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.MapTask: soft limit at 83886080
&lt;/span&gt;&lt;span&gt; 22&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
&lt;/span&gt;&lt;span&gt; 23&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
&lt;/span&gt;&lt;span&gt; 24&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
&lt;/span&gt;&lt;span&gt; 25&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.LocalJobRunner: 
&lt;/span&gt;&lt;span&gt; 26&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.MapTask: Starting flush of map output
&lt;/span&gt;&lt;span&gt; 27&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.MapTask: Spilling map output
&lt;/span&gt;&lt;span&gt; 28&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.MapTask: bufstart = 0; bufend = 17; bufvoid = 104857600
&lt;/span&gt;&lt;span&gt; 29&lt;/span&gt; &lt;span&gt;18/03/03 11:20:31 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
&lt;/span&gt;&lt;span&gt; 30&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: Finished spill 0
&lt;/span&gt;&lt;span&gt; 31&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.Task: Task:attempt_local325822439_0001_m_000000_0 is done. And is in the process of committing
&lt;/span&gt;&lt;span&gt; 32&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.LocalJobRunner: map
&lt;/span&gt;&lt;span&gt; 33&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.Task: Task 'attempt_local325822439_0001_m_000000_0' done.
&lt;/span&gt;&lt;span&gt; 34&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local325822439_0001_m_000000_0
&lt;/span&gt;&lt;span&gt; 35&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.LocalJobRunner: Starting task: attempt_local325822439_0001_m_000001_0
&lt;/span&gt;&lt;span&gt; 36&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
&lt;/span&gt;&lt;span&gt; 37&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
&lt;/span&gt;&lt;span&gt; 38&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapreduce.Job: Job job_local325822439_0001 running in uber mode : false
&lt;/span&gt;&lt;span&gt; 39&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
&lt;/span&gt;&lt;span&gt; 40&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: Processing split: file:/usr/local/hadoop/input/capacity-scheduler.xml:0+7861
&lt;/span&gt;&lt;span&gt; 41&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapreduce.Job:  map 100% reduce 0%
&lt;/span&gt;&lt;span&gt; 42&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
&lt;/span&gt;&lt;span&gt; 43&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
&lt;/span&gt;&lt;span&gt; 44&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: soft limit at 83886080
&lt;/span&gt;&lt;span&gt; 45&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
&lt;/span&gt;&lt;span&gt; 46&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
&lt;/span&gt;&lt;span&gt; 47&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
&lt;/span&gt;&lt;span&gt; 48&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.LocalJobRunner: 
&lt;/span&gt;&lt;span&gt; 49&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: Starting flush of map output
&lt;/span&gt;&lt;span&gt; 50&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.Task: Task:attempt_local325822439_0001_m_000001_0 is done. And is in the process of committing
&lt;/span&gt;&lt;span&gt; 51&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.LocalJobRunner: map
&lt;/span&gt;&lt;span&gt; 52&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.Task: Task 'attempt_local325822439_0001_m_000001_0' done.
&lt;/span&gt;&lt;span&gt; 53&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.LocalJobRunner: Finishing task: attempt_local325822439_0001_m_000001_0
&lt;/span&gt;&lt;span&gt; 54&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.LocalJobRunner: Starting task: attempt_local325822439_0001_m_000002_0
&lt;/span&gt;&lt;span&gt; 55&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
&lt;/span&gt;&lt;span&gt; 56&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
&lt;/span&gt;&lt;span&gt; 57&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
&lt;/span&gt;&lt;span&gt; 58&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: Processing split: file:/usr/local/hadoop/input/kms-site.xml:0+5939
&lt;/span&gt;&lt;span&gt; 59&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
&lt;/span&gt;&lt;span&gt; 60&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
&lt;/span&gt;&lt;span&gt; 61&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: soft limit at 83886080
&lt;/span&gt;&lt;span&gt; 62&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
&lt;/span&gt;&lt;span&gt; 63&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
&lt;/span&gt;&lt;span&gt; 64&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
&lt;/span&gt;&lt;span&gt; 65&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.LocalJobRunner: 
&lt;/span&gt;&lt;span&gt; 66&lt;/span&gt; &lt;span&gt;18/03/03 11:20:32 INFO mapred.MapTask: Starting flush of map output
&lt;/span&gt;&lt;span&gt; 67&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.Task: Task:attempt_local325822439_0001_m_000002_0 is done. And is in the process of committing
&lt;/span&gt;&lt;span&gt; 68&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: map
&lt;/span&gt;&lt;span&gt; 69&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.Task: Task 'attempt_local325822439_0001_m_000002_0' done.
&lt;/span&gt;&lt;span&gt; 70&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local325822439_0001_m_000002_0
&lt;/span&gt;&lt;span&gt; 71&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: Starting task: attempt_local325822439_0001_m_000003_0
&lt;/span&gt;&lt;span&gt; 72&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
&lt;/span&gt;&lt;span&gt; 73&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
&lt;/span&gt;&lt;span&gt; 74&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
&lt;/span&gt;&lt;span&gt; 75&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: Processing split: file:/usr/local/hadoop/input/kms-acls.xml:0+3518
&lt;/span&gt;&lt;span&gt; 76&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
&lt;/span&gt;&lt;span&gt; 77&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
&lt;/span&gt;&lt;span&gt; 78&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: soft limit at 83886080
&lt;/span&gt;&lt;span&gt; 79&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
&lt;/span&gt;&lt;span&gt; 80&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
&lt;/span&gt;&lt;span&gt; 81&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
&lt;/span&gt;&lt;span&gt; 82&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: 
&lt;/span&gt;&lt;span&gt; 83&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: Starting flush of map output
&lt;/span&gt;&lt;span&gt; 84&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapreduce.Job:  map 38% reduce 0%
&lt;/span&gt;&lt;span&gt; 85&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.Task: Task:attempt_local325822439_0001_m_000003_0 is done. And is in the process of committing
&lt;/span&gt;&lt;span&gt; 86&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: map
&lt;/span&gt;&lt;span&gt; 87&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.Task: Task 'attempt_local325822439_0001_m_000003_0' done.
&lt;/span&gt;&lt;span&gt; 88&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local325822439_0001_m_000003_0
&lt;/span&gt;&lt;span&gt; 89&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: Starting task: attempt_local325822439_0001_m_000004_0
&lt;/span&gt;&lt;span&gt; 90&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
&lt;/span&gt;&lt;span&gt; 91&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
&lt;/span&gt;&lt;span&gt; 92&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
&lt;/span&gt;&lt;span&gt; 93&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: Processing split: file:/usr/local/hadoop/input/hdfs-site.xml:0+775
&lt;/span&gt;&lt;span&gt; 94&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
&lt;/span&gt;&lt;span&gt; 95&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
&lt;/span&gt;&lt;span&gt; 96&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: soft limit at 83886080
&lt;/span&gt;&lt;span&gt; 97&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
&lt;/span&gt;&lt;span&gt; 98&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
&lt;/span&gt;&lt;span&gt; 99&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
&lt;/span&gt;&lt;span&gt;100&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: 
&lt;/span&gt;&lt;span&gt;101&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: Starting flush of map output
&lt;/span&gt;&lt;span&gt;102&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.Task: Task:attempt_local325822439_0001_m_000004_0 is done. And is in the process of committing
&lt;/span&gt;&lt;span&gt;103&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: map
&lt;/span&gt;&lt;span&gt;104&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.Task: Task 'attempt_local325822439_0001_m_000004_0' done.
&lt;/span&gt;&lt;span&gt;105&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local325822439_0001_m_000004_0
&lt;/span&gt;&lt;span&gt;106&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: Starting task: attempt_local325822439_0001_m_000005_0
&lt;/span&gt;&lt;span&gt;107&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
&lt;/span&gt;&lt;span&gt;108&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
&lt;/span&gt;&lt;span&gt;109&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
&lt;/span&gt;&lt;span&gt;110&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: Processing split: file:/usr/local/hadoop/input/core-site.xml:0+774
&lt;/span&gt;&lt;span&gt;111&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
&lt;/span&gt;&lt;span&gt;112&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
&lt;/span&gt;&lt;span&gt;113&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: soft limit at 83886080
&lt;/span&gt;&lt;span&gt;114&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
&lt;/span&gt;&lt;span&gt;115&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
&lt;/span&gt;&lt;span&gt;116&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
&lt;/span&gt;&lt;span&gt;117&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: 
&lt;/span&gt;&lt;span&gt;118&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: Starting flush of map output
&lt;/span&gt;&lt;span&gt;119&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.Task: Task:attempt_local325822439_0001_m_000005_0 is done. And is in the process of committing
&lt;/span&gt;&lt;span&gt;120&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: map
&lt;/span&gt;&lt;span&gt;121&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.Task: Task 'attempt_local325822439_0001_m_000005_0' done.
&lt;/span&gt;&lt;span&gt;122&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: Finishing task: attempt_local325822439_0001_m_000005_0
&lt;/span&gt;&lt;span&gt;123&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: Starting task: attempt_local325822439_0001_m_000006_0
&lt;/span&gt;&lt;span&gt;124&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
&lt;/span&gt;&lt;span&gt;125&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
&lt;/span&gt;&lt;span&gt;126&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
&lt;/span&gt;&lt;span&gt;127&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: Processing split: file:/usr/local/hadoop/input/yarn-site.xml:0+690
&lt;/span&gt;&lt;span&gt;128&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
&lt;/span&gt;&lt;span&gt;129&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
&lt;/span&gt;&lt;span&gt;130&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: soft limit at 83886080
&lt;/span&gt;&lt;span&gt;131&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
&lt;/span&gt;&lt;span&gt;132&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
&lt;/span&gt;&lt;span&gt;133&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
&lt;/span&gt;&lt;span&gt;134&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.LocalJobRunner: 
&lt;/span&gt;&lt;span&gt;135&lt;/span&gt; &lt;span&gt;18/03/03 11:20:33 INFO mapred.MapTask: Starting flush of map output
&lt;/span&gt;&lt;span&gt;136&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.Task: Task:attempt_local325822439_0001_m_000006_0 is done. And is in the process of committing
&lt;/span&gt;&lt;span&gt;137&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.LocalJobRunner: map
&lt;/span&gt;&lt;span&gt;138&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.Task: Task 'attempt_local325822439_0001_m_000006_0' done.
&lt;/span&gt;&lt;span&gt;139&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local325822439_0001_m_000006_0
&lt;/span&gt;&lt;span&gt;140&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.LocalJobRunner: Starting task: attempt_local325822439_0001_m_000007_0
&lt;/span&gt;&lt;span&gt;141&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
&lt;/span&gt;&lt;span&gt;142&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
&lt;/span&gt;&lt;span&gt;143&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
&lt;/span&gt;&lt;span&gt;144&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.MapTask: Processing split: file:/usr/local/hadoop/input/httpfs-site.xml:0+620
&lt;/span&gt;&lt;span&gt;145&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
&lt;/span&gt;&lt;span&gt;146&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
&lt;/span&gt;&lt;span&gt;147&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.MapTask: soft limit at 83886080
&lt;/span&gt;&lt;span&gt;148&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
&lt;/span&gt;&lt;span&gt;149&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
&lt;/span&gt;&lt;span&gt;150&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
&lt;/span&gt;&lt;span&gt;151&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.LocalJobRunner: 
&lt;/span&gt;&lt;span&gt;152&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.MapTask: Starting flush of map output
&lt;/span&gt;&lt;span&gt;153&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.Task: Task:attempt_local325822439_0001_m_000007_0 is done. And is in the process of committing
&lt;/span&gt;&lt;span&gt;154&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.LocalJobRunner: map
&lt;/span&gt;&lt;span&gt;155&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.Task: Task 'attempt_local325822439_0001_m_000007_0' done.
&lt;/span&gt;&lt;span&gt;156&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local325822439_0001_m_000007_0
&lt;/span&gt;&lt;span&gt;157&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.LocalJobRunner: map task executor complete.
&lt;/span&gt;&lt;span&gt;158&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.LocalJobRunner: Waiting for reduce tasks
&lt;/span&gt;&lt;span&gt;159&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.LocalJobRunner: Starting task: attempt_local325822439_0001_r_000000_0
&lt;/span&gt;&lt;span&gt;160&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
&lt;/span&gt;&lt;span&gt;161&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
&lt;/span&gt;&lt;span&gt;162&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
&lt;/span&gt;&lt;span&gt;163&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@362850fb
&lt;/span&gt;&lt;span&gt;164&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=369937600, maxSingleShuffleLimit=92484400, mergeThreshold=244158832, ioSortFactor=10, memToMemMergeOutputsThreshold=10
&lt;/span&gt;&lt;span&gt;165&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.EventFetcher: attempt_local325822439_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
&lt;/span&gt;&lt;span&gt;166&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapreduce.Job:  map 100% reduce 0%
&lt;/span&gt;&lt;span&gt;167&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local325822439_0001_m_000003_0 decomp: 2 len: 6 to MEMORY
&lt;/span&gt;&lt;span&gt;168&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local325822439_0001_m_000003_0
&lt;/span&gt;&lt;span&gt;169&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.MergeManagerImpl: closeInMemoryFile -&amp;gt; map-output of size: 2, inMemoryMapOutputs.size() -&amp;gt; 1, commitMemory -&amp;gt; 0, usedMemory -&amp;gt;2
&lt;/span&gt;&lt;span&gt;170&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local325822439_0001_m_000000_0 decomp: 21 len: 25 to MEMORY
&lt;/span&gt;&lt;span&gt;171&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.InMemoryMapOutput: Read 21 bytes from map-output for attempt_local325822439_0001_m_000000_0
&lt;/span&gt;&lt;span&gt;172&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.MergeManagerImpl: closeInMemoryFile -&amp;gt; map-output of size: 21, inMemoryMapOutputs.size() -&amp;gt; 2, commitMemory -&amp;gt; 2, usedMemory -&amp;gt;23
&lt;/span&gt;&lt;span&gt;173&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local325822439_0001_m_000006_0 decomp: 2 len: 6 to MEMORY
&lt;/span&gt;&lt;span&gt;174&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local325822439_0001_m_000006_0
&lt;/span&gt;&lt;span&gt;175&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.MergeManagerImpl: closeInMemoryFile -&amp;gt; map-output of size: 2, inMemoryMapOutputs.size() -&amp;gt; 3, commitMemory -&amp;gt; 23, usedMemory -&amp;gt;25
&lt;/span&gt;&lt;span&gt;176&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local325822439_0001_m_000005_0 decomp: 2 len: 6 to MEMORY
&lt;/span&gt;&lt;span&gt;177&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local325822439_0001_m_000005_0
&lt;/span&gt;&lt;span&gt;178&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.MergeManagerImpl: closeInMemoryFile -&amp;gt; map-output of size: 2, inMemoryMapOutputs.size() -&amp;gt; 4, commitMemory -&amp;gt; 25, usedMemory -&amp;gt;27
&lt;/span&gt;&lt;span&gt;179&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 WARN io.ReadaheadPool: Failed readahead on ifile
&lt;/span&gt;&lt;span&gt;180&lt;/span&gt; &lt;span&gt;EBADF: Bad file descriptor
&lt;/span&gt;&lt;span&gt;181&lt;/span&gt; &lt;span&gt;    at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
&lt;/span&gt;&lt;span&gt;182&lt;/span&gt; &lt;span&gt;    at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
&lt;/span&gt;&lt;span&gt;183&lt;/span&gt; &lt;span&gt;    at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
&lt;/span&gt;&lt;span&gt;184&lt;/span&gt; &lt;span&gt;    at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)
&lt;/span&gt;&lt;span&gt;185&lt;/span&gt; &lt;span&gt;    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
&lt;/span&gt;&lt;span&gt;186&lt;/span&gt; &lt;span&gt;    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
&lt;/span&gt;&lt;span&gt;187&lt;/span&gt; &lt;span&gt;    at java.lang.Thread.run(Thread.java:745)
&lt;/span&gt;&lt;span&gt;188&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local325822439_0001_m_000001_0 decomp: 2 len: 6 to MEMORY
&lt;/span&gt;&lt;span&gt;189&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local325822439_0001_m_000001_0
&lt;/span&gt;&lt;span&gt;190&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.MergeManagerImpl: closeInMemoryFile -&amp;gt; map-output of size: 2, inMemoryMapOutputs.size() -&amp;gt; 5, commitMemory -&amp;gt; 27, usedMemory -&amp;gt;29
&lt;/span&gt;&lt;span&gt;191&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local325822439_0001_m_000004_0 decomp: 2 len: 6 to MEMORY
&lt;/span&gt;&lt;span&gt;192&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local325822439_0001_m_000004_0
&lt;/span&gt;&lt;span&gt;193&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.MergeManagerImpl: closeInMemoryFile -&amp;gt; map-output of size: 2, inMemoryMapOutputs.size() -&amp;gt; 6, commitMemory -&amp;gt; 29, usedMemory -&amp;gt;31
&lt;/span&gt;&lt;span&gt;194&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local325822439_0001_m_000007_0 decomp: 2 len: 6 to MEMORY
&lt;/span&gt;&lt;span&gt;195&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local325822439_0001_m_000007_0
&lt;/span&gt;&lt;span&gt;196&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.MergeManagerImpl: closeInMemoryFile -&amp;gt; map-output of size: 2, inMemoryMapOutputs.size() -&amp;gt; 7, commitMemory -&amp;gt; 31, usedMemory -&amp;gt;33
&lt;/span&gt;&lt;span&gt;197&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local325822439_0001_m_000002_0 decomp: 2 len: 6 to MEMORY
&lt;/span&gt;&lt;span&gt;198&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local325822439_0001_m_000002_0
&lt;/span&gt;&lt;span&gt;199&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.MergeManagerImpl: closeInMemoryFile -&amp;gt; map-output of size: 2, inMemoryMapOutputs.size() -&amp;gt; 8, commitMemory -&amp;gt; 33, usedMemory -&amp;gt;35
&lt;/span&gt;&lt;span&gt;200&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
&lt;/span&gt;&lt;span&gt;201&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.LocalJobRunner: 8 / 8 copied.
&lt;/span&gt;&lt;span&gt;202&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.MergeManagerImpl: finalMerge called with 8 in-memory map-outputs and 0 on-disk map-outputs
&lt;/span&gt;&lt;span&gt;203&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.Merger: Merging 8 sorted segments
&lt;/span&gt;&lt;span&gt;204&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 10 bytes
&lt;/span&gt;&lt;span&gt;205&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.MergeManagerImpl: Merged 8 segments, 35 bytes to disk to satisfy reduce memory limit
&lt;/span&gt;&lt;span&gt;206&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.MergeManagerImpl: Merging 1 files, 25 bytes from disk
&lt;/span&gt;&lt;span&gt;207&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
&lt;/span&gt;&lt;span&gt;208&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.Merger: Merging 1 sorted segments
&lt;/span&gt;&lt;span&gt;209&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 10 bytes
&lt;/span&gt;&lt;span&gt;210&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.LocalJobRunner: 8 / 8 copied.
&lt;/span&gt;&lt;span&gt;211&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
&lt;/span&gt;&lt;span&gt;212&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.Task: Task:attempt_local325822439_0001_r_000000_0 is done. And is in the process of committing
&lt;/span&gt;&lt;span&gt;213&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.LocalJobRunner: 8 / 8 copied.
&lt;/span&gt;&lt;span&gt;214&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.Task: Task attempt_local325822439_0001_r_000000_0 is allowed to commit now
&lt;/span&gt;&lt;span&gt;215&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO output.FileOutputCommitter: Saved output of task 'attempt_local325822439_0001_r_000000_0' to file:/usr/local/hadoop/grep-temp-876870354/_temporary/0/task_local325822439_0001_r_000000
&lt;/span&gt;&lt;span&gt;216&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.LocalJobRunner: reduce &amp;gt; reduce
&lt;/span&gt;&lt;span&gt;217&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.Task: Task 'attempt_local325822439_0001_r_000000_0' done.
&lt;/span&gt;&lt;span&gt;218&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.LocalJobRunner: Finishing task: attempt_local325822439_0001_r_000000_0
&lt;/span&gt;&lt;span&gt;219&lt;/span&gt; &lt;span&gt;18/03/03 11:20:34 INFO mapred.LocalJobRunner: reduce task executor complete.
&lt;/span&gt;&lt;span&gt;220&lt;/span&gt; &lt;span&gt;18/03/03 11:20:35 INFO mapreduce.Job:  map 100% reduce 100%
&lt;/span&gt;&lt;span&gt;221&lt;/span&gt; &lt;span&gt;18/03/03 11:20:35 INFO mapreduce.Job: Job job_local325822439_0001 completed successfully
&lt;/span&gt;&lt;span&gt;222&lt;/span&gt; &lt;span&gt;18/03/03 11:20:35 INFO mapreduce.Job: Counters: 30
&lt;/span&gt;&lt;span&gt;223&lt;/span&gt; &lt;span&gt;    File System Counters
&lt;/span&gt;&lt;span&gt;224&lt;/span&gt; &lt;span&gt;        FILE: Number of bytes read=2993922
&lt;/span&gt;&lt;span&gt;225&lt;/span&gt; &lt;span&gt;        FILE: Number of bytes written=7026239
&lt;/span&gt;&lt;span&gt;226&lt;/span&gt; &lt;span&gt;        FILE: Number of read operations=0
&lt;/span&gt;&lt;span&gt;227&lt;/span&gt; &lt;span&gt;        FILE: Number of large read operations=0
&lt;/span&gt;&lt;span&gt;228&lt;/span&gt; &lt;span&gt;        FILE: Number of write operations=0
&lt;/span&gt;&lt;span&gt;229&lt;/span&gt; &lt;span&gt;    Map-Reduce Framework
&lt;/span&gt;&lt;span&gt;230&lt;/span&gt; &lt;span&gt;        Map input records=840
&lt;/span&gt;&lt;span&gt;231&lt;/span&gt; &lt;span&gt;        Map output records=1
&lt;/span&gt;&lt;span&gt;232&lt;/span&gt; &lt;span&gt;        Map output bytes=17
&lt;/span&gt;&lt;span&gt;233&lt;/span&gt; &lt;span&gt;        Map output materialized bytes=67
&lt;/span&gt;&lt;span&gt;234&lt;/span&gt; &lt;span&gt;        Input split bytes=869
&lt;/span&gt;&lt;span&gt;235&lt;/span&gt; &lt;span&gt;        Combine input records=1
&lt;/span&gt;&lt;span&gt;236&lt;/span&gt; &lt;span&gt;        Combine output records=1
&lt;/span&gt;&lt;span&gt;237&lt;/span&gt; &lt;span&gt;        Reduce input groups=1
&lt;/span&gt;&lt;span&gt;238&lt;/span&gt; &lt;span&gt;        Reduce shuffle bytes=67
&lt;/span&gt;&lt;span&gt;239&lt;/span&gt; &lt;span&gt;        Reduce input records=1
&lt;/span&gt;&lt;span&gt;240&lt;/span&gt; &lt;span&gt;        Reduce output records=1
&lt;/span&gt;&lt;span&gt;241&lt;/span&gt; &lt;span&gt;        Spilled Records=2
&lt;/span&gt;&lt;span&gt;242&lt;/span&gt; &lt;span&gt;        Shuffled Maps =8
&lt;/span&gt;&lt;span&gt;243&lt;/span&gt; &lt;span&gt;        Failed Shuffles=0
&lt;/span&gt;&lt;span&gt;244&lt;/span&gt; &lt;span&gt;        Merged Map outputs=8
&lt;/span&gt;&lt;span&gt;245&lt;/span&gt; &lt;span&gt;        GC time elapsed (ms)=120
&lt;/span&gt;&lt;span&gt;246&lt;/span&gt; &lt;span&gt;        Total committed heap usage (bytes)=3988258816
&lt;/span&gt;&lt;span&gt;247&lt;/span&gt; &lt;span&gt;    Shuffle Errors
&lt;/span&gt;&lt;span&gt;248&lt;/span&gt; &lt;span&gt;        BAD_ID=0
&lt;/span&gt;&lt;span&gt;249&lt;/span&gt; &lt;span&gt;        CONNECTION=0
&lt;/span&gt;&lt;span&gt;250&lt;/span&gt; &lt;span&gt;        IO_ERROR=0
&lt;/span&gt;&lt;span&gt;251&lt;/span&gt; &lt;span&gt;        WRONG_LENGTH=0
&lt;/span&gt;&lt;span&gt;252&lt;/span&gt; &lt;span&gt;        WRONG_MAP=0
&lt;/span&gt;&lt;span&gt;253&lt;/span&gt; &lt;span&gt;        WRONG_REDUCE=0
&lt;/span&gt;&lt;span&gt;254&lt;/span&gt; &lt;span&gt;    File Input Format Counters 
&lt;/span&gt;&lt;span&gt;255&lt;/span&gt; &lt;span&gt;        Bytes Read=30383
&lt;/span&gt;&lt;span&gt;256&lt;/span&gt; &lt;span&gt;    File Output Format Counters 
&lt;/span&gt;&lt;span&gt;257&lt;/span&gt; &lt;span&gt;        Bytes Written=123
&lt;/span&gt;&lt;span&gt;258&lt;/span&gt; &lt;span&gt;18/03/03 11:20:35 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
&lt;/span&gt;&lt;span&gt;259&lt;/span&gt; &lt;span&gt;18/03/03 11:20:35 INFO input.FileInputFormat: Total input files to process : 1
&lt;/span&gt;&lt;span&gt;260&lt;/span&gt; &lt;span&gt;18/03/03 11:20:35 INFO mapreduce.JobSubmitter: number of splits:1
&lt;/span&gt;&lt;span&gt;261&lt;/span&gt; &lt;span&gt;18/03/03 11:20:35 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1695778912_0002
&lt;/span&gt;&lt;span&gt;262&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
&lt;/span&gt;&lt;span&gt;263&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapreduce.Job: Running job: job_local1695778912_0002
&lt;/span&gt;&lt;span&gt;264&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: OutputCommitter set in config null
&lt;/span&gt;&lt;span&gt;265&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
&lt;/span&gt;&lt;span&gt;266&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
&lt;/span&gt;&lt;span&gt;267&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
&lt;/span&gt;&lt;span&gt;268&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: Waiting for map tasks
&lt;/span&gt;&lt;span&gt;269&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1695778912_0002_m_000000_0
&lt;/span&gt;&lt;span&gt;270&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
&lt;/span&gt;&lt;span&gt;271&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
&lt;/span&gt;&lt;span&gt;272&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
&lt;/span&gt;&lt;span&gt;273&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.MapTask: Processing split: file:/usr/local/hadoop/grep-temp-876870354/part-r-00000:0+111
&lt;/span&gt;&lt;span&gt;274&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
&lt;/span&gt;&lt;span&gt;275&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
&lt;/span&gt;&lt;span&gt;276&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.MapTask: soft limit at 83886080
&lt;/span&gt;&lt;span&gt;277&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
&lt;/span&gt;&lt;span&gt;278&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
&lt;/span&gt;&lt;span&gt;279&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
&lt;/span&gt;&lt;span&gt;280&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: 
&lt;/span&gt;&lt;span&gt;281&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.MapTask: Starting flush of map output
&lt;/span&gt;&lt;span&gt;282&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.MapTask: Spilling map output
&lt;/span&gt;&lt;span&gt;283&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.MapTask: bufstart = 0; bufend = 17; bufvoid = 104857600
&lt;/span&gt;&lt;span&gt;284&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
&lt;/span&gt;&lt;span&gt;285&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.MapTask: Finished spill 0
&lt;/span&gt;&lt;span&gt;286&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.Task: Task:attempt_local1695778912_0002_m_000000_0 is done. And is in the process of committing
&lt;/span&gt;&lt;span&gt;287&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: map
&lt;/span&gt;&lt;span&gt;288&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.Task: Task 'attempt_local1695778912_0002_m_000000_0' done.
&lt;/span&gt;&lt;span&gt;289&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1695778912_0002_m_000000_0
&lt;/span&gt;&lt;span&gt;290&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: map task executor complete.
&lt;/span&gt;&lt;span&gt;291&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: Waiting for reduce tasks
&lt;/span&gt;&lt;span&gt;292&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: Starting task: attempt_local1695778912_0002_r_000000_0
&lt;/span&gt;&lt;span&gt;293&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
&lt;/span&gt;&lt;span&gt;294&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
&lt;/span&gt;&lt;span&gt;295&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
&lt;/span&gt;&lt;span&gt;296&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@18e6a4dc
&lt;/span&gt;&lt;span&gt;297&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=370304608, maxSingleShuffleLimit=92576152, mergeThreshold=244401056, ioSortFactor=10, memToMemMergeOutputsThreshold=10
&lt;/span&gt;&lt;span&gt;298&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO reduce.EventFetcher: attempt_local1695778912_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
&lt;/span&gt;&lt;span&gt;299&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1695778912_0002_m_000000_0 decomp: 21 len: 25 to MEMORY
&lt;/span&gt;&lt;span&gt;300&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO reduce.InMemoryMapOutput: Read 21 bytes from map-output for attempt_local1695778912_0002_m_000000_0
&lt;/span&gt;&lt;span&gt;301&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO reduce.MergeManagerImpl: closeInMemoryFile -&amp;gt; map-output of size: 21, inMemoryMapOutputs.size() -&amp;gt; 1, commitMemory -&amp;gt; 0, usedMemory -&amp;gt;21
&lt;/span&gt;&lt;span&gt;302&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
&lt;/span&gt;&lt;span&gt;303&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: 1 / 1 copied.
&lt;/span&gt;&lt;span&gt;304&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
&lt;/span&gt;&lt;span&gt;305&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.Merger: Merging 1 sorted segments
&lt;/span&gt;&lt;span&gt;306&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 11 bytes
&lt;/span&gt;&lt;span&gt;307&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO reduce.MergeManagerImpl: Merged 1 segments, 21 bytes to disk to satisfy reduce memory limit
&lt;/span&gt;&lt;span&gt;308&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO reduce.MergeManagerImpl: Merging 1 files, 25 bytes from disk
&lt;/span&gt;&lt;span&gt;309&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
&lt;/span&gt;&lt;span&gt;310&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.Merger: Merging 1 sorted segments
&lt;/span&gt;&lt;span&gt;311&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 11 bytes
&lt;/span&gt;&lt;span&gt;312&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: 1 / 1 copied.
&lt;/span&gt;&lt;span&gt;313&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.Task: Task:attempt_local1695778912_0002_r_000000_0 is done. And is in the process of committing
&lt;/span&gt;&lt;span&gt;314&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: 1 / 1 copied.
&lt;/span&gt;&lt;span&gt;315&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.Task: Task attempt_local1695778912_0002_r_000000_0 is allowed to commit now
&lt;/span&gt;&lt;span&gt;316&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1695778912_0002_r_000000_0' to file:/usr/local/hadoop/output/_temporary/0/task_local1695778912_0002_r_000000
&lt;/span&gt;&lt;span&gt;317&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: reduce &amp;gt; reduce
&lt;/span&gt;&lt;span&gt;318&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.Task: Task 'attempt_local1695778912_0002_r_000000_0' done.
&lt;/span&gt;&lt;span&gt;319&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: Finishing task: attempt_local1695778912_0002_r_000000_0
&lt;/span&gt;&lt;span&gt;320&lt;/span&gt; &lt;span&gt;18/03/03 11:20:36 INFO mapred.LocalJobRunner: reduce task executor complete.
&lt;/span&gt;&lt;span&gt;321&lt;/span&gt; &lt;span&gt;18/03/03 11:20:37 INFO mapreduce.Job: Job job_local1695778912_0002 running in uber mode : false
&lt;/span&gt;&lt;span&gt;322&lt;/span&gt; &lt;span&gt;18/03/03 11:20:37 INFO mapreduce.Job:  map 100% reduce 100%
&lt;/span&gt;&lt;span&gt;323&lt;/span&gt; &lt;span&gt;18/03/03 11:20:37 INFO mapreduce.Job: Job job_local1695778912_0002 completed successfully
&lt;/span&gt;&lt;span&gt;324&lt;/span&gt; &lt;span&gt;18/03/03 11:20:37 INFO mapreduce.Job: Counters: 30
&lt;/span&gt;&lt;span&gt;325&lt;/span&gt; &lt;span&gt;    File System Counters
&lt;/span&gt;&lt;span&gt;326&lt;/span&gt; &lt;span&gt;        FILE: Number of bytes read=1286912
&lt;/span&gt;&lt;span&gt;327&lt;/span&gt; &lt;span&gt;        FILE: Number of bytes written=3123146
&lt;/span&gt;&lt;span&gt;328&lt;/span&gt; &lt;span&gt;        FILE: Number of read operations=0
&lt;/span&gt;&lt;span&gt;329&lt;/span&gt; &lt;span&gt;        FILE: Number of large read operations=0
&lt;/span&gt;&lt;span&gt;330&lt;/span&gt; &lt;span&gt;        FILE: Number of write operations=0
&lt;/span&gt;&lt;span&gt;331&lt;/span&gt; &lt;span&gt;    Map-Reduce Framework
&lt;/span&gt;&lt;span&gt;332&lt;/span&gt; &lt;span&gt;        Map input records=1
&lt;/span&gt;&lt;span&gt;333&lt;/span&gt; &lt;span&gt;        Map output records=1
&lt;/span&gt;&lt;span&gt;334&lt;/span&gt; &lt;span&gt;        Map output bytes=17
&lt;/span&gt;&lt;span&gt;335&lt;/span&gt; &lt;span&gt;        Map output materialized bytes=25
&lt;/span&gt;&lt;span&gt;336&lt;/span&gt; &lt;span&gt;        Input split bytes=120
&lt;/span&gt;&lt;span&gt;337&lt;/span&gt; &lt;span&gt;        Combine input records=0
&lt;/span&gt;&lt;span&gt;338&lt;/span&gt; &lt;span&gt;        Combine output records=0
&lt;/span&gt;&lt;span&gt;339&lt;/span&gt; &lt;span&gt;        Reduce input groups=1
&lt;/span&gt;&lt;span&gt;340&lt;/span&gt; &lt;span&gt;        Reduce shuffle bytes=25
&lt;/span&gt;&lt;span&gt;341&lt;/span&gt; &lt;span&gt;        Reduce input records=1
&lt;/span&gt;&lt;span&gt;342&lt;/span&gt; &lt;span&gt;        Reduce output records=1
&lt;/span&gt;&lt;span&gt;343&lt;/span&gt; &lt;span&gt;        Spilled Records=2
&lt;/span&gt;&lt;span&gt;344&lt;/span&gt; &lt;span&gt;        Shuffled Maps =1
&lt;/span&gt;&lt;span&gt;345&lt;/span&gt; &lt;span&gt;        Failed Shuffles=0
&lt;/span&gt;&lt;span&gt;346&lt;/span&gt; &lt;span&gt;        Merged Map outputs=1
&lt;/span&gt;&lt;span&gt;347&lt;/span&gt; &lt;span&gt;        GC time elapsed (ms)=0
&lt;/span&gt;&lt;span&gt;348&lt;/span&gt; &lt;span&gt;        Total committed heap usage (bytes)=1058013184
&lt;/span&gt;&lt;span&gt;349&lt;/span&gt; &lt;span&gt;    Shuffle Errors
&lt;/span&gt;&lt;span&gt;350&lt;/span&gt; &lt;span&gt;        BAD_ID=0
&lt;/span&gt;&lt;span&gt;351&lt;/span&gt; &lt;span&gt;        CONNECTION=0
&lt;/span&gt;&lt;span&gt;352&lt;/span&gt; &lt;span&gt;        IO_ERROR=0
&lt;/span&gt;&lt;span&gt;353&lt;/span&gt; &lt;span&gt;        WRONG_LENGTH=0
&lt;/span&gt;&lt;span&gt;354&lt;/span&gt; &lt;span&gt;        WRONG_MAP=0
&lt;/span&gt;&lt;span&gt;355&lt;/span&gt; &lt;span&gt;        WRONG_REDUCE=0
&lt;/span&gt;&lt;span&gt;356&lt;/span&gt; &lt;span&gt;    File Input Format Counters 
&lt;/span&gt;&lt;span&gt;357&lt;/span&gt; &lt;span&gt;        Bytes Read=123
&lt;/span&gt;&lt;span&gt;358&lt;/span&gt; &lt;span&gt;    File Output Format Counters 
&lt;/span&gt;&lt;span&gt;359&lt;/span&gt;         Bytes Written=23
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;p&gt;    &lt;span&gt;然后我们使用如下命令来查看运行的结果，可以看到程序运行成功，找到一个符合这样规则的答案。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;span&gt;&lt;strong&gt;cat ./output/*&lt;/strong&gt;&lt;/span&gt;
&lt;span&gt;1    dfsadmin&lt;/span&gt;
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;span&gt;&lt;strong&gt;ll ./output/&lt;/strong&gt;&lt;/span&gt;
total 20
drwxrwxr-x  2 hadoop hadoop 4096  3月  3 11:20 ./
drwxr-xr-x 11 hadoop zyr    4096  3月  3 11:20 ../
-rw-r--r--  1 hadoop hadoop   11  3月  3 11:20 part-r-00000
-rw-r--r--  1 hadoop hadoop   12  3月  3 11:20 .part-r-00000.crc
-rw-r--r--  1 hadoop hadoop    0  3月  3 11:20 _SUCCESS
-rw-r--r--  1 hadoop hadoop    8  3月  3 11:20 ._SUCCESS.crc&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;  需要注意的是，我们接下来如果还要运行的计划，如果命令中的output不变是会出错的，错误是系统中已经存在这样的文件夹了，这里我们需要删除output文件夹然后再运行就好了！&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;strong&gt;rm -r ./output&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;  再比如下面的WordCount程序，执行之后输入相应的结果。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;strong&gt; ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.0.jar  wordcount ./input  ./output&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt; 六、&lt;span&gt;Hadoop伪分布式实例测试，HDFS&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;      &lt;span&gt;到这里，我们还没用到HDFS，下面就需要配置相关的文件，使得我们可以使用网络浏览器来查看程序运行情况，并且监控HDFS了。在修改文件之前，我们要养成好习惯，&lt;strong&gt;先备份再修改，&lt;/strong&gt;这样我们就算是错误了还是可以回滚的，在这里需要在:&lt;span&gt;&lt;strong&gt;/usr/local/hadoop/etc/hadoop/&lt;/strong&gt;&lt;/span&gt;下修改两个文件：&lt;span&gt;&lt;strong&gt;core-site.xml&lt;/strong&gt;&lt;/span&gt;和&lt;span&gt;&lt;strong&gt;hdfs-site.xml&lt;span&gt;，&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;具体的修改代码如下：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:~$&lt;span&gt;&lt;strong&gt; cd  /usr/local/hadoop/&lt;/strong&gt;&lt;/span&gt;

hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;strong&gt;&lt;span&gt;cp ./etc/hadoop/core-site.xml  ./etc/hadoop/core-site.xml.backup&lt;/span&gt;&lt;/strong&gt;
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;strong&gt;&lt;span&gt; gedit ./etc/hadoop/core-site.xml
&lt;/span&gt;&lt;/strong&gt;
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;strong&gt;&lt;span&gt;cp ./etc/hadoop/hdfs-site.xml  ./etc/hadoop/hdfs-site.xml.backup&lt;/span&gt;&lt;/strong&gt;
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;span&gt;&lt;strong&gt;gedit ./etc/hadoop/hdfs-site.xml&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;     &lt;span&gt;在&lt;span&gt;&lt;strong&gt;core-site.xml&lt;/strong&gt;&lt;/span&gt;文件下，我们加入如下代码，其实就是将配置里面填充数据，里面默认为空。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;configuration&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;property&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
             &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;hadoop.tmp.dir&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
             &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;value&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;file:/usr/local/hadoop/tmp&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;value&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
             &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;description&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;Abase for other temporary directories.&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;description&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;property&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;property&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
             &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;fs.defaultFS&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
             &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;value&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;hdfs://localhost:9000&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;value&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;property&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;configuration&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;   &lt;span&gt;在&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;strong&gt;hdfs-site.xml&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;文件下，我们加入：&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;configuration&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;property&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
             &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;dfs.replication&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
             &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;value&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;1&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;value&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;property&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;property&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
             &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;dfs.namenode.name.dir&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
             &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;value&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;value&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;property&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;property&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
             &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;dfs.datanode.data.dir&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
             &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;value&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;value&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;property&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;configuration&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;      &lt;span&gt;然后我们使用&lt;span&gt;&lt;span&gt;&lt;strong&gt;./bin/hdfs namenode -format&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt; 格式化namenode节点&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;span&gt;&lt;strong&gt;./bin/hdfs namenode -format&lt;/strong&gt;&lt;/span&gt;
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = zyr-Aspire-V5-551G/127.0.1.1
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 2.9.0
STARTUP_MSG:   classpath = 
……
18/03/03 12:48:03 INFO common.Storage: &lt;strong&gt;&lt;span&gt;Storage directory /usr/local/hadoop/tmp/dfs/name has been successfully formatted.&lt;/span&gt;&lt;/strong&gt;
…...
18/03/03 12:48:03 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at zyr-Aspire-V5-551G/127.0.1.1
************************************************************/&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;   开启 NameNode 和 DataNode 守护进程:&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;strong&gt;&lt;span&gt;ls&lt;/span&gt;&lt;/strong&gt;
bin  include  lib      LICENSE.txt  output      sbin   tmp
etc  input    libexec  NOTICE.txt   README.txt  share

hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;span&gt;&lt;strong&gt;./sbin/start-dfs.sh&lt;/strong&gt;&lt;/span&gt;
Starting namenodes on [localhost]
localhost: starting &lt;span&gt;&lt;strong&gt;namenode&lt;/strong&gt;&lt;/span&gt;, logging to /usr/local/hadoop/logs/hadoop-hadoop-namenode-zyr-Aspire-V5-551G.out
localhost: starting &lt;strong&gt;&lt;span&gt;datanode&lt;/span&gt;&lt;/strong&gt;, logging to /usr/local/hadoop/logs/hadoop-hadoop-datanode-zyr-Aspire-V5-551G.out
Starting &lt;span&gt;&lt;strong&gt;secondary namenodes&lt;/strong&gt;&lt;/span&gt; [0.0.0.0]
The authenticity of host '0.0.0.0 (0.0.0.0)' can't be established.
ECDSA key fingerprint is ca:78:98:94:a3:ae:56:dc:57:18:87:3e:d3:a6:13:cf.
Are you sure you want to continue connecting (yes/no)?&lt;strong&gt;&lt;span&gt; yes&lt;/span&gt;&lt;/strong&gt;
0.0.0.0: Warning: Permanently added '0.0.0.0' (ECDSA) to the list of known hosts.
0.0.0.0: starting &lt;strong&gt;&lt;span&gt;secondarynamenode&lt;/span&gt;&lt;/strong&gt;, logging to /usr/local/hadoop/logs/hadoop-hadoop-secondarynamenode-zyr-Aspire-V5-551G.out&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;  通过jps命令查看，必须全部出现才算安装成功：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;span&gt;&lt;strong&gt; jps&lt;/strong&gt;&lt;/span&gt;
&lt;span&gt;12225 SecondaryNameNode
11865 NameNode
11989 DataNode
12376 Jps&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;  &lt;span&gt;  如果出现错误，我们可以查看相关的日志来判断：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;strong&gt;&lt;span&gt;cd  /usr/local/hadoop/logs/&lt;/span&gt;&lt;/strong&gt;
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop/logs$&lt;span&gt;&lt;strong&gt; ll&lt;/strong&gt;&lt;/span&gt;
total 112
drwxrwxr-x  2 hadoop hadoop  4096  3月  3 12:56 ./
drwxr-xr-x 13 hadoop zyr     4096  3月  3 12:56 ../
-rw-rw-r--  1 hadoop hadoop 27917  3月  3 12:56 hadoop-hadoop-datanode-zyr-Aspire-V5-551G.log
-rw-rw-r--  1 hadoop hadoop   718  3月  3 12:56 hadoop-hadoop-datanode-zyr-Aspire-V5-551G.out
-rw-rw-r--  1 hadoop hadoop 33782  3月  3 12:58 hadoop-hadoop-namenode-zyr-Aspire-V5-551G.log
-rw-rw-r--  1 hadoop hadoop   718  3月  3 12:56 hadoop-hadoop-namenode-zyr-Aspire-V5-551G.out
-rw-rw-r--  1 hadoop hadoop 28631  3月  3 12:58 hadoop-hadoop-secondarynamenode-zyr-Aspire-V5-551G.log
-rw-rw-r--  1 hadoop hadoop   718  3月  3 12:56 hadoop-hadoop-secondarynamenode-zyr-Aspire-V5-551G.out
-rw-rw-r--  1 hadoop hadoop     0  3月  3 12:56 SecurityAuth-hadoop.audit

hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop/logs$ &lt;span&gt;&lt;strong&gt;cat hadoop-hadoop-datanode-zyr-Aspire-V5-551G.log&lt;/strong&gt; &lt;/span&gt;
2018-03-03 12:56:23,450 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
……&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;     &lt;span&gt;至此我们可以访问 Web 界面 &lt;strong&gt;&lt;span&gt;&lt;a target=&quot;_blank&quot;&gt;&lt;span&gt;http://localhost:50070&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt; 查看 NameNode 和 Datanode 信息，还可以在线查看 HDFS 中的文件。&lt;/span&gt;&lt;br/&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1157683/201803/1157683-20180303223856883-1123547219.png&quot; alt=&quot;&quot; width=&quot;734&quot; height=&quot;412&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    &lt;span&gt;让我们再一次运行样例程序，首先创建hdfs文件系统中的文件夹&lt;span&gt;&lt;span&gt;&lt;strong&gt;/user/hadoop&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;，我们可以在网页中看到。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;strong&gt;&lt;span&gt;ll&lt;/span&gt;&lt;/strong&gt;
total 176
drwxr-xr-x 13 hadoop zyr      4096  3月  3 12:56 ./
drwxr-xr-x 11 root   root     4096  3月  3 11:07 ../
drwxr-xr-x  2 hadoop zyr      4096 11月 14 07:28 bin/
drwxr-xr-x  3 hadoop zyr      4096 11月 14 07:28 etc/
drwxr-xr-x  2 hadoop zyr      4096 11月 14 07:28 include/
drwxrwxr-x  2 hadoop hadoop   4096  3月  3 11:18 input/
drwxr-xr-x  3 hadoop zyr      4096 11月 14 07:28 lib/
drwxr-xr-x  2 hadoop zyr      4096 11月 14 07:28 libexec/
-rw-r--r--  1 hadoop zyr    106210 11月 14 07:28 LICENSE.txt
drwxrwxr-x  2 hadoop hadoop   4096  3月  3 12:56 logs/
-rw-r--r--  1 hadoop zyr     15915 11月 14 07:28 NOTICE.txt
drwxrwxr-x  2 hadoop hadoop   4096  3月  3 12:23 output/
-rw-r--r--  1 hadoop zyr      1366 11月 14 07:28 README.txt
drwxr-xr-x  3 hadoop zyr      4096 11月 14 07:28 sbin/
drwxr-xr-x  4 hadoop zyr      4096 11月 14 07:28 share/
drwxrwxr-x  3 hadoop hadoop   4096  3月  3 12:48 tmp/

hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;span&gt;&lt;strong&gt; ./bin/hdfs dfs -mkdir -p /user/hadoop&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1157683/201803/1157683-20180303224252547-204114793.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;   &lt;span&gt;该文件夹是虚拟的，在真实的文件系统中不存在：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1157683/201803/1157683-20180303224352920-866526584.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;  我们查看自己的位置：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ pwd
&lt;span&gt;&lt;strong&gt;/usr/local/hadoop&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;  然后在虚拟的hdfs中，我们创建输入文件夹，并且从真实的文件系统中将文件通过hdfs的put命令放入该新加的文件夹中！&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;span&gt;&lt;strong&gt; ./bin/hdfs dfs -mkdir input&lt;/strong&gt;&lt;/span&gt;
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;strong&gt;&lt;span&gt;./bin/hdfs dfs -put ./etc/hadoop/*.xml input&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;   &lt;span&gt;我们还可以查看hdfs上的文件，通过网页查看来比较。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;span&gt;&lt;strong&gt;./bin/hdfs dfs -ls input&lt;/strong&gt;&lt;/span&gt;
Found 8 items
-rw-r--r--   1 hadoop supergroup       7861 2018-03-03 13:21 input/capacity-scheduler.xml
-rw-r--r--   1 hadoop supergroup       1117 2018-03-03 13:21 input/core-site.xml
-rw-r--r--   1 hadoop supergroup      10206 2018-03-03 13:21 input/hadoop-policy.xml
-rw-r--r--   1 hadoop supergroup       1187 2018-03-03 13:21 input/hdfs-site.xml
-rw-r--r--   1 hadoop supergroup        620 2018-03-03 13:21 input/httpfs-site.xml
-rw-r--r--   1 hadoop supergroup       3518 2018-03-03 13:21 input/kms-acls.xml
-rw-r--r--   1 hadoop supergroup       5939 2018-03-03 13:21 input/kms-site.xml
-rw-r--r--   1 hadoop supergroup        690 2018-03-03 13:21 input/yarn-site.xml&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1157683/201803/1157683-20180303224817756-1222901288.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;  之后我们执行和以前同样的命令，观察结果，发现使用第一个命令是没有结果的，原因是从本地文件系统中查找，我已经删除了这个文件夹，肯定找不到的，第二个是通过hdfs来查找，这次真的找到了结果，因为配置文件做出了改变，所以结果稍微有所变化。从侧面证明了，我们的系统是在hdfs上运行的。&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;span&gt;&lt;strong&gt;cat ./output/*&lt;/strong&gt;&lt;/span&gt;


hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;span&gt;&lt;strong&gt; ./bin/hdfs dfs -cat output/*&lt;/strong&gt;&lt;/span&gt;
1    dfsadmin
1    dfs.replication
1    dfs.namenode.name.dir
1    dfs.datanode.data.dir&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;   我将本地文件系统中的input和output都删除，但是从网站上依旧可以看到结果，更加证明了是在hdfs上运行的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1157683/201803/1157683-20180303225341706-1944576333.png&quot; alt=&quot;&quot;/&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1157683/201803/1157683-20180303225359103-1709620848.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;   那hdfs到底给我们提供了多少命令呢，让我们使用help来查看：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;span&gt;&lt;strong&gt; ./bin/hdfs dfs -help&lt;/strong&gt;&lt;/span&gt;
Usage: hadoop fs [generic options]
    [-appendToFile &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;localsrc&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; ... &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dst&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-cat [-ignoreCrc] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;src&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; ...]
    [-checksum &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;src&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; ...]
    [-chgrp [-R] GROUP PATH...]
    [-chmod [-R] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;MODE&lt;/span&gt;&lt;span&gt;[,MODE]... | OCTALMODE&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; PATH...]
    [-chown [-R] [OWNER][:[GROUP]] PATH...]
    [-copyFromLocal [-f] [-p] [-l] [-d] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;localsrc&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; ... &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dst&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;src&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; ... &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;localdst&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-count [-q] [-h] [-v] [-t [&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;storage &lt;/span&gt;&lt;span&gt;type&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;]] [-u] [-x] &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; ...]
    [-cp [-f] [-p | -p[topax]] [-d] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;src&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; ... &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dst&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-createSnapshot &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;snapshotDir&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; [&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;snapshotName&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]]
    [-deleteSnapshot &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;snapshotDir&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;snapshotName&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-df [-h] [&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; ...]]
    [-du [-s] [-h] [-x] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; ...]
    [-expunge]
    [-find &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; ... &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;expression&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; ...]
    [-get [-f] [-p] [-ignoreCrc] [-crc] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;src&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; ... &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;localdst&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-getfacl [-R] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-getfattr [-R] {-n name | -d} [-e en] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-getmerge [-nl] [-skip-empty-file] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;src&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;localdst&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-help [cmd ...]]
    [-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [&lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; ...]]
    [-mkdir [-p] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; ...]
    [-moveFromLocal &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;localsrc&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; ... &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dst&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-moveToLocal &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;src&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;localdst&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-mv &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;src&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; ... &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dst&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-put [-f] [-p] [-l] [-d] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;localsrc&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; ... &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dst&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-renameSnapshot &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;snapshotDir&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;oldName&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;newName&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-rm [-f] [-r|-R] [-skipTrash] [-safely] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;src&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; ...]
    [-rmdir [--ignore-fail-on-non-empty] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;dir&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; ...]
    [-setfacl [-R] [{-b|-k} {-m|-x &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;acl_spec&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;} &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;]|[--set &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;acl_spec&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]]
    [-setfattr {-n name [-v value] | -x name} &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-setrep [-R] [-w] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;rep&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; ...]
    [-stat [format] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; ...]
    [-tail [-f] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;file&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-test -[defsz] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt;]
    [-text [-ignoreCrc] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;src&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; ...]
    [-touchz &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; ...]
    [-truncate [-w] &lt;/span&gt;&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;length&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt; &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;path&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;&lt;span&gt; ...]
    [-usage [cmd ...]]
……&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    &lt;span&gt;  因此可以通过get将hdfs上的文件下载到本地：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;span&gt;&lt;strong&gt; ./bin/hdfs dfs -get output ./output&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1157683/201803/1157683-20180303225553612-1208678447.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;      &lt;span&gt;同样的，在hdfs上执行命令也需要注意文件夹不能一样，不然会报错：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1157683/201803/1157683-20180303225725768-2125438173.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;    &lt;span&gt;这个时候我们可以通过如下命令来删除：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;span&gt;&lt;strong&gt;./bin/hdfs dfs -rm -r output &lt;/strong&gt; &lt;/span&gt;
Deleted output&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;    &lt;span&gt;然后再执行这样就可以了。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;span&gt;&lt;strong&gt;./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output 'dfs[a-z.]+'&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;   &lt;span&gt;最后我们需要知道停止服务的命令：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;span&gt;&lt;strong&gt;./sbin/stop-dfs.sh&lt;/strong&gt;&lt;/span&gt;
Stopping namenodes on [localhost]
localhost: stopping namenode
localhost: stopping datanode
Stopping secondary namenodes [0.0.0.0]
0.0.0.0: stopping secondarynamenode
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;span&gt;&lt;strong&gt; ./sbin/start-dfs.sh&lt;/strong&gt; &lt;/span&gt;
Starting namenodes on [localhost]
localhost: starting namenode, logging to /usr/local/hadoop/logs/hadoop-hadoop-namenode-zyr-Aspire-V5-551G.out
localhost: starting datanode, logging to /usr/local/hadoop/logs/hadoop-hadoop-datanode-zyr-Aspire-V5-551G.out
Starting secondary namenodes [0.0.0.0]
0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-hadoop-secondarynamenode-zyr-Aspire-V5-551G.out&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt; 七、&lt;span&gt;安装YARN&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;   在完成了上面的操作，我们基本上算是进入了hadoop的大门了，但是我们也必须知道yarn这个资源管理器，因为这是MapReduce的下一个版本，安装方式很简单，只用修改几个文件即可，在单机/伪分布式系统中，我们不建议使用yarn，因为这会大大的拖慢运行速度，杀鸡焉用牛刀，真正的用处是在大型的分布式集群中才能发挥yarn的威力！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;   我们首先在配置文件中找到&lt;span&gt;mapred-site.xml.template&lt;/span&gt;这个文件，非常重要，将其备份之后，重命名成&lt;span&gt;mapred-site.xml&lt;/span&gt;，在对其进行修改，这样就完成了一大半工作了！&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;span&gt;&lt;strong&gt; pwd&lt;/strong&gt;&lt;/span&gt;
/usr/local/hadoop
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ cp ./etc/hadoop/mapred-site.xml.template  ./etc/hadoop/mapred-site.xml.template.backup
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ mv ./etc/hadoop/mapred-site.xml.template  ./etc/hadoop/mapred-site.xml
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ gedit ./etc/hadoop/mapred-site.xml
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ gedit ./etc/hadoop/yarn-site.xml&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;  修改的&lt;strong&gt;&lt;span&gt;mapred-site.xml&lt;/span&gt;&lt;/strong&gt;方法为，加入如下配置：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;configuration&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;property&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
             &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;mapreduce.framework.name&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
             &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;value&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;yarn&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;value&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;property&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;configuration&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;     &lt;span&gt;之后我们对&lt;span&gt;&lt;strong&gt;yarn-site.xml&lt;/strong&gt;&lt;/span&gt;进行修改：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;configuration&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
        &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;property&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
             &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;yarn.nodemanager.aux-services&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;name&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
             &lt;span&gt;&amp;lt;&lt;/span&gt;&lt;span&gt;value&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;mapreduce_shuffle&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;value&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
            &lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;property&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;span&gt;&amp;lt;/&lt;/span&gt;&lt;span&gt;configuration&lt;/span&gt;&lt;span&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;     &lt;span&gt;然后启动yarn，并用jps查看，可以看到多了三个进程。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;strong&gt;&lt;span&gt;./sbin/start-yarn.sh&lt;/span&gt; &lt;/strong&gt;
starting yarn daemons
starting &lt;strong&gt;&lt;span&gt;resourcemanager&lt;/span&gt;&lt;/strong&gt;, logging to /usr/local/hadoop/logs/yarn-hadoop-resourcemanager-zyr-Aspire-V5-551G.out
localhost: starting &lt;span&gt;&lt;strong&gt;nodemanager&lt;/strong&gt;&lt;/span&gt;, logging to /usr/local/hadoop/logs/yarn-hadoop-nodemanager-zyr-Aspire-V5-551G.out
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ ./sbin/mr-jobhistory-daemon.sh start historyserver
starting &lt;span&gt;&lt;strong&gt;historyserver&lt;/strong&gt;&lt;/span&gt;, logging to /usr/local/hadoop/logs/mapred-hadoop-historyserver-zyr-Aspire-V5-551G.out
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;span&gt;&lt;strong&gt;jps&lt;/strong&gt;&lt;/span&gt;
14423 DataNode
14291 NameNode
15642 Jps
&lt;span&gt;&lt;strong&gt;15570 JobHistoryServer
15220 NodeManager
15008 ResourceManager&lt;/strong&gt;&lt;/span&gt;
14655 SecondaryNameNode&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1157683/201803/1157683-20180303231032939-1938638829.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;       &lt;span&gt;启动 YARN 之后，运行实例的方法还是一样的，仅仅是资源管理方式、任务调度不同。观察日志信息可以发现，不启用 YARN 时，是 “mapred.LocalJobRunner” 在跑任务，启用 YARN 之后，是 “mapred.YARNRunner” 在跑任务。启动 YARN 有个好处是可以通过 Web 界面查看任务的运行情况：&lt;a href=&quot;http://localhost:8088/cluster&quot; target=&quot;_blank&quot;&gt;http://localhost:8088/cluster&lt;/a&gt;，如下图所示。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;https://images2018.cnblogs.com/blog/1157683/201803/1157683-20180303231130454-4422092.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt;  不启动 YARN 需重命名 mapred-site.xml，如果不想启动 YARN，务必把配置文件 mapred-site.xml 重命名，改成 mapred-site.xml.template，需要用时改回来就行（&lt;span&gt;&lt;strong&gt;这个时候不需要修改里面已经修改过的内容&lt;/strong&gt;&lt;/span&gt;）。否则在该配置文件存在，而未开启 YARN 的情况下，运行程序会提示 “Retrying connect to server: 0.0.0.0/0.0.0.0:8032” 的错误，这也是为何该配置文件初始文件名为 mapred-site.xml.template。&lt;/strong&gt;&lt;/span&gt;&lt;br/&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;   再执行&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;span&gt;&lt;strong&gt;&lt;span&gt;可以看到程序执行的非常缓慢，系统资源被大量占用，程序变得非常的卡顿，可以看到yarn的优缺点。&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_Highlighter&quot; readability=&quot;33&quot;&gt;
&lt;pre class=&quot;brush:csharp;gutter:true;&quot;&gt;
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;span&gt;&lt;strong&gt;./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output_yarn 'dfs[a-z.]+'&lt;/strong&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;        &lt;span&gt;执行的日志如下：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;&lt;img id=&quot;code_img_closed_1f01ed4a-a3da-486f-aea1-64431be2fa94&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_1f01ed4a-a3da-486f-aea1-64431be2fa94&quot; class=&quot;code_img_opened&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_1f01ed4a-a3da-486f-aea1-64431be2fa94&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;61&quot;&gt;
&lt;pre&gt;
&lt;span&gt;18/03/03 14:23:43 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
18/03/03 14:23:45 INFO input.FileInputFormat: Total input files to process : 8
18/03/03 14:23:45 INFO mapreduce.JobSubmitter: number of splits:8
18/03/03 14:23:45 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
18/03/03 14:23:47 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1520057034339_0002
18/03/03 14:23:48 INFO impl.YarnClientImpl: Submitted application application_1520057034339_0002
18/03/03 14:23:48 INFO mapreduce.Job: The url to track the job: http://zyr-Aspire-V5-551G:8088/proxy/application_1520057034339_0002/
18/03/03 14:23:48 INFO mapreduce.Job: Running job: job_1520057034339_0002
18/03/03 14:24:05 INFO mapreduce.Job: Job job_1520057034339_0002 running in uber mode : false
18/03/03 14:24:05 INFO mapreduce.Job:  map 0% reduce 0%
18/03/03 14:24:33 INFO mapreduce.Job:  map 13% reduce 0%
18/03/03 14:24:50 INFO mapreduce.Job:  map 63% reduce 0%
18/03/03 14:24:51 INFO mapreduce.Job:  map 75% reduce 0%
18/03/03 14:25:31 INFO mapreduce.Job:  map 100% reduce 0%
18/03/03 14:25:33 INFO mapreduce.Job:  map 100% reduce 100%
18/03/03 14:25:35 INFO mapreduce.Job: Job job_1520057034339_0002 completed successfully
18/03/03 14:25:35 INFO mapreduce.Job: Counters: 50
    File System Counters
        FILE: Number of bytes read=115
        FILE: Number of bytes written=1819819
        FILE: Number of read operations=0
        FILE: Number of large read operations=0
        FILE: Number of write operations=0
        HDFS: Number of bytes read=32095
        HDFS: Number of bytes written=219
        HDFS: Number of read operations=27
        HDFS: Number of large read operations=0
        HDFS: Number of write operations=2
    Job Counters 
        Killed map tasks=2
        Launched map tasks=10
        Launched reduce tasks=1
        Data-local map tasks=10
        Total time spent by all maps in occupied slots (ms)=352992
        Total time spent by all reduces in occupied slots (ms)=36370
        Total time spent by all map tasks (ms)=352992
        Total time spent by all reduce tasks (ms)=36370
        Total vcore-milliseconds taken by all map tasks=352992
        Total vcore-milliseconds taken by all reduce tasks=36370
        Total megabyte-milliseconds taken by all map tasks=361463808
        Total megabyte-milliseconds taken by all reduce tasks=37242880
    Map-Reduce Framework
        Map input records=861
        Map output records=4
        Map output bytes=101
        Map output materialized bytes=157
        Input split bytes=957
        Combine input records=4
        Combine output records=4
        Reduce input groups=4
        Reduce shuffle bytes=157
        Reduce input records=4
        Reduce output records=4
        Spilled Records=8
        Shuffled Maps =8
        Failed Shuffles=0
        Merged Map outputs=8
        GC time elapsed (ms)=1582
        CPU time spent (ms)=16070
        Physical memory (bytes) snapshot=2409881600
        Virtual memory (bytes) snapshot=7588835328
        Total committed heap usage (bytes)=1692925952
    Shuffle Errors
        BAD_ID=0
        CONNECTION=0
        IO_ERROR=0
        WRONG_LENGTH=0
        WRONG_MAP=0
        WRONG_REDUCE=0
    File Input Format Counters 
        Bytes Read=31138
    File Output Format Counters 
        Bytes Written=219
18/03/03 14:25:36 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
18/03/03 14:25:36 INFO input.FileInputFormat: Total input files to process : 1
18/03/03 14:25:37 INFO mapreduce.JobSubmitter: number of splits:1
18/03/03 14:25:37 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1520057034339_0003
18/03/03 14:25:38 INFO impl.YarnClientImpl: Submitted application application_1520057034339_0003
18/03/03 14:25:38 INFO mapreduce.Job: The url to track the job: http://zyr-Aspire-V5-551G:8088/proxy/application_1520057034339_0003/
18/03/03 14:25:38 INFO mapreduce.Job: Running job: job_1520057034339_0003
18/03/03 14:25:58 INFO mapreduce.Job: Job job_1520057034339_0003 running in uber mode : false
18/03/03 14:25:58 INFO mapreduce.Job:  map 0% reduce 0%
18/03/03 14:26:11 INFO mapreduce.Job:  map 100% reduce 0%
18/03/03 14:26:22 INFO mapreduce.Job:  map 100% reduce 100%
18/03/03 14:26:24 INFO mapreduce.Job: Job job_1520057034339_0003 completed successfully
18/03/03 14:26:24 INFO mapreduce.Job: Counters: 49
    File System Counters
        FILE: Number of bytes read=115
        FILE: Number of bytes written=403351
        FILE: Number of read operations=0
        FILE: Number of large read operations=0
        FILE: Number of write operations=0
        HDFS: Number of bytes read=351
        HDFS: Number of bytes written=77
        HDFS: Number of read operations=7
        HDFS: Number of large read operations=0
        HDFS: Number of write operations=2
    Job Counters 
        Launched map tasks=1
        Launched reduce tasks=1
        Data-local map tasks=1
        Total time spent by all maps in occupied slots (ms)=9271
        Total time spent by all reduces in occupied slots (ms)=9646
        Total time spent by all map tasks (ms)=9271
        Total time spent by all reduce tasks (ms)=9646
        Total vcore-milliseconds taken by all map tasks=9271
        Total vcore-milliseconds taken by all reduce tasks=9646
        Total megabyte-milliseconds taken by all map tasks=9493504
        Total megabyte-milliseconds taken by all reduce tasks=9877504
    Map-Reduce Framework
        Map input records=4
        Map output records=4
        Map output bytes=101
        Map output materialized bytes=115
        Input split bytes=132
        Combine input records=0
        Combine output records=0
        Reduce input groups=1
        Reduce shuffle bytes=115
        Reduce input records=4
        Reduce output records=4
        Spilled Records=8
        Shuffled Maps =1
        Failed Shuffles=0
        Merged Map outputs=1
        GC time elapsed (ms)=178
        CPU time spent (ms)=2890
        Physical memory (bytes) snapshot=490590208
        Virtual memory (bytes) snapshot=1719349248
        Total committed heap usage (bytes)=298319872
    Shuffle Errors
        BAD_ID=0
        CONNECTION=0
        IO_ERROR=0
        WRONG_LENGTH=0
        WRONG_MAP=0
        WRONG_REDUCE=0
    File Input Format Counters 
        Bytes Read=219
    File Output Format Counters 
        Bytes Written=77&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;https://images2018.cnblogs.com/blog/1157683/201803/1157683-20180303231556106-1494198011.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;strong&gt;&lt;span&gt;./bin/hdfs dfs -ls&lt;/span&gt;&lt;/strong&gt;
Found 3 items
drwxr-xr-x   - hadoop supergroup          0 2018-03-03 13:21 input
drwxr-xr-x   - hadoop supergroup          0 2018-03-03 13:47 output
drwxr-xr-x   - hadoop supergroup          0 2018-03-03 14:26 output_yarn


hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;span&gt;&lt;strong&gt; ./bin/hdfs dfs -cat ./output/*&lt;/strong&gt;&lt;/span&gt;
1    dfsadmin
1    dfs.replication
1    dfs.namenode.name.dir
1    dfs.datanode.data.dir

hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;span&gt;&lt;strong&gt; ./bin/hdfs dfs -cat ./output_yarn/*&lt;/strong&gt;&lt;/span&gt;
1    dfsadmin
1    dfs.replication
1    dfs.namenode.name.dir
1    dfs.datanode.data.dir&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;     &lt;span&gt;&lt;strong&gt;关闭 YARN 的脚本如下：&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;span&gt;&lt;strong&gt; jps&lt;/strong&gt;&lt;/span&gt;
14423 DataNode
14291 NameNode
18221 Jps
15570 JobHistoryServer
15220 NodeManager
15008 ResourceManager
14655 SecondaryNameNode
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;span&gt;&lt;strong&gt;./sbin/stop-yarn.sh&lt;/strong&gt;&lt;/span&gt;
stopping yarn daemons
stopping resourcemanager
localhost: stopping nodemanager
localhost: nodemanager did not stop gracefully after 5 seconds: killing with kill -9
no proxyserver to stop
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;strong&gt;&lt;span&gt;./sbin/mr-jobhistory-daemon.sh stop historyserver&lt;/span&gt;&lt;/strong&gt;
stopping historyserver
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$ &lt;span&gt;&lt;strong&gt;jps&lt;/strong&gt;&lt;/span&gt;
14423 DataNode
14291 NameNode
14655 SecondaryNameNode
18427 Jps&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;   &lt;span&gt;  关闭之后再执行程序，发现不能运行这是在配置了yarn并关闭之后的必然结果。&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
hadoop@zyr-Aspire-V5-551G:/usr/local/hadoop$&lt;strong&gt;&lt;span&gt; ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output_yarn_close 'dfs[a-z.]+'&lt;/span&gt;&lt;/strong&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;  &lt;span&gt;  结果如下：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;&lt;img id=&quot;code_img_closed_c353e746-5766-40c7-b7a0-ef14129fdf1e&quot; class=&quot;code_img_closed&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ContractedBlock.gif&quot; alt=&quot;&quot;/&gt;&lt;img id=&quot;code_img_opened_c353e746-5766-40c7-b7a0-ef14129fdf1e&quot; class=&quot;code_img_opened&quot; src=&quot;https://images.cnblogs.com/OutliningIndicators/ExpandedBlockStart.gif&quot; alt=&quot;&quot;/&gt;&lt;div id=&quot;cnblogs_code_open_c353e746-5766-40c7-b7a0-ef14129fdf1e&quot; class=&quot;cnblogs_code_hide&quot; readability=&quot;65&quot;&gt;
&lt;pre&gt;
&lt;span&gt; 1&lt;/span&gt; &lt;span&gt;18/03/03 14:42:20 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
&lt;/span&gt;&lt;span&gt; 2&lt;/span&gt; &lt;span&gt;18/03/03 14:42:21 INFO ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
&lt;/span&gt;&lt;span&gt; 3&lt;/span&gt; &lt;span&gt;18/03/03 14:42:22 INFO ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10,
&lt;/span&gt;&lt;span&gt; 4&lt;/span&gt; &lt;span&gt;…...
&lt;/span&gt;&lt;span&gt; 5&lt;/span&gt; &lt;span&gt;18/03/03 14:42:40 INFO ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8032. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
&lt;/span&gt;&lt;span&gt; 6&lt;/span&gt; &lt;span&gt;18/03/03 14:42:40 INFO retry.RetryInvocationHandler: java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort, while invoking ApplicationClientProtocolPBClientImpl.getNewApplication over null after 1 failover attempts. Trying to failover after sleeping for 31517ms.
&lt;/span&gt;&lt;span&gt; 7&lt;/span&gt; 
&lt;span&gt; 8&lt;/span&gt; 
&lt;span&gt; 9&lt;/span&gt; &lt;span&gt;After modify the yarn file,the mapreduce program running well.
&lt;/span&gt;&lt;span&gt;10&lt;/span&gt; The  http://localhost:8088/cluster  could not find.
&lt;/pre&gt;&lt;/div&gt;
&lt;span class=&quot;cnblogs_code_collapse&quot;&gt;View Code&lt;/span&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;&lt;strong&gt; 八、&lt;span&gt;项目小结&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;   至此，我们已经从最开始的配置系统，到之后的配置ssh，java环境，安装hadoop，单机hadoop运行，伪分布式hadoop运行，以及最后的安装yarn，使用yarn运行，不知不觉的，我们对hadoop的基本主线有了本质性的把握，深入的了解了hdfs，知道了MapReduce的执行过程，了解了很多的命令，同时也锻炼了自己的查找问题，分析问题，解决问题的能力，在一番沉淀之后，我们将会搭建真正的集群，不积跬步无以至千里，细节决定成败，虚心，踏实，不断的积累，未来必将属于我们！静下心来，认真探索，深入研究，前方的风景无限美好~~~&lt;/span&gt;&lt;/p&gt;
</description>
<pubDate>Tue, 06 Mar 2018 05:37:00 +0000</pubDate>
<dc:creator>精心出精品</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/zyrblog/p/8503123.html</dc:identifier>
</item>
<item>
<title>Oracle总结【视图、索引、事务、用户权限、批量操作】 - Java3y</title>
<link>http://www.cnblogs.com/Java3y/p/8513813.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/Java3y/p/8513813.html</guid>
<description>&lt;p&gt;在Oracle总结的第一篇中，我们已经总结了一些常用的SQL相关的知识点了...那么本篇主要总结关于&lt;strong&gt;Oralce视图、序列、事务的一些内容&lt;/strong&gt;...&lt;/p&gt;
&lt;p&gt;在数据库中，我们可以把各种的SQL语句分为四大类...&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（1）&lt;strong&gt;DML（数据操纵语言）：select，insert，update，delete&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;（2）&lt;strong&gt;DDL（数据定义语言）：create table，alter table，drop table，truncate table&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;（3）&lt;strong&gt;DCL（数据控制语言）：grant select any table to scott/revoke select any table from scott&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;（4）&lt;strong&gt;TCL（事务控制语言）：commit，rollback，savepoint to 回滚点&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;何为批量操作，就是一次性插入多条数据....在SQL中，&lt;strong&gt;我们查询出来的数据可看成是一张表，那么我们在插入数据的时候，可以根据查询出来的数据进行插入&lt;/strong&gt;...这就可以看成是批量操作...&lt;/p&gt;
&lt;p&gt;值得注意的是，&lt;strong&gt;如果没有指定插入哪些字段的话，那么查询出来的全部字段均会插入表中&lt;/strong&gt;..&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;8&quot;&gt;
&lt;pre class=&quot;sourceCode sql&quot;&gt;
&lt;code class=&quot;sourceCode sql&quot;&gt;
将xxx_emp表中所有20号部门的员工，复制到emp表中，批量插入，insert &lt;span class=&quot;kw&quot;&gt;into&lt;/span&gt; 表名 &lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; ...语法
&lt;span class=&quot;kw&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;into&lt;/span&gt; emp
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; * 
&lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; xxx_emp
&lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt; deptno=&lt;span class=&quot;dv&quot;&gt;20&lt;/span&gt;;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;我们的删除语法有三种：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;delete from&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;truncate from&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;drop from&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;我们来对比一下他们的区别：&lt;/p&gt;
&lt;p&gt;drop table&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1)属于DDL&lt;/li&gt;
&lt;li&gt;2)不可回滚&lt;/li&gt;
&lt;li&gt;3)不可带where&lt;/li&gt;
&lt;li&gt;4)表内容和结构删除&lt;/li&gt;
&lt;li&gt;5)删除速度快&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;truncate table&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1)属于DDL&lt;/li&gt;
&lt;li&gt;2)不可回滚&lt;/li&gt;
&lt;li&gt;3)不可带where&lt;/li&gt;
&lt;li&gt;4)表内容删除&lt;/li&gt;
&lt;li&gt;5)删除速度快&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;delete from&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;1)属于DML&lt;/li&gt;
&lt;li&gt;2)可回滚&lt;/li&gt;
&lt;li&gt;3)可带where&lt;/li&gt;
&lt;li&gt;4)表结构在，表内容要看where执行的情况&lt;/li&gt;
&lt;li&gt;5)删除速度慢,需要逐行删除&lt;/li&gt;
&lt;/ul&gt;&lt;hr/&gt;
&lt;p&gt;事务其实我们在JDBC章节中已经讲解过了，详情可查看我JDBC的博文。&lt;/p&gt;
&lt;p&gt;再次明确一下：事务就是&lt;strong&gt;让一个不可分割的子操作形成一个整体，该整体要么全部执行成功，要么全部执行失败&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们值得注意的是Oracle中的事务与Mysql中的事务操作是有些不同的：&lt;/p&gt;
&lt;p&gt;Oracle的事务开始：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;第一条DML操作做为事务开始【并不需要手动开启事务】&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Oracle的提交事务&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（1）显示提交：commit&lt;br/&gt;&lt;/li&gt;
&lt;li&gt;（2）&lt;strong&gt;隐藏提交：DDL/DCL/exit(sqlplus工具)【注意】&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Oracle的回滚事务&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（1）显示回滚：rollback&lt;/li&gt;
&lt;li&gt;（2）&lt;strong&gt;隐藏回滚：关闭窗口(sqlplus工具)，死机，掉电&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;因为&lt;strong&gt;Oracle有实例池这个概念，所以Oracle支持回滚&lt;/strong&gt;...&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170706092830178?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaG9uXzN5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast&quot; alt=&quot;这里写图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;Oracle默认支持的隔离级别是：read commited&lt;/p&gt;
&lt;p&gt;Mysql默认支持的隔离级别是：reapatable read&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;7&quot;&gt;
&lt;pre class=&quot;sourceCode sql&quot;&gt;
&lt;code class=&quot;sourceCode sql&quot;&gt;
Oracle中设置事务隔离级别为serializable
&lt;span class=&quot;kw&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;transaction&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;isolation&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;level&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;serializable&lt;/span&gt;;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;hr/&gt;
&lt;p&gt;在上一篇博文已经说了，Oracle将表/用户都看成是对象...那么我们怎么在scott用户下访问hr用户下的表呢？？？&lt;/p&gt;
&lt;p&gt;其实，&lt;strong&gt;我们只要在访问表的时候，指定具体的用户.数据库表就行了，但是呢，还要看看该用户有没有权限查询别的用户的数据表，于是就需要赋予权限了&lt;/strong&gt;...&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode sql&quot;&gt;
&lt;code class=&quot;sourceCode sql&quot;&gt;声明：scott或hr叫用户名/方案名/空间名
      scott&lt;span class=&quot;co&quot;&gt;--tiger&lt;/span&gt;
      hr&lt;span class=&quot;co&quot;&gt;-----lion&lt;/span&gt;
      
查询当前用户是谁
show &lt;span class=&quot;fu&quot;&gt;user&lt;/span&gt;;

查询scott自己表空间下的所有对象时，可加，或不加用户名select * &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; emp;
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; emp;
或
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; scott.emp;

以sysdba身份解锁hr普通帐户
&lt;span class=&quot;kw&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;user&lt;/span&gt; hr &lt;span class=&quot;kw&quot;&gt;account&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;unlock&lt;/span&gt;;

以sysdba身份设置hr普通帐户的密码
&lt;span class=&quot;kw&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;user&lt;/span&gt; hr &lt;span class=&quot;kw&quot;&gt;identified&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;by&lt;/span&gt; lion;

当scott查询hr表空间下的所有表时，必须得加用户名
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; hr.jobs;

在默认情况下，每个用户只能查询自已空间下的对象的权限，不能查询其它用户空间下的对象

以sysdba身份角色，授予scott用户查询所有用户空间下的对象权限
&lt;span class=&quot;kw&quot;&gt;grant&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;any&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;to&lt;/span&gt; scott;

以sysdba身份，撤销scott用户查询所有用户空间下的对象权限
&lt;span class=&quot;kw&quot;&gt;revoke&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;any&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; scott;

scott自已查看自己所拥有的权限
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; user_sys_privs;

从scott用户空间导航到sysdba用户空间
conn / &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sysdba&lt;/span&gt;;

从sysdba用户空间导航到scott用户空间
conn scott/tiger;

从scott用户空间导航到hr用户空间
conn hr/lion;

查询hr用户空间中的所有对象
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; tab;

从hr用户空间导航到scott用户空间
conn scott/tiger;

在scott用户空间下，查询hr用户空间下的jobs表，必须加上hr用户空间名
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; hr.jobs;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;hr/&gt;
&lt;p&gt;视图是一种基于数据表的一种&lt;strong&gt;虚表&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（1）视图是一种虚表&lt;/li&gt;
&lt;li&gt;（2）视图建立在已有表的基础上, 视图赖以建立的这些表称为基表&lt;/li&gt;
&lt;li&gt;（3）向视图提供数据内容的语句为 SELECT 语句,&lt;strong&gt;可以将视图理解为存储起来的 SELECT 语句&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;（4）视图向用户提供基表数据的另一种表现形式&lt;/li&gt;
&lt;li&gt;（5）&lt;strong&gt;视图没有存储真正的数据，真正的数据还是存储在基表中&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;（6）程序员虽然操作的是视图，但最终&lt;strong&gt;视图还会转成操作基表&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;（7）一个基表可以有0个或多个视图&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;为什么要用到视图&quot;&gt;为什么要用到视图？&lt;/h2&gt;
&lt;p&gt;有的时候，我们可能只关系一张数据表中的某些字段，而另外的一些人只关系同一张数据表的某些字段...&lt;/p&gt;
&lt;p&gt;那么把全部的字段都都显示给他们看，这是不合理的。我们应该做到：&lt;strong&gt;他们想看到什么样的数据，我们就给他们什么样的数据&lt;/strong&gt;...一方面就能够让他们只关注自己的数据，另一方面，我们也保证数据表一些保密的数据不会泄露出来...&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170706093613664?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaG9uXzN5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast&quot; alt=&quot;这里写图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;还有另外一个原因：&lt;/p&gt;
&lt;p&gt;我们在查询数据的时候，常常需要编写非常长的SQL语句，几乎每次都要写很长很长....上面已经说了，视图就是基于查询的一种虚表，也就是说，&lt;strong&gt;视图可以将查询出来的数据进行封装&lt;/strong&gt;。。。那么我们在使用的时候就会变得非常方便...&lt;/p&gt;
&lt;p&gt;小总结：&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（1）如果你不想让用户看到所有数据（字段，记录），只想让用户看到某些的数据时，此时可以使用视图&lt;/li&gt;
&lt;li&gt;（2）当你需要减化SQL查询语句的编写时，可以使用视图，但不提高查询效率&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;sourceCode&quot; readability=&quot;56&quot;&gt;
&lt;pre class=&quot;sourceCode sql&quot;&gt;
&lt;code class=&quot;sourceCode sql&quot;&gt;

基于emp表所有列，创建视图emp_view_1，create &lt;span class=&quot;kw&quot;&gt;view&lt;/span&gt; 视图名 &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; select对一张或多张基表的查询
&lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;view&lt;/span&gt; emp_view_1
&lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; emp;

默认情况下，普通用户无权创建视图，得让sysdba为你分配creare view的权限 

以sysdba身份，授权scott用户create view权限
&lt;span class=&quot;kw&quot;&gt;grant&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;view&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;to&lt;/span&gt; scott;

以sysdba身份，撤销scott用户create view权限
&lt;span class=&quot;kw&quot;&gt;revoke&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;view&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; scott;

基于emp表指定列，创建视图emp_view_2，该视图包含编号/姓名/工资/年薪/年收入（查询中使用列别名）
&lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;view&lt;/span&gt; emp_view_2
&lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; empno &lt;span class=&quot;ot&quot;&gt;&quot;编号&quot;&lt;/span&gt;,ename &lt;span class=&quot;ot&quot;&gt;&quot;姓名&quot;&lt;/span&gt;,sal &lt;span class=&quot;ot&quot;&gt;&quot;工资&quot;&lt;/span&gt;,sal*&lt;span class=&quot;dv&quot;&gt;12&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;&quot;年薪&quot;&lt;/span&gt;,sal*&lt;span class=&quot;dv&quot;&gt;12&lt;/span&gt;+NVL(comm,&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;) &lt;span class=&quot;ot&quot;&gt;&quot;年收入&quot;&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; emp;

基于emp表指定列，创建视图emp_view_3(a,b,c,d,e)，包含编号/姓名/工资/年薪/年收入（视图中使用列名）
&lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;view&lt;/span&gt; emp_view_3(a,b,c,d,e)
&lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; empno &lt;span class=&quot;ot&quot;&gt;&quot;编号&quot;&lt;/span&gt;,ename &lt;span class=&quot;ot&quot;&gt;&quot;姓名&quot;&lt;/span&gt;,sal &lt;span class=&quot;ot&quot;&gt;&quot;工资&quot;&lt;/span&gt;,sal*&lt;span class=&quot;dv&quot;&gt;12&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;&quot;年薪&quot;&lt;/span&gt;,sal*&lt;span class=&quot;dv&quot;&gt;12&lt;/span&gt;+NVL(comm,&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;) &lt;span class=&quot;ot&quot;&gt;&quot;年收入&quot;&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; emp;

查询emp_view_3创建视图的结构
&lt;span class=&quot;kw&quot;&gt;desc&lt;/span&gt; emp_view_3;

修改emp_view_3(&lt;span class=&quot;kw&quot;&gt;id&lt;/span&gt;,name,salary,annual,income)视图，create &lt;span class=&quot;kw&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;replace&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;view&lt;/span&gt; 视图名 &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; 子查询
&lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;replace&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;view&lt;/span&gt; emp_view_3(&lt;span class=&quot;kw&quot;&gt;id&lt;/span&gt;,name,salary,annual,income)
&lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; empno &lt;span class=&quot;ot&quot;&gt;&quot;编号&quot;&lt;/span&gt;,ename &lt;span class=&quot;ot&quot;&gt;&quot;姓名&quot;&lt;/span&gt;,sal &lt;span class=&quot;ot&quot;&gt;&quot;工资&quot;&lt;/span&gt;,sal*&lt;span class=&quot;dv&quot;&gt;12&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;&quot;年薪&quot;&lt;/span&gt;,sal*&lt;span class=&quot;dv&quot;&gt;12&lt;/span&gt;+NVL(comm,&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;) &lt;span class=&quot;ot&quot;&gt;&quot;年收入&quot;&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; emp;

查询emp表，求出各部门的最低工资，最高工资，平均工资
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;min&lt;/span&gt;(sal),&lt;span class=&quot;fu&quot;&gt;max&lt;/span&gt;(sal),&lt;span class=&quot;fu&quot;&gt;round&lt;/span&gt;(&lt;span class=&quot;fu&quot;&gt;avg&lt;/span&gt;(sal),&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;),deptno
&lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; emp
&lt;span class=&quot;kw&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;by&lt;/span&gt; deptno;

创建视图emp_view_4，视图中包含各部门的最低工资，最高工资，平均工资
&lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;replace&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;view&lt;/span&gt; emp_view_4
&lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; deptno &lt;span class=&quot;ot&quot;&gt;&quot;部门号&quot;&lt;/span&gt;,&lt;span class=&quot;fu&quot;&gt;min&lt;/span&gt;(sal) &lt;span class=&quot;ot&quot;&gt;&quot;最低工资&quot;&lt;/span&gt;,&lt;span class=&quot;fu&quot;&gt;max&lt;/span&gt;(sal) &lt;span class=&quot;ot&quot;&gt;&quot;最高工资&quot;&lt;/span&gt;,&lt;span class=&quot;fu&quot;&gt;round&lt;/span&gt;(&lt;span class=&quot;fu&quot;&gt;avg&lt;/span&gt;(sal),&lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;) &lt;span class=&quot;ot&quot;&gt;&quot;平均工资&quot;&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; emp
&lt;span class=&quot;kw&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;by&lt;/span&gt; deptno;

创建视图emp_view_5，视图中包含员工编号，姓名，工资，部门名，工资等级
&lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;replace&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;view&lt;/span&gt; emp_view_5
&lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; e.empno &lt;span class=&quot;ot&quot;&gt;&quot;编号&quot;&lt;/span&gt;,e.ename &lt;span class=&quot;ot&quot;&gt;&quot;姓名&quot;&lt;/span&gt;,e.sal &lt;span class=&quot;ot&quot;&gt;&quot;工资&quot;&lt;/span&gt;,d.dname &lt;span class=&quot;ot&quot;&gt;&quot;部门名&quot;&lt;/span&gt;,s.grade &lt;span class=&quot;ot&quot;&gt;&quot;工资等级&quot;&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; emp e,dept d,salgrade s
&lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt; (e.deptno=d.deptno) &lt;span class=&quot;kw&quot;&gt;and&lt;/span&gt; (e.sal &lt;span class=&quot;kw&quot;&gt;between&lt;/span&gt; s.losal &lt;span class=&quot;kw&quot;&gt;and&lt;/span&gt; s.hisal);

删除视图emp_view_1中的7788号员工的记录，使用delete操作，会影响基表吗
&lt;span class=&quot;kw&quot;&gt;delete&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; emp_view_1 &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt; empno=&lt;span class=&quot;dv&quot;&gt;7788&lt;/span&gt;;写法正确，会影响基表

修改emp_view_1为只读视图【with &lt;span class=&quot;kw&quot;&gt;read&lt;/span&gt; only】，再执行上述delete操作，还行吗？
&lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;replace&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;view&lt;/span&gt; emp_view_1
&lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; emp
&lt;span class=&quot;kw&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;read&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;only&lt;/span&gt;;
不能进行delete操作了

删除视图中的【某条】记录会影响基表吗？
会影响基表

将【整个】视图删除，会影响表吗？
不会影响基表

删除视图，会进入回收站吗？
不会进入回收站

删除基表会影响视图吗？
会影响视图

闪回基表后,视图有影响吗？
视图又可以正常工作了&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;我们在使用多表查询，或者查询出来的表字段意义不清晰的时候，我们就使用别名来替代....当然了，&lt;strong&gt;别名只针对列名或表名&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;现在，我们已经知道的对象有用户/视图/表等等其他对象了，&lt;strong&gt;Oracle也提供了同义词【类似于别名】给我们进行使用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;同义词的作用&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（1）&lt;strong&gt;缩短对象名字的长度&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;（2）&lt;strong&gt;方便访问其它用户的对象&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;sourceCode&quot; readability=&quot;10&quot;&gt;
&lt;pre class=&quot;sourceCode sql&quot;&gt;
&lt;code class=&quot;sourceCode sql&quot;&gt;创建与salgrade表对应的同义词，create &lt;span class=&quot;kw&quot;&gt;synonym&lt;/span&gt; 同义词 &lt;span class=&quot;kw&quot;&gt;for&lt;/span&gt; 表名/视图/其它对象
&lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;synonym&lt;/span&gt; e &lt;span class=&quot;kw&quot;&gt;for&lt;/span&gt; salgrade;
&lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;synonym&lt;/span&gt; ev5 &lt;span class=&quot;kw&quot;&gt;for&lt;/span&gt; emp_view_5;

以sys身份授予scott普通用户create synonym权限
&lt;span class=&quot;kw&quot;&gt;grant&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;synonym&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;to&lt;/span&gt; scott;

以sys身份从scott普通用户撤销create synonym权限
&lt;span class=&quot;kw&quot;&gt;revoke&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;synonym&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; scott;

使用同义词操作salgrade表
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; s;

删除同义词
&lt;span class=&quot;kw&quot;&gt;drop&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;synonym&lt;/span&gt; ev5;

删除同义词，会影响基表吗？
不会影响基表

删除基表，会影响同义词吗？
会影响同义词
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Mysql的自动增长可以直接在创建表的时候，在字段后面跟上auto increament关键字就行了。那Oracle 有没有自动增长策略呢？？？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Oracle使用的是序列这么一个对象&lt;/strong&gt;....&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（1）类似于MySQL中的auto_increment自动增长机制，但Oracle中无auto_increment机制&lt;/li&gt;
&lt;li&gt;（2）&lt;strong&gt;是oracle提供的一个产生唯一数值型值的机制&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;（3）通常用于表的主健值&lt;/li&gt;
&lt;li&gt;（4）序列只能保证唯一，不能保证连续
&lt;ul&gt;&lt;li&gt;声明：&lt;strong&gt;oracle中，只有rownum永远保持从1开始，且继续&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;（5）序列值，&lt;strong&gt;可放于内存，取之较快&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;那oralce中的序列和Mysql中的自动增长有啥区别？？？&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Mysql每张表都会维护一个自动增长的程序...&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Oralce会把序列存放在内存中，可以供几张表使用...&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170706094434848?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaG9uXzN5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast&quot; alt=&quot;这里写图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;有的同学可能会疑问，我们在分页的时候用到了rownum这么一个伪列，为啥不用它来做自动增长的呢？？？&lt;/p&gt;
&lt;p&gt;rownum的值虽然是唯一和连续的，但是&lt;strong&gt;不能一直唯一标识该记录&lt;/strong&gt;...也就是说，&lt;strong&gt;一旦该记录删除了，那么rownum的值是会变的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;为什么要用序列&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（1）&lt;strong&gt;以前我们为主健设置值，需要人工设置值，容易出错&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;（2）&lt;strong&gt;以前每张表的主健值，是独立的，不能共享&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;sourceCode&quot; readability=&quot;11&quot;&gt;
&lt;pre class=&quot;sourceCode sql&quot;&gt;
&lt;code class=&quot;sourceCode sql&quot;&gt;
为emp表的empno字段，创建序列emp_empno_seq，create &lt;span class=&quot;kw&quot;&gt;sequence&lt;/span&gt; 序列名
&lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sequence&lt;/span&gt; emp_empno_seq;

删除序列emp_empno_seq，drop &lt;span class=&quot;kw&quot;&gt;sequence&lt;/span&gt; 序列名
&lt;span class=&quot;kw&quot;&gt;drop&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sequence&lt;/span&gt; emp_empno_seq;

查询emp_empno_seq序列的当前值currval和下一个值nextval，第一次使用序列时，必须选用：序列名.nextval
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; emp_empno_seq.nextval &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; dual;
&lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; emp_empno_seq.currval &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; dual;

使用序列，向emp表插入记录，empno字段使用序列值
&lt;span class=&quot;kw&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;into&lt;/span&gt; emp(empno) &lt;span class=&quot;kw&quot;&gt;values&lt;/span&gt;(emp_empno_seq.nextval);
&lt;span class=&quot;kw&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;into&lt;/span&gt; emp(empno) &lt;span class=&quot;kw&quot;&gt;values&lt;/span&gt;(emp_empno_seq.nextval);
&lt;span class=&quot;kw&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;into&lt;/span&gt; emp(empno) &lt;span class=&quot;kw&quot;&gt;values&lt;/span&gt;(emp_empno_seq.nextval);

修改emp_empno_seq序列的increment by属性为20，默认start with是1，alter &lt;span class=&quot;kw&quot;&gt;sequence&lt;/span&gt; 序列名
&lt;span class=&quot;kw&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sequence&lt;/span&gt; emp_empno_seq
&lt;span class=&quot;kw&quot;&gt;increment&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;20&lt;/span&gt;;

修改修改emp_empno_seq序列的的increment by属性为5
&lt;span class=&quot;kw&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sequence&lt;/span&gt; emp_empno_seq
&lt;span class=&quot;kw&quot;&gt;increment&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;;

修改emp_empno_seq序列的start with属性，行吗
&lt;span class=&quot;kw&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sequence&lt;/span&gt; emp_empno_seq
&lt;span class=&quot;kw&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;;

有了序列后，还能为主健手工设置值吗？
&lt;span class=&quot;kw&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;into&lt;/span&gt; emp(empno) &lt;span class=&quot;kw&quot;&gt;values&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;9999&lt;/span&gt;);
&lt;span class=&quot;kw&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;into&lt;/span&gt; emp(empno) &lt;span class=&quot;kw&quot;&gt;values&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;7900&lt;/span&gt;);

删除表，会影响序列吗？
你无法做insert操作,表真正亡，序列亡

删除序列，会影响表吗？

不会


在hibernate中，如果是访问oracle数据库服务器，那么User.hbm.xml映射文件中关于&amp;lt;id&amp;gt;标签如何配置呢？
&amp;lt;id name=&lt;span class=&quot;ot&quot;&gt;&quot;id&quot;&lt;/span&gt; column=&lt;span class=&quot;ot&quot;&gt;&quot;id&quot;&lt;/span&gt;&amp;gt;
   &amp;lt;generator class=&lt;span class=&quot;ot&quot;&gt;&quot;increment/identity/uuid/【sequence】/【native】&quot;&lt;/span&gt;/&amp;gt;
&amp;lt;/id&amp;gt;&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;hr/&gt;
&lt;h2 id=&quot;什么是索引&quot;&gt;什么是索引&lt;/h2&gt;
&lt;p&gt;什么是索引【Index】&lt;/p&gt;
&lt;p&gt;（1）是一种&lt;strong&gt;快速查询表中内容的机制&lt;/strong&gt;，类似于新华字典的目录&lt;br/&gt;（2）运用在表中某个/些字段上，但&lt;strong&gt;存储时，独立于表之外&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&quot;为什么要用索引&quot;&gt;为什么要用索引&lt;/h2&gt;
&lt;p&gt;为什么要用索引&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（1）&lt;strong&gt;通过指针加速Oracle服务器的查询速度&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;（2）&lt;strong&gt;通过rowid快速定位数据的方法，减少磁盘I/O&lt;/strong&gt;
&lt;ul&gt;&lt;li&gt;rowid是oracle中唯一确定每张表不同记录的唯一身份证&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;索引表把数据变成是有序的....&lt;br/&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170706125711221?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaG9uXzN5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast&quot; alt=&quot;这里写图片描述&quot;/&gt;&lt;/p&gt;
&lt;p&gt;快速定位到硬盘中的数据文件...&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170706125742419?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaG9uXzN5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast&quot; alt=&quot;这里写图片描述&quot;/&gt;&lt;/p&gt;
&lt;hr/&gt;&lt;h2 id=&quot;rowid特点&quot;&gt;rowid特点&lt;/h2&gt;
&lt;p&gt;rowid的特点&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（1）位于每个表中，但表面上看不见，例如：desc emp是看不见的&lt;/li&gt;
&lt;li&gt;（2）只有在select中，显示写出rowid，方可看见&lt;/li&gt;
&lt;li&gt;（3）它与每个表绑定在一起，表亡，该表的rowid亡，二张表rownum可以相同，但rowid必须是唯一的&lt;/li&gt;
&lt;li&gt;（4）rowid是18位大小写加数字混杂体，唯一表代该条记录在DBF文件中的位置&lt;/li&gt;
&lt;li&gt;（5）rowid可以参与=/like比较时，用''单引号将rowid的值包起来，且区分大小写&lt;/li&gt;
&lt;li&gt;（6）rowid是联系表与DBF文件的桥梁&lt;/li&gt;
&lt;/ul&gt;&lt;h2 id=&quot;索引特点&quot;&gt;索引特点&lt;/h2&gt;
&lt;p&gt;索引的特点&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（1）索引一旦建立,** Oracle管理系统会对其进行自动维护**, 而且由Oracle管理系统决定何时使用索引&lt;/li&gt;
&lt;li&gt;（2）用户不用在查询语句中指定使用哪个索引&lt;/li&gt;
&lt;li&gt;（3）&lt;strong&gt;在定义primary key或unique约束后系统自动在相应的列上创建索引&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;（4）用户也能按自己的需求，对指定单个字段或多个字段，添加索引&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;需要注意的是：&lt;strong&gt;Oracle是自动帮我们管理索引的，并且如果我们指定了primary key或者unique约束，系统会自动在对应的列上创建索引&lt;/strong&gt;..&lt;/p&gt;
&lt;p&gt;什么时候【要】创建索引&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（1）表经常进行 SELECT 操作&lt;/li&gt;
&lt;li&gt;（2）表很大(记录超多)，记录内容分布范围很广&lt;/li&gt;
&lt;li&gt;（3）列名经常在 WHERE 子句或连接条件中出现&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;什么时候【不要】创建索引&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;（1）表经常进行 INSERT/UPDATE/DELETE 操作&lt;/li&gt;
&lt;li&gt;（2）表很小(记录超少)&lt;/li&gt;
&lt;li&gt;（3）列名不经常作为连接条件或出现在 WHERE 子句中&lt;/li&gt;
&lt;/ul&gt;&lt;div class=&quot;sourceCode&quot; readability=&quot;14&quot;&gt;
&lt;pre class=&quot;sourceCode sql&quot;&gt;
&lt;code class=&quot;sourceCode sql&quot;&gt;


为emp表的empno单个字段，创建索引emp_empno_idx，叫单列索引，create &lt;span class=&quot;kw&quot;&gt;index&lt;/span&gt; 索引名 &lt;span class=&quot;kw&quot;&gt;on&lt;/span&gt; 表名(字段,...)
&lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;index&lt;/span&gt; emp_empno_idx
&lt;span class=&quot;kw&quot;&gt;on&lt;/span&gt; emp(empno);

为emp表的ename,job多个字段，创建索引emp_ename_job_idx，多列索引/联合索引
&lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;index&lt;/span&gt; emp_ename_job 
&lt;span class=&quot;kw&quot;&gt;on&lt;/span&gt; emp(ename,job);
如果在where中只出现job不使用索引
如果在where中只出现ename使用索引
我们提倡同时出现ename和job

注意：索引创建后，只有查询表有关，和其它（insert/update/delete）无关,解决速度问题

删除emp_empno_idx和emp_ename_job_idx索引，drop &lt;span class=&quot;kw&quot;&gt;index&lt;/span&gt; 索引名
&lt;span class=&quot;kw&quot;&gt;drop&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;index&lt;/span&gt; emp_empno_idx;
&lt;span class=&quot;kw&quot;&gt;drop&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;index&lt;/span&gt; emp_ename_job_idx;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;http://img.blog.csdn.net/20170706130259962?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaG9uXzN5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast&quot; alt=&quot;这里写图片描述&quot;/&gt;&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; readability=&quot;17&quot;&gt;
&lt;pre class=&quot;sourceCode sql&quot;&gt;
&lt;code class=&quot;sourceCode sql&quot;&gt;

一）用户
Oracle中的用户分为二大类
&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;）Oracle数据库服务器创建时，由系统自动创建的用户，叫系统用户，如sys。
&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;）利用系统用户创建的用户，叫普通用户，如scott,hr，c##tiger,zhaojun,...

》用sys登录，查询当前Oracle数据库服务器中已有用户的名字和状态
  username表示登录名
  expired&lt;span class=&quot;ch&quot;&gt;&amp;amp;locked&lt;/span&gt;表示帐号过期和锁定
  open表示帐号现在可用
  sqlplus / &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sysdba&lt;/span&gt;;
  col username &lt;span class=&quot;kw&quot;&gt;for&lt;/span&gt; a30;
  col account_status &lt;span class=&quot;kw&quot;&gt;for&lt;/span&gt; a30;
  &lt;span class=&quot;kw&quot;&gt;set&lt;/span&gt; pagesize &lt;span class=&quot;dv&quot;&gt;100&lt;/span&gt;;
  &lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; username,account_status &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; dba_users;
  
  查询Oracle中有哪些用户
  &lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; all_users;



二）创建与删除普通用户
可以在Oracle中创建新的普通用户，创建普通用户命令是：create user，在创建普通用户的同时，应该为其分配一个具体的表空间，通常叫users。

》用sys登录，查询Oracle中有哪些可用存储空间，所有普通用户默认为users存储空间
  &lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; v$tablespace;

》用sys登录，创建普通用户c##tiger，密码为abc，默认使用users存储空间，即对应硬盘上的一个DBF二进制文件
  sqlplus / &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sysdba&lt;/span&gt;;
  &lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;user&lt;/span&gt; c##tiger &lt;span class=&quot;kw&quot;&gt;identified&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;by&lt;/span&gt; abc &lt;span class=&quot;kw&quot;&gt;default&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;tablespace&lt;/span&gt; users;

》用sys登录，为c##tiger分配users空间无限制使用，即数据库中DBF文件可以无限增加，一个DBF文件不够，会创建第二个DBF文件
  sqlplus / &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sysdba&lt;/span&gt;;
  &lt;span class=&quot;kw&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;user&lt;/span&gt; c##tiger &lt;span class=&quot;kw&quot;&gt;quota&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;unlimited&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;on&lt;/span&gt; users;

》用c##tiger登录，能进orcl数据库吗？
  sqlplus c##tiger/abc
  进不去orcl数据库

》用sys登录，删除普通用户c##tiger
  sqlplus / &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sysdba&lt;/span&gt;;
  &lt;span class=&quot;kw&quot;&gt;drop&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;user&lt;/span&gt; c##tiger &lt;span class=&quot;kw&quot;&gt;cascade&lt;/span&gt;;



三）了解系统用户
sys是Oracle中一个重要的系统用户，sys是Oracle中最高权限用户，其角色为SYSDBA（系统管理员）
sqlplus / &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sysdba&lt;/span&gt;



四）权限
权限的最终作用于用户。即所有用户在数据库内的操作对象和可执行的动作都是受到限制的。
Oracle中权限分为二大类：
&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;）系统权限
&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;）对象权限



五）系统权限
针对数据库中特定操作的许可，例如：让c##tiger能登录到orcl数据库，能在orcl数据库中创建表

》用sys登录，获取系统权限的相关信息，例如：select &lt;span class=&quot;kw&quot;&gt;any&lt;/span&gt; table表示针对所有表的select权限
  sqlplus / &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sysdba&lt;/span&gt;;
  &lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;distinct&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;privilege&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; dba_sys_privs;

》用sys登录，为c##tiger分配create session与数据库建立会话的权限，即允许该用户登录
  sqlplus / &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sysdba&lt;/span&gt;;
  &lt;span class=&quot;kw&quot;&gt;grant&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;session&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;to&lt;/span&gt; c##tiger;

》用c##tiger登录，能进orcl数据库吗？
  sqlplus c##tiger/abc
  能进去orcl数据库

》用c##tiger登录，创建一张tiger的表，能创建吗？
  sqlplus c##tiger/abc
  &lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;table&lt;/span&gt; tiger(
    name &lt;span class=&quot;dt&quot;&gt;varchar2&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;20&lt;/span&gt;)
  );
  这时c##tiger没有权限创建表

》用sys登录，为c##tiger分配create table权限，即允许创建表
  sqlplus / &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sysdba&lt;/span&gt;;
  &lt;span class=&quot;kw&quot;&gt;grant&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;to&lt;/span&gt; c##tiger;

》用c##tiger登录，创建一张tiger的表，能创建吗？
  sqlplus c##tiger/abc
  &lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;table&lt;/span&gt; tiger(
    name &lt;span class=&quot;dt&quot;&gt;varchar2&lt;/span&gt;(&lt;span class=&quot;dv&quot;&gt;20&lt;/span&gt;)
  );
  可以创建c##tiger表

》用sys登录，查询c##tiger所拥有的系统权限
  sqlplus / &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sysdba&lt;/span&gt;;
  &lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; grantee,&lt;span class=&quot;kw&quot;&gt;privilege&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; dba_sys_privs &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;lower&lt;/span&gt;(grantee) = &lt;span class=&quot;st&quot;&gt;'c##tiger'&lt;/span&gt;;
  grantee表示普通用户名
  privilege权限名  

》用sys登录，撤销c##tiger的create table权限
  sqlplus / &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sysdba&lt;/span&gt;;
  &lt;span class=&quot;kw&quot;&gt;revoke&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; c##tiger;



六）对象权限
用户对已有对象的操作权限，包括：
&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;）select可用于表，视图和序列
&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;）insert向表或视图中插入新的记录
&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;）update更新表中数据
&lt;span class=&quot;dv&quot;&gt;4&lt;/span&gt;）delete删除表中数据
&lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt;）execute函数，过程的执行
&lt;span class=&quot;dv&quot;&gt;6&lt;/span&gt;）index为表创建索引
&lt;span class=&quot;dv&quot;&gt;7&lt;/span&gt;）references为表创建外健
&lt;span class=&quot;dv&quot;&gt;8&lt;/span&gt;）alter修改表或者序列的属性

》用sys登录，查询c##tiger所拥有的对象权限
  sqlplus / &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sysdba&lt;/span&gt;;
  col grantee &lt;span class=&quot;kw&quot;&gt;for&lt;/span&gt; a10;
  col table_name &lt;span class=&quot;kw&quot;&gt;for&lt;/span&gt; a10;
  col &lt;span class=&quot;kw&quot;&gt;privilege&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;for&lt;/span&gt; a20;
  &lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; grantee,table_name,&lt;span class=&quot;kw&quot;&gt;privilege&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; dba_tab_privs &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;lower&lt;/span&gt;(grantee) = &lt;span class=&quot;st&quot;&gt;'c##tiger'&lt;/span&gt;;

》用sys登录，为c##tiger分配对tiger表的所有权限，即增删改查操作
  sqlplus / &lt;span class=&quot;kw&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;sysdba&lt;/span&gt;;
  &lt;span class=&quot;kw&quot;&gt;grant&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;on&lt;/span&gt; c##tiger.tiger &lt;span class=&quot;kw&quot;&gt;to&lt;/span&gt; c##tiger;
  注意：c##tiger表示空间名
        tiger表示该空间下的表名
  C##TIGER   TIGER      &lt;span class=&quot;kw&quot;&gt;FLASHBACK&lt;/span&gt;
  C##TIGER   TIGER      &lt;span class=&quot;kw&quot;&gt;DEBUG&lt;/span&gt;
  C##TIGER   TIGER      &lt;span class=&quot;kw&quot;&gt;QUERY&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;REWRITE&lt;/span&gt;
  C##TIGER   TIGER      &lt;span class=&quot;kw&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;COMMIT&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;REFRESH&lt;/span&gt;
  C##TIGER   TIGER      &lt;span class=&quot;kw&quot;&gt;REFERENCES&lt;/span&gt;
  C##TIGER   TIGER      &lt;span class=&quot;kw&quot;&gt;UPDATE&lt;/span&gt;
  C##TIGER   TIGER      &lt;span class=&quot;kw&quot;&gt;SELECT&lt;/span&gt;
  C##TIGER   TIGER      &lt;span class=&quot;kw&quot;&gt;INSERT&lt;/span&gt;
  C##TIGER   TIGER      &lt;span class=&quot;kw&quot;&gt;INDEX&lt;/span&gt;
  C##TIGER   TIGER      &lt;span class=&quot;kw&quot;&gt;DELETE&lt;/span&gt;
  C##TIGER   TIGER      &lt;span class=&quot;kw&quot;&gt;ALTER&lt;/span&gt;

》用c##tiger登录，对tiger表进行增删改查操作
  sqlplus c##tiger/abc;
  &lt;span class=&quot;kw&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;into&lt;/span&gt; tiger(name) &lt;span class=&quot;kw&quot;&gt;values&lt;/span&gt;(&lt;span class=&quot;st&quot;&gt;'AA'&lt;/span&gt;);
  &lt;span class=&quot;kw&quot;&gt;update&lt;/span&gt; tiger &lt;span class=&quot;kw&quot;&gt;set&lt;/span&gt; name = &lt;span class=&quot;st&quot;&gt;'BB'&lt;/span&gt;;
  &lt;span class=&quot;kw&quot;&gt;delete&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; tiger &lt;span class=&quot;kw&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;rownum&lt;/span&gt; = &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;;
  &lt;span class=&quot;kw&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;kw&quot;&gt;from&lt;/span&gt; tiger;
&lt;/code&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;hr/&gt;&lt;blockquote readability=&quot;6&quot;&gt;
&lt;p&gt;如果文章有错的地方欢迎指正，大家互相交流。习惯在微信看技术文章，想要获取更多的Java资源的同学，可以&lt;strong&gt;关注微信公众号:Java3y&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
<pubDate>Tue, 06 Mar 2018 05:15:00 +0000</pubDate>
<dc:creator>Java3y</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/Java3y/p/8513813.html</dc:identifier>
</item>
<item>
<title>SDP（9）：MongoDB-Scala - data access and modeling - 雪川大虫</title>
<link>http://www.cnblogs.com/tiger-xc/p/8513685.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/tiger-xc/p/8513685.html</guid>
<description>&lt;p&gt;&lt;span&gt;    MongoDB是一种文件型数据库，对数据格式没有硬性要求，所以可以实现灵活多变的数据存储和读取。MongoDB又是一种分布式数据库，与传统关系数据库不同的是，分布式数据库不支持table-join，所以在设计数据库表结构方面与关系数据库有很大的不同。分布式数据库有一套与传统观念不同的数据模式，在设计库表结构时必须从满足各种数据抽取的需要为主要目的。关系数据库设计要求遵循范式模式（normalization）库表结构，在抽取数据时再通过table-join联结关系表。因为分布式数据库不支持table-join，在读取跨表数据时就需要多次抽取，影响数据处理的效率。MongoDB作为文件型数据库最大的特点就是容许嵌入Document：我们可以把相关联的Document嵌入在另一个关联Document中，这样就可以一次性读取全部数据，实现反范式（denormalization）的数据模式了。这方面MongoDB比Cassandra更加优胜。MongoDB支持灵活多样的索引方式，使它成为提供高效数据读取的分布式数据库最佳选择。另外，MongoDB还通过提供sort、aggregation、map-reduce来支持丰富强大的大数据统计功能。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;   在使用MongoDB前我们必须熟悉它的数据模式和设计理念：在大数据时代的今天，数据的产生和使用发生了质的变化，传统关系数据库数据模式已经无法满足现代信息系统的要求。比如，在设计个人信息表时要考虑有些人有两个地址，有些甚至没有地址，又有些有传真号，还有这个那个的其它特点等等。在关系数据库模式设计中我们必须作出取舍，牺牲一些属性。但MongoDB的文件类数据库特点容许不同的数据格式，能实现完整的数据采集与储存。下面是一个采购单的Document设计：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;62&quot;&gt;
&lt;pre&gt;
&lt;span&gt;  val po1 =&lt;span&gt; Document (
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ponum&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;po18012301&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;vendor&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;The smartphone compay&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podate&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt;&lt;span&gt; podate1,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;remarks&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;urgent, rush order&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;handler&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt;&lt;span&gt; pic,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podtl&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt;&lt;span&gt; Seq(
      Document(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;item&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;sony smartphone&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;price&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;2389.00&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;qty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;1239&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;packing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;standard&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
      Document(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;item&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ericson smartphone&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;price&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;897.00&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;qty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;1000&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;payterm&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;30 days&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    )
  )

  val po2 &lt;/span&gt;=&lt;span&gt; Document (
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ponum&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;po18022002&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;vendor&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;The Samsung compay&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podate&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt;&lt;span&gt; podate2,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podtl&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt;&lt;span&gt; Seq(
      Document(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;item&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;samsung galaxy s8&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;price&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;2300.00&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;qty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;100&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;packing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;standard&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
      Document(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;item&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;samsung galaxy s7&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;price&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;1897.00&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;qty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;1000&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;payterm&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;30 days&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
      Document(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;item&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;apple iphone7&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;price&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;6500.00&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;qty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;100&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;packing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;luxury&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    )
  )&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;po1和po2都在podtl键嵌入了多条采购项目Document。首先，po1与po2有结构上的不同：po1多出了remarks、handler这两个键。嵌入的Document各自也有不同的结构。在这个例子里我特别加了date、binary、array类型的使用示范：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;38&quot;&gt;
&lt;pre&gt;
&lt;span&gt;  val ca =&lt;span&gt; Calendar.getInstance()
  ca.&lt;/span&gt;&lt;span&gt;set&lt;/span&gt;(&lt;span&gt;2011&lt;/span&gt;,&lt;span&gt;10&lt;/span&gt;,&lt;span&gt;23&lt;/span&gt;&lt;span&gt;)
  val podate1 &lt;/span&gt;=&lt;span&gt; ca.getTime
  ca.&lt;/span&gt;&lt;span&gt;set&lt;/span&gt;(&lt;span&gt;2012&lt;/span&gt;,&lt;span&gt;12&lt;/span&gt;,&lt;span&gt;23&lt;/span&gt;&lt;span&gt;)
  val podate2 &lt;/span&gt;=&lt;span&gt; ca.getTime

  val pic &lt;/span&gt;= FileToByteArray(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/users/tiger-macpro/sample.png&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt; seconds)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;MongoDB的Date是java.util.Date，可以用Calendar来操作。再看看下面类型转换中的数据类型对应： &lt;/span&gt;&lt;/p&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;53&quot;&gt;
&lt;pre&gt;
&lt;span&gt;  &lt;span&gt;case&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; PO (
                 ponum: String,
                 podate: java.util.Date,
                 vendor: String,
                 remarks: Option[String],
                 podtl: Option[BsonArray],
                 handler: Option[BsonBinary]
                 )
  def toPO(doc: Document): PO &lt;/span&gt;=&lt;span&gt; {
      val ks &lt;/span&gt;=&lt;span&gt; doc.keySet
      PO(
        ponum &lt;/span&gt;= doc.getString(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ponum&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
        podate &lt;/span&gt;= doc.getDate(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podate&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
        vendor &lt;/span&gt;= doc.getString(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;vendor&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
        remarks &lt;/span&gt;=&lt;span&gt; {
          &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (ks.contains(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;remarks&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
            Some(doc.getString(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;remarks&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
          &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;
            None
        },
        podtl &lt;/span&gt;=&lt;span&gt; {
          &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (ks.contains(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podtl&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
            doc.&lt;/span&gt;&lt;span&gt;get&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podtl&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;).asInstanceOf[Option[BsonArray]]
          &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;
            None
        },
        handler &lt;/span&gt;=&lt;span&gt; {
          &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (ks.contains(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;handler&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
            doc.&lt;/span&gt;&lt;span&gt;get&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;handler&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;).asInstanceOf[Option[BsonBinary]]
          &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;
            None
        }
      )
    }

   &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; PODTL(
                   item: String,
                   price: Double,
                   qty: Int,
                   packing: Option[String],
                   payTerm: Option[String]
                   )
   def toPODTL(podtl: Document): PODTL &lt;/span&gt;=&lt;span&gt; {
     val ks &lt;/span&gt;=&lt;span&gt; podtl.keySet
     PODTL(
       item &lt;/span&gt;= podtl.getString(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;item&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
       price &lt;/span&gt;= podtl.getDouble(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;price&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
       qty &lt;/span&gt;= podtl.getInteger(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;qty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
       packing &lt;/span&gt;=&lt;span&gt; {
         &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (ks.contains(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;packing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
           Some(podtl.getString(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;packing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
         &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; None
       },
       payTerm &lt;/span&gt;=&lt;span&gt; {
         &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;(ks.contains(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;payterm&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
           Some(podtl.getString(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;payterm&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
         &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; None
       }
     )
   }&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;注意BsonBinary和BsonArray这两个类型和它们的使用方法。我们可以用嵌入Document的键作为查询条件：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;   poCollection.find(equal(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podtl.qty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,&lt;span&gt;100&lt;/span&gt;&lt;span&gt;)).toFuture().onComplete {
    &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; Success(docs) =&amp;gt; docs.map(toPO).&lt;span&gt;foreach&lt;/span&gt;&lt;span&gt; (showPO)
      println(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;-------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; Failure(e) =&amp;gt;&lt;span&gt; println(e.getMessage)
  }&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;我们可以用toPO和toPODTL把po,podtl对应到case class，然后用强类型方式来使用它们：&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;37&quot;&gt;
&lt;pre&gt;
&lt;span&gt;   def showPO(po: PO) =&lt;span&gt; {
     println(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;po number: ${po.ponum}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
     println(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;po date: ${po.podate.toString}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
     println(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;vendor: ${po.vendor}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
     &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (po.remarks !=&lt;span&gt; None)
       println(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;remarks: ${po.remarks.get}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
     po.podtl match {
       &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; Some(barr) =&amp;gt;&lt;span&gt;
         val docs &lt;/span&gt;=&lt;span&gt; barr.getValues.asScala.toList
         docs.map { dc &lt;/span&gt;=&amp;gt;&lt;span&gt;
           toPODTL(dc.asInstanceOf[org.bson.BsonDocument])
         }.&lt;/span&gt;&lt;span&gt;foreach&lt;/span&gt; { doc: PODTL =&amp;gt;&lt;span&gt;
             print(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;==&amp;gt;Item: ${doc.item} &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
             print(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;price: ${doc.price} &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
             print(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;qty: ${doc.qty} &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
             doc.packing.&lt;/span&gt;&lt;span&gt;foreach&lt;/span&gt;(pk =&amp;gt; print(s&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;packing: ${pk} &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
             doc.payTerm.&lt;/span&gt;&lt;span&gt;foreach&lt;/span&gt;(pt =&amp;gt; print(s&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;payTerm: ${pt} &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
             println(&lt;/span&gt;&lt;span&gt;&quot;&quot;&lt;/span&gt;&lt;span&gt;)
           }
       &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; _ =&amp;gt;&lt;span&gt;
     }

     po.handler match {
       &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; Some(bs) =&amp;gt;&lt;span&gt;
         val fileName &lt;/span&gt;= s&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/users/tiger-macpro/${po.ponum}.png&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
         ByteArrayToFile(bs.getData,fileName)
         println(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;picture saved to ${fileName}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
       &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; None =&amp;gt; println(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;no picture provided&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
     }
   }
   poCollection.find(equal(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podtl.qty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,&lt;span&gt;100&lt;/span&gt;&lt;span&gt;)).toFuture().onComplete {
     &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; Success(docs) =&amp;gt; docs.map(toPO).&lt;span&gt;foreach&lt;/span&gt;&lt;span&gt; (showPO)
       println(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
     &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; Failure(e) =&amp;gt;&lt;span&gt; println(e.getMessage)
   }
   poCollection.find().toFuture().onComplete {
    &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; Success(docs) =&amp;gt; docs.map(toPO).&lt;span&gt;foreach&lt;/span&gt;&lt;span&gt; (showPO)
      println(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;-------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; Failure(e) =&amp;gt;&lt;span&gt; println(e.getMessage)
  }&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;试运行显示结果如下：&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;span&gt;po number: po18022002
po date: Wed Jan &lt;/span&gt;&lt;span&gt;23&lt;/span&gt; &lt;span&gt;11&lt;/span&gt;:&lt;span&gt;57&lt;/span&gt;:&lt;span&gt;50&lt;/span&gt; HKT &lt;span&gt;2013&lt;/span&gt;&lt;span&gt;
vendor: The Samsung compay
&lt;/span&gt;==&amp;gt;Item: samsung galaxy s8 price: &lt;span&gt;2300.0&lt;/span&gt; qty: &lt;span&gt;100&lt;/span&gt;&lt;span&gt; packing: standard 
&lt;/span&gt;==&amp;gt;Item: samsung galaxy s7 price: &lt;span&gt;1897.0&lt;/span&gt; qty: &lt;span&gt;1000&lt;/span&gt; payTerm: &lt;span&gt;30&lt;/span&gt;&lt;span&gt; days 
&lt;/span&gt;==&amp;gt;Item: apple iphone7 price: &lt;span&gt;6500.0&lt;/span&gt; qty: &lt;span&gt;100&lt;/span&gt;&lt;span&gt; packing: luxury 
no picture provided
&lt;/span&gt;-------------------------------&lt;span&gt;
po number: po18012301
po date: Wed Nov &lt;/span&gt;&lt;span&gt;23&lt;/span&gt; &lt;span&gt;11&lt;/span&gt;:&lt;span&gt;57&lt;/span&gt;:&lt;span&gt;50&lt;/span&gt; HKT &lt;span&gt;2011&lt;/span&gt;&lt;span&gt;
vendor: The smartphone compay
remarks: urgent, rush order
&lt;/span&gt;==&amp;gt;Item: sony smartphone price: &lt;span&gt;2389.0&lt;/span&gt; qty: &lt;span&gt;1239&lt;/span&gt;&lt;span&gt; packing: standard 
&lt;/span&gt;==&amp;gt;Item: ericson smartphone price: &lt;span&gt;897.0&lt;/span&gt; qty: &lt;span&gt;1000&lt;/span&gt; payTerm: &lt;span&gt;30&lt;/span&gt;&lt;span&gt; days 
picture saved to &lt;/span&gt;/users/tiger-macpro/&lt;span&gt;po18012301.png
po number: po18022002
po date: Wed Jan &lt;/span&gt;&lt;span&gt;23&lt;/span&gt; &lt;span&gt;11&lt;/span&gt;:&lt;span&gt;57&lt;/span&gt;:&lt;span&gt;50&lt;/span&gt; HKT &lt;span&gt;2013&lt;/span&gt;&lt;span&gt;
vendor: The Samsung compay
&lt;/span&gt;==&amp;gt;Item: samsung galaxy s8 price: &lt;span&gt;2300.0&lt;/span&gt; qty: &lt;span&gt;100&lt;/span&gt;&lt;span&gt; packing: standard 
&lt;/span&gt;==&amp;gt;Item: samsung galaxy s7 price: &lt;span&gt;1897.0&lt;/span&gt; qty: &lt;span&gt;1000&lt;/span&gt; payTerm: &lt;span&gt;30&lt;/span&gt;&lt;span&gt; days 
&lt;/span&gt;==&amp;gt;Item: apple iphone7 price: &lt;span&gt;6500.0&lt;/span&gt; qty: &lt;span&gt;100&lt;/span&gt;&lt;span&gt; packing: luxury 
no picture provided
&lt;/span&gt;------------------------------&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;span&gt;下面是本次示范的源代码：&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;build.sbt&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;name := &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;learn-mongo&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;

version :&lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;0.1&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;

scalaVersion :&lt;/span&gt;= &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;2.12.4&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;

libraryDependencies :&lt;/span&gt;=&lt;span&gt; Seq(
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;org.mongodb.scala&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; %% &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;mongo-scala-driver&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; % &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;2.2.1&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
  &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;com.lightbend.akka&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; %% &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;akka-stream-alpakka-mongodb&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; % &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;0.17&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
)&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;FileStreaming.scala&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;50&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;span&gt;import java.nio.file.Paths

import akka.stream.{Materializer}
import akka.stream.scaladsl.{FileIO, StreamConverters}

import scala.concurrent.{Await}
import akka.util._
import scala.concurrent.duration._

&lt;/span&gt;&lt;span&gt;object&lt;/span&gt;&lt;span&gt; FileStreaming {
  def FileToByteBuffer(fileName: String, timeOut: FiniteDuration)(
    &lt;/span&gt;&lt;span&gt;implicit&lt;/span&gt; mat: Materializer):ByteBuffer =&lt;span&gt; {
    val fut &lt;/span&gt;= FileIO.fromPath(Paths.&lt;span&gt;get&lt;/span&gt;(fileName)).runFold(ByteString()) { &lt;span&gt;case&lt;/span&gt; (hd, bs) =&amp;gt;&lt;span&gt;
      hd &lt;/span&gt;++&lt;span&gt; bs
    }
    (Await.result(fut, timeOut)).toByteBuffer
  }

  def FileToByteArray(fileName: String, timeOut: FiniteDuration)(
    &lt;/span&gt;&lt;span&gt;implicit&lt;/span&gt; mat: Materializer): Array[Byte] =&lt;span&gt; {
    val fut &lt;/span&gt;= FileIO.fromPath(Paths.&lt;span&gt;get&lt;/span&gt;(fileName)).runFold(ByteString()) { &lt;span&gt;case&lt;/span&gt; (hd, bs) =&amp;gt;&lt;span&gt;
      hd &lt;/span&gt;++&lt;span&gt; bs
    }
    (Await.result(fut, timeOut)).toArray
  }

  def FileToInputStream(fileName: String, timeOut: FiniteDuration)(
    &lt;/span&gt;&lt;span&gt;implicit&lt;/span&gt; mat: Materializer): InputStream =&lt;span&gt; {
    val fut &lt;/span&gt;= FileIO.fromPath(Paths.&lt;span&gt;get&lt;/span&gt;(fileName)).runFold(ByteString()) { &lt;span&gt;case&lt;/span&gt; (hd, bs) =&amp;gt;&lt;span&gt;
      hd &lt;/span&gt;++&lt;span&gt; bs
    }
    val buf &lt;/span&gt;=&lt;span&gt; (Await.result(fut, timeOut)).toArray
    &lt;/span&gt;&lt;span&gt;new&lt;/span&gt;&lt;span&gt; ByteArrayInputStream(buf)
  }

  def ByteBufferToFile(byteBuf: ByteBuffer, fileName: String)(
    &lt;/span&gt;&lt;span&gt;implicit&lt;/span&gt; mat: Materializer) =&lt;span&gt; {
    val ba &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; Array[Byte](byteBuf.remaining())
    byteBuf.&lt;/span&gt;&lt;span&gt;get&lt;/span&gt;(ba,&lt;span&gt;0&lt;/span&gt;&lt;span&gt;,ba.length)
    val baInput &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ByteArrayInputStream(ba)
    val source &lt;/span&gt;= StreamConverters.fromInputStream(() =&amp;gt; baInput)  &lt;span&gt;//&lt;/span&gt;&lt;span&gt;ByteBufferInputStream(bytes))&lt;/span&gt;
    source.runWith(FileIO.toPath(Paths.&lt;span&gt;get&lt;/span&gt;&lt;span&gt;(fileName)))
  }

  def ByteArrayToFile(bytes: Array[Byte], fileName: String)(
    &lt;/span&gt;&lt;span&gt;implicit&lt;/span&gt; mat: Materializer) =&lt;span&gt; {
    val bb &lt;/span&gt;=&lt;span&gt; ByteBuffer.wrap(bytes)
    val baInput &lt;/span&gt;= &lt;span&gt;new&lt;/span&gt;&lt;span&gt; ByteArrayInputStream(bytes)
    val source &lt;/span&gt;= StreamConverters.fromInputStream(() =&amp;gt; baInput) &lt;span&gt;//&lt;/span&gt;&lt;span&gt;ByteBufferInputStream(bytes))&lt;/span&gt;
    source.runWith(FileIO.toPath(Paths.&lt;span&gt;get&lt;/span&gt;&lt;span&gt;(fileName)))
  }

  def InputStreamToFile(&lt;/span&gt;&lt;span&gt;is&lt;/span&gt;&lt;span&gt;: InputStream, fileName: String)(
    &lt;/span&gt;&lt;span&gt;implicit&lt;/span&gt; mat: Materializer) =&lt;span&gt; {
    val source &lt;/span&gt;= StreamConverters.fromInputStream(() =&amp;gt; &lt;span&gt;is&lt;/span&gt;&lt;span&gt;)
    source.runWith(FileIO.toPath(Paths.&lt;/span&gt;&lt;span&gt;get&lt;/span&gt;&lt;span&gt;(fileName)))
  }
}&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;MongoScala103.scala&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;89&quot;&gt;
&lt;pre&gt;
&lt;span&gt;&lt;span&gt;import akka.actor.ActorSystem
import akka.stream.ActorMaterializer
import java.util.Calendar

import org.bson.BsonBinary

import scala.util._
import FileStreaming._

import scala.concurrent.duration._
import org.mongodb.scala._
import org.mongodb.scala.bson.{BsonArray, BsonDocument}

import scala.collection.JavaConverters._

import org.mongodb.scala.connection.ClusterSettings
import org.mongodb.scala.model.Filters._
&lt;/span&gt;&lt;span&gt;object&lt;/span&gt;&lt;span&gt; MongoScala103 extends App {
  import Helpers._

  val clusterSettings &lt;/span&gt;=&lt;span&gt; ClusterSettings.builder()
    .hosts(List(&lt;/span&gt;&lt;span&gt;new&lt;/span&gt; ServerAddress(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;localhost:27017&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)).asJava).build()
  val clientSettings &lt;/span&gt;=&lt;span&gt; MongoClientSettings.builder().clusterSettings(clusterSettings).build()
  val client &lt;/span&gt;=&lt;span&gt; MongoClient(clientSettings)

  &lt;/span&gt;&lt;span&gt;implicit&lt;/span&gt; val system =&lt;span&gt; ActorSystem()
  &lt;/span&gt;&lt;span&gt;implicit&lt;/span&gt; val mat =&lt;span&gt; ActorMaterializer()
  &lt;/span&gt;&lt;span&gt;implicit&lt;/span&gt; val ec =&lt;span&gt; system.dispatcher


  val db: MongoDatabase &lt;/span&gt;= client.getDatabase(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;testdb&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
  val poOrgCollection: MongoCollection[Document] &lt;/span&gt;= db.getCollection(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;po&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
  poOrgCollection.drop.headResult()
  val poCollection: MongoCollection[Document] &lt;/span&gt;= db.getCollection(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;po&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)


  val ca &lt;/span&gt;=&lt;span&gt; Calendar.getInstance()
  ca.&lt;/span&gt;&lt;span&gt;set&lt;/span&gt;(&lt;span&gt;2011&lt;/span&gt;,&lt;span&gt;10&lt;/span&gt;,&lt;span&gt;23&lt;/span&gt;&lt;span&gt;)
  val podate1 &lt;/span&gt;=&lt;span&gt; ca.getTime
  ca.&lt;/span&gt;&lt;span&gt;set&lt;/span&gt;(&lt;span&gt;2012&lt;/span&gt;,&lt;span&gt;12&lt;/span&gt;,&lt;span&gt;23&lt;/span&gt;&lt;span&gt;)
  val podate2 &lt;/span&gt;=&lt;span&gt; ca.getTime

  val pic &lt;/span&gt;= FileToByteArray(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/users/tiger-macpro/sample.png&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,&lt;span&gt;3&lt;/span&gt;&lt;span&gt; seconds)

  val po1 &lt;/span&gt;=&lt;span&gt; Document (
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ponum&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;po18012301&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;vendor&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;The smartphone compay&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podate&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt;&lt;span&gt; podate1,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;remarks&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;urgent, rush order&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;handler&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt;&lt;span&gt; pic,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podtl&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt;&lt;span&gt; Seq(
      Document(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;item&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;sony smartphone&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;price&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;2389.00&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;qty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;1239&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;packing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;standard&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
      Document(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;item&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ericson smartphone&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;price&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;897.00&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;qty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;1000&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;payterm&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;30 days&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    )
  )

  val po2 &lt;/span&gt;=&lt;span&gt; Document (
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ponum&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;po18022002&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;vendor&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;The Samsung compay&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podate&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt;&lt;span&gt; podate2,
    &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podtl&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt;&lt;span&gt; Seq(
      Document(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;item&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;samsung galaxy s8&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;price&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;2300.00&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;qty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;100&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;packing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;standard&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
      Document(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;item&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;samsung galaxy s7&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;price&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;1897.00&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;qty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;1000&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;payterm&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;30 days&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
      Document(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;item&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;apple iphone7&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;price&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;6500.00&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;qty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;100&lt;/span&gt;, &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;packing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; -&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;luxury&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    )
  )


  poCollection.insertMany(Seq(po1,po2)).headResult()

  &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; PO (
                 ponum: String,
                 podate: java.util.Date,
                 vendor: String,
                 remarks: Option[String],
                 podtl: Option[BsonArray],
                 handler: Option[BsonBinary]
                 )
  def toPO(doc: Document): PO &lt;/span&gt;=&lt;span&gt; {
      val ks &lt;/span&gt;=&lt;span&gt; doc.keySet
      PO(
        ponum &lt;/span&gt;= doc.getString(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ponum&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
        podate &lt;/span&gt;= doc.getDate(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podate&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
        vendor &lt;/span&gt;= doc.getString(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;vendor&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
        remarks &lt;/span&gt;=&lt;span&gt; {
          &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (ks.contains(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;remarks&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
            Some(doc.getString(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;remarks&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
          &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;
            None
        },
        podtl &lt;/span&gt;=&lt;span&gt; {
          &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (ks.contains(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podtl&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
            doc.&lt;/span&gt;&lt;span&gt;get&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podtl&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;).asInstanceOf[Option[BsonArray]]
          &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;
            None
        },
        handler &lt;/span&gt;=&lt;span&gt; {
          &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (ks.contains(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;handler&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
            doc.&lt;/span&gt;&lt;span&gt;get&lt;/span&gt;(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;handler&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;).asInstanceOf[Option[BsonBinary]]
          &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt;
            None
        }
      )
    }

   &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; &lt;span&gt;class&lt;/span&gt;&lt;span&gt; PODTL(
                   item: String,
                   price: Double,
                   qty: Int,
                   packing: Option[String],
                   payTerm: Option[String]
                   )
   def toPODTL(podtl: Document): PODTL &lt;/span&gt;=&lt;span&gt; {
     val ks &lt;/span&gt;=&lt;span&gt; podtl.keySet
     PODTL(
       item &lt;/span&gt;= podtl.getString(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;item&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
       price &lt;/span&gt;= podtl.getDouble(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;price&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
       qty &lt;/span&gt;= podtl.getInteger(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;qty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;),
       packing &lt;/span&gt;=&lt;span&gt; {
         &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (ks.contains(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;packing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
           Some(podtl.getString(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;packing&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
         &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; None
       },
       payTerm &lt;/span&gt;=&lt;span&gt; {
         &lt;/span&gt;&lt;span&gt;if&lt;/span&gt;(ks.contains(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;payterm&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
           Some(podtl.getString(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;payterm&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
         &lt;/span&gt;&lt;span&gt;else&lt;/span&gt;&lt;span&gt; None
       }
     )
   }

   def showPO(po: PO) &lt;/span&gt;=&lt;span&gt; {
     println(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;po number: ${po.ponum}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
     println(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;po date: ${po.podate.toString}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
     println(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;vendor: ${po.vendor}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
     &lt;/span&gt;&lt;span&gt;if&lt;/span&gt; (po.remarks !=&lt;span&gt; None)
       println(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;remarks: ${po.remarks.get}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
     po.podtl match {
       &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; Some(barr) =&amp;gt;&lt;span&gt;
         val docs &lt;/span&gt;=&lt;span&gt; barr.getValues.asScala.toList
         docs.map { dc &lt;/span&gt;=&amp;gt;&lt;span&gt;
           toPODTL(dc.asInstanceOf[org.bson.BsonDocument])
         }.&lt;/span&gt;&lt;span&gt;foreach&lt;/span&gt; { doc: PODTL =&amp;gt;&lt;span&gt;
             print(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;==&amp;gt;Item: ${doc.item} &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
             print(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;price: ${doc.price} &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
             print(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;qty: ${doc.qty} &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
             doc.packing.&lt;/span&gt;&lt;span&gt;foreach&lt;/span&gt;(pk =&amp;gt; print(s&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;packing: ${pk} &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
             doc.payTerm.&lt;/span&gt;&lt;span&gt;foreach&lt;/span&gt;(pt =&amp;gt; print(s&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;payTerm: ${pt} &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;))
             println(&lt;/span&gt;&lt;span&gt;&quot;&quot;&lt;/span&gt;&lt;span&gt;)
           }
       &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; _ =&amp;gt;&lt;span&gt;
     }

     po.handler match {
       &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; Some(bs) =&amp;gt;&lt;span&gt;
         val fileName &lt;/span&gt;= s&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/users/tiger-macpro/${po.ponum}.png&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
         ByteArrayToFile(bs.getData,fileName)
         println(s&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;picture saved to ${fileName}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
       &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; None =&amp;gt; println(&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;no picture provided&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
     }

   }

   poCollection.find().toFuture().onComplete {
     &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; Success(docs) =&amp;gt; docs.map(toPO).&lt;span&gt;foreach&lt;/span&gt;&lt;span&gt; (showPO)
       println(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
     &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; Failure(e) =&amp;gt;&lt;span&gt; println(e.getMessage)
   }


   poCollection.find(equal(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;podtl.qty&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,&lt;span&gt;100&lt;/span&gt;&lt;span&gt;)).toFuture().onComplete {
    &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; Success(docs) =&amp;gt; docs.map(toPO).&lt;span&gt;foreach&lt;/span&gt;&lt;span&gt; (showPO)
      println(&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;-------------------------------&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;)
    &lt;/span&gt;&lt;span&gt;case&lt;/span&gt; Failure(e) =&amp;gt;&lt;span&gt; println(e.getMessage)
  }


  scala.io.StdIn.readLine()
  system.terminate()

}&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

</description>
<pubDate>Tue, 06 Mar 2018 04:21:00 +0000</pubDate>
<dc:creator>雪川大虫</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/tiger-xc/p/8513685.html</dc:identifier>
</item>
<item>
<title>终于，我也要出一本C#的书了 - 我的写作历程与C#书单推荐 - 风口上的猪</title>
<link>http://www.cnblogs.com/haoyifei/p/8513687.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/haoyifei/p/8513687.html</guid>
<description>&lt;p&gt;我之前的面试题停了很久，是因为 - 我写书去了。&lt;/p&gt;
&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;我于2012年3月开始工作，到现在马上就满六年了。这六年里，我从一个连Sql server是什么都不知道，只会写最简单的c#的程序员开始做起，一步一步从一个籍籍无名的外包公司奋斗到了一个比较大的金融机构的中层，工资也提升到刚参加工作的接近四倍。在奋斗的过程中，我也走了很多弯路，一度十分消沉，但幸运的是，最终我的努力并没有白费。&lt;/p&gt;
&lt;p&gt;我一直就是一个比较喜欢写文章的人。在平时工作时，我也喜欢把很多必要的东西（例如服务器的ip地址，登录密码等）写下来，并做成文档以便随时查阅。在前几年，我对自己的公司不满意，在业余时间一直在准备跳槽，于是，我搜集了很多面试题和解答。后来我发现这样准备毫无系统性，便去买了本书开始看。说来惭愧，我在工作的第三年才开始系统的看书，那时买的第一本书是《精通C#》第6版。在读书的同时，我也知道了其实C#领域最出名的书是clr via c#，并买了一本，重写了自己的文章（之前它们只是面试题的解答），慢慢贴到网上，成为了面试题系列。在这个系列的编写过程中，我也参考了博客园上很多杰出的网友的优秀文章。这个过程中我的技术水平提高了很多。在写博客的同时，我也得到了某公司编辑的注意。通过博客园站内信，编辑希望我写一本关于C#的书。当时我清点了一下自己文章存货，发现总字数已经有大概10万左右，而且那时候公司工作也不忙，就同意了。&lt;/p&gt;
&lt;h2&gt;书籍写作&lt;/h2&gt;
&lt;p&gt;在签了初步合同之后，编辑将我的书命名为C#笔试面试题集，因为毕竟我在网上的博客和面试题关系比较密切。我根据自己电脑里已有的文章存货，提交了目录，并拟定为7大块：&lt;br/&gt;1 .NET基础知识，包括类型基础，面向对象等&lt;br/&gt;2 C#重要特性，包括委托事件，泛型反射，LINQ等&lt;br/&gt;3 设计模式&lt;br/&gt;4 数据库基础知识&lt;br/&gt;5 算法基础知识&lt;br/&gt;6 测试，部署和持续集成&lt;br/&gt;7 多线程&lt;/p&gt;
&lt;p&gt;之所以包括这么多内容，是因为我在准备面试时对这些都写了文章。但在写书的过程中，我逐渐发现，我的“野心太大”了。如果我按照上面的大纲去写书，我不仅时间不够，目前的能力也完全无法胜任：我的算法水平很一般，也不是设计模式和数据库专家，对测试和部署的经验也不多。而且，即使在刚开始写.NET基础知识这部分我自以为最“擅长”的部分时，我也在查资料和参考其他书时，发现我的认知其实还颇为皮毛。因此，在刚开始写书时，虽然是在过去文章的基础上改进，我的进度仍然很慢。有时候，我还会不时的在网上撞到一篇超强文章，它比我的认识透彻多了，导致之前写的大部分内容都得重写。&lt;/p&gt;
&lt;p&gt;在写书进行了几个月之后，我决定从书中砍掉设计模式，数据库，算法，测试和部署，并令书更加集中于c#的讨论。这样一来可以不让书的内容过于松散，二来也让自己更有信心。现在，整个书已经写了90%，这个月底就全部交稿了。在交稿之后，相信还会有一段审稿和与编辑讨论的时间。等到该书正式出版时，我再来通知大家。现在这本书的内容包括：&lt;br/&gt;1 .NET基础知识，包括程序集，类型基础，内存分配，面向对象，字符串，GC等。介绍了一点关于IL的知识。&lt;br/&gt;2 C#，包括委托事件，泛型反射，LINQ，DLR，C#6和7的新特性等&lt;br/&gt;3 多线程，包括多线程基础知识，同步与锁，异步模型，async/await等&lt;/p&gt;
&lt;p&gt;第一部分主要参考了clr via c#的第一和第二部分以及其他国内外相关书&lt;br/&gt;第二部分主要参考了深入理解c#以及其他国内外相关书&lt;br/&gt;第三部分主要参考了clr via c#最后一部分（关于线程的），深入理解c#的async/await那部分。我试图用较为容易理解的语言将这两本书的相关章节解释清楚。&lt;/p&gt;
&lt;p&gt;我对本书的定位是：适合有1-2年开发经验的人士阅读。该书的书名已经确定为《c# 从现象到本质》，将会有以下几个特点：&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;与时俱进，对最新推出的C# 7的特性也有涵盖，但不会介绍最基础的c#语法&lt;/li&gt;
&lt;li&gt;夯实基础，深入本质，并非简单的msdn搬运工 + 一段又长又没有注释的代码这种风格的图书，例如，《21天。。。》。本书会提到IL,并不时张贴IL代码以便深入分析各种语法糖背后的实质&lt;/li&gt;
&lt;li&gt;目前市面上关于c#多线程的中文资料较少，大部分c#书籍在这部分都是简单一提，但我的书中多线程将自成一篇，包括5章，使用通俗易懂的文字解释c#多线程相关的各种各样的锁和同步工具，以及异步编程模型，直到最新的async/await&lt;/li&gt;
&lt;li&gt;重视英语，很多名词旁边配有对应英文翻译&lt;/li&gt;
&lt;/ol&gt;&lt;h2&gt;参考书籍&lt;/h2&gt;
&lt;p&gt;我在写作的时候参考了大量书籍，从大名鼎鼎的赵三本到很多博客园网友写的书，和其他中英文书籍。在阅读他人的书籍时，我也发现有些书真的十分优秀，但却默默无闻。有些书的某些章节颇为精彩。这里我也将它们列出来，作为一个我自己推荐的C#进阶书单。&lt;/p&gt;
&lt;p&gt;如果你基础不是很扎实，那么可以找来《精通C# 第6版》入门（不用看wpf,wcf那几部分），或者《Learning hard C#学习笔记》也行。前者内容比较多，后者相对比较简练，可以增强学习信心。但最好的入门书我认为是《NET 4.0面向对象编程漫谈 基础篇》这本。&lt;/p&gt;
&lt;p&gt;下面的书都不是用来入门的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CLR via C#第四版&lt;/strong&gt;&lt;br/&gt;这本书实在太重要了，太有名了。实际上，它几乎出现在任何一本讲C#的书的参考资料中。该书虽然现在看来已经有点“过时”了，但它对CLR的讲解是十分透彻的。很多国人的C#书籍，都或多或少的受了这本书的影响。&lt;/p&gt;
&lt;p&gt;该书虽然很厚，但结构十分清晰，分为五大部分：&lt;br/&gt;1. CLR基础，讲程序集的结构和部署，IL，JIT，类型系统。第一章很重要，必须好好看，第二章和第三章相对不那么重要。&lt;br/&gt;2. 设计类型，该部分遍览了一个类型可以拥有的所有成员，所有章节都很重要，第12章泛型尤其重要。&lt;br/&gt;3. 基本类型，13，14，16，17，19章很重要，15和18可以大概看看。&lt;br/&gt;4. 核心机制，主要包括异常处理，GC，应用程序域，反射和序列化。&lt;br/&gt;5. 线程处理，作为Windows操作系统的大师，作者对线程的理解非常深入。26章主要是概念，27-30章全是多线程，通读这部分对多线程的理解帮助极大。不过，该部分充斥大量专有名词，对非windows高手来说不太友好。可以和其他多线程书配合着看。&lt;/p&gt;
&lt;p&gt;这本书由于成书较早，因此缺失了对C#一些较新版本功能的介绍，例如LINQ等。此时，就需要另外一本大名鼎鼎的书 - 《深入理解C#》出来救场了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;深入理解C#&lt;/strong&gt;&lt;br/&gt;这本书相比上一本不那么“底层”，不过，它的阅读难度也不小。对于更喜欢特性而非原理的读者，可以通读一遍此书，它按照演进顺序讲述了C#1-5的所有特性，对LINQ，异步的讲解既实用又涉及原理。本书所有章节都很重要。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;.NET设计规范：约定，惯用法与模式&lt;/strong&gt;&lt;br/&gt;在争论应该是抽象类还是接口，应该是类还是结构时，我们其实看看这本书就够了，它早就给了我们一大堆最佳实践。不知道怎么书写异常处理？看看第七章吧。本书实际上就是一个代码规范集合。&lt;/p&gt;
&lt;p&gt;本书适合在需要的时候随时查阅。以上三本书相辅相成，包括了一个中级开发者需要掌握的所有主语言相关技能（实际上，即使只理解一半也已经足够好了），故被某知名程序员称为“赵三本”。该程序员还认为，充分理解了“赵三本”的开发者在大陆的待遇应至少为20k人民币每月，即中级开发者。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pro .NET Performance&lt;/strong&gt;&lt;br/&gt;本书以一个独特的视角 – 性能作为切入点，讲述了.NET程序和类型在性能这一方面的体现。该书的前两章主要讨论了性能测试的衡量方法和工具，第三章深入了类型系统，第四章详细的讲述了GC，这两章值得细读。&lt;/p&gt;
&lt;p&gt;本书目前只有英文版，阅读难度很大。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;.NET本质论 第一卷 公共语言运行时（Don Box）&lt;/strong&gt;&lt;br/&gt;本书实际上就是在讲CLR，它也是对CLR的探讨中，我目前知道的书中，最底层，最深入的一本。该书的作者同时也是COM专家，因此，对于CLR这个更好的COM来说，他必然也是驾轻就熟。&lt;/p&gt;
&lt;p&gt;本书中我最喜欢的部分是第6章，作者使用了一章的篇幅讨论了方法调用。该书过于底层，成书年代也很早，读起来可能有些脱离实际的感觉。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NET 4.0面向对象编程漫谈 基础篇&lt;/strong&gt;&lt;br/&gt;本书的作者是金旭亮老师。他的这本书（以及后面相邻的那本）以生动有趣的笔触讲解了.NET的方方面面。我个人非常喜欢这本书。如果你觉得《CLR via C#》太枯燥，行文方式又过于老外，看不下去，可以先看这本。这本书虽然没有《CLR via C#》那么深，但对于底层也有颇多涉及，它和很多粗制滥造的“拖控件教程”有着本质的不同。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NET 4.0面向对象编程漫谈 应用篇&lt;/strong&gt;&lt;br/&gt;作者在此书中着重分析了进程和线程以及在C#中的实地应用。这是多线程方面来自国人的为数较少的好资料。这本书和上一本一样，我强烈推荐。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;你必须知道的.NET（第二版）&lt;/strong&gt;&lt;br/&gt;本书的编排顺序十分独特。它的视角是完全面向对象的，并且将.NET各个知识点以逐个对比的方式呈现在了读者面前，第一次阅读时，可能会觉得不太适应。本书有一定深度，而且作者行文比较幽默，因此读起来也不是很枯燥。&lt;/p&gt;
&lt;p&gt;本书有很多SOLID和设计模式方面的内容，对开发者不无裨益。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Threading in C#&lt;/strong&gt;&lt;br/&gt;本书（以网页形式在网上公开）提供了另一个关于C#多线程的介绍资料，目前已经有翻译版本https://blog.gkarch.com/threading/part1.html。该书对.NET提供的各种各样的锁都有所涉及，可以和《CLR via C#》最后四章一起看。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;.NET之美 .net关键技术深入解析&lt;/strong&gt;&lt;br/&gt;本书是博客园网友张子阳的作品。这本书的委托那章是经典之作。&lt;/p&gt;
&lt;p&gt;其他多线程书籍包括async in c#(只有英文)，c#并发编程经典实例（这本内容新，但实在是。。。难懂）以及C#并行编程高级教程（这本难度还比较温和但没有async/await）。&lt;/p&gt;
&lt;h2&gt;结语&lt;/h2&gt;
&lt;p&gt;我写书并非是指望它挣多少钱（稿费很低）。首先，我对技术与.net有着浓厚的兴趣，常常在写书时搞到废寝忘食，玩游戏都觉得没意思了。另外，我的文章受到出版社编辑的赏识也是对我能力的一种肯定，我既然接下了这个任务就应该认真完成，对得起自己写的每一个字，不误导读者。最后，我也希望通过写书这个契机认识更多的朋友，给自己带来更多的机会。这本书顺利出版之后，我的下一步可能会转向人工智能或机器学习方向的学习和研究（我自学过作曲理论，也一直对人工智能作曲很有兴趣），或者算法方面的研究（出一本书用c#实现各种小游戏求解，例如华容道，数字拼图等等），现在还没有确定。但是我可以确定的是，整个写书的过程中，我收获了很多，也很快乐。&lt;/p&gt;

</description>
<pubDate>Tue, 06 Mar 2018 04:15:00 +0000</pubDate>
<dc:creator>风口上的猪</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/haoyifei/p/8513687.html</dc:identifier>
</item>
<item>
<title>ELK 经典用法—企业自定义日志收集切割和mysql模块 - 阿龙along</title>
<link>http://www.cnblogs.com/along21/p/8513420.html</link>
<guid isPermaLink="true" >http://www.cnblogs.com/along21/p/8513420.html</guid>
<description>&lt;p&gt;&lt;strong&gt;本文收录在&lt;span&gt;&lt;a id=&quot;cb_post_title_url&quot; href=&quot;http://www.cnblogs.com/along21/p/8000812.html&quot;&gt;&lt;span&gt;Linux运维企业架构实战系列&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span&gt;一、收集切割公司自定义的日志&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;很多公司的日志并不是和服务默认的日志格式一致，因此，就需要我们来进行切割了。&lt;/p&gt;
&lt;h3&gt;&lt;span&gt;1、需切割的日志示例&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;2018-02-24 11:19:23,532 [143] DEBUG performanceTrace 1145 http://api.114995.com:8082/api/Carpool/QueryMatchRoutes 183.205.134.240 null 972533 310000 TITTL00 HUAWEI 860485038452951 3.1.146 HUAWEI 5.1 113.552344 33.332737 发送响应完成 Exception:(null)&lt;/p&gt;

&lt;h3&gt;&lt;span&gt;2、切割的配置&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;在logstash 上，使用fifter 的grok 插件进行切割&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;input {
        beats {
                port &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;5044&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
        }
}

filter {
    grok {
        match &lt;/span&gt;=&amp;gt;&lt;span&gt; {
            &lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;message&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; =&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;%{TIMESTAMP_ISO8601:timestamp} \[%{NUMBER:thread:int}\] %{DATA:level} (?&amp;lt;logger&amp;gt;[a-zA-Z]+) %{NUMBER:executeTime:int} %{URI:url} %{IP:clientip} %{USERNAME:UserName} %{NUMBER:userid:int} %{NUMBER:AreaCode:int} (?&amp;lt;Board&amp;gt;[0-9a-zA-Z]+[-]?[0-9a-zA-Z]+) (?&amp;lt;Brand&amp;gt;[0-9a-zA-Z]+[-]?[0-9a-zA-Z]+) %{NUMBER:DeviceId:int} (?&amp;lt;TerminalSourceVersion&amp;gt;[0-9a-z\.]+) %{NUMBER:Sdk:float} %{NUMBER:Lng:float} %{NUMBER:Lat:float} (?&amp;lt;Exception&amp;gt;.*)&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
        }
        remove_field &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;message&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
    }
    date {
                   match &lt;/span&gt;=&amp;gt; [&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;timestamp&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;dd/MMM/YYYY:H:m:s Z&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;]
        remove_field &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;timestamp&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
           }
    geoip {
        source &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;clientip&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
        target &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;geoip&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
        database &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;/etc/logstash/maxmind/GeoLite2-City.mmdb&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
    }
}

output {
    elasticsearch {
        hosts &lt;/span&gt;=&amp;gt; [&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http://192.168.10.101:9200/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;]
        index &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;logstash-%{+YYYY.MM.dd}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
        document_type &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;apache_logs&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
    }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;&lt;span&gt;3、切割解析后效果&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1216496/201803/1216496-20180306113024199-1437466737.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;&lt;span&gt;4、最终kibana 展示效果&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;① top10 clientip&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1216496/201803/1216496-20180306113024808-309773843.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;② top5 url&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1216496/201803/1216496-20180306113025121-594193422.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;③ 根据ip 显示地理位置&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1216496/201803/1216496-20180306113025605-717311722.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;⑤ top10 executeTime&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1216496/201803/1216496-20180306113025855-1442464812.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;⑥ 其他字段都可进行设置，多种图案，也可将多个图形放在一起展示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1216496/201803/1216496-20180306113026230-1898007318.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;


&lt;h2&gt;&lt;span&gt;二、grok 用法详解&lt;/span&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;span&gt;1、简介&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;　　Grok是迄今为止使蹩脚的、无结构的日志结构化和可查询的最好方式。Grok在解析 syslog logs、apache and other webserver logs、mysql logs等任意格式的文件上表现完美。&lt;/p&gt;
&lt;p&gt;　　Grok内置了120多种的正则表达式库，地址:https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns。&lt;/p&gt;

&lt;h3&gt;&lt;span&gt;2、入门例子&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;① 示例&lt;/p&gt;
&lt;p&gt;55.3.244.1 GET /index.html 15824 0.043&lt;/p&gt;

&lt;p&gt;② 分析&lt;/p&gt;
&lt;p&gt;　　这条日志可切分为5个部分，&lt;strong&gt;IP(55.3.244.1)、方法(GET)、请求文件路径(/index.html)、字节数(15824)、访问时长(0.043)&lt;/strong&gt;,对这条日志的解析模式(正则表达式匹配)如下:&lt;/p&gt;
&lt;p&gt;%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}&lt;/p&gt;

&lt;p&gt;③ 写到filter中&lt;/p&gt;
&lt;p&gt;filter { grok { match =&amp;gt; { &quot;message&quot; =&amp;gt; &quot;%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}&quot;} } }&lt;/p&gt;

&lt;p&gt;④ 解析后效果&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;32&quot;&gt;
&lt;pre&gt;
client: &lt;span&gt;55.3&lt;/span&gt;.&lt;span&gt;244.1&lt;/span&gt;&lt;span&gt;
method: GET
request: &lt;/span&gt;/&lt;span&gt;index.html
bytes: &lt;/span&gt;&lt;span&gt;15824&lt;/span&gt;&lt;span&gt;
duration: &lt;/span&gt;&lt;span&gt;0.043&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;&lt;span&gt;3、解析任意格式日志&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;（1）解析任意格式日志的步骤：&lt;/p&gt;
&lt;p&gt;① 先确定日志的切分原则，也就是一条日志切分成几个部分。&lt;/p&gt;
&lt;p&gt;② 对每一块进行分析，如果Grok中正则满足需求，直接拿来用。如果Grok中没用现成的，采用自定义模式。&lt;/p&gt;
&lt;p&gt;③ 学会在&lt;a href=&quot;http://grokdebug.herokuapp.com/&quot;&gt;&lt;span&gt;Grok Debugger&lt;/span&gt;&lt;/a&gt;中调试。&lt;/p&gt;

&lt;p&gt;（2）grok 的分类&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;满足自带的grok 正则 grok_pattern&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;① 可以查询&lt;/p&gt;
&lt;p&gt;# less /usr/share/logstash/vendor/bundle/jruby/1.9/gems/logstash-patterns-core-4.1.1/patterns/grok-patterns&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1216496/201803/1216496-20180306113026527-393823741.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;② 使用格式&lt;/p&gt;
&lt;p&gt;grok_pattern 由零个或多个 &lt;span&gt;&lt;strong&gt;%{SYNTAX:SEMANTIC}&lt;/strong&gt;&lt;/span&gt;组成&lt;/p&gt;
&lt;p&gt;例： %{IP:clientip}&lt;/p&gt;
&lt;p&gt;　　其中SYNTAX 是表达式的名字，是由grok提供的：例如数字表达式的名字是NUMBER，IP地址表达式的名字是IP&lt;/p&gt;
&lt;p&gt;　　SEMANTIC 表示解析出来的这个字符的名字，由自己定义，例如IP字段的名字可以是 client&lt;/p&gt;

&lt;ul&gt;&lt;li&gt;&lt;strong&gt;自定义SYNTAX&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;使用格式：(?&amp;lt;field_name&amp;gt;the pattern here)&lt;/p&gt;
&lt;p&gt;例：(?&amp;lt;Board&amp;gt;[0-9a-zA-Z]+[-]?[0-9a-zA-Z]+)&lt;/p&gt;

&lt;p&gt;（3）正则解析容易出错，强烈建议使用Grok Debugger调试，姿势如下（我打开这个网页不能用）&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1216496/201803/1216496-20180306113026949-1306496664.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h2&gt;&lt;span&gt;三、使用mysql 模块，收集mysql 日志&lt;/span&gt;&lt;/h2&gt;
&lt;h3&gt;&lt;span&gt;1、官方文档使用介绍&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-module-mysql.html&quot;&gt;&lt;span&gt;https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-module-mysql.html&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;&lt;span&gt;2、配置filebeat ，使用mysql 模块收集mysql 的慢查询&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;# vim filebeat.yml&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#=========================== Filebeat prospectors =============================
filebeat.modules:
- module: mysql
  error:
    enabled: true
    var.paths: [&quot;/var/log/mariadb/mariadb.log&quot;]

  slowlog:
    enabled: true
    var.paths: [&quot;/var/log/mariadb/mysql-slow.log&quot;]
#----------------------------- Redis output --------------------------------
output.redis:
  hosts: [&quot;192.168.10.102&quot;]
  password: &quot;ilinux.io&quot;
  key: &quot;httpdlogs&quot;
  datatype: &quot;list&quot;
  db: 0
  timeout: 5&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;&lt;span&gt;3、elk—logstash 切割mysql 的慢查询日志&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;① 切割配置&lt;/p&gt;
&lt;p&gt;# vim mysqllogs.conf&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;36&quot;&gt;
&lt;pre&gt;
&lt;span&gt;input {
        redis {
                host &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;192.168.10.102&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
                port &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;6379&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
                password &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;ilinux.io&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
                data_type &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;list&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
                key &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;httpdlogs&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
                threads &lt;/span&gt;=&amp;gt; 2&lt;span&gt;
        }
}

filter {
        grok {
                match &lt;/span&gt;=&amp;gt; { &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;message&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; =&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;(?m)^#\s+User@Host:\s+%{USER:user}\[[^\]]+\]\s+@\s+(?:(?&amp;lt;clienthost&amp;gt;\S*) )?\[(?:%{IPV4:clientip})?\]\s+Id:\s+%{NUMBER:row_id:int}\n#\s+Query_time:\s+%{NUMBER:query_time:float}\s+Lock_time:\s+%{NUMBER:lock_time:float}\s+Rows_sent:\s+%{NUMBER:rows_sent:int}\s+Rows_examined:\s+%{NUMBER:rows_examined:int}\n\s*(?:use %{DATA:database};\s*\n)?SET\s+timestamp=%{NUMBER:timestamp};\n\s*(?&amp;lt;sql&amp;gt;(?&amp;lt;action&amp;gt;\w+)\b.*;)\s*(?:\n#\s+Time)?.*$&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; }
        }
        date {
                match &lt;/span&gt;=&amp;gt; [&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;timestamp&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;dd/MMM/YYYY:H:m:s Z&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;]
                remove_field &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;timestamp&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
        }
}

output {
        elasticsearch {
                hosts &lt;/span&gt;=&amp;gt; [&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http://192.168.10.101:9200/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;]
                index &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;logstash-%{+YYYY.MM.dd}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
                document_type &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;mysql_logs&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
        }
}&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;② 切割后显示结果&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1216496/201803/1216496-20180306113027324-2144020688.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;&lt;span&gt;4、kibana 最终显示效果&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;① 哪几个的数据库最多，例：top2 库&lt;/p&gt;
&lt;p&gt;表无法显示，因为有些语句不涉及表，切割不出来&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1216496/201803/1216496-20180306113027542-1115686699.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;② 哪几个sql语句出现的最多，例：top5 sql语句&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1216496/201803/1216496-20180306113027839-219366439.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;③ 哪几个sql语句出现的最多，例：top5 sql语句&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1216496/201803/1216496-20180306113028042-833619175.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;④ 哪几台服务器慢查询日志生成的最多，例：top5 服务器&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1216496/201803/1216496-20180306113028230-1756534488.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;⑤ 哪几个用户慢查询日志生成的最多，例：top2 用户&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1216496/201803/1216496-20180306113028433-716492115.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;p&gt;可以合并显示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://images2017.cnblogs.com/blog/1216496/201803/1216496-20180306113028714-993202256.png&quot; alt=&quot;&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;&lt;span&gt;5、使用mysql 模块收集mysql 的慢查询&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;（1）filebeat 配置和上边一样&lt;/p&gt;

&lt;p&gt;（2）elk—logstash 切割mysql 的错误日志&lt;/p&gt;
&lt;p&gt;# vim mysqllogs.conf&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;35&quot;&gt;
&lt;pre&gt;
&lt;span&gt;filter {
        grok {
                match &lt;/span&gt;=&amp;gt; { &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;message&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt; =&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;(?&amp;lt;timestamp&amp;gt;\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}) %{NUMBER:pid:int} \[%{DATA:level}\] (?&amp;lt;content&amp;gt;.*)&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt; }
        }
        date {
                match &lt;/span&gt;=&amp;gt; [&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;timestamp&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;,&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;dd/MMM/YYYY:H:m:s Z&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;]
                remove_field &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;timestamp&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
        }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;（3）就不在展示结果了&lt;/p&gt;

&lt;h2&gt;&lt;span&gt;四、ELK 收集多实例日志&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;很多情况下，公司资金不足，不会一对一收集日志；因此，一台logstash 使用多实例收集处理多台agent 的日志很有必要。&lt;/p&gt;
&lt;h3&gt;&lt;span&gt;1、filebeat 的配置&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;主要是output 的配置，只需不同agent 指向不同的端口即可&lt;/p&gt;
&lt;p&gt;① agent 1 配置指向5044 端口&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#----------------------------- Logstash output --------------------------------
output.logstash:
  # The Logstash hosts
  hosts: [&quot;192.168.10.107:5044&quot;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;② agent 2 配置指向5045 端口&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;33&quot;&gt;
&lt;pre&gt;
&lt;span&gt;#----------------------------- Logstash output --------------------------------
output.logstash:
  # The Logstash hosts
  hosts: [&quot;192.168.10.107:5045&quot;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;&lt;span&gt;2、logstash 的配置&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;针对不同的agent ，input 指定对应的端口&lt;/p&gt;
&lt;p&gt;① agent 1&lt;/p&gt;

&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;input {
        beats {
                port &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;5044&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
        }
}
output {   &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;可以在output 加以区分&lt;/span&gt;
&lt;span&gt;        elasticsearch {
                hosts &lt;/span&gt;=&amp;gt; [&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http://192.168.10.107:9200/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;]
                index &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;logstash-apache1-%{+YYYY.MM.dd}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
                document_type &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;apache1_logs&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
        }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;② agent 1&lt;/p&gt;
&lt;div class=&quot;cnblogs_code&quot; readability=&quot;34&quot;&gt;
&lt;pre&gt;
&lt;span&gt;input {
        beats {
                port &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;5045&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
        }
}
output {   &lt;/span&gt;&lt;span&gt;#&lt;/span&gt;&lt;span&gt;可以在output 加以区分&lt;/span&gt;
&lt;span&gt;        elasticsearch {
                hosts &lt;/span&gt;=&amp;gt; [&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;http://192.168.10.107:9200/&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;]
                index &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;logstash-apache2-%{+YYYY.MM.dd}&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
                document_type &lt;/span&gt;=&amp;gt; &lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;apache2_logs&lt;/span&gt;&lt;span&gt;&quot;&lt;/span&gt;&lt;span&gt;
        }
}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;开启对应的服务就ok 了。&lt;/p&gt;

</description>
<pubDate>Tue, 06 Mar 2018 03:41:00 +0000</pubDate>
<dc:creator>阿龙along</dc:creator>
<dc:language>zh-cn</dc:language>
<dc:format>text/html</dc:format>
<dc:identifier>http://www.cnblogs.com/along21/p/8513420.html</dc:identifier>
</item>
</channel>
</rss>